{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"5f5b1ac3c4db4dd77972997d7d5684e05813be04","modified":1569660660831},{"_id":"themes/next/.gitignore","hash":"32ea93f21d8693d5d8fa4eef1c51a21ad0670047","modified":1569660660995},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1569660660995},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1569660660994},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1569660660995},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1569660660995},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1569660660996},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1569660660995},{"_id":"themes/next/.travis.yml","hash":"c42d9608c8c7fe90de7b1581a8dc3886e90c179e","modified":1569660660996},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1569660660996},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1569660660996},{"_id":"themes/next/README.en.md","hash":"32d6cdfec1447f54aae1d7f1365ce6733dfcec8f","modified":1569660660996},{"_id":"themes/next/_config.yml","hash":"ad953b7cdfe51f7e4a0671f2273ec6386fc803b8","modified":1569660660996},{"_id":"themes/next/bower.json","hash":"7d7938f9da896fe710aa0e9120140e528bf058df","modified":1569660660996},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1569660660996},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1569660660997},{"_id":"themes/next/package.json","hash":"193dad6f59a588908fac082cc46fe067dac1b84d","modified":1569660661011},{"_id":"source/_posts/Algorithm-Dynamic-programming.md","hash":"2a896ba8c9e3fee81e5a399367b93bc4a68d4d79","modified":1569660660832},{"_id":"source/_posts/Algorithm-Big-data-sort-with-BitSet.md","hash":"393f573fed905bf50b44fb7b49193c9a70b6629e","modified":1569660660832},{"_id":"source/_posts/Algorithm-Divide-and-conquer.md","hash":"1d1c9f542045d066b2169f0fa0fe015c3b8460b2","modified":1569660660832},{"_id":"source/_posts/.DS_Store","hash":"4c0a29dd23d96555b17ed83ca45d0d8e19608544","modified":1569660660832},{"_id":"source/_posts/Algorithm-Kmp.md","hash":"9fd8aac4251032e2556ab7b58053bd6f35d9bcbe","modified":1569660660832},{"_id":"source/_posts/CPP-C-Posix-Library.md","hash":"b6113bd1b777922f830045cd20a047001a027c08","modified":1569660660832},{"_id":"source/_posts/Algorithm-Sort.md","hash":"f6eae5fb24b0624313f0f910360090c502d37701","modified":1569660660832},{"_id":"source/_posts/Algorithm-Recursion.md","hash":"63e9e1b61dba199fa5a298823edefb85cf9a4c2b","modified":1569660660832},{"_id":"source/_posts/CPP-Memory-leak.md","hash":"59a3edb275562e01605ef1e7a48cc59938ba4669","modified":1569660660833},{"_id":"source/_posts/CPP-File-Operations.md","hash":"6e9cce4d928b7967f32e318cc501526d375b307c","modified":1569660660833},{"_id":"source/_posts/CPP-Endian.md","hash":"4773d237bb56ee12b097c38fd04d4487ddf07eda","modified":1569660660832},{"_id":"source/_posts/Cobar-Reactor-design-pattern.md","hash":"83b4c81a4233e3e8d19ac9b49ebb697954c36527","modified":1569660660851},{"_id":"source/_posts/Curator-sync-and-mutual-exclusion-between-thread-and-process.md","hash":"adfb453524a26e4a44034718c4564ae02f55f2e8","modified":1569660660859},{"_id":"source/_posts/Curator-Distributed-lock.md","hash":"4ce7ecbc35261132da1e63a5a877d340349937c5","modified":1569660660859},{"_id":"source/_posts/DataStructure-Red-black-tree.md","hash":"14cebbae85ae7e30a4991bbbbaa7059a711a5e84","modified":1569660660859},{"_id":"source/_posts/DataStructure-Skiplist.md","hash":"f9115aee20054c23d3c8ed127de94c4ccdcf9ec6","modified":1569660660859},{"_id":"source/_posts/Disruptor-Internal.md","hash":"f42ff5c18969d1cc7da815f59480fb6910758ac6","modified":1569660660859},{"_id":"source/_posts/Disruptor-Low-Latency-Mode.md","hash":"f7d1ac366e71af674525fa384440570711edbff7","modified":1569660660860},{"_id":"source/_posts/Distributed-CAP.md","hash":"91d78d7e2480e66df700765e1287b0be451dac9f","modified":1569660660860},{"_id":"source/_posts/Distributed-Consensus-Raft.md","hash":"c1a9ed77ae882f4d52f5612d636201875d66c00f","modified":1569660660860},{"_id":"source/_posts/Distributed-Transaction-TCC.md","hash":"cf9bec2c4b64876dc17faf9baaec72b9619d8d94","modified":1569660660860},{"_id":"source/_posts/Distributed-Unique-id.md","hash":"9251d391cad3597140c12cecb7f24ad8a4d49f8b","modified":1569660660862},{"_id":"source/_posts/Distributed-Transaction.md","hash":"45df09aa76c88d30e2913be4cca7250c8927ef76","modified":1569660660860},{"_id":"source/_posts/Failfast-Failover-Failsafe-Failback.md","hash":"6ba1d5bcc42fa6a79e03308952c237622ed77a05","modified":1569660660863},{"_id":"source/_posts/Flink-FAQ.md","hash":"650687d9d66cb1e3aaba5f722833065877b7f103","modified":1573709836962},{"_id":"source/_posts/Flink-CheckoutPoint-Barrier.md","hash":"2e5bef5adaceaed05e8340b26cd6d084c706e75b","modified":1569660660863},{"_id":"source/_posts/Flink-SourceCode-analysis.md","hash":"e72a4e42e6085d3c8dfd481bc960148c3836e1ab","modified":1569660660863},{"_id":"source/_posts/Github-Pull-Request.md","hash":"9be5bc3e41fe109287078db52f55916416ac017b","modified":1569660660863},{"_id":"source/_posts/Go-GC.md","hash":"391dc8e1f302d7ff4e53c04ac39295c019340922","modified":1569660660864},{"_id":"source/_posts/Go-Scheduler.md","hash":"fcbb6f06941304995375b114d864966e7a3ab738","modified":1569660660864},{"_id":"source/_posts/Go-Memory-Allocate-And-Collect.md","hash":"3c08056b9d2bdd1eb034728a91480757c1b9dac8","modified":1569660660864},{"_id":"source/_posts/Go-Tcp.md","hash":"ec408d7d602f4ec6900f6c339338854572957403","modified":1569660660864},{"_id":"source/_posts/IDEA-Keymap.md","hash":"da93f22f2f2c01dbdbb3f7200ef5d03c24b08fe3","modified":1569660660865},{"_id":"source/_posts/Interview-Questions.md","hash":"2e077eba1e313f347cefc258520c38caa350f870","modified":1569660660865},{"_id":"source/_posts/Guava-Black-techs.md","hash":"2e51a2c282b32bb6661c54007a76c4e09982ebc2","modified":1569660660864},{"_id":"source/_posts/Intellij-Useful-shortcuts.md","hash":"31f847d070b27dcb3932a5b94fa7c2c302f6c615","modified":1570797941037},{"_id":"source/_posts/JDK-AQS.md","hash":"7a4fff3d0e70b071c8fd1026ad7bb2b65227543a","modified":1574672747113},{"_id":"source/_posts/JDK-CLH-Lock.md","hash":"50ded946c3d6ae01d5cff4287ba3c0d20ff45664","modified":1569660660865},{"_id":"source/_posts/JDK-AbstractQueuedSynchronizer.md","hash":"e9ccaf6c183fec89867b231393d0c5972eb264a8","modified":1574929279381},{"_id":"source/_posts/JDK-Classloader.md","hash":"0341bfd96d33f4263ecf89232686dc7d53120dfb","modified":1569660660865},{"_id":"source/_posts/JDK-Condition.md","hash":"70db62ee380d5323b9b43c2f710f160e783812ab","modified":1574755587927},{"_id":"source/_posts/JDK-ConcurrentHashMap.md","hash":"0b52710d08326a3f9f186ccf2e08ea46d852122a","modified":1575257403906},{"_id":"source/_posts/JDK-CountDownLatch.md","hash":"265d4e04643da57638bf4cade78db1dff4fdb5a4","modified":1574672984001},{"_id":"source/_posts/JDK-CopyOnWriteArrayList.md","hash":"f6a88b9b012da8a089d431ddcf470a4d8f1de394","modified":1574673235912},{"_id":"source/_posts/JDK-ExecutorService.md","hash":"004221607554205529ea10e59fcb7f488bb7fd2b","modified":1569660660865},{"_id":"source/_posts/JDK-ReentrantLock.md","hash":"1aeb746c71c2bb53a6d21544a705f5a5b5d09500","modified":1574756554844},{"_id":"source/_posts/JDK-JUC.md","hash":"d83f39e902f3252f0ebc18c2e79bd240f60bd153","modified":1569660660865},{"_id":"source/_posts/JDK-Semaphore.md","hash":"7c1d516b48eca38ed2e6c7420b8c5af19663ba2a","modified":1574673036040},{"_id":"source/_posts/JDK-ReentrantReadWriteLock.md","hash":"5c03928fc9ec05723dc269af1ac9a009a539a767","modified":1574671455257},{"_id":"source/_posts/JDK-ThreadPoolExecutor.md","hash":"77772e62a4d4e66c99475e0da376b2984dd56661","modified":1574847772471},{"_id":"source/_posts/JMM-Double-Checked-Locking.md","hash":"fd6539267053879509d7575cc41aed6d0b2ec5b8","modified":1574925131828},{"_id":"source/_posts/JVM-Atomic-operation.md","hash":"0ccc0331a673e525e65bb3027b33a1fdbfb72d39","modified":1569660660866},{"_id":"source/_posts/JVM-CAS-Campare-and-swap.md","hash":"ba68978c50138649b6e89570bdc1e15600d8756f","modified":1569660660866},{"_id":"source/_posts/JMM-Volatile.md","hash":"afd66419375bcff365dba83c5062ceb3a260b731","modified":1574925514489},{"_id":"source/_posts/JVM-Card-table.md","hash":"6e916b7c1a91c1d561f83d84e459c2cd47622228","modified":1569660660866},{"_id":"source/_posts/JVM-Crash-Log-Analysis.md","hash":"d426d07b067b3210f59200cf1d903ea5d817fa57","modified":1569660660866},{"_id":"source/_posts/JVM-Escape-analysis.md","hash":"8afda38312ee87f654b9c20c94fbbe2e75c213c8","modified":1569660660866},{"_id":"source/_posts/JVM-Debug-Openjdk-On-Mac.md","hash":"4854f89d0b7df8089871b85ec4207ca03ae33997","modified":1570777095109},{"_id":"source/_posts/JVM-FreeList.md","hash":"3e614334860c392d8e99014e8d997fcbb61ff610","modified":1569660660867},{"_id":"source/_posts/JVM-GC-Allocation-failed.md","hash":"61291f9726970a5270b030611ffbb9c80282d81a","modified":1569660660867},{"_id":"source/_posts/JVM-GC-G1-FAQ.md","hash":"70d48a43065b7357f5dcbb5ba0cecf032518fae1","modified":1569660660867},{"_id":"source/_posts/JVM-GC-CMS-Concurrent-Mode-Failure.md","hash":"2741582bc58de7bce5aadec464a4162583d79277","modified":1569660660867},{"_id":"source/_posts/JVM-GC-CMS-Thread.md","hash":"aa9a7676d8abfe6f0658b1880568fd591ca8ff01","modified":1569660660867},{"_id":"source/_posts/JVM-GC-G1-FullGC.md","hash":"4273185b54235c6ed00d00ce31389b1ac2825dd8","modified":1569660660867},{"_id":"source/_posts/JVM-GC-CMS.md","hash":"a8e2f902d638fc3a4b7529b42a1c5e2709355aef","modified":1569660660867},{"_id":"source/_posts/JVM-GC-G1-Tuning.md","hash":"ba45d2088d486e2b252f5720b475d5a7df6e8da4","modified":1569660660868},{"_id":"source/_posts/JVM-GC-G1-SATB.md","hash":"9ee34dfc9968464cf0cfd729f19c34ba2acb8725","modified":1569660660867},{"_id":"source/_posts/JVM-GC-SystemGC.md","hash":"e754207aff637746b7743f04f7efd1b2840309f4","modified":1569660660868},{"_id":"source/_posts/JVM-GC-G1.md","hash":"4e2f83a92ebf44916f070cd48f6214c48d69d79d","modified":1569660660868},{"_id":"source/_posts/JVM-GC-ParNew.md","hash":"5a620c98466b19c73ce945d76f7c679f6fe70dc2","modified":1569660660868},{"_id":"source/_posts/JVM-GC-Write-barrier.md","hash":"b0dd590a6efa4514439d5f86e23e016d2a95f37e","modified":1569660660868},{"_id":"source/_posts/JVM-Greys.md","hash":"c860cd95713657b7ec5afb1b0a5ab2ed7d3bd1a8","modified":1569660660869},{"_id":"source/_posts/JVM-GC-log.md","hash":"2e93faae41f05323847094e55a1a8dec66f74fda","modified":1569660660869},{"_id":"source/_posts/JVM-GC.md","hash":"e2517ed292665ec404283519923862826ec612eb","modified":1569660660869},{"_id":"source/_posts/JVM-Interpreter.md","hash":"bc97c8e6919634ef102bab75a29ad428efe6f3f5","modified":1569660660869},{"_id":"source/_posts/JVM-JMH.md","hash":"0d2ec3eb1bd8a32c0c09c2c6700a1d2289aa8dc2","modified":1569660660869},{"_id":"source/_posts/JVM-Lock.md","hash":"5bd65a943e35574dfb364f825e73430b2a615623","modified":1569660660870},{"_id":"source/_posts/JVM-NIO-Epoll-and-Kqueue.md","hash":"7f6223c960e459b1d9e0351b23368a90610b812f","modified":1569660660870},{"_id":"source/_posts/JVM-Native-memory-tracking.md","hash":"35ae339a23b1dec3e106b29451b65eedb7504661","modified":1569660660870},{"_id":"source/_posts/JVM-Off-Heap-Memory.md","hash":"5738d639d6cd73850d57019070a9ec4a7e0dcc2c","modified":1569660660870},{"_id":"source/_posts/JVM-Oop-Klass.md","hash":"25c12da1ac40fa9247746ee27255b23f02735582","modified":1569660660870},{"_id":"source/_posts/JVM-ParNew-and-CMS.md","hash":"76701647ee9965afa3c5063990b99437096ffda8","modified":1569660660870},{"_id":"source/_posts/JVM-ParNewGC.md","hash":"d0efded64a9bcf4f156609eafa0fa5b83c4b28f1","modified":1569660660870},{"_id":"source/_posts/JVM-Park-Unpark.md","hash":"62f4860be5da413a3ec65d5956c606c20e0b96fc","modified":1569660660870},{"_id":"source/_posts/JVM-Polymorphism.md","hash":"28456994ae6df41cc78937b77d9c5bd1a789a7e7","modified":1569660660870},{"_id":"source/_posts/JVM-Profiling.md","hash":"8b9e1ce6f2d59c5cd527df9b1e7017ce5a64aa5e","modified":1569660660871},{"_id":"source/_posts/JVM-JIT.md","hash":"650a6d339368adc475a60a045b9723c56f874766","modified":1569660660869},{"_id":"source/_posts/JVM-Safepoint.md","hash":"85556679acae0ce12a79e53921037274f017fb52","modified":1569660660871},{"_id":"source/_posts/JVM-SoftReference.md","hash":"5561c1b55954cea6cefb0d69114e5453c15ee71e","modified":1569660660871},{"_id":"source/_posts/JVM-Heap.md","hash":"c4bbbbc9752dc138a58d0dafa623a1f2f2a8306d","modified":1571371126748},{"_id":"source/_posts/JVM-TLAB.md","hash":"8b00e99943b5977ab51246a61e854c5157732ef7","modified":1569660660878},{"_id":"source/_posts/JVM-Synchronized.md","hash":"29e1b46a4ec81e08114a900d4449d99f68ada787","modified":1569660660871},{"_id":"source/_posts/JVM-Valotile.md","hash":"7dc0bf17e7f2a5eb23bec3f635acb58b158ed53e","modified":1574944614160},{"_id":"source/_posts/Kafka-Blogs.md","hash":"8fcfe9331f7a78f5470f5c1493558ad2bcb5d406","modified":1569660660879},{"_id":"source/_posts/JVM-Thread-interupt.md","hash":"d6b0d69bceb8489d3995c2aed22181f87bdeb94c","modified":1569660660878},{"_id":"source/_posts/Kafka-Broker-Message-Producing.md","hash":"9ddba4c9a098143affaefdb7f09e9d79e650c6c3","modified":1569660660879},{"_id":"source/_posts/JVM-Volatile-impl.md","hash":"ae01c21ba822abc482e60e4bd45538be06dc8a9d","modified":1569660660879},{"_id":"source/_posts/Kafka-Streaming.md","hash":"495635c3373fc3c2f447f1e0f2c8e68d103fa280","modified":1569660660881},{"_id":"source/_posts/Kafka-Opertion-Tools.md","hash":"09eb5edcc10edd3ccbbd1a0c19fe5050a0aa6299","modified":1574154769818},{"_id":"source/_posts/Kafka-FAQ.md","hash":"1ce6dcfbf52a6854dff7a61515f6f6d98c4fefc7","modified":1575280994224},{"_id":"source/_posts/Kafka-High-performance-design-with-pagecache.md","hash":"9aea0b6ce9c1bb9ccbe51fbfcd227a349bb7a03b","modified":1569660660879},{"_id":"source/_posts/LevelDB-Code-Analysis-Bloom-Filter.md","hash":"bf050ee207407fcb450c71ae7fc2be091933ead3","modified":1569660660882},{"_id":"source/_posts/LevelDB.md","hash":"340e335618016e033cb83beddc2168870473bd94","modified":1570797401875},{"_id":"source/_posts/Kafka-Useful-Metrics.md","hash":"d09c499fbdb09ca5530609ce833098fcab803cba","modified":1569660660881},{"_id":"source/_posts/LevelDB-Options-Tuning.md","hash":"7a9815e29dbb795233470268c2ef9261c428120c","modified":1569660660882},{"_id":"source/_posts/Linux-Context-Switch.md","hash":"369e0e388606032706e3070e24e0e16138d593d3","modified":1569660660882},{"_id":"source/_posts/Linux-Ansible-Operation.md","hash":"3ca83fe8a2a731d2517b09571b4fda3ac6140758","modified":1569660660882},{"_id":"source/_posts/Linux-Core-dump.md","hash":"e5b18305b3d13c97d763c7d045de559b5be55432","modified":1569660660882},{"_id":"source/_posts/Linux-Cacheline.md","hash":"a5e564d2aa8bcf9b5895d6c977dbd807a18bb819","modified":1569660660882},{"_id":"source/_posts/Linux-DirectIO.md","hash":"a12ad8e5c5e9fce68a6d2b8215d807047a37f3ee","modified":1569660660882},{"_id":"source/_posts/Linux-Disk-io-scheduler.md","hash":"4efed3c104c68f9048e9ee0850fab4f179da0850","modified":1569660660883},{"_id":"source/_posts/Linux-Disk-io-test.md","hash":"955299a18a2e0c6ad6317c3a5890c77214949e3a","modified":1569660660883},{"_id":"source/_posts/Linux-Dmesg.md","hash":"6e3ef42155ff344865d7436f951f251c31d8bea5","modified":1569660660883},{"_id":"source/_posts/Linux-IO.md","hash":"dfcab19f32742f4d6a994f366a43fcf0226e33b8","modified":1569660660883},{"_id":"source/_posts/Linux-Kernel-space-and-User-space.md","hash":"34df2ae8c7353b5a219c3fd49b5b32637dfe3a3b","modified":1569660660883},{"_id":"source/_posts/Linux-Madvise.md","hash":"b0fddf59a7485cdaedc06401a852e93a4518086d","modified":1569660660883},{"_id":"source/_posts/Linux-Memory-allocation.md","hash":"81ebe871d67c23a12955f747945363ce0aa08ed7","modified":1569660660883},{"_id":"source/_posts/Linux-Memory-management.md","hash":"9c1c7fe95f70907535363efb19352a4678f580eb","modified":1569660660883},{"_id":"source/_posts/Linux-Mlock.md","hash":"9de01630442c320461e9a9cbf32c055b9341b271","modified":1569660660883},{"_id":"source/_posts/Linux-Memory-Alignment.md","hash":"8baa4950a28f824c15eea1992fa7c7ee7bed1ea5","modified":1569660660883},{"_id":"source/_posts/Linux-NUMA.md","hash":"04fd94306d806076a74d29b764bde82d16d6a898","modified":1569660660884},{"_id":"source/_posts/Linux-OOM-killer.md","hash":"e837ecb7c41ebdce66a1af980ad8f26faf5b012e","modified":1569660660884},{"_id":"source/_posts/Linux-Mmap.md","hash":"eafbb622972fa9292b2f765b810dd9a6d6dc68cb","modified":1569660660884},{"_id":"source/_posts/Linux-Pagecache.md","hash":"ab61a2229185fde977c7b3280ff4d3de96cbe2c5","modified":1569660660884},{"_id":"source/_posts/Linux-Pmap.md","hash":"89659f6c9d6fe948924ac728dd3298aed156b1e5","modified":1569660660884},{"_id":"source/_posts/Linux-Page-fault.md","hash":"fe7bb048407552e97b0fb6a1ae0e6d9ccde84736","modified":1569660660884},{"_id":"source/_posts/Linux-Swap.md","hash":"07ea73fcc5f2134371a6e3ff9874a4bc8168bb98","modified":1569660660885},{"_id":"source/_posts/Linux-SAR.md","hash":"1a031a22b80b5786041a4b417fcf84d22429afed","modified":1569660660884},{"_id":"source/_posts/Linux-TCP-dump.md","hash":"8408b39bfdf9c53e62d8aa1478597d7af7bfeca1","modified":1569660660885},{"_id":"source/_posts/Linux-TCP.md","hash":"5e3a7d81979b39c60cb222d03380585e8e0cf830","modified":1569660660906},{"_id":"source/_posts/Linux-Useful-command.md","hash":"2745e2b14701c196289387f05f3d5d847156b4dc","modified":1569660660907},{"_id":"source/_posts/Linux-Top.md","hash":"7e0fb9f6e983e571bc2f37fb375169e5bf3bea6b","modified":1569660660906},{"_id":"source/_posts/Linux-Virtual-memory.md","hash":"aa75efecda7598a36baee88fab16d8f0316e0dcb","modified":1569660660907},{"_id":"source/_posts/Linux-Zero-Copy.md","hash":"b2b5f51dc2095d9b4a8107ecfac7bb83a8fae352","modified":1569660660907},{"_id":"source/_posts/Mac-Multi-JDK.md","hash":"0c86ca47bf4a2e967e36353c9767f3cd3714527a","modified":1570518005140},{"_id":"source/_posts/Linux-dstat.md","hash":"931774dc04d4d70c4eeb9ec63e125db3d5919470","modified":1569660660907},{"_id":"source/_posts/Linux-sync-async-blocking-noblocking.md","hash":"8e301b3ccf3c6b75a9e46554a245a1b80b3625f3","modified":1569660660907},{"_id":"source/_posts/MySQL-Redo-Log-Flush.md","hash":"9f0e064bf8530e87d155dbdf09c5d0929eb73ed3","modified":1569660660908},{"_id":"source/_posts/Netty-AdaptiveRecvByteBufAllocator.md","hash":"012286067db1a9f2072344b4cd48eede6196d7dd","modified":1569660660908},{"_id":"source/_posts/MySQL-MVCC.md","hash":"204095f6127c34f9d2296c829b6064d85264044d","modified":1569660660907},{"_id":"source/_posts/MySQL-Transaction-isolation.md","hash":"72868cda3c91c290f1f8f70c0ca2f3de017827a7","modified":1569660660908},{"_id":"source/_posts/Netty-Bind-Port.md","hash":"dbbec87f86abc89fa82cb324c7ff4467dc3d2168","modified":1569660660908},{"_id":"source/_posts/Netty-Async-write.md","hash":"25735c396bca806ae145049f84d04f8718aa67c0","modified":1569660660908},{"_id":"source/_posts/Netty-Buffer-Allocator.md","hash":"62b359381afb64c0947490b22b19123c322bda58","modified":1569660660908},{"_id":"source/_posts/Netty-ChannelOption-Backlog.md","hash":"e66c4b7cb2d2a9ff28c73af255886779dd10c458","modified":1569660660908},{"_id":"source/_posts/Netty-ChannelOption.md","hash":"c80e51a1707cab52569842f09ffe3faa344b1df3","modified":1569660660909},{"_id":"source/_posts/Netty-DirectMemory-leak.md","hash":"25de0f1b2a53401ddbad3b27a120f6431e7d3c78","modified":1569660660909},{"_id":"source/_posts/Netty-ChannelPool.md","hash":"a6293ac1270f5a046c01388495d4ff4169061f4f","modified":1569660660909},{"_id":"source/_posts/Netty-FastThreadLocal.md","hash":"966bff295bc23a000943a41f592d25bd64fb3d3c","modified":1569660660910},{"_id":"source/_posts/Netty-FileRegion.md","hash":"3ebfbb8e65909fbee004ed5eaeedf72c5973b7ca","modified":1569660660910},{"_id":"source/_posts/Netty-Child-EventLoopGroup.md","hash":"23c01ab43156f4ebc4b87c6abf347f80fbd36625","modified":1569660660909},{"_id":"source/_posts/Netty-FAQ.md","hash":"b99cd6f6b9bec2d2919c955193ac1852b61474f6","modified":1569660660909},{"_id":"source/_posts/Netty-High-Performance.md","hash":"7e52cac4320a8bd759164da378e7c1c09ec6ee31","modified":1569660660910},{"_id":"source/_posts/Netty-Jemalloc-PoolArena.md","hash":"3f9189dc28f4752cee3b64cbabd9fef35c4cc118","modified":1569660660910},{"_id":"source/_posts/Netty-Jemalloc-PoolThreadLocalCache.md","hash":"37a2c92c9b52a7919bbcee019317712647af1ff1","modified":1569660660910},{"_id":"source/_posts/Netty-Jemalloc.md","hash":"77f7dc62d20ac578ee908bfe96b378816ac08634","modified":1569660660910},{"_id":"source/_posts/Netty-Performance-Test.md","hash":"9ad441f9fc5e1ec4859f2217811d989ebb98756a","modified":1569660660912},{"_id":"source/_posts/Netty-Mpsc-queue.md","hash":"5ad3239e1cb21ad8a4af5d165f73e30ee32e1c8f","modified":1569660660912},{"_id":"source/_posts/Netty-Source.md","hash":"e1434fbc872e9e1b075c4acb1798ea44737506cd","modified":1569660660912},{"_id":"source/_posts/Netty-TrafficShaping.md","hash":"af53ab7ad9a513cd9d11fa76774d7710784318c5","modified":1569660660912},{"_id":"source/_posts/Netty-NioEventLoop.md","hash":"51c3a5ade2c3e813b338c9c0f272193a6ba18bc8","modified":1569660660912},{"_id":"source/_posts/Netty-Transport-Native.md","hash":"8d90ec02c89e9aa43e3a28c9ec823f4cf42c4bc0","modified":1569660660913},{"_id":"source/_posts/Netty-Watermark.md","hash":"1056d4bffdc0aca88a2ed27b4c041147c687677f","modified":1569660660913},{"_id":"source/_posts/Netty-Pipeline.md","hash":"82219773e495ab66f15215d4e52fcd142bf706eb","modified":1569660660912},{"_id":"source/_posts/OSAHS.md","hash":"503951e42f3539955cd9edf3890546afe17fd998","modified":1569660660913},{"_id":"source/_posts/Personal-Marketing.md","hash":"683db7b222ce3f3d0683daa495b1d9fa5633d0aa","modified":1569660660913},{"_id":"source/_posts/Pulsar-Bookkeeper-LSM-Like-SingleDirectoryDbLedgerStorage.md","hash":"aedf1b6ac6fbb88a74fae50b4d038029b95ddcf0","modified":1569660660913},{"_id":"source/_posts/Pulsar-Bookkeeper-LSM-Like-SortedLedgerStorage.md","hash":"f04b9953a85ae2e422350e0583986a0d4dcacaa7","modified":1569660660913},{"_id":"source/_posts/Pulsar-BrokerCache.md","hash":"f841a78653e5ff79bab7fc3dce33c084176731a9","modified":1569660660913},{"_id":"source/_posts/Pulsar-FAQ.md","hash":"bf926cc67cbdb88eb27c3336462d89b653881552","modified":1569660660914},{"_id":"source/_posts/Pulsar-Produce-Msg.md","hash":"f2c6b3516e1f677b568f1367c0659f82febb0d76","modified":1569660660914},{"_id":"source/_posts/Pulsar-Consume-Msg.md","hash":"670341029993a71d864ec4ffe6e0555f6bde9b24","modified":1569660660914},{"_id":"source/_posts/RocketMQ-Consumer-rebalance.md","hash":"668c5b0786ff8ad76cb9fc26990ae2fcab69370a","modified":1569660660914},{"_id":"source/_posts/RocketMQ-Delay-message-delivery.md","hash":"90c1dc23d003496f2326db87233e413868b83f3a","modified":1569660660915},{"_id":"source/_posts/RocketMQ-FAQ.md","hash":"5c9421ac3097b7c85a9901cc8f073b6e3e7471bc","modified":1569660660915},{"_id":"source/_posts/RocketMQ-Debug-with-intellij.md","hash":"34fcba818644088edf18dbf5caf8cece177472ea","modified":1569660660914},{"_id":"source/_posts/RocketMQ-Index-service.md","hash":"8332e365e90a13cdde07178c95cee83fcb70a61b","modified":1569660660915},{"_id":"source/_posts/RocketMQ-Error-Code.md","hash":"783e56f1464576565d843361aae3c712ca5b5904","modified":1569660660915},{"_id":"source/_posts/RocketMQ-Master-slave-high-availability.md","hash":"a528a5a68efcf7aa26fa47f985ede482f54fa08f","modified":1569660660918},{"_id":"source/_posts/RocketMQ-Message-send-and-persistence.md","hash":"c04fc1cc76a6c54a9d8f5a85c0deba5ff7f0b64d","modified":1569660660919},{"_id":"source/_posts/RocketMQ-Netty-imp-sync-and-async-invoke.md","hash":"2c5fe3afb630894f98c782d82eebeb3ae1c89a37","modified":1569660660921},{"_id":"source/_posts/RocketMQ-Pagecache.md","hash":"1ff0085a53a545332edd9222eb0dd1b23f42b823","modified":1569660660934},{"_id":"source/_posts/RocketMQ-Persistence.md","hash":"2595a5b246945ffa1e4cd7b89567882d764c3515","modified":1569660660934},{"_id":"source/_posts/RocketMQ-Performance-tunning.md","hash":"24e11dc1a818a17469c21fa77b720f357c1a64ee","modified":1569660660934},{"_id":"source/_posts/RocketMQ-Remote-communication-protocol-and-serialization.md","hash":"6ad95fbfebf431b4006dcb3caea35a6f3bdac147","modified":1569660660934},{"_id":"source/_posts/RocketMQ-Pull-message-with-long-polling.md","hash":"705aef0084f5c53f3dda8e4ce52555d09fd728bf","modified":1569660660934},{"_id":"source/_posts/RocketMQ-Transactional-message.md","hash":"89ba7288ee5298e75d77dc14b9d0883bca48c709","modified":1569660660935},{"_id":"source/_posts/RocketMQ-TransientStorePool.md","hash":"8b3e0feab19bb5288d1bb75cc504eda83fa4110c","modified":1569660660935},{"_id":"source/_posts/RocksDB-Options-Tuning.md","hash":"20786a54fb48483abca8e57ab4c22a2e35959bc0","modified":1569660660935},{"_id":"source/_posts/RocksDB.md","hash":"aa0aa2d871b1b4c3ed08a6e34fc81673b1ea1b69","modified":1569660660936},{"_id":"source/_posts/Sofa-Jraft.md","hash":"3e6c2d35481b62988235a5ce15d08742c32ad11d","modified":1570706472213},{"_id":"source/_posts/Serialization-Hessian.md","hash":"47dcc1676849cb6520cfe359fe79e052130d002a","modified":1569660660936},{"_id":"source/_posts/SourceCode-AbstractQueuedSynchronizer.md","hash":"f7e7486fc66140a4d4c7fe1e10e14743c0bd65ef","modified":1569660660989},{"_id":"source/_posts/SourceCode-Map.md","hash":"2d9fba844d0ba482d408ae85c0bcca79a82936fb","modified":1569660660989},{"_id":"source/_posts/TCP-Protocol-Analyzer.md","hash":"e34305a86c4312309b1d8eafb31f0849bd91eb93","modified":1569660660989},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1569660660995},{"_id":"source/_posts/Thread-FAQ.md","hash":"e7f87e7a2b48cfcd4d02419ee530c43a49b0df5d","modified":1569660660994},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"b56c01cdfc6ee7ffea8a8a9fa149263f368caef6","modified":1569660660995},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"37bd0ec1d655c601946fc5f5ac2fe8ed1e529b77","modified":1569660660995},{"_id":"source/tags/index.md","hash":"5c890fd947e675abc3ce2371a6ff2ff409362311","modified":1569660660994},{"_id":"themes/next/languages/fr-FR.yml","hash":"24180322c83587a153cea110e74e96eacc3355ad","modified":1569660660997},{"_id":"themes/next/languages/en.yml","hash":"e7def07a709ef55684490b700a06998c67f35f39","modified":1569660660997},{"_id":"themes/next/languages/id.yml","hash":"2835ea80dadf093fcf47edd957680973f1fb6b85","modified":1569660660997},{"_id":"themes/next/languages/de.yml","hash":"306db8c865630f32c6b6260ade9d3209fbec8011","modified":1569660660997},{"_id":"themes/next/languages/ja.yml","hash":"1c3a05ab80a6f8be63268b66da6f19da7aa2c638","modified":1569660660997},{"_id":"themes/next/languages/pt.yml","hash":"36c8f60dacbe5d27d84d0e0d6974d7679f928da0","modified":1569660660998},{"_id":"themes/next/languages/pt-BR.yml","hash":"958e49571818a34fdf4af3232a07a024050f8f4e","modified":1569660660997},{"_id":"themes/next/languages/ko.yml","hash":"be150543379150f78329815af427bf152c0e9431","modified":1569660660997},{"_id":"themes/next/languages/zh-tw.yml","hash":"0b2c18aa76570364003c8d1cd429fa158ae89022","modified":1569660660998},{"_id":"themes/next/scripts/merge-configs.js","hash":"13c8b3a2d9fce06c2488820d9248d190c8100e0a","modified":1569660661011},{"_id":"themes/next/languages/zh-Hans.yml","hash":"3c0c7dfd0256457ee24df9e9879226c58cb084b5","modified":1569660660998},{"_id":"themes/next/languages/zh-hk.yml","hash":"1c917997413bf566cb79e0975789f3c9c9128ccd","modified":1569660660998},{"_id":"themes/next/languages/ru.yml","hash":"1549a7c2fe23caa7cbedcd0aa2b77c46e57caf27","modified":1569660660998},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1569660661011},{"_id":"themes/next/layout/_layout.swig","hash":"06b1eab2e00273e0b94bd32dc682bd92c1e0a747","modified":1569660660999},{"_id":"themes/next/layout/archive.swig","hash":"383f64deab105724fd5512371963bd9e9aafbffd","modified":1569660661010},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1569660661010},{"_id":"themes/next/layout/index.swig","hash":"03e8a2cda03bad42ac0cb827025eb81f95d496a2","modified":1569660661010},{"_id":"themes/next/layout/page.swig","hash":"37c874cd720acf0eda8d26e063278f2b6ae8d3a6","modified":1569660661010},{"_id":"themes/next/layout/post.swig","hash":"2d5f8d7f0a96b611e2d5a5e4d111fc17726a990f","modified":1569660661010},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1569660661011},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1569660661011},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1569660661075},{"_id":"themes/next/languages/default.yml","hash":"4cc6aeb1ac09a58330e494c8771773758ab354af","modified":1569660660997},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1569660661075},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1569660661075},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1569660661025},{"_id":"source/_posts/Cobar-Cluster-datasource-switch-design-with-distributed-lock/sign.gif","hash":"999dfe3ed086bd56471bddb697dd2dd70157cb31","modified":1569660660839},{"_id":"source/_posts/Cobar-Database-Scales/cobar-rule-reload.gif","hash":"f22fc213ac979074b93952f9f9371d79d5441b55","modified":1569660660844},{"_id":"source/_posts/Cobar-Reactor-design-pattern/NioSign.gif","hash":"6c1b820c2c71938b240d4bc5ac56691f2c538dca","modified":1569660660858},{"_id":"source/_posts/JVM-Synchronized/biased_lock_convert_flow.jpg","hash":"437ba37b1e9acdac50b4d813ddd6b44199cd035c","modified":1569660660872},{"_id":"source/_posts/Kafka-High-performance-design-with-pagecache/disk_read_write_speed.jpg","hash":"3a3bcb8193115780dd7568721270a217ba4499e9","modified":1569660660880},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1569660661012},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1569660661012},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1569660661012},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1569660661012},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1569660661012},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1569660661012},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1569660661012},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1569660661013},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1569660661013},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1569660660998},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1569660660998},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"53d4f83b2b7fb4387dfc9fe81519abd56fbce4ae","modified":1569660660999},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1569660660999},{"_id":"themes/next/layout/_macro/post.swig","hash":"911363776867d9523a3e322cdf591d49cd166403","modified":1569660660999},{"_id":"themes/next/layout/_macro/reward.swig","hash":"5d5f70deb6074cb4dd0438463e14ccf89213c282","modified":1569660660999},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"faa7886ccf986890cd776f4e9d70cb89fe9fda5f","modified":1569660660999},{"_id":"themes/next/layout/_partials/footer.swig","hash":"7172c6053118b7c291a56a7860128a652ae66b83","modified":1569660661000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1569660661000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"ce7094ee05878161e7568a6dfae5b56ff3fbd6e1","modified":1569660661000},{"_id":"themes/next/layout/_partials/header.swig","hash":"a1ffbb691dfad3eaf2832a11766e58a179003b8b","modified":1569660661001},{"_id":"themes/next/layout/_partials/head.swig","hash":"1f14d3f494b2dbbcee802fd6f6d1abd5b7e2304c","modified":1569660661000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1569660661001},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1569660661001},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1569660661001},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1569660661003},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1569660661003},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9baf90f7c40b3b10f288e9268c3191e895890cea","modified":1569660661005},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1569660661008},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1569660661009},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1569660661009},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1569660661009},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1569660661025},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1569660661025},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1569660661025},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1569660661026},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1569660661026},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1569660661026},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1569660661026},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1569660661026},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1569660661026},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1569660661026},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1569660661027},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1569660661027},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1569660661027},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1569660661009},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1569660661009},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1569660661026},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1569660661026},{"_id":"source/_posts/Cobar-Database-Scales/backup-and-replay.gif","hash":"0a0d6a449b889101bba7f512f8126b9b244f8a93","modified":1569660660842},{"_id":"source/_posts/Cobar-Database-Scales/binlog-sync.gif","hash":"ea89adb683aae42bcb5382e86b2cf79a6aabb609","modified":1569660660843},{"_id":"source/_posts/JVM-Synchronized/markword_state.jpg","hash":"59b1e2cd4dd8962ab1657d79ac8db8a8cd980d95","modified":1569660660878},{"_id":"source/_posts/Kafka-High-performance-design-with-pagecache/read_write.gif","hash":"d8b58d9570bbe1056bbbb54d8e1d1b54f1c4870e","modified":1569660660881},{"_id":"source/_posts/Netty-Jemalloc/jemalloc.jpg","hash":"350568c3a6c2abff13fb244a3e78e7f758fd99c2","modified":1569660660912},{"_id":"source/_posts/RocketMQ-Index-service/index-file.gif","hash":"4ccabf0aed972624fd7a8c4648430c975af70f3c","modified":1569660660918},{"_id":"source/_posts/Cobar-Reactor-design-pattern/CobarReactorSign.gif","hash":"17ac291d666654f13097a9ab729adf5d329bd37a","modified":1569660660856},{"_id":"source/_posts/TCP-Protocol-Analyzer/mySql-handshake.gif","hash":"9f1b58afc5332c49f53b88e2e3ec081d5dd886f9","modified":1569660660993},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1569660661004},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1569660661004},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1569660661022},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1569660661022},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1569660661022},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1569660661025},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1569660661025},{"_id":"source/_posts/Cobar-Cluster-datasource-switch-design-with-distributed-lock/normal.gif","hash":"65ce3f933e03889174067eba323f00a55b13129e","modified":1569660660838},{"_id":"source/_posts/Cobar-Enhance-cobar-driver-with-high-availability/after-cobar-driver.gif","hash":"76597fd5ef32d8ebdf1dee82ab29e1fe092c810a","modified":1569660660849},{"_id":"source/_posts/Cobar-Enhance-cobar-driver-with-high-availability/before-cobar-driver.gif","hash":"75a442326aecac7ad3d959ef816cddec8b32dca4","modified":1569660660851},{"_id":"source/_posts/Distributed-Transaction/transaction_rocketmq.gif","hash":"9a6c9cd908a78d62a435afdea7ac7bac702f4cd0","modified":1569660660862},{"_id":"source/_posts/RocketMQ-Transactional-message/transaction_rocketmq.gif","hash":"9a6c9cd908a78d62a435afdea7ac7bac702f4cd0","modified":1569660660935},{"_id":"source/_posts/Cobar-Reactor-design-pattern/NioRegister.gif","hash":"4aec07220806ec8f3168d58ef8ff62b885bba9c6","modified":1569660660858},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1569660661001},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1569660661002},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1569660661002},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1569660661002},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1569660661002},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1569660661002},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1569660661003},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1569660661004},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1569660661004},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1569660661005},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1569660661005},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1569660661005},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1569660661006},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1569660661006},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1569660661006},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"3358d11b9a26185a2d36c96049e4340e701646e4","modified":1569660661007},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1569660661007},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1569660661006},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1569660661007},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1569660661007},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1569660661007},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1569660661008},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1569660661007},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1569660661008},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1569660661008},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1569660661000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1569660661002},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1569660661009},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1569660661010},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1569660661010},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1569660661008},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1569660661010},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"ee63aa2e49507b884a2d56778479cf01c723d751","modified":1569660661008},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1569660661008},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1569660661021},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"eaedfaf06dae94ba77a8f4893e2e434bf8859bac","modified":1569660661022},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1569660661022},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1569660661022},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"cfee25d790e4f9b7d57f0dc7e2ea9c1649f08f11","modified":1569660661025},{"_id":"themes/next/source/css/_variables/base.styl","hash":"d477196c5699c8261b08e993a77ef67054d86166","modified":1569660661025},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"49b5210fa62d6cbc6a98f57d89d5067a06ab3561","modified":1569660661024},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1569660661025},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1569660661027},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"6117f97b4984b8e33f21c726132da64ba678e4ed","modified":1569660661027},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1569660661027},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1569660661027},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1569660661028},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1569660661028},{"_id":"themes/next/source/js/src/motion.js","hash":"dc0365b2fb315a8b43d3ef19b59d3a82a366fcc1","modified":1569660661028},{"_id":"themes/next/source/js/src/post-details.js","hash":"0693695a9512641daff63d99da772625a058ab18","modified":1569660661028},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1569660661034},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1569660661028},{"_id":"themes/next/source/js/src/utils.js","hash":"2917c39c75b14b6dab7e1c46ab4d87b4df9fcd5d","modified":1569660661028},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1569660661031},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"7fd2f3e2773555392ef40df40cae3bedb884f17a","modified":1569660661034},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1569660661038},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1569660661038},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1569660661039},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1569660661038},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1569660661038},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1569660661039},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1569660661039},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1569660661039},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1569660661039},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1569660661059},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1569660661060},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1569660661061},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1569660661061},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1569660661061},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1569660661061},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1569660661061},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1569660661072},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1569660661072},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1569660661074},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1569660661066},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1569660661066},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1569660661075},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1569660661074},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1569660661066},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1569660661062},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1569660661062},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1569660661062},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1569660661062},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1569660661062},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1569660661063},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1569660661063},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1569660661063},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1569660661065},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1569660661064},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1569660661064},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1569660661065},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1569660661065},{"_id":"source/_posts/Cobar-Cluster-datasource-switch-design-with-distributed-lock/abnormal.gif","hash":"c2da1c2fc71056fb224ef0c0a276805206c7cbc6","modified":1569660660835},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1569660661064},{"_id":"source/_posts/Cobar-Enhance-cobar-dataSource-with-dataHost/datasource-on-datahost.gif","hash":"60fea3fcc8b92bcac7b5e6449e8c3bdcf0a35104","modified":1569660660845},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1569660661027},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1569660661060},{"_id":"source/_posts/Cobar-Enhance-cobar-dataSource-with-dataHost/datasource-on-datanode.gif","hash":"8a219316b10fe6c514b0baa83585f23298404d8a","modified":1569660660847},{"_id":"source/_posts/Cobar-Cluster-datasource-switch-design-with-distributed-lock/datasource-swithch-with-zk-event-sender.gif","hash":"4a199f1a2930ed182c8eab7dabfdd489fe7f69df","modified":1569660660837},{"_id":"source/_posts/JVM-Synchronized/biased_lock_flow.jpg","hash":"79d27d2fbe382878f0af70a4694657573ad4cc47","modified":1569660660875},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1569660661013},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"d026c8489f66ab6c12ad04bd37f1d5b6f2f3f0d1","modified":1569660661013},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1569660661013},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1569660661013},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1569660661013},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1569660661015},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1569660661009},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1569660661009},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"2915df7152ea095a6290ef69157fd67669e0e793","modified":1569660661021},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1569660661021},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1569660661019},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1569660661021},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1569660661021},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1569660661021},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1569660661022},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1569660661023},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"86b6fd7f1b1be3ae98f8af6b23a6b1299c670ce9","modified":1569660661021},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1569660661021},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1569660661022},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1569660661023},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1569660661023},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1569660661023},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1569660661023},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"bc8c388553bbcf95897459a466ba35bffd5ec5f0","modified":1569660661022},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1569660661023},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1569660661023},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1569660661023},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1569660661023},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1569660661024},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1569660661024},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1569660661024},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1569660661024},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"e3e23751d4ad24e8714b425d768cf68e37de7ded","modified":1569660661024},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1569660661024},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1569660661024},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1569660661028},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1569660661031},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1569660661031},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1569660661034},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1569660661035},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1569660661035},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1569660661035},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1569660661035},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1569660661035},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1569660661036},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1569660661038},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1569660661038},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1569660661037},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1569660661037},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1569660661040},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1569660661040},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1569660661040},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1569660661071},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1569660661072},{"_id":"source/_posts/Cobar-Cluster-datasource-switch-design-with-distributed-lock/zk-distributed-lock.gif","hash":"f8f28db26e293ca5eb4c9f357707e5866cecea4b","modified":1569660660841},{"_id":"source/_posts/JVM-Synchronized/light_lock_flow.jpg","hash":"8e5801eb0ba5786d871c495188a81eb2f21508a0","modified":1569660660877},{"_id":"source/_posts/RocketMQ-Message-send-and-persistence/disc-fall.gif","hash":"c365fc98e4f8e66420abcaea0474846ae6978533","modified":1569660660921},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1569660661030},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1569660661030},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1569660661059},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1569660661014},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1569660661014},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1569660661014},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1569660661014},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1569660661014},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1569660661014},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1569660661014},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"740d37f428b8f4574a76fc95cc25e50e0565f45e","modified":1569660661014},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1569660661015},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1569660661015},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1569660661015},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1569660661015},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1569660661015},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1569660661016},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1569660661015},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"88c7d75646b66b168213190ee4cd874609afd5e3","modified":1569660661016},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1569660661016},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"beccb53dcd658136fb91a0c5678dea8f37d6e0b6","modified":1569660661015},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"ed88c8b51d0517759c777e71a6bfbe2907bcd994","modified":1569660661016},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1569660661016},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1569660661015},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"ee554b1031ef0070a5916477939021800e3c9d27","modified":1569660661016},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1569660661016},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1569660661017},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1569660661017},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1569660661017},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"51eca243220cf57133a4becae9b78514bcfdc723","modified":1569660661017},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"08a500b2984f109b751f3697ca33172d1340591a","modified":1569660661017},{"_id":"themes/next/source/css/_common/components/post/post-wordcount.styl","hash":"4fda5d38c6c8d910e3bf5c74a48a8d4a3f3dc73d","modified":1569660661017},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"65a64d5662637b66e2f039a5f58217afe7a6e800","modified":1569660661017},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1569660661018},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"5f6ea57aabfa30a437059bf8352f1ad829dbd4ff","modified":1569660661018},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1569660661018},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1569660661018},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1569660661018},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"77c92a449ce84d558d26d052681f2e0dd77c70c9","modified":1569660661018},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1569660661018},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"57d2c8a060f5e4e1a0aef9aae11a0016cf7ac5ba","modified":1569660661018},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1569660661018},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1569660661019},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1569660661019},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1569660661019},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1569660661019},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1569660661019},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1569660661019},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"45df0cf4c97b47e05573bcd41028ee50f3fdf432","modified":1569660661019},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1569660661020},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1569660661020},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1569660661020},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1569660661020},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1569660661020},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1569660661020},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1569660661020},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1569660661020},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1569660661020},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"aeff0e6e23725e8baea27c890ccbbf466024f767","modified":1569660661021},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1569660661016},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1569660661023},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1569660661023},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1569660661024},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1569660661029},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1569660661029},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1569660661029},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1569660661029},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1569660661035},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1569660661036},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1569660661036},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1569660661036},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1569660661036},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1569660661036},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1569660661043},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1569660661074},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1569660661057},{"_id":"source/_posts/Cobar-Reactor-design-pattern/CobarReactor.gif","hash":"7ab7adf110a40c2820cd40110d653d44a1e97c3d","modified":1569660660854},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1569660661054},{"_id":"source/_posts/RocketMQ-Netty-imp-sync-and-async-invoke/invokeSync.png","hash":"f5462e215665696a7867fc6d4ca8d0722c4fe72a","modified":1569660660933},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1569660661047},{"_id":"source/_posts/RocketMQ-Netty-imp-sync-and-async-invoke/invokeAsync.png","hash":"65984a036bbd1af9b8b862e80d2f765fc3e19a17","modified":1569660660929},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1569660661034},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1569660661071},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1569660661054},{"_id":"source/_posts/Linux-TCP-dump/find_packet.jpg","hash":"580ee299edac2f062ba8c56761941785f2868314","modified":1569660660889},{"_id":"source/_posts/Linux-TCP-dump/tcp_stream.jpg","hash":"a890703393e32e51d67fa7b4842d071c02a41886","modified":1569660660906},{"_id":"source/_posts/Linux-TCP-dump/search_tcp_stream.jpg","hash":"2012e9bb9bea3f996c1bce27d945303361945fbe","modified":1569660660894},{"_id":"source/_posts/Sharding-Scale-Without-Data-Migration/WechatIMG204.jpeg","hash":"5a0d9fad2a0521c6e31b6a1bf60fd47b8798e635","modified":1569660660989}],"Category":[],"Data":[],"Page":[{"title":"tags","date":"2017-10-12T11:33:19.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2017-10-12 19:33:19\ntype: \"tags\"\n---\n","updated":"2019-09-28T08:51:00.994Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ck3o9o8y5005gv1np7mig7ead","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Algorithm-Dynamic-programming","date":"2018-10-27T15:02:33.000Z","_content":"Algorithm","source":"_posts/Algorithm-Dynamic-programming.md","raw":"---\ntitle: Algorithm-Dynamic-programming\ndate: 2018-10-27 23:02:33\ntags:\n---\nAlgorithm","slug":"Algorithm-Dynamic-programming","published":1,"updated":"2019-09-28T08:51:00.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o81z0000v1np4uy3eqr2","content":"<p>Algorithm</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Algorithm</p>\n"},{"title":"Algorithm-Big-data-sort-with-BitSet","date":"2018-11-05T09:52:15.000Z","_content":"\n经常遇到一个面试题，给1000万个Int整数排序，整数的范围在0-1亿之间\n\n或者找出1000万个正整数（0-1亿）中，找出重复的。\n\n\n### Java BitSet实现原理\nhttp://processon.com/chart_image/5be01911e4b067b9db5642ce.png","source":"_posts/Algorithm-Big-data-sort-with-BitSet.md","raw":"---\ntitle: Algorithm-Big-data-sort-with-BitSet\ndate: 2018-11-05 17:52:15\ntags:\n---\n\n经常遇到一个面试题，给1000万个Int整数排序，整数的范围在0-1亿之间\n\n或者找出1000万个正整数（0-1亿）中，找出重复的。\n\n\n### Java BitSet实现原理\nhttp://processon.com/chart_image/5be01911e4b067b9db5642ce.png","slug":"Algorithm-Big-data-sort-with-BitSet","published":1,"updated":"2019-09-28T08:51:00.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8220001v1nptjtudoj2","content":"<p>经常遇到一个面试题，给1000万个Int整数排序，整数的范围在0-1亿之间</p>\n<p>或者找出1000万个正整数（0-1亿）中，找出重复的。</p>\n<h3 id=\"Java-BitSet实现原理\"><a href=\"#Java-BitSet实现原理\" class=\"headerlink\" title=\"Java BitSet实现原理\"></a>Java BitSet实现原理</h3><p><a href=\"http://processon.com/chart_image/5be01911e4b067b9db5642ce.png\" target=\"_blank\" rel=\"noopener\">http://processon.com/chart_image/5be01911e4b067b9db5642ce.png</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>经常遇到一个面试题，给1000万个Int整数排序，整数的范围在0-1亿之间</p>\n<p>或者找出1000万个正整数（0-1亿）中，找出重复的。</p>\n<h3 id=\"Java-BitSet实现原理\"><a href=\"#Java-BitSet实现原理\" class=\"headerlink\" title=\"Java BitSet实现原理\"></a>Java BitSet实现原理</h3><p><a href=\"http://processon.com/chart_image/5be01911e4b067b9db5642ce.png\" target=\"_blank\" rel=\"noopener\">http://processon.com/chart_image/5be01911e4b067b9db5642ce.png</a></p>\n"},{"title":"Algorithm-Divide-and-conquer","date":"2018-10-27T15:01:35.000Z","_content":"\n### 分治模式代码\n```\nresult divideConquer(problem, param...) {\n    \n    #recursion terminator\n    if problem is none {\n        return ;\n    }\n\n    subProblems[] = splitProblem(problem);\n    \n    subResult1 = divideConquer(subProblems[0], p1...);\n    subResult2 = divideConquer(subProblems[1], p2...);\n    subResult3 = divideConquer(subProblems[2], p3...);\n    \n    result = processResult(subResult1, subResult2, subResult3 ...);\n}\n```\n\n\n### 作者还是总结能力很强的\nhttps://blog.csdn.net/cyfcsd/article/details/49924291","source":"_posts/Algorithm-Divide-and-conquer.md","raw":"---\ntitle: Algorithm-Divide-and-conquer\ndate: 2018-10-27 23:01:35\ntags:\n---\n\n### 分治模式代码\n```\nresult divideConquer(problem, param...) {\n    \n    #recursion terminator\n    if problem is none {\n        return ;\n    }\n\n    subProblems[] = splitProblem(problem);\n    \n    subResult1 = divideConquer(subProblems[0], p1...);\n    subResult2 = divideConquer(subProblems[1], p2...);\n    subResult3 = divideConquer(subProblems[2], p3...);\n    \n    result = processResult(subResult1, subResult2, subResult3 ...);\n}\n```\n\n\n### 作者还是总结能力很强的\nhttps://blog.csdn.net/cyfcsd/article/details/49924291","slug":"Algorithm-Divide-and-conquer","published":1,"updated":"2019-09-28T08:51:00.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8230002v1np0l28kasf","content":"<h3 id=\"分治模式代码\"><a href=\"#分治模式代码\" class=\"headerlink\" title=\"分治模式代码\"></a>分治模式代码</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">result divideConquer(problem, param...) &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    #recursion terminator</span><br><span class=\"line\">    if problem is none &#123;</span><br><span class=\"line\">        return ;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    subProblems[] = splitProblem(problem);</span><br><span class=\"line\">    </span><br><span class=\"line\">    subResult1 = divideConquer(subProblems[0], p1...);</span><br><span class=\"line\">    subResult2 = divideConquer(subProblems[1], p2...);</span><br><span class=\"line\">    subResult3 = divideConquer(subProblems[2], p3...);</span><br><span class=\"line\">    </span><br><span class=\"line\">    result = processResult(subResult1, subResult2, subResult3 ...);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"作者还是总结能力很强的\"><a href=\"#作者还是总结能力很强的\" class=\"headerlink\" title=\"作者还是总结能力很强的\"></a>作者还是总结能力很强的</h3><p><a href=\"https://blog.csdn.net/cyfcsd/article/details/49924291\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/cyfcsd/article/details/49924291</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"分治模式代码\"><a href=\"#分治模式代码\" class=\"headerlink\" title=\"分治模式代码\"></a>分治模式代码</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">result divideConquer(problem, param...) &#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    #recursion terminator</span><br><span class=\"line\">    if problem is none &#123;</span><br><span class=\"line\">        return ;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    subProblems[] = splitProblem(problem);</span><br><span class=\"line\">    </span><br><span class=\"line\">    subResult1 = divideConquer(subProblems[0], p1...);</span><br><span class=\"line\">    subResult2 = divideConquer(subProblems[1], p2...);</span><br><span class=\"line\">    subResult3 = divideConquer(subProblems[2], p3...);</span><br><span class=\"line\">    </span><br><span class=\"line\">    result = processResult(subResult1, subResult2, subResult3 ...);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"作者还是总结能力很强的\"><a href=\"#作者还是总结能力很强的\" class=\"headerlink\" title=\"作者还是总结能力很强的\"></a>作者还是总结能力很强的</h3><p><a href=\"https://blog.csdn.net/cyfcsd/article/details/49924291\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/cyfcsd/article/details/49924291</a></p>\n"},{"title":"Algorithm-Kmp","date":"2018-10-24T12:09:48.000Z","_content":"\n\nhttp://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html\n\n1.当红色部分相同（即S[k]==S[q]）时，则当前 next 数组的值为上一次 next 的值加一（即next[q] = k++），如上图所示。\n\n2.当红色部分不等的时候，则需要对绿色部分递推求解 k’ = next[k-1]，然后再对新的 k’ 位置字符与 q 位置字符进行匹配，如果相等，则 next[q] = k’+1，否则，执行递推匹配，直到k’=0时递推结束。比如，模式串“ABCABXABCABC”，最后一个字符C的next数组值为3。（因为C之前的最长公共前后缀为“ABCAB”，而“ABCAB”的最长公共前后缀为“AB”，其长度为2，又源于第三个字符C与最后一个字符C匹配，所以最后一个字符C的next数组值为3）\n\n作者：knowalker\n链接：https://www.jianshu.com/p/53a0c6ffbf77\n來源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n\nString : S1 A S2 B S1 A S2 D\nPattern: S1 A S2 B S1 A S2 C\n这时发现D和C不一样，需要找到Pattern在最后的C位置的Next值。这里有一层递归的关系。\n","source":"_posts/Algorithm-Kmp.md","raw":"---\ntitle: Algorithm-Kmp\ndate: 2018-10-24 20:09:48\ntags:\n---\n\n\nhttp://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html\n\n1.当红色部分相同（即S[k]==S[q]）时，则当前 next 数组的值为上一次 next 的值加一（即next[q] = k++），如上图所示。\n\n2.当红色部分不等的时候，则需要对绿色部分递推求解 k’ = next[k-1]，然后再对新的 k’ 位置字符与 q 位置字符进行匹配，如果相等，则 next[q] = k’+1，否则，执行递推匹配，直到k’=0时递推结束。比如，模式串“ABCABXABCABC”，最后一个字符C的next数组值为3。（因为C之前的最长公共前后缀为“ABCAB”，而“ABCAB”的最长公共前后缀为“AB”，其长度为2，又源于第三个字符C与最后一个字符C匹配，所以最后一个字符C的next数组值为3）\n\n作者：knowalker\n链接：https://www.jianshu.com/p/53a0c6ffbf77\n來源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n\nString : S1 A S2 B S1 A S2 D\nPattern: S1 A S2 B S1 A S2 C\n这时发现D和C不一样，需要找到Pattern在最后的C位置的Next值。这里有一层递归的关系。\n","slug":"Algorithm-Kmp","published":1,"updated":"2019-09-28T08:51:00.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8240003v1npwxa2frit","content":"<p><a href=\"http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html\" target=\"_blank\" rel=\"noopener\">http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html</a></p>\n<p>1.当红色部分相同（即S[k]==S[q]）时，则当前 next 数组的值为上一次 next 的值加一（即next[q] = k++），如上图所示。</p>\n<p>2.当红色部分不等的时候，则需要对绿色部分递推求解 k’ = next[k-1]，然后再对新的 k’ 位置字符与 q 位置字符进行匹配，如果相等，则 next[q] = k’+1，否则，执行递推匹配，直到k’=0时递推结束。比如，模式串“ABCABXABCABC”，最后一个字符C的next数组值为3。（因为C之前的最长公共前后缀为“ABCAB”，而“ABCAB”的最长公共前后缀为“AB”，其长度为2，又源于第三个字符C与最后一个字符C匹配，所以最后一个字符C的next数组值为3）</p>\n<p>作者：knowalker<br>链接：<a href=\"https://www.jianshu.com/p/53a0c6ffbf77\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/53a0c6ffbf77</a><br>來源：简书<br>简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p>\n<p>String : S1 A S2 B S1 A S2 D<br>Pattern: S1 A S2 B S1 A S2 C<br>这时发现D和C不一样，需要找到Pattern在最后的C位置的Next值。这里有一层递归的关系。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html\" target=\"_blank\" rel=\"noopener\">http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html</a></p>\n<p>1.当红色部分相同（即S[k]==S[q]）时，则当前 next 数组的值为上一次 next 的值加一（即next[q] = k++），如上图所示。</p>\n<p>2.当红色部分不等的时候，则需要对绿色部分递推求解 k’ = next[k-1]，然后再对新的 k’ 位置字符与 q 位置字符进行匹配，如果相等，则 next[q] = k’+1，否则，执行递推匹配，直到k’=0时递推结束。比如，模式串“ABCABXABCABC”，最后一个字符C的next数组值为3。（因为C之前的最长公共前后缀为“ABCAB”，而“ABCAB”的最长公共前后缀为“AB”，其长度为2，又源于第三个字符C与最后一个字符C匹配，所以最后一个字符C的next数组值为3）</p>\n<p>作者：knowalker<br>链接：<a href=\"https://www.jianshu.com/p/53a0c6ffbf77\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/53a0c6ffbf77</a><br>來源：简书<br>简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p>\n<p>String : S1 A S2 B S1 A S2 D<br>Pattern: S1 A S2 B S1 A S2 C<br>这时发现D和C不一样，需要找到Pattern在最后的C位置的Next值。这里有一层递归的关系。</p>\n"},{"title":"CPP-C-Posix-Library","date":"2019-04-01T11:49:53.000Z","_content":"\n\n\n\n\n\nhttps://en.wikipedia.org/wiki/C_POSIX_library\n\n\n\nHeader file\tDescription\tFirst released\n<netinet/tcp.h>\tAdditional TCP control options (part of Berkeley sockets)\tIssue 6\n<termios.h>\tAllows terminal I/O interfaces\tIssue 3\n<dirent.h>\tAllows the opening and listing of directories\tIssue 2\n<iso646.h>\tAlternative spellings, see C alternative tokens\tIssue 5\n<poll.h>\tAsynchronous file descriptor multiplexing\tIssue 4\n<aio.h>\tAsynchronous input and output\tIssue 5\n<stdbool.h>\tBoolean type and values, see C data types\tIssue 6\n<strings.h>\tCase-insensitive string comparisons\tIssue 4\n<locale.h>\tCategory macros, see C localization functions\tIssue 3\n<ctype.h>\tCharacter types\tIssue 1\n<iconv.h>\tCodeset conversion facility\tIssue 4\n<complex.h>\tComplex Arithmetic, see C mathematical functions\tIssue 6\n<pthread.h>\tDefines an API for creating and manipulating POSIX threads\tIssue 5\n<netinet/in.h>\tDefines Internet protocol and address family (part of Berkeley sockets)\tIssue 6\n<dlfcn.h>\tDynamic linking\tIssue 5\n<sched.h>\tExecution scheduling\tIssue 5\n<sys/times.h>\tFile access and modification times\tIssue 1\n<sys/stat.h>\tFile information (stat et al.)\tIssue 1\n<fcntl.h>\tFile opening, locking and other operations\tIssue 1\n<sys/statvfs.h>\tFile System information\tIssue 4\n<ftw.h>\tFile tree traversal\tIssue 1\n<fnmatch.h>\tFilename matching\tIssue 4\n<inttypes.h>\tFixed sized integer types, see C data types\tIssue 5\n<fenv.h>\tFloating-Point Environment (FPE), see C mathematical functions\tIssue 6\n<float.h>\tFloating-point types, see C data types\tIssue 4\n<arpa/inet.h>\tFunctions for manipulating numeric IP addresses (part of Berkeley sockets)\tIssue 6\n<stdarg.h>\tHandle Variable Argument List\tIssue 4\n<limits.h>\tImplementation-defined constants, see C data types\tIssue 1\n<utime.h>\tinode access and modification times\tIssue 3\n<stdint.h>\tInteger types, see C data types\tIssue 6\n<sys/ipc.h>\tInter-process communication (IPC)\tIssue 2\n<langinfo.h>\tLanguage information constants – builds on C localization functions\tIssue 2\n<net/if.h>\tListing of local network interfaces\tIssue 6\n<nl_types.h>\tLocalization message catalog functions\tIssue 2\n<cpio.h>\tMagic numbers for the cpio archive format\tIssue 3\n<tar.h>\tMagic numbers for the tar archive format\tIssue 3\n<sys/socket.h>\tMain Berkeley sockets header\tIssue 6\n<math.h>\tMathematical declarations, see C mathematical functions\tIssue 1\n<sys/mman.h>\tMemory management, including POSIX shared memory and memory mapped files\tIssue 4\n<fmtmsg.h>\tMessage display structures\tIssue 4\n<mqueue.h>\tMessage queue\tIssue 5\n<ndbm.h>\tNDBM database operations\tIssue 4\n<sys/utsname.h>\tOperating system information, including uname\tIssue 1\n<pwd.h>\tpasswd (user information) access and control\tIssue 1\n<glob.h>\tPathname \"globbing\" (pattern-matching)\tIssue 4\n<libgen.h>\tPathname manipulation\tIssue 4\n<sys/msg.h>\tPOSIX message queues\tIssue 2\n<semaphore.h>\tPOSIX semaphores\tIssue 5\n<spawn.h>\tProcess spawning\tIssue 6\n<regex.h>\tRegular expression matching\tIssue 4\n<ulimit.h>\tResource limiting (DEPRECATED in favor of <sys/resource.h>)\tIssue 1\n<sys/resource.h>\tResource usage, priorities, and limiting\tIssue 4\n<errno.h>\tRetrieving Error Number\tIssue 1\n<search.h>\tSearch tables\tIssue 1\n<string.h>\tSeveral String Operations, see C string handling\tIssue 1\n<signal.h>\tSignals, see C signal handling\tIssue 1\n<setjmp.h>\tStack environment declarations\tIssue 1\n<stdio.h>\tStandard buffered input/output, see C file input/output\tIssue 1\n<stdlib.h>\tStandard library definitions, see C standard library\tIssue 3\n<stddef.h>\tStandard type definitions, see C data types\tIssue 4\n<sys/wait.h>\tStatus of terminated child processes (see wait)\tIssue 3\n<stropts.h>\tStream manipulation, including ioctl\tIssue 4\n<monetary.h>\tString formatting of monetary units\tIssue 4\n<sys/select.h>\tSynchronous I/O multiplexing\tIssue 6\n<syslog.h>\tSystem error logging\tIssue 4\n<sys/time.h>\tTime and date functions and structures\tIssue 4\n<trace.h>\tTracing of runtime behavior (DEPRECATED)\tIssue 6\n<netdb.h>\tTranslating protocol and host names into numeric addresses (part of Berkeley sockets)\tIssue 6\n<time.h>\tType-Generic Macros, see C date and time functions\tIssue 1\n<tgmath.h>\tType-Generic Macros, see C mathematical functions\tIssue 1\n<sys/un.h>\tUnix domain sockets\tIssue 6\n<utmpx.h>\tUser accounting database functions\tIssue 4\n<grp.h>\tUser group information and control\tIssue 1\n<sys/types.h>\tVarious data types used elsewhere\tIssue 1\n<unistd.h>\tVarious essential POSIX functions and constants\tIssue 1\n<sys/uio.h>\tVectored I/O operations\tIssue 4\n<assert.h>\tVerify assumptions\tIssue 1\n<wctype.h>\tWide-Character Classification and Mapping Utilities, see C character classification\tIssue 5\n<wchar.h>\tWide-Character Handling, see C string handling\tIssue 4\n<wordexp.h>\tWord-expansion like the shell would perform\tIssue 4\n<sys/sem.h>\tXSI (SysV style) semaphores\tIssue 2\n<sys/shm.h>\tXSI (SysV style) shared memory\tIssue 2","source":"_posts/CPP-C-Posix-Library.md","raw":"---\ntitle: CPP-C-Posix-Library\ndate: 2019-04-01 19:49:53\ntags:\n---\n\n\n\n\n\n\nhttps://en.wikipedia.org/wiki/C_POSIX_library\n\n\n\nHeader file\tDescription\tFirst released\n<netinet/tcp.h>\tAdditional TCP control options (part of Berkeley sockets)\tIssue 6\n<termios.h>\tAllows terminal I/O interfaces\tIssue 3\n<dirent.h>\tAllows the opening and listing of directories\tIssue 2\n<iso646.h>\tAlternative spellings, see C alternative tokens\tIssue 5\n<poll.h>\tAsynchronous file descriptor multiplexing\tIssue 4\n<aio.h>\tAsynchronous input and output\tIssue 5\n<stdbool.h>\tBoolean type and values, see C data types\tIssue 6\n<strings.h>\tCase-insensitive string comparisons\tIssue 4\n<locale.h>\tCategory macros, see C localization functions\tIssue 3\n<ctype.h>\tCharacter types\tIssue 1\n<iconv.h>\tCodeset conversion facility\tIssue 4\n<complex.h>\tComplex Arithmetic, see C mathematical functions\tIssue 6\n<pthread.h>\tDefines an API for creating and manipulating POSIX threads\tIssue 5\n<netinet/in.h>\tDefines Internet protocol and address family (part of Berkeley sockets)\tIssue 6\n<dlfcn.h>\tDynamic linking\tIssue 5\n<sched.h>\tExecution scheduling\tIssue 5\n<sys/times.h>\tFile access and modification times\tIssue 1\n<sys/stat.h>\tFile information (stat et al.)\tIssue 1\n<fcntl.h>\tFile opening, locking and other operations\tIssue 1\n<sys/statvfs.h>\tFile System information\tIssue 4\n<ftw.h>\tFile tree traversal\tIssue 1\n<fnmatch.h>\tFilename matching\tIssue 4\n<inttypes.h>\tFixed sized integer types, see C data types\tIssue 5\n<fenv.h>\tFloating-Point Environment (FPE), see C mathematical functions\tIssue 6\n<float.h>\tFloating-point types, see C data types\tIssue 4\n<arpa/inet.h>\tFunctions for manipulating numeric IP addresses (part of Berkeley sockets)\tIssue 6\n<stdarg.h>\tHandle Variable Argument List\tIssue 4\n<limits.h>\tImplementation-defined constants, see C data types\tIssue 1\n<utime.h>\tinode access and modification times\tIssue 3\n<stdint.h>\tInteger types, see C data types\tIssue 6\n<sys/ipc.h>\tInter-process communication (IPC)\tIssue 2\n<langinfo.h>\tLanguage information constants – builds on C localization functions\tIssue 2\n<net/if.h>\tListing of local network interfaces\tIssue 6\n<nl_types.h>\tLocalization message catalog functions\tIssue 2\n<cpio.h>\tMagic numbers for the cpio archive format\tIssue 3\n<tar.h>\tMagic numbers for the tar archive format\tIssue 3\n<sys/socket.h>\tMain Berkeley sockets header\tIssue 6\n<math.h>\tMathematical declarations, see C mathematical functions\tIssue 1\n<sys/mman.h>\tMemory management, including POSIX shared memory and memory mapped files\tIssue 4\n<fmtmsg.h>\tMessage display structures\tIssue 4\n<mqueue.h>\tMessage queue\tIssue 5\n<ndbm.h>\tNDBM database operations\tIssue 4\n<sys/utsname.h>\tOperating system information, including uname\tIssue 1\n<pwd.h>\tpasswd (user information) access and control\tIssue 1\n<glob.h>\tPathname \"globbing\" (pattern-matching)\tIssue 4\n<libgen.h>\tPathname manipulation\tIssue 4\n<sys/msg.h>\tPOSIX message queues\tIssue 2\n<semaphore.h>\tPOSIX semaphores\tIssue 5\n<spawn.h>\tProcess spawning\tIssue 6\n<regex.h>\tRegular expression matching\tIssue 4\n<ulimit.h>\tResource limiting (DEPRECATED in favor of <sys/resource.h>)\tIssue 1\n<sys/resource.h>\tResource usage, priorities, and limiting\tIssue 4\n<errno.h>\tRetrieving Error Number\tIssue 1\n<search.h>\tSearch tables\tIssue 1\n<string.h>\tSeveral String Operations, see C string handling\tIssue 1\n<signal.h>\tSignals, see C signal handling\tIssue 1\n<setjmp.h>\tStack environment declarations\tIssue 1\n<stdio.h>\tStandard buffered input/output, see C file input/output\tIssue 1\n<stdlib.h>\tStandard library definitions, see C standard library\tIssue 3\n<stddef.h>\tStandard type definitions, see C data types\tIssue 4\n<sys/wait.h>\tStatus of terminated child processes (see wait)\tIssue 3\n<stropts.h>\tStream manipulation, including ioctl\tIssue 4\n<monetary.h>\tString formatting of monetary units\tIssue 4\n<sys/select.h>\tSynchronous I/O multiplexing\tIssue 6\n<syslog.h>\tSystem error logging\tIssue 4\n<sys/time.h>\tTime and date functions and structures\tIssue 4\n<trace.h>\tTracing of runtime behavior (DEPRECATED)\tIssue 6\n<netdb.h>\tTranslating protocol and host names into numeric addresses (part of Berkeley sockets)\tIssue 6\n<time.h>\tType-Generic Macros, see C date and time functions\tIssue 1\n<tgmath.h>\tType-Generic Macros, see C mathematical functions\tIssue 1\n<sys/un.h>\tUnix domain sockets\tIssue 6\n<utmpx.h>\tUser accounting database functions\tIssue 4\n<grp.h>\tUser group information and control\tIssue 1\n<sys/types.h>\tVarious data types used elsewhere\tIssue 1\n<unistd.h>\tVarious essential POSIX functions and constants\tIssue 1\n<sys/uio.h>\tVectored I/O operations\tIssue 4\n<assert.h>\tVerify assumptions\tIssue 1\n<wctype.h>\tWide-Character Classification and Mapping Utilities, see C character classification\tIssue 5\n<wchar.h>\tWide-Character Handling, see C string handling\tIssue 4\n<wordexp.h>\tWord-expansion like the shell would perform\tIssue 4\n<sys/sem.h>\tXSI (SysV style) semaphores\tIssue 2\n<sys/shm.h>\tXSI (SysV style) shared memory\tIssue 2","slug":"CPP-C-Posix-Library","published":1,"updated":"2019-09-28T08:51:00.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8250004v1npi0gm8cxp","content":"<p><a href=\"https://en.wikipedia.org/wiki/C_POSIX_library\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/C_POSIX_library</a></p>\n<p>Header file    Description    First released<br>&lt;netinet/tcp.h&gt;    Additional TCP control options (part of Berkeley sockets)    Issue 6<br>&lt;termios.h&gt;    Allows terminal I/O interfaces    Issue 3<br>&lt;dirent.h&gt;    Allows the opening and listing of directories    Issue 2<br>&lt;iso646.h&gt;    Alternative spellings, see C alternative tokens    Issue 5<br>&lt;poll.h&gt;    Asynchronous file descriptor multiplexing    Issue 4<br>&lt;aio.h&gt;    Asynchronous input and output    Issue 5<br>&lt;stdbool.h&gt;    Boolean type and values, see C data types    Issue 6<br>&lt;strings.h&gt;    Case-insensitive string comparisons    Issue 4<br>&lt;locale.h&gt;    Category macros, see C localization functions    Issue 3<br>&lt;ctype.h&gt;    Character types    Issue 1<br>&lt;iconv.h&gt;    Codeset conversion facility    Issue 4<br>&lt;complex.h&gt;    Complex Arithmetic, see C mathematical functions    Issue 6<br>&lt;pthread.h&gt;    Defines an API for creating and manipulating POSIX threads    Issue 5<br>&lt;netinet/in.h&gt;    Defines Internet protocol and address family (part of Berkeley sockets)    Issue 6<br>&lt;dlfcn.h&gt;    Dynamic linking    Issue 5<br>&lt;sched.h&gt;    Execution scheduling    Issue 5<br>&lt;sys/times.h&gt;    File access and modification times    Issue 1<br>&lt;sys/stat.h&gt;    File information (stat et al.)    Issue 1<br>&lt;fcntl.h&gt;    File opening, locking and other operations    Issue 1<br>&lt;sys/statvfs.h&gt;    File System information    Issue 4<br>&lt;ftw.h&gt;    File tree traversal    Issue 1<br>&lt;fnmatch.h&gt;    Filename matching    Issue 4<br>&lt;inttypes.h&gt;    Fixed sized integer types, see C data types    Issue 5<br>&lt;fenv.h&gt;    Floating-Point Environment (FPE), see C mathematical functions    Issue 6<br>&lt;float.h&gt;    Floating-point types, see C data types    Issue 4<br>&lt;arpa/inet.h&gt;    Functions for manipulating numeric IP addresses (part of Berkeley sockets)    Issue 6<br>&lt;stdarg.h&gt;    Handle Variable Argument List    Issue 4<br>&lt;limits.h&gt;    Implementation-defined constants, see C data types    Issue 1<br>&lt;utime.h&gt;    inode access and modification times    Issue 3<br>&lt;stdint.h&gt;    Integer types, see C data types    Issue 6<br>&lt;sys/ipc.h&gt;    Inter-process communication (IPC)    Issue 2<br>&lt;langinfo.h&gt;    Language information constants – builds on C localization functions    Issue 2<br>&lt;net/if.h&gt;    Listing of local network interfaces    Issue 6<br>&lt;nl_types.h&gt;    Localization message catalog functions    Issue 2<br>&lt;cpio.h&gt;    Magic numbers for the cpio archive format    Issue 3<br>&lt;tar.h&gt;    Magic numbers for the tar archive format    Issue 3<br>&lt;sys/socket.h&gt;    Main Berkeley sockets header    Issue 6<br>&lt;math.h&gt;    Mathematical declarations, see C mathematical functions    Issue 1<br>&lt;sys/mman.h&gt;    Memory management, including POSIX shared memory and memory mapped files    Issue 4<br>&lt;fmtmsg.h&gt;    Message display structures    Issue 4<br>&lt;mqueue.h&gt;    Message queue    Issue 5<br>&lt;ndbm.h&gt;    NDBM database operations    Issue 4<br>&lt;sys/utsname.h&gt;    Operating system information, including uname    Issue 1<br>&lt;pwd.h&gt;    passwd (user information) access and control    Issue 1<br>&lt;glob.h&gt;    Pathname “globbing” (pattern-matching)    Issue 4<br>&lt;libgen.h&gt;    Pathname manipulation    Issue 4<br>&lt;sys/msg.h&gt;    POSIX message queues    Issue 2<br>&lt;semaphore.h&gt;    POSIX semaphores    Issue 5<br>&lt;spawn.h&gt;    Process spawning    Issue 6<br>&lt;regex.h&gt;    Regular expression matching    Issue 4<br>&lt;ulimit.h&gt;    Resource limiting (DEPRECATED in favor of &lt;sys/resource.h&gt;)    Issue 1<br>&lt;sys/resource.h&gt;    Resource usage, priorities, and limiting    Issue 4<br>&lt;errno.h&gt;    Retrieving Error Number    Issue 1<br>&lt;search.h&gt;    Search tables    Issue 1<br>&lt;string.h&gt;    Several String Operations, see C string handling    Issue 1<br>&lt;signal.h&gt;    Signals, see C signal handling    Issue 1<br>&lt;setjmp.h&gt;    Stack environment declarations    Issue 1<br>&lt;stdio.h&gt;    Standard buffered input/output, see C file input/output    Issue 1<br>&lt;stdlib.h&gt;    Standard library definitions, see C standard library    Issue 3<br>&lt;stddef.h&gt;    Standard type definitions, see C data types    Issue 4<br>&lt;sys/wait.h&gt;    Status of terminated child processes (see wait)    Issue 3<br>&lt;stropts.h&gt;    Stream manipulation, including ioctl    Issue 4<br>&lt;monetary.h&gt;    String formatting of monetary units    Issue 4<br>&lt;sys/select.h&gt;    Synchronous I/O multiplexing    Issue 6<br>&lt;syslog.h&gt;    System error logging    Issue 4<br>&lt;sys/time.h&gt;    Time and date functions and structures    Issue 4<br>&lt;trace.h&gt;    Tracing of runtime behavior (DEPRECATED)    Issue 6<br>&lt;netdb.h&gt;    Translating protocol and host names into numeric addresses (part of Berkeley sockets)    Issue 6<br>&lt;time.h&gt;    Type-Generic Macros, see C date and time functions    Issue 1<br>&lt;tgmath.h&gt;    Type-Generic Macros, see C mathematical functions    Issue 1<br>&lt;sys/un.h&gt;    Unix domain sockets    Issue 6<br>&lt;utmpx.h&gt;    User accounting database functions    Issue 4<br>&lt;grp.h&gt;    User group information and control    Issue 1<br>&lt;sys/types.h&gt;    Various data types used elsewhere    Issue 1<br>&lt;unistd.h&gt;    Various essential POSIX functions and constants    Issue 1<br>&lt;sys/uio.h&gt;    Vectored I/O operations    Issue 4<br>&lt;assert.h&gt;    Verify assumptions    Issue 1<br>&lt;wctype.h&gt;    Wide-Character Classification and Mapping Utilities, see C character classification    Issue 5<br>&lt;wchar.h&gt;    Wide-Character Handling, see C string handling    Issue 4<br>&lt;wordexp.h&gt;    Word-expansion like the shell would perform    Issue 4<br>&lt;sys/sem.h&gt;    XSI (SysV style) semaphores    Issue 2<br>&lt;sys/shm.h&gt;    XSI (SysV style) shared memory    Issue 2</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://en.wikipedia.org/wiki/C_POSIX_library\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/C_POSIX_library</a></p>\n<p>Header file    Description    First released<br>&lt;netinet/tcp.h&gt;    Additional TCP control options (part of Berkeley sockets)    Issue 6<br>&lt;termios.h&gt;    Allows terminal I/O interfaces    Issue 3<br>&lt;dirent.h&gt;    Allows the opening and listing of directories    Issue 2<br>&lt;iso646.h&gt;    Alternative spellings, see C alternative tokens    Issue 5<br>&lt;poll.h&gt;    Asynchronous file descriptor multiplexing    Issue 4<br>&lt;aio.h&gt;    Asynchronous input and output    Issue 5<br>&lt;stdbool.h&gt;    Boolean type and values, see C data types    Issue 6<br>&lt;strings.h&gt;    Case-insensitive string comparisons    Issue 4<br>&lt;locale.h&gt;    Category macros, see C localization functions    Issue 3<br>&lt;ctype.h&gt;    Character types    Issue 1<br>&lt;iconv.h&gt;    Codeset conversion facility    Issue 4<br>&lt;complex.h&gt;    Complex Arithmetic, see C mathematical functions    Issue 6<br>&lt;pthread.h&gt;    Defines an API for creating and manipulating POSIX threads    Issue 5<br>&lt;netinet/in.h&gt;    Defines Internet protocol and address family (part of Berkeley sockets)    Issue 6<br>&lt;dlfcn.h&gt;    Dynamic linking    Issue 5<br>&lt;sched.h&gt;    Execution scheduling    Issue 5<br>&lt;sys/times.h&gt;    File access and modification times    Issue 1<br>&lt;sys/stat.h&gt;    File information (stat et al.)    Issue 1<br>&lt;fcntl.h&gt;    File opening, locking and other operations    Issue 1<br>&lt;sys/statvfs.h&gt;    File System information    Issue 4<br>&lt;ftw.h&gt;    File tree traversal    Issue 1<br>&lt;fnmatch.h&gt;    Filename matching    Issue 4<br>&lt;inttypes.h&gt;    Fixed sized integer types, see C data types    Issue 5<br>&lt;fenv.h&gt;    Floating-Point Environment (FPE), see C mathematical functions    Issue 6<br>&lt;float.h&gt;    Floating-point types, see C data types    Issue 4<br>&lt;arpa/inet.h&gt;    Functions for manipulating numeric IP addresses (part of Berkeley sockets)    Issue 6<br>&lt;stdarg.h&gt;    Handle Variable Argument List    Issue 4<br>&lt;limits.h&gt;    Implementation-defined constants, see C data types    Issue 1<br>&lt;utime.h&gt;    inode access and modification times    Issue 3<br>&lt;stdint.h&gt;    Integer types, see C data types    Issue 6<br>&lt;sys/ipc.h&gt;    Inter-process communication (IPC)    Issue 2<br>&lt;langinfo.h&gt;    Language information constants – builds on C localization functions    Issue 2<br>&lt;net/if.h&gt;    Listing of local network interfaces    Issue 6<br>&lt;nl_types.h&gt;    Localization message catalog functions    Issue 2<br>&lt;cpio.h&gt;    Magic numbers for the cpio archive format    Issue 3<br>&lt;tar.h&gt;    Magic numbers for the tar archive format    Issue 3<br>&lt;sys/socket.h&gt;    Main Berkeley sockets header    Issue 6<br>&lt;math.h&gt;    Mathematical declarations, see C mathematical functions    Issue 1<br>&lt;sys/mman.h&gt;    Memory management, including POSIX shared memory and memory mapped files    Issue 4<br>&lt;fmtmsg.h&gt;    Message display structures    Issue 4<br>&lt;mqueue.h&gt;    Message queue    Issue 5<br>&lt;ndbm.h&gt;    NDBM database operations    Issue 4<br>&lt;sys/utsname.h&gt;    Operating system information, including uname    Issue 1<br>&lt;pwd.h&gt;    passwd (user information) access and control    Issue 1<br>&lt;glob.h&gt;    Pathname “globbing” (pattern-matching)    Issue 4<br>&lt;libgen.h&gt;    Pathname manipulation    Issue 4<br>&lt;sys/msg.h&gt;    POSIX message queues    Issue 2<br>&lt;semaphore.h&gt;    POSIX semaphores    Issue 5<br>&lt;spawn.h&gt;    Process spawning    Issue 6<br>&lt;regex.h&gt;    Regular expression matching    Issue 4<br>&lt;ulimit.h&gt;    Resource limiting (DEPRECATED in favor of &lt;sys/resource.h&gt;)    Issue 1<br>&lt;sys/resource.h&gt;    Resource usage, priorities, and limiting    Issue 4<br>&lt;errno.h&gt;    Retrieving Error Number    Issue 1<br>&lt;search.h&gt;    Search tables    Issue 1<br>&lt;string.h&gt;    Several String Operations, see C string handling    Issue 1<br>&lt;signal.h&gt;    Signals, see C signal handling    Issue 1<br>&lt;setjmp.h&gt;    Stack environment declarations    Issue 1<br>&lt;stdio.h&gt;    Standard buffered input/output, see C file input/output    Issue 1<br>&lt;stdlib.h&gt;    Standard library definitions, see C standard library    Issue 3<br>&lt;stddef.h&gt;    Standard type definitions, see C data types    Issue 4<br>&lt;sys/wait.h&gt;    Status of terminated child processes (see wait)    Issue 3<br>&lt;stropts.h&gt;    Stream manipulation, including ioctl    Issue 4<br>&lt;monetary.h&gt;    String formatting of monetary units    Issue 4<br>&lt;sys/select.h&gt;    Synchronous I/O multiplexing    Issue 6<br>&lt;syslog.h&gt;    System error logging    Issue 4<br>&lt;sys/time.h&gt;    Time and date functions and structures    Issue 4<br>&lt;trace.h&gt;    Tracing of runtime behavior (DEPRECATED)    Issue 6<br>&lt;netdb.h&gt;    Translating protocol and host names into numeric addresses (part of Berkeley sockets)    Issue 6<br>&lt;time.h&gt;    Type-Generic Macros, see C date and time functions    Issue 1<br>&lt;tgmath.h&gt;    Type-Generic Macros, see C mathematical functions    Issue 1<br>&lt;sys/un.h&gt;    Unix domain sockets    Issue 6<br>&lt;utmpx.h&gt;    User accounting database functions    Issue 4<br>&lt;grp.h&gt;    User group information and control    Issue 1<br>&lt;sys/types.h&gt;    Various data types used elsewhere    Issue 1<br>&lt;unistd.h&gt;    Various essential POSIX functions and constants    Issue 1<br>&lt;sys/uio.h&gt;    Vectored I/O operations    Issue 4<br>&lt;assert.h&gt;    Verify assumptions    Issue 1<br>&lt;wctype.h&gt;    Wide-Character Classification and Mapping Utilities, see C character classification    Issue 5<br>&lt;wchar.h&gt;    Wide-Character Handling, see C string handling    Issue 4<br>&lt;wordexp.h&gt;    Word-expansion like the shell would perform    Issue 4<br>&lt;sys/sem.h&gt;    XSI (SysV style) semaphores    Issue 2<br>&lt;sys/shm.h&gt;    XSI (SysV style) shared memory    Issue 2</p>\n"},{"title":"Algorithm-Sort","date":"2018-10-30T12:06:43.000Z","_content":"\n### 快速排序\nhttps://www.jianshu.com/p/2ae6ba100d3a\n\nhttps://blog.csdn.net/qq_36528114/article/details/78667034\n\n\nhttp://blog.51cto.com/13733462/2113397","source":"_posts/Algorithm-Sort.md","raw":"---\ntitle: Algorithm-Sort\ndate: 2018-10-30 20:06:43\ntags:\n---\n\n### 快速排序\nhttps://www.jianshu.com/p/2ae6ba100d3a\n\nhttps://blog.csdn.net/qq_36528114/article/details/78667034\n\n\nhttp://blog.51cto.com/13733462/2113397","slug":"Algorithm-Sort","published":1,"updated":"2019-09-28T08:51:00.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8250005v1npb6jmat5k","content":"<h3 id=\"快速排序\"><a href=\"#快速排序\" class=\"headerlink\" title=\"快速排序\"></a>快速排序</h3><p><a href=\"https://www.jianshu.com/p/2ae6ba100d3a\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/2ae6ba100d3a</a></p>\n<p><a href=\"https://blog.csdn.net/qq_36528114/article/details/78667034\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_36528114/article/details/78667034</a></p>\n<p><a href=\"http://blog.51cto.com/13733462/2113397\" target=\"_blank\" rel=\"noopener\">http://blog.51cto.com/13733462/2113397</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"快速排序\"><a href=\"#快速排序\" class=\"headerlink\" title=\"快速排序\"></a>快速排序</h3><p><a href=\"https://www.jianshu.com/p/2ae6ba100d3a\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/2ae6ba100d3a</a></p>\n<p><a href=\"https://blog.csdn.net/qq_36528114/article/details/78667034\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_36528114/article/details/78667034</a></p>\n<p><a href=\"http://blog.51cto.com/13733462/2113397\" target=\"_blank\" rel=\"noopener\">http://blog.51cto.com/13733462/2113397</a></p>\n"},{"title":"Algorithm-Recursion","date":"2018-10-27T14:37:31.000Z","_content":"\n\n### 递归模式代码\n\n```\nresult recursion(level, param...) {\n    # recursion terminator\n    if \n        return ;\n    \n    processData(param);\n    result = recursion(level + 1, param...);\n    // 作为本level层，已经处理完了所有level大于本层的事情\n    processResult(result);\n}\n```","source":"_posts/Algorithm-Recursion.md","raw":"---\ntitle: Algorithm-Recursion\ndate: 2018-10-27 22:37:31\ntags:\n---\n\n\n### 递归模式代码\n\n```\nresult recursion(level, param...) {\n    # recursion terminator\n    if \n        return ;\n    \n    processData(param);\n    result = recursion(level + 1, param...);\n    // 作为本level层，已经处理完了所有level大于本层的事情\n    processResult(result);\n}\n```","slug":"Algorithm-Recursion","published":1,"updated":"2019-09-28T08:51:00.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8260006v1npm2vwuy4d","content":"<h3 id=\"递归模式代码\"><a href=\"#递归模式代码\" class=\"headerlink\" title=\"递归模式代码\"></a>递归模式代码</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">result recursion(level, param...) &#123;</span><br><span class=\"line\">    # recursion terminator</span><br><span class=\"line\">    if </span><br><span class=\"line\">        return ;</span><br><span class=\"line\">    </span><br><span class=\"line\">    processData(param);</span><br><span class=\"line\">    result = recursion(level + 1, param...);</span><br><span class=\"line\">    // 作为本level层，已经处理完了所有level大于本层的事情</span><br><span class=\"line\">    processResult(result);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"递归模式代码\"><a href=\"#递归模式代码\" class=\"headerlink\" title=\"递归模式代码\"></a>递归模式代码</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">result recursion(level, param...) &#123;</span><br><span class=\"line\">    # recursion terminator</span><br><span class=\"line\">    if </span><br><span class=\"line\">        return ;</span><br><span class=\"line\">    </span><br><span class=\"line\">    processData(param);</span><br><span class=\"line\">    result = recursion(level + 1, param...);</span><br><span class=\"line\">    // 作为本level层，已经处理完了所有level大于本层的事情</span><br><span class=\"line\">    processResult(result);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"CPP-Memory-leak","date":"2019-03-26T11:56:39.000Z","_content":"\n\nhttps://blog.csdn.net/qq_18824491/article/details/78902636","source":"_posts/CPP-Memory-leak.md","raw":"---\ntitle: CPP-Memory-leak\ndate: 2019-03-26 19:56:39\ntags:\n---\n\n\nhttps://blog.csdn.net/qq_18824491/article/details/78902636","slug":"CPP-Memory-leak","published":1,"updated":"2019-09-28T08:51:00.833Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8270007v1nphredm54s","content":"<p><a href=\"https://blog.csdn.net/qq_18824491/article/details/78902636\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_18824491/article/details/78902636</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/qq_18824491/article/details/78902636\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_18824491/article/details/78902636</a></p>\n"},{"title":"CPP-File-Operations","date":"2019-03-26T05:21:15.000Z","_content":"\nhttp://c.biancheng.net/c/file/\n缓冲和非缓冲文件系统\nC语言中文件系统可分为两大类，一种是缓冲文件系统也称为标准文件系统，另一种是非缓冲文件系统。ANSI C 标准中只采用缓冲文件系统。\n\n缓冲文件系统：系统自动为每个打开的文件在内存开辟一块缓冲区，缓冲区的大小一般由系统决定。当程序向文件中输出（写入）数据时，程序先把数据输出到缓冲区，待缓冲区满或数据输出完成后，再把数据从缓冲区输出到文件；当程序从文件输入(读取)数据时，先把数据输入到缓冲区，待缓冲区满或数据输人完成后，再把数据从缓冲区逐个输入到程序。\n\n非缓冲文件系统：系统不自动为打开的文件开辟内存缓冲区，由程序设计者自行设置缓冲区及大小。\n\n程序每一次访问磁盘等外存文件都需要移动磁头来定位磁头扇区，如果程序频繁地访问磁盘文件，会缩短磁盘的寿命，况且速度较慢，与快速的计算机内存处理速度不匹配。\n\n带缓冲区文件系统的好处是减少对磁盘等外存文件的操作次数，先把数据读取（写入）到缓冲区中，相当于把缓冲区中的数据一次性与内存交互，提髙了访问速度和设备利用率。\n\n一般把带缓冲文件系统的输入输出称作标准输入输出（标准 I/O），而非缓冲文件系统的输入输出称为系统输入输出（系统 I/O）。\n\nANSI C 为正在使用的每个文件分配一个文件信息区，该信息区中包含文件描述信息、 该文件所使用的缓冲区大小及缓冲区位置、该文件当前读写到的位置等基本信息。这些信息保存在一个结构体类型变量中，该结构体类型为 FILE 在 stdio.h 头文件中定义，不允许用户改变。\n\n每个 C 编译系统 stdio.h 文件中的 FILE 定义可能会稍有差别，但均包含文件读写的基本信息。","source":"_posts/CPP-File-Operations.md","raw":"---\ntitle: CPP-File-Operations\ndate: 2019-03-26 13:21:15\ntags:\n---\n\nhttp://c.biancheng.net/c/file/\n缓冲和非缓冲文件系统\nC语言中文件系统可分为两大类，一种是缓冲文件系统也称为标准文件系统，另一种是非缓冲文件系统。ANSI C 标准中只采用缓冲文件系统。\n\n缓冲文件系统：系统自动为每个打开的文件在内存开辟一块缓冲区，缓冲区的大小一般由系统决定。当程序向文件中输出（写入）数据时，程序先把数据输出到缓冲区，待缓冲区满或数据输出完成后，再把数据从缓冲区输出到文件；当程序从文件输入(读取)数据时，先把数据输入到缓冲区，待缓冲区满或数据输人完成后，再把数据从缓冲区逐个输入到程序。\n\n非缓冲文件系统：系统不自动为打开的文件开辟内存缓冲区，由程序设计者自行设置缓冲区及大小。\n\n程序每一次访问磁盘等外存文件都需要移动磁头来定位磁头扇区，如果程序频繁地访问磁盘文件，会缩短磁盘的寿命，况且速度较慢，与快速的计算机内存处理速度不匹配。\n\n带缓冲区文件系统的好处是减少对磁盘等外存文件的操作次数，先把数据读取（写入）到缓冲区中，相当于把缓冲区中的数据一次性与内存交互，提髙了访问速度和设备利用率。\n\n一般把带缓冲文件系统的输入输出称作标准输入输出（标准 I/O），而非缓冲文件系统的输入输出称为系统输入输出（系统 I/O）。\n\nANSI C 为正在使用的每个文件分配一个文件信息区，该信息区中包含文件描述信息、 该文件所使用的缓冲区大小及缓冲区位置、该文件当前读写到的位置等基本信息。这些信息保存在一个结构体类型变量中，该结构体类型为 FILE 在 stdio.h 头文件中定义，不允许用户改变。\n\n每个 C 编译系统 stdio.h 文件中的 FILE 定义可能会稍有差别，但均包含文件读写的基本信息。","slug":"CPP-File-Operations","published":1,"updated":"2019-09-28T08:51:00.833Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8280008v1npnx3czdfv","content":"<p><a href=\"http://c.biancheng.net/c/file/\" target=\"_blank\" rel=\"noopener\">http://c.biancheng.net/c/file/</a><br>缓冲和非缓冲文件系统<br>C语言中文件系统可分为两大类，一种是缓冲文件系统也称为标准文件系统，另一种是非缓冲文件系统。ANSI C 标准中只采用缓冲文件系统。</p>\n<p>缓冲文件系统：系统自动为每个打开的文件在内存开辟一块缓冲区，缓冲区的大小一般由系统决定。当程序向文件中输出（写入）数据时，程序先把数据输出到缓冲区，待缓冲区满或数据输出完成后，再把数据从缓冲区输出到文件；当程序从文件输入(读取)数据时，先把数据输入到缓冲区，待缓冲区满或数据输人完成后，再把数据从缓冲区逐个输入到程序。</p>\n<p>非缓冲文件系统：系统不自动为打开的文件开辟内存缓冲区，由程序设计者自行设置缓冲区及大小。</p>\n<p>程序每一次访问磁盘等外存文件都需要移动磁头来定位磁头扇区，如果程序频繁地访问磁盘文件，会缩短磁盘的寿命，况且速度较慢，与快速的计算机内存处理速度不匹配。</p>\n<p>带缓冲区文件系统的好处是减少对磁盘等外存文件的操作次数，先把数据读取（写入）到缓冲区中，相当于把缓冲区中的数据一次性与内存交互，提髙了访问速度和设备利用率。</p>\n<p>一般把带缓冲文件系统的输入输出称作标准输入输出（标准 I/O），而非缓冲文件系统的输入输出称为系统输入输出（系统 I/O）。</p>\n<p>ANSI C 为正在使用的每个文件分配一个文件信息区，该信息区中包含文件描述信息、 该文件所使用的缓冲区大小及缓冲区位置、该文件当前读写到的位置等基本信息。这些信息保存在一个结构体类型变量中，该结构体类型为 FILE 在 stdio.h 头文件中定义，不允许用户改变。</p>\n<p>每个 C 编译系统 stdio.h 文件中的 FILE 定义可能会稍有差别，但均包含文件读写的基本信息。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://c.biancheng.net/c/file/\" target=\"_blank\" rel=\"noopener\">http://c.biancheng.net/c/file/</a><br>缓冲和非缓冲文件系统<br>C语言中文件系统可分为两大类，一种是缓冲文件系统也称为标准文件系统，另一种是非缓冲文件系统。ANSI C 标准中只采用缓冲文件系统。</p>\n<p>缓冲文件系统：系统自动为每个打开的文件在内存开辟一块缓冲区，缓冲区的大小一般由系统决定。当程序向文件中输出（写入）数据时，程序先把数据输出到缓冲区，待缓冲区满或数据输出完成后，再把数据从缓冲区输出到文件；当程序从文件输入(读取)数据时，先把数据输入到缓冲区，待缓冲区满或数据输人完成后，再把数据从缓冲区逐个输入到程序。</p>\n<p>非缓冲文件系统：系统不自动为打开的文件开辟内存缓冲区，由程序设计者自行设置缓冲区及大小。</p>\n<p>程序每一次访问磁盘等外存文件都需要移动磁头来定位磁头扇区，如果程序频繁地访问磁盘文件，会缩短磁盘的寿命，况且速度较慢，与快速的计算机内存处理速度不匹配。</p>\n<p>带缓冲区文件系统的好处是减少对磁盘等外存文件的操作次数，先把数据读取（写入）到缓冲区中，相当于把缓冲区中的数据一次性与内存交互，提髙了访问速度和设备利用率。</p>\n<p>一般把带缓冲文件系统的输入输出称作标准输入输出（标准 I/O），而非缓冲文件系统的输入输出称为系统输入输出（系统 I/O）。</p>\n<p>ANSI C 为正在使用的每个文件分配一个文件信息区，该信息区中包含文件描述信息、 该文件所使用的缓冲区大小及缓冲区位置、该文件当前读写到的位置等基本信息。这些信息保存在一个结构体类型变量中，该结构体类型为 FILE 在 stdio.h 头文件中定义，不允许用户改变。</p>\n<p>每个 C 编译系统 stdio.h 文件中的 FILE 定义可能会稍有差别，但均包含文件读写的基本信息。</p>\n"},{"title":"CPP-Endian","date":"2019-03-18T09:06:57.000Z","_content":"\n\nhttps://www.jianshu.com/p/befb3a7de297\n\n```\n// 在 ubuntu12.04 系统下，运行的结果是“Little Endian”；\n// 在 iOS 系统下，运行的结果也是“Little Endian”。\nvoid main() {\n    int i = 0x12345678;\n    char* pc = (char*)&i;\n    if (*pc == 0x12) {\n        printf(\"Big Endian\\n\");\n    } else if (*pc == 0x78) {\n        printf(\"Little Endian\\n\");\n    }\n}\n```","source":"_posts/CPP-Endian.md","raw":"---\ntitle: CPP-Endian\ndate: 2019-03-18 17:06:57\ntags:\n---\n\n\nhttps://www.jianshu.com/p/befb3a7de297\n\n```\n// 在 ubuntu12.04 系统下，运行的结果是“Little Endian”；\n// 在 iOS 系统下，运行的结果也是“Little Endian”。\nvoid main() {\n    int i = 0x12345678;\n    char* pc = (char*)&i;\n    if (*pc == 0x12) {\n        printf(\"Big Endian\\n\");\n    } else if (*pc == 0x78) {\n        printf(\"Little Endian\\n\");\n    }\n}\n```","slug":"CPP-Endian","published":1,"updated":"2019-09-28T08:51:00.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8290009v1np7tm4z6wm","content":"<p><a href=\"https://www.jianshu.com/p/befb3a7de297\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/befb3a7de297</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 在 ubuntu12.04 系统下，运行的结果是“Little Endian”；</span><br><span class=\"line\">// 在 iOS 系统下，运行的结果也是“Little Endian”。</span><br><span class=\"line\">void main() &#123;</span><br><span class=\"line\">    int i = 0x12345678;</span><br><span class=\"line\">    char* pc = (char*)&amp;i;</span><br><span class=\"line\">    if (*pc == 0x12) &#123;</span><br><span class=\"line\">        printf(&quot;Big Endian\\n&quot;);</span><br><span class=\"line\">    &#125; else if (*pc == 0x78) &#123;</span><br><span class=\"line\">        printf(&quot;Little Endian\\n&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.jianshu.com/p/befb3a7de297\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/befb3a7de297</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 在 ubuntu12.04 系统下，运行的结果是“Little Endian”；</span><br><span class=\"line\">// 在 iOS 系统下，运行的结果也是“Little Endian”。</span><br><span class=\"line\">void main() &#123;</span><br><span class=\"line\">    int i = 0x12345678;</span><br><span class=\"line\">    char* pc = (char*)&amp;i;</span><br><span class=\"line\">    if (*pc == 0x12) &#123;</span><br><span class=\"line\">        printf(&quot;Big Endian\\n&quot;);</span><br><span class=\"line\">    &#125; else if (*pc == 0x78) &#123;</span><br><span class=\"line\">        printf(&quot;Little Endian\\n&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Cobar——Reactor设计模式","date":"2017-07-24T10:00:58.000Z","_content":"\n### I/O多路复用（multiplexing）和 行为分用（demultiplexing）\n\n### Redis为什么是单线程的？\nhttp://www.dengshenyu.com/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/2016/01/09/redis-reactor-pattern.html\n\n### C10K问题\nhttps://segmentfault.com/a/1190000007240744\n\n### 为什么我们要用NIO而不是BIO？\nIO复用模型，Linux下的select、poll和epoll就是干这个的，这三个东西本质上都上做同一种事情。将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用非阻塞模式。这样，整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，这个阻塞而且是可以设置超时时间，超时时间过后，程序还可以处理除了epoll之外的逻辑，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的reactor模式。\n但是，和熟悉Linux的同事交流后，发现阻塞IO其实也是能复用线程的，也就是说，用几个线程也是可以处理成千上万的连接的。那怎么做呢？关键在于，阻塞IO的read和write可以向OS提供一种超时机制，如果read或者write没有数据，是会阻塞，但是时间非常短，这依赖于程序向OS发送的超时信号。那既然可以，为什么我们一定是用非阻塞的IO去处理C10K问题，而不是用阻塞IO呢？注意到，如果用阻塞IO，CPU在使用上一直是去探测Socket上究竟有没有数据，而没有正儿八经用在数据的处理上；非阻塞IO的好处在于，这个探测的过程是OS用epoll这种事件机制帮你做的，不仅在探测数据时间的效率上比轮询高，并且CPU还没有浪费在探测上。\n\n### Cobar Reactor\n\n![](Cobar-Reactor-design-pattern/CobarReactorSign.gif)\n\n#### NIO原生API\n\n![](Cobar-Reactor-design-pattern/NioRegister.gif)\n\n#### Cobar NIO Server线程模型\n\n![](Cobar-Reactor-design-pattern/CobarReactor.gif)\n\n#### Cobar的整个模型非常像 Fork/Join\nForks and Joins: When a job arrives at a fork point, it is split into N sub-jobs which are then serviced by n tasks. After being serviced, each sub-job waits until all other sub-jobs are done processing. Then, they are joined again and leave the system. Thus, in parallel programming, we require synchronization as all the parallel processes wait for several other processes to occur.\n\n\n### 如何深刻理解reactor和proactor？\n\nreactor：能收了你跟俺说一声。\nproactor: 你给我收十个字节，收好了跟俺说一声。\n\nRefer:\nhttp://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf\n\n","source":"_posts/Cobar-Reactor-design-pattern.md","raw":"---\ntitle: Cobar——Reactor设计模式\ndate: 2017-07-24 18:00:58\ntags: Cobar\n---\n\n### I/O多路复用（multiplexing）和 行为分用（demultiplexing）\n\n### Redis为什么是单线程的？\nhttp://www.dengshenyu.com/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/2016/01/09/redis-reactor-pattern.html\n\n### C10K问题\nhttps://segmentfault.com/a/1190000007240744\n\n### 为什么我们要用NIO而不是BIO？\nIO复用模型，Linux下的select、poll和epoll就是干这个的，这三个东西本质上都上做同一种事情。将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用非阻塞模式。这样，整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，这个阻塞而且是可以设置超时时间，超时时间过后，程序还可以处理除了epoll之外的逻辑，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的reactor模式。\n但是，和熟悉Linux的同事交流后，发现阻塞IO其实也是能复用线程的，也就是说，用几个线程也是可以处理成千上万的连接的。那怎么做呢？关键在于，阻塞IO的read和write可以向OS提供一种超时机制，如果read或者write没有数据，是会阻塞，但是时间非常短，这依赖于程序向OS发送的超时信号。那既然可以，为什么我们一定是用非阻塞的IO去处理C10K问题，而不是用阻塞IO呢？注意到，如果用阻塞IO，CPU在使用上一直是去探测Socket上究竟有没有数据，而没有正儿八经用在数据的处理上；非阻塞IO的好处在于，这个探测的过程是OS用epoll这种事件机制帮你做的，不仅在探测数据时间的效率上比轮询高，并且CPU还没有浪费在探测上。\n\n### Cobar Reactor\n\n![](Cobar-Reactor-design-pattern/CobarReactorSign.gif)\n\n#### NIO原生API\n\n![](Cobar-Reactor-design-pattern/NioRegister.gif)\n\n#### Cobar NIO Server线程模型\n\n![](Cobar-Reactor-design-pattern/CobarReactor.gif)\n\n#### Cobar的整个模型非常像 Fork/Join\nForks and Joins: When a job arrives at a fork point, it is split into N sub-jobs which are then serviced by n tasks. After being serviced, each sub-job waits until all other sub-jobs are done processing. Then, they are joined again and leave the system. Thus, in parallel programming, we require synchronization as all the parallel processes wait for several other processes to occur.\n\n\n### 如何深刻理解reactor和proactor？\n\nreactor：能收了你跟俺说一声。\nproactor: 你给我收十个字节，收好了跟俺说一声。\n\nRefer:\nhttp://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf\n\n","slug":"Cobar-Reactor-design-pattern","published":1,"updated":"2019-09-28T08:51:00.851Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82a000av1npkdn9c5fx","content":"<h3 id=\"I-O多路复用（multiplexing）和-行为分用（demultiplexing）\"><a href=\"#I-O多路复用（multiplexing）和-行为分用（demultiplexing）\" class=\"headerlink\" title=\"I/O多路复用（multiplexing）和 行为分用（demultiplexing）\"></a>I/O多路复用（multiplexing）和 行为分用（demultiplexing）</h3><h3 id=\"Redis为什么是单线程的？\"><a href=\"#Redis为什么是单线程的？\" class=\"headerlink\" title=\"Redis为什么是单线程的？\"></a>Redis为什么是单线程的？</h3><p><a href=\"http://www.dengshenyu.com/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/2016/01/09/redis-reactor-pattern.html\" target=\"_blank\" rel=\"noopener\">http://www.dengshenyu.com/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/2016/01/09/redis-reactor-pattern.html</a></p>\n<h3 id=\"C10K问题\"><a href=\"#C10K问题\" class=\"headerlink\" title=\"C10K问题\"></a>C10K问题</h3><p><a href=\"https://segmentfault.com/a/1190000007240744\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000007240744</a></p>\n<h3 id=\"为什么我们要用NIO而不是BIO？\"><a href=\"#为什么我们要用NIO而不是BIO？\" class=\"headerlink\" title=\"为什么我们要用NIO而不是BIO？\"></a>为什么我们要用NIO而不是BIO？</h3><p>IO复用模型，Linux下的select、poll和epoll就是干这个的，这三个东西本质上都上做同一种事情。将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用非阻塞模式。这样，整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，这个阻塞而且是可以设置超时时间，超时时间过后，程序还可以处理除了epoll之外的逻辑，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的reactor模式。<br>但是，和熟悉Linux的同事交流后，发现阻塞IO其实也是能复用线程的，也就是说，用几个线程也是可以处理成千上万的连接的。那怎么做呢？关键在于，阻塞IO的read和write可以向OS提供一种超时机制，如果read或者write没有数据，是会阻塞，但是时间非常短，这依赖于程序向OS发送的超时信号。那既然可以，为什么我们一定是用非阻塞的IO去处理C10K问题，而不是用阻塞IO呢？注意到，如果用阻塞IO，CPU在使用上一直是去探测Socket上究竟有没有数据，而没有正儿八经用在数据的处理上；非阻塞IO的好处在于，这个探测的过程是OS用epoll这种事件机制帮你做的，不仅在探测数据时间的效率上比轮询高，并且CPU还没有浪费在探测上。</p>\n<h3 id=\"Cobar-Reactor\"><a href=\"#Cobar-Reactor\" class=\"headerlink\" title=\"Cobar Reactor\"></a>Cobar Reactor</h3><p><img src=\"/2017/07/24/Cobar-Reactor-design-pattern/CobarReactorSign.gif\" alt=\"\"></p>\n<h4 id=\"NIO原生API\"><a href=\"#NIO原生API\" class=\"headerlink\" title=\"NIO原生API\"></a>NIO原生API</h4><p><img src=\"/2017/07/24/Cobar-Reactor-design-pattern/NioRegister.gif\" alt=\"\"></p>\n<h4 id=\"Cobar-NIO-Server线程模型\"><a href=\"#Cobar-NIO-Server线程模型\" class=\"headerlink\" title=\"Cobar NIO Server线程模型\"></a>Cobar NIO Server线程模型</h4><p><img src=\"/2017/07/24/Cobar-Reactor-design-pattern/CobarReactor.gif\" alt=\"\"></p>\n<h4 id=\"Cobar的整个模型非常像-Fork-Join\"><a href=\"#Cobar的整个模型非常像-Fork-Join\" class=\"headerlink\" title=\"Cobar的整个模型非常像 Fork/Join\"></a>Cobar的整个模型非常像 Fork/Join</h4><p>Forks and Joins: When a job arrives at a fork point, it is split into N sub-jobs which are then serviced by n tasks. After being serviced, each sub-job waits until all other sub-jobs are done processing. Then, they are joined again and leave the system. Thus, in parallel programming, we require synchronization as all the parallel processes wait for several other processes to occur.</p>\n<h3 id=\"如何深刻理解reactor和proactor？\"><a href=\"#如何深刻理解reactor和proactor？\" class=\"headerlink\" title=\"如何深刻理解reactor和proactor？\"></a>如何深刻理解reactor和proactor？</h3><p>reactor：能收了你跟俺说一声。<br>proactor: 你给我收十个字节，收好了跟俺说一声。</p>\n<p>Refer:<br><a href=\"http://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf\" target=\"_blank\" rel=\"noopener\">http://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"I-O多路复用（multiplexing）和-行为分用（demultiplexing）\"><a href=\"#I-O多路复用（multiplexing）和-行为分用（demultiplexing）\" class=\"headerlink\" title=\"I/O多路复用（multiplexing）和 行为分用（demultiplexing）\"></a>I/O多路复用（multiplexing）和 行为分用（demultiplexing）</h3><h3 id=\"Redis为什么是单线程的？\"><a href=\"#Redis为什么是单线程的？\" class=\"headerlink\" title=\"Redis为什么是单线程的？\"></a>Redis为什么是单线程的？</h3><p><a href=\"http://www.dengshenyu.com/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/2016/01/09/redis-reactor-pattern.html\" target=\"_blank\" rel=\"noopener\">http://www.dengshenyu.com/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF/2016/01/09/redis-reactor-pattern.html</a></p>\n<h3 id=\"C10K问题\"><a href=\"#C10K问题\" class=\"headerlink\" title=\"C10K问题\"></a>C10K问题</h3><p><a href=\"https://segmentfault.com/a/1190000007240744\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000007240744</a></p>\n<h3 id=\"为什么我们要用NIO而不是BIO？\"><a href=\"#为什么我们要用NIO而不是BIO？\" class=\"headerlink\" title=\"为什么我们要用NIO而不是BIO？\"></a>为什么我们要用NIO而不是BIO？</h3><p>IO复用模型，Linux下的select、poll和epoll就是干这个的，这三个东西本质上都上做同一种事情。将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用非阻塞模式。这样，整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，这个阻塞而且是可以设置超时时间，超时时间过后，程序还可以处理除了epoll之外的逻辑，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的reactor模式。<br>但是，和熟悉Linux的同事交流后，发现阻塞IO其实也是能复用线程的，也就是说，用几个线程也是可以处理成千上万的连接的。那怎么做呢？关键在于，阻塞IO的read和write可以向OS提供一种超时机制，如果read或者write没有数据，是会阻塞，但是时间非常短，这依赖于程序向OS发送的超时信号。那既然可以，为什么我们一定是用非阻塞的IO去处理C10K问题，而不是用阻塞IO呢？注意到，如果用阻塞IO，CPU在使用上一直是去探测Socket上究竟有没有数据，而没有正儿八经用在数据的处理上；非阻塞IO的好处在于，这个探测的过程是OS用epoll这种事件机制帮你做的，不仅在探测数据时间的效率上比轮询高，并且CPU还没有浪费在探测上。</p>\n<h3 id=\"Cobar-Reactor\"><a href=\"#Cobar-Reactor\" class=\"headerlink\" title=\"Cobar Reactor\"></a>Cobar Reactor</h3><p><img src=\"/2017/07/24/Cobar-Reactor-design-pattern/CobarReactorSign.gif\" alt=\"\"></p>\n<h4 id=\"NIO原生API\"><a href=\"#NIO原生API\" class=\"headerlink\" title=\"NIO原生API\"></a>NIO原生API</h4><p><img src=\"/2017/07/24/Cobar-Reactor-design-pattern/NioRegister.gif\" alt=\"\"></p>\n<h4 id=\"Cobar-NIO-Server线程模型\"><a href=\"#Cobar-NIO-Server线程模型\" class=\"headerlink\" title=\"Cobar NIO Server线程模型\"></a>Cobar NIO Server线程模型</h4><p><img src=\"/2017/07/24/Cobar-Reactor-design-pattern/CobarReactor.gif\" alt=\"\"></p>\n<h4 id=\"Cobar的整个模型非常像-Fork-Join\"><a href=\"#Cobar的整个模型非常像-Fork-Join\" class=\"headerlink\" title=\"Cobar的整个模型非常像 Fork/Join\"></a>Cobar的整个模型非常像 Fork/Join</h4><p>Forks and Joins: When a job arrives at a fork point, it is split into N sub-jobs which are then serviced by n tasks. After being serviced, each sub-job waits until all other sub-jobs are done processing. Then, they are joined again and leave the system. Thus, in parallel programming, we require synchronization as all the parallel processes wait for several other processes to occur.</p>\n<h3 id=\"如何深刻理解reactor和proactor？\"><a href=\"#如何深刻理解reactor和proactor？\" class=\"headerlink\" title=\"如何深刻理解reactor和proactor？\"></a>如何深刻理解reactor和proactor？</h3><p>reactor：能收了你跟俺说一声。<br>proactor: 你给我收十个字节，收好了跟俺说一声。</p>\n<p>Refer:<br><a href=\"http://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf\" target=\"_blank\" rel=\"noopener\">http://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf</a></p>\n"},{"title":"Curator-sync-and-mutual-exclusion-between-thread-and-process","date":"2017-10-28T02:46:49.000Z","_content":"\n### Lock\n\n#### read write lock\n\n#### spin lock\n\n#### reentrant lock\n\n### Barrier\n\n### Semaphore\n\n###","source":"_posts/Curator-sync-and-mutual-exclusion-between-thread-and-process.md","raw":"---\ntitle: Curator-sync-and-mutual-exclusion-between-thread-and-process\ndate: 2017-10-28 10:46:49\ntags: Curator\n---\n\n### Lock\n\n#### read write lock\n\n#### spin lock\n\n#### reentrant lock\n\n### Barrier\n\n### Semaphore\n\n###","slug":"Curator-sync-and-mutual-exclusion-between-thread-and-process","published":1,"updated":"2019-09-28T08:51:00.859Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82b000bv1npt1qx4bw6","content":"<h3 id=\"Lock\"><a href=\"#Lock\" class=\"headerlink\" title=\"Lock\"></a>Lock</h3><h4 id=\"read-write-lock\"><a href=\"#read-write-lock\" class=\"headerlink\" title=\"read write lock\"></a>read write lock</h4><h4 id=\"spin-lock\"><a href=\"#spin-lock\" class=\"headerlink\" title=\"spin lock\"></a>spin lock</h4><h4 id=\"reentrant-lock\"><a href=\"#reentrant-lock\" class=\"headerlink\" title=\"reentrant lock\"></a>reentrant lock</h4><h3 id=\"Barrier\"><a href=\"#Barrier\" class=\"headerlink\" title=\"Barrier\"></a>Barrier</h3><h3 id=\"Semaphore\"><a href=\"#Semaphore\" class=\"headerlink\" title=\"Semaphore\"></a>Semaphore</h3><p>###</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Lock\"><a href=\"#Lock\" class=\"headerlink\" title=\"Lock\"></a>Lock</h3><h4 id=\"read-write-lock\"><a href=\"#read-write-lock\" class=\"headerlink\" title=\"read write lock\"></a>read write lock</h4><h4 id=\"spin-lock\"><a href=\"#spin-lock\" class=\"headerlink\" title=\"spin lock\"></a>spin lock</h4><h4 id=\"reentrant-lock\"><a href=\"#reentrant-lock\" class=\"headerlink\" title=\"reentrant lock\"></a>reentrant lock</h4><h3 id=\"Barrier\"><a href=\"#Barrier\" class=\"headerlink\" title=\"Barrier\"></a>Barrier</h3><h3 id=\"Semaphore\"><a href=\"#Semaphore\" class=\"headerlink\" title=\"Semaphore\"></a>Semaphore</h3><p>###</p>\n"},{"title":"curator——分布式锁的实现之一","date":"2017-09-28T08:58:05.000Z","_content":"\n\n### MySQL实现\n\n\n### Redis\n\nhttp://blog.csdn.net/bolg_hero/article/details/78532920\n\n### ZooKeeper\n RedLock\n\n\n``` java\npublic class InterProcessMutexTest {\n    public static final String LOCK_PATH = \"/curator-kick-off/lock\";\n    private static CuratorFramework client;\n\n    @BeforeClass\n    public static void before() {\n        client = CuratorFrameworkFactory.newClient(\n                \"127.0.0.1:2181\",\n                1000 * 10,\n                3000, new ExponentialBackoffRetry(\n                        1000,\n                        3));\n        client.start();\n    }\n\n    @Test\n    public void test() throws Exception {\n        InterProcessMutex lock = new InterProcessMutex(client, LOCK_PATH);\n        boolean acquire = lock.acquire(5, TimeUnit.SECONDS);\n        System.out.println(acquire);\n        System.out.println(\"done\");\n        lock.release();\n        System.in.read();\n    }\n}\n```\n","source":"_posts/Curator-Distributed-lock.md","raw":"---\ntitle: curator——分布式锁的实现之一\ndate: 2017-09-28 16:58:05\ntags: Curator\n---\n\n\n### MySQL实现\n\n\n### Redis\n\nhttp://blog.csdn.net/bolg_hero/article/details/78532920\n\n### ZooKeeper\n RedLock\n\n\n``` java\npublic class InterProcessMutexTest {\n    public static final String LOCK_PATH = \"/curator-kick-off/lock\";\n    private static CuratorFramework client;\n\n    @BeforeClass\n    public static void before() {\n        client = CuratorFrameworkFactory.newClient(\n                \"127.0.0.1:2181\",\n                1000 * 10,\n                3000, new ExponentialBackoffRetry(\n                        1000,\n                        3));\n        client.start();\n    }\n\n    @Test\n    public void test() throws Exception {\n        InterProcessMutex lock = new InterProcessMutex(client, LOCK_PATH);\n        boolean acquire = lock.acquire(5, TimeUnit.SECONDS);\n        System.out.println(acquire);\n        System.out.println(\"done\");\n        lock.release();\n        System.in.read();\n    }\n}\n```\n","slug":"Curator-Distributed-lock","published":1,"updated":"2019-09-28T08:51:00.859Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82c000cv1npg2rlimpa","content":"<h3 id=\"MySQL实现\"><a href=\"#MySQL实现\" class=\"headerlink\" title=\"MySQL实现\"></a>MySQL实现</h3><h3 id=\"Redis\"><a href=\"#Redis\" class=\"headerlink\" title=\"Redis\"></a>Redis</h3><p><a href=\"http://blog.csdn.net/bolg_hero/article/details/78532920\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/bolg_hero/article/details/78532920</a></p>\n<h3 id=\"ZooKeeper\"><a href=\"#ZooKeeper\" class=\"headerlink\" title=\"ZooKeeper\"></a>ZooKeeper</h3><p> RedLock</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">InterProcessMutexTest</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> String LOCK_PATH = <span class=\"string\">\"/curator-kick-off/lock\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> CuratorFramework client;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@BeforeClass</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">before</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        client = CuratorFrameworkFactory.newClient(</span><br><span class=\"line\">                <span class=\"string\">\"127.0.0.1:2181\"</span>,</span><br><span class=\"line\">                <span class=\"number\">1000</span> * <span class=\"number\">10</span>,</span><br><span class=\"line\">                <span class=\"number\">3000</span>, <span class=\"keyword\">new</span> ExponentialBackoffRetry(</span><br><span class=\"line\">                        <span class=\"number\">1000</span>,</span><br><span class=\"line\">                        <span class=\"number\">3</span>));</span><br><span class=\"line\">        client.start();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        InterProcessMutex lock = <span class=\"keyword\">new</span> InterProcessMutex(client, LOCK_PATH);</span><br><span class=\"line\">        <span class=\"keyword\">boolean</span> acquire = lock.acquire(<span class=\"number\">5</span>, TimeUnit.SECONDS);</span><br><span class=\"line\">        System.out.println(acquire);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"done\"</span>);</span><br><span class=\"line\">        lock.release();</span><br><span class=\"line\">        System.in.read();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"MySQL实现\"><a href=\"#MySQL实现\" class=\"headerlink\" title=\"MySQL实现\"></a>MySQL实现</h3><h3 id=\"Redis\"><a href=\"#Redis\" class=\"headerlink\" title=\"Redis\"></a>Redis</h3><p><a href=\"http://blog.csdn.net/bolg_hero/article/details/78532920\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/bolg_hero/article/details/78532920</a></p>\n<h3 id=\"ZooKeeper\"><a href=\"#ZooKeeper\" class=\"headerlink\" title=\"ZooKeeper\"></a>ZooKeeper</h3><p> RedLock</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">InterProcessMutexTest</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> String LOCK_PATH = <span class=\"string\">\"/curator-kick-off/lock\"</span>;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> CuratorFramework client;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@BeforeClass</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">before</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        client = CuratorFrameworkFactory.newClient(</span><br><span class=\"line\">                <span class=\"string\">\"127.0.0.1:2181\"</span>,</span><br><span class=\"line\">                <span class=\"number\">1000</span> * <span class=\"number\">10</span>,</span><br><span class=\"line\">                <span class=\"number\">3000</span>, <span class=\"keyword\">new</span> ExponentialBackoffRetry(</span><br><span class=\"line\">                        <span class=\"number\">1000</span>,</span><br><span class=\"line\">                        <span class=\"number\">3</span>));</span><br><span class=\"line\">        client.start();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Test</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">        InterProcessMutex lock = <span class=\"keyword\">new</span> InterProcessMutex(client, LOCK_PATH);</span><br><span class=\"line\">        <span class=\"keyword\">boolean</span> acquire = lock.acquire(<span class=\"number\">5</span>, TimeUnit.SECONDS);</span><br><span class=\"line\">        System.out.println(acquire);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"done\"</span>);</span><br><span class=\"line\">        lock.release();</span><br><span class=\"line\">        System.in.read();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"DataStructure-Red-black-tree","date":"2018-10-23T09:46:26.000Z","_content":"","source":"_posts/DataStructure-Red-black-tree.md","raw":"---\ntitle: DataStructure-Red-black-tree\ndate: 2018-10-23 17:46:26\ntags:\n---\n","slug":"DataStructure-Red-black-tree","published":1,"updated":"2019-09-28T08:51:00.859Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82c000dv1nps6r0dfkg","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"DataStructure-Skiplist","date":"2018-11-01T04:45:15.000Z","_content":"\n### 精品博客\nhttp://hacking.love/2016/06/26/%E8%B7%B3%E8%B7%83%E8%A1%A8Skip-List%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0-Java/\n\nhttps://blog.csdn.net/derrantcm/article/details/79063312\n","source":"_posts/DataStructure-Skiplist.md","raw":"---\ntitle: DataStructure-Skiplist\ndate: 2018-11-01 12:45:15\ntags:\n---\n\n### 精品博客\nhttp://hacking.love/2016/06/26/%E8%B7%B3%E8%B7%83%E8%A1%A8Skip-List%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0-Java/\n\nhttps://blog.csdn.net/derrantcm/article/details/79063312\n","slug":"DataStructure-Skiplist","published":1,"updated":"2019-09-28T08:51:00.859Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82d000ev1np4ew38vlm","content":"<h3 id=\"精品博客\"><a href=\"#精品博客\" class=\"headerlink\" title=\"精品博客\"></a>精品博客</h3><p><a href=\"http://hacking.love/2016/06/26/%E8%B7%B3%E8%B7%83%E8%A1%A8Skip-List%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0-Java/\" target=\"_blank\" rel=\"noopener\">http://hacking.love/2016/06/26/%E8%B7%B3%E8%B7%83%E8%A1%A8Skip-List%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0-Java/</a></p>\n<p><a href=\"https://blog.csdn.net/derrantcm/article/details/79063312\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/derrantcm/article/details/79063312</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"精品博客\"><a href=\"#精品博客\" class=\"headerlink\" title=\"精品博客\"></a>精品博客</h3><p><a href=\"http://hacking.love/2016/06/26/%E8%B7%B3%E8%B7%83%E8%A1%A8Skip-List%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0-Java/\" target=\"_blank\" rel=\"noopener\">http://hacking.love/2016/06/26/%E8%B7%B3%E8%B7%83%E8%A1%A8Skip-List%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0-Java/</a></p>\n<p><a href=\"https://blog.csdn.net/derrantcm/article/details/79063312\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/derrantcm/article/details/79063312</a></p>\n"},{"title":"Disruptor-Internal","date":"2018-08-13T08:46:51.000Z","_content":"\n\n\n### 美团的技术博客，质量真的高\nhttps://tech.meituan.com/disruptor.html\n\n经常会被面试官问到，如果设计一个无锁(Lock-Free)的并发数字自增器，或者无锁的RingBuffer。在开发经验还不够的情况下，确实很难想到改怎么去实现，知道后面接触了CAS后。\n\n常用的，并发情况下访问共享资源，思路总是将并行访问串行化，也就是说，要锁住共享资源。所以，锁还是必要的，而Lock-Free中说的无锁是指没有用到传统的方式对线程进行上锁，也就是sync或者ReentrantLock甚至是wait，不知说真的就没有锁。传统的锁会让线程调度器改变内核级线程的状态，而且有频繁的线程上下文切换，比较耗时，而CAS自旋锁的好处是，线程没有改变running的状态，CAS是CPU级别的操作，不耗时间，属于轻量级锁，坏处也是非常明显的，如果资源上锁时间特别长，阻塞的线程CAS自旋会消耗比较多的CPU资源，而这种CPU消耗，在传统锁上是不存在的，因为线程失去了CPU的执行权力。\n\n自旋锁伪代码：\n```\nclass SpinLock {\n    private AtomicBoolean locked = false;\n    \n    \n    public Lock() {\n        while(!locked.cas(false->true)){\n        }\n    }\n    \n    public Unlock() {\n        locked.set(false)\n    }\n}\n\n```\n\n当然以上代码会有非常大的问题，尤其是Lock()方法被阻塞得太久了，CPU就饿死了(starving)了。所以，当自旋的次数超过了某个阈值后，可以讲自旋锁升级为mutex。\n\n\n\n\n\n### Disruptor:为什么会这么快\nhttps://ifeve.com/disruptor/\n1. 无锁CAS抢占，防止上下文切换\n2. 伪共享内存，独立缓存存放独立cursor变量\n3. RingBuffer，减少GC\n\n\n### Disruptor视频资源\nhttp://edu.51cto.com/course/11789.html\nhttp://study.163.com/course/introduction/1004573050.htm\nhttps://www.bilibili.com/video/av15276598/\n\n","source":"_posts/Disruptor-Internal.md","raw":"---\ntitle: Disruptor-Internal\ndate: 2018-08-13 16:46:51\ntags:\n---\n\n\n\n### 美团的技术博客，质量真的高\nhttps://tech.meituan.com/disruptor.html\n\n经常会被面试官问到，如果设计一个无锁(Lock-Free)的并发数字自增器，或者无锁的RingBuffer。在开发经验还不够的情况下，确实很难想到改怎么去实现，知道后面接触了CAS后。\n\n常用的，并发情况下访问共享资源，思路总是将并行访问串行化，也就是说，要锁住共享资源。所以，锁还是必要的，而Lock-Free中说的无锁是指没有用到传统的方式对线程进行上锁，也就是sync或者ReentrantLock甚至是wait，不知说真的就没有锁。传统的锁会让线程调度器改变内核级线程的状态，而且有频繁的线程上下文切换，比较耗时，而CAS自旋锁的好处是，线程没有改变running的状态，CAS是CPU级别的操作，不耗时间，属于轻量级锁，坏处也是非常明显的，如果资源上锁时间特别长，阻塞的线程CAS自旋会消耗比较多的CPU资源，而这种CPU消耗，在传统锁上是不存在的，因为线程失去了CPU的执行权力。\n\n自旋锁伪代码：\n```\nclass SpinLock {\n    private AtomicBoolean locked = false;\n    \n    \n    public Lock() {\n        while(!locked.cas(false->true)){\n        }\n    }\n    \n    public Unlock() {\n        locked.set(false)\n    }\n}\n\n```\n\n当然以上代码会有非常大的问题，尤其是Lock()方法被阻塞得太久了，CPU就饿死了(starving)了。所以，当自旋的次数超过了某个阈值后，可以讲自旋锁升级为mutex。\n\n\n\n\n\n### Disruptor:为什么会这么快\nhttps://ifeve.com/disruptor/\n1. 无锁CAS抢占，防止上下文切换\n2. 伪共享内存，独立缓存存放独立cursor变量\n3. RingBuffer，减少GC\n\n\n### Disruptor视频资源\nhttp://edu.51cto.com/course/11789.html\nhttp://study.163.com/course/introduction/1004573050.htm\nhttps://www.bilibili.com/video/av15276598/\n\n","slug":"Disruptor-Internal","published":1,"updated":"2019-09-28T08:51:00.859Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82e000fv1nputbgxxzg","content":"<h3 id=\"美团的技术博客，质量真的高\"><a href=\"#美团的技术博客，质量真的高\" class=\"headerlink\" title=\"美团的技术博客，质量真的高\"></a>美团的技术博客，质量真的高</h3><p><a href=\"https://tech.meituan.com/disruptor.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/disruptor.html</a></p>\n<p>经常会被面试官问到，如果设计一个无锁(Lock-Free)的并发数字自增器，或者无锁的RingBuffer。在开发经验还不够的情况下，确实很难想到改怎么去实现，知道后面接触了CAS后。</p>\n<p>常用的，并发情况下访问共享资源，思路总是将并行访问串行化，也就是说，要锁住共享资源。所以，锁还是必要的，而Lock-Free中说的无锁是指没有用到传统的方式对线程进行上锁，也就是sync或者ReentrantLock甚至是wait，不知说真的就没有锁。传统的锁会让线程调度器改变内核级线程的状态，而且有频繁的线程上下文切换，比较耗时，而CAS自旋锁的好处是，线程没有改变running的状态，CAS是CPU级别的操作，不耗时间，属于轻量级锁，坏处也是非常明显的，如果资源上锁时间特别长，阻塞的线程CAS自旋会消耗比较多的CPU资源，而这种CPU消耗，在传统锁上是不存在的，因为线程失去了CPU的执行权力。</p>\n<p>自旋锁伪代码：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class SpinLock &#123;</span><br><span class=\"line\">    private AtomicBoolean locked = false;</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">    public Lock() &#123;</span><br><span class=\"line\">        while(!locked.cas(false-&gt;true))&#123;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    public Unlock() &#123;</span><br><span class=\"line\">        locked.set(false)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当然以上代码会有非常大的问题，尤其是Lock()方法被阻塞得太久了，CPU就饿死了(starving)了。所以，当自旋的次数超过了某个阈值后，可以讲自旋锁升级为mutex。</p>\n<h3 id=\"Disruptor-为什么会这么快\"><a href=\"#Disruptor-为什么会这么快\" class=\"headerlink\" title=\"Disruptor:为什么会这么快\"></a>Disruptor:为什么会这么快</h3><p><a href=\"https://ifeve.com/disruptor/\" target=\"_blank\" rel=\"noopener\">https://ifeve.com/disruptor/</a></p>\n<ol>\n<li>无锁CAS抢占，防止上下文切换</li>\n<li>伪共享内存，独立缓存存放独立cursor变量</li>\n<li>RingBuffer，减少GC</li>\n</ol>\n<h3 id=\"Disruptor视频资源\"><a href=\"#Disruptor视频资源\" class=\"headerlink\" title=\"Disruptor视频资源\"></a>Disruptor视频资源</h3><p><a href=\"http://edu.51cto.com/course/11789.html\" target=\"_blank\" rel=\"noopener\">http://edu.51cto.com/course/11789.html</a><br><a href=\"http://study.163.com/course/introduction/1004573050.htm\" target=\"_blank\" rel=\"noopener\">http://study.163.com/course/introduction/1004573050.htm</a><br><a href=\"https://www.bilibili.com/video/av15276598/\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/av15276598/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"美团的技术博客，质量真的高\"><a href=\"#美团的技术博客，质量真的高\" class=\"headerlink\" title=\"美团的技术博客，质量真的高\"></a>美团的技术博客，质量真的高</h3><p><a href=\"https://tech.meituan.com/disruptor.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/disruptor.html</a></p>\n<p>经常会被面试官问到，如果设计一个无锁(Lock-Free)的并发数字自增器，或者无锁的RingBuffer。在开发经验还不够的情况下，确实很难想到改怎么去实现，知道后面接触了CAS后。</p>\n<p>常用的，并发情况下访问共享资源，思路总是将并行访问串行化，也就是说，要锁住共享资源。所以，锁还是必要的，而Lock-Free中说的无锁是指没有用到传统的方式对线程进行上锁，也就是sync或者ReentrantLock甚至是wait，不知说真的就没有锁。传统的锁会让线程调度器改变内核级线程的状态，而且有频繁的线程上下文切换，比较耗时，而CAS自旋锁的好处是，线程没有改变running的状态，CAS是CPU级别的操作，不耗时间，属于轻量级锁，坏处也是非常明显的，如果资源上锁时间特别长，阻塞的线程CAS自旋会消耗比较多的CPU资源，而这种CPU消耗，在传统锁上是不存在的，因为线程失去了CPU的执行权力。</p>\n<p>自旋锁伪代码：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class SpinLock &#123;</span><br><span class=\"line\">    private AtomicBoolean locked = false;</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">    public Lock() &#123;</span><br><span class=\"line\">        while(!locked.cas(false-&gt;true))&#123;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    public Unlock() &#123;</span><br><span class=\"line\">        locked.set(false)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当然以上代码会有非常大的问题，尤其是Lock()方法被阻塞得太久了，CPU就饿死了(starving)了。所以，当自旋的次数超过了某个阈值后，可以讲自旋锁升级为mutex。</p>\n<h3 id=\"Disruptor-为什么会这么快\"><a href=\"#Disruptor-为什么会这么快\" class=\"headerlink\" title=\"Disruptor:为什么会这么快\"></a>Disruptor:为什么会这么快</h3><p><a href=\"https://ifeve.com/disruptor/\" target=\"_blank\" rel=\"noopener\">https://ifeve.com/disruptor/</a></p>\n<ol>\n<li>无锁CAS抢占，防止上下文切换</li>\n<li>伪共享内存，独立缓存存放独立cursor变量</li>\n<li>RingBuffer，减少GC</li>\n</ol>\n<h3 id=\"Disruptor视频资源\"><a href=\"#Disruptor视频资源\" class=\"headerlink\" title=\"Disruptor视频资源\"></a>Disruptor视频资源</h3><p><a href=\"http://edu.51cto.com/course/11789.html\" target=\"_blank\" rel=\"noopener\">http://edu.51cto.com/course/11789.html</a><br><a href=\"http://study.163.com/course/introduction/1004573050.htm\" target=\"_blank\" rel=\"noopener\">http://study.163.com/course/introduction/1004573050.htm</a><br><a href=\"https://www.bilibili.com/video/av15276598/\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/av15276598/</a></p>\n"},{"title":"Disruptor-Low-Latency-Mode","date":"2019-04-10T02:17:17.000Z","_content":"\n\n\nhttps://www.infoq.com/articles/High-Performance-Java-Inter-Thread-Communications\nAfter a quick search for performance tests I found a throughput test for three publishers and one consumer. That was just what the doctor ordered and it produced the following results:\n","source":"_posts/Disruptor-Low-Latency-Mode.md","raw":"---\ntitle: Disruptor-Low-Latency-Mode\ndate: 2019-04-10 10:17:17\ntags:\n---\n\n\n\nhttps://www.infoq.com/articles/High-Performance-Java-Inter-Thread-Communications\nAfter a quick search for performance tests I found a throughput test for three publishers and one consumer. That was just what the doctor ordered and it produced the following results:\n","slug":"Disruptor-Low-Latency-Mode","published":1,"updated":"2019-09-28T08:51:00.860Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82e000gv1nphupygefq","content":"<p><a href=\"https://www.infoq.com/articles/High-Performance-Java-Inter-Thread-Communications\" target=\"_blank\" rel=\"noopener\">https://www.infoq.com/articles/High-Performance-Java-Inter-Thread-Communications</a><br>After a quick search for performance tests I found a throughput test for three publishers and one consumer. That was just what the doctor ordered and it produced the following results:</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.infoq.com/articles/High-Performance-Java-Inter-Thread-Communications\" target=\"_blank\" rel=\"noopener\">https://www.infoq.com/articles/High-Performance-Java-Inter-Thread-Communications</a><br>After a quick search for performance tests I found a throughput test for three publishers and one consumer. That was just what the doctor ordered and it produced the following results:</p>\n"},{"title":"Distributed-CAP","date":"2018-08-22T01:50:30.000Z","_content":"\n### 为什么说zookeeper不适合做服务注册中心\nhttps://www.jianshu.com/p/87ef94edaf5a","source":"_posts/Distributed-CAP.md","raw":"---\ntitle: Distributed-CAP\ndate: 2018-08-22 09:50:30\ntags:\n---\n\n### 为什么说zookeeper不适合做服务注册中心\nhttps://www.jianshu.com/p/87ef94edaf5a","slug":"Distributed-CAP","published":1,"updated":"2019-09-28T08:51:00.860Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82f000hv1npvyq6a4l3","content":"<h3 id=\"为什么说zookeeper不适合做服务注册中心\"><a href=\"#为什么说zookeeper不适合做服务注册中心\" class=\"headerlink\" title=\"为什么说zookeeper不适合做服务注册中心\"></a>为什么说zookeeper不适合做服务注册中心</h3><p><a href=\"https://www.jianshu.com/p/87ef94edaf5a\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/87ef94edaf5a</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"为什么说zookeeper不适合做服务注册中心\"><a href=\"#为什么说zookeeper不适合做服务注册中心\" class=\"headerlink\" title=\"为什么说zookeeper不适合做服务注册中心\"></a>为什么说zookeeper不适合做服务注册中心</h3><p><a href=\"https://www.jianshu.com/p/87ef94edaf5a\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/87ef94edaf5a</a></p>\n"},{"title":"Distributed-Consensus-Raft","date":"2017-11-15T03:41:21.000Z","_content":"\nhttps://zhuanlan.zhihu.com/p/27910576\nhttp://thesecretlivesofdata.com/raft/\n\n### 不想当将军的兵不是好兵\n\n### 将军永远想独裁\n\n### 为了生存，要隐忍","source":"_posts/Distributed-Consensus-Raft.md","raw":"---\ntitle: Distributed-Consensus-Raft\ndate: 2017-11-15 11:41:21\ntags: Raft\n---\n\nhttps://zhuanlan.zhihu.com/p/27910576\nhttp://thesecretlivesofdata.com/raft/\n\n### 不想当将军的兵不是好兵\n\n### 将军永远想独裁\n\n### 为了生存，要隐忍","slug":"Distributed-Consensus-Raft","published":1,"updated":"2019-09-28T08:51:00.860Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82f000iv1npo2o3eg1u","content":"<p><a href=\"https://zhuanlan.zhihu.com/p/27910576\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/27910576</a><br><a href=\"http://thesecretlivesofdata.com/raft/\" target=\"_blank\" rel=\"noopener\">http://thesecretlivesofdata.com/raft/</a></p>\n<h3 id=\"不想当将军的兵不是好兵\"><a href=\"#不想当将军的兵不是好兵\" class=\"headerlink\" title=\"不想当将军的兵不是好兵\"></a>不想当将军的兵不是好兵</h3><h3 id=\"将军永远想独裁\"><a href=\"#将军永远想独裁\" class=\"headerlink\" title=\"将军永远想独裁\"></a>将军永远想独裁</h3><h3 id=\"为了生存，要隐忍\"><a href=\"#为了生存，要隐忍\" class=\"headerlink\" title=\"为了生存，要隐忍\"></a>为了生存，要隐忍</h3>","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://zhuanlan.zhihu.com/p/27910576\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/27910576</a><br><a href=\"http://thesecretlivesofdata.com/raft/\" target=\"_blank\" rel=\"noopener\">http://thesecretlivesofdata.com/raft/</a></p>\n<h3 id=\"不想当将军的兵不是好兵\"><a href=\"#不想当将军的兵不是好兵\" class=\"headerlink\" title=\"不想当将军的兵不是好兵\"></a>不想当将军的兵不是好兵</h3><h3 id=\"将军永远想独裁\"><a href=\"#将军永远想独裁\" class=\"headerlink\" title=\"将军永远想独裁\"></a>将军永远想独裁</h3><h3 id=\"为了生存，要隐忍\"><a href=\"#为了生存，要隐忍\" class=\"headerlink\" title=\"为了生存，要隐忍\"></a>为了生存，要隐忍</h3>"},{"title":"Distributed-Transaction-TCC","date":"2017-11-10T11:03:55.000Z","_content":"\n### TCC\n\n### 变种\n\nhttps://github.com/1991wangliang/tx-lcn","source":"_posts/Distributed-Transaction-TCC.md","raw":"---\ntitle: Distributed-Transaction-TCC\ndate: 2017-11-10 19:03:55\ntags: 分布式事务\n---\n\n### TCC\n\n### 变种\n\nhttps://github.com/1991wangliang/tx-lcn","slug":"Distributed-Transaction-TCC","published":1,"updated":"2019-09-28T08:51:00.860Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82g000jv1nptreffjo3","content":"<h3 id=\"TCC\"><a href=\"#TCC\" class=\"headerlink\" title=\"TCC\"></a>TCC</h3><h3 id=\"变种\"><a href=\"#变种\" class=\"headerlink\" title=\"变种\"></a>变种</h3><p><a href=\"https://github.com/1991wangliang/tx-lcn\" target=\"_blank\" rel=\"noopener\">https://github.com/1991wangliang/tx-lcn</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"TCC\"><a href=\"#TCC\" class=\"headerlink\" title=\"TCC\"></a>TCC</h3><h3 id=\"变种\"><a href=\"#变种\" class=\"headerlink\" title=\"变种\"></a>变种</h3><p><a href=\"https://github.com/1991wangliang/tx-lcn\" target=\"_blank\" rel=\"noopener\">https://github.com/1991wangliang/tx-lcn</a></p>\n"},{"title":"分布式唯一ID","date":"2017-11-08T06:39:03.000Z","_content":"\n\n``` java\n/**\n * Twitter_Snowflake<br>\n * SnowFlake的结构如下(每部分用-分开):<br>\n * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 <br>\n * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0<br>\n * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截)\n * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L << 41) / (1000L * 60 * 60 * 24 * 365) = 69<br>\n * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId<br>\n * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号<br>\n * 加起来刚好64位，为一个Long型。<br>\n * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。\n */\npublic class SnowflakeIdWorker {\n\n    // ==============================Fields===========================================\n    /** 开始时间截 (2015-01-01) */\n    private final long twepoch = 1420041600000L;\n\n    /** 机器id所占的位数 */\n    private final long workerIdBits = 5L;\n\n    /** 数据标识id所占的位数 */\n    private final long datacenterIdBits = 5L;\n\n    /** 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */\n    private final long maxWorkerId = -1L ^ (-1L << workerIdBits);\n\n    /** 支持的最大数据标识id，结果是31 */\n    private final long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);\n\n    /** 序列在id中占的位数 */\n    private final long sequenceBits = 12L;\n\n    /** 机器ID向左移12位 */\n    private final long workerIdShift = sequenceBits;\n\n    /** 数据标识id向左移17位(12+5) */\n    private final long datacenterIdShift = sequenceBits + workerIdBits;\n\n    /** 时间截向左移22位(5+5+12) */\n    private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;\n\n    /** 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */\n    private final long sequenceMask = -1L ^ (-1L << sequenceBits);\n\n    /** 工作机器ID(0~31) */\n    private long workerId;\n\n    /** 数据中心ID(0~31) */\n    private long datacenterId;\n\n    /** 毫秒内序列(0~4095) */\n    private long sequence = 0L;\n\n    /** 上次生成ID的时间截 */\n    private long lastTimestamp = -1L;\n\n    //==============================Constructors=====================================\n    /**\n     * 构造函数\n     * @param workerId 工作ID (0~31)\n     * @param datacenterId 数据中心ID (0~31)\n     */\n    public SnowflakeIdWorker(long workerId, long datacenterId) {\n        if (workerId > maxWorkerId || workerId < 0) {\n            throw new IllegalArgumentException(String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId));\n        }\n        if (datacenterId > maxDatacenterId || datacenterId < 0) {\n            throw new IllegalArgumentException(String.format(\"datacenter Id can't be greater than %d or less than 0\", maxDatacenterId));\n        }\n        this.workerId = workerId;\n        this.datacenterId = datacenterId;\n    }\n\n    // ==============================Methods==========================================\n    /**\n     * 获得下一个ID (该方法是线程安全的)\n     * @return SnowflakeId\n     */\n    public synchronized long nextId() {\n        long timestamp = timeGen();\n\n        //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常\n        if (timestamp < lastTimestamp) {\n            throw new RuntimeException(\n                    String.format(\"Clock moved backwards.  Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp));\n        }\n\n        //如果是同一时间生成的，则进行毫秒内序列\n        if (lastTimestamp == timestamp) {\n            sequence = (sequence + 1) & sequenceMask;\n            //毫秒内序列溢出\n            if (sequence == 0) {\n                //阻塞到下一个毫秒,获得新的时间戳\n                timestamp = tilNextMillis(lastTimestamp);\n            }\n        }\n        //时间戳改变，毫秒内序列重置\n        else {\n            sequence = 0L;\n        }\n\n        //上次生成ID的时间截\n        lastTimestamp = timestamp;\n\n        //移位并通过或运算拼到一起组成64位的ID\n        return ((timestamp - twepoch) << timestampLeftShift) //\n                | (datacenterId << datacenterIdShift) //\n                | (workerId << workerIdShift) //\n                | sequence;\n    }\n\n    /**\n     * 阻塞到下一个毫秒，直到获得新的时间戳\n     * @param lastTimestamp 上次生成ID的时间截\n     * @return 当前时间戳\n     */\n    protected long tilNextMillis(long lastTimestamp) {\n        long timestamp = timeGen();\n        while (timestamp <= lastTimestamp) {\n            timestamp = timeGen();\n        }\n        return timestamp;\n    }\n\n    /**\n     * 返回以毫秒为单位的当前时间\n     * @return 当前时间(毫秒)\n     */\n    protected long timeGen() {\n        return System.currentTimeMillis();\n    }\n\n    //==============================Test=============================================\n    /** 测试 */\n    public static void main(String[] args) {\n        SnowflakeIdWorker idWorker = new SnowflakeIdWorker(0, 0);\n        for (int i = 0; i < 1000; i++) {\n            long id = idWorker.nextId();\n            System.out.println(Long.toBinaryString(id));\n            System.out.println(id);\n        }\n    }\n}\n```\n\n### baidu uid-generator\n\nhttps://github.com/baidu/uid-generator\n\n### 怎么解决由于\n","source":"_posts/Distributed-Unique-id.md","raw":"---\ntitle: 分布式唯一ID\ndate: 2017-11-08 14:39:03\ntags: 分布式设计\n---\n\n\n``` java\n/**\n * Twitter_Snowflake<br>\n * SnowFlake的结构如下(每部分用-分开):<br>\n * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 <br>\n * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0<br>\n * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截)\n * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L << 41) / (1000L * 60 * 60 * 24 * 365) = 69<br>\n * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId<br>\n * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号<br>\n * 加起来刚好64位，为一个Long型。<br>\n * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。\n */\npublic class SnowflakeIdWorker {\n\n    // ==============================Fields===========================================\n    /** 开始时间截 (2015-01-01) */\n    private final long twepoch = 1420041600000L;\n\n    /** 机器id所占的位数 */\n    private final long workerIdBits = 5L;\n\n    /** 数据标识id所占的位数 */\n    private final long datacenterIdBits = 5L;\n\n    /** 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */\n    private final long maxWorkerId = -1L ^ (-1L << workerIdBits);\n\n    /** 支持的最大数据标识id，结果是31 */\n    private final long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);\n\n    /** 序列在id中占的位数 */\n    private final long sequenceBits = 12L;\n\n    /** 机器ID向左移12位 */\n    private final long workerIdShift = sequenceBits;\n\n    /** 数据标识id向左移17位(12+5) */\n    private final long datacenterIdShift = sequenceBits + workerIdBits;\n\n    /** 时间截向左移22位(5+5+12) */\n    private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;\n\n    /** 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */\n    private final long sequenceMask = -1L ^ (-1L << sequenceBits);\n\n    /** 工作机器ID(0~31) */\n    private long workerId;\n\n    /** 数据中心ID(0~31) */\n    private long datacenterId;\n\n    /** 毫秒内序列(0~4095) */\n    private long sequence = 0L;\n\n    /** 上次生成ID的时间截 */\n    private long lastTimestamp = -1L;\n\n    //==============================Constructors=====================================\n    /**\n     * 构造函数\n     * @param workerId 工作ID (0~31)\n     * @param datacenterId 数据中心ID (0~31)\n     */\n    public SnowflakeIdWorker(long workerId, long datacenterId) {\n        if (workerId > maxWorkerId || workerId < 0) {\n            throw new IllegalArgumentException(String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId));\n        }\n        if (datacenterId > maxDatacenterId || datacenterId < 0) {\n            throw new IllegalArgumentException(String.format(\"datacenter Id can't be greater than %d or less than 0\", maxDatacenterId));\n        }\n        this.workerId = workerId;\n        this.datacenterId = datacenterId;\n    }\n\n    // ==============================Methods==========================================\n    /**\n     * 获得下一个ID (该方法是线程安全的)\n     * @return SnowflakeId\n     */\n    public synchronized long nextId() {\n        long timestamp = timeGen();\n\n        //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常\n        if (timestamp < lastTimestamp) {\n            throw new RuntimeException(\n                    String.format(\"Clock moved backwards.  Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp));\n        }\n\n        //如果是同一时间生成的，则进行毫秒内序列\n        if (lastTimestamp == timestamp) {\n            sequence = (sequence + 1) & sequenceMask;\n            //毫秒内序列溢出\n            if (sequence == 0) {\n                //阻塞到下一个毫秒,获得新的时间戳\n                timestamp = tilNextMillis(lastTimestamp);\n            }\n        }\n        //时间戳改变，毫秒内序列重置\n        else {\n            sequence = 0L;\n        }\n\n        //上次生成ID的时间截\n        lastTimestamp = timestamp;\n\n        //移位并通过或运算拼到一起组成64位的ID\n        return ((timestamp - twepoch) << timestampLeftShift) //\n                | (datacenterId << datacenterIdShift) //\n                | (workerId << workerIdShift) //\n                | sequence;\n    }\n\n    /**\n     * 阻塞到下一个毫秒，直到获得新的时间戳\n     * @param lastTimestamp 上次生成ID的时间截\n     * @return 当前时间戳\n     */\n    protected long tilNextMillis(long lastTimestamp) {\n        long timestamp = timeGen();\n        while (timestamp <= lastTimestamp) {\n            timestamp = timeGen();\n        }\n        return timestamp;\n    }\n\n    /**\n     * 返回以毫秒为单位的当前时间\n     * @return 当前时间(毫秒)\n     */\n    protected long timeGen() {\n        return System.currentTimeMillis();\n    }\n\n    //==============================Test=============================================\n    /** 测试 */\n    public static void main(String[] args) {\n        SnowflakeIdWorker idWorker = new SnowflakeIdWorker(0, 0);\n        for (int i = 0; i < 1000; i++) {\n            long id = idWorker.nextId();\n            System.out.println(Long.toBinaryString(id));\n            System.out.println(id);\n        }\n    }\n}\n```\n\n### baidu uid-generator\n\nhttps://github.com/baidu/uid-generator\n\n### 怎么解决由于\n","slug":"Distributed-Unique-id","published":1,"updated":"2019-09-28T08:51:00.862Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82h000kv1np169wkwsl","content":"<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Twitter_Snowflake&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * SnowFlake的结构如下(每部分用-分开):&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截)</span></span><br><span class=\"line\"><span class=\"comment\"> * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * 加起来刚好64位，为一个Long型。&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SnowflakeIdWorker</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ==============================Fields===========================================</span></span><br><span class=\"line\">    <span class=\"comment\">/** 开始时间截 (2015-01-01) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> twepoch = <span class=\"number\">1420041600000L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 机器id所占的位数 */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> workerIdBits = <span class=\"number\">5L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 数据标识id所占的位数 */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> datacenterIdBits = <span class=\"number\">5L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> maxWorkerId = -<span class=\"number\">1L</span> ^ (-<span class=\"number\">1L</span> &lt;&lt; workerIdBits);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 支持的最大数据标识id，结果是31 */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> maxDatacenterId = -<span class=\"number\">1L</span> ^ (-<span class=\"number\">1L</span> &lt;&lt; datacenterIdBits);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 序列在id中占的位数 */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> sequenceBits = <span class=\"number\">12L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 机器ID向左移12位 */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> workerIdShift = sequenceBits;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 数据标识id向左移17位(12+5) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> datacenterIdShift = sequenceBits + workerIdBits;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 时间截向左移22位(5+5+12) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> sequenceMask = -<span class=\"number\">1L</span> ^ (-<span class=\"number\">1L</span> &lt;&lt; sequenceBits);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 工作机器ID(0~31) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> workerId;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 数据中心ID(0~31) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> datacenterId;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 毫秒内序列(0~4095) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> sequence = <span class=\"number\">0L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 上次生成ID的时间截 */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> lastTimestamp = -<span class=\"number\">1L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//==============================Constructors=====================================</span></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 构造函数</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> workerId 工作ID (0~31)</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> datacenterId 数据中心ID (0~31)</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">SnowflakeIdWorker</span><span class=\"params\">(<span class=\"keyword\">long</span> workerId, <span class=\"keyword\">long</span> datacenterId)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (workerId &gt; maxWorkerId || workerId &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(String.format(<span class=\"string\">\"worker Id can't be greater than %d or less than 0\"</span>, maxWorkerId));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (datacenterId &gt; maxDatacenterId || datacenterId &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(String.format(<span class=\"string\">\"datacenter Id can't be greater than %d or less than 0\"</span>, maxDatacenterId));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.workerId = workerId;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.datacenterId = datacenterId;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ==============================Methods==========================================</span></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获得下一个ID (该方法是线程安全的)</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> SnowflakeId</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">synchronized</span> <span class=\"keyword\">long</span> <span class=\"title\">nextId</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> timestamp = timeGen();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (timestamp &lt; lastTimestamp) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> RuntimeException(</span><br><span class=\"line\">                    String.format(<span class=\"string\">\"Clock moved backwards.  Refusing to generate id for %d milliseconds\"</span>, lastTimestamp - timestamp));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//如果是同一时间生成的，则进行毫秒内序列</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (lastTimestamp == timestamp) &#123;</span><br><span class=\"line\">            sequence = (sequence + <span class=\"number\">1</span>) &amp; sequenceMask;</span><br><span class=\"line\">            <span class=\"comment\">//毫秒内序列溢出</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (sequence == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                <span class=\"comment\">//阻塞到下一个毫秒,获得新的时间戳</span></span><br><span class=\"line\">                timestamp = tilNextMillis(lastTimestamp);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//时间戳改变，毫秒内序列重置</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            sequence = <span class=\"number\">0L</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//上次生成ID的时间截</span></span><br><span class=\"line\">        lastTimestamp = timestamp;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//移位并通过或运算拼到一起组成64位的ID</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> ((timestamp - twepoch) &lt;&lt; timestampLeftShift) <span class=\"comment\">//</span></span><br><span class=\"line\">                | (datacenterId &lt;&lt; datacenterIdShift) <span class=\"comment\">//</span></span><br><span class=\"line\">                | (workerId &lt;&lt; workerIdShift) <span class=\"comment\">//</span></span><br><span class=\"line\">                | sequence;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 阻塞到下一个毫秒，直到获得新的时间戳</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> lastTimestamp 上次生成ID的时间截</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> 当前时间戳</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">long</span> <span class=\"title\">tilNextMillis</span><span class=\"params\">(<span class=\"keyword\">long</span> lastTimestamp)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> timestamp = timeGen();</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (timestamp &lt;= lastTimestamp) &#123;</span><br><span class=\"line\">            timestamp = timeGen();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> timestamp;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 返回以毫秒为单位的当前时间</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> 当前时间(毫秒)</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">long</span> <span class=\"title\">timeGen</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> System.currentTimeMillis();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//==============================Test=============================================</span></span><br><span class=\"line\">    <span class=\"comment\">/** 测试 */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        SnowflakeIdWorker idWorker = <span class=\"keyword\">new</span> SnowflakeIdWorker(<span class=\"number\">0</span>, <span class=\"number\">0</span>);</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">1000</span>; i++) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">long</span> id = idWorker.nextId();</span><br><span class=\"line\">            System.out.println(Long.toBinaryString(id));</span><br><span class=\"line\">            System.out.println(id);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"baidu-uid-generator\"><a href=\"#baidu-uid-generator\" class=\"headerlink\" title=\"baidu uid-generator\"></a>baidu uid-generator</h3><p><a href=\"https://github.com/baidu/uid-generator\" target=\"_blank\" rel=\"noopener\">https://github.com/baidu/uid-generator</a></p>\n<h3 id=\"怎么解决由于\"><a href=\"#怎么解决由于\" class=\"headerlink\" title=\"怎么解决由于\"></a>怎么解决由于</h3>","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Twitter_Snowflake&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * SnowFlake的结构如下(每部分用-分开):&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截)</span></span><br><span class=\"line\"><span class=\"comment\"> * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * 加起来刚好64位，为一个Long型。&lt;br&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SnowflakeIdWorker</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ==============================Fields===========================================</span></span><br><span class=\"line\">    <span class=\"comment\">/** 开始时间截 (2015-01-01) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> twepoch = <span class=\"number\">1420041600000L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 机器id所占的位数 */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> workerIdBits = <span class=\"number\">5L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 数据标识id所占的位数 */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> datacenterIdBits = <span class=\"number\">5L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> maxWorkerId = -<span class=\"number\">1L</span> ^ (-<span class=\"number\">1L</span> &lt;&lt; workerIdBits);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 支持的最大数据标识id，结果是31 */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> maxDatacenterId = -<span class=\"number\">1L</span> ^ (-<span class=\"number\">1L</span> &lt;&lt; datacenterIdBits);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 序列在id中占的位数 */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> sequenceBits = <span class=\"number\">12L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 机器ID向左移12位 */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> workerIdShift = sequenceBits;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 数据标识id向左移17位(12+5) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> datacenterIdShift = sequenceBits + workerIdBits;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 时间截向左移22位(5+5+12) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> sequenceMask = -<span class=\"number\">1L</span> ^ (-<span class=\"number\">1L</span> &lt;&lt; sequenceBits);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 工作机器ID(0~31) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> workerId;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 数据中心ID(0~31) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> datacenterId;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 毫秒内序列(0~4095) */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> sequence = <span class=\"number\">0L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** 上次生成ID的时间截 */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> lastTimestamp = -<span class=\"number\">1L</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//==============================Constructors=====================================</span></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 构造函数</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> workerId 工作ID (0~31)</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> datacenterId 数据中心ID (0~31)</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">SnowflakeIdWorker</span><span class=\"params\">(<span class=\"keyword\">long</span> workerId, <span class=\"keyword\">long</span> datacenterId)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (workerId &gt; maxWorkerId || workerId &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(String.format(<span class=\"string\">\"worker Id can't be greater than %d or less than 0\"</span>, maxWorkerId));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (datacenterId &gt; maxDatacenterId || datacenterId &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(String.format(<span class=\"string\">\"datacenter Id can't be greater than %d or less than 0\"</span>, maxDatacenterId));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.workerId = workerId;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.datacenterId = datacenterId;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ==============================Methods==========================================</span></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 获得下一个ID (该方法是线程安全的)</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> SnowflakeId</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">synchronized</span> <span class=\"keyword\">long</span> <span class=\"title\">nextId</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> timestamp = timeGen();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (timestamp &lt; lastTimestamp) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> RuntimeException(</span><br><span class=\"line\">                    String.format(<span class=\"string\">\"Clock moved backwards.  Refusing to generate id for %d milliseconds\"</span>, lastTimestamp - timestamp));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//如果是同一时间生成的，则进行毫秒内序列</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (lastTimestamp == timestamp) &#123;</span><br><span class=\"line\">            sequence = (sequence + <span class=\"number\">1</span>) &amp; sequenceMask;</span><br><span class=\"line\">            <span class=\"comment\">//毫秒内序列溢出</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (sequence == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                <span class=\"comment\">//阻塞到下一个毫秒,获得新的时间戳</span></span><br><span class=\"line\">                timestamp = tilNextMillis(lastTimestamp);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">//时间戳改变，毫秒内序列重置</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            sequence = <span class=\"number\">0L</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//上次生成ID的时间截</span></span><br><span class=\"line\">        lastTimestamp = timestamp;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//移位并通过或运算拼到一起组成64位的ID</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> ((timestamp - twepoch) &lt;&lt; timestampLeftShift) <span class=\"comment\">//</span></span><br><span class=\"line\">                | (datacenterId &lt;&lt; datacenterIdShift) <span class=\"comment\">//</span></span><br><span class=\"line\">                | (workerId &lt;&lt; workerIdShift) <span class=\"comment\">//</span></span><br><span class=\"line\">                | sequence;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 阻塞到下一个毫秒，直到获得新的时间戳</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> lastTimestamp 上次生成ID的时间截</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> 当前时间戳</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">long</span> <span class=\"title\">tilNextMillis</span><span class=\"params\">(<span class=\"keyword\">long</span> lastTimestamp)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> timestamp = timeGen();</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (timestamp &lt;= lastTimestamp) &#123;</span><br><span class=\"line\">            timestamp = timeGen();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> timestamp;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * 返回以毫秒为单位的当前时间</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> 当前时间(毫秒)</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">long</span> <span class=\"title\">timeGen</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> System.currentTimeMillis();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//==============================Test=============================================</span></span><br><span class=\"line\">    <span class=\"comment\">/** 测试 */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        SnowflakeIdWorker idWorker = <span class=\"keyword\">new</span> SnowflakeIdWorker(<span class=\"number\">0</span>, <span class=\"number\">0</span>);</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">1000</span>; i++) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">long</span> id = idWorker.nextId();</span><br><span class=\"line\">            System.out.println(Long.toBinaryString(id));</span><br><span class=\"line\">            System.out.println(id);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"baidu-uid-generator\"><a href=\"#baidu-uid-generator\" class=\"headerlink\" title=\"baidu uid-generator\"></a>baidu uid-generator</h3><p><a href=\"https://github.com/baidu/uid-generator\" target=\"_blank\" rel=\"noopener\">https://github.com/baidu/uid-generator</a></p>\n<h3 id=\"怎么解决由于\"><a href=\"#怎么解决由于\" class=\"headerlink\" title=\"怎么解决由于\"></a>怎么解决由于</h3>"},{"title":"Distributed-Transaction","date":"2017-11-03T02:54:48.000Z","_content":"\n### TCC\n\n### RocketMQ事务功能\n![你想输入的替代文字](Distributed-Transaction/transaction_rocketmq.gif)\n\n### 抽象出一个完整的系统\n不是所有的MQ系统都是支持这个HalfMsg的操作的，所以我们把这个系统抽成一个事务SOA服务\n\nhttps://mp.weixin.qq.com/s?__biz=MzU4MTEyODIzMg==&mid=2247483713&idx=1&sn=c9efdd6eda9d7bd32f82e42b2ca3fbe3&chksm=fd4d1806ca3a9110474f9c0b1d2a886a9f994c4b8ed8d354a3c6bd8d8373cd012646443ebfca&mpshare=1&scene=1&srcid=1110kSXANwBrbL2TWtA0NAK6&key=86d1b0bfcae3874289b26357e30923b1734881e3a43437f4558c9c6be8f133e62f000fc4c315915ad48066faca9893f45a6515e6faebf3f27b85a03bf975ca15ecd8401181121b82a5d41040f7b5c565&ascene=0&uin=MjcyMjMxNTA0Mg%3D%3D&devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12+build(16A323)&version=12010210&nettype=WIFI&fontScale=100&pass_ticket=T2oTN5azeGV4Brh%2FOFJxtVGb2WVp1QN3ylyWucAGYWTJBOrOLdFJzJoRIwToLTv8\n\n### Spring Cloud\nhttp://www.jianshu.com/p/cf3a2884a8d2?open_source=weibo_search\nhttps://www.atomikos.com/Blog/TransactionManagementAPIForRESTTCC\n\n\nhttps://github.com/beston123/Tarzan","source":"_posts/Distributed-Transaction.md","raw":"---\ntitle: Distributed-Transaction\ndate: 2017-11-03 10:54:48\ntags: 分布式事务\n---\n\n### TCC\n\n### RocketMQ事务功能\n![你想输入的替代文字](Distributed-Transaction/transaction_rocketmq.gif)\n\n### 抽象出一个完整的系统\n不是所有的MQ系统都是支持这个HalfMsg的操作的，所以我们把这个系统抽成一个事务SOA服务\n\nhttps://mp.weixin.qq.com/s?__biz=MzU4MTEyODIzMg==&mid=2247483713&idx=1&sn=c9efdd6eda9d7bd32f82e42b2ca3fbe3&chksm=fd4d1806ca3a9110474f9c0b1d2a886a9f994c4b8ed8d354a3c6bd8d8373cd012646443ebfca&mpshare=1&scene=1&srcid=1110kSXANwBrbL2TWtA0NAK6&key=86d1b0bfcae3874289b26357e30923b1734881e3a43437f4558c9c6be8f133e62f000fc4c315915ad48066faca9893f45a6515e6faebf3f27b85a03bf975ca15ecd8401181121b82a5d41040f7b5c565&ascene=0&uin=MjcyMjMxNTA0Mg%3D%3D&devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12+build(16A323)&version=12010210&nettype=WIFI&fontScale=100&pass_ticket=T2oTN5azeGV4Brh%2FOFJxtVGb2WVp1QN3ylyWucAGYWTJBOrOLdFJzJoRIwToLTv8\n\n### Spring Cloud\nhttp://www.jianshu.com/p/cf3a2884a8d2?open_source=weibo_search\nhttps://www.atomikos.com/Blog/TransactionManagementAPIForRESTTCC\n\n\nhttps://github.com/beston123/Tarzan","slug":"Distributed-Transaction","published":1,"updated":"2019-09-28T08:51:00.860Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82h000lv1np438d5ipr","content":"<h3 id=\"TCC\"><a href=\"#TCC\" class=\"headerlink\" title=\"TCC\"></a>TCC</h3><h3 id=\"RocketMQ事务功能\"><a href=\"#RocketMQ事务功能\" class=\"headerlink\" title=\"RocketMQ事务功能\"></a>RocketMQ事务功能</h3><p><img src=\"/2017/11/03/Distributed-Transaction/transaction_rocketmq.gif\" alt=\"你想输入的替代文字\"></p>\n<h3 id=\"抽象出一个完整的系统\"><a href=\"#抽象出一个完整的系统\" class=\"headerlink\" title=\"抽象出一个完整的系统\"></a>抽象出一个完整的系统</h3><p>不是所有的MQ系统都是支持这个HalfMsg的操作的，所以我们把这个系统抽成一个事务SOA服务</p>\n<p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU4MTEyODIzMg==&amp;mid=2247483713&amp;idx=1&amp;sn=c9efdd6eda9d7bd32f82e42b2ca3fbe3&amp;chksm=fd4d1806ca3a9110474f9c0b1d2a886a9f994c4b8ed8d354a3c6bd8d8373cd012646443ebfca&amp;mpshare=1&amp;scene=1&amp;srcid=1110kSXANwBrbL2TWtA0NAK6&amp;key=86d1b0bfcae3874289b26357e30923b1734881e3a43437f4558c9c6be8f133e62f000fc4c315915ad48066faca9893f45a6515e6faebf3f27b85a03bf975ca15ecd8401181121b82a5d41040f7b5c565&amp;ascene=0&amp;uin=MjcyMjMxNTA0Mg%3D%3D&amp;devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12+build(16A323)&amp;version=12010210&amp;nettype=WIFI&amp;fontScale=100&amp;pass_ticket=T2oTN5azeGV4Brh%2FOFJxtVGb2WVp1QN3ylyWucAGYWTJBOrOLdFJzJoRIwToLTv8\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s?__biz=MzU4MTEyODIzMg==&amp;mid=2247483713&amp;idx=1&amp;sn=c9efdd6eda9d7bd32f82e42b2ca3fbe3&amp;chksm=fd4d1806ca3a9110474f9c0b1d2a886a9f994c4b8ed8d354a3c6bd8d8373cd012646443ebfca&amp;mpshare=1&amp;scene=1&amp;srcid=1110kSXANwBrbL2TWtA0NAK6&amp;key=86d1b0bfcae3874289b26357e30923b1734881e3a43437f4558c9c6be8f133e62f000fc4c315915ad48066faca9893f45a6515e6faebf3f27b85a03bf975ca15ecd8401181121b82a5d41040f7b5c565&amp;ascene=0&amp;uin=MjcyMjMxNTA0Mg%3D%3D&amp;devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12+build(16A323)&amp;version=12010210&amp;nettype=WIFI&amp;fontScale=100&amp;pass_ticket=T2oTN5azeGV4Brh%2FOFJxtVGb2WVp1QN3ylyWucAGYWTJBOrOLdFJzJoRIwToLTv8</a></p>\n<h3 id=\"Spring-Cloud\"><a href=\"#Spring-Cloud\" class=\"headerlink\" title=\"Spring Cloud\"></a>Spring Cloud</h3><p><a href=\"http://www.jianshu.com/p/cf3a2884a8d2?open_source=weibo_search\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/cf3a2884a8d2?open_source=weibo_search</a><br><a href=\"https://www.atomikos.com/Blog/TransactionManagementAPIForRESTTCC\" target=\"_blank\" rel=\"noopener\">https://www.atomikos.com/Blog/TransactionManagementAPIForRESTTCC</a></p>\n<p><a href=\"https://github.com/beston123/Tarzan\" target=\"_blank\" rel=\"noopener\">https://github.com/beston123/Tarzan</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"TCC\"><a href=\"#TCC\" class=\"headerlink\" title=\"TCC\"></a>TCC</h3><h3 id=\"RocketMQ事务功能\"><a href=\"#RocketMQ事务功能\" class=\"headerlink\" title=\"RocketMQ事务功能\"></a>RocketMQ事务功能</h3><p><img src=\"/2017/11/03/Distributed-Transaction/transaction_rocketmq.gif\" alt=\"你想输入的替代文字\"></p>\n<h3 id=\"抽象出一个完整的系统\"><a href=\"#抽象出一个完整的系统\" class=\"headerlink\" title=\"抽象出一个完整的系统\"></a>抽象出一个完整的系统</h3><p>不是所有的MQ系统都是支持这个HalfMsg的操作的，所以我们把这个系统抽成一个事务SOA服务</p>\n<p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU4MTEyODIzMg==&amp;mid=2247483713&amp;idx=1&amp;sn=c9efdd6eda9d7bd32f82e42b2ca3fbe3&amp;chksm=fd4d1806ca3a9110474f9c0b1d2a886a9f994c4b8ed8d354a3c6bd8d8373cd012646443ebfca&amp;mpshare=1&amp;scene=1&amp;srcid=1110kSXANwBrbL2TWtA0NAK6&amp;key=86d1b0bfcae3874289b26357e30923b1734881e3a43437f4558c9c6be8f133e62f000fc4c315915ad48066faca9893f45a6515e6faebf3f27b85a03bf975ca15ecd8401181121b82a5d41040f7b5c565&amp;ascene=0&amp;uin=MjcyMjMxNTA0Mg%3D%3D&amp;devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12+build(16A323)&amp;version=12010210&amp;nettype=WIFI&amp;fontScale=100&amp;pass_ticket=T2oTN5azeGV4Brh%2FOFJxtVGb2WVp1QN3ylyWucAGYWTJBOrOLdFJzJoRIwToLTv8\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s?__biz=MzU4MTEyODIzMg==&amp;mid=2247483713&amp;idx=1&amp;sn=c9efdd6eda9d7bd32f82e42b2ca3fbe3&amp;chksm=fd4d1806ca3a9110474f9c0b1d2a886a9f994c4b8ed8d354a3c6bd8d8373cd012646443ebfca&amp;mpshare=1&amp;scene=1&amp;srcid=1110kSXANwBrbL2TWtA0NAK6&amp;key=86d1b0bfcae3874289b26357e30923b1734881e3a43437f4558c9c6be8f133e62f000fc4c315915ad48066faca9893f45a6515e6faebf3f27b85a03bf975ca15ecd8401181121b82a5d41040f7b5c565&amp;ascene=0&amp;uin=MjcyMjMxNTA0Mg%3D%3D&amp;devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12+build(16A323)&amp;version=12010210&amp;nettype=WIFI&amp;fontScale=100&amp;pass_ticket=T2oTN5azeGV4Brh%2FOFJxtVGb2WVp1QN3ylyWucAGYWTJBOrOLdFJzJoRIwToLTv8</a></p>\n<h3 id=\"Spring-Cloud\"><a href=\"#Spring-Cloud\" class=\"headerlink\" title=\"Spring Cloud\"></a>Spring Cloud</h3><p><a href=\"http://www.jianshu.com/p/cf3a2884a8d2?open_source=weibo_search\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/cf3a2884a8d2?open_source=weibo_search</a><br><a href=\"https://www.atomikos.com/Blog/TransactionManagementAPIForRESTTCC\" target=\"_blank\" rel=\"noopener\">https://www.atomikos.com/Blog/TransactionManagementAPIForRESTTCC</a></p>\n<p><a href=\"https://github.com/beston123/Tarzan\" target=\"_blank\" rel=\"noopener\">https://github.com/beston123/Tarzan</a></p>\n"},{"title":"Failfast-Failover-Failsafe-Failback","date":"2018-09-02T13:41:38.000Z","_content":"\n\nhttps://blog.csdn.net/luojinbai/article/details/53428370?utm_source=itdadao&utm_medium=referral\n\n\n\n### Fail-Fast\n\n维基百科地址：http://en.wikipedia.org/wiki/Fail-fast\n\n> Fail-fast is a property of a system or module with respect to its response to failures. A fail-fast system is designed to immediately report at its interface anyfailure or condition that is likely to lead to failure. Fail-fast systems are usually designed to stop normal operation rather than attempt to continue a possibly flawed process. Such designs often check the system’s state at several points in an operation, so any failures can be detected early. A fail-fast module passes the responsibility for handling errors, but not detecting them, to the next-higher system design level.\n\n从字面含义看就是“快速失败”，尽可能的发现系统中的错误，使系统能够按照事先设定好的错误的流程执行，对应的方式是“fault-tolerant（错误容忍）”。以JAVA集合（Collection）的快速失败为例，当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常（发现错误执行设定好的错误的流程），产生fail-fast事件。\n\n### Fail-Over\n\n维基百科地址：http://en.wikipedia.org/wiki/Failover\n\n> In computing, failover is switching to a redundant or standby computer server, system, hardware component or network upon the failure or abnormal termination of the previously active application,[1] server, system, hardware component, or network. Failover and switchover are essentially the same operation, except that failover is automatic and usually operates without warning, while switchover requires human intervention.\n\nFail-Over的含义为“失效转移”，是一种备份操作模式，当主要组件异常时，其功能转移到备份组件。其要点在于有主有备，且主故障时备可启用，并设置为主。如Mysql的双Master模式，当正在使用的Master出现故障时，可以拿备Master做主使用。\n\n### Faile-Safe\n\n维基百科地址：http://en.wikipedia.org/wiki/Fail-safe\n\n> A fail-safe or fail-secure device is one that, in the event of failure, responds in a way that will cause no harm, or at least a minimum of harm, to other devices or danger to personnel.\n\nFail-Safe的含义为“失效安全”，即使在故障的情况下也不会造成伤害或者尽量减少伤害。维基百科上一个形象的例子是红绿灯的“冲突监测模块”当监测到错误或者冲突的信号时会将十字路口的红绿灯变为闪烁错误模式，而不是全部显示为绿灯。\n\n另外就是我们误用的“自动功能降级”翻译做“Auto-Degrade”会更好一些。\n\n### Fail-Back\n\nFail-over之后的自动恢复，在簇网络系统（有两台或多台服务器互联的网络）中，由于要某台服务器进行维修，需要网络资源和服务暂时重定向到备用系统。在此之后将网络资源和服务器恢复为由原始主机提供的过程，称为自动恢复。","source":"_posts/Failfast-Failover-Failsafe-Failback.md","raw":"---\ntitle: Failfast-Failover-Failsafe-Failback\ndate: 2018-09-02 21:41:38\ntags:\n---\n\n\nhttps://blog.csdn.net/luojinbai/article/details/53428370?utm_source=itdadao&utm_medium=referral\n\n\n\n### Fail-Fast\n\n维基百科地址：http://en.wikipedia.org/wiki/Fail-fast\n\n> Fail-fast is a property of a system or module with respect to its response to failures. A fail-fast system is designed to immediately report at its interface anyfailure or condition that is likely to lead to failure. Fail-fast systems are usually designed to stop normal operation rather than attempt to continue a possibly flawed process. Such designs often check the system’s state at several points in an operation, so any failures can be detected early. A fail-fast module passes the responsibility for handling errors, but not detecting them, to the next-higher system design level.\n\n从字面含义看就是“快速失败”，尽可能的发现系统中的错误，使系统能够按照事先设定好的错误的流程执行，对应的方式是“fault-tolerant（错误容忍）”。以JAVA集合（Collection）的快速失败为例，当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常（发现错误执行设定好的错误的流程），产生fail-fast事件。\n\n### Fail-Over\n\n维基百科地址：http://en.wikipedia.org/wiki/Failover\n\n> In computing, failover is switching to a redundant or standby computer server, system, hardware component or network upon the failure or abnormal termination of the previously active application,[1] server, system, hardware component, or network. Failover and switchover are essentially the same operation, except that failover is automatic and usually operates without warning, while switchover requires human intervention.\n\nFail-Over的含义为“失效转移”，是一种备份操作模式，当主要组件异常时，其功能转移到备份组件。其要点在于有主有备，且主故障时备可启用，并设置为主。如Mysql的双Master模式，当正在使用的Master出现故障时，可以拿备Master做主使用。\n\n### Faile-Safe\n\n维基百科地址：http://en.wikipedia.org/wiki/Fail-safe\n\n> A fail-safe or fail-secure device is one that, in the event of failure, responds in a way that will cause no harm, or at least a minimum of harm, to other devices or danger to personnel.\n\nFail-Safe的含义为“失效安全”，即使在故障的情况下也不会造成伤害或者尽量减少伤害。维基百科上一个形象的例子是红绿灯的“冲突监测模块”当监测到错误或者冲突的信号时会将十字路口的红绿灯变为闪烁错误模式，而不是全部显示为绿灯。\n\n另外就是我们误用的“自动功能降级”翻译做“Auto-Degrade”会更好一些。\n\n### Fail-Back\n\nFail-over之后的自动恢复，在簇网络系统（有两台或多台服务器互联的网络）中，由于要某台服务器进行维修，需要网络资源和服务暂时重定向到备用系统。在此之后将网络资源和服务器恢复为由原始主机提供的过程，称为自动恢复。","slug":"Failfast-Failover-Failsafe-Failback","published":1,"updated":"2019-09-28T08:51:00.863Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82i000mv1np3skxgs4s","content":"<p><a href=\"https://blog.csdn.net/luojinbai/article/details/53428370?utm_source=itdadao&amp;utm_medium=referral\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/luojinbai/article/details/53428370?utm_source=itdadao&amp;utm_medium=referral</a></p>\n<h3 id=\"Fail-Fast\"><a href=\"#Fail-Fast\" class=\"headerlink\" title=\"Fail-Fast\"></a>Fail-Fast</h3><p>维基百科地址：<a href=\"http://en.wikipedia.org/wiki/Fail-fast\" target=\"_blank\" rel=\"noopener\">http://en.wikipedia.org/wiki/Fail-fast</a></p>\n<blockquote>\n<p>Fail-fast is a property of a system or module with respect to its response to failures. A fail-fast system is designed to immediately report at its interface anyfailure or condition that is likely to lead to failure. Fail-fast systems are usually designed to stop normal operation rather than attempt to continue a possibly flawed process. Such designs often check the system’s state at several points in an operation, so any failures can be detected early. A fail-fast module passes the responsibility for handling errors, but not detecting them, to the next-higher system design level.</p>\n</blockquote>\n<p>从字面含义看就是“快速失败”，尽可能的发现系统中的错误，使系统能够按照事先设定好的错误的流程执行，对应的方式是“fault-tolerant（错误容忍）”。以JAVA集合（Collection）的快速失败为例，当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常（发现错误执行设定好的错误的流程），产生fail-fast事件。</p>\n<h3 id=\"Fail-Over\"><a href=\"#Fail-Over\" class=\"headerlink\" title=\"Fail-Over\"></a>Fail-Over</h3><p>维基百科地址：<a href=\"http://en.wikipedia.org/wiki/Failover\" target=\"_blank\" rel=\"noopener\">http://en.wikipedia.org/wiki/Failover</a></p>\n<blockquote>\n<p>In computing, failover is switching to a redundant or standby computer server, system, hardware component or network upon the failure or abnormal termination of the previously active application,[1] server, system, hardware component, or network. Failover and switchover are essentially the same operation, except that failover is automatic and usually operates without warning, while switchover requires human intervention.</p>\n</blockquote>\n<p>Fail-Over的含义为“失效转移”，是一种备份操作模式，当主要组件异常时，其功能转移到备份组件。其要点在于有主有备，且主故障时备可启用，并设置为主。如Mysql的双Master模式，当正在使用的Master出现故障时，可以拿备Master做主使用。</p>\n<h3 id=\"Faile-Safe\"><a href=\"#Faile-Safe\" class=\"headerlink\" title=\"Faile-Safe\"></a>Faile-Safe</h3><p>维基百科地址：<a href=\"http://en.wikipedia.org/wiki/Fail-safe\" target=\"_blank\" rel=\"noopener\">http://en.wikipedia.org/wiki/Fail-safe</a></p>\n<blockquote>\n<p>A fail-safe or fail-secure device is one that, in the event of failure, responds in a way that will cause no harm, or at least a minimum of harm, to other devices or danger to personnel.</p>\n</blockquote>\n<p>Fail-Safe的含义为“失效安全”，即使在故障的情况下也不会造成伤害或者尽量减少伤害。维基百科上一个形象的例子是红绿灯的“冲突监测模块”当监测到错误或者冲突的信号时会将十字路口的红绿灯变为闪烁错误模式，而不是全部显示为绿灯。</p>\n<p>另外就是我们误用的“自动功能降级”翻译做“Auto-Degrade”会更好一些。</p>\n<h3 id=\"Fail-Back\"><a href=\"#Fail-Back\" class=\"headerlink\" title=\"Fail-Back\"></a>Fail-Back</h3><p>Fail-over之后的自动恢复，在簇网络系统（有两台或多台服务器互联的网络）中，由于要某台服务器进行维修，需要网络资源和服务暂时重定向到备用系统。在此之后将网络资源和服务器恢复为由原始主机提供的过程，称为自动恢复。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/luojinbai/article/details/53428370?utm_source=itdadao&amp;utm_medium=referral\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/luojinbai/article/details/53428370?utm_source=itdadao&amp;utm_medium=referral</a></p>\n<h3 id=\"Fail-Fast\"><a href=\"#Fail-Fast\" class=\"headerlink\" title=\"Fail-Fast\"></a>Fail-Fast</h3><p>维基百科地址：<a href=\"http://en.wikipedia.org/wiki/Fail-fast\" target=\"_blank\" rel=\"noopener\">http://en.wikipedia.org/wiki/Fail-fast</a></p>\n<blockquote>\n<p>Fail-fast is a property of a system or module with respect to its response to failures. A fail-fast system is designed to immediately report at its interface anyfailure or condition that is likely to lead to failure. Fail-fast systems are usually designed to stop normal operation rather than attempt to continue a possibly flawed process. Such designs often check the system’s state at several points in an operation, so any failures can be detected early. A fail-fast module passes the responsibility for handling errors, but not detecting them, to the next-higher system design level.</p>\n</blockquote>\n<p>从字面含义看就是“快速失败”，尽可能的发现系统中的错误，使系统能够按照事先设定好的错误的流程执行，对应的方式是“fault-tolerant（错误容忍）”。以JAVA集合（Collection）的快速失败为例，当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常（发现错误执行设定好的错误的流程），产生fail-fast事件。</p>\n<h3 id=\"Fail-Over\"><a href=\"#Fail-Over\" class=\"headerlink\" title=\"Fail-Over\"></a>Fail-Over</h3><p>维基百科地址：<a href=\"http://en.wikipedia.org/wiki/Failover\" target=\"_blank\" rel=\"noopener\">http://en.wikipedia.org/wiki/Failover</a></p>\n<blockquote>\n<p>In computing, failover is switching to a redundant or standby computer server, system, hardware component or network upon the failure or abnormal termination of the previously active application,[1] server, system, hardware component, or network. Failover and switchover are essentially the same operation, except that failover is automatic and usually operates without warning, while switchover requires human intervention.</p>\n</blockquote>\n<p>Fail-Over的含义为“失效转移”，是一种备份操作模式，当主要组件异常时，其功能转移到备份组件。其要点在于有主有备，且主故障时备可启用，并设置为主。如Mysql的双Master模式，当正在使用的Master出现故障时，可以拿备Master做主使用。</p>\n<h3 id=\"Faile-Safe\"><a href=\"#Faile-Safe\" class=\"headerlink\" title=\"Faile-Safe\"></a>Faile-Safe</h3><p>维基百科地址：<a href=\"http://en.wikipedia.org/wiki/Fail-safe\" target=\"_blank\" rel=\"noopener\">http://en.wikipedia.org/wiki/Fail-safe</a></p>\n<blockquote>\n<p>A fail-safe or fail-secure device is one that, in the event of failure, responds in a way that will cause no harm, or at least a minimum of harm, to other devices or danger to personnel.</p>\n</blockquote>\n<p>Fail-Safe的含义为“失效安全”，即使在故障的情况下也不会造成伤害或者尽量减少伤害。维基百科上一个形象的例子是红绿灯的“冲突监测模块”当监测到错误或者冲突的信号时会将十字路口的红绿灯变为闪烁错误模式，而不是全部显示为绿灯。</p>\n<p>另外就是我们误用的“自动功能降级”翻译做“Auto-Degrade”会更好一些。</p>\n<h3 id=\"Fail-Back\"><a href=\"#Fail-Back\" class=\"headerlink\" title=\"Fail-Back\"></a>Fail-Back</h3><p>Fail-over之后的自动恢复，在簇网络系统（有两台或多台服务器互联的网络）中，由于要某台服务器进行维修，需要网络资源和服务暂时重定向到备用系统。在此之后将网络资源和服务器恢复为由原始主机提供的过程，称为自动恢复。</p>\n"},{"title":"Flink-FAQ","date":"2018-12-27T23:29:22.000Z","_content":"\n### 超高质量文章\nhttps://mlog.club/articles/tag/2178\n\n### 很多好问题\nhttps://mlog.club/article/40687\nhttps://www.aboutyun.com/thread-27738-1-1.html\n\n### \nhttps://blog.csdn.net/fct2001140269/article/details/87357949\n\n### 现在要处理一批数据，KeyBy(entityId)后，发现某几个entityId数据量特别大，可能是其它的好几倍，怎么处理？\n\n### 当Flink的Checkpoint非常大时，怎么样进行低延时保存？\nhttps://www.ververica.com/blog/managing-large-state-apache-flink-incremental-checkpointing-overview\n\n### 这个例子就没有并发问题么？\nhttps://training.ververica.com/exercises/rideEnrichment-flatmap.html\n\n\n### Flink与Kafka融合时，Kafka的游标时怎么管理的？\n\n\n### Sliding Window的数据复制\nSliding Windows Make Copies\nSliding window assigners can create lots of window objects, and will copy each event into every relevant window. For example, if you have sliding windows every 15 minutes that are 24-hours in length, each event will be copied into 4 * 24 = 96 windows.\n\n### \nmsg1,t1\nmsg2,t2\nmsg3,t3\nmsg4,t4\n...\n以这个顺序进入Flink\nmsg1,t1\nmsg2,t2\nmsg4,t4\nmsg5,t5\nmsg6,t6\nmsg7,t7\n...\n10条\n...\nmsg3,t3\n### 有一个作业是去统计一个超级大的文件的单词出现的次数，这个文件需要被处理整整一个月，如果中间Streaming作业停掉了，那后续应该怎么恢复才能达到exactly once？因为这个作业的源没有像Kafka那样有下标。\n\n### Flink的slot指的是什么？和线程是什么关系？\n按照我现在的理解，10个Slot并不是说有10个线程在执行，而是10个并行线。\n\nsource -> map -> aggregation -> sink\n\n### KeyBy修改了并行度后，并行线会发生变化么？\n\n###\n\n### Flink是怎么实现Exactly once？和Kafka有什么区别？\nhttps://mp.weixin.qq.com/s/4EtkNns-KAzEqL3GRMRLAg\nStreamingFileSink\n\n### 一个flink的并行任务，对于每一个taskSlot，它保存的是自己Keyed到的State，如果修改了并行度，State怎么变化？\n\n### 如果Kafka的Topic有10个Partition，那Source的时候，设置多少的并行度比较合适？\n\n### 如果已知Kafka的Topic已经按照Entity做了Partition，这个时候Flink的Source是和这个Topic并行的么？","source":"_posts/Flink-FAQ.md","raw":"---\ntitle: Flink-FAQ\ndate: 2018-12-28 07:29:22\ntags:\n---\n\n### 超高质量文章\nhttps://mlog.club/articles/tag/2178\n\n### 很多好问题\nhttps://mlog.club/article/40687\nhttps://www.aboutyun.com/thread-27738-1-1.html\n\n### \nhttps://blog.csdn.net/fct2001140269/article/details/87357949\n\n### 现在要处理一批数据，KeyBy(entityId)后，发现某几个entityId数据量特别大，可能是其它的好几倍，怎么处理？\n\n### 当Flink的Checkpoint非常大时，怎么样进行低延时保存？\nhttps://www.ververica.com/blog/managing-large-state-apache-flink-incremental-checkpointing-overview\n\n### 这个例子就没有并发问题么？\nhttps://training.ververica.com/exercises/rideEnrichment-flatmap.html\n\n\n### Flink与Kafka融合时，Kafka的游标时怎么管理的？\n\n\n### Sliding Window的数据复制\nSliding Windows Make Copies\nSliding window assigners can create lots of window objects, and will copy each event into every relevant window. For example, if you have sliding windows every 15 minutes that are 24-hours in length, each event will be copied into 4 * 24 = 96 windows.\n\n### \nmsg1,t1\nmsg2,t2\nmsg3,t3\nmsg4,t4\n...\n以这个顺序进入Flink\nmsg1,t1\nmsg2,t2\nmsg4,t4\nmsg5,t5\nmsg6,t6\nmsg7,t7\n...\n10条\n...\nmsg3,t3\n### 有一个作业是去统计一个超级大的文件的单词出现的次数，这个文件需要被处理整整一个月，如果中间Streaming作业停掉了，那后续应该怎么恢复才能达到exactly once？因为这个作业的源没有像Kafka那样有下标。\n\n### Flink的slot指的是什么？和线程是什么关系？\n按照我现在的理解，10个Slot并不是说有10个线程在执行，而是10个并行线。\n\nsource -> map -> aggregation -> sink\n\n### KeyBy修改了并行度后，并行线会发生变化么？\n\n###\n\n### Flink是怎么实现Exactly once？和Kafka有什么区别？\nhttps://mp.weixin.qq.com/s/4EtkNns-KAzEqL3GRMRLAg\nStreamingFileSink\n\n### 一个flink的并行任务，对于每一个taskSlot，它保存的是自己Keyed到的State，如果修改了并行度，State怎么变化？\n\n### 如果Kafka的Topic有10个Partition，那Source的时候，设置多少的并行度比较合适？\n\n### 如果已知Kafka的Topic已经按照Entity做了Partition，这个时候Flink的Source是和这个Topic并行的么？","slug":"Flink-FAQ","published":1,"updated":"2019-11-14T05:37:16.962Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82i000nv1np579wnr1o","content":"<h3 id=\"超高质量文章\"><a href=\"#超高质量文章\" class=\"headerlink\" title=\"超高质量文章\"></a>超高质量文章</h3><p><a href=\"https://mlog.club/articles/tag/2178\" target=\"_blank\" rel=\"noopener\">https://mlog.club/articles/tag/2178</a></p>\n<h3 id=\"很多好问题\"><a href=\"#很多好问题\" class=\"headerlink\" title=\"很多好问题\"></a>很多好问题</h3><p><a href=\"https://mlog.club/article/40687\" target=\"_blank\" rel=\"noopener\">https://mlog.club/article/40687</a><br><a href=\"https://www.aboutyun.com/thread-27738-1-1.html\" target=\"_blank\" rel=\"noopener\">https://www.aboutyun.com/thread-27738-1-1.html</a></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><a href=\"https://blog.csdn.net/fct2001140269/article/details/87357949\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/fct2001140269/article/details/87357949</a></p>\n<h3 id=\"现在要处理一批数据，KeyBy-entityId-后，发现某几个entityId数据量特别大，可能是其它的好几倍，怎么处理？\"><a href=\"#现在要处理一批数据，KeyBy-entityId-后，发现某几个entityId数据量特别大，可能是其它的好几倍，怎么处理？\" class=\"headerlink\" title=\"现在要处理一批数据，KeyBy(entityId)后，发现某几个entityId数据量特别大，可能是其它的好几倍，怎么处理？\"></a>现在要处理一批数据，KeyBy(entityId)后，发现某几个entityId数据量特别大，可能是其它的好几倍，怎么处理？</h3><h3 id=\"当Flink的Checkpoint非常大时，怎么样进行低延时保存？\"><a href=\"#当Flink的Checkpoint非常大时，怎么样进行低延时保存？\" class=\"headerlink\" title=\"当Flink的Checkpoint非常大时，怎么样进行低延时保存？\"></a>当Flink的Checkpoint非常大时，怎么样进行低延时保存？</h3><p><a href=\"https://www.ververica.com/blog/managing-large-state-apache-flink-incremental-checkpointing-overview\" target=\"_blank\" rel=\"noopener\">https://www.ververica.com/blog/managing-large-state-apache-flink-incremental-checkpointing-overview</a></p>\n<h3 id=\"这个例子就没有并发问题么？\"><a href=\"#这个例子就没有并发问题么？\" class=\"headerlink\" title=\"这个例子就没有并发问题么？\"></a>这个例子就没有并发问题么？</h3><p><a href=\"https://training.ververica.com/exercises/rideEnrichment-flatmap.html\" target=\"_blank\" rel=\"noopener\">https://training.ververica.com/exercises/rideEnrichment-flatmap.html</a></p>\n<h3 id=\"Flink与Kafka融合时，Kafka的游标时怎么管理的？\"><a href=\"#Flink与Kafka融合时，Kafka的游标时怎么管理的？\" class=\"headerlink\" title=\"Flink与Kafka融合时，Kafka的游标时怎么管理的？\"></a>Flink与Kafka融合时，Kafka的游标时怎么管理的？</h3><h3 id=\"Sliding-Window的数据复制\"><a href=\"#Sliding-Window的数据复制\" class=\"headerlink\" title=\"Sliding Window的数据复制\"></a>Sliding Window的数据复制</h3><p>Sliding Windows Make Copies<br>Sliding window assigners can create lots of window objects, and will copy each event into every relevant window. For example, if you have sliding windows every 15 minutes that are 24-hours in length, each event will be copied into 4 * 24 = 96 windows.</p>\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p>msg1,t1<br>msg2,t2<br>msg3,t3<br>msg4,t4<br>…<br>以这个顺序进入Flink<br>msg1,t1<br>msg2,t2<br>msg4,t4<br>msg5,t5<br>msg6,t6<br>msg7,t7<br>…<br>10条<br>…<br>msg3,t3</p>\n<h3 id=\"有一个作业是去统计一个超级大的文件的单词出现的次数，这个文件需要被处理整整一个月，如果中间Streaming作业停掉了，那后续应该怎么恢复才能达到exactly-once？因为这个作业的源没有像Kafka那样有下标。\"><a href=\"#有一个作业是去统计一个超级大的文件的单词出现的次数，这个文件需要被处理整整一个月，如果中间Streaming作业停掉了，那后续应该怎么恢复才能达到exactly-once？因为这个作业的源没有像Kafka那样有下标。\" class=\"headerlink\" title=\"有一个作业是去统计一个超级大的文件的单词出现的次数，这个文件需要被处理整整一个月，如果中间Streaming作业停掉了，那后续应该怎么恢复才能达到exactly once？因为这个作业的源没有像Kafka那样有下标。\"></a>有一个作业是去统计一个超级大的文件的单词出现的次数，这个文件需要被处理整整一个月，如果中间Streaming作业停掉了，那后续应该怎么恢复才能达到exactly once？因为这个作业的源没有像Kafka那样有下标。</h3><h3 id=\"Flink的slot指的是什么？和线程是什么关系？\"><a href=\"#Flink的slot指的是什么？和线程是什么关系？\" class=\"headerlink\" title=\"Flink的slot指的是什么？和线程是什么关系？\"></a>Flink的slot指的是什么？和线程是什么关系？</h3><p>按照我现在的理解，10个Slot并不是说有10个线程在执行，而是10个并行线。</p>\n<p>source -&gt; map -&gt; aggregation -&gt; sink</p>\n<h3 id=\"KeyBy修改了并行度后，并行线会发生变化么？\"><a href=\"#KeyBy修改了并行度后，并行线会发生变化么？\" class=\"headerlink\" title=\"KeyBy修改了并行度后，并行线会发生变化么？\"></a>KeyBy修改了并行度后，并行线会发生变化么？</h3><p>###</p>\n<h3 id=\"Flink是怎么实现Exactly-once？和Kafka有什么区别？\"><a href=\"#Flink是怎么实现Exactly-once？和Kafka有什么区别？\" class=\"headerlink\" title=\"Flink是怎么实现Exactly once？和Kafka有什么区别？\"></a>Flink是怎么实现Exactly once？和Kafka有什么区别？</h3><p><a href=\"https://mp.weixin.qq.com/s/4EtkNns-KAzEqL3GRMRLAg\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/4EtkNns-KAzEqL3GRMRLAg</a><br>StreamingFileSink</p>\n<h3 id=\"一个flink的并行任务，对于每一个taskSlot，它保存的是自己Keyed到的State，如果修改了并行度，State怎么变化？\"><a href=\"#一个flink的并行任务，对于每一个taskSlot，它保存的是自己Keyed到的State，如果修改了并行度，State怎么变化？\" class=\"headerlink\" title=\"一个flink的并行任务，对于每一个taskSlot，它保存的是自己Keyed到的State，如果修改了并行度，State怎么变化？\"></a>一个flink的并行任务，对于每一个taskSlot，它保存的是自己Keyed到的State，如果修改了并行度，State怎么变化？</h3><h3 id=\"如果Kafka的Topic有10个Partition，那Source的时候，设置多少的并行度比较合适？\"><a href=\"#如果Kafka的Topic有10个Partition，那Source的时候，设置多少的并行度比较合适？\" class=\"headerlink\" title=\"如果Kafka的Topic有10个Partition，那Source的时候，设置多少的并行度比较合适？\"></a>如果Kafka的Topic有10个Partition，那Source的时候，设置多少的并行度比较合适？</h3><h3 id=\"如果已知Kafka的Topic已经按照Entity做了Partition，这个时候Flink的Source是和这个Topic并行的么？\"><a href=\"#如果已知Kafka的Topic已经按照Entity做了Partition，这个时候Flink的Source是和这个Topic并行的么？\" class=\"headerlink\" title=\"如果已知Kafka的Topic已经按照Entity做了Partition，这个时候Flink的Source是和这个Topic并行的么？\"></a>如果已知Kafka的Topic已经按照Entity做了Partition，这个时候Flink的Source是和这个Topic并行的么？</h3>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"超高质量文章\"><a href=\"#超高质量文章\" class=\"headerlink\" title=\"超高质量文章\"></a>超高质量文章</h3><p><a href=\"https://mlog.club/articles/tag/2178\" target=\"_blank\" rel=\"noopener\">https://mlog.club/articles/tag/2178</a></p>\n<h3 id=\"很多好问题\"><a href=\"#很多好问题\" class=\"headerlink\" title=\"很多好问题\"></a>很多好问题</h3><p><a href=\"https://mlog.club/article/40687\" target=\"_blank\" rel=\"noopener\">https://mlog.club/article/40687</a><br><a href=\"https://www.aboutyun.com/thread-27738-1-1.html\" target=\"_blank\" rel=\"noopener\">https://www.aboutyun.com/thread-27738-1-1.html</a></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><a href=\"https://blog.csdn.net/fct2001140269/article/details/87357949\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/fct2001140269/article/details/87357949</a></p>\n<h3 id=\"现在要处理一批数据，KeyBy-entityId-后，发现某几个entityId数据量特别大，可能是其它的好几倍，怎么处理？\"><a href=\"#现在要处理一批数据，KeyBy-entityId-后，发现某几个entityId数据量特别大，可能是其它的好几倍，怎么处理？\" class=\"headerlink\" title=\"现在要处理一批数据，KeyBy(entityId)后，发现某几个entityId数据量特别大，可能是其它的好几倍，怎么处理？\"></a>现在要处理一批数据，KeyBy(entityId)后，发现某几个entityId数据量特别大，可能是其它的好几倍，怎么处理？</h3><h3 id=\"当Flink的Checkpoint非常大时，怎么样进行低延时保存？\"><a href=\"#当Flink的Checkpoint非常大时，怎么样进行低延时保存？\" class=\"headerlink\" title=\"当Flink的Checkpoint非常大时，怎么样进行低延时保存？\"></a>当Flink的Checkpoint非常大时，怎么样进行低延时保存？</h3><p><a href=\"https://www.ververica.com/blog/managing-large-state-apache-flink-incremental-checkpointing-overview\" target=\"_blank\" rel=\"noopener\">https://www.ververica.com/blog/managing-large-state-apache-flink-incremental-checkpointing-overview</a></p>\n<h3 id=\"这个例子就没有并发问题么？\"><a href=\"#这个例子就没有并发问题么？\" class=\"headerlink\" title=\"这个例子就没有并发问题么？\"></a>这个例子就没有并发问题么？</h3><p><a href=\"https://training.ververica.com/exercises/rideEnrichment-flatmap.html\" target=\"_blank\" rel=\"noopener\">https://training.ververica.com/exercises/rideEnrichment-flatmap.html</a></p>\n<h3 id=\"Flink与Kafka融合时，Kafka的游标时怎么管理的？\"><a href=\"#Flink与Kafka融合时，Kafka的游标时怎么管理的？\" class=\"headerlink\" title=\"Flink与Kafka融合时，Kafka的游标时怎么管理的？\"></a>Flink与Kafka融合时，Kafka的游标时怎么管理的？</h3><h3 id=\"Sliding-Window的数据复制\"><a href=\"#Sliding-Window的数据复制\" class=\"headerlink\" title=\"Sliding Window的数据复制\"></a>Sliding Window的数据复制</h3><p>Sliding Windows Make Copies<br>Sliding window assigners can create lots of window objects, and will copy each event into every relevant window. For example, if you have sliding windows every 15 minutes that are 24-hours in length, each event will be copied into 4 * 24 = 96 windows.</p>\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p>msg1,t1<br>msg2,t2<br>msg3,t3<br>msg4,t4<br>…<br>以这个顺序进入Flink<br>msg1,t1<br>msg2,t2<br>msg4,t4<br>msg5,t5<br>msg6,t6<br>msg7,t7<br>…<br>10条<br>…<br>msg3,t3</p>\n<h3 id=\"有一个作业是去统计一个超级大的文件的单词出现的次数，这个文件需要被处理整整一个月，如果中间Streaming作业停掉了，那后续应该怎么恢复才能达到exactly-once？因为这个作业的源没有像Kafka那样有下标。\"><a href=\"#有一个作业是去统计一个超级大的文件的单词出现的次数，这个文件需要被处理整整一个月，如果中间Streaming作业停掉了，那后续应该怎么恢复才能达到exactly-once？因为这个作业的源没有像Kafka那样有下标。\" class=\"headerlink\" title=\"有一个作业是去统计一个超级大的文件的单词出现的次数，这个文件需要被处理整整一个月，如果中间Streaming作业停掉了，那后续应该怎么恢复才能达到exactly once？因为这个作业的源没有像Kafka那样有下标。\"></a>有一个作业是去统计一个超级大的文件的单词出现的次数，这个文件需要被处理整整一个月，如果中间Streaming作业停掉了，那后续应该怎么恢复才能达到exactly once？因为这个作业的源没有像Kafka那样有下标。</h3><h3 id=\"Flink的slot指的是什么？和线程是什么关系？\"><a href=\"#Flink的slot指的是什么？和线程是什么关系？\" class=\"headerlink\" title=\"Flink的slot指的是什么？和线程是什么关系？\"></a>Flink的slot指的是什么？和线程是什么关系？</h3><p>按照我现在的理解，10个Slot并不是说有10个线程在执行，而是10个并行线。</p>\n<p>source -&gt; map -&gt; aggregation -&gt; sink</p>\n<h3 id=\"KeyBy修改了并行度后，并行线会发生变化么？\"><a href=\"#KeyBy修改了并行度后，并行线会发生变化么？\" class=\"headerlink\" title=\"KeyBy修改了并行度后，并行线会发生变化么？\"></a>KeyBy修改了并行度后，并行线会发生变化么？</h3><p>###</p>\n<h3 id=\"Flink是怎么实现Exactly-once？和Kafka有什么区别？\"><a href=\"#Flink是怎么实现Exactly-once？和Kafka有什么区别？\" class=\"headerlink\" title=\"Flink是怎么实现Exactly once？和Kafka有什么区别？\"></a>Flink是怎么实现Exactly once？和Kafka有什么区别？</h3><p><a href=\"https://mp.weixin.qq.com/s/4EtkNns-KAzEqL3GRMRLAg\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/4EtkNns-KAzEqL3GRMRLAg</a><br>StreamingFileSink</p>\n<h3 id=\"一个flink的并行任务，对于每一个taskSlot，它保存的是自己Keyed到的State，如果修改了并行度，State怎么变化？\"><a href=\"#一个flink的并行任务，对于每一个taskSlot，它保存的是自己Keyed到的State，如果修改了并行度，State怎么变化？\" class=\"headerlink\" title=\"一个flink的并行任务，对于每一个taskSlot，它保存的是自己Keyed到的State，如果修改了并行度，State怎么变化？\"></a>一个flink的并行任务，对于每一个taskSlot，它保存的是自己Keyed到的State，如果修改了并行度，State怎么变化？</h3><h3 id=\"如果Kafka的Topic有10个Partition，那Source的时候，设置多少的并行度比较合适？\"><a href=\"#如果Kafka的Topic有10个Partition，那Source的时候，设置多少的并行度比较合适？\" class=\"headerlink\" title=\"如果Kafka的Topic有10个Partition，那Source的时候，设置多少的并行度比较合适？\"></a>如果Kafka的Topic有10个Partition，那Source的时候，设置多少的并行度比较合适？</h3><h3 id=\"如果已知Kafka的Topic已经按照Entity做了Partition，这个时候Flink的Source是和这个Topic并行的么？\"><a href=\"#如果已知Kafka的Topic已经按照Entity做了Partition，这个时候Flink的Source是和这个Topic并行的么？\" class=\"headerlink\" title=\"如果已知Kafka的Topic已经按照Entity做了Partition，这个时候Flink的Source是和这个Topic并行的么？\"></a>如果已知Kafka的Topic已经按照Entity做了Partition，这个时候Flink的Source是和这个Topic并行的么？</h3>"},{"title":"Flink-CheckoutPoint-Barrier","date":"2019-01-04T08:00:37.000Z","_content":"\n\nhttp://ju.outofmemory.cn/entry/370841\n\n### 这个模型和JVM的Safepoint太像了\n\n\nhttps://www.jianshu.com/p/9b10313fde10\n果然是通了\n```\nAt-Most-Once\nAt-Least-Once\nExactly-Once\nEnd-to-end Exactly-Once\n\n当不采用checkpoint时，每个event做多就只会被处理一次，这就是At-Most-Once。\n\n当不开启Barrier对齐时，上图中的Source1来的在barrier后面的一些event有可能比Source2的barrier要先到Task1.1，因为我们没有cache这些event，所以他们会正常被处理并有可能更新Task1.1的state。这样，在回复checkpoint后，Task1.1的state可能就是处理了某些checkpoint“时刻”之后数据的状态。但是对于Source1来说，他还是会offset到正常的checkpoint“时刻”的位置，那么之前处理过的barrier后面的event可能还是会被再次放入这个流中。那么这些event就不能保证“只处理一次”了，有可能处理多次，这就是At-Least-once。\n如果在Task1.1.处，先来的barrier后面的event都被cache了，那么就不会影响到这个task的state。那么Task1.1的checkpoint的state就能准确反映checkpoint“时刻”的情况。那么checkpoint回复后也不会有前面说的问题，这就是Exactly-Once。但是因为Exactly-Once引入了cache机制，这会给checkpoint动作带来额外的时延（latency）。\nEnd-to-end Exactly-Once需要结合外部系统一起完成，这里就不做讨论。\n\n作者：WoodsWalker\n链接：https://www.jianshu.com/p/9b10313fde10\n來源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n```\n\n\n解读Flink中轻量级的异步快照机制--论文\nhttps://blog.csdn.net/lmalds/article/details/54925877","source":"_posts/Flink-CheckoutPoint-Barrier.md","raw":"---\ntitle: Flink-CheckoutPoint-Barrier\ndate: 2019-01-04 16:00:37\ntags:\n---\n\n\nhttp://ju.outofmemory.cn/entry/370841\n\n### 这个模型和JVM的Safepoint太像了\n\n\nhttps://www.jianshu.com/p/9b10313fde10\n果然是通了\n```\nAt-Most-Once\nAt-Least-Once\nExactly-Once\nEnd-to-end Exactly-Once\n\n当不采用checkpoint时，每个event做多就只会被处理一次，这就是At-Most-Once。\n\n当不开启Barrier对齐时，上图中的Source1来的在barrier后面的一些event有可能比Source2的barrier要先到Task1.1，因为我们没有cache这些event，所以他们会正常被处理并有可能更新Task1.1的state。这样，在回复checkpoint后，Task1.1的state可能就是处理了某些checkpoint“时刻”之后数据的状态。但是对于Source1来说，他还是会offset到正常的checkpoint“时刻”的位置，那么之前处理过的barrier后面的event可能还是会被再次放入这个流中。那么这些event就不能保证“只处理一次”了，有可能处理多次，这就是At-Least-once。\n如果在Task1.1.处，先来的barrier后面的event都被cache了，那么就不会影响到这个task的state。那么Task1.1的checkpoint的state就能准确反映checkpoint“时刻”的情况。那么checkpoint回复后也不会有前面说的问题，这就是Exactly-Once。但是因为Exactly-Once引入了cache机制，这会给checkpoint动作带来额外的时延（latency）。\nEnd-to-end Exactly-Once需要结合外部系统一起完成，这里就不做讨论。\n\n作者：WoodsWalker\n链接：https://www.jianshu.com/p/9b10313fde10\n來源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n```\n\n\n解读Flink中轻量级的异步快照机制--论文\nhttps://blog.csdn.net/lmalds/article/details/54925877","slug":"Flink-CheckoutPoint-Barrier","published":1,"updated":"2019-09-28T08:51:00.863Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82j000ov1npunal0v1k","content":"<p><a href=\"http://ju.outofmemory.cn/entry/370841\" target=\"_blank\" rel=\"noopener\">http://ju.outofmemory.cn/entry/370841</a></p>\n<h3 id=\"这个模型和JVM的Safepoint太像了\"><a href=\"#这个模型和JVM的Safepoint太像了\" class=\"headerlink\" title=\"这个模型和JVM的Safepoint太像了\"></a>这个模型和JVM的Safepoint太像了</h3><p><a href=\"https://www.jianshu.com/p/9b10313fde10\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/9b10313fde10</a><br>果然是通了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">At-Most-Once</span><br><span class=\"line\">At-Least-Once</span><br><span class=\"line\">Exactly-Once</span><br><span class=\"line\">End-to-end Exactly-Once</span><br><span class=\"line\"></span><br><span class=\"line\">当不采用checkpoint时，每个event做多就只会被处理一次，这就是At-Most-Once。</span><br><span class=\"line\"></span><br><span class=\"line\">当不开启Barrier对齐时，上图中的Source1来的在barrier后面的一些event有可能比Source2的barrier要先到Task1.1，因为我们没有cache这些event，所以他们会正常被处理并有可能更新Task1.1的state。这样，在回复checkpoint后，Task1.1的state可能就是处理了某些checkpoint“时刻”之后数据的状态。但是对于Source1来说，他还是会offset到正常的checkpoint“时刻”的位置，那么之前处理过的barrier后面的event可能还是会被再次放入这个流中。那么这些event就不能保证“只处理一次”了，有可能处理多次，这就是At-Least-once。</span><br><span class=\"line\">如果在Task1.1.处，先来的barrier后面的event都被cache了，那么就不会影响到这个task的state。那么Task1.1的checkpoint的state就能准确反映checkpoint“时刻”的情况。那么checkpoint回复后也不会有前面说的问题，这就是Exactly-Once。但是因为Exactly-Once引入了cache机制，这会给checkpoint动作带来额外的时延（latency）。</span><br><span class=\"line\">End-to-end Exactly-Once需要结合外部系统一起完成，这里就不做讨论。</span><br><span class=\"line\"></span><br><span class=\"line\">作者：WoodsWalker</span><br><span class=\"line\">链接：https://www.jianshu.com/p/9b10313fde10</span><br><span class=\"line\">來源：简书</span><br><span class=\"line\">简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</span><br></pre></td></tr></table></figure>\n\n<p>解读Flink中轻量级的异步快照机制–论文<br><a href=\"https://blog.csdn.net/lmalds/article/details/54925877\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lmalds/article/details/54925877</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://ju.outofmemory.cn/entry/370841\" target=\"_blank\" rel=\"noopener\">http://ju.outofmemory.cn/entry/370841</a></p>\n<h3 id=\"这个模型和JVM的Safepoint太像了\"><a href=\"#这个模型和JVM的Safepoint太像了\" class=\"headerlink\" title=\"这个模型和JVM的Safepoint太像了\"></a>这个模型和JVM的Safepoint太像了</h3><p><a href=\"https://www.jianshu.com/p/9b10313fde10\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/9b10313fde10</a><br>果然是通了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">At-Most-Once</span><br><span class=\"line\">At-Least-Once</span><br><span class=\"line\">Exactly-Once</span><br><span class=\"line\">End-to-end Exactly-Once</span><br><span class=\"line\"></span><br><span class=\"line\">当不采用checkpoint时，每个event做多就只会被处理一次，这就是At-Most-Once。</span><br><span class=\"line\"></span><br><span class=\"line\">当不开启Barrier对齐时，上图中的Source1来的在barrier后面的一些event有可能比Source2的barrier要先到Task1.1，因为我们没有cache这些event，所以他们会正常被处理并有可能更新Task1.1的state。这样，在回复checkpoint后，Task1.1的state可能就是处理了某些checkpoint“时刻”之后数据的状态。但是对于Source1来说，他还是会offset到正常的checkpoint“时刻”的位置，那么之前处理过的barrier后面的event可能还是会被再次放入这个流中。那么这些event就不能保证“只处理一次”了，有可能处理多次，这就是At-Least-once。</span><br><span class=\"line\">如果在Task1.1.处，先来的barrier后面的event都被cache了，那么就不会影响到这个task的state。那么Task1.1的checkpoint的state就能准确反映checkpoint“时刻”的情况。那么checkpoint回复后也不会有前面说的问题，这就是Exactly-Once。但是因为Exactly-Once引入了cache机制，这会给checkpoint动作带来额外的时延（latency）。</span><br><span class=\"line\">End-to-end Exactly-Once需要结合外部系统一起完成，这里就不做讨论。</span><br><span class=\"line\"></span><br><span class=\"line\">作者：WoodsWalker</span><br><span class=\"line\">链接：https://www.jianshu.com/p/9b10313fde10</span><br><span class=\"line\">來源：简书</span><br><span class=\"line\">简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</span><br></pre></td></tr></table></figure>\n\n<p>解读Flink中轻量级的异步快照机制–论文<br><a href=\"https://blog.csdn.net/lmalds/article/details/54925877\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lmalds/article/details/54925877</a></p>\n"},{"title":"Flink-SourceCode-analysis","date":"2018-12-28T07:05:05.000Z","_content":"\n\n","source":"_posts/Flink-SourceCode-analysis.md","raw":"---\ntitle: Flink-SourceCode-analysis\ndate: 2018-12-28 15:05:05\ntags:\n---\n\n\n","slug":"Flink-SourceCode-analysis","published":1,"updated":"2019-09-28T08:51:00.863Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82j000pv1np8kwb0x6n","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Github-Pull-Request","date":"2019-01-22T13:59:58.000Z","_content":"\n\n\n1. fork 到自己的仓库\n2. git clone 到本地\n3. 上游建立连接\n* git remote add upstream 开源项目地址\n4. 创建开发分支 (非必须)\n* git checkout -b dev\n5. 修改提交代码\n* git status git add . git commit -m git push origin branch\n6. 同步代码三部曲\n* git fetch upstream\n* git rebase upstream/master\n* git push origin master\n7. 提交pr\n去自己github仓库对应fork的项目下\nnew pull request\n\n\n\n同步远程git代码到fork\ngit remote add upstream <原仓库github地址>\ngit remote -v\ngit fetch upstream","source":"_posts/Github-Pull-Request.md","raw":"---\ntitle: Github-Pull-Request\ndate: 2019-01-22 21:59:58\ntags:\n---\n\n\n\n1. fork 到自己的仓库\n2. git clone 到本地\n3. 上游建立连接\n* git remote add upstream 开源项目地址\n4. 创建开发分支 (非必须)\n* git checkout -b dev\n5. 修改提交代码\n* git status git add . git commit -m git push origin branch\n6. 同步代码三部曲\n* git fetch upstream\n* git rebase upstream/master\n* git push origin master\n7. 提交pr\n去自己github仓库对应fork的项目下\nnew pull request\n\n\n\n同步远程git代码到fork\ngit remote add upstream <原仓库github地址>\ngit remote -v\ngit fetch upstream","slug":"Github-Pull-Request","published":1,"updated":"2019-09-28T08:51:00.863Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82j000qv1np8lj6qs6f","content":"<ol>\n<li>fork 到自己的仓库</li>\n<li>git clone 到本地</li>\n<li>上游建立连接</li>\n</ol>\n<ul>\n<li>git remote add upstream 开源项目地址</li>\n</ul>\n<ol start=\"4\">\n<li>创建开发分支 (非必须)</li>\n</ol>\n<ul>\n<li>git checkout -b dev</li>\n</ul>\n<ol start=\"5\">\n<li>修改提交代码</li>\n</ol>\n<ul>\n<li>git status git add . git commit -m git push origin branch</li>\n</ul>\n<ol start=\"6\">\n<li>同步代码三部曲</li>\n</ol>\n<ul>\n<li>git fetch upstream</li>\n<li>git rebase upstream/master</li>\n<li>git push origin master</li>\n</ul>\n<ol start=\"7\">\n<li>提交pr<br>去自己github仓库对应fork的项目下<br>new pull request</li>\n</ol>\n<p>同步远程git代码到fork<br>git remote add upstream &lt;原仓库github地址&gt;<br>git remote -v<br>git fetch upstream</p>\n","site":{"data":{}},"excerpt":"","more":"<ol>\n<li>fork 到自己的仓库</li>\n<li>git clone 到本地</li>\n<li>上游建立连接</li>\n</ol>\n<ul>\n<li>git remote add upstream 开源项目地址</li>\n</ul>\n<ol start=\"4\">\n<li>创建开发分支 (非必须)</li>\n</ol>\n<ul>\n<li>git checkout -b dev</li>\n</ul>\n<ol start=\"5\">\n<li>修改提交代码</li>\n</ol>\n<ul>\n<li>git status git add . git commit -m git push origin branch</li>\n</ul>\n<ol start=\"6\">\n<li>同步代码三部曲</li>\n</ol>\n<ul>\n<li>git fetch upstream</li>\n<li>git rebase upstream/master</li>\n<li>git push origin master</li>\n</ul>\n<ol start=\"7\">\n<li>提交pr<br>去自己github仓库对应fork的项目下<br>new pull request</li>\n</ol>\n<p>同步远程git代码到fork<br>git remote add upstream &lt;原仓库github地址&gt;<br>git remote -v<br>git fetch upstream</p>\n"},{"title":"Go-GC","date":"2018-09-05T09:08:04.000Z","_content":"\n### Golang源码分析——GC的实现原理\nhttps://yq.aliyun.com/articles/536589\n\nhttps://www.jianshu.com/p/6da18331ed18\n\nhttps://github.com/golang/proposal/blob/master/design/17503-eliminate-rescan.md","source":"_posts/Go-GC.md","raw":"---\ntitle: Go-GC\ndate: 2018-09-05 17:08:04\ntags:\n---\n\n### Golang源码分析——GC的实现原理\nhttps://yq.aliyun.com/articles/536589\n\nhttps://www.jianshu.com/p/6da18331ed18\n\nhttps://github.com/golang/proposal/blob/master/design/17503-eliminate-rescan.md","slug":"Go-GC","published":1,"updated":"2019-09-28T08:51:00.864Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82k000rv1np6zj2f98c","content":"<h3 id=\"Golang源码分析——GC的实现原理\"><a href=\"#Golang源码分析——GC的实现原理\" class=\"headerlink\" title=\"Golang源码分析——GC的实现原理\"></a>Golang源码分析——GC的实现原理</h3><p><a href=\"https://yq.aliyun.com/articles/536589\" target=\"_blank\" rel=\"noopener\">https://yq.aliyun.com/articles/536589</a></p>\n<p><a href=\"https://www.jianshu.com/p/6da18331ed18\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/6da18331ed18</a></p>\n<p><a href=\"https://github.com/golang/proposal/blob/master/design/17503-eliminate-rescan.md\" target=\"_blank\" rel=\"noopener\">https://github.com/golang/proposal/blob/master/design/17503-eliminate-rescan.md</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Golang源码分析——GC的实现原理\"><a href=\"#Golang源码分析——GC的实现原理\" class=\"headerlink\" title=\"Golang源码分析——GC的实现原理\"></a>Golang源码分析——GC的实现原理</h3><p><a href=\"https://yq.aliyun.com/articles/536589\" target=\"_blank\" rel=\"noopener\">https://yq.aliyun.com/articles/536589</a></p>\n<p><a href=\"https://www.jianshu.com/p/6da18331ed18\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/6da18331ed18</a></p>\n<p><a href=\"https://github.com/golang/proposal/blob/master/design/17503-eliminate-rescan.md\" target=\"_blank\" rel=\"noopener\">https://github.com/golang/proposal/blob/master/design/17503-eliminate-rescan.md</a></p>\n"},{"title":"Go-Scheduler","date":"2018-07-24T13:15:58.000Z","_content":"\n### 分享\n首先，思考几个问题。\n\n什么叫做并行，基础是什么？\n在同一时刻内，多件时间一起做。\n对处理器，或者单处理器多核心。\n有个问题，如果系统总共有4个线程，在4核的机器上，应该不会有上下文切换吧？\n\n什么叫做并发，基础是什么？\n并发的概念没有并行严格，指在一个时段内，多件事情一起做。并发的基础是多线程调度，线程是操作系统进程中能够并发执行的实体，是处理器调度和分派的基本单位。 P101:一个线程什么时候获得CPU时间，能够运行多久，是由调度器根据某种调度策略所定。叫做线程的调度，也叫线程的上下文切换\n\n程序在处理一个问题时，是不是线程越多越好？\n送分题，不是，1分拿到。从煎鸡蛋和数学题开始讨论，哪一个线程可以适当多一点，哪一个可以少一点，多到多少最好，少到多少最好？\n\n注意到，既然我们在煎鸡蛋的时候无法自己直观得确定内核线程的数量，开小了，并发度不够，开大了，上下文切换太严重，在golang的设计哲学里，决定到底要创建多少个线程合适，这个事情就由golang来做。所以，大部分情况下，go程序运行时，无法控制线程的数量。\n\n更加细粒度的并发执行的调度单位：协程(goroutine)。线程的调度是由操作系统来做的，协程的调度就是由go scheduler (runtime)来做的。本质上，协程如果要执行，还是需要线程的支持。\n模仿上面的话，一个协程什么时候获得线程的时间，能够占用线程运行多久，就是go scheduler做的事情。也叫协程的上下文切换，是一种非常轻量级的上下文切换。\n\n当然事情远远没有那么简单\n\n协程上下文切换过程？\n\n如果G被阻塞了，\n\n如果G在M上调用了阻塞API，导致M阻塞了\n\n如果某个P的可运行G列表太多了\n\n如果某个P的可运行G列表太少了\n\n如果调用go func()，发生什么事情\n\n如果G的生命周期很短，怎么重用G?\n\n\n\n\n用刚刚所说的理论，来解释下，为什么net包中的IO一定是非阻塞的。\n假如，IO是阻塞的，会发生什么情况\n在zeroProxy或者tidb中，proxy层来一个用户就启用一个goroutine来单独处理读和写，假如有1万个连接同时进来，所有的连接都在read上阻塞，由于是阻塞IO，那么阻塞的级别就不在goroutine上，而是在内核线程上。这时调度器会给这1万个G去寻找可以运行的M，如果M实在是不够，那么调度器会创建\n\n查看下源码:\n```go\nfunc (fd *FD) Read(p []byte) (int, error) {\n\tif err := fd.readLock(); err != nil {\n\t\treturn 0, err\n\t}\n\tdefer fd.readUnlock()\n\tif len(p) == 0 {\n\t\t// If the caller wanted a zero byte read, return immediately\n\t\t// without trying (but after acquiring the readLock).\n\t\t// Otherwise syscall.Read returns 0, nil which looks like\n\t\t// io.EOF.\n\t\t// TODO(bradfitz): make it wait for readability? (Issue 15735)\n\t\treturn 0, nil\n\t}\n\tif err := fd.pd.prepareRead(fd.isFile); err != nil {\n\t\treturn 0, err\n\t}\n\tif fd.IsStream && len(p) > maxRW {\n\t\tp = p[:maxRW]\n\t}\n\tfor {\n\t\tn, err := syscall.Read(fd.Sysfd, p)\n\t\tif err != nil {\n\t\t\tn = 0\n\t\t\tif err == syscall.EAGAIN && fd.pd.pollable() {\n\t\t\t\tif err = fd.pd.waitRead(fd.isFile); err == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// On MacOS we can see EINTR here if the user\n\t\t\t// pressed ^Z.  See issue #22838.\n\t\t\tif runtime.GOOS == \"darwin\" && err == syscall.EINTR {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\terr = fd.eofError(n, err)\n\t\treturn n, err\n\t}\n}\n```\n\n\nhttp://morsmachine.dk/go-scheduler\nhttps://www.zhihu.com/question/20862617\nhttps://www.zhihu.com/question/22345230\n#### 进击的Golang专栏——说说Golang的runtime\nhttps://zhuanlan.zhihu.com/p/27328476\n\n从监控Go进程中的线程开始讲起:\n\n```\n[nanxing@zerodb-proxy001 zeroproxy]$ sudo sh start_zeroproxy_public.sh \n[nanxing@zerodb-proxy001 zeroproxy]$ ps axu|grep zero\nroot     25086  4.6  0.2  34100 18748 pts/0    Sl   14:35   0:00 ./zeroProxy.out -config app.yaml\nnanxing  25098  0.0  0.0 112704   972 pts/0    S+   14:35   0:00 grep --color=auto zero\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     └─{zeroProxy.out}(25095)\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086|wc -l\n9\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     └─{zeroProxy.out}(25095)\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     └─{zeroProxy.out}(25095)\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     ├─{zeroProxy.out}(25095)\n                     ├─{zeroProxy.out}(25120)\n                     └─{zeroProxy.out}(25121)\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     ├─{zeroProxy.out}(25095)\n                     ├─{zeroProxy.out}(25120)\n                     ├─{zeroProxy.out}(25121)\n                     └─{zeroProxy.out}(25123)\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     ├─{zeroProxy.out}(25095)\n                     ├─{zeroProxy.out}(25120)\n                     ├─{zeroProxy.out}(25121)\n                     └─{zeroProxy.out}(25123)\n```\n注意到，随着性能测试工具的压力逐渐增大，进程自己创建了少量线程。但是内部的协程\n\npprof -http \"0.0.0.0:12345\" 'http://10.12.0.241:50011/debug/pprof/profile'\n\n\n## 这里的图片可以参考下\nttps://blog.csdn.net/u010824081/article/details/78186611h\n\n\n## 为什么 Go 不实现分代和紧凑(Compact) gc\nGenerational and Compact gc have already been thought best practice. But golang doesn't adopt it. Who can tell me the reason? \n\n官方回答：\nhttps://lingchao.xin/post/why-golang-garbage-collector-not-implement-generational-and-compact-gc.html\nhttps://groups.google.com/forum/#!msg/golang-nuts/KJiyv2mV2pU/wdBUH1mHCAAJ\n\n\n## google's tcmalloc\nhttps://www.jianshu.com/p/7c55fbdef679\n\n在Netty-Jemalloc中提到了jemalloc，tcmalloc是与jemalloc齐名的内存分配算法。\n\n## 有几个重要的问题在这里抛出\n### 怎么写一个程序，这个程序会大量创建线程？？\nhttps://stackoverflow.com/questions/28186361/why-does-it-not-create-many-threads-when-many-goroutines-are-blocked-in-writing\n这里面有答案\n如果能理解这个问题，就基本上可以理解golang的调度器，可以参考下面的这个链接\nhttps://stackoverflow.com/questions/27600587/why-my-program-of-golang-create-so-many-threads\n\n\n## 如果linux的cpu使用率非常低，cpu的load会不会很高？\n\n## 调度器初始化源码分析\n```\nfunc schedinit() {\n\t// raceinit must be the first call to race detector.\n\t// In particular, it must be done before mallocinit below calls racemapshadow.\n\t_g_ := getg()\n\tif raceenabled {\n\t\t_g_.racectx, raceprocctx0 = raceinit()\n\t}\n\n\tsched.maxmcount = 10000\n\n\ttracebackinit()\n\tmoduledataverify()\n\tstackinit()\n\tmallocinit()\n\tmcommoninit(_g_.m)\n\talginit()       // maps must not be used before this call\n\tmodulesinit()   // provides activeModules\n\ttypelinksinit() // uses maps, activeModules\n\titabsinit()     // uses activeModules\n\n\tmsigsave(_g_.m)\n\tinitSigmask = _g_.m.sigmask\n\n\tgoargs()\n\tgoenvs()\n\tparsedebugvars()\n\tgcinit()\n\n\tsched.lastpoll = uint64(nanotime())\n\tprocs := ncpu\n\tif n, ok := atoi32(gogetenv(\"GOMAXPROCS\")); ok && n > 0 {\n\t\tprocs = n\n\t}\n\tif procresize(procs) != nil {\n\t\tthrow(\"unknown runnable goroutine during bootstrap\")\n\t}\n\n\t// For cgocheck > 1, we turn on the write barrier at all times\n\t// and check all pointer writes. We can't do this until after\n\t// procresize because the write barrier needs a P.\n\tif debug.cgocheck > 1 {\n\t\twriteBarrier.cgo = true\n\t\twriteBarrier.enabled = true\n\t\tfor _, p := range allp {\n\t\t\tp.wbBuf.reset()\n\t\t}\n\t}\n\n\tif buildVersion == \"\" {\n\t\t// Condition should never trigger. This code just serves\n\t\t// to ensure runtime·buildVersion is kept in the resulting binary.\n\t\tbuildVersion = \"unknown\"\n\t}\n}\n```","source":"_posts/Go-Scheduler.md","raw":"---\ntitle: Go-Scheduler\ndate: 2018-07-24 21:15:58\ntags:\n---\n\n### 分享\n首先，思考几个问题。\n\n什么叫做并行，基础是什么？\n在同一时刻内，多件时间一起做。\n对处理器，或者单处理器多核心。\n有个问题，如果系统总共有4个线程，在4核的机器上，应该不会有上下文切换吧？\n\n什么叫做并发，基础是什么？\n并发的概念没有并行严格，指在一个时段内，多件事情一起做。并发的基础是多线程调度，线程是操作系统进程中能够并发执行的实体，是处理器调度和分派的基本单位。 P101:一个线程什么时候获得CPU时间，能够运行多久，是由调度器根据某种调度策略所定。叫做线程的调度，也叫线程的上下文切换\n\n程序在处理一个问题时，是不是线程越多越好？\n送分题，不是，1分拿到。从煎鸡蛋和数学题开始讨论，哪一个线程可以适当多一点，哪一个可以少一点，多到多少最好，少到多少最好？\n\n注意到，既然我们在煎鸡蛋的时候无法自己直观得确定内核线程的数量，开小了，并发度不够，开大了，上下文切换太严重，在golang的设计哲学里，决定到底要创建多少个线程合适，这个事情就由golang来做。所以，大部分情况下，go程序运行时，无法控制线程的数量。\n\n更加细粒度的并发执行的调度单位：协程(goroutine)。线程的调度是由操作系统来做的，协程的调度就是由go scheduler (runtime)来做的。本质上，协程如果要执行，还是需要线程的支持。\n模仿上面的话，一个协程什么时候获得线程的时间，能够占用线程运行多久，就是go scheduler做的事情。也叫协程的上下文切换，是一种非常轻量级的上下文切换。\n\n当然事情远远没有那么简单\n\n协程上下文切换过程？\n\n如果G被阻塞了，\n\n如果G在M上调用了阻塞API，导致M阻塞了\n\n如果某个P的可运行G列表太多了\n\n如果某个P的可运行G列表太少了\n\n如果调用go func()，发生什么事情\n\n如果G的生命周期很短，怎么重用G?\n\n\n\n\n用刚刚所说的理论，来解释下，为什么net包中的IO一定是非阻塞的。\n假如，IO是阻塞的，会发生什么情况\n在zeroProxy或者tidb中，proxy层来一个用户就启用一个goroutine来单独处理读和写，假如有1万个连接同时进来，所有的连接都在read上阻塞，由于是阻塞IO，那么阻塞的级别就不在goroutine上，而是在内核线程上。这时调度器会给这1万个G去寻找可以运行的M，如果M实在是不够，那么调度器会创建\n\n查看下源码:\n```go\nfunc (fd *FD) Read(p []byte) (int, error) {\n\tif err := fd.readLock(); err != nil {\n\t\treturn 0, err\n\t}\n\tdefer fd.readUnlock()\n\tif len(p) == 0 {\n\t\t// If the caller wanted a zero byte read, return immediately\n\t\t// without trying (but after acquiring the readLock).\n\t\t// Otherwise syscall.Read returns 0, nil which looks like\n\t\t// io.EOF.\n\t\t// TODO(bradfitz): make it wait for readability? (Issue 15735)\n\t\treturn 0, nil\n\t}\n\tif err := fd.pd.prepareRead(fd.isFile); err != nil {\n\t\treturn 0, err\n\t}\n\tif fd.IsStream && len(p) > maxRW {\n\t\tp = p[:maxRW]\n\t}\n\tfor {\n\t\tn, err := syscall.Read(fd.Sysfd, p)\n\t\tif err != nil {\n\t\t\tn = 0\n\t\t\tif err == syscall.EAGAIN && fd.pd.pollable() {\n\t\t\t\tif err = fd.pd.waitRead(fd.isFile); err == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// On MacOS we can see EINTR here if the user\n\t\t\t// pressed ^Z.  See issue #22838.\n\t\t\tif runtime.GOOS == \"darwin\" && err == syscall.EINTR {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\terr = fd.eofError(n, err)\n\t\treturn n, err\n\t}\n}\n```\n\n\nhttp://morsmachine.dk/go-scheduler\nhttps://www.zhihu.com/question/20862617\nhttps://www.zhihu.com/question/22345230\n#### 进击的Golang专栏——说说Golang的runtime\nhttps://zhuanlan.zhihu.com/p/27328476\n\n从监控Go进程中的线程开始讲起:\n\n```\n[nanxing@zerodb-proxy001 zeroproxy]$ sudo sh start_zeroproxy_public.sh \n[nanxing@zerodb-proxy001 zeroproxy]$ ps axu|grep zero\nroot     25086  4.6  0.2  34100 18748 pts/0    Sl   14:35   0:00 ./zeroProxy.out -config app.yaml\nnanxing  25098  0.0  0.0 112704   972 pts/0    S+   14:35   0:00 grep --color=auto zero\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     └─{zeroProxy.out}(25095)\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086|wc -l\n9\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     └─{zeroProxy.out}(25095)\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     └─{zeroProxy.out}(25095)\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     ├─{zeroProxy.out}(25095)\n                     ├─{zeroProxy.out}(25120)\n                     └─{zeroProxy.out}(25121)\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     ├─{zeroProxy.out}(25095)\n                     ├─{zeroProxy.out}(25120)\n                     ├─{zeroProxy.out}(25121)\n                     └─{zeroProxy.out}(25123)\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     ├─{zeroProxy.out}(25095)\n                     ├─{zeroProxy.out}(25120)\n                     ├─{zeroProxy.out}(25121)\n                     └─{zeroProxy.out}(25123)\n```\n注意到，随着性能测试工具的压力逐渐增大，进程自己创建了少量线程。但是内部的协程\n\npprof -http \"0.0.0.0:12345\" 'http://10.12.0.241:50011/debug/pprof/profile'\n\n\n## 这里的图片可以参考下\nttps://blog.csdn.net/u010824081/article/details/78186611h\n\n\n## 为什么 Go 不实现分代和紧凑(Compact) gc\nGenerational and Compact gc have already been thought best practice. But golang doesn't adopt it. Who can tell me the reason? \n\n官方回答：\nhttps://lingchao.xin/post/why-golang-garbage-collector-not-implement-generational-and-compact-gc.html\nhttps://groups.google.com/forum/#!msg/golang-nuts/KJiyv2mV2pU/wdBUH1mHCAAJ\n\n\n## google's tcmalloc\nhttps://www.jianshu.com/p/7c55fbdef679\n\n在Netty-Jemalloc中提到了jemalloc，tcmalloc是与jemalloc齐名的内存分配算法。\n\n## 有几个重要的问题在这里抛出\n### 怎么写一个程序，这个程序会大量创建线程？？\nhttps://stackoverflow.com/questions/28186361/why-does-it-not-create-many-threads-when-many-goroutines-are-blocked-in-writing\n这里面有答案\n如果能理解这个问题，就基本上可以理解golang的调度器，可以参考下面的这个链接\nhttps://stackoverflow.com/questions/27600587/why-my-program-of-golang-create-so-many-threads\n\n\n## 如果linux的cpu使用率非常低，cpu的load会不会很高？\n\n## 调度器初始化源码分析\n```\nfunc schedinit() {\n\t// raceinit must be the first call to race detector.\n\t// In particular, it must be done before mallocinit below calls racemapshadow.\n\t_g_ := getg()\n\tif raceenabled {\n\t\t_g_.racectx, raceprocctx0 = raceinit()\n\t}\n\n\tsched.maxmcount = 10000\n\n\ttracebackinit()\n\tmoduledataverify()\n\tstackinit()\n\tmallocinit()\n\tmcommoninit(_g_.m)\n\talginit()       // maps must not be used before this call\n\tmodulesinit()   // provides activeModules\n\ttypelinksinit() // uses maps, activeModules\n\titabsinit()     // uses activeModules\n\n\tmsigsave(_g_.m)\n\tinitSigmask = _g_.m.sigmask\n\n\tgoargs()\n\tgoenvs()\n\tparsedebugvars()\n\tgcinit()\n\n\tsched.lastpoll = uint64(nanotime())\n\tprocs := ncpu\n\tif n, ok := atoi32(gogetenv(\"GOMAXPROCS\")); ok && n > 0 {\n\t\tprocs = n\n\t}\n\tif procresize(procs) != nil {\n\t\tthrow(\"unknown runnable goroutine during bootstrap\")\n\t}\n\n\t// For cgocheck > 1, we turn on the write barrier at all times\n\t// and check all pointer writes. We can't do this until after\n\t// procresize because the write barrier needs a P.\n\tif debug.cgocheck > 1 {\n\t\twriteBarrier.cgo = true\n\t\twriteBarrier.enabled = true\n\t\tfor _, p := range allp {\n\t\t\tp.wbBuf.reset()\n\t\t}\n\t}\n\n\tif buildVersion == \"\" {\n\t\t// Condition should never trigger. This code just serves\n\t\t// to ensure runtime·buildVersion is kept in the resulting binary.\n\t\tbuildVersion = \"unknown\"\n\t}\n}\n```","slug":"Go-Scheduler","published":1,"updated":"2019-09-28T08:51:00.864Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82k000sv1np1g0m4j6k","content":"<h3 id=\"分享\"><a href=\"#分享\" class=\"headerlink\" title=\"分享\"></a>分享</h3><p>首先，思考几个问题。</p>\n<p>什么叫做并行，基础是什么？<br>在同一时刻内，多件时间一起做。<br>对处理器，或者单处理器多核心。<br>有个问题，如果系统总共有4个线程，在4核的机器上，应该不会有上下文切换吧？</p>\n<p>什么叫做并发，基础是什么？<br>并发的概念没有并行严格，指在一个时段内，多件事情一起做。并发的基础是多线程调度，线程是操作系统进程中能够并发执行的实体，是处理器调度和分派的基本单位。 P101:一个线程什么时候获得CPU时间，能够运行多久，是由调度器根据某种调度策略所定。叫做线程的调度，也叫线程的上下文切换</p>\n<p>程序在处理一个问题时，是不是线程越多越好？<br>送分题，不是，1分拿到。从煎鸡蛋和数学题开始讨论，哪一个线程可以适当多一点，哪一个可以少一点，多到多少最好，少到多少最好？</p>\n<p>注意到，既然我们在煎鸡蛋的时候无法自己直观得确定内核线程的数量，开小了，并发度不够，开大了，上下文切换太严重，在golang的设计哲学里，决定到底要创建多少个线程合适，这个事情就由golang来做。所以，大部分情况下，go程序运行时，无法控制线程的数量。</p>\n<p>更加细粒度的并发执行的调度单位：协程(goroutine)。线程的调度是由操作系统来做的，协程的调度就是由go scheduler (runtime)来做的。本质上，协程如果要执行，还是需要线程的支持。<br>模仿上面的话，一个协程什么时候获得线程的时间，能够占用线程运行多久，就是go scheduler做的事情。也叫协程的上下文切换，是一种非常轻量级的上下文切换。</p>\n<p>当然事情远远没有那么简单</p>\n<p>协程上下文切换过程？</p>\n<p>如果G被阻塞了，</p>\n<p>如果G在M上调用了阻塞API，导致M阻塞了</p>\n<p>如果某个P的可运行G列表太多了</p>\n<p>如果某个P的可运行G列表太少了</p>\n<p>如果调用go func()，发生什么事情</p>\n<p>如果G的生命周期很短，怎么重用G?</p>\n<p>用刚刚所说的理论，来解释下，为什么net包中的IO一定是非阻塞的。<br>假如，IO是阻塞的，会发生什么情况<br>在zeroProxy或者tidb中，proxy层来一个用户就启用一个goroutine来单独处理读和写，假如有1万个连接同时进来，所有的连接都在read上阻塞，由于是阻塞IO，那么阻塞的级别就不在goroutine上，而是在内核线程上。这时调度器会给这1万个G去寻找可以运行的M，如果M实在是不够，那么调度器会创建</p>\n<p>查看下源码:</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(fd *FD)</span> <span class=\"title\">Read</span><span class=\"params\">(p []<span class=\"keyword\">byte</span>)</span> <span class=\"params\">(<span class=\"keyword\">int</span>, error)</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err := fd.readLock(); err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">defer</span> fd.readUnlock()</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(p) == <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"comment\">// If the caller wanted a zero byte read, return immediately</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// without trying (but after acquiring the readLock).</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// Otherwise syscall.Read returns 0, nil which looks like</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// io.EOF.</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// TODO(bradfitz): make it wait for readability? (Issue 15735)</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>, <span class=\"literal\">nil</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err := fd.pd.prepareRead(fd.isFile); err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> fd.IsStream &amp;&amp; <span class=\"built_in\">len</span>(p) &gt; maxRW &#123;</span><br><span class=\"line\">\t\tp = p[:maxRW]</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">\t\tn, err := syscall.Read(fd.Sysfd, p)</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\tn = <span class=\"number\">0</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> err == syscall.EAGAIN &amp;&amp; fd.pd.pollable() &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">if</span> err = fd.pd.waitRead(fd.isFile); err == <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\t\t\t<span class=\"keyword\">continue</span></span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t<span class=\"comment\">// On MacOS we can see EINTR here if the user</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">// pressed ^Z.  See issue #22838.</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> runtime.GOOS == <span class=\"string\">\"darwin\"</span> &amp;&amp; err == syscall.EINTR &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">continue</span></span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\terr = fd.eofError(n, err)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> n, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"http://morsmachine.dk/go-scheduler\" target=\"_blank\" rel=\"noopener\">http://morsmachine.dk/go-scheduler</a><br><a href=\"https://www.zhihu.com/question/20862617\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/20862617</a><br><a href=\"https://www.zhihu.com/question/22345230\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/22345230</a></p>\n<h4 id=\"进击的Golang专栏——说说Golang的runtime\"><a href=\"#进击的Golang专栏——说说Golang的runtime\" class=\"headerlink\" title=\"进击的Golang专栏——说说Golang的runtime\"></a>进击的Golang专栏——说说Golang的runtime</h4><p><a href=\"https://zhuanlan.zhihu.com/p/27328476\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/27328476</a></p>\n<p>从监控Go进程中的线程开始讲起:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ sudo sh start_zeroproxy_public.sh </span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ ps axu|grep zero</span><br><span class=\"line\">root     25086  4.6  0.2  34100 18748 pts/0    Sl   14:35   0:00 ./zeroProxy.out -config app.yaml</span><br><span class=\"line\">nanxing  25098  0.0  0.0 112704   972 pts/0    S+   14:35   0:00 grep --color=auto zero</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086|wc -l</span><br><span class=\"line\">9</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25120)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25121)</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25120)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25121)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25123)</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25120)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25121)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25123)</span><br></pre></td></tr></table></figure>\n\n<p>注意到，随着性能测试工具的压力逐渐增大，进程自己创建了少量线程。但是内部的协程</p>\n<p>pprof -http “0.0.0.0:12345” ‘<a href=\"http://10.12.0.241:50011/debug/pprof/profile&#39;\" target=\"_blank\" rel=\"noopener\">http://10.12.0.241:50011/debug/pprof/profile&#39;</a></p>\n<h2 id=\"这里的图片可以参考下\"><a href=\"#这里的图片可以参考下\" class=\"headerlink\" title=\"这里的图片可以参考下\"></a>这里的图片可以参考下</h2><p>ttps://blog.csdn.net/u010824081/article/details/78186611h</p>\n<h2 id=\"为什么-Go-不实现分代和紧凑-Compact-gc\"><a href=\"#为什么-Go-不实现分代和紧凑-Compact-gc\" class=\"headerlink\" title=\"为什么 Go 不实现分代和紧凑(Compact) gc\"></a>为什么 Go 不实现分代和紧凑(Compact) gc</h2><p>Generational and Compact gc have already been thought best practice. But golang doesn’t adopt it. Who can tell me the reason? </p>\n<p>官方回答：<br><a href=\"https://lingchao.xin/post/why-golang-garbage-collector-not-implement-generational-and-compact-gc.html\" target=\"_blank\" rel=\"noopener\">https://lingchao.xin/post/why-golang-garbage-collector-not-implement-generational-and-compact-gc.html</a><br><a href=\"https://groups.google.com/forum/#!msg/golang-nuts/KJiyv2mV2pU/wdBUH1mHCAAJ\" target=\"_blank\" rel=\"noopener\">https://groups.google.com/forum/#!msg/golang-nuts/KJiyv2mV2pU/wdBUH1mHCAAJ</a></p>\n<h2 id=\"google’s-tcmalloc\"><a href=\"#google’s-tcmalloc\" class=\"headerlink\" title=\"google’s tcmalloc\"></a>google’s tcmalloc</h2><p><a href=\"https://www.jianshu.com/p/7c55fbdef679\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/7c55fbdef679</a></p>\n<p>在Netty-Jemalloc中提到了jemalloc，tcmalloc是与jemalloc齐名的内存分配算法。</p>\n<h2 id=\"有几个重要的问题在这里抛出\"><a href=\"#有几个重要的问题在这里抛出\" class=\"headerlink\" title=\"有几个重要的问题在这里抛出\"></a>有几个重要的问题在这里抛出</h2><h3 id=\"怎么写一个程序，这个程序会大量创建线程？？\"><a href=\"#怎么写一个程序，这个程序会大量创建线程？？\" class=\"headerlink\" title=\"怎么写一个程序，这个程序会大量创建线程？？\"></a>怎么写一个程序，这个程序会大量创建线程？？</h3><p><a href=\"https://stackoverflow.com/questions/28186361/why-does-it-not-create-many-threads-when-many-goroutines-are-blocked-in-writing\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/28186361/why-does-it-not-create-many-threads-when-many-goroutines-are-blocked-in-writing</a><br>这里面有答案<br>如果能理解这个问题，就基本上可以理解golang的调度器，可以参考下面的这个链接<br><a href=\"https://stackoverflow.com/questions/27600587/why-my-program-of-golang-create-so-many-threads\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/27600587/why-my-program-of-golang-create-so-many-threads</a></p>\n<h2 id=\"如果linux的cpu使用率非常低，cpu的load会不会很高？\"><a href=\"#如果linux的cpu使用率非常低，cpu的load会不会很高？\" class=\"headerlink\" title=\"如果linux的cpu使用率非常低，cpu的load会不会很高？\"></a>如果linux的cpu使用率非常低，cpu的load会不会很高？</h2><h2 id=\"调度器初始化源码分析\"><a href=\"#调度器初始化源码分析\" class=\"headerlink\" title=\"调度器初始化源码分析\"></a>调度器初始化源码分析</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func schedinit() &#123;</span><br><span class=\"line\">\t// raceinit must be the first call to race detector.</span><br><span class=\"line\">\t// In particular, it must be done before mallocinit below calls racemapshadow.</span><br><span class=\"line\">\t_g_ := getg()</span><br><span class=\"line\">\tif raceenabled &#123;</span><br><span class=\"line\">\t\t_g_.racectx, raceprocctx0 = raceinit()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tsched.maxmcount = 10000</span><br><span class=\"line\"></span><br><span class=\"line\">\ttracebackinit()</span><br><span class=\"line\">\tmoduledataverify()</span><br><span class=\"line\">\tstackinit()</span><br><span class=\"line\">\tmallocinit()</span><br><span class=\"line\">\tmcommoninit(_g_.m)</span><br><span class=\"line\">\talginit()       // maps must not be used before this call</span><br><span class=\"line\">\tmodulesinit()   // provides activeModules</span><br><span class=\"line\">\ttypelinksinit() // uses maps, activeModules</span><br><span class=\"line\">\titabsinit()     // uses activeModules</span><br><span class=\"line\"></span><br><span class=\"line\">\tmsigsave(_g_.m)</span><br><span class=\"line\">\tinitSigmask = _g_.m.sigmask</span><br><span class=\"line\"></span><br><span class=\"line\">\tgoargs()</span><br><span class=\"line\">\tgoenvs()</span><br><span class=\"line\">\tparsedebugvars()</span><br><span class=\"line\">\tgcinit()</span><br><span class=\"line\"></span><br><span class=\"line\">\tsched.lastpoll = uint64(nanotime())</span><br><span class=\"line\">\tprocs := ncpu</span><br><span class=\"line\">\tif n, ok := atoi32(gogetenv(&quot;GOMAXPROCS&quot;)); ok &amp;&amp; n &gt; 0 &#123;</span><br><span class=\"line\">\t\tprocs = n</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif procresize(procs) != nil &#123;</span><br><span class=\"line\">\t\tthrow(&quot;unknown runnable goroutine during bootstrap&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// For cgocheck &gt; 1, we turn on the write barrier at all times</span><br><span class=\"line\">\t// and check all pointer writes. We can&apos;t do this until after</span><br><span class=\"line\">\t// procresize because the write barrier needs a P.</span><br><span class=\"line\">\tif debug.cgocheck &gt; 1 &#123;</span><br><span class=\"line\">\t\twriteBarrier.cgo = true</span><br><span class=\"line\">\t\twriteBarrier.enabled = true</span><br><span class=\"line\">\t\tfor _, p := range allp &#123;</span><br><span class=\"line\">\t\t\tp.wbBuf.reset()</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tif buildVersion == &quot;&quot; &#123;</span><br><span class=\"line\">\t\t// Condition should never trigger. This code just serves</span><br><span class=\"line\">\t\t// to ensure runtime·buildVersion is kept in the resulting binary.</span><br><span class=\"line\">\t\tbuildVersion = &quot;unknown&quot;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"分享\"><a href=\"#分享\" class=\"headerlink\" title=\"分享\"></a>分享</h3><p>首先，思考几个问题。</p>\n<p>什么叫做并行，基础是什么？<br>在同一时刻内，多件时间一起做。<br>对处理器，或者单处理器多核心。<br>有个问题，如果系统总共有4个线程，在4核的机器上，应该不会有上下文切换吧？</p>\n<p>什么叫做并发，基础是什么？<br>并发的概念没有并行严格，指在一个时段内，多件事情一起做。并发的基础是多线程调度，线程是操作系统进程中能够并发执行的实体，是处理器调度和分派的基本单位。 P101:一个线程什么时候获得CPU时间，能够运行多久，是由调度器根据某种调度策略所定。叫做线程的调度，也叫线程的上下文切换</p>\n<p>程序在处理一个问题时，是不是线程越多越好？<br>送分题，不是，1分拿到。从煎鸡蛋和数学题开始讨论，哪一个线程可以适当多一点，哪一个可以少一点，多到多少最好，少到多少最好？</p>\n<p>注意到，既然我们在煎鸡蛋的时候无法自己直观得确定内核线程的数量，开小了，并发度不够，开大了，上下文切换太严重，在golang的设计哲学里，决定到底要创建多少个线程合适，这个事情就由golang来做。所以，大部分情况下，go程序运行时，无法控制线程的数量。</p>\n<p>更加细粒度的并发执行的调度单位：协程(goroutine)。线程的调度是由操作系统来做的，协程的调度就是由go scheduler (runtime)来做的。本质上，协程如果要执行，还是需要线程的支持。<br>模仿上面的话，一个协程什么时候获得线程的时间，能够占用线程运行多久，就是go scheduler做的事情。也叫协程的上下文切换，是一种非常轻量级的上下文切换。</p>\n<p>当然事情远远没有那么简单</p>\n<p>协程上下文切换过程？</p>\n<p>如果G被阻塞了，</p>\n<p>如果G在M上调用了阻塞API，导致M阻塞了</p>\n<p>如果某个P的可运行G列表太多了</p>\n<p>如果某个P的可运行G列表太少了</p>\n<p>如果调用go func()，发生什么事情</p>\n<p>如果G的生命周期很短，怎么重用G?</p>\n<p>用刚刚所说的理论，来解释下，为什么net包中的IO一定是非阻塞的。<br>假如，IO是阻塞的，会发生什么情况<br>在zeroProxy或者tidb中，proxy层来一个用户就启用一个goroutine来单独处理读和写，假如有1万个连接同时进来，所有的连接都在read上阻塞，由于是阻塞IO，那么阻塞的级别就不在goroutine上，而是在内核线程上。这时调度器会给这1万个G去寻找可以运行的M，如果M实在是不够，那么调度器会创建</p>\n<p>查看下源码:</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(fd *FD)</span> <span class=\"title\">Read</span><span class=\"params\">(p []<span class=\"keyword\">byte</span>)</span> <span class=\"params\">(<span class=\"keyword\">int</span>, error)</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err := fd.readLock(); err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">defer</span> fd.readUnlock()</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(p) == <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"comment\">// If the caller wanted a zero byte read, return immediately</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// without trying (but after acquiring the readLock).</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// Otherwise syscall.Read returns 0, nil which looks like</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// io.EOF.</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// TODO(bradfitz): make it wait for readability? (Issue 15735)</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>, <span class=\"literal\">nil</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err := fd.pd.prepareRead(fd.isFile); err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> fd.IsStream &amp;&amp; <span class=\"built_in\">len</span>(p) &gt; maxRW &#123;</span><br><span class=\"line\">\t\tp = p[:maxRW]</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">\t\tn, err := syscall.Read(fd.Sysfd, p)</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\tn = <span class=\"number\">0</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> err == syscall.EAGAIN &amp;&amp; fd.pd.pollable() &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">if</span> err = fd.pd.waitRead(fd.isFile); err == <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\t\t\t\t<span class=\"keyword\">continue</span></span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t<span class=\"comment\">// On MacOS we can see EINTR here if the user</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">// pressed ^Z.  See issue #22838.</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> runtime.GOOS == <span class=\"string\">\"darwin\"</span> &amp;&amp; err == syscall.EINTR &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">continue</span></span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\terr = fd.eofError(n, err)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> n, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"http://morsmachine.dk/go-scheduler\" target=\"_blank\" rel=\"noopener\">http://morsmachine.dk/go-scheduler</a><br><a href=\"https://www.zhihu.com/question/20862617\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/20862617</a><br><a href=\"https://www.zhihu.com/question/22345230\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/22345230</a></p>\n<h4 id=\"进击的Golang专栏——说说Golang的runtime\"><a href=\"#进击的Golang专栏——说说Golang的runtime\" class=\"headerlink\" title=\"进击的Golang专栏——说说Golang的runtime\"></a>进击的Golang专栏——说说Golang的runtime</h4><p><a href=\"https://zhuanlan.zhihu.com/p/27328476\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/27328476</a></p>\n<p>从监控Go进程中的线程开始讲起:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ sudo sh start_zeroproxy_public.sh </span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ ps axu|grep zero</span><br><span class=\"line\">root     25086  4.6  0.2  34100 18748 pts/0    Sl   14:35   0:00 ./zeroProxy.out -config app.yaml</span><br><span class=\"line\">nanxing  25098  0.0  0.0 112704   972 pts/0    S+   14:35   0:00 grep --color=auto zero</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086|wc -l</span><br><span class=\"line\">9</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25120)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25121)</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25120)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25121)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25123)</span><br><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25120)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25121)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25123)</span><br></pre></td></tr></table></figure>\n\n<p>注意到，随着性能测试工具的压力逐渐增大，进程自己创建了少量线程。但是内部的协程</p>\n<p>pprof -http “0.0.0.0:12345” ‘<a href=\"http://10.12.0.241:50011/debug/pprof/profile&#39;\" target=\"_blank\" rel=\"noopener\">http://10.12.0.241:50011/debug/pprof/profile&#39;</a></p>\n<h2 id=\"这里的图片可以参考下\"><a href=\"#这里的图片可以参考下\" class=\"headerlink\" title=\"这里的图片可以参考下\"></a>这里的图片可以参考下</h2><p>ttps://blog.csdn.net/u010824081/article/details/78186611h</p>\n<h2 id=\"为什么-Go-不实现分代和紧凑-Compact-gc\"><a href=\"#为什么-Go-不实现分代和紧凑-Compact-gc\" class=\"headerlink\" title=\"为什么 Go 不实现分代和紧凑(Compact) gc\"></a>为什么 Go 不实现分代和紧凑(Compact) gc</h2><p>Generational and Compact gc have already been thought best practice. But golang doesn’t adopt it. Who can tell me the reason? </p>\n<p>官方回答：<br><a href=\"https://lingchao.xin/post/why-golang-garbage-collector-not-implement-generational-and-compact-gc.html\" target=\"_blank\" rel=\"noopener\">https://lingchao.xin/post/why-golang-garbage-collector-not-implement-generational-and-compact-gc.html</a><br><a href=\"https://groups.google.com/forum/#!msg/golang-nuts/KJiyv2mV2pU/wdBUH1mHCAAJ\" target=\"_blank\" rel=\"noopener\">https://groups.google.com/forum/#!msg/golang-nuts/KJiyv2mV2pU/wdBUH1mHCAAJ</a></p>\n<h2 id=\"google’s-tcmalloc\"><a href=\"#google’s-tcmalloc\" class=\"headerlink\" title=\"google’s tcmalloc\"></a>google’s tcmalloc</h2><p><a href=\"https://www.jianshu.com/p/7c55fbdef679\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/7c55fbdef679</a></p>\n<p>在Netty-Jemalloc中提到了jemalloc，tcmalloc是与jemalloc齐名的内存分配算法。</p>\n<h2 id=\"有几个重要的问题在这里抛出\"><a href=\"#有几个重要的问题在这里抛出\" class=\"headerlink\" title=\"有几个重要的问题在这里抛出\"></a>有几个重要的问题在这里抛出</h2><h3 id=\"怎么写一个程序，这个程序会大量创建线程？？\"><a href=\"#怎么写一个程序，这个程序会大量创建线程？？\" class=\"headerlink\" title=\"怎么写一个程序，这个程序会大量创建线程？？\"></a>怎么写一个程序，这个程序会大量创建线程？？</h3><p><a href=\"https://stackoverflow.com/questions/28186361/why-does-it-not-create-many-threads-when-many-goroutines-are-blocked-in-writing\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/28186361/why-does-it-not-create-many-threads-when-many-goroutines-are-blocked-in-writing</a><br>这里面有答案<br>如果能理解这个问题，就基本上可以理解golang的调度器，可以参考下面的这个链接<br><a href=\"https://stackoverflow.com/questions/27600587/why-my-program-of-golang-create-so-many-threads\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/27600587/why-my-program-of-golang-create-so-many-threads</a></p>\n<h2 id=\"如果linux的cpu使用率非常低，cpu的load会不会很高？\"><a href=\"#如果linux的cpu使用率非常低，cpu的load会不会很高？\" class=\"headerlink\" title=\"如果linux的cpu使用率非常低，cpu的load会不会很高？\"></a>如果linux的cpu使用率非常低，cpu的load会不会很高？</h2><h2 id=\"调度器初始化源码分析\"><a href=\"#调度器初始化源码分析\" class=\"headerlink\" title=\"调度器初始化源码分析\"></a>调度器初始化源码分析</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func schedinit() &#123;</span><br><span class=\"line\">\t// raceinit must be the first call to race detector.</span><br><span class=\"line\">\t// In particular, it must be done before mallocinit below calls racemapshadow.</span><br><span class=\"line\">\t_g_ := getg()</span><br><span class=\"line\">\tif raceenabled &#123;</span><br><span class=\"line\">\t\t_g_.racectx, raceprocctx0 = raceinit()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tsched.maxmcount = 10000</span><br><span class=\"line\"></span><br><span class=\"line\">\ttracebackinit()</span><br><span class=\"line\">\tmoduledataverify()</span><br><span class=\"line\">\tstackinit()</span><br><span class=\"line\">\tmallocinit()</span><br><span class=\"line\">\tmcommoninit(_g_.m)</span><br><span class=\"line\">\talginit()       // maps must not be used before this call</span><br><span class=\"line\">\tmodulesinit()   // provides activeModules</span><br><span class=\"line\">\ttypelinksinit() // uses maps, activeModules</span><br><span class=\"line\">\titabsinit()     // uses activeModules</span><br><span class=\"line\"></span><br><span class=\"line\">\tmsigsave(_g_.m)</span><br><span class=\"line\">\tinitSigmask = _g_.m.sigmask</span><br><span class=\"line\"></span><br><span class=\"line\">\tgoargs()</span><br><span class=\"line\">\tgoenvs()</span><br><span class=\"line\">\tparsedebugvars()</span><br><span class=\"line\">\tgcinit()</span><br><span class=\"line\"></span><br><span class=\"line\">\tsched.lastpoll = uint64(nanotime())</span><br><span class=\"line\">\tprocs := ncpu</span><br><span class=\"line\">\tif n, ok := atoi32(gogetenv(&quot;GOMAXPROCS&quot;)); ok &amp;&amp; n &gt; 0 &#123;</span><br><span class=\"line\">\t\tprocs = n</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif procresize(procs) != nil &#123;</span><br><span class=\"line\">\t\tthrow(&quot;unknown runnable goroutine during bootstrap&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// For cgocheck &gt; 1, we turn on the write barrier at all times</span><br><span class=\"line\">\t// and check all pointer writes. We can&apos;t do this until after</span><br><span class=\"line\">\t// procresize because the write barrier needs a P.</span><br><span class=\"line\">\tif debug.cgocheck &gt; 1 &#123;</span><br><span class=\"line\">\t\twriteBarrier.cgo = true</span><br><span class=\"line\">\t\twriteBarrier.enabled = true</span><br><span class=\"line\">\t\tfor _, p := range allp &#123;</span><br><span class=\"line\">\t\t\tp.wbBuf.reset()</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tif buildVersion == &quot;&quot; &#123;</span><br><span class=\"line\">\t\t// Condition should never trigger. This code just serves</span><br><span class=\"line\">\t\t// to ensure runtime·buildVersion is kept in the resulting binary.</span><br><span class=\"line\">\t\tbuildVersion = &quot;unknown&quot;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Go-Memory-Allocate-And-Collect","date":"2018-08-04T09:20:02.000Z","_content":"\n### 写得太好了\nhttps://www.jianshu.com/p/34984105175c\n\n\nGO语言内存管理子系统主要由两部分组成：内存分配器和垃圾回收器（gc）\n\n内存分配器主要解决小对象的分配管理和多线程的内存分配问题。什么是小对象呢？小于等于32k的对象就是小对象，其它都是大对象。小对象的内存分配是通过一级一级的缓存来实现的，目的就是为了提升内存分配释放的速度以及避免内存碎片等问题。\n\n为什么大部分编程语言都会给对象分配的内存设计「堆Heap」和「栈Stack」这么两块区域？\n\ngolang在「堆Heap」和「栈Stack」内存分配上有没有做什么优化？\n参考官方（https://groups.google.com/forum/#!msg/golang-nuts/KJiyv2mV2pU/wdBUH1mHCAAJ）\nThe Go compiler uses escape analysis to find objects whose lifetime is known at compile time, and allocates them on the stack rather than in garbage collected memory. \nSo in general, in Go, compared to other languages, a larger percentage of the quickly-unused values that a generational GC looks for are never allocated in GC memory in the first place.  So a generational GC would likely bring less advantage to Go than it does for other \nlanguages. \n\n\n### 简书 tcmalloc\nhttps://www.jianshu.com/p/ec585064a6e1\n\n### 对比JVM中的逃逸分析\nhttp://www.importnew.com/23150.html\n\n### golang的逃逸分析\n\n### Region-based memory management\nhttps://en.wikipedia.org/wiki/Region-based_memory_management\n\nIn computer science, region-based memory management is a type of memory management in which each allocated object is assigned to a region. A region, also called a zone, arena, area, or memory context, is a collection of allocated objects that can be efficiently deallocated all at once. Like stack allocation, regions facilitate allocation and deallocation of memory with low overhead; but they are more flexible, allowing objects to live longer than the stack frame in which they were allocated. In typical implementations, all objects in a region are allocated in a single contiguous range of memory addresses, similarly to how stack frames are typically allocated.","source":"_posts/Go-Memory-Allocate-And-Collect.md","raw":"---\ntitle: Go-Memory-Allocate-And-Collect\ndate: 2018-08-04 17:20:02\ntags:\n---\n\n### 写得太好了\nhttps://www.jianshu.com/p/34984105175c\n\n\nGO语言内存管理子系统主要由两部分组成：内存分配器和垃圾回收器（gc）\n\n内存分配器主要解决小对象的分配管理和多线程的内存分配问题。什么是小对象呢？小于等于32k的对象就是小对象，其它都是大对象。小对象的内存分配是通过一级一级的缓存来实现的，目的就是为了提升内存分配释放的速度以及避免内存碎片等问题。\n\n为什么大部分编程语言都会给对象分配的内存设计「堆Heap」和「栈Stack」这么两块区域？\n\ngolang在「堆Heap」和「栈Stack」内存分配上有没有做什么优化？\n参考官方（https://groups.google.com/forum/#!msg/golang-nuts/KJiyv2mV2pU/wdBUH1mHCAAJ）\nThe Go compiler uses escape analysis to find objects whose lifetime is known at compile time, and allocates them on the stack rather than in garbage collected memory. \nSo in general, in Go, compared to other languages, a larger percentage of the quickly-unused values that a generational GC looks for are never allocated in GC memory in the first place.  So a generational GC would likely bring less advantage to Go than it does for other \nlanguages. \n\n\n### 简书 tcmalloc\nhttps://www.jianshu.com/p/ec585064a6e1\n\n### 对比JVM中的逃逸分析\nhttp://www.importnew.com/23150.html\n\n### golang的逃逸分析\n\n### Region-based memory management\nhttps://en.wikipedia.org/wiki/Region-based_memory_management\n\nIn computer science, region-based memory management is a type of memory management in which each allocated object is assigned to a region. A region, also called a zone, arena, area, or memory context, is a collection of allocated objects that can be efficiently deallocated all at once. Like stack allocation, regions facilitate allocation and deallocation of memory with low overhead; but they are more flexible, allowing objects to live longer than the stack frame in which they were allocated. In typical implementations, all objects in a region are allocated in a single contiguous range of memory addresses, similarly to how stack frames are typically allocated.","slug":"Go-Memory-Allocate-And-Collect","published":1,"updated":"2019-09-28T08:51:00.864Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82l000tv1npplb125uo","content":"<h3 id=\"写得太好了\"><a href=\"#写得太好了\" class=\"headerlink\" title=\"写得太好了\"></a>写得太好了</h3><p><a href=\"https://www.jianshu.com/p/34984105175c\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/34984105175c</a></p>\n<p>GO语言内存管理子系统主要由两部分组成：内存分配器和垃圾回收器（gc）</p>\n<p>内存分配器主要解决小对象的分配管理和多线程的内存分配问题。什么是小对象呢？小于等于32k的对象就是小对象，其它都是大对象。小对象的内存分配是通过一级一级的缓存来实现的，目的就是为了提升内存分配释放的速度以及避免内存碎片等问题。</p>\n<p>为什么大部分编程语言都会给对象分配的内存设计「堆Heap」和「栈Stack」这么两块区域？</p>\n<p>golang在「堆Heap」和「栈Stack」内存分配上有没有做什么优化？<br>参考官方（<a href=\"https://groups.google.com/forum/#!msg/golang-nuts/KJiyv2mV2pU/wdBUH1mHCAAJ）\" target=\"_blank\" rel=\"noopener\">https://groups.google.com/forum/#!msg/golang-nuts/KJiyv2mV2pU/wdBUH1mHCAAJ）</a><br>The Go compiler uses escape analysis to find objects whose lifetime is known at compile time, and allocates them on the stack rather than in garbage collected memory.<br>So in general, in Go, compared to other languages, a larger percentage of the quickly-unused values that a generational GC looks for are never allocated in GC memory in the first place.  So a generational GC would likely bring less advantage to Go than it does for other<br>languages. </p>\n<h3 id=\"简书-tcmalloc\"><a href=\"#简书-tcmalloc\" class=\"headerlink\" title=\"简书 tcmalloc\"></a>简书 tcmalloc</h3><p><a href=\"https://www.jianshu.com/p/ec585064a6e1\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/ec585064a6e1</a></p>\n<h3 id=\"对比JVM中的逃逸分析\"><a href=\"#对比JVM中的逃逸分析\" class=\"headerlink\" title=\"对比JVM中的逃逸分析\"></a>对比JVM中的逃逸分析</h3><p><a href=\"http://www.importnew.com/23150.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/23150.html</a></p>\n<h3 id=\"golang的逃逸分析\"><a href=\"#golang的逃逸分析\" class=\"headerlink\" title=\"golang的逃逸分析\"></a>golang的逃逸分析</h3><h3 id=\"Region-based-memory-management\"><a href=\"#Region-based-memory-management\" class=\"headerlink\" title=\"Region-based memory management\"></a>Region-based memory management</h3><p><a href=\"https://en.wikipedia.org/wiki/Region-based_memory_management\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Region-based_memory_management</a></p>\n<p>In computer science, region-based memory management is a type of memory management in which each allocated object is assigned to a region. A region, also called a zone, arena, area, or memory context, is a collection of allocated objects that can be efficiently deallocated all at once. Like stack allocation, regions facilitate allocation and deallocation of memory with low overhead; but they are more flexible, allowing objects to live longer than the stack frame in which they were allocated. In typical implementations, all objects in a region are allocated in a single contiguous range of memory addresses, similarly to how stack frames are typically allocated.</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"写得太好了\"><a href=\"#写得太好了\" class=\"headerlink\" title=\"写得太好了\"></a>写得太好了</h3><p><a href=\"https://www.jianshu.com/p/34984105175c\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/34984105175c</a></p>\n<p>GO语言内存管理子系统主要由两部分组成：内存分配器和垃圾回收器（gc）</p>\n<p>内存分配器主要解决小对象的分配管理和多线程的内存分配问题。什么是小对象呢？小于等于32k的对象就是小对象，其它都是大对象。小对象的内存分配是通过一级一级的缓存来实现的，目的就是为了提升内存分配释放的速度以及避免内存碎片等问题。</p>\n<p>为什么大部分编程语言都会给对象分配的内存设计「堆Heap」和「栈Stack」这么两块区域？</p>\n<p>golang在「堆Heap」和「栈Stack」内存分配上有没有做什么优化？<br>参考官方（<a href=\"https://groups.google.com/forum/#!msg/golang-nuts/KJiyv2mV2pU/wdBUH1mHCAAJ）\" target=\"_blank\" rel=\"noopener\">https://groups.google.com/forum/#!msg/golang-nuts/KJiyv2mV2pU/wdBUH1mHCAAJ）</a><br>The Go compiler uses escape analysis to find objects whose lifetime is known at compile time, and allocates them on the stack rather than in garbage collected memory.<br>So in general, in Go, compared to other languages, a larger percentage of the quickly-unused values that a generational GC looks for are never allocated in GC memory in the first place.  So a generational GC would likely bring less advantage to Go than it does for other<br>languages. </p>\n<h3 id=\"简书-tcmalloc\"><a href=\"#简书-tcmalloc\" class=\"headerlink\" title=\"简书 tcmalloc\"></a>简书 tcmalloc</h3><p><a href=\"https://www.jianshu.com/p/ec585064a6e1\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/ec585064a6e1</a></p>\n<h3 id=\"对比JVM中的逃逸分析\"><a href=\"#对比JVM中的逃逸分析\" class=\"headerlink\" title=\"对比JVM中的逃逸分析\"></a>对比JVM中的逃逸分析</h3><p><a href=\"http://www.importnew.com/23150.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/23150.html</a></p>\n<h3 id=\"golang的逃逸分析\"><a href=\"#golang的逃逸分析\" class=\"headerlink\" title=\"golang的逃逸分析\"></a>golang的逃逸分析</h3><h3 id=\"Region-based-memory-management\"><a href=\"#Region-based-memory-management\" class=\"headerlink\" title=\"Region-based memory management\"></a>Region-based memory management</h3><p><a href=\"https://en.wikipedia.org/wiki/Region-based_memory_management\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Region-based_memory_management</a></p>\n<p>In computer science, region-based memory management is a type of memory management in which each allocated object is assigned to a region. A region, also called a zone, arena, area, or memory context, is a collection of allocated objects that can be efficiently deallocated all at once. Like stack allocation, regions facilitate allocation and deallocation of memory with low overhead; but they are more flexible, allowing objects to live longer than the stack frame in which they were allocated. In typical implementations, all objects in a region are allocated in a single contiguous range of memory addresses, similarly to how stack frames are typically allocated.</p>\n"},{"title":"Go-Tcp","date":"2018-07-28T03:39:56.000Z","_content":"\nhttps://www.cnblogs.com/findumars/p/5624958.html\n\nhttps://studygolang.com/articles/11868\n\nhttp://ju.outofmemory.cn/entry/168649\n\n\n### 知乎专栏\nhttps://zhuanlan.zhihu.com/p/31644462\n\n\n### 好文章\nhttp://skoo.me/go/2014/04/21/go-net-core?hmsr=studygolang.com&utm_medium=studygolang.com&utm_source=studygolang.com\n\n### TCP超时\nhttps://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/?utm_source=studygolang&utm_medium=email","source":"_posts/Go-Tcp.md","raw":"---\ntitle: Go-Tcp\ndate: 2018-07-28 11:39:56\ntags:\n---\n\nhttps://www.cnblogs.com/findumars/p/5624958.html\n\nhttps://studygolang.com/articles/11868\n\nhttp://ju.outofmemory.cn/entry/168649\n\n\n### 知乎专栏\nhttps://zhuanlan.zhihu.com/p/31644462\n\n\n### 好文章\nhttp://skoo.me/go/2014/04/21/go-net-core?hmsr=studygolang.com&utm_medium=studygolang.com&utm_source=studygolang.com\n\n### TCP超时\nhttps://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/?utm_source=studygolang&utm_medium=email","slug":"Go-Tcp","published":1,"updated":"2019-09-28T08:51:00.864Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82l000uv1npwuck2m8c","content":"<p><a href=\"https://www.cnblogs.com/findumars/p/5624958.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/findumars/p/5624958.html</a></p>\n<p><a href=\"https://studygolang.com/articles/11868\" target=\"_blank\" rel=\"noopener\">https://studygolang.com/articles/11868</a></p>\n<p><a href=\"http://ju.outofmemory.cn/entry/168649\" target=\"_blank\" rel=\"noopener\">http://ju.outofmemory.cn/entry/168649</a></p>\n<h3 id=\"知乎专栏\"><a href=\"#知乎专栏\" class=\"headerlink\" title=\"知乎专栏\"></a>知乎专栏</h3><p><a href=\"https://zhuanlan.zhihu.com/p/31644462\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/31644462</a></p>\n<h3 id=\"好文章\"><a href=\"#好文章\" class=\"headerlink\" title=\"好文章\"></a>好文章</h3><p><a href=\"http://skoo.me/go/2014/04/21/go-net-core?hmsr=studygolang.com&amp;utm_medium=studygolang.com&amp;utm_source=studygolang.com\" target=\"_blank\" rel=\"noopener\">http://skoo.me/go/2014/04/21/go-net-core?hmsr=studygolang.com&amp;utm_medium=studygolang.com&amp;utm_source=studygolang.com</a></p>\n<h3 id=\"TCP超时\"><a href=\"#TCP超时\" class=\"headerlink\" title=\"TCP超时\"></a>TCP超时</h3><p><a href=\"https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/?utm_source=studygolang&amp;utm_medium=email\" target=\"_blank\" rel=\"noopener\">https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/?utm_source=studygolang&amp;utm_medium=email</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.cnblogs.com/findumars/p/5624958.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/findumars/p/5624958.html</a></p>\n<p><a href=\"https://studygolang.com/articles/11868\" target=\"_blank\" rel=\"noopener\">https://studygolang.com/articles/11868</a></p>\n<p><a href=\"http://ju.outofmemory.cn/entry/168649\" target=\"_blank\" rel=\"noopener\">http://ju.outofmemory.cn/entry/168649</a></p>\n<h3 id=\"知乎专栏\"><a href=\"#知乎专栏\" class=\"headerlink\" title=\"知乎专栏\"></a>知乎专栏</h3><p><a href=\"https://zhuanlan.zhihu.com/p/31644462\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/31644462</a></p>\n<h3 id=\"好文章\"><a href=\"#好文章\" class=\"headerlink\" title=\"好文章\"></a>好文章</h3><p><a href=\"http://skoo.me/go/2014/04/21/go-net-core?hmsr=studygolang.com&amp;utm_medium=studygolang.com&amp;utm_source=studygolang.com\" target=\"_blank\" rel=\"noopener\">http://skoo.me/go/2014/04/21/go-net-core?hmsr=studygolang.com&amp;utm_medium=studygolang.com&amp;utm_source=studygolang.com</a></p>\n<h3 id=\"TCP超时\"><a href=\"#TCP超时\" class=\"headerlink\" title=\"TCP超时\"></a>TCP超时</h3><p><a href=\"https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/?utm_source=studygolang&amp;utm_medium=email\" target=\"_blank\" rel=\"noopener\">https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/?utm_source=studygolang&amp;utm_medium=email</a></p>\n"},{"title":"IDEA-Keymap","date":"2019-01-05T09:54:05.000Z","_content":"\n\nctrl + o","source":"_posts/IDEA-Keymap.md","raw":"---\ntitle: IDEA-Keymap\ndate: 2019-01-05 17:54:05\ntags:\n---\n\n\nctrl + o","slug":"IDEA-Keymap","published":1,"updated":"2019-09-28T08:51:00.865Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82m000vv1npuv4rbgn5","content":"<p>ctrl + o</p>\n","site":{"data":{}},"excerpt":"","more":"<p>ctrl + o</p>\n"},{"title":"Interview-Questions","date":"2017-11-20T07:38:08.000Z","_content":"\n\n### 高阶面试题集合\nhttps://www.bookstack.cn/books/system-design\n\n### 优秀文章\nhttps://www.jianshu.com/p/5c926f878c96\n\nhttps://github.com/xingshaocheng/architect-awesome/blob/master/README.md\n\n\n### 如果让你设计一个异步调用的服务，你会注意些什么？\n\n异步结果（Future & Promise）设计\n异步没有被调用者的反馈（Feed Back），如果没有限流，将会被调用垮掉\n\n作者：Leo Yang\n链接：https://www.zhihu.com/question/60949531/answer/184044541\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n从阿里的常规java技术面试角度说一说，一般都是由浅到深去问，思路是先考察基础是否过关，再通过深度考察是否有技术热情和深度，同时可能会通过提出一些质疑和挑战来考察候选人是如何与不同意见进行沟通考察内容和方式基础知识：考察基础的时候一般都不会太深入地去问，主要目的是考察知识面，如果发现候选人很多都不知道可能就不会继续进入下一步的考察。\nJDK 集合、BIO/NIO、annotation 等虚拟机 内存模型、类加载原理数据库 索引、事务、死锁 等并发 并发优缺点、内存可见性（volatile）、锁、同步、线程池框架网络 TCP/HTTP 常见设计模式深入考察：深入考察的时候不会像考察基础一样面面俱到，而是会在某个点上深入去聊，这个点的选择可能是让候选人自己选一个点，也可能是面试官根据简历内容去选，主要目的是考察候选人对某个技术点的深入掌握程度，技术是相通的，如果一个人能在某个技术点上达到很深入的程度，其他点上通常也不会有太大问题；相反如果某个人在他声称很了解的点上都支支吾吾、一知半解多半可以判断此人要么技术能力有限、要么遇到问题不愿深入考察、浅尝辄止。\nJDK ConcurrentHashMap如何提高并发度、NIO的原理（零拷贝、堆外内存），优缺点虚拟机 包冲突，类冲突的形成原理及解决办法（可能会引申JDK9的模块化设计）、TCCL的存在价值分布式 一致性哈希、RPC原理和设计（通信协议、序列化方式、超时机制等）、负载均衡、分布式缓存架构设计、分布式消息、分布式事务、paxos（这个可能只有在技术专业型很强的职位上会去问）数据库 数据库性能优化（慢sql、索引优化、大事务、内核参数调优），也可能会把一些工作中碰到的诡异场景抛出来问并发 非阻塞锁（CAS)、并发对编译器优化的影响、线程池调优、也肯会把工作中碰到的并发问题抛出来问技术趋势、docker、微服务等新技术发展历史、带来的福利如何准备首先要声明的是，最好的“准备”方式一定是平时多积累、遇到问题不要逃避或者讨巧、深入去思考并解决，在解决一个个问题的过程中积累解决问题的能力，形成自己的知识体系。所以这里说的如何准备不是说临时抱佛脚，而是如何能通过提前准备把自己平时的积累展现出来，不因为临场的表现影响面试官对你的判断。针对以上列的知识点思考答案甚至扩展，如果能知道大部分，深入一部分就很好，这个过程主要是整理自己的知识体系回忆整理简历和过往项目中的”难点“、”亮点“，因为这些是用来区分候选人很重要的点，合格的面试官一定会问类似于”你在项目中经历的最大的技术难点是什么？“，整理一下思路，不至于在面试时候因为时间久远而回忆不起来细节影响面试效果。沟通过程中做到有理有据，不要过于自大，也无需刻意迎合面试官。沟通的本质是信息透明化，工作中也许我们无法做到完全客观公正，但是在技术问题上坚持自己的客观和原则是我认为技术人应该坚持的品格，我这里说的坚持不是一根筋的固执已见，而是根据共同认可的事实进行逻辑推断得出的观点。长远来看这种品格会带给你足够的技术影响力和回报。","source":"_posts/Interview-Questions.md","raw":"---\ntitle: Interview-Questions\ndate: 2017-11-20 15:38:08\ntags: 面试\n---\n\n\n### 高阶面试题集合\nhttps://www.bookstack.cn/books/system-design\n\n### 优秀文章\nhttps://www.jianshu.com/p/5c926f878c96\n\nhttps://github.com/xingshaocheng/architect-awesome/blob/master/README.md\n\n\n### 如果让你设计一个异步调用的服务，你会注意些什么？\n\n异步结果（Future & Promise）设计\n异步没有被调用者的反馈（Feed Back），如果没有限流，将会被调用垮掉\n\n作者：Leo Yang\n链接：https://www.zhihu.com/question/60949531/answer/184044541\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n从阿里的常规java技术面试角度说一说，一般都是由浅到深去问，思路是先考察基础是否过关，再通过深度考察是否有技术热情和深度，同时可能会通过提出一些质疑和挑战来考察候选人是如何与不同意见进行沟通考察内容和方式基础知识：考察基础的时候一般都不会太深入地去问，主要目的是考察知识面，如果发现候选人很多都不知道可能就不会继续进入下一步的考察。\nJDK 集合、BIO/NIO、annotation 等虚拟机 内存模型、类加载原理数据库 索引、事务、死锁 等并发 并发优缺点、内存可见性（volatile）、锁、同步、线程池框架网络 TCP/HTTP 常见设计模式深入考察：深入考察的时候不会像考察基础一样面面俱到，而是会在某个点上深入去聊，这个点的选择可能是让候选人自己选一个点，也可能是面试官根据简历内容去选，主要目的是考察候选人对某个技术点的深入掌握程度，技术是相通的，如果一个人能在某个技术点上达到很深入的程度，其他点上通常也不会有太大问题；相反如果某个人在他声称很了解的点上都支支吾吾、一知半解多半可以判断此人要么技术能力有限、要么遇到问题不愿深入考察、浅尝辄止。\nJDK ConcurrentHashMap如何提高并发度、NIO的原理（零拷贝、堆外内存），优缺点虚拟机 包冲突，类冲突的形成原理及解决办法（可能会引申JDK9的模块化设计）、TCCL的存在价值分布式 一致性哈希、RPC原理和设计（通信协议、序列化方式、超时机制等）、负载均衡、分布式缓存架构设计、分布式消息、分布式事务、paxos（这个可能只有在技术专业型很强的职位上会去问）数据库 数据库性能优化（慢sql、索引优化、大事务、内核参数调优），也可能会把一些工作中碰到的诡异场景抛出来问并发 非阻塞锁（CAS)、并发对编译器优化的影响、线程池调优、也肯会把工作中碰到的并发问题抛出来问技术趋势、docker、微服务等新技术发展历史、带来的福利如何准备首先要声明的是，最好的“准备”方式一定是平时多积累、遇到问题不要逃避或者讨巧、深入去思考并解决，在解决一个个问题的过程中积累解决问题的能力，形成自己的知识体系。所以这里说的如何准备不是说临时抱佛脚，而是如何能通过提前准备把自己平时的积累展现出来，不因为临场的表现影响面试官对你的判断。针对以上列的知识点思考答案甚至扩展，如果能知道大部分，深入一部分就很好，这个过程主要是整理自己的知识体系回忆整理简历和过往项目中的”难点“、”亮点“，因为这些是用来区分候选人很重要的点，合格的面试官一定会问类似于”你在项目中经历的最大的技术难点是什么？“，整理一下思路，不至于在面试时候因为时间久远而回忆不起来细节影响面试效果。沟通过程中做到有理有据，不要过于自大，也无需刻意迎合面试官。沟通的本质是信息透明化，工作中也许我们无法做到完全客观公正，但是在技术问题上坚持自己的客观和原则是我认为技术人应该坚持的品格，我这里说的坚持不是一根筋的固执已见，而是根据共同认可的事实进行逻辑推断得出的观点。长远来看这种品格会带给你足够的技术影响力和回报。","slug":"Interview-Questions","published":1,"updated":"2019-09-28T08:51:00.865Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82m000wv1npvzv1uxgm","content":"<h3 id=\"高阶面试题集合\"><a href=\"#高阶面试题集合\" class=\"headerlink\" title=\"高阶面试题集合\"></a>高阶面试题集合</h3><p><a href=\"https://www.bookstack.cn/books/system-design\" target=\"_blank\" rel=\"noopener\">https://www.bookstack.cn/books/system-design</a></p>\n<h3 id=\"优秀文章\"><a href=\"#优秀文章\" class=\"headerlink\" title=\"优秀文章\"></a>优秀文章</h3><p><a href=\"https://www.jianshu.com/p/5c926f878c96\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/5c926f878c96</a></p>\n<p><a href=\"https://github.com/xingshaocheng/architect-awesome/blob/master/README.md\" target=\"_blank\" rel=\"noopener\">https://github.com/xingshaocheng/architect-awesome/blob/master/README.md</a></p>\n<h3 id=\"如果让你设计一个异步调用的服务，你会注意些什么？\"><a href=\"#如果让你设计一个异步调用的服务，你会注意些什么？\" class=\"headerlink\" title=\"如果让你设计一个异步调用的服务，你会注意些什么？\"></a>如果让你设计一个异步调用的服务，你会注意些什么？</h3><p>异步结果（Future &amp; Promise）设计<br>异步没有被调用者的反馈（Feed Back），如果没有限流，将会被调用垮掉</p>\n<p>作者：Leo Yang<br>链接：<a href=\"https://www.zhihu.com/question/60949531/answer/184044541\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/60949531/answer/184044541</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>\n<p>从阿里的常规java技术面试角度说一说，一般都是由浅到深去问，思路是先考察基础是否过关，再通过深度考察是否有技术热情和深度，同时可能会通过提出一些质疑和挑战来考察候选人是如何与不同意见进行沟通考察内容和方式基础知识：考察基础的时候一般都不会太深入地去问，主要目的是考察知识面，如果发现候选人很多都不知道可能就不会继续进入下一步的考察。<br>JDK 集合、BIO/NIO、annotation 等虚拟机 内存模型、类加载原理数据库 索引、事务、死锁 等并发 并发优缺点、内存可见性（volatile）、锁、同步、线程池框架网络 TCP/HTTP 常见设计模式深入考察：深入考察的时候不会像考察基础一样面面俱到，而是会在某个点上深入去聊，这个点的选择可能是让候选人自己选一个点，也可能是面试官根据简历内容去选，主要目的是考察候选人对某个技术点的深入掌握程度，技术是相通的，如果一个人能在某个技术点上达到很深入的程度，其他点上通常也不会有太大问题；相反如果某个人在他声称很了解的点上都支支吾吾、一知半解多半可以判断此人要么技术能力有限、要么遇到问题不愿深入考察、浅尝辄止。<br>JDK ConcurrentHashMap如何提高并发度、NIO的原理（零拷贝、堆外内存），优缺点虚拟机 包冲突，类冲突的形成原理及解决办法（可能会引申JDK9的模块化设计）、TCCL的存在价值分布式 一致性哈希、RPC原理和设计（通信协议、序列化方式、超时机制等）、负载均衡、分布式缓存架构设计、分布式消息、分布式事务、paxos（这个可能只有在技术专业型很强的职位上会去问）数据库 数据库性能优化（慢sql、索引优化、大事务、内核参数调优），也可能会把一些工作中碰到的诡异场景抛出来问并发 非阻塞锁（CAS)、并发对编译器优化的影响、线程池调优、也肯会把工作中碰到的并发问题抛出来问技术趋势、docker、微服务等新技术发展历史、带来的福利如何准备首先要声明的是，最好的“准备”方式一定是平时多积累、遇到问题不要逃避或者讨巧、深入去思考并解决，在解决一个个问题的过程中积累解决问题的能力，形成自己的知识体系。所以这里说的如何准备不是说临时抱佛脚，而是如何能通过提前准备把自己平时的积累展现出来，不因为临场的表现影响面试官对你的判断。针对以上列的知识点思考答案甚至扩展，如果能知道大部分，深入一部分就很好，这个过程主要是整理自己的知识体系回忆整理简历和过往项目中的”难点“、”亮点“，因为这些是用来区分候选人很重要的点，合格的面试官一定会问类似于”你在项目中经历的最大的技术难点是什么？“，整理一下思路，不至于在面试时候因为时间久远而回忆不起来细节影响面试效果。沟通过程中做到有理有据，不要过于自大，也无需刻意迎合面试官。沟通的本质是信息透明化，工作中也许我们无法做到完全客观公正，但是在技术问题上坚持自己的客观和原则是我认为技术人应该坚持的品格，我这里说的坚持不是一根筋的固执已见，而是根据共同认可的事实进行逻辑推断得出的观点。长远来看这种品格会带给你足够的技术影响力和回报。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"高阶面试题集合\"><a href=\"#高阶面试题集合\" class=\"headerlink\" title=\"高阶面试题集合\"></a>高阶面试题集合</h3><p><a href=\"https://www.bookstack.cn/books/system-design\" target=\"_blank\" rel=\"noopener\">https://www.bookstack.cn/books/system-design</a></p>\n<h3 id=\"优秀文章\"><a href=\"#优秀文章\" class=\"headerlink\" title=\"优秀文章\"></a>优秀文章</h3><p><a href=\"https://www.jianshu.com/p/5c926f878c96\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/5c926f878c96</a></p>\n<p><a href=\"https://github.com/xingshaocheng/architect-awesome/blob/master/README.md\" target=\"_blank\" rel=\"noopener\">https://github.com/xingshaocheng/architect-awesome/blob/master/README.md</a></p>\n<h3 id=\"如果让你设计一个异步调用的服务，你会注意些什么？\"><a href=\"#如果让你设计一个异步调用的服务，你会注意些什么？\" class=\"headerlink\" title=\"如果让你设计一个异步调用的服务，你会注意些什么？\"></a>如果让你设计一个异步调用的服务，你会注意些什么？</h3><p>异步结果（Future &amp; Promise）设计<br>异步没有被调用者的反馈（Feed Back），如果没有限流，将会被调用垮掉</p>\n<p>作者：Leo Yang<br>链接：<a href=\"https://www.zhihu.com/question/60949531/answer/184044541\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/60949531/answer/184044541</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>\n<p>从阿里的常规java技术面试角度说一说，一般都是由浅到深去问，思路是先考察基础是否过关，再通过深度考察是否有技术热情和深度，同时可能会通过提出一些质疑和挑战来考察候选人是如何与不同意见进行沟通考察内容和方式基础知识：考察基础的时候一般都不会太深入地去问，主要目的是考察知识面，如果发现候选人很多都不知道可能就不会继续进入下一步的考察。<br>JDK 集合、BIO/NIO、annotation 等虚拟机 内存模型、类加载原理数据库 索引、事务、死锁 等并发 并发优缺点、内存可见性（volatile）、锁、同步、线程池框架网络 TCP/HTTP 常见设计模式深入考察：深入考察的时候不会像考察基础一样面面俱到，而是会在某个点上深入去聊，这个点的选择可能是让候选人自己选一个点，也可能是面试官根据简历内容去选，主要目的是考察候选人对某个技术点的深入掌握程度，技术是相通的，如果一个人能在某个技术点上达到很深入的程度，其他点上通常也不会有太大问题；相反如果某个人在他声称很了解的点上都支支吾吾、一知半解多半可以判断此人要么技术能力有限、要么遇到问题不愿深入考察、浅尝辄止。<br>JDK ConcurrentHashMap如何提高并发度、NIO的原理（零拷贝、堆外内存），优缺点虚拟机 包冲突，类冲突的形成原理及解决办法（可能会引申JDK9的模块化设计）、TCCL的存在价值分布式 一致性哈希、RPC原理和设计（通信协议、序列化方式、超时机制等）、负载均衡、分布式缓存架构设计、分布式消息、分布式事务、paxos（这个可能只有在技术专业型很强的职位上会去问）数据库 数据库性能优化（慢sql、索引优化、大事务、内核参数调优），也可能会把一些工作中碰到的诡异场景抛出来问并发 非阻塞锁（CAS)、并发对编译器优化的影响、线程池调优、也肯会把工作中碰到的并发问题抛出来问技术趋势、docker、微服务等新技术发展历史、带来的福利如何准备首先要声明的是，最好的“准备”方式一定是平时多积累、遇到问题不要逃避或者讨巧、深入去思考并解决，在解决一个个问题的过程中积累解决问题的能力，形成自己的知识体系。所以这里说的如何准备不是说临时抱佛脚，而是如何能通过提前准备把自己平时的积累展现出来，不因为临场的表现影响面试官对你的判断。针对以上列的知识点思考答案甚至扩展，如果能知道大部分，深入一部分就很好，这个过程主要是整理自己的知识体系回忆整理简历和过往项目中的”难点“、”亮点“，因为这些是用来区分候选人很重要的点，合格的面试官一定会问类似于”你在项目中经历的最大的技术难点是什么？“，整理一下思路，不至于在面试时候因为时间久远而回忆不起来细节影响面试效果。沟通过程中做到有理有据，不要过于自大，也无需刻意迎合面试官。沟通的本质是信息透明化，工作中也许我们无法做到完全客观公正，但是在技术问题上坚持自己的客观和原则是我认为技术人应该坚持的品格，我这里说的坚持不是一根筋的固执已见，而是根据共同认可的事实进行逻辑推断得出的观点。长远来看这种品格会带给你足够的技术影响力和回报。</p>\n"},{"title":"guava中的黑科技","date":"2017-09-19T09:39:05.000Z","_content":"\n### 限流\n\nhttp://www.itwendao.com/article/detail/357611.html\n\n### 缓存\n\n### 集合\n\n#### BiMap\n\n### 反射\n\n### 并发","source":"_posts/Guava-Black-techs.md","raw":"---\ntitle: guava中的黑科技\ndate: 2017-09-19 17:39:05\ntags: Guava\n---\n\n### 限流\n\nhttp://www.itwendao.com/article/detail/357611.html\n\n### 缓存\n\n### 集合\n\n#### BiMap\n\n### 反射\n\n### 并发","slug":"Guava-Black-techs","published":1,"updated":"2019-09-28T08:51:00.864Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82n000xv1npsqxiplr8","content":"<h3 id=\"限流\"><a href=\"#限流\" class=\"headerlink\" title=\"限流\"></a>限流</h3><p><a href=\"http://www.itwendao.com/article/detail/357611.html\" target=\"_blank\" rel=\"noopener\">http://www.itwendao.com/article/detail/357611.html</a></p>\n<h3 id=\"缓存\"><a href=\"#缓存\" class=\"headerlink\" title=\"缓存\"></a>缓存</h3><h3 id=\"集合\"><a href=\"#集合\" class=\"headerlink\" title=\"集合\"></a>集合</h3><h4 id=\"BiMap\"><a href=\"#BiMap\" class=\"headerlink\" title=\"BiMap\"></a>BiMap</h4><h3 id=\"反射\"><a href=\"#反射\" class=\"headerlink\" title=\"反射\"></a>反射</h3><h3 id=\"并发\"><a href=\"#并发\" class=\"headerlink\" title=\"并发\"></a>并发</h3>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"限流\"><a href=\"#限流\" class=\"headerlink\" title=\"限流\"></a>限流</h3><p><a href=\"http://www.itwendao.com/article/detail/357611.html\" target=\"_blank\" rel=\"noopener\">http://www.itwendao.com/article/detail/357611.html</a></p>\n<h3 id=\"缓存\"><a href=\"#缓存\" class=\"headerlink\" title=\"缓存\"></a>缓存</h3><h3 id=\"集合\"><a href=\"#集合\" class=\"headerlink\" title=\"集合\"></a>集合</h3><h4 id=\"BiMap\"><a href=\"#BiMap\" class=\"headerlink\" title=\"BiMap\"></a>BiMap</h4><h3 id=\"反射\"><a href=\"#反射\" class=\"headerlink\" title=\"反射\"></a>反射</h3><h3 id=\"并发\"><a href=\"#并发\" class=\"headerlink\" title=\"并发\"></a>并发</h3>"},{"title":"Intellij-Useful-shortcuts","date":"2019-10-11T12:37:54.000Z","_content":"\nMain menu | Navigate | File Structure\nMain menu | View | Parameter Info\nMain menu | Navigate | Back\nMain menu | Navigate | Forward\nMain menu | Code | Move Statement Up\nMain menu | Code | Move Statement Down\nMain menu | Edit | Extend Selection\nEditor Actions | Extend Selection\nOther | Search Everywhere\nMain menu | View | Recent Files\nOther | Show Context Actions\nMain menu | Edit | Find | Replace...\nEditor Actions | Delete Line\nMain menu | Navigate | Implementation(s)\nMain menu | Run | Smart Step Into\nMain menu | Run | Run to Cursor\nMain menu | Run | Resume Program\nMain menu | View | Quick Documentation","source":"_posts/Intellij-Useful-shortcuts.md","raw":"---\ntitle: Intellij-Useful-shortcuts\ndate: 2019-10-11 20:37:54\ntags:\n---\n\nMain menu | Navigate | File Structure\nMain menu | View | Parameter Info\nMain menu | Navigate | Back\nMain menu | Navigate | Forward\nMain menu | Code | Move Statement Up\nMain menu | Code | Move Statement Down\nMain menu | Edit | Extend Selection\nEditor Actions | Extend Selection\nOther | Search Everywhere\nMain menu | View | Recent Files\nOther | Show Context Actions\nMain menu | Edit | Find | Replace...\nEditor Actions | Delete Line\nMain menu | Navigate | Implementation(s)\nMain menu | Run | Smart Step Into\nMain menu | Run | Run to Cursor\nMain menu | Run | Resume Program\nMain menu | View | Quick Documentation","slug":"Intellij-Useful-shortcuts","published":1,"updated":"2019-10-11T12:45:41.037Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82n000yv1npw73vkgsp","content":"<p>Main menu | Navigate | File Structure<br>Main menu | View | Parameter Info<br>Main menu | Navigate | Back<br>Main menu | Navigate | Forward<br>Main menu | Code | Move Statement Up<br>Main menu | Code | Move Statement Down<br>Main menu | Edit | Extend Selection<br>Editor Actions | Extend Selection<br>Other | Search Everywhere<br>Main menu | View | Recent Files<br>Other | Show Context Actions<br>Main menu | Edit | Find | Replace…<br>Editor Actions | Delete Line<br>Main menu | Navigate | Implementation(s)<br>Main menu | Run | Smart Step Into<br>Main menu | Run | Run to Cursor<br>Main menu | Run | Resume Program<br>Main menu | View | Quick Documentation</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Main menu | Navigate | File Structure<br>Main menu | View | Parameter Info<br>Main menu | Navigate | Back<br>Main menu | Navigate | Forward<br>Main menu | Code | Move Statement Up<br>Main menu | Code | Move Statement Down<br>Main menu | Edit | Extend Selection<br>Editor Actions | Extend Selection<br>Other | Search Everywhere<br>Main menu | View | Recent Files<br>Other | Show Context Actions<br>Main menu | Edit | Find | Replace…<br>Editor Actions | Delete Line<br>Main menu | Navigate | Implementation(s)<br>Main menu | Run | Smart Step Into<br>Main menu | Run | Run to Cursor<br>Main menu | Run | Resume Program<br>Main menu | View | Quick Documentation</p>\n"},{"title":"JDK-AQS","date":"2019-11-25T09:05:47.000Z","_content":"","source":"_posts/JDK-AQS.md","raw":"---\ntitle: JDK-AQS\ndate: 2019-11-25 17:05:47\ntags:\n---\n","slug":"JDK-AQS","published":1,"updated":"2019-11-25T09:05:47.113Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82n000zv1npfnjf2t9a","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"JDK-AbstractQueuedSynchronizer","date":"2019-11-25T09:07:21.000Z","_content":"\n\n### AQS内部三个基础组件：\n1. Unsafe.cas()\n2. LockSupport.park()/unpark()\n3. CLH Queue: sync queue & condition queue","source":"_posts/JDK-AbstractQueuedSynchronizer.md","raw":"---\ntitle: JDK-AbstractQueuedSynchronizer\ndate: 2019-11-25 17:07:21\ntags:\n---\n\n\n### AQS内部三个基础组件：\n1. Unsafe.cas()\n2. LockSupport.park()/unpark()\n3. CLH Queue: sync queue & condition queue","slug":"JDK-AbstractQueuedSynchronizer","published":1,"updated":"2019-11-28T08:21:19.381Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82o0010v1npx11t41b1","content":"<h3 id=\"AQS内部三个基础组件：\"><a href=\"#AQS内部三个基础组件：\" class=\"headerlink\" title=\"AQS内部三个基础组件：\"></a>AQS内部三个基础组件：</h3><ol>\n<li>Unsafe.cas()</li>\n<li>LockSupport.park()/unpark()</li>\n<li>CLH Queue: sync queue &amp; condition queue</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"AQS内部三个基础组件：\"><a href=\"#AQS内部三个基础组件：\" class=\"headerlink\" title=\"AQS内部三个基础组件：\"></a>AQS内部三个基础组件：</h3><ol>\n<li>Unsafe.cas()</li>\n<li>LockSupport.park()/unpark()</li>\n<li>CLH Queue: sync queue &amp; condition queue</li>\n</ol>\n"},{"title":"JVM-Classloader","date":"2018-08-28T09:47:54.000Z","_content":"\n\n### 怎么样设计一个程序，会有class冲突问题，然后用Classloader来解决问题？\n\n\n### \n断点:class_name._temp->index_of_at(0, \"Student\", 7) > -1\n\n\njvm_define_class_common(JNIEnv_*, char const*, _jobject*, signed char const*, int, _jobject*, char const*, Thread*) jvm.cpp:927\n::JVM_DefineClassWithSource(JNIEnv *, const char *, jobject, const jbyte *, jsize, jobject, const char *) jvm.cpp:960\nJava_java_lang_ClassLoader_defineClass1 ClassLoader.c:136\n<unknown> 0x0000000115fecbb0\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fbf9f1\nJavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:410\nos::os_exception_wrapper(void (*)(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*), JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) os_bsd.cpp:3682\nJavaCalls::call(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:306\nJavaCalls::call_virtual(JavaValue*, KlassHandle, Symbol*, Symbol*, JavaCallArguments*, Thread*) javaCalls.cpp:193\nJavaCalls::call_virtual(JavaValue*, Handle, KlassHandle, Symbol*, Symbol*, Handle, Thread*) javaCalls.cpp:206\nSystemDictionary::load_instance_class(Symbol*, Handle, Thread*) systemDictionary.cpp:1586\nSystemDictionary::resolve_instance_class_or_null(Symbol*, Handle, Handle, Thread*) systemDictionary.cpp:840\nSystemDictionary::resolve_or_null(Symbol*, Handle, Handle, Thread*) systemDictionary.cpp:248\nSystemDictionary::resolve_or_fail(Symbol*, Handle, Handle, bool, Thread*) systemDictionary.cpp:185\nConstantPool::klass_at_impl(constantPoolHandle const&, int, bool, Thread*) constantPool.cpp:256\nConstantPool::klass_at(int, Thread*) constantPool.hpp:342\nInterpreterRuntime::_new(JavaThread*, ConstantPool*, int) interpreterRuntime.cpp:141\n<unknown> 0x000000011600d6a9\n<unknown> 0x0000000115fbf9f1\nJavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:410\nos::os_exception_wrapper(void (*)(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*), JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) os_bsd.cpp:3682\nJavaCalls::call(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:306\njni_invoke_static(JNIEnv_*, JavaValue*, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) jni.cpp:1119\n::jni_CallStaticVoidMethod(JNIEnv *, jclass, jmethodID, ...) jni.cpp:1989\nJavaMain 0x000000010fa4dc90\n_pthread_body 0x00007fffc9ad493b\n_pthread_start 0x00007fffc9ad4887\nthread_start 0x00007fffc9ad408d","source":"_posts/JDK-Classloader.md","raw":"---\ntitle: JVM-Classloader\ndate: 2018-08-28 17:47:54\ntags: JVM\n---\n\n\n### 怎么样设计一个程序，会有class冲突问题，然后用Classloader来解决问题？\n\n\n### \n断点:class_name._temp->index_of_at(0, \"Student\", 7) > -1\n\n\njvm_define_class_common(JNIEnv_*, char const*, _jobject*, signed char const*, int, _jobject*, char const*, Thread*) jvm.cpp:927\n::JVM_DefineClassWithSource(JNIEnv *, const char *, jobject, const jbyte *, jsize, jobject, const char *) jvm.cpp:960\nJava_java_lang_ClassLoader_defineClass1 ClassLoader.c:136\n<unknown> 0x0000000115fecbb0\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fca220\n<unknown> 0x0000000115fbf9f1\nJavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:410\nos::os_exception_wrapper(void (*)(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*), JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) os_bsd.cpp:3682\nJavaCalls::call(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:306\nJavaCalls::call_virtual(JavaValue*, KlassHandle, Symbol*, Symbol*, JavaCallArguments*, Thread*) javaCalls.cpp:193\nJavaCalls::call_virtual(JavaValue*, Handle, KlassHandle, Symbol*, Symbol*, Handle, Thread*) javaCalls.cpp:206\nSystemDictionary::load_instance_class(Symbol*, Handle, Thread*) systemDictionary.cpp:1586\nSystemDictionary::resolve_instance_class_or_null(Symbol*, Handle, Handle, Thread*) systemDictionary.cpp:840\nSystemDictionary::resolve_or_null(Symbol*, Handle, Handle, Thread*) systemDictionary.cpp:248\nSystemDictionary::resolve_or_fail(Symbol*, Handle, Handle, bool, Thread*) systemDictionary.cpp:185\nConstantPool::klass_at_impl(constantPoolHandle const&, int, bool, Thread*) constantPool.cpp:256\nConstantPool::klass_at(int, Thread*) constantPool.hpp:342\nInterpreterRuntime::_new(JavaThread*, ConstantPool*, int) interpreterRuntime.cpp:141\n<unknown> 0x000000011600d6a9\n<unknown> 0x0000000115fbf9f1\nJavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:410\nos::os_exception_wrapper(void (*)(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*), JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) os_bsd.cpp:3682\nJavaCalls::call(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:306\njni_invoke_static(JNIEnv_*, JavaValue*, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) jni.cpp:1119\n::jni_CallStaticVoidMethod(JNIEnv *, jclass, jmethodID, ...) jni.cpp:1989\nJavaMain 0x000000010fa4dc90\n_pthread_body 0x00007fffc9ad493b\n_pthread_start 0x00007fffc9ad4887\nthread_start 0x00007fffc9ad408d","slug":"JDK-Classloader","published":1,"updated":"2019-09-28T08:51:00.865Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82o0011v1np8un7p2pb","content":"<h3 id=\"怎么样设计一个程序，会有class冲突问题，然后用Classloader来解决问题？\"><a href=\"#怎么样设计一个程序，会有class冲突问题，然后用Classloader来解决问题？\" class=\"headerlink\" title=\"怎么样设计一个程序，会有class冲突问题，然后用Classloader来解决问题？\"></a>怎么样设计一个程序，会有class冲突问题，然后用Classloader来解决问题？</h3><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>断点:class_name._temp-&gt;index_of_at(0, “Student”, 7) &gt; -1</p>\n<p>jvm_define_class_common(JNIEnv_<em>, char const</em>, <em>jobject<em>, signed char const</em>, int, _jobject<em>, char const</em>, Thread<em>) jvm.cpp:927<br>::JVM_DefineClassWithSource(JNIEnv *, const char *, jobject, const jbyte *, jsize, jobject, const char *) jvm.cpp:960<br>Java_java_lang_ClassLoader_defineClass1 ClassLoader.c:136<br><unknown> 0x0000000115fecbb0<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fbf9f1<br>JavaCalls::call_helper(JavaValue</unknown></unknown></unknown></unknown></unknown></unknown></unknown></unknown></unknown></unknown></em>, methodHandle const&amp;, JavaCallArguments<em>, Thread</em>) javaCalls.cpp:410<br>os::os_exception_wrapper(void (<em>)(JavaValue</em>, methodHandle const&amp;, JavaCallArguments<em>, Thread</em>), JavaValue<em>, methodHandle const&amp;, JavaCallArguments</em>, Thread<em>) os_bsd.cpp:3682<br>JavaCalls::call(JavaValue</em>, methodHandle const&amp;, JavaCallArguments<em>, Thread</em>) javaCalls.cpp:306<br>JavaCalls::call_virtual(JavaValue<em>, KlassHandle, Symbol</em>, Symbol<em>, JavaCallArguments</em>, Thread<em>) javaCalls.cpp:193<br>JavaCalls::call_virtual(JavaValue</em>, Handle, KlassHandle, Symbol<em>, Symbol</em>, Handle, Thread<em>) javaCalls.cpp:206<br>SystemDictionary::load_instance_class(Symbol</em>, Handle, Thread<em>) systemDictionary.cpp:1586<br>SystemDictionary::resolve_instance_class_or_null(Symbol</em>, Handle, Handle, Thread<em>) systemDictionary.cpp:840<br>SystemDictionary::resolve_or_null(Symbol</em>, Handle, Handle, Thread<em>) systemDictionary.cpp:248<br>SystemDictionary::resolve_or_fail(Symbol</em>, Handle, Handle, bool, Thread<em>) systemDictionary.cpp:185<br>ConstantPool::klass_at_impl(constantPoolHandle const&amp;, int, bool, Thread</em>) constantPool.cpp:256<br>ConstantPool::klass_at(int, Thread<em>) constantPool.hpp:342<br>InterpreterRuntime::_new(JavaThread</em>, ConstantPool<em>, int) interpreterRuntime.cpp:141<br><unknown> 0x000000011600d6a9<br><unknown> 0x0000000115fbf9f1<br>JavaCalls::call_helper(JavaValue</unknown></unknown></em>, methodHandle const&amp;, JavaCallArguments<em>, Thread</em>) javaCalls.cpp:410<br>os::os_exception_wrapper(void (<em>)(JavaValue</em>, methodHandle const&amp;, JavaCallArguments<em>, Thread</em>), JavaValue<em>, methodHandle const&amp;, JavaCallArguments</em>, Thread<em>) os_bsd.cpp:3682<br>JavaCalls::call(JavaValue</em>, methodHandle const&amp;, JavaCallArguments<em>, Thread</em>) javaCalls.cpp:306<br>jni_invoke_static(JNIEnv</em><em>, JavaValue</em>, _jobject<em>, JNICallType, _jmethodID</em>, JNI_ArgumentPusher<em>, Thread</em>) jni.cpp:1119<br>::jni_CallStaticVoidMethod(JNIEnv *, jclass, jmethodID, …) jni.cpp:1989<br>JavaMain 0x000000010fa4dc90<br>_pthread_body 0x00007fffc9ad493b<br>_pthread_start 0x00007fffc9ad4887<br>thread_start 0x00007fffc9ad408d</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"怎么样设计一个程序，会有class冲突问题，然后用Classloader来解决问题？\"><a href=\"#怎么样设计一个程序，会有class冲突问题，然后用Classloader来解决问题？\" class=\"headerlink\" title=\"怎么样设计一个程序，会有class冲突问题，然后用Classloader来解决问题？\"></a>怎么样设计一个程序，会有class冲突问题，然后用Classloader来解决问题？</h3><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>断点:class_name._temp-&gt;index_of_at(0, “Student”, 7) &gt; -1</p>\n<p>jvm_define_class_common(JNIEnv_<em>, char const</em>, <em>jobject<em>, signed char const</em>, int, _jobject<em>, char const</em>, Thread<em>) jvm.cpp:927<br>::JVM_DefineClassWithSource(JNIEnv *, const char *, jobject, const jbyte *, jsize, jobject, const char *) jvm.cpp:960<br>Java_java_lang_ClassLoader_defineClass1 ClassLoader.c:136<br><unknown> 0x0000000115fecbb0<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fca220<br><unknown> 0x0000000115fbf9f1<br>JavaCalls::call_helper(JavaValue</unknown></unknown></unknown></unknown></unknown></unknown></unknown></unknown></unknown></unknown></em>, methodHandle const&amp;, JavaCallArguments<em>, Thread</em>) javaCalls.cpp:410<br>os::os_exception_wrapper(void (<em>)(JavaValue</em>, methodHandle const&amp;, JavaCallArguments<em>, Thread</em>), JavaValue<em>, methodHandle const&amp;, JavaCallArguments</em>, Thread<em>) os_bsd.cpp:3682<br>JavaCalls::call(JavaValue</em>, methodHandle const&amp;, JavaCallArguments<em>, Thread</em>) javaCalls.cpp:306<br>JavaCalls::call_virtual(JavaValue<em>, KlassHandle, Symbol</em>, Symbol<em>, JavaCallArguments</em>, Thread<em>) javaCalls.cpp:193<br>JavaCalls::call_virtual(JavaValue</em>, Handle, KlassHandle, Symbol<em>, Symbol</em>, Handle, Thread<em>) javaCalls.cpp:206<br>SystemDictionary::load_instance_class(Symbol</em>, Handle, Thread<em>) systemDictionary.cpp:1586<br>SystemDictionary::resolve_instance_class_or_null(Symbol</em>, Handle, Handle, Thread<em>) systemDictionary.cpp:840<br>SystemDictionary::resolve_or_null(Symbol</em>, Handle, Handle, Thread<em>) systemDictionary.cpp:248<br>SystemDictionary::resolve_or_fail(Symbol</em>, Handle, Handle, bool, Thread<em>) systemDictionary.cpp:185<br>ConstantPool::klass_at_impl(constantPoolHandle const&amp;, int, bool, Thread</em>) constantPool.cpp:256<br>ConstantPool::klass_at(int, Thread<em>) constantPool.hpp:342<br>InterpreterRuntime::_new(JavaThread</em>, ConstantPool<em>, int) interpreterRuntime.cpp:141<br><unknown> 0x000000011600d6a9<br><unknown> 0x0000000115fbf9f1<br>JavaCalls::call_helper(JavaValue</unknown></unknown></em>, methodHandle const&amp;, JavaCallArguments<em>, Thread</em>) javaCalls.cpp:410<br>os::os_exception_wrapper(void (<em>)(JavaValue</em>, methodHandle const&amp;, JavaCallArguments<em>, Thread</em>), JavaValue<em>, methodHandle const&amp;, JavaCallArguments</em>, Thread<em>) os_bsd.cpp:3682<br>JavaCalls::call(JavaValue</em>, methodHandle const&amp;, JavaCallArguments<em>, Thread</em>) javaCalls.cpp:306<br>jni_invoke_static(JNIEnv</em><em>, JavaValue</em>, _jobject<em>, JNICallType, _jmethodID</em>, JNI_ArgumentPusher<em>, Thread</em>) jni.cpp:1119<br>::jni_CallStaticVoidMethod(JNIEnv *, jclass, jmethodID, …) jni.cpp:1989<br>JavaMain 0x000000010fa4dc90<br>_pthread_body 0x00007fffc9ad493b<br>_pthread_start 0x00007fffc9ad4887<br>thread_start 0x00007fffc9ad408d</p>\n"},{"title":"JDK-Condition","date":"2019-11-26T08:05:19.000Z","_content":"\n### 监视器锁的 wait/notify 机制的弊端\n通常情况下，调用wait方法，主要是因为一定的条件没有满足，这里把需要满足的事件或条件称作条件谓词。\n\n而另一方面，由synchronized的原理可知，所有调用了wait方法的线程，都会在同一个监视器锁的wait set中等待，这看上去很合理，但是却是该机制的短板所在——所有的线程都等待在同一个notify方法上(notify方法指notify()和notifyAll()两个方法，下同)。每一个调用wait方法的线程可能等待在不同的条件谓词上，但是有时候即使自己等待的条件并没有满足，线程也有可能被“别的线程的”notify方法唤醒，因为大家用的是同一个监视器锁。这就好比一个班上有几个重名的同学(使用相同的监视器锁)，老师喊了这个名字（notify方法），结果这几个同学全都站起来了（等待在监视器锁上的线程都被唤醒了）。\n\n这样一来，即使自己被唤醒后抢到了监视器锁，发现其实条件还是不满足，还是得调用wait方法挂起，就导致了很多无意义的时间和CPU资源的浪费。\n\n这一切的根源就在于在调用wait方法时没有办法来指明究竟是在等待什么样的条件谓词上，因此唤醒时，也不知道该唤醒谁，只能把所有的线程都唤醒了。\n\n因此，最好的方式是，线程在挂起时就指明了在什么样的条件谓词上挂起，同时，在等待的事件发生后，只唤醒等待在这个事件上的线程，而实现了这个思路的就是Condition接口。\n\n有了Condition接口，就可以在同一个锁上创建不同的唤醒条件，从而在一定条件谓词满足后，有针对性的唤醒特定的线程，而不是将所有等待的线程都唤醒。","source":"_posts/JDK-Condition.md","raw":"---\ntitle: JDK-Condition\ndate: 2019-11-26 16:05:19\ntags:\n---\n\n### 监视器锁的 wait/notify 机制的弊端\n通常情况下，调用wait方法，主要是因为一定的条件没有满足，这里把需要满足的事件或条件称作条件谓词。\n\n而另一方面，由synchronized的原理可知，所有调用了wait方法的线程，都会在同一个监视器锁的wait set中等待，这看上去很合理，但是却是该机制的短板所在——所有的线程都等待在同一个notify方法上(notify方法指notify()和notifyAll()两个方法，下同)。每一个调用wait方法的线程可能等待在不同的条件谓词上，但是有时候即使自己等待的条件并没有满足，线程也有可能被“别的线程的”notify方法唤醒，因为大家用的是同一个监视器锁。这就好比一个班上有几个重名的同学(使用相同的监视器锁)，老师喊了这个名字（notify方法），结果这几个同学全都站起来了（等待在监视器锁上的线程都被唤醒了）。\n\n这样一来，即使自己被唤醒后抢到了监视器锁，发现其实条件还是不满足，还是得调用wait方法挂起，就导致了很多无意义的时间和CPU资源的浪费。\n\n这一切的根源就在于在调用wait方法时没有办法来指明究竟是在等待什么样的条件谓词上，因此唤醒时，也不知道该唤醒谁，只能把所有的线程都唤醒了。\n\n因此，最好的方式是，线程在挂起时就指明了在什么样的条件谓词上挂起，同时，在等待的事件发生后，只唤醒等待在这个事件上的线程，而实现了这个思路的就是Condition接口。\n\n有了Condition接口，就可以在同一个锁上创建不同的唤醒条件，从而在一定条件谓词满足后，有针对性的唤醒特定的线程，而不是将所有等待的线程都唤醒。","slug":"JDK-Condition","published":1,"updated":"2019-11-26T08:06:27.927Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82p0012v1npogixco3w","content":"<h3 id=\"监视器锁的-wait-notify-机制的弊端\"><a href=\"#监视器锁的-wait-notify-机制的弊端\" class=\"headerlink\" title=\"监视器锁的 wait/notify 机制的弊端\"></a>监视器锁的 wait/notify 机制的弊端</h3><p>通常情况下，调用wait方法，主要是因为一定的条件没有满足，这里把需要满足的事件或条件称作条件谓词。</p>\n<p>而另一方面，由synchronized的原理可知，所有调用了wait方法的线程，都会在同一个监视器锁的wait set中等待，这看上去很合理，但是却是该机制的短板所在——所有的线程都等待在同一个notify方法上(notify方法指notify()和notifyAll()两个方法，下同)。每一个调用wait方法的线程可能等待在不同的条件谓词上，但是有时候即使自己等待的条件并没有满足，线程也有可能被“别的线程的”notify方法唤醒，因为大家用的是同一个监视器锁。这就好比一个班上有几个重名的同学(使用相同的监视器锁)，老师喊了这个名字（notify方法），结果这几个同学全都站起来了（等待在监视器锁上的线程都被唤醒了）。</p>\n<p>这样一来，即使自己被唤醒后抢到了监视器锁，发现其实条件还是不满足，还是得调用wait方法挂起，就导致了很多无意义的时间和CPU资源的浪费。</p>\n<p>这一切的根源就在于在调用wait方法时没有办法来指明究竟是在等待什么样的条件谓词上，因此唤醒时，也不知道该唤醒谁，只能把所有的线程都唤醒了。</p>\n<p>因此，最好的方式是，线程在挂起时就指明了在什么样的条件谓词上挂起，同时，在等待的事件发生后，只唤醒等待在这个事件上的线程，而实现了这个思路的就是Condition接口。</p>\n<p>有了Condition接口，就可以在同一个锁上创建不同的唤醒条件，从而在一定条件谓词满足后，有针对性的唤醒特定的线程，而不是将所有等待的线程都唤醒。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"监视器锁的-wait-notify-机制的弊端\"><a href=\"#监视器锁的-wait-notify-机制的弊端\" class=\"headerlink\" title=\"监视器锁的 wait/notify 机制的弊端\"></a>监视器锁的 wait/notify 机制的弊端</h3><p>通常情况下，调用wait方法，主要是因为一定的条件没有满足，这里把需要满足的事件或条件称作条件谓词。</p>\n<p>而另一方面，由synchronized的原理可知，所有调用了wait方法的线程，都会在同一个监视器锁的wait set中等待，这看上去很合理，但是却是该机制的短板所在——所有的线程都等待在同一个notify方法上(notify方法指notify()和notifyAll()两个方法，下同)。每一个调用wait方法的线程可能等待在不同的条件谓词上，但是有时候即使自己等待的条件并没有满足，线程也有可能被“别的线程的”notify方法唤醒，因为大家用的是同一个监视器锁。这就好比一个班上有几个重名的同学(使用相同的监视器锁)，老师喊了这个名字（notify方法），结果这几个同学全都站起来了（等待在监视器锁上的线程都被唤醒了）。</p>\n<p>这样一来，即使自己被唤醒后抢到了监视器锁，发现其实条件还是不满足，还是得调用wait方法挂起，就导致了很多无意义的时间和CPU资源的浪费。</p>\n<p>这一切的根源就在于在调用wait方法时没有办法来指明究竟是在等待什么样的条件谓词上，因此唤醒时，也不知道该唤醒谁，只能把所有的线程都唤醒了。</p>\n<p>因此，最好的方式是，线程在挂起时就指明了在什么样的条件谓词上挂起，同时，在等待的事件发生后，只唤醒等待在这个事件上的线程，而实现了这个思路的就是Condition接口。</p>\n<p>有了Condition接口，就可以在同一个锁上创建不同的唤醒条件，从而在一定条件谓词满足后，有针对性的唤醒特定的线程，而不是将所有等待的线程都唤醒。</p>\n"},{"title":"JDK-ConcurrentHashMap","date":"2019-11-25T09:05:54.000Z","_content":"\n\n### 内部的talbe用volatile修饰，`volatile Node<K,V>[] table`，这样做是无法让多个线程在读取数组的某一个元素时有volatile的语义（内存可见性语义），那为什么还要加volatile关键字？\n\n在ConcurrentHashMap的内部数组长度达到loadFactor阈值时（数组长度不大，但也发生treefy的时候也有可能扩容），需要进行扩容，\n```\nif (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {\n    try {\n        if (table == tab) {\n            @SuppressWarnings(\"unchecked\")\n            Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];\n            table = nt;\n            sc = n - (n >>> 2);\n        }\n    } finally {\n        sizeCtl = sc;\n    }\n}\n```\n\n### ConcurrentHashMap内部是一个volatile Node[]实现的，那么多线程获取数组的引用时，确实是达到了volatile的效果，但是多线程想要去获取数组Node[]的某一个元素时，怎么能保证每个线程看到的是最新的值？\n```\n/*\n    * Volatile access methods are used for table elements as well as\n    * elements of in-progress next table while resizing.  All uses of\n    * the tab arguments must be null checked by callers.  All callers\n    * also paranoically precheck that tab's length is not zero (or an\n    * equivalent check), thus ensuring that any index argument taking\n    * the form of a hash value anded with (length - 1) is a valid\n    * index.  Note that, to be correct wrt arbitrary concurrency\n    * errors by users, these checks must operate on local variables,\n    * which accounts for some odd-looking inline assignments below.\n    * Note that calls to setTabAt always occur within locked regions,\n    * and so in principle require only release ordering, not\n    * full volatile semantics, but are currently coded as volatile\n    * writes to be conservative.\n    */\n\n@SuppressWarnings(\"unchecked\")\nstatic final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {\n    return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);\n}\n```\n","source":"_posts/JDK-ConcurrentHashMap.md","raw":"---\ntitle: JDK-ConcurrentHashMap\ndate: 2019-11-25 17:05:54\ntags:\n---\n\n\n### 内部的talbe用volatile修饰，`volatile Node<K,V>[] table`，这样做是无法让多个线程在读取数组的某一个元素时有volatile的语义（内存可见性语义），那为什么还要加volatile关键字？\n\n在ConcurrentHashMap的内部数组长度达到loadFactor阈值时（数组长度不大，但也发生treefy的时候也有可能扩容），需要进行扩容，\n```\nif (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {\n    try {\n        if (table == tab) {\n            @SuppressWarnings(\"unchecked\")\n            Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];\n            table = nt;\n            sc = n - (n >>> 2);\n        }\n    } finally {\n        sizeCtl = sc;\n    }\n}\n```\n\n### ConcurrentHashMap内部是一个volatile Node[]实现的，那么多线程获取数组的引用时，确实是达到了volatile的效果，但是多线程想要去获取数组Node[]的某一个元素时，怎么能保证每个线程看到的是最新的值？\n```\n/*\n    * Volatile access methods are used for table elements as well as\n    * elements of in-progress next table while resizing.  All uses of\n    * the tab arguments must be null checked by callers.  All callers\n    * also paranoically precheck that tab's length is not zero (or an\n    * equivalent check), thus ensuring that any index argument taking\n    * the form of a hash value anded with (length - 1) is a valid\n    * index.  Note that, to be correct wrt arbitrary concurrency\n    * errors by users, these checks must operate on local variables,\n    * which accounts for some odd-looking inline assignments below.\n    * Note that calls to setTabAt always occur within locked regions,\n    * and so in principle require only release ordering, not\n    * full volatile semantics, but are currently coded as volatile\n    * writes to be conservative.\n    */\n\n@SuppressWarnings(\"unchecked\")\nstatic final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {\n    return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);\n}\n```\n","slug":"JDK-ConcurrentHashMap","published":1,"updated":"2019-12-02T03:30:03.906Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82p0013v1npjkqdti18","content":"<h3 id=\"内部的talbe用volatile修饰，volatile-Node-lt-K-V-gt-table，这样做是无法让多个线程在读取数组的某一个元素时有volatile的语义（内存可见性语义），那为什么还要加volatile关键字？\"><a href=\"#内部的talbe用volatile修饰，volatile-Node-lt-K-V-gt-table，这样做是无法让多个线程在读取数组的某一个元素时有volatile的语义（内存可见性语义），那为什么还要加volatile关键字？\" class=\"headerlink\" title=\"内部的talbe用volatile修饰，volatile Node&lt;K,V&gt;[] table，这样做是无法让多个线程在读取数组的某一个元素时有volatile的语义（内存可见性语义），那为什么还要加volatile关键字？\"></a>内部的talbe用volatile修饰，<code>volatile Node&lt;K,V&gt;[] table</code>，这样做是无法让多个线程在读取数组的某一个元素时有volatile的语义（内存可见性语义），那为什么还要加volatile关键字？</h3><p>在ConcurrentHashMap的内部数组长度达到loadFactor阈值时（数组长度不大，但也发生treefy的时候也有可能扩容），需要进行扩容，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        if (table == tab) &#123;</span><br><span class=\"line\">            @SuppressWarnings(&quot;unchecked&quot;)</span><br><span class=\"line\">            Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];</span><br><span class=\"line\">            table = nt;</span><br><span class=\"line\">            sc = n - (n &gt;&gt;&gt; 2);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; finally &#123;</span><br><span class=\"line\">        sizeCtl = sc;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"ConcurrentHashMap内部是一个volatile-Node-实现的，那么多线程获取数组的引用时，确实是达到了volatile的效果，但是多线程想要去获取数组Node-的某一个元素时，怎么能保证每个线程看到的是最新的值？\"><a href=\"#ConcurrentHashMap内部是一个volatile-Node-实现的，那么多线程获取数组的引用时，确实是达到了volatile的效果，但是多线程想要去获取数组Node-的某一个元素时，怎么能保证每个线程看到的是最新的值？\" class=\"headerlink\" title=\"ConcurrentHashMap内部是一个volatile Node[]实现的，那么多线程获取数组的引用时，确实是达到了volatile的效果，但是多线程想要去获取数组Node[]的某一个元素时，怎么能保证每个线程看到的是最新的值？\"></a>ConcurrentHashMap内部是一个volatile Node[]实现的，那么多线程获取数组的引用时，确实是达到了volatile的效果，但是多线程想要去获取数组Node[]的某一个元素时，怎么能保证每个线程看到的是最新的值？</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/*</span><br><span class=\"line\">    * Volatile access methods are used for table elements as well as</span><br><span class=\"line\">    * elements of in-progress next table while resizing.  All uses of</span><br><span class=\"line\">    * the tab arguments must be null checked by callers.  All callers</span><br><span class=\"line\">    * also paranoically precheck that tab&apos;s length is not zero (or an</span><br><span class=\"line\">    * equivalent check), thus ensuring that any index argument taking</span><br><span class=\"line\">    * the form of a hash value anded with (length - 1) is a valid</span><br><span class=\"line\">    * index.  Note that, to be correct wrt arbitrary concurrency</span><br><span class=\"line\">    * errors by users, these checks must operate on local variables,</span><br><span class=\"line\">    * which accounts for some odd-looking inline assignments below.</span><br><span class=\"line\">    * Note that calls to setTabAt always occur within locked regions,</span><br><span class=\"line\">    * and so in principle require only release ordering, not</span><br><span class=\"line\">    * full volatile semantics, but are currently coded as volatile</span><br><span class=\"line\">    * writes to be conservative.</span><br><span class=\"line\">    */</span><br><span class=\"line\"></span><br><span class=\"line\">@SuppressWarnings(&quot;unchecked&quot;)</span><br><span class=\"line\">static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123;</span><br><span class=\"line\">    return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"内部的talbe用volatile修饰，volatile-Node-lt-K-V-gt-table，这样做是无法让多个线程在读取数组的某一个元素时有volatile的语义（内存可见性语义），那为什么还要加volatile关键字？\"><a href=\"#内部的talbe用volatile修饰，volatile-Node-lt-K-V-gt-table，这样做是无法让多个线程在读取数组的某一个元素时有volatile的语义（内存可见性语义），那为什么还要加volatile关键字？\" class=\"headerlink\" title=\"内部的talbe用volatile修饰，volatile Node&lt;K,V&gt;[] table，这样做是无法让多个线程在读取数组的某一个元素时有volatile的语义（内存可见性语义），那为什么还要加volatile关键字？\"></a>内部的talbe用volatile修饰，<code>volatile Node&lt;K,V&gt;[] table</code>，这样做是无法让多个线程在读取数组的某一个元素时有volatile的语义（内存可见性语义），那为什么还要加volatile关键字？</h3><p>在ConcurrentHashMap的内部数组长度达到loadFactor阈值时（数组长度不大，但也发生treefy的时候也有可能扩容），需要进行扩容，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        if (table == tab) &#123;</span><br><span class=\"line\">            @SuppressWarnings(&quot;unchecked&quot;)</span><br><span class=\"line\">            Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];</span><br><span class=\"line\">            table = nt;</span><br><span class=\"line\">            sc = n - (n &gt;&gt;&gt; 2);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; finally &#123;</span><br><span class=\"line\">        sizeCtl = sc;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"ConcurrentHashMap内部是一个volatile-Node-实现的，那么多线程获取数组的引用时，确实是达到了volatile的效果，但是多线程想要去获取数组Node-的某一个元素时，怎么能保证每个线程看到的是最新的值？\"><a href=\"#ConcurrentHashMap内部是一个volatile-Node-实现的，那么多线程获取数组的引用时，确实是达到了volatile的效果，但是多线程想要去获取数组Node-的某一个元素时，怎么能保证每个线程看到的是最新的值？\" class=\"headerlink\" title=\"ConcurrentHashMap内部是一个volatile Node[]实现的，那么多线程获取数组的引用时，确实是达到了volatile的效果，但是多线程想要去获取数组Node[]的某一个元素时，怎么能保证每个线程看到的是最新的值？\"></a>ConcurrentHashMap内部是一个volatile Node[]实现的，那么多线程获取数组的引用时，确实是达到了volatile的效果，但是多线程想要去获取数组Node[]的某一个元素时，怎么能保证每个线程看到的是最新的值？</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/*</span><br><span class=\"line\">    * Volatile access methods are used for table elements as well as</span><br><span class=\"line\">    * elements of in-progress next table while resizing.  All uses of</span><br><span class=\"line\">    * the tab arguments must be null checked by callers.  All callers</span><br><span class=\"line\">    * also paranoically precheck that tab&apos;s length is not zero (or an</span><br><span class=\"line\">    * equivalent check), thus ensuring that any index argument taking</span><br><span class=\"line\">    * the form of a hash value anded with (length - 1) is a valid</span><br><span class=\"line\">    * index.  Note that, to be correct wrt arbitrary concurrency</span><br><span class=\"line\">    * errors by users, these checks must operate on local variables,</span><br><span class=\"line\">    * which accounts for some odd-looking inline assignments below.</span><br><span class=\"line\">    * Note that calls to setTabAt always occur within locked regions,</span><br><span class=\"line\">    * and so in principle require only release ordering, not</span><br><span class=\"line\">    * full volatile semantics, but are currently coded as volatile</span><br><span class=\"line\">    * writes to be conservative.</span><br><span class=\"line\">    */</span><br><span class=\"line\"></span><br><span class=\"line\">@SuppressWarnings(&quot;unchecked&quot;)</span><br><span class=\"line\">static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123;</span><br><span class=\"line\">    return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"JDK-CLH-Lock","date":"2019-05-27T14:10:42.000Z","_content":"\n\nhttps://www.cnblogs.com/llkmst/p/4895478.html\nCLH(Craig, Landin, and Hagersten  locks): 是一个自旋锁，能确保无饥饿性，提供先来先服务的公平性。\nCLH锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。","source":"_posts/JDK-CLH-Lock.md","raw":"---\ntitle: JDK-CLH-Lock\ndate: 2019-05-27 22:10:42\ntags:\n---\n\n\nhttps://www.cnblogs.com/llkmst/p/4895478.html\nCLH(Craig, Landin, and Hagersten  locks): 是一个自旋锁，能确保无饥饿性，提供先来先服务的公平性。\nCLH锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。","slug":"JDK-CLH-Lock","published":1,"updated":"2019-09-28T08:51:00.865Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82q0014v1np1olo9ijd","content":"<p><a href=\"https://www.cnblogs.com/llkmst/p/4895478.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/llkmst/p/4895478.html</a><br>CLH(Craig, Landin, and Hagersten  locks): 是一个自旋锁，能确保无饥饿性，提供先来先服务的公平性。<br>CLH锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.cnblogs.com/llkmst/p/4895478.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/llkmst/p/4895478.html</a><br>CLH(Craig, Landin, and Hagersten  locks): 是一个自旋锁，能确保无饥饿性，提供先来先服务的公平性。<br>CLH锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。</p>\n"},{"title":"JDK-CountDownLatch","date":"2019-11-25T09:09:43.000Z","_content":"","source":"_posts/JDK-CountDownLatch.md","raw":"---\ntitle: JDK-CountDownLatch\ndate: 2019-11-25 17:09:43\ntags:\n---\n","slug":"JDK-CountDownLatch","published":1,"updated":"2019-11-25T09:09:44.001Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82q0015v1npe7mm8r71","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"JDK-CopyOnWriteArrayList","date":"2019-11-25T09:13:55.000Z","_content":"","source":"_posts/JDK-CopyOnWriteArrayList.md","raw":"---\ntitle: JDK-CopyOnWriteArrayList\ndate: 2019-11-25 17:13:55\ntags:\n---\n","slug":"JDK-CopyOnWriteArrayList","published":1,"updated":"2019-11-25T09:13:55.912Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82q0016v1npin858qmp","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"JDK-ReentrantLock","date":"2019-11-26T08:17:49.000Z","_content":"\n### 为什么用了ReentrantLock后，在lock()和unlock()之间，不用担心指令重排序的？\n\n### 为什么用CAS加锁的{}中，需要对数据加volatile限定词？","source":"_posts/JDK-ReentrantLock.md","raw":"---\ntitle: JDK-ReentrantLock\ndate: 2019-11-26 16:17:49\ntags:\n---\n\n### 为什么用了ReentrantLock后，在lock()和unlock()之间，不用担心指令重排序的？\n\n### 为什么用CAS加锁的{}中，需要对数据加volatile限定词？","slug":"JDK-ReentrantLock","published":1,"updated":"2019-11-26T08:22:34.844Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82r0017v1np38pn6x8w","content":"<h3 id=\"为什么用了ReentrantLock后，在lock-和unlock-之间，不用担心指令重排序的？\"><a href=\"#为什么用了ReentrantLock后，在lock-和unlock-之间，不用担心指令重排序的？\" class=\"headerlink\" title=\"为什么用了ReentrantLock后，在lock()和unlock()之间，不用担心指令重排序的？\"></a>为什么用了ReentrantLock后，在lock()和unlock()之间，不用担心指令重排序的？</h3><h3 id=\"为什么用CAS加锁的-中，需要对数据加volatile限定词？\"><a href=\"#为什么用CAS加锁的-中，需要对数据加volatile限定词？\" class=\"headerlink\" title=\"为什么用CAS加锁的{}中，需要对数据加volatile限定词？\"></a>为什么用CAS加锁的{}中，需要对数据加volatile限定词？</h3>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"为什么用了ReentrantLock后，在lock-和unlock-之间，不用担心指令重排序的？\"><a href=\"#为什么用了ReentrantLock后，在lock-和unlock-之间，不用担心指令重排序的？\" class=\"headerlink\" title=\"为什么用了ReentrantLock后，在lock()和unlock()之间，不用担心指令重排序的？\"></a>为什么用了ReentrantLock后，在lock()和unlock()之间，不用担心指令重排序的？</h3><h3 id=\"为什么用CAS加锁的-中，需要对数据加volatile限定词？\"><a href=\"#为什么用CAS加锁的-中，需要对数据加volatile限定词？\" class=\"headerlink\" title=\"为什么用CAS加锁的{}中，需要对数据加volatile限定词？\"></a>为什么用CAS加锁的{}中，需要对数据加volatile限定词？</h3>"},{"title":"JDK-ExecutorService","date":"2019-03-01T10:15:50.000Z","_content":"\n\n\n写得非常好\nhttps://mp.weixin.qq.com/s/z2V9YqI7zuLHW4D0HM7yzg","source":"_posts/JDK-ExecutorService.md","raw":"---\ntitle: JDK-ExecutorService\ndate: 2019-03-01 18:15:50\ntags:\n---\n\n\n\n写得非常好\nhttps://mp.weixin.qq.com/s/z2V9YqI7zuLHW4D0HM7yzg","slug":"JDK-ExecutorService","published":1,"updated":"2019-09-28T08:51:00.865Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82r0018v1np40j9a2lg","content":"<p>写得非常好<br><a href=\"https://mp.weixin.qq.com/s/z2V9YqI7zuLHW4D0HM7yzg\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/z2V9YqI7zuLHW4D0HM7yzg</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>写得非常好<br><a href=\"https://mp.weixin.qq.com/s/z2V9YqI7zuLHW4D0HM7yzg\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/z2V9YqI7zuLHW4D0HM7yzg</a></p>\n"},{"title":"JVM-JUC","date":"2018-11-05T08:41:09.000Z","_content":"\n\n### 死磕JUC大作\nhttps://blog.csdn.net/chenssy/article/details/81154894","source":"_posts/JDK-JUC.md","raw":"---\ntitle: JVM-JUC\ndate: 2018-11-05 16:41:09\ntags: JVM\n---\n\n\n### 死磕JUC大作\nhttps://blog.csdn.net/chenssy/article/details/81154894","slug":"JDK-JUC","published":1,"updated":"2019-09-28T08:51:00.865Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82s0019v1np0n4p3662","content":"<h3 id=\"死磕JUC大作\"><a href=\"#死磕JUC大作\" class=\"headerlink\" title=\"死磕JUC大作\"></a>死磕JUC大作</h3><p><a href=\"https://blog.csdn.net/chenssy/article/details/81154894\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/chenssy/article/details/81154894</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"死磕JUC大作\"><a href=\"#死磕JUC大作\" class=\"headerlink\" title=\"死磕JUC大作\"></a>死磕JUC大作</h3><p><a href=\"https://blog.csdn.net/chenssy/article/details/81154894\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/chenssy/article/details/81154894</a></p>\n"},{"title":"JDK-Semaphore","date":"2019-11-25T09:10:36.000Z","_content":"","source":"_posts/JDK-Semaphore.md","raw":"---\ntitle: JDK-Semaphore\ndate: 2019-11-25 17:10:36\ntags:\n---\n","slug":"JDK-Semaphore","published":1,"updated":"2019-11-25T09:10:36.040Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82s001av1np6ce4aow9","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"JDK-ReentrantReadWriteLock","date":"2019-11-25T08:35:19.000Z","_content":"\n### ReentrantReadWriteLock默认的实现中，怎么保证写操作不被大量的读操作饿死\n每次在尝试获取读锁时，会去check下等待队列的队头是不是exclusive(写线程)的线程，如果是的话，当前的读线程先block住，让写线程优先去竞争锁。这样写线程就不会饿死。","source":"_posts/JDK-ReentrantReadWriteLock.md","raw":"---\ntitle: JDK-ReentrantReadWriteLock\ndate: 2019-11-25 16:35:19\ntags:\n---\n\n### ReentrantReadWriteLock默认的实现中，怎么保证写操作不被大量的读操作饿死\n每次在尝试获取读锁时，会去check下等待队列的队头是不是exclusive(写线程)的线程，如果是的话，当前的读线程先block住，让写线程优先去竞争锁。这样写线程就不会饿死。","slug":"JDK-ReentrantReadWriteLock","published":1,"updated":"2019-11-25T08:44:15.257Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82s001bv1npi95e3scn","content":"<h3 id=\"ReentrantReadWriteLock默认的实现中，怎么保证写操作不被大量的读操作饿死\"><a href=\"#ReentrantReadWriteLock默认的实现中，怎么保证写操作不被大量的读操作饿死\" class=\"headerlink\" title=\"ReentrantReadWriteLock默认的实现中，怎么保证写操作不被大量的读操作饿死\"></a>ReentrantReadWriteLock默认的实现中，怎么保证写操作不被大量的读操作饿死</h3><p>每次在尝试获取读锁时，会去check下等待队列的队头是不是exclusive(写线程)的线程，如果是的话，当前的读线程先block住，让写线程优先去竞争锁。这样写线程就不会饿死。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"ReentrantReadWriteLock默认的实现中，怎么保证写操作不被大量的读操作饿死\"><a href=\"#ReentrantReadWriteLock默认的实现中，怎么保证写操作不被大量的读操作饿死\" class=\"headerlink\" title=\"ReentrantReadWriteLock默认的实现中，怎么保证写操作不被大量的读操作饿死\"></a>ReentrantReadWriteLock默认的实现中，怎么保证写操作不被大量的读操作饿死</h3><p>每次在尝试获取读锁时，会去check下等待队列的队头是不是exclusive(写线程)的线程，如果是的话，当前的读线程先block住，让写线程优先去竞争锁。这样写线程就不会饿死。</p>\n"},{"title":"JDK-ThreadPoolExecutor","date":"2019-11-27T09:27:56.000Z","_content":"\n\n\n### 一个Worker代表着一个线程，如果某个Worker长时间没有从队列中取到任务，为了节省系统资源，会不会把线程给关闭掉？","source":"_posts/JDK-ThreadPoolExecutor.md","raw":"---\ntitle: JDK-ThreadPoolExecutor\ndate: 2019-11-27 17:27:56\ntags:\n---\n\n\n\n### 一个Worker代表着一个线程，如果某个Worker长时间没有从队列中取到任务，为了节省系统资源，会不会把线程给关闭掉？","slug":"JDK-ThreadPoolExecutor","published":1,"updated":"2019-11-27T09:42:52.471Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82t001cv1npjpdvmqvs","content":"<h3 id=\"一个Worker代表着一个线程，如果某个Worker长时间没有从队列中取到任务，为了节省系统资源，会不会把线程给关闭掉？\"><a href=\"#一个Worker代表着一个线程，如果某个Worker长时间没有从队列中取到任务，为了节省系统资源，会不会把线程给关闭掉？\" class=\"headerlink\" title=\"一个Worker代表着一个线程，如果某个Worker长时间没有从队列中取到任务，为了节省系统资源，会不会把线程给关闭掉？\"></a>一个Worker代表着一个线程，如果某个Worker长时间没有从队列中取到任务，为了节省系统资源，会不会把线程给关闭掉？</h3>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"一个Worker代表着一个线程，如果某个Worker长时间没有从队列中取到任务，为了节省系统资源，会不会把线程给关闭掉？\"><a href=\"#一个Worker代表着一个线程，如果某个Worker长时间没有从队列中取到任务，为了节省系统资源，会不会把线程给关闭掉？\" class=\"headerlink\" title=\"一个Worker代表着一个线程，如果某个Worker长时间没有从队列中取到任务，为了节省系统资源，会不会把线程给关闭掉？\"></a>一个Worker代表着一个线程，如果某个Worker长时间没有从队列中取到任务，为了节省系统资源，会不会把线程给关闭掉？</h3>"},{"title":"JMM-Double-Checked-Locking","date":"2019-11-28T03:35:38.000Z","_content":"\n\n### 基于现在的JMM Spec, DCL为什么一定要加volatile，如果不加，会有什么问题？\nhttps://stackoverflow.com/questions/7855700/why-is-volatile-used-in-double-checked-locking\n\nhttp://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/\n\nThe \"Double-Checked Locking is Broken\" Declaration\nhttp://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html","source":"_posts/JMM-Double-Checked-Locking.md","raw":"---\ntitle: JMM-Double-Checked-Locking\ndate: 2019-11-28 11:35:38\ntags:\n---\n\n\n### 基于现在的JMM Spec, DCL为什么一定要加volatile，如果不加，会有什么问题？\nhttps://stackoverflow.com/questions/7855700/why-is-volatile-used-in-double-checked-locking\n\nhttp://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/\n\nThe \"Double-Checked Locking is Broken\" Declaration\nhttp://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html","slug":"JMM-Double-Checked-Locking","published":1,"updated":"2019-11-28T07:12:11.828Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82t001dv1nprlv7slvq","content":"<h3 id=\"基于现在的JMM-Spec-DCL为什么一定要加volatile，如果不加，会有什么问题？\"><a href=\"#基于现在的JMM-Spec-DCL为什么一定要加volatile，如果不加，会有什么问题？\" class=\"headerlink\" title=\"基于现在的JMM Spec, DCL为什么一定要加volatile，如果不加，会有什么问题？\"></a>基于现在的JMM Spec, DCL为什么一定要加volatile，如果不加，会有什么问题？</h3><p><a href=\"https://stackoverflow.com/questions/7855700/why-is-volatile-used-in-double-checked-locking\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/7855700/why-is-volatile-used-in-double-checked-locking</a></p>\n<p><a href=\"http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/\" target=\"_blank\" rel=\"noopener\">http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/</a></p>\n<p>The “Double-Checked Locking is Broken” Declaration<br><a href=\"http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"基于现在的JMM-Spec-DCL为什么一定要加volatile，如果不加，会有什么问题？\"><a href=\"#基于现在的JMM-Spec-DCL为什么一定要加volatile，如果不加，会有什么问题？\" class=\"headerlink\" title=\"基于现在的JMM Spec, DCL为什么一定要加volatile，如果不加，会有什么问题？\"></a>基于现在的JMM Spec, DCL为什么一定要加volatile，如果不加，会有什么问题？</h3><p><a href=\"https://stackoverflow.com/questions/7855700/why-is-volatile-used-in-double-checked-locking\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/7855700/why-is-volatile-used-in-double-checked-locking</a></p>\n<p><a href=\"http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/\" target=\"_blank\" rel=\"noopener\">http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/</a></p>\n<p>The “Double-Checked Locking is Broken” Declaration<br><a href=\"http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html</a></p>\n"},{"title":"JVM-Atomic-operation","date":"2017-11-09T02:12:31.000Z","_content":"\n### Volatile关键词\n\nvolatile的实现原理\n\n1.可见性\n\n处理器为了提高处理速度，不直接和内存进行通讯，而是将系统内存的数据独到内部缓存后再进行操作，但操作完后不知什么时候会写到内存。\n\n如果对声明了volatile变量进行写操作时，JVM会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写会到系统内存。 这一步确保了如果有其他线程对声明了volatile变量进行修改，则立即更新主内存中数据。\n\n但这时候其他处理器的缓存还是旧的，所以在多处理器环境下，为了保证各个处理器缓存一致，每个处理会通过嗅探在总线上传播的数据来检查 自己的缓存是否过期，当处理器发现自己缓存行对应的内存地址被修改了，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作时，会强制重新从系统内存把数据读到处理器缓存里。 这一步确保了其他线程获得的声明了volatile变量都是从主内存中获取最新的。\n\n2.有序性\n\nLock前缀指令实际上相当于一个内存屏障（也成内存栅栏），它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成。\n\n作者：Ruheng\n链接：http://www.jianshu.com/p/7798161d7472\n來源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n#### 主内存与线程工作内存\n\n### MVCC Copy on write\n\nCopyOnWriteArrayList 实现细节\n\n``` java\npublic class CopyOnWriteArrayList<E> {\n    /** The lock protecting all mutators */\n    final transient ReentrantLock lock = new ReentrantLock();\n\n    /** The array, accessed only via getArray/setArray. */\n    private transient volatile Object[] array;\n\n    /**\n     * Gets the array.  Non-private so as to also be accessible\n     * from CopyOnWriteArraySet class.\n     */\n    final Object[] getArray() {\n        return array;\n    }\n\n    /**\n     * Sets the array.\n     */\n    final void setArray(Object[] a) {\n        array = a;\n    }\n\n    /**\n     * {@inheritDoc}\n     *\n     * @throws IndexOutOfBoundsException {@inheritDoc}\n     */\n    public E get(int index) {\n        return get(getArray(), index);\n    }\n\n    /**\n     * Appends the specified element to the end of this list.\n     *\n     * @param e element to be appended to this list\n     * @return {@code true} (as specified by {@link Collection#add})\n     */\n    public boolean add(E e) {\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            Object[] elements = getArray();\n            int len = elements.length;\n            Object[] newElements = Arrays.copyOf(elements, len + 1);\n            newElements[len] = e;\n            setArray(newElements);\n            return true;\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    /**\n     * Removes the element at the specified position in this list.\n     * Shifts any subsequent elements to the left (subtracts one from their\n     * indices).  Returns the element that was removed from the list.\n     *\n     * @throws IndexOutOfBoundsException {@inheritDoc}\n     */\n    public E remove(int index) {\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            Object[] elements = getArray();\n            int len = elements.length;\n            E oldValue = get(elements, index);\n            int numMoved = len - index - 1;\n            if (numMoved == 0)\n                setArray(Arrays.copyOf(elements, len - 1));\n            else {\n                Object[] newElements = new Object[len - 1];\n                System.arraycopy(elements, 0, newElements, 0, index);\n                System.arraycopy(elements, index + 1, newElements, index,\n                                 numMoved);\n                setArray(newElements);\n            }\n            return oldValue;\n        } finally {\n            lock.unlock();\n        }\n    }\n\n   \n}\n```\n\n可以看到，对CopyOnWriteArrayList的「写」操作，代码中都是有加互斥锁——ReentrantLock的，而对于「读」操作，没有任何锁机制。所以也就决定了CopyOnWriteArrayList一般在有大量并发读，少量并发写的场景下使用。\n\n> 参考：http://www.cnblogs.com/aigongsi/archive/2012/04/01/2429166.html\n\n七、volatile的应用场景\n\nsynchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：\n\n1）对变量的写操作不依赖于当前值\n\n2）该变量没有包含在具有其他变量的不变式中\n\n下面列举几个Java中使用volatile的几个场景。\n\n①.状态标记量\n\n``` java\nvolatile boolean flag = false;\n //线程1\nwhile(!flag){\n    doSomething();\n}\n  //线程2\npublic void setFlag() {\n    flag = true;\n}\n```\n\n根据状态标记，终止线程。\n\n②.单例模式中的double check\n\n``` java\nclass Singleton{\n    private volatile static Singleton instance = null;\n\n    private Singleton() {\n\n    }\n\n    public static Singleton getInstance() {\n        if(instance==null) {\n            synchronized (Singleton.class) {\n                if(instance==null)\n                    instance = new Singleton();\n            }\n        }\n        return instance;\n    }\n}\n```\n\n\n为什么要使用volatile 修饰instance？\n\n主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情:\n\n1.给 instance 分配内存\n\n2.调用 Singleton 的构造函数来初始化成员变量\n\n3.将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了）。\n\n但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。\n\n作者：Ruheng\n链接：http://www.jianshu.com/p/7798161d7472\n來源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","source":"_posts/JVM-Atomic-operation.md","raw":"---\ntitle: JVM-Atomic-operation\ndate: 2017-11-09 10:12:31\ntags: JVM\n---\n\n### Volatile关键词\n\nvolatile的实现原理\n\n1.可见性\n\n处理器为了提高处理速度，不直接和内存进行通讯，而是将系统内存的数据独到内部缓存后再进行操作，但操作完后不知什么时候会写到内存。\n\n如果对声明了volatile变量进行写操作时，JVM会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写会到系统内存。 这一步确保了如果有其他线程对声明了volatile变量进行修改，则立即更新主内存中数据。\n\n但这时候其他处理器的缓存还是旧的，所以在多处理器环境下，为了保证各个处理器缓存一致，每个处理会通过嗅探在总线上传播的数据来检查 自己的缓存是否过期，当处理器发现自己缓存行对应的内存地址被修改了，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作时，会强制重新从系统内存把数据读到处理器缓存里。 这一步确保了其他线程获得的声明了volatile变量都是从主内存中获取最新的。\n\n2.有序性\n\nLock前缀指令实际上相当于一个内存屏障（也成内存栅栏），它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成。\n\n作者：Ruheng\n链接：http://www.jianshu.com/p/7798161d7472\n來源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n#### 主内存与线程工作内存\n\n### MVCC Copy on write\n\nCopyOnWriteArrayList 实现细节\n\n``` java\npublic class CopyOnWriteArrayList<E> {\n    /** The lock protecting all mutators */\n    final transient ReentrantLock lock = new ReentrantLock();\n\n    /** The array, accessed only via getArray/setArray. */\n    private transient volatile Object[] array;\n\n    /**\n     * Gets the array.  Non-private so as to also be accessible\n     * from CopyOnWriteArraySet class.\n     */\n    final Object[] getArray() {\n        return array;\n    }\n\n    /**\n     * Sets the array.\n     */\n    final void setArray(Object[] a) {\n        array = a;\n    }\n\n    /**\n     * {@inheritDoc}\n     *\n     * @throws IndexOutOfBoundsException {@inheritDoc}\n     */\n    public E get(int index) {\n        return get(getArray(), index);\n    }\n\n    /**\n     * Appends the specified element to the end of this list.\n     *\n     * @param e element to be appended to this list\n     * @return {@code true} (as specified by {@link Collection#add})\n     */\n    public boolean add(E e) {\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            Object[] elements = getArray();\n            int len = elements.length;\n            Object[] newElements = Arrays.copyOf(elements, len + 1);\n            newElements[len] = e;\n            setArray(newElements);\n            return true;\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    /**\n     * Removes the element at the specified position in this list.\n     * Shifts any subsequent elements to the left (subtracts one from their\n     * indices).  Returns the element that was removed from the list.\n     *\n     * @throws IndexOutOfBoundsException {@inheritDoc}\n     */\n    public E remove(int index) {\n        final ReentrantLock lock = this.lock;\n        lock.lock();\n        try {\n            Object[] elements = getArray();\n            int len = elements.length;\n            E oldValue = get(elements, index);\n            int numMoved = len - index - 1;\n            if (numMoved == 0)\n                setArray(Arrays.copyOf(elements, len - 1));\n            else {\n                Object[] newElements = new Object[len - 1];\n                System.arraycopy(elements, 0, newElements, 0, index);\n                System.arraycopy(elements, index + 1, newElements, index,\n                                 numMoved);\n                setArray(newElements);\n            }\n            return oldValue;\n        } finally {\n            lock.unlock();\n        }\n    }\n\n   \n}\n```\n\n可以看到，对CopyOnWriteArrayList的「写」操作，代码中都是有加互斥锁——ReentrantLock的，而对于「读」操作，没有任何锁机制。所以也就决定了CopyOnWriteArrayList一般在有大量并发读，少量并发写的场景下使用。\n\n> 参考：http://www.cnblogs.com/aigongsi/archive/2012/04/01/2429166.html\n\n七、volatile的应用场景\n\nsynchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：\n\n1）对变量的写操作不依赖于当前值\n\n2）该变量没有包含在具有其他变量的不变式中\n\n下面列举几个Java中使用volatile的几个场景。\n\n①.状态标记量\n\n``` java\nvolatile boolean flag = false;\n //线程1\nwhile(!flag){\n    doSomething();\n}\n  //线程2\npublic void setFlag() {\n    flag = true;\n}\n```\n\n根据状态标记，终止线程。\n\n②.单例模式中的double check\n\n``` java\nclass Singleton{\n    private volatile static Singleton instance = null;\n\n    private Singleton() {\n\n    }\n\n    public static Singleton getInstance() {\n        if(instance==null) {\n            synchronized (Singleton.class) {\n                if(instance==null)\n                    instance = new Singleton();\n            }\n        }\n        return instance;\n    }\n}\n```\n\n\n为什么要使用volatile 修饰instance？\n\n主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情:\n\n1.给 instance 分配内存\n\n2.调用 Singleton 的构造函数来初始化成员变量\n\n3.将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了）。\n\n但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。\n\n作者：Ruheng\n链接：http://www.jianshu.com/p/7798161d7472\n來源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","slug":"JVM-Atomic-operation","published":1,"updated":"2019-09-28T08:51:00.866Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82u001ev1np83aqshpy","content":"<h3 id=\"Volatile关键词\"><a href=\"#Volatile关键词\" class=\"headerlink\" title=\"Volatile关键词\"></a>Volatile关键词</h3><p>volatile的实现原理</p>\n<p>1.可见性</p>\n<p>处理器为了提高处理速度，不直接和内存进行通讯，而是将系统内存的数据独到内部缓存后再进行操作，但操作完后不知什么时候会写到内存。</p>\n<p>如果对声明了volatile变量进行写操作时，JVM会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写会到系统内存。 这一步确保了如果有其他线程对声明了volatile变量进行修改，则立即更新主内存中数据。</p>\n<p>但这时候其他处理器的缓存还是旧的，所以在多处理器环境下，为了保证各个处理器缓存一致，每个处理会通过嗅探在总线上传播的数据来检查 自己的缓存是否过期，当处理器发现自己缓存行对应的内存地址被修改了，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作时，会强制重新从系统内存把数据读到处理器缓存里。 这一步确保了其他线程获得的声明了volatile变量都是从主内存中获取最新的。</p>\n<p>2.有序性</p>\n<p>Lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成。</p>\n<p>作者：Ruheng<br>链接：<a href=\"http://www.jianshu.com/p/7798161d7472\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/7798161d7472</a><br>來源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>\n<h4 id=\"主内存与线程工作内存\"><a href=\"#主内存与线程工作内存\" class=\"headerlink\" title=\"主内存与线程工作内存\"></a>主内存与线程工作内存</h4><h3 id=\"MVCC-Copy-on-write\"><a href=\"#MVCC-Copy-on-write\" class=\"headerlink\" title=\"MVCC Copy on write\"></a>MVCC Copy on write</h3><p>CopyOnWriteArrayList 实现细节</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CopyOnWriteArrayList</span>&lt;<span class=\"title\">E</span>&gt; </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/** The lock protecting all mutators */</span></span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">transient</span> ReentrantLock lock = <span class=\"keyword\">new</span> ReentrantLock();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** The array, accessed only via getArray/setArray. */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">transient</span> <span class=\"keyword\">volatile</span> Object[] array;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Gets the array.  Non-private so as to also be accessible</span></span><br><span class=\"line\"><span class=\"comment\">     * from CopyOnWriteArraySet class.</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">final</span> Object[] getArray() &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> array;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Sets the array.</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">setArray</span><span class=\"params\">(Object[] a)</span> </span>&#123;</span><br><span class=\"line\">        array = a;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * &#123;<span class=\"doctag\">@inheritDoc</span>&#125;</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IndexOutOfBoundsException &#123;<span class=\"doctag\">@inheritDoc</span>&#125;</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> E <span class=\"title\">get</span><span class=\"params\">(<span class=\"keyword\">int</span> index)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> get(getArray(), index);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Appends the specified element to the end of this list.</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> e element to be appended to this list</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> &#123;<span class=\"doctag\">@code</span> true&#125; (as specified by &#123;<span class=\"doctag\">@link</span> Collection#add&#125;)</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">add</span><span class=\"params\">(E e)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> ReentrantLock lock = <span class=\"keyword\">this</span>.lock;</span><br><span class=\"line\">        lock.lock();</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            Object[] elements = getArray();</span><br><span class=\"line\">            <span class=\"keyword\">int</span> len = elements.length;</span><br><span class=\"line\">            Object[] newElements = Arrays.copyOf(elements, len + <span class=\"number\">1</span>);</span><br><span class=\"line\">            newElements[len] = e;</span><br><span class=\"line\">            setArray(newElements);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">            lock.unlock();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Removes the element at the specified position in this list.</span></span><br><span class=\"line\"><span class=\"comment\">     * Shifts any subsequent elements to the left (subtracts one from their</span></span><br><span class=\"line\"><span class=\"comment\">     * indices).  Returns the element that was removed from the list.</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IndexOutOfBoundsException &#123;<span class=\"doctag\">@inheritDoc</span>&#125;</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> E <span class=\"title\">remove</span><span class=\"params\">(<span class=\"keyword\">int</span> index)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> ReentrantLock lock = <span class=\"keyword\">this</span>.lock;</span><br><span class=\"line\">        lock.lock();</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            Object[] elements = getArray();</span><br><span class=\"line\">            <span class=\"keyword\">int</span> len = elements.length;</span><br><span class=\"line\">            E oldValue = get(elements, index);</span><br><span class=\"line\">            <span class=\"keyword\">int</span> numMoved = len - index - <span class=\"number\">1</span>;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (numMoved == <span class=\"number\">0</span>)</span><br><span class=\"line\">                setArray(Arrays.copyOf(elements, len - <span class=\"number\">1</span>));</span><br><span class=\"line\">            <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                Object[] newElements = <span class=\"keyword\">new</span> Object[len - <span class=\"number\">1</span>];</span><br><span class=\"line\">                System.arraycopy(elements, <span class=\"number\">0</span>, newElements, <span class=\"number\">0</span>, index);</span><br><span class=\"line\">                System.arraycopy(elements, index + <span class=\"number\">1</span>, newElements, index,</span><br><span class=\"line\">                                 numMoved);</span><br><span class=\"line\">                setArray(newElements);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> oldValue;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">            lock.unlock();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看到，对CopyOnWriteArrayList的「写」操作，代码中都是有加互斥锁——ReentrantLock的，而对于「读」操作，没有任何锁机制。所以也就决定了CopyOnWriteArrayList一般在有大量并发读，少量并发写的场景下使用。</p>\n<blockquote>\n<p>参考：<a href=\"http://www.cnblogs.com/aigongsi/archive/2012/04/01/2429166.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/aigongsi/archive/2012/04/01/2429166.html</a></p>\n</blockquote>\n<p>七、volatile的应用场景</p>\n<p>synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：</p>\n<p>1）对变量的写操作不依赖于当前值</p>\n<p>2）该变量没有包含在具有其他变量的不变式中</p>\n<p>下面列举几个Java中使用volatile的几个场景。</p>\n<p>①.状态标记量</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">volatile</span> <span class=\"keyword\">boolean</span> flag = <span class=\"keyword\">false</span>;</span><br><span class=\"line\"> <span class=\"comment\">//线程1</span></span><br><span class=\"line\"><span class=\"keyword\">while</span>(!flag)&#123;</span><br><span class=\"line\">    doSomething();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">  <span class=\"comment\">//线程2</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setFlag</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    flag = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>根据状态标记，终止线程。</p>\n<p>②.单例模式中的double check</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Singleton</span></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">volatile</span> <span class=\"keyword\">static</span> Singleton instance = <span class=\"keyword\">null</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"title\">Singleton</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Singleton <span class=\"title\">getInstance</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(instance==<span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">synchronized</span> (Singleton.class) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(instance==<span class=\"keyword\">null</span>)</span><br><span class=\"line\">                    instance = <span class=\"keyword\">new</span> Singleton();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> instance;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>为什么要使用volatile 修饰instance？</p>\n<p>主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情:</p>\n<p>1.给 instance 分配内存</p>\n<p>2.调用 Singleton 的构造函数来初始化成员变量</p>\n<p>3.将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了）。</p>\n<p>但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。</p>\n<p>作者：Ruheng<br>链接：<a href=\"http://www.jianshu.com/p/7798161d7472\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/7798161d7472</a><br>來源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Volatile关键词\"><a href=\"#Volatile关键词\" class=\"headerlink\" title=\"Volatile关键词\"></a>Volatile关键词</h3><p>volatile的实现原理</p>\n<p>1.可见性</p>\n<p>处理器为了提高处理速度，不直接和内存进行通讯，而是将系统内存的数据独到内部缓存后再进行操作，但操作完后不知什么时候会写到内存。</p>\n<p>如果对声明了volatile变量进行写操作时，JVM会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写会到系统内存。 这一步确保了如果有其他线程对声明了volatile变量进行修改，则立即更新主内存中数据。</p>\n<p>但这时候其他处理器的缓存还是旧的，所以在多处理器环境下，为了保证各个处理器缓存一致，每个处理会通过嗅探在总线上传播的数据来检查 自己的缓存是否过期，当处理器发现自己缓存行对应的内存地址被修改了，就会将当前处理器的缓存行设置成无效状态，当处理器要对这个数据进行修改操作时，会强制重新从系统内存把数据读到处理器缓存里。 这一步确保了其他线程获得的声明了volatile变量都是从主内存中获取最新的。</p>\n<p>2.有序性</p>\n<p>Lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成。</p>\n<p>作者：Ruheng<br>链接：<a href=\"http://www.jianshu.com/p/7798161d7472\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/7798161d7472</a><br>來源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>\n<h4 id=\"主内存与线程工作内存\"><a href=\"#主内存与线程工作内存\" class=\"headerlink\" title=\"主内存与线程工作内存\"></a>主内存与线程工作内存</h4><h3 id=\"MVCC-Copy-on-write\"><a href=\"#MVCC-Copy-on-write\" class=\"headerlink\" title=\"MVCC Copy on write\"></a>MVCC Copy on write</h3><p>CopyOnWriteArrayList 实现细节</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CopyOnWriteArrayList</span>&lt;<span class=\"title\">E</span>&gt; </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/** The lock protecting all mutators */</span></span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">transient</span> ReentrantLock lock = <span class=\"keyword\">new</span> ReentrantLock();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** The array, accessed only via getArray/setArray. */</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">transient</span> <span class=\"keyword\">volatile</span> Object[] array;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Gets the array.  Non-private so as to also be accessible</span></span><br><span class=\"line\"><span class=\"comment\">     * from CopyOnWriteArraySet class.</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">final</span> Object[] getArray() &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> array;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Sets the array.</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">setArray</span><span class=\"params\">(Object[] a)</span> </span>&#123;</span><br><span class=\"line\">        array = a;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * &#123;<span class=\"doctag\">@inheritDoc</span>&#125;</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IndexOutOfBoundsException &#123;<span class=\"doctag\">@inheritDoc</span>&#125;</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> E <span class=\"title\">get</span><span class=\"params\">(<span class=\"keyword\">int</span> index)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> get(getArray(), index);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Appends the specified element to the end of this list.</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> e element to be appended to this list</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> &#123;<span class=\"doctag\">@code</span> true&#125; (as specified by &#123;<span class=\"doctag\">@link</span> Collection#add&#125;)</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">add</span><span class=\"params\">(E e)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> ReentrantLock lock = <span class=\"keyword\">this</span>.lock;</span><br><span class=\"line\">        lock.lock();</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            Object[] elements = getArray();</span><br><span class=\"line\">            <span class=\"keyword\">int</span> len = elements.length;</span><br><span class=\"line\">            Object[] newElements = Arrays.copyOf(elements, len + <span class=\"number\">1</span>);</span><br><span class=\"line\">            newElements[len] = e;</span><br><span class=\"line\">            setArray(newElements);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">            lock.unlock();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Removes the element at the specified position in this list.</span></span><br><span class=\"line\"><span class=\"comment\">     * Shifts any subsequent elements to the left (subtracts one from their</span></span><br><span class=\"line\"><span class=\"comment\">     * indices).  Returns the element that was removed from the list.</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@throws</span> IndexOutOfBoundsException &#123;<span class=\"doctag\">@inheritDoc</span>&#125;</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> E <span class=\"title\">remove</span><span class=\"params\">(<span class=\"keyword\">int</span> index)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> ReentrantLock lock = <span class=\"keyword\">this</span>.lock;</span><br><span class=\"line\">        lock.lock();</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            Object[] elements = getArray();</span><br><span class=\"line\">            <span class=\"keyword\">int</span> len = elements.length;</span><br><span class=\"line\">            E oldValue = get(elements, index);</span><br><span class=\"line\">            <span class=\"keyword\">int</span> numMoved = len - index - <span class=\"number\">1</span>;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (numMoved == <span class=\"number\">0</span>)</span><br><span class=\"line\">                setArray(Arrays.copyOf(elements, len - <span class=\"number\">1</span>));</span><br><span class=\"line\">            <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                Object[] newElements = <span class=\"keyword\">new</span> Object[len - <span class=\"number\">1</span>];</span><br><span class=\"line\">                System.arraycopy(elements, <span class=\"number\">0</span>, newElements, <span class=\"number\">0</span>, index);</span><br><span class=\"line\">                System.arraycopy(elements, index + <span class=\"number\">1</span>, newElements, index,</span><br><span class=\"line\">                                 numMoved);</span><br><span class=\"line\">                setArray(newElements);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> oldValue;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">            lock.unlock();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看到，对CopyOnWriteArrayList的「写」操作，代码中都是有加互斥锁——ReentrantLock的，而对于「读」操作，没有任何锁机制。所以也就决定了CopyOnWriteArrayList一般在有大量并发读，少量并发写的场景下使用。</p>\n<blockquote>\n<p>参考：<a href=\"http://www.cnblogs.com/aigongsi/archive/2012/04/01/2429166.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/aigongsi/archive/2012/04/01/2429166.html</a></p>\n</blockquote>\n<p>七、volatile的应用场景</p>\n<p>synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：</p>\n<p>1）对变量的写操作不依赖于当前值</p>\n<p>2）该变量没有包含在具有其他变量的不变式中</p>\n<p>下面列举几个Java中使用volatile的几个场景。</p>\n<p>①.状态标记量</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">volatile</span> <span class=\"keyword\">boolean</span> flag = <span class=\"keyword\">false</span>;</span><br><span class=\"line\"> <span class=\"comment\">//线程1</span></span><br><span class=\"line\"><span class=\"keyword\">while</span>(!flag)&#123;</span><br><span class=\"line\">    doSomething();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">  <span class=\"comment\">//线程2</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setFlag</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    flag = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>根据状态标记，终止线程。</p>\n<p>②.单例模式中的double check</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Singleton</span></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">volatile</span> <span class=\"keyword\">static</span> Singleton instance = <span class=\"keyword\">null</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"title\">Singleton</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Singleton <span class=\"title\">getInstance</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(instance==<span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">synchronized</span> (Singleton.class) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span>(instance==<span class=\"keyword\">null</span>)</span><br><span class=\"line\">                    instance = <span class=\"keyword\">new</span> Singleton();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> instance;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>为什么要使用volatile 修饰instance？</p>\n<p>主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情:</p>\n<p>1.给 instance 分配内存</p>\n<p>2.调用 Singleton 的构造函数来初始化成员变量</p>\n<p>3.将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了）。</p>\n<p>但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。</p>\n<p>作者：Ruheng<br>链接：<a href=\"http://www.jianshu.com/p/7798161d7472\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/7798161d7472</a><br>來源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>\n"},{"title":"JVM-CAS-Campare-and-swap","date":"2017-11-10T11:48:55.000Z","_content":"> 仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢\n\n### CAS\n\n硬件指令\n\n### 基于CAS的无所化（Lock-Free）设计\n\n也就是所谓的乐观锁\n``` java\n/**\n * 自旋锁\n */\npublic class SpinLock {\n    private AtomicBoolean canLock = new AtomicBoolean(true);\n\n    public void lock() {\n        boolean b;\n        do {\n            b = canLock.compareAndSet(true, false);\n        } while (!b);\n    }\n\n    public void release() {\n        canLock.compareAndSet(false, true);\n    }\n}\n```\n\n调用lock方法时，`canLock`初始为true，cas成功执行，返回修改后的值，也就是false。然后循环在while中，只要canLock没有被重置会true，cas一直是失败的。CPU被该线程长久占用着。\n\n### ABA问题\n\nCAS本身是没有任何问题的，是操作系统的指令。但是，当我们用CAS原理来设计无锁化的互斥机制时，就一定会产生ABA问题。\n\n### 优化ABA\n\n对于某些系统，ABA不会产生问题，但也有不能容忍ABA的系统\n","source":"_posts/JVM-CAS-Campare-and-swap.md","raw":"---\ntitle: JVM-CAS-Campare-and-swap\ndate: 2017-11-10 19:48:55\ntags: JVM\n---\n> 仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢\n\n### CAS\n\n硬件指令\n\n### 基于CAS的无所化（Lock-Free）设计\n\n也就是所谓的乐观锁\n``` java\n/**\n * 自旋锁\n */\npublic class SpinLock {\n    private AtomicBoolean canLock = new AtomicBoolean(true);\n\n    public void lock() {\n        boolean b;\n        do {\n            b = canLock.compareAndSet(true, false);\n        } while (!b);\n    }\n\n    public void release() {\n        canLock.compareAndSet(false, true);\n    }\n}\n```\n\n调用lock方法时，`canLock`初始为true，cas成功执行，返回修改后的值，也就是false。然后循环在while中，只要canLock没有被重置会true，cas一直是失败的。CPU被该线程长久占用着。\n\n### ABA问题\n\nCAS本身是没有任何问题的，是操作系统的指令。但是，当我们用CAS原理来设计无锁化的互斥机制时，就一定会产生ABA问题。\n\n### 优化ABA\n\n对于某些系统，ABA不会产生问题，但也有不能容忍ABA的系统\n","slug":"JVM-CAS-Campare-and-swap","published":1,"updated":"2019-09-28T08:51:00.866Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82u001fv1np78h3z15h","content":"<blockquote>\n<p>仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢</p>\n</blockquote>\n<h3 id=\"CAS\"><a href=\"#CAS\" class=\"headerlink\" title=\"CAS\"></a>CAS</h3><p>硬件指令</p>\n<h3 id=\"基于CAS的无所化（Lock-Free）设计\"><a href=\"#基于CAS的无所化（Lock-Free）设计\" class=\"headerlink\" title=\"基于CAS的无所化（Lock-Free）设计\"></a>基于CAS的无所化（Lock-Free）设计</h3><p>也就是所谓的乐观锁</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 自旋锁</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SpinLock</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> AtomicBoolean canLock = <span class=\"keyword\">new</span> AtomicBoolean(<span class=\"keyword\">true</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">lock</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">boolean</span> b;</span><br><span class=\"line\">        <span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">            b = canLock.compareAndSet(<span class=\"keyword\">true</span>, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">while</span> (!b);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">release</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        canLock.compareAndSet(<span class=\"keyword\">false</span>, <span class=\"keyword\">true</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>调用lock方法时，<code>canLock</code>初始为true，cas成功执行，返回修改后的值，也就是false。然后循环在while中，只要canLock没有被重置会true，cas一直是失败的。CPU被该线程长久占用着。</p>\n<h3 id=\"ABA问题\"><a href=\"#ABA问题\" class=\"headerlink\" title=\"ABA问题\"></a>ABA问题</h3><p>CAS本身是没有任何问题的，是操作系统的指令。但是，当我们用CAS原理来设计无锁化的互斥机制时，就一定会产生ABA问题。</p>\n<h3 id=\"优化ABA\"><a href=\"#优化ABA\" class=\"headerlink\" title=\"优化ABA\"></a>优化ABA</h3><p>对于某些系统，ABA不会产生问题，但也有不能容忍ABA的系统</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>仅供学习交流,如有错误请指出,如要转载请加上出处,谢谢</p>\n</blockquote>\n<h3 id=\"CAS\"><a href=\"#CAS\" class=\"headerlink\" title=\"CAS\"></a>CAS</h3><p>硬件指令</p>\n<h3 id=\"基于CAS的无所化（Lock-Free）设计\"><a href=\"#基于CAS的无所化（Lock-Free）设计\" class=\"headerlink\" title=\"基于CAS的无所化（Lock-Free）设计\"></a>基于CAS的无所化（Lock-Free）设计</h3><p>也就是所谓的乐观锁</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * 自旋锁</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SpinLock</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> AtomicBoolean canLock = <span class=\"keyword\">new</span> AtomicBoolean(<span class=\"keyword\">true</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">lock</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">boolean</span> b;</span><br><span class=\"line\">        <span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">            b = canLock.compareAndSet(<span class=\"keyword\">true</span>, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">while</span> (!b);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">release</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        canLock.compareAndSet(<span class=\"keyword\">false</span>, <span class=\"keyword\">true</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>调用lock方法时，<code>canLock</code>初始为true，cas成功执行，返回修改后的值，也就是false。然后循环在while中，只要canLock没有被重置会true，cas一直是失败的。CPU被该线程长久占用着。</p>\n<h3 id=\"ABA问题\"><a href=\"#ABA问题\" class=\"headerlink\" title=\"ABA问题\"></a>ABA问题</h3><p>CAS本身是没有任何问题的，是操作系统的指令。但是，当我们用CAS原理来设计无锁化的互斥机制时，就一定会产生ABA问题。</p>\n<h3 id=\"优化ABA\"><a href=\"#优化ABA\" class=\"headerlink\" title=\"优化ABA\"></a>优化ABA</h3><p>对于某些系统，ABA不会产生问题，但也有不能容忍ABA的系统</p>\n"},{"title":"JMM-Volatile","date":"2019-11-28T07:15:18.000Z","_content":"\n### Java中的`Volatile`关键词，到底是什么解决一个什么问题？\n对于一些'宽'的数据类型，对其进行读写访问，怎么能保证读写原子性(读写原子性)，不是'++'原子性。","source":"_posts/JMM-Volatile.md","raw":"---\ntitle: JMM-Volatile\ndate: 2019-11-28 15:15:18\ntags:\n---\n\n### Java中的`Volatile`关键词，到底是什么解决一个什么问题？\n对于一些'宽'的数据类型，对其进行读写访问，怎么能保证读写原子性(读写原子性)，不是'++'原子性。","slug":"JMM-Volatile","published":1,"updated":"2019-11-28T07:18:34.489Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82v001gv1npeigciybh","content":"<h3 id=\"Java中的Volatile关键词，到底是什么解决一个什么问题？\"><a href=\"#Java中的Volatile关键词，到底是什么解决一个什么问题？\" class=\"headerlink\" title=\"Java中的Volatile关键词，到底是什么解决一个什么问题？\"></a>Java中的<code>Volatile</code>关键词，到底是什么解决一个什么问题？</h3><p>对于一些’宽’的数据类型，对其进行读写访问，怎么能保证读写原子性(读写原子性)，不是’++’原子性。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Java中的Volatile关键词，到底是什么解决一个什么问题？\"><a href=\"#Java中的Volatile关键词，到底是什么解决一个什么问题？\" class=\"headerlink\" title=\"Java中的Volatile关键词，到底是什么解决一个什么问题？\"></a>Java中的<code>Volatile</code>关键词，到底是什么解决一个什么问题？</h3><p>对于一些’宽’的数据类型，对其进行读写访问，怎么能保证读写原子性(读写原子性)，不是’++’原子性。</p>\n"},{"title":"JVM-Card-table","date":"2018-11-21T12:18:31.000Z","_content":"\n\n```\nDirtyCardToOopClosure::do_MemRegion space.cpp:116\nClearNoncleanCardWrapper::do_MemRegion cardTableRS.cpp:243\nCardTableModRefBSForCTRS::process_stride parCardTableModRefBS.cpp:157\nCardTableModRefBSForCTRS::non_clean_card_iterate_parallel_work parCardTableModRefBS.cpp:65\nCardTableModRefBSForCTRS::non_clean_card_iterate_possibly_parallel cardTableModRefBSForCTRS.cpp:106\nCardTableRS::younger_refs_in_space_iterate cardTableRS.cpp:343\nGeneration::younger_refs_in_space_iterate generation.cpp:280\nCardGeneration::younger_refs_iterate cardGeneration.cpp:314\nCardTableRS::younger_refs_iterate cardTableRS.cpp:152\nGenCollectedHeap::young_process_roots genCollectedHeap.cpp:671\nParNewGenTask::work parNewGeneration.cpp:608\nGangWorker::run_task workgroup.cpp:332\nGangWorker::loop workgroup.cpp:342\nAbstractGangWorker::run workgroup.cpp:291\nthread_native_entry os_bsd.cpp:720\n_pthread_body 0x00007fff942c793b\n_pthread_start 0x00007fff942c7887\nthread_start 0x00007fff942c708d\n<unknown> 0x0000000000000000\n```\n\n### 讲得超赞\nhttps://segmentfault.com/a/1190000004682407\n\n\n### \nhttps://www.jianshu.com/p/5037459097ee\n\n```\nclass CardTableModRefBSForCTRS: public CardTableModRefBS {\n  // This is an array, one element per covered region of the card table.\n  // Each entry is itself an array, with one element per chunk in the\n  // covered region.  Each entry of these arrays is the lowest non-clean\n  // card of the corresponding chunk containing part of an object from the\n  // previous chunk, or else NULL.\n  typedef jbyte*  CardPtr;\n  typedef CardPtr* CardArr;\n  CardArr* _lowest_non_clean;\n  size_t*  _lowest_non_clean_chunk_size;\n  uintptr_t* _lowest_non_clean_base_chunk_index;\n  volatile int* _last_LNC_resizing_collection;\n}\n```","source":"_posts/JVM-Card-table.md","raw":"---\ntitle: JVM-Card-table\ndate: 2018-11-21 20:18:31\ntags: JVM\n---\n\n\n```\nDirtyCardToOopClosure::do_MemRegion space.cpp:116\nClearNoncleanCardWrapper::do_MemRegion cardTableRS.cpp:243\nCardTableModRefBSForCTRS::process_stride parCardTableModRefBS.cpp:157\nCardTableModRefBSForCTRS::non_clean_card_iterate_parallel_work parCardTableModRefBS.cpp:65\nCardTableModRefBSForCTRS::non_clean_card_iterate_possibly_parallel cardTableModRefBSForCTRS.cpp:106\nCardTableRS::younger_refs_in_space_iterate cardTableRS.cpp:343\nGeneration::younger_refs_in_space_iterate generation.cpp:280\nCardGeneration::younger_refs_iterate cardGeneration.cpp:314\nCardTableRS::younger_refs_iterate cardTableRS.cpp:152\nGenCollectedHeap::young_process_roots genCollectedHeap.cpp:671\nParNewGenTask::work parNewGeneration.cpp:608\nGangWorker::run_task workgroup.cpp:332\nGangWorker::loop workgroup.cpp:342\nAbstractGangWorker::run workgroup.cpp:291\nthread_native_entry os_bsd.cpp:720\n_pthread_body 0x00007fff942c793b\n_pthread_start 0x00007fff942c7887\nthread_start 0x00007fff942c708d\n<unknown> 0x0000000000000000\n```\n\n### 讲得超赞\nhttps://segmentfault.com/a/1190000004682407\n\n\n### \nhttps://www.jianshu.com/p/5037459097ee\n\n```\nclass CardTableModRefBSForCTRS: public CardTableModRefBS {\n  // This is an array, one element per covered region of the card table.\n  // Each entry is itself an array, with one element per chunk in the\n  // covered region.  Each entry of these arrays is the lowest non-clean\n  // card of the corresponding chunk containing part of an object from the\n  // previous chunk, or else NULL.\n  typedef jbyte*  CardPtr;\n  typedef CardPtr* CardArr;\n  CardArr* _lowest_non_clean;\n  size_t*  _lowest_non_clean_chunk_size;\n  uintptr_t* _lowest_non_clean_base_chunk_index;\n  volatile int* _last_LNC_resizing_collection;\n}\n```","slug":"JVM-Card-table","published":1,"updated":"2019-09-28T08:51:00.866Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82v001hv1np57ws7jhd","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DirtyCardToOopClosure::do_MemRegion space.cpp:116</span><br><span class=\"line\">ClearNoncleanCardWrapper::do_MemRegion cardTableRS.cpp:243</span><br><span class=\"line\">CardTableModRefBSForCTRS::process_stride parCardTableModRefBS.cpp:157</span><br><span class=\"line\">CardTableModRefBSForCTRS::non_clean_card_iterate_parallel_work parCardTableModRefBS.cpp:65</span><br><span class=\"line\">CardTableModRefBSForCTRS::non_clean_card_iterate_possibly_parallel cardTableModRefBSForCTRS.cpp:106</span><br><span class=\"line\">CardTableRS::younger_refs_in_space_iterate cardTableRS.cpp:343</span><br><span class=\"line\">Generation::younger_refs_in_space_iterate generation.cpp:280</span><br><span class=\"line\">CardGeneration::younger_refs_iterate cardGeneration.cpp:314</span><br><span class=\"line\">CardTableRS::younger_refs_iterate cardTableRS.cpp:152</span><br><span class=\"line\">GenCollectedHeap::young_process_roots genCollectedHeap.cpp:671</span><br><span class=\"line\">ParNewGenTask::work parNewGeneration.cpp:608</span><br><span class=\"line\">GangWorker::run_task workgroup.cpp:332</span><br><span class=\"line\">GangWorker::loop workgroup.cpp:342</span><br><span class=\"line\">AbstractGangWorker::run workgroup.cpp:291</span><br><span class=\"line\">thread_native_entry os_bsd.cpp:720</span><br><span class=\"line\">_pthread_body 0x00007fff942c793b</span><br><span class=\"line\">_pthread_start 0x00007fff942c7887</span><br><span class=\"line\">thread_start 0x00007fff942c708d</span><br><span class=\"line\">&lt;unknown&gt; 0x0000000000000000</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"讲得超赞\"><a href=\"#讲得超赞\" class=\"headerlink\" title=\"讲得超赞\"></a>讲得超赞</h3><p><a href=\"https://segmentfault.com/a/1190000004682407\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000004682407</a></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><a href=\"https://www.jianshu.com/p/5037459097ee\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/5037459097ee</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class CardTableModRefBSForCTRS: public CardTableModRefBS &#123;</span><br><span class=\"line\">  // This is an array, one element per covered region of the card table.</span><br><span class=\"line\">  // Each entry is itself an array, with one element per chunk in the</span><br><span class=\"line\">  // covered region.  Each entry of these arrays is the lowest non-clean</span><br><span class=\"line\">  // card of the corresponding chunk containing part of an object from the</span><br><span class=\"line\">  // previous chunk, or else NULL.</span><br><span class=\"line\">  typedef jbyte*  CardPtr;</span><br><span class=\"line\">  typedef CardPtr* CardArr;</span><br><span class=\"line\">  CardArr* _lowest_non_clean;</span><br><span class=\"line\">  size_t*  _lowest_non_clean_chunk_size;</span><br><span class=\"line\">  uintptr_t* _lowest_non_clean_base_chunk_index;</span><br><span class=\"line\">  volatile int* _last_LNC_resizing_collection;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DirtyCardToOopClosure::do_MemRegion space.cpp:116</span><br><span class=\"line\">ClearNoncleanCardWrapper::do_MemRegion cardTableRS.cpp:243</span><br><span class=\"line\">CardTableModRefBSForCTRS::process_stride parCardTableModRefBS.cpp:157</span><br><span class=\"line\">CardTableModRefBSForCTRS::non_clean_card_iterate_parallel_work parCardTableModRefBS.cpp:65</span><br><span class=\"line\">CardTableModRefBSForCTRS::non_clean_card_iterate_possibly_parallel cardTableModRefBSForCTRS.cpp:106</span><br><span class=\"line\">CardTableRS::younger_refs_in_space_iterate cardTableRS.cpp:343</span><br><span class=\"line\">Generation::younger_refs_in_space_iterate generation.cpp:280</span><br><span class=\"line\">CardGeneration::younger_refs_iterate cardGeneration.cpp:314</span><br><span class=\"line\">CardTableRS::younger_refs_iterate cardTableRS.cpp:152</span><br><span class=\"line\">GenCollectedHeap::young_process_roots genCollectedHeap.cpp:671</span><br><span class=\"line\">ParNewGenTask::work parNewGeneration.cpp:608</span><br><span class=\"line\">GangWorker::run_task workgroup.cpp:332</span><br><span class=\"line\">GangWorker::loop workgroup.cpp:342</span><br><span class=\"line\">AbstractGangWorker::run workgroup.cpp:291</span><br><span class=\"line\">thread_native_entry os_bsd.cpp:720</span><br><span class=\"line\">_pthread_body 0x00007fff942c793b</span><br><span class=\"line\">_pthread_start 0x00007fff942c7887</span><br><span class=\"line\">thread_start 0x00007fff942c708d</span><br><span class=\"line\">&lt;unknown&gt; 0x0000000000000000</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"讲得超赞\"><a href=\"#讲得超赞\" class=\"headerlink\" title=\"讲得超赞\"></a>讲得超赞</h3><p><a href=\"https://segmentfault.com/a/1190000004682407\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000004682407</a></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><a href=\"https://www.jianshu.com/p/5037459097ee\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/5037459097ee</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class CardTableModRefBSForCTRS: public CardTableModRefBS &#123;</span><br><span class=\"line\">  // This is an array, one element per covered region of the card table.</span><br><span class=\"line\">  // Each entry is itself an array, with one element per chunk in the</span><br><span class=\"line\">  // covered region.  Each entry of these arrays is the lowest non-clean</span><br><span class=\"line\">  // card of the corresponding chunk containing part of an object from the</span><br><span class=\"line\">  // previous chunk, or else NULL.</span><br><span class=\"line\">  typedef jbyte*  CardPtr;</span><br><span class=\"line\">  typedef CardPtr* CardArr;</span><br><span class=\"line\">  CardArr* _lowest_non_clean;</span><br><span class=\"line\">  size_t*  _lowest_non_clean_chunk_size;</span><br><span class=\"line\">  uintptr_t* _lowest_non_clean_base_chunk_index;</span><br><span class=\"line\">  volatile int* _last_LNC_resizing_collection;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"JVM-Crash-Log-Analysis","date":"2018-01-11T06:39:37.000Z","_content":"\nhttp://www.javaranger.com/archives/1636\n\n工具：\nhttps://github.com/xpbob/CrashAnalysis\n\nhttp://www.raychase.net/1459\n\nhttps://www.jianshu.com/p/7652f931cafd\n\n致命错误出现的时候，JVM生成了hs_err_pid<pid>.log这样的文件，其中往往包含了虚拟机崩溃原因的重要信息。因为经常遇到，在这篇文章里，我挑选了一个，并且逐段分析它包含的内容（文件可以在文章最后下载）。默认情况下文件是创建在工作目录下的（如果没权限创建的话JVM会尝试把文件写到/tmp这样的临时目录下面去），当然，文件格式和路径也可以通过参数指定，比如：\n\n1\njava -XX:ErrorFile=/var/log/java/java_error%p.log\n这个文件将包括：\n\n触发致命错误的操作异常或者信号；\n版本和配置信息；\n触发致命异常的线程详细信息和线程栈；\n当前运行的线程列表和它们的状态；\n堆的总括信息；\n加载的本地库；\n命令行参数；\n环境变量；\n操作系统CPU的详细信息。\n首先，看到的是对问题的概要介绍：\n\n1\n#  SIGSEGV (0xb) at pc=0x03568cf4, pid=16819, tid=3073346448\n一个非预期的错误被JRE检测到，其中：\n\nSIGSEGV是信号名称\n0xb是信号码\npc=0x03568cf4指的是程序计数器的值\npid=16819是进程号\ntid=3073346448是线程号\n如果你对JVM有了解，应该不会对这些东西陌生。\n\n\n```\npublic class OutOfMemory {\n    public static void main(String[] args) {\n        ArrayList<StubClass> list = new ArrayList<StubClass>();\n        int count = 1000000000;\n        for (int i = 0; i < count; i++) {\n            StubClass bj = new StubClass();\n            list.add(obj);\n        }\n    }\n}\n```\n\n\n```\nclass StubClass {\n    private Integer n = new Integer(123334);\n    private Integer m = new Integer(123334);\n    \n    public void print() {\n        System.out.println(\"m=\"+m);\n        System.out.println(\"n=\"+n);\n    }\n}\n```\n","source":"_posts/JVM-Crash-Log-Analysis.md","raw":"---\ntitle: JVM-Crash-Log-Analysis\ndate: 2018-01-11 14:39:37\ntags: JVM\n---\n\nhttp://www.javaranger.com/archives/1636\n\n工具：\nhttps://github.com/xpbob/CrashAnalysis\n\nhttp://www.raychase.net/1459\n\nhttps://www.jianshu.com/p/7652f931cafd\n\n致命错误出现的时候，JVM生成了hs_err_pid<pid>.log这样的文件，其中往往包含了虚拟机崩溃原因的重要信息。因为经常遇到，在这篇文章里，我挑选了一个，并且逐段分析它包含的内容（文件可以在文章最后下载）。默认情况下文件是创建在工作目录下的（如果没权限创建的话JVM会尝试把文件写到/tmp这样的临时目录下面去），当然，文件格式和路径也可以通过参数指定，比如：\n\n1\njava -XX:ErrorFile=/var/log/java/java_error%p.log\n这个文件将包括：\n\n触发致命错误的操作异常或者信号；\n版本和配置信息；\n触发致命异常的线程详细信息和线程栈；\n当前运行的线程列表和它们的状态；\n堆的总括信息；\n加载的本地库；\n命令行参数；\n环境变量；\n操作系统CPU的详细信息。\n首先，看到的是对问题的概要介绍：\n\n1\n#  SIGSEGV (0xb) at pc=0x03568cf4, pid=16819, tid=3073346448\n一个非预期的错误被JRE检测到，其中：\n\nSIGSEGV是信号名称\n0xb是信号码\npc=0x03568cf4指的是程序计数器的值\npid=16819是进程号\ntid=3073346448是线程号\n如果你对JVM有了解，应该不会对这些东西陌生。\n\n\n```\npublic class OutOfMemory {\n    public static void main(String[] args) {\n        ArrayList<StubClass> list = new ArrayList<StubClass>();\n        int count = 1000000000;\n        for (int i = 0; i < count; i++) {\n            StubClass bj = new StubClass();\n            list.add(obj);\n        }\n    }\n}\n```\n\n\n```\nclass StubClass {\n    private Integer n = new Integer(123334);\n    private Integer m = new Integer(123334);\n    \n    public void print() {\n        System.out.println(\"m=\"+m);\n        System.out.println(\"n=\"+n);\n    }\n}\n```\n","slug":"JVM-Crash-Log-Analysis","published":1,"updated":"2019-09-28T08:51:00.866Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82w001iv1npa06luhu9","content":"<p><a href=\"http://www.javaranger.com/archives/1636\" target=\"_blank\" rel=\"noopener\">http://www.javaranger.com/archives/1636</a></p>\n<p>工具：<br><a href=\"https://github.com/xpbob/CrashAnalysis\" target=\"_blank\" rel=\"noopener\">https://github.com/xpbob/CrashAnalysis</a></p>\n<p><a href=\"http://www.raychase.net/1459\" target=\"_blank\" rel=\"noopener\">http://www.raychase.net/1459</a></p>\n<p><a href=\"https://www.jianshu.com/p/7652f931cafd\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/7652f931cafd</a></p>\n<p>致命错误出现的时候，JVM生成了hs_err_pid<pid>.log这样的文件，其中往往包含了虚拟机崩溃原因的重要信息。因为经常遇到，在这篇文章里，我挑选了一个，并且逐段分析它包含的内容（文件可以在文章最后下载）。默认情况下文件是创建在工作目录下的（如果没权限创建的话JVM会尝试把文件写到/tmp这样的临时目录下面去），当然，文件格式和路径也可以通过参数指定，比如：</pid></p>\n<p>1<br>java -XX:ErrorFile=/var/log/java/java_error%p.log<br>这个文件将包括：</p>\n<p>触发致命错误的操作异常或者信号；<br>版本和配置信息；<br>触发致命异常的线程详细信息和线程栈；<br>当前运行的线程列表和它们的状态；<br>堆的总括信息；<br>加载的本地库；<br>命令行参数；<br>环境变量；<br>操作系统CPU的详细信息。<br>首先，看到的是对问题的概要介绍：</p>\n<p>1</p>\n<h1 id=\"SIGSEGV-0xb-at-pc-0x03568cf4-pid-16819-tid-3073346448\"><a href=\"#SIGSEGV-0xb-at-pc-0x03568cf4-pid-16819-tid-3073346448\" class=\"headerlink\" title=\"SIGSEGV (0xb) at pc=0x03568cf4, pid=16819, tid=3073346448\"></a>SIGSEGV (0xb) at pc=0x03568cf4, pid=16819, tid=3073346448</h1><p>一个非预期的错误被JRE检测到，其中：</p>\n<p>SIGSEGV是信号名称<br>0xb是信号码<br>pc=0x03568cf4指的是程序计数器的值<br>pid=16819是进程号<br>tid=3073346448是线程号<br>如果你对JVM有了解，应该不会对这些东西陌生。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class OutOfMemory &#123;</span><br><span class=\"line\">    public static void main(String[] args) &#123;</span><br><span class=\"line\">        ArrayList&lt;StubClass&gt; list = new ArrayList&lt;StubClass&gt;();</span><br><span class=\"line\">        int count = 1000000000;</span><br><span class=\"line\">        for (int i = 0; i &lt; count; i++) &#123;</span><br><span class=\"line\">            StubClass bj = new StubClass();</span><br><span class=\"line\">            list.add(obj);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class StubClass &#123;</span><br><span class=\"line\">    private Integer n = new Integer(123334);</span><br><span class=\"line\">    private Integer m = new Integer(123334);</span><br><span class=\"line\">    </span><br><span class=\"line\">    public void print() &#123;</span><br><span class=\"line\">        System.out.println(&quot;m=&quot;+m);</span><br><span class=\"line\">        System.out.println(&quot;n=&quot;+n);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://www.javaranger.com/archives/1636\" target=\"_blank\" rel=\"noopener\">http://www.javaranger.com/archives/1636</a></p>\n<p>工具：<br><a href=\"https://github.com/xpbob/CrashAnalysis\" target=\"_blank\" rel=\"noopener\">https://github.com/xpbob/CrashAnalysis</a></p>\n<p><a href=\"http://www.raychase.net/1459\" target=\"_blank\" rel=\"noopener\">http://www.raychase.net/1459</a></p>\n<p><a href=\"https://www.jianshu.com/p/7652f931cafd\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/7652f931cafd</a></p>\n<p>致命错误出现的时候，JVM生成了hs_err_pid<pid>.log这样的文件，其中往往包含了虚拟机崩溃原因的重要信息。因为经常遇到，在这篇文章里，我挑选了一个，并且逐段分析它包含的内容（文件可以在文章最后下载）。默认情况下文件是创建在工作目录下的（如果没权限创建的话JVM会尝试把文件写到/tmp这样的临时目录下面去），当然，文件格式和路径也可以通过参数指定，比如：</pid></p>\n<p>1<br>java -XX:ErrorFile=/var/log/java/java_error%p.log<br>这个文件将包括：</p>\n<p>触发致命错误的操作异常或者信号；<br>版本和配置信息；<br>触发致命异常的线程详细信息和线程栈；<br>当前运行的线程列表和它们的状态；<br>堆的总括信息；<br>加载的本地库；<br>命令行参数；<br>环境变量；<br>操作系统CPU的详细信息。<br>首先，看到的是对问题的概要介绍：</p>\n<p>1</p>\n<h1 id=\"SIGSEGV-0xb-at-pc-0x03568cf4-pid-16819-tid-3073346448\"><a href=\"#SIGSEGV-0xb-at-pc-0x03568cf4-pid-16819-tid-3073346448\" class=\"headerlink\" title=\"SIGSEGV (0xb) at pc=0x03568cf4, pid=16819, tid=3073346448\"></a>SIGSEGV (0xb) at pc=0x03568cf4, pid=16819, tid=3073346448</h1><p>一个非预期的错误被JRE检测到，其中：</p>\n<p>SIGSEGV是信号名称<br>0xb是信号码<br>pc=0x03568cf4指的是程序计数器的值<br>pid=16819是进程号<br>tid=3073346448是线程号<br>如果你对JVM有了解，应该不会对这些东西陌生。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class OutOfMemory &#123;</span><br><span class=\"line\">    public static void main(String[] args) &#123;</span><br><span class=\"line\">        ArrayList&lt;StubClass&gt; list = new ArrayList&lt;StubClass&gt;();</span><br><span class=\"line\">        int count = 1000000000;</span><br><span class=\"line\">        for (int i = 0; i &lt; count; i++) &#123;</span><br><span class=\"line\">            StubClass bj = new StubClass();</span><br><span class=\"line\">            list.add(obj);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class StubClass &#123;</span><br><span class=\"line\">    private Integer n = new Integer(123334);</span><br><span class=\"line\">    private Integer m = new Integer(123334);</span><br><span class=\"line\">    </span><br><span class=\"line\">    public void print() &#123;</span><br><span class=\"line\">        System.out.println(&quot;m=&quot;+m);</span><br><span class=\"line\">        System.out.println(&quot;n=&quot;+n);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"JVM-Escape-analysis","date":"2018-10-04T07:46:42.000Z","_content":"\nhttps://blog.csdn.net/blueheart20/article/details/52050545\n\n\n\n### 这篇写得更加有操作性\nhttp://www.importnew.com/21699.html","source":"_posts/JVM-Escape-analysis.md","raw":"---\ntitle: JVM-Escape-analysis\ndate: 2018-10-04 15:46:42\ntags: JVM\n---\n\nhttps://blog.csdn.net/blueheart20/article/details/52050545\n\n\n\n### 这篇写得更加有操作性\nhttp://www.importnew.com/21699.html","slug":"JVM-Escape-analysis","published":1,"updated":"2019-09-28T08:51:00.866Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82w001jv1np6gb0f1fd","content":"<p><a href=\"https://blog.csdn.net/blueheart20/article/details/52050545\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/blueheart20/article/details/52050545</a></p>\n<h3 id=\"这篇写得更加有操作性\"><a href=\"#这篇写得更加有操作性\" class=\"headerlink\" title=\"这篇写得更加有操作性\"></a>这篇写得更加有操作性</h3><p><a href=\"http://www.importnew.com/21699.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/21699.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/blueheart20/article/details/52050545\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/blueheart20/article/details/52050545</a></p>\n<h3 id=\"这篇写得更加有操作性\"><a href=\"#这篇写得更加有操作性\" class=\"headerlink\" title=\"这篇写得更加有操作性\"></a>这篇写得更加有操作性</h3><p><a href=\"http://www.importnew.com/21699.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/21699.html</a></p>\n"},{"title":"JVM-FreeList","date":"2018-10-11T11:46:45.000Z","_content":"\nhttps://blog.csdn.net/happyqwz/article/details/8723016\n```\n方法是重载运算符，重新定义new，和delete方法。英文书，原理细节描述不清，我的大致理解是，new操作的时候，要跑到内存中去取一块内存单元，CPU在跑着程序，如果能从较近的地方取内存肯定要比去远的地方要好的多。于是，就采取自行管理链表所需内存的方式，定义一freeList链表，为Link类的静态成员变量，初始值为NULL，表示没有“近内存”。调用new方法的时候，如果freelist不为空，那么就在freelist中取一块内存（近内存），如果为NULL，那么只能调用原new操作符，调用“远内存”。调用delete方法的时候，释放的内存不丢弃，而是把它加载到freelist中，供程序之后重新使用。这样的话，程序的运行就可以在小范围内存区域中存取，那么注定要比系统定义的new delete方法要快得多吧...\n```","source":"_posts/JVM-FreeList.md","raw":"---\ntitle: JVM-FreeList\ndate: 2018-10-11 19:46:45\ntags: JVM\n---\n\nhttps://blog.csdn.net/happyqwz/article/details/8723016\n```\n方法是重载运算符，重新定义new，和delete方法。英文书，原理细节描述不清，我的大致理解是，new操作的时候，要跑到内存中去取一块内存单元，CPU在跑着程序，如果能从较近的地方取内存肯定要比去远的地方要好的多。于是，就采取自行管理链表所需内存的方式，定义一freeList链表，为Link类的静态成员变量，初始值为NULL，表示没有“近内存”。调用new方法的时候，如果freelist不为空，那么就在freelist中取一块内存（近内存），如果为NULL，那么只能调用原new操作符，调用“远内存”。调用delete方法的时候，释放的内存不丢弃，而是把它加载到freelist中，供程序之后重新使用。这样的话，程序的运行就可以在小范围内存区域中存取，那么注定要比系统定义的new delete方法要快得多吧...\n```","slug":"JVM-FreeList","published":1,"updated":"2019-09-28T08:51:00.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82x001kv1npwtw9f3db","content":"<p><a href=\"https://blog.csdn.net/happyqwz/article/details/8723016\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/happyqwz/article/details/8723016</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">方法是重载运算符，重新定义new，和delete方法。英文书，原理细节描述不清，我的大致理解是，new操作的时候，要跑到内存中去取一块内存单元，CPU在跑着程序，如果能从较近的地方取内存肯定要比去远的地方要好的多。于是，就采取自行管理链表所需内存的方式，定义一freeList链表，为Link类的静态成员变量，初始值为NULL，表示没有“近内存”。调用new方法的时候，如果freelist不为空，那么就在freelist中取一块内存（近内存），如果为NULL，那么只能调用原new操作符，调用“远内存”。调用delete方法的时候，释放的内存不丢弃，而是把它加载到freelist中，供程序之后重新使用。这样的话，程序的运行就可以在小范围内存区域中存取，那么注定要比系统定义的new delete方法要快得多吧...</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/happyqwz/article/details/8723016\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/happyqwz/article/details/8723016</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">方法是重载运算符，重新定义new，和delete方法。英文书，原理细节描述不清，我的大致理解是，new操作的时候，要跑到内存中去取一块内存单元，CPU在跑着程序，如果能从较近的地方取内存肯定要比去远的地方要好的多。于是，就采取自行管理链表所需内存的方式，定义一freeList链表，为Link类的静态成员变量，初始值为NULL，表示没有“近内存”。调用new方法的时候，如果freelist不为空，那么就在freelist中取一块内存（近内存），如果为NULL，那么只能调用原new操作符，调用“远内存”。调用delete方法的时候，释放的内存不丢弃，而是把它加载到freelist中，供程序之后重新使用。这样的话，程序的运行就可以在小范围内存区域中存取，那么注定要比系统定义的new delete方法要快得多吧...</span><br></pre></td></tr></table></figure>"},{"title":"JVM-GC-because-of-allocation-failed","date":"2018-11-17T03:06:31.000Z","_content":"\n\nclass VM_CollectForAllocation : public VM_GC_Operation\n\n### 所有由于内存分配而引起的GC的操作，都是继承于`CollectForAllocation`。\n\n#### G1由于内存分配而引起GC\nclass VM_G1OperationWithAllocRequest : public VM_CollectForAllocation\n\n#### CMS由于内存分配而引起GC（可能是cms，也可能是fullgc）\nclass VM_GenCollectForAllocation : public VM_CollectForAllocation","source":"_posts/JVM-GC-Allocation-failed.md","raw":"---\ntitle: JVM-GC-because-of-allocation-failed\ndate: 2018-11-17 11:06:31\ntags: JVM\n---\n\n\nclass VM_CollectForAllocation : public VM_GC_Operation\n\n### 所有由于内存分配而引起的GC的操作，都是继承于`CollectForAllocation`。\n\n#### G1由于内存分配而引起GC\nclass VM_G1OperationWithAllocRequest : public VM_CollectForAllocation\n\n#### CMS由于内存分配而引起GC（可能是cms，也可能是fullgc）\nclass VM_GenCollectForAllocation : public VM_CollectForAllocation","slug":"JVM-GC-Allocation-failed","published":1,"updated":"2019-09-28T08:51:00.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o82x001lv1npszdlr0fv","content":"<p>class VM_CollectForAllocation : public VM_GC_Operation</p>\n<h3 id=\"所有由于内存分配而引起的GC的操作，都是继承于CollectForAllocation。\"><a href=\"#所有由于内存分配而引起的GC的操作，都是继承于CollectForAllocation。\" class=\"headerlink\" title=\"所有由于内存分配而引起的GC的操作，都是继承于CollectForAllocation。\"></a>所有由于内存分配而引起的GC的操作，都是继承于<code>CollectForAllocation</code>。</h3><h4 id=\"G1由于内存分配而引起GC\"><a href=\"#G1由于内存分配而引起GC\" class=\"headerlink\" title=\"G1由于内存分配而引起GC\"></a>G1由于内存分配而引起GC</h4><p>class VM_G1OperationWithAllocRequest : public VM_CollectForAllocation</p>\n<h4 id=\"CMS由于内存分配而引起GC（可能是cms，也可能是fullgc）\"><a href=\"#CMS由于内存分配而引起GC（可能是cms，也可能是fullgc）\" class=\"headerlink\" title=\"CMS由于内存分配而引起GC（可能是cms，也可能是fullgc）\"></a>CMS由于内存分配而引起GC（可能是cms，也可能是fullgc）</h4><p>class VM_GenCollectForAllocation : public VM_CollectForAllocation</p>\n","site":{"data":{}},"excerpt":"","more":"<p>class VM_CollectForAllocation : public VM_GC_Operation</p>\n<h3 id=\"所有由于内存分配而引起的GC的操作，都是继承于CollectForAllocation。\"><a href=\"#所有由于内存分配而引起的GC的操作，都是继承于CollectForAllocation。\" class=\"headerlink\" title=\"所有由于内存分配而引起的GC的操作，都是继承于CollectForAllocation。\"></a>所有由于内存分配而引起的GC的操作，都是继承于<code>CollectForAllocation</code>。</h3><h4 id=\"G1由于内存分配而引起GC\"><a href=\"#G1由于内存分配而引起GC\" class=\"headerlink\" title=\"G1由于内存分配而引起GC\"></a>G1由于内存分配而引起GC</h4><p>class VM_G1OperationWithAllocRequest : public VM_CollectForAllocation</p>\n<h4 id=\"CMS由于内存分配而引起GC（可能是cms，也可能是fullgc）\"><a href=\"#CMS由于内存分配而引起GC（可能是cms，也可能是fullgc）\" class=\"headerlink\" title=\"CMS由于内存分配而引起GC（可能是cms，也可能是fullgc）\"></a>CMS由于内存分配而引起GC（可能是cms，也可能是fullgc）</h4><p>class VM_GenCollectForAllocation : public VM_CollectForAllocation</p>\n"},{"title":"JVM-GC-G1-FAQ","date":"2018-12-21T09:13:48.000Z","_content":"\n### 这个需要看源码验证下\nWhen the aforementioned young collection takes place, dead objects are collected and any remaining live objects are evacuated and compacted into the Survivor space. G1 has an explicit hard-margin, defined by the G1ReservePercent (default 10%), that results in a percentage of the heap always being available for the Survivor space during evacuation.","source":"_posts/JVM-GC-G1-FAQ.md","raw":"---\ntitle: JVM-GC-G1-FAQ\ndate: 2018-12-21 17:13:48\ntags: JVM\n---\n\n### 这个需要看源码验证下\nWhen the aforementioned young collection takes place, dead objects are collected and any remaining live objects are evacuated and compacted into the Survivor space. G1 has an explicit hard-margin, defined by the G1ReservePercent (default 10%), that results in a percentage of the heap always being available for the Survivor space during evacuation.","slug":"JVM-GC-G1-FAQ","published":1,"updated":"2019-09-28T08:51:00.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o830001mv1npmbht70vv","content":"<h3 id=\"这个需要看源码验证下\"><a href=\"#这个需要看源码验证下\" class=\"headerlink\" title=\"这个需要看源码验证下\"></a>这个需要看源码验证下</h3><p>When the aforementioned young collection takes place, dead objects are collected and any remaining live objects are evacuated and compacted into the Survivor space. G1 has an explicit hard-margin, defined by the G1ReservePercent (default 10%), that results in a percentage of the heap always being available for the Survivor space during evacuation.</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"这个需要看源码验证下\"><a href=\"#这个需要看源码验证下\" class=\"headerlink\" title=\"这个需要看源码验证下\"></a>这个需要看源码验证下</h3><p>When the aforementioned young collection takes place, dead objects are collected and any remaining live objects are evacuated and compacted into the Survivor space. G1 has an explicit hard-margin, defined by the G1ReservePercent (default 10%), that results in a percentage of the heap always being available for the Survivor space during evacuation.</p>\n"},{"title":"JVM-Debug-Openjdk-On-Mac","date":"2017-12-08T04:54:59.000Z","_content":"\n### 用VSCode搭建OpenJDK调试环境\nhttps://zhuanlan.zhihu.com/p/50220757\n\n### hotspot官方调试工具——hsdb\nhttp://www.bubuko.com/infodetail-1858803.html\n\n### 英文，如何读OpenJDK源码\nhttps://www.infoq.com/articles/Introduction-to-HotSpot/\n\n### 大神博客\nhttp://rednaxelafx.iteye.com/\n\n### openjdk源码\nhttps://github.com/unofficial-openjdk/openjdk\n\n### xcode版本\nVersion 11.1 (11A1027)\n\n\n```\n➜  ~ gcc -v\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/4.2.1\nApple clang version 11.0.0 (clang-1100.0.33.8)\nTarget: x86_64-apple-darwin18.7.0\nThread model: posix\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\n```\n\n### boot jdk\n系统装的是jdk 8和jdk 12(但是必须再装一个boot jdk完成configure)\n```\n$ java -version\njava version \"12.0.2\" 2019-07-16\nJava(TM) SE Runtime Environment (build 12.0.2+10)\nJava HotSpot(TM) 64-Bit Server VM (build 12.0.2+10, mixed mode, sharing)\n```\n```\n➜  ~ /usr/libexec/java_home -V\nMatching Java Virtual Machines (2):\n    12.0.2, x86_64:\t\"Java SE 12.0.2\"\t/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home\n    1.8.0_221, x86_64:\t\"Java SE 8\"\t/Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home\n\n/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home\n```\n\n\n### configure build makefile 不要显示制定freetype\n```\n\n```\n\n\n### make all\n```\n\n```\n\n### 验证\n```\n➜  bin pwd\n/Users/ericfei/Code/opensource/openjdk-jdk12u/build/macosx-x86_64-serverANDclient-slowdebug/jdk/bin\n\n➜  bin ./java -version\nopenjdk version \"12.0.2-internal\" 2019-07-16\nOpenJDK Runtime Environment (slowdebug build 12.0.2-internal+0-adhoc.ericfei.openjdk-jdk12u)\nOpenJDK 64-Bit Server VM (slowdebug build 12.0.2-internal+0-adhoc.ericfei.openjdk-jdk12u, mixed mode)\n```\n\n### 导入Clion\n```\n/Users/eric/Code/middleware/openjdk/src/hotspot\n```\n\n### 配置调试\n\n### Clion导致CPU彪高\nFile -> Power Save Mode 可以解决问题\n\n\nRefer:\nhttps://blog.csdn.net/wd2014610/article/details/81664062\nhttps://blog.csdn.net/wd2014610/article/details/81703203#commentBox\nhttps://www.jianshu.com/p/ee7e9176632c","source":"_posts/JVM-Debug-Openjdk-On-Mac.md","raw":"---\ntitle: JVM-Debug-Openjdk-On-Mac\ndate: 2017-12-08 12:54:59\ntags: JVM\n---\n\n### 用VSCode搭建OpenJDK调试环境\nhttps://zhuanlan.zhihu.com/p/50220757\n\n### hotspot官方调试工具——hsdb\nhttp://www.bubuko.com/infodetail-1858803.html\n\n### 英文，如何读OpenJDK源码\nhttps://www.infoq.com/articles/Introduction-to-HotSpot/\n\n### 大神博客\nhttp://rednaxelafx.iteye.com/\n\n### openjdk源码\nhttps://github.com/unofficial-openjdk/openjdk\n\n### xcode版本\nVersion 11.1 (11A1027)\n\n\n```\n➜  ~ gcc -v\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/4.2.1\nApple clang version 11.0.0 (clang-1100.0.33.8)\nTarget: x86_64-apple-darwin18.7.0\nThread model: posix\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\n```\n\n### boot jdk\n系统装的是jdk 8和jdk 12(但是必须再装一个boot jdk完成configure)\n```\n$ java -version\njava version \"12.0.2\" 2019-07-16\nJava(TM) SE Runtime Environment (build 12.0.2+10)\nJava HotSpot(TM) 64-Bit Server VM (build 12.0.2+10, mixed mode, sharing)\n```\n```\n➜  ~ /usr/libexec/java_home -V\nMatching Java Virtual Machines (2):\n    12.0.2, x86_64:\t\"Java SE 12.0.2\"\t/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home\n    1.8.0_221, x86_64:\t\"Java SE 8\"\t/Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home\n\n/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home\n```\n\n\n### configure build makefile 不要显示制定freetype\n```\n\n```\n\n\n### make all\n```\n\n```\n\n### 验证\n```\n➜  bin pwd\n/Users/ericfei/Code/opensource/openjdk-jdk12u/build/macosx-x86_64-serverANDclient-slowdebug/jdk/bin\n\n➜  bin ./java -version\nopenjdk version \"12.0.2-internal\" 2019-07-16\nOpenJDK Runtime Environment (slowdebug build 12.0.2-internal+0-adhoc.ericfei.openjdk-jdk12u)\nOpenJDK 64-Bit Server VM (slowdebug build 12.0.2-internal+0-adhoc.ericfei.openjdk-jdk12u, mixed mode)\n```\n\n### 导入Clion\n```\n/Users/eric/Code/middleware/openjdk/src/hotspot\n```\n\n### 配置调试\n\n### Clion导致CPU彪高\nFile -> Power Save Mode 可以解决问题\n\n\nRefer:\nhttps://blog.csdn.net/wd2014610/article/details/81664062\nhttps://blog.csdn.net/wd2014610/article/details/81703203#commentBox\nhttps://www.jianshu.com/p/ee7e9176632c","slug":"JVM-Debug-Openjdk-On-Mac","published":1,"updated":"2019-10-11T06:58:15.109Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o831001nv1npu4un1qq7","content":"<h3 id=\"用VSCode搭建OpenJDK调试环境\"><a href=\"#用VSCode搭建OpenJDK调试环境\" class=\"headerlink\" title=\"用VSCode搭建OpenJDK调试环境\"></a>用VSCode搭建OpenJDK调试环境</h3><p><a href=\"https://zhuanlan.zhihu.com/p/50220757\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/50220757</a></p>\n<h3 id=\"hotspot官方调试工具——hsdb\"><a href=\"#hotspot官方调试工具——hsdb\" class=\"headerlink\" title=\"hotspot官方调试工具——hsdb\"></a>hotspot官方调试工具——hsdb</h3><p><a href=\"http://www.bubuko.com/infodetail-1858803.html\" target=\"_blank\" rel=\"noopener\">http://www.bubuko.com/infodetail-1858803.html</a></p>\n<h3 id=\"英文，如何读OpenJDK源码\"><a href=\"#英文，如何读OpenJDK源码\" class=\"headerlink\" title=\"英文，如何读OpenJDK源码\"></a>英文，如何读OpenJDK源码</h3><p><a href=\"https://www.infoq.com/articles/Introduction-to-HotSpot/\" target=\"_blank\" rel=\"noopener\">https://www.infoq.com/articles/Introduction-to-HotSpot/</a></p>\n<h3 id=\"大神博客\"><a href=\"#大神博客\" class=\"headerlink\" title=\"大神博客\"></a>大神博客</h3><p><a href=\"http://rednaxelafx.iteye.com/\" target=\"_blank\" rel=\"noopener\">http://rednaxelafx.iteye.com/</a></p>\n<h3 id=\"openjdk源码\"><a href=\"#openjdk源码\" class=\"headerlink\" title=\"openjdk源码\"></a>openjdk源码</h3><p><a href=\"https://github.com/unofficial-openjdk/openjdk\" target=\"_blank\" rel=\"noopener\">https://github.com/unofficial-openjdk/openjdk</a></p>\n<h3 id=\"xcode版本\"><a href=\"#xcode版本\" class=\"headerlink\" title=\"xcode版本\"></a>xcode版本</h3><p>Version 11.1 (11A1027)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  ~ gcc -v</span><br><span class=\"line\">Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/4.2.1</span><br><span class=\"line\">Apple clang version 11.0.0 (clang-1100.0.33.8)</span><br><span class=\"line\">Target: x86_64-apple-darwin18.7.0</span><br><span class=\"line\">Thread model: posix</span><br><span class=\"line\">InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"boot-jdk\"><a href=\"#boot-jdk\" class=\"headerlink\" title=\"boot jdk\"></a>boot jdk</h3><p>系统装的是jdk 8和jdk 12(但是必须再装一个boot jdk完成configure)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ java -version</span><br><span class=\"line\">java version &quot;12.0.2&quot; 2019-07-16</span><br><span class=\"line\">Java(TM) SE Runtime Environment (build 12.0.2+10)</span><br><span class=\"line\">Java HotSpot(TM) 64-Bit Server VM (build 12.0.2+10, mixed mode, sharing)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  ~ /usr/libexec/java_home -V</span><br><span class=\"line\">Matching Java Virtual Machines (2):</span><br><span class=\"line\">    12.0.2, x86_64:\t&quot;Java SE 12.0.2&quot;\t/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home</span><br><span class=\"line\">    1.8.0_221, x86_64:\t&quot;Java SE 8&quot;\t/Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home</span><br><span class=\"line\"></span><br><span class=\"line\">/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"configure-build-makefile-不要显示制定freetype\"><a href=\"#configure-build-makefile-不要显示制定freetype\" class=\"headerlink\" title=\"configure build makefile 不要显示制定freetype\"></a>configure build makefile 不要显示制定freetype</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"make-all\"><a href=\"#make-all\" class=\"headerlink\" title=\"make all\"></a>make all</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  bin pwd</span><br><span class=\"line\">/Users/ericfei/Code/opensource/openjdk-jdk12u/build/macosx-x86_64-serverANDclient-slowdebug/jdk/bin</span><br><span class=\"line\"></span><br><span class=\"line\">➜  bin ./java -version</span><br><span class=\"line\">openjdk version &quot;12.0.2-internal&quot; 2019-07-16</span><br><span class=\"line\">OpenJDK Runtime Environment (slowdebug build 12.0.2-internal+0-adhoc.ericfei.openjdk-jdk12u)</span><br><span class=\"line\">OpenJDK 64-Bit Server VM (slowdebug build 12.0.2-internal+0-adhoc.ericfei.openjdk-jdk12u, mixed mode)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"导入Clion\"><a href=\"#导入Clion\" class=\"headerlink\" title=\"导入Clion\"></a>导入Clion</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/Users/eric/Code/middleware/openjdk/src/hotspot</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"配置调试\"><a href=\"#配置调试\" class=\"headerlink\" title=\"配置调试\"></a>配置调试</h3><h3 id=\"Clion导致CPU彪高\"><a href=\"#Clion导致CPU彪高\" class=\"headerlink\" title=\"Clion导致CPU彪高\"></a>Clion导致CPU彪高</h3><p>File -&gt; Power Save Mode 可以解决问题</p>\n<p>Refer:<br><a href=\"https://blog.csdn.net/wd2014610/article/details/81664062\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/wd2014610/article/details/81664062</a><br><a href=\"https://blog.csdn.net/wd2014610/article/details/81703203#commentBox\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/wd2014610/article/details/81703203#commentBox</a><br><a href=\"https://www.jianshu.com/p/ee7e9176632c\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/ee7e9176632c</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"用VSCode搭建OpenJDK调试环境\"><a href=\"#用VSCode搭建OpenJDK调试环境\" class=\"headerlink\" title=\"用VSCode搭建OpenJDK调试环境\"></a>用VSCode搭建OpenJDK调试环境</h3><p><a href=\"https://zhuanlan.zhihu.com/p/50220757\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/50220757</a></p>\n<h3 id=\"hotspot官方调试工具——hsdb\"><a href=\"#hotspot官方调试工具——hsdb\" class=\"headerlink\" title=\"hotspot官方调试工具——hsdb\"></a>hotspot官方调试工具——hsdb</h3><p><a href=\"http://www.bubuko.com/infodetail-1858803.html\" target=\"_blank\" rel=\"noopener\">http://www.bubuko.com/infodetail-1858803.html</a></p>\n<h3 id=\"英文，如何读OpenJDK源码\"><a href=\"#英文，如何读OpenJDK源码\" class=\"headerlink\" title=\"英文，如何读OpenJDK源码\"></a>英文，如何读OpenJDK源码</h3><p><a href=\"https://www.infoq.com/articles/Introduction-to-HotSpot/\" target=\"_blank\" rel=\"noopener\">https://www.infoq.com/articles/Introduction-to-HotSpot/</a></p>\n<h3 id=\"大神博客\"><a href=\"#大神博客\" class=\"headerlink\" title=\"大神博客\"></a>大神博客</h3><p><a href=\"http://rednaxelafx.iteye.com/\" target=\"_blank\" rel=\"noopener\">http://rednaxelafx.iteye.com/</a></p>\n<h3 id=\"openjdk源码\"><a href=\"#openjdk源码\" class=\"headerlink\" title=\"openjdk源码\"></a>openjdk源码</h3><p><a href=\"https://github.com/unofficial-openjdk/openjdk\" target=\"_blank\" rel=\"noopener\">https://github.com/unofficial-openjdk/openjdk</a></p>\n<h3 id=\"xcode版本\"><a href=\"#xcode版本\" class=\"headerlink\" title=\"xcode版本\"></a>xcode版本</h3><p>Version 11.1 (11A1027)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  ~ gcc -v</span><br><span class=\"line\">Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/4.2.1</span><br><span class=\"line\">Apple clang version 11.0.0 (clang-1100.0.33.8)</span><br><span class=\"line\">Target: x86_64-apple-darwin18.7.0</span><br><span class=\"line\">Thread model: posix</span><br><span class=\"line\">InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"boot-jdk\"><a href=\"#boot-jdk\" class=\"headerlink\" title=\"boot jdk\"></a>boot jdk</h3><p>系统装的是jdk 8和jdk 12(但是必须再装一个boot jdk完成configure)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ java -version</span><br><span class=\"line\">java version &quot;12.0.2&quot; 2019-07-16</span><br><span class=\"line\">Java(TM) SE Runtime Environment (build 12.0.2+10)</span><br><span class=\"line\">Java HotSpot(TM) 64-Bit Server VM (build 12.0.2+10, mixed mode, sharing)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  ~ /usr/libexec/java_home -V</span><br><span class=\"line\">Matching Java Virtual Machines (2):</span><br><span class=\"line\">    12.0.2, x86_64:\t&quot;Java SE 12.0.2&quot;\t/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home</span><br><span class=\"line\">    1.8.0_221, x86_64:\t&quot;Java SE 8&quot;\t/Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home</span><br><span class=\"line\"></span><br><span class=\"line\">/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"configure-build-makefile-不要显示制定freetype\"><a href=\"#configure-build-makefile-不要显示制定freetype\" class=\"headerlink\" title=\"configure build makefile 不要显示制定freetype\"></a>configure build makefile 不要显示制定freetype</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"make-all\"><a href=\"#make-all\" class=\"headerlink\" title=\"make all\"></a>make all</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"验证\"><a href=\"#验证\" class=\"headerlink\" title=\"验证\"></a>验证</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  bin pwd</span><br><span class=\"line\">/Users/ericfei/Code/opensource/openjdk-jdk12u/build/macosx-x86_64-serverANDclient-slowdebug/jdk/bin</span><br><span class=\"line\"></span><br><span class=\"line\">➜  bin ./java -version</span><br><span class=\"line\">openjdk version &quot;12.0.2-internal&quot; 2019-07-16</span><br><span class=\"line\">OpenJDK Runtime Environment (slowdebug build 12.0.2-internal+0-adhoc.ericfei.openjdk-jdk12u)</span><br><span class=\"line\">OpenJDK 64-Bit Server VM (slowdebug build 12.0.2-internal+0-adhoc.ericfei.openjdk-jdk12u, mixed mode)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"导入Clion\"><a href=\"#导入Clion\" class=\"headerlink\" title=\"导入Clion\"></a>导入Clion</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/Users/eric/Code/middleware/openjdk/src/hotspot</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"配置调试\"><a href=\"#配置调试\" class=\"headerlink\" title=\"配置调试\"></a>配置调试</h3><h3 id=\"Clion导致CPU彪高\"><a href=\"#Clion导致CPU彪高\" class=\"headerlink\" title=\"Clion导致CPU彪高\"></a>Clion导致CPU彪高</h3><p>File -&gt; Power Save Mode 可以解决问题</p>\n<p>Refer:<br><a href=\"https://blog.csdn.net/wd2014610/article/details/81664062\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/wd2014610/article/details/81664062</a><br><a href=\"https://blog.csdn.net/wd2014610/article/details/81703203#commentBox\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/wd2014610/article/details/81703203#commentBox</a><br><a href=\"https://www.jianshu.com/p/ee7e9176632c\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/ee7e9176632c</a></p>\n"},{"title":"JVM-GC-CMS-Concurrent-Mode-Failure","date":"2019-01-10T02:44:19.000Z","_content":"\nhttps://www.cnblogs.com/Jaxlinda/p/7145912.html","source":"_posts/JVM-GC-CMS-Concurrent-Mode-Failure.md","raw":"---\ntitle: JVM-GC-CMS-Concurrent-Mode-Failure\ndate: 2019-01-10 10:44:19\ntags: JVM\n---\n\nhttps://www.cnblogs.com/Jaxlinda/p/7145912.html","slug":"JVM-GC-CMS-Concurrent-Mode-Failure","published":1,"updated":"2019-09-28T08:51:00.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o831001ov1npqixf4eh7","content":"<p><a href=\"https://www.cnblogs.com/Jaxlinda/p/7145912.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/Jaxlinda/p/7145912.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.cnblogs.com/Jaxlinda/p/7145912.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/Jaxlinda/p/7145912.html</a></p>\n"},{"title":"JVM-CMS-Thread","date":"2018-11-16T03:03:53.000Z","_content":"\n##\nhttps://blog.csdn.net/foolishandstupid/article/details/77430875\n\nParNew+CMS是Hotspot JVM中一对经典的GC组合，其中ParNew负责Young区的GC，CMS负责Old区的GC。\n\nJVM启动会调用`Universe::initialize_heap`初始化Heap，如果JVM启动参数中指定了`-XX:+UseConcMarkSweepGC`，初始化堆时会创建CMS收集器（cms colloector）。\n``` GenCollectedHeap::initialize()\nif (collector_policy()->is_concurrent_mark_sweep_policy()) {\n    bool success = create_cms_collector();\n    if (!success) return JNI_ENOMEM;\n}\n```\n忽略下中间部分细节，通过调试代码，最终会JVM会在`ConcurrentMarkSweepThread`的构造函数中启动该线程。JVM中C++对线程的抽象与Java非常类似，启动线程后，内核调度到该线程时，会执行它的run()方法。\n``` \n// Create & start a CMS thread for this CMS collector\n  _cmsThread = ConcurrentMarkSweepThread::start(this);\n\n\n```\nStacktrace展示了CMS线程的启动时机。\n```\nConcurrentGCThread::create_and_start concurrentGCThread.cpp:41\nConcurrentMarkSweepThread::ConcurrentMarkSweepThread concurrentMarkSweepThread.cpp:69\nConcurrentMarkSweepThread::ConcurrentMarkSweepThread concurrentMarkSweepThread.cpp:49\nConcurrentMarkSweepThread::start concurrentMarkSweepThread.cpp:107\nCMSCollector::CMSCollector concurrentMarkSweepGeneration.cpp:592\nCMSCollector::CMSCollector concurrentMarkSweepGeneration.cpp:490\nGenCollectedHeap::create_cms_collector genCollectedHeap.cpp:829\nGenCollectedHeap::initialize genCollectedHeap.cpp:144\nUniverse::initialize_heap universe.cpp:762\nuniverse_init universe.cpp:672\ninit_globals init.cpp:110\nThreads::create_vm thread.cpp:3630\nJNI_CreateJavaVM_inner jni.cpp:3937\nJNI_CreateJavaVM jni.cpp:4032\nInitializeJVM\nJavaMain\n```\n\n\n通过简单的分析，会发现`ConcurrentMarkSweepThread`自己没有run()，但是它的父类`ConcurrentGCThread`中有，如下所示，run_service是一个纯虚函数（类似Java的抽象方法），自然在运行时会指向子类`ConcurrentMarkSweepThread`对`run_service`的实现。\n```\nvoid ConcurrentGCThread::run() {\n  initialize_in_thread();\n  wait_for_universe_init();\n\n  run_service(); // virtual void run_service() = 0; 虚函数，指向子类ConcurrentMarkSweepThread的实现\n\n  terminate();\n}\n```\n\n在`run_service`中`while (true)`的形式异常明显，暗示着这是一个生命周期很长的线程，只要没有被terminate，就会永远在后台执行。`ConcurrentMarkSweepThread`会在它的生命周期内，默认每隔`2000ms`就检查下，进程需不需要进行`background cms gc`。`sleepBeforeNextCycle()`描述了为什么是`2000ms`和什么样的情况下会需要GC，而`_collector->collect_in_background`会描述什么是`background`式的CMS。\n```\nvoid ConcurrentMarkSweepThread::run_service() {\n  assert(this == cmst(), \"just checking\");\n\n  if (BindCMSThreadToCPU && !os::bind_to_processor(CPUForCMSThread)) {\n    log_warning(gc)(\"Couldn't bind CMS thread to processor \" UINTX_FORMAT, CPUForCMSThread);\n  }\n\n  while (!should_terminate()) {\n    sleepBeforeNextCycle();\n    if (should_terminate()) break;\n    GCIdMark gc_id_mark;\n    GCCause::Cause cause = _collector->_full_gc_requested ?\n      _collector->_full_gc_cause : GCCause::_cms_concurrent_mark;\n    _collector->collect_in_background(cause);\n  }\n\n  // Check that the state of any protocol for synchronization\n  // between background (CMS) and foreground collector is \"clean\"\n  // (i.e. will not potentially block the foreground collector,\n  // requiring action by us).\n  verify_ok_to_terminate();\n}\n```\n`CMSWaitDuration`默认宏定义为2000，调用`wait_on_cms_lock_for_scavenge(CMSWaitDuration)`后让当前线程等待，注意下它的注释，有3种情况当前的线程会被唤醒，\n 下一次`synchronous GC`\n 一个并发Full gc请求\n 2000ms的超时到达\n当线程醒后，只有当满足`_collector->shouldConcurrentCollect()`才能跳出当前调用，才能在外层真正调用CMS。\n```\nvoid ConcurrentMarkSweepThread::sleepBeforeNextCycle() {\n  while (!should_terminate()) {\n    if(CMSWaitDuration >= 0) {\n      // Wait until the next synchronous GC, a concurrent full gc\n      // request or a timeout, whichever is earlier.\n      wait_on_cms_lock_for_scavenge(CMSWaitDuration);\n    } else {\n      // Wait until any cms_lock event or check interval not to call shouldConcurrentCollect permanently\n      wait_on_cms_lock(CMSCheckInterval);\n    }\n    // Check if we should start a CMS collection cycle\n    if (_collector->shouldConcurrentCollect()) {\n      return;\n    }\n    // .. collection criterion not yet met, let's go back\n    // and wait some more\n  }\n}\n```\n以下有8种Case会返回。重点分析下Case \n\nCase 4:\n\n``` \nbool CMSCollector::shouldConcurrentCollect() {\n  // Case 1\n  if (_full_gc_requested) {\n    log.print(\"CMSCollector: collect because of explicit  gc request (or GCLocker)\");\n    return true;\n  }\n  ...\n  // If the estimated time to complete a cms collection (cms_duration())\n  // is less than the estimated time remaining until the cms generation\n  // is full, start a collection.\n  if (!UseCMSInitiatingOccupancyOnly) {\n    if (stats().valid()) {\n      // Case 2\n      if (stats().time_until_cms_start() == 0.0) {\n        return true;\n      }\n    } else {\n      // We want to conservatively collect somewhat early in order\n      // to try and \"bootstrap\" our CMS/promotion statistics;\n      // this branch will not fire after the first successful CMS\n      // collection because the stats should then be valid.\n      // Case 3\n      if (_cmsGen->occupancy() >= _bootstrap_occupancy) {\n        log.print(\" CMSCollector: collect for bootstrapping statistics: occupancy = %f, boot occupancy = %f\",\n                  _cmsGen->occupancy(), _bootstrap_occupancy);\n        return true;\n      }\n    }\n  }\n\n  // Otherwise, we start a collection cycle if\n  // old gen want a collection cycle started. Each may use\n  // an appropriate criterion for making this decision.\n  // XXX We need to make sure that the gen expansion\n  // criterion dovetails well with this. XXX NEED TO FIX THIS\n  // Case 4\n  if (_cmsGen->should_concurrent_collect()) {\n    log.print(\"CMS old gen initiated\");\n    return true;\n  }\n\n  // We start a collection if we believe an incremental collection may fail;\n  // this is not likely to be productive in practice because it's probably too\n  // late anyway.\n  GenCollectedHeap* gch = GenCollectedHeap::heap();\n  assert(gch->collector_policy()->is_generation_policy(),\n         \"You may want to check the correctness of the following\");\n  // Case 5\n  if (gch->incremental_collection_will_fail(true /* consult_young */)) {\n    log.print(\"CMSCollector: collect because incremental collection will fail \");\n    return true;\n  }\n\n  // Case 6\n  if (MetaspaceGC::should_concurrent_collect()) {\n    log.print(\"CMSCollector: collect for metadata allocation \");\n    return true;\n  }\n\n  // CMSTriggerInterval starts a CMS cycle if enough time has passed.\n  if (CMSTriggerInterval >= 0) {\n    // Case 7\n    if (CMSTriggerInterval == 0) {\n      // Trigger always\n      return true;\n    }\n\n    // Check the CMS time since begin (we do not check the stats validity\n    // as we want to be able to trigger the first CMS cycle as well)\n    // Case 8\n    if (stats().cms_time_since_begin() >= (CMSTriggerInterval / ((double) MILLIUNITS))) {\n      if (stats().valid()) {\n        log.print(\"CMSCollector: collect because of trigger interval (time since last begin %3.7f secs)\",\n                  stats().cms_time_since_begin());\n      } else {\n        log.print(\"CMSCollector: collect because of trigger interval (first collection)\");\n      }\n      return true;\n    }\n  }\n\n  return false;\n}\n```\nCase 5: 去询问下young区，下次如果发送ygc，在最坏的情况下，所有eden+survivor假如都不能被回收，都需要晋升，在old区有没有连续的内存来供应这些晋升的对象。如果连这些连续内存都没有，那就一定要CMS了。\n```\nbool incremental_collection_will_fail(bool consult_young) {\n    // The first disjunct remembers if an incremental collection failed, even\n    // when we thought (second disjunct) that it would not.\n    return incremental_collection_failed() ||\n           (consult_young && !_young_gen->collection_attempt_is_safe());\n}\n\nbool DefNewGeneration::collection_attempt_is_safe() {\n  if (!to()->is_empty()) {\n    log_trace(gc)(\":: to is not empty ::\");\n    return false;\n  }\n  if (_old_gen == NULL) {\n    GenCollectedHeap* gch = GenCollectedHeap::heap();\n    _old_gen = gch->old_gen();\n  }\n  return _old_gen->promotion_attempt_is_safe(used()); \n}\n\nsize_t DefNewGeneration::used() const {\n  return eden()->used()\n       + from()->used();      // to() is only used during scavenge\n}\n\nbool Generation::promotion_attempt_is_safe(size_t max_promotion_in_bytes) const {\n  size_t available = max_contiguous_available();\n  bool   res = (available >= max_promotion_in_bytes);\n  log_trace(gc)(\"Generation: promo attempt is%s safe: available(\" SIZE_FORMAT \") %s max_promo(\" SIZE_FORMAT \")\",\n                res? \"\":\" not\", available, res? \">=\":\"<\", max_promotion_in_bytes);\n  return res;\n}\n```","source":"_posts/JVM-GC-CMS-Thread.md","raw":"---\ntitle: JVM-CMS-Thread\ndate: 2018-11-16 11:03:53\ntags: JVM\n---\n\n##\nhttps://blog.csdn.net/foolishandstupid/article/details/77430875\n\nParNew+CMS是Hotspot JVM中一对经典的GC组合，其中ParNew负责Young区的GC，CMS负责Old区的GC。\n\nJVM启动会调用`Universe::initialize_heap`初始化Heap，如果JVM启动参数中指定了`-XX:+UseConcMarkSweepGC`，初始化堆时会创建CMS收集器（cms colloector）。\n``` GenCollectedHeap::initialize()\nif (collector_policy()->is_concurrent_mark_sweep_policy()) {\n    bool success = create_cms_collector();\n    if (!success) return JNI_ENOMEM;\n}\n```\n忽略下中间部分细节，通过调试代码，最终会JVM会在`ConcurrentMarkSweepThread`的构造函数中启动该线程。JVM中C++对线程的抽象与Java非常类似，启动线程后，内核调度到该线程时，会执行它的run()方法。\n``` \n// Create & start a CMS thread for this CMS collector\n  _cmsThread = ConcurrentMarkSweepThread::start(this);\n\n\n```\nStacktrace展示了CMS线程的启动时机。\n```\nConcurrentGCThread::create_and_start concurrentGCThread.cpp:41\nConcurrentMarkSweepThread::ConcurrentMarkSweepThread concurrentMarkSweepThread.cpp:69\nConcurrentMarkSweepThread::ConcurrentMarkSweepThread concurrentMarkSweepThread.cpp:49\nConcurrentMarkSweepThread::start concurrentMarkSweepThread.cpp:107\nCMSCollector::CMSCollector concurrentMarkSweepGeneration.cpp:592\nCMSCollector::CMSCollector concurrentMarkSweepGeneration.cpp:490\nGenCollectedHeap::create_cms_collector genCollectedHeap.cpp:829\nGenCollectedHeap::initialize genCollectedHeap.cpp:144\nUniverse::initialize_heap universe.cpp:762\nuniverse_init universe.cpp:672\ninit_globals init.cpp:110\nThreads::create_vm thread.cpp:3630\nJNI_CreateJavaVM_inner jni.cpp:3937\nJNI_CreateJavaVM jni.cpp:4032\nInitializeJVM\nJavaMain\n```\n\n\n通过简单的分析，会发现`ConcurrentMarkSweepThread`自己没有run()，但是它的父类`ConcurrentGCThread`中有，如下所示，run_service是一个纯虚函数（类似Java的抽象方法），自然在运行时会指向子类`ConcurrentMarkSweepThread`对`run_service`的实现。\n```\nvoid ConcurrentGCThread::run() {\n  initialize_in_thread();\n  wait_for_universe_init();\n\n  run_service(); // virtual void run_service() = 0; 虚函数，指向子类ConcurrentMarkSweepThread的实现\n\n  terminate();\n}\n```\n\n在`run_service`中`while (true)`的形式异常明显，暗示着这是一个生命周期很长的线程，只要没有被terminate，就会永远在后台执行。`ConcurrentMarkSweepThread`会在它的生命周期内，默认每隔`2000ms`就检查下，进程需不需要进行`background cms gc`。`sleepBeforeNextCycle()`描述了为什么是`2000ms`和什么样的情况下会需要GC，而`_collector->collect_in_background`会描述什么是`background`式的CMS。\n```\nvoid ConcurrentMarkSweepThread::run_service() {\n  assert(this == cmst(), \"just checking\");\n\n  if (BindCMSThreadToCPU && !os::bind_to_processor(CPUForCMSThread)) {\n    log_warning(gc)(\"Couldn't bind CMS thread to processor \" UINTX_FORMAT, CPUForCMSThread);\n  }\n\n  while (!should_terminate()) {\n    sleepBeforeNextCycle();\n    if (should_terminate()) break;\n    GCIdMark gc_id_mark;\n    GCCause::Cause cause = _collector->_full_gc_requested ?\n      _collector->_full_gc_cause : GCCause::_cms_concurrent_mark;\n    _collector->collect_in_background(cause);\n  }\n\n  // Check that the state of any protocol for synchronization\n  // between background (CMS) and foreground collector is \"clean\"\n  // (i.e. will not potentially block the foreground collector,\n  // requiring action by us).\n  verify_ok_to_terminate();\n}\n```\n`CMSWaitDuration`默认宏定义为2000，调用`wait_on_cms_lock_for_scavenge(CMSWaitDuration)`后让当前线程等待，注意下它的注释，有3种情况当前的线程会被唤醒，\n 下一次`synchronous GC`\n 一个并发Full gc请求\n 2000ms的超时到达\n当线程醒后，只有当满足`_collector->shouldConcurrentCollect()`才能跳出当前调用，才能在外层真正调用CMS。\n```\nvoid ConcurrentMarkSweepThread::sleepBeforeNextCycle() {\n  while (!should_terminate()) {\n    if(CMSWaitDuration >= 0) {\n      // Wait until the next synchronous GC, a concurrent full gc\n      // request or a timeout, whichever is earlier.\n      wait_on_cms_lock_for_scavenge(CMSWaitDuration);\n    } else {\n      // Wait until any cms_lock event or check interval not to call shouldConcurrentCollect permanently\n      wait_on_cms_lock(CMSCheckInterval);\n    }\n    // Check if we should start a CMS collection cycle\n    if (_collector->shouldConcurrentCollect()) {\n      return;\n    }\n    // .. collection criterion not yet met, let's go back\n    // and wait some more\n  }\n}\n```\n以下有8种Case会返回。重点分析下Case \n\nCase 4:\n\n``` \nbool CMSCollector::shouldConcurrentCollect() {\n  // Case 1\n  if (_full_gc_requested) {\n    log.print(\"CMSCollector: collect because of explicit  gc request (or GCLocker)\");\n    return true;\n  }\n  ...\n  // If the estimated time to complete a cms collection (cms_duration())\n  // is less than the estimated time remaining until the cms generation\n  // is full, start a collection.\n  if (!UseCMSInitiatingOccupancyOnly) {\n    if (stats().valid()) {\n      // Case 2\n      if (stats().time_until_cms_start() == 0.0) {\n        return true;\n      }\n    } else {\n      // We want to conservatively collect somewhat early in order\n      // to try and \"bootstrap\" our CMS/promotion statistics;\n      // this branch will not fire after the first successful CMS\n      // collection because the stats should then be valid.\n      // Case 3\n      if (_cmsGen->occupancy() >= _bootstrap_occupancy) {\n        log.print(\" CMSCollector: collect for bootstrapping statistics: occupancy = %f, boot occupancy = %f\",\n                  _cmsGen->occupancy(), _bootstrap_occupancy);\n        return true;\n      }\n    }\n  }\n\n  // Otherwise, we start a collection cycle if\n  // old gen want a collection cycle started. Each may use\n  // an appropriate criterion for making this decision.\n  // XXX We need to make sure that the gen expansion\n  // criterion dovetails well with this. XXX NEED TO FIX THIS\n  // Case 4\n  if (_cmsGen->should_concurrent_collect()) {\n    log.print(\"CMS old gen initiated\");\n    return true;\n  }\n\n  // We start a collection if we believe an incremental collection may fail;\n  // this is not likely to be productive in practice because it's probably too\n  // late anyway.\n  GenCollectedHeap* gch = GenCollectedHeap::heap();\n  assert(gch->collector_policy()->is_generation_policy(),\n         \"You may want to check the correctness of the following\");\n  // Case 5\n  if (gch->incremental_collection_will_fail(true /* consult_young */)) {\n    log.print(\"CMSCollector: collect because incremental collection will fail \");\n    return true;\n  }\n\n  // Case 6\n  if (MetaspaceGC::should_concurrent_collect()) {\n    log.print(\"CMSCollector: collect for metadata allocation \");\n    return true;\n  }\n\n  // CMSTriggerInterval starts a CMS cycle if enough time has passed.\n  if (CMSTriggerInterval >= 0) {\n    // Case 7\n    if (CMSTriggerInterval == 0) {\n      // Trigger always\n      return true;\n    }\n\n    // Check the CMS time since begin (we do not check the stats validity\n    // as we want to be able to trigger the first CMS cycle as well)\n    // Case 8\n    if (stats().cms_time_since_begin() >= (CMSTriggerInterval / ((double) MILLIUNITS))) {\n      if (stats().valid()) {\n        log.print(\"CMSCollector: collect because of trigger interval (time since last begin %3.7f secs)\",\n                  stats().cms_time_since_begin());\n      } else {\n        log.print(\"CMSCollector: collect because of trigger interval (first collection)\");\n      }\n      return true;\n    }\n  }\n\n  return false;\n}\n```\nCase 5: 去询问下young区，下次如果发送ygc，在最坏的情况下，所有eden+survivor假如都不能被回收，都需要晋升，在old区有没有连续的内存来供应这些晋升的对象。如果连这些连续内存都没有，那就一定要CMS了。\n```\nbool incremental_collection_will_fail(bool consult_young) {\n    // The first disjunct remembers if an incremental collection failed, even\n    // when we thought (second disjunct) that it would not.\n    return incremental_collection_failed() ||\n           (consult_young && !_young_gen->collection_attempt_is_safe());\n}\n\nbool DefNewGeneration::collection_attempt_is_safe() {\n  if (!to()->is_empty()) {\n    log_trace(gc)(\":: to is not empty ::\");\n    return false;\n  }\n  if (_old_gen == NULL) {\n    GenCollectedHeap* gch = GenCollectedHeap::heap();\n    _old_gen = gch->old_gen();\n  }\n  return _old_gen->promotion_attempt_is_safe(used()); \n}\n\nsize_t DefNewGeneration::used() const {\n  return eden()->used()\n       + from()->used();      // to() is only used during scavenge\n}\n\nbool Generation::promotion_attempt_is_safe(size_t max_promotion_in_bytes) const {\n  size_t available = max_contiguous_available();\n  bool   res = (available >= max_promotion_in_bytes);\n  log_trace(gc)(\"Generation: promo attempt is%s safe: available(\" SIZE_FORMAT \") %s max_promo(\" SIZE_FORMAT \")\",\n                res? \"\":\" not\", available, res? \">=\":\"<\", max_promotion_in_bytes);\n  return res;\n}\n```","slug":"JVM-GC-CMS-Thread","published":1,"updated":"2019-09-28T08:51:00.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o832001pv1nppouura90","content":"<p>##<br><a href=\"https://blog.csdn.net/foolishandstupid/article/details/77430875\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/foolishandstupid/article/details/77430875</a></p>\n<p>ParNew+CMS是Hotspot JVM中一对经典的GC组合，其中ParNew负责Young区的GC，CMS负责Old区的GC。</p>\n<p>JVM启动会调用<code>Universe::initialize_heap</code>初始化Heap，如果JVM启动参数中指定了<code>-XX:+UseConcMarkSweepGC</code>，初始化堆时会创建CMS收集器（cms colloector）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (collector_policy()-&gt;is_concurrent_mark_sweep_policy()) &#123;</span><br><span class=\"line\">    bool success = create_cms_collector();</span><br><span class=\"line\">    if (!success) return JNI_ENOMEM;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>忽略下中间部分细节，通过调试代码，最终会JVM会在<code>ConcurrentMarkSweepThread</code>的构造函数中启动该线程。JVM中C++对线程的抽象与Java非常类似，启动线程后，内核调度到该线程时，会执行它的run()方法。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Create &amp; start a CMS thread for this CMS collector</span><br><span class=\"line\">  _cmsThread = ConcurrentMarkSweepThread::start(this);</span><br></pre></td></tr></table></figure>\n\n<p>Stacktrace展示了CMS线程的启动时机。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ConcurrentGCThread::create_and_start concurrentGCThread.cpp:41</span><br><span class=\"line\">ConcurrentMarkSweepThread::ConcurrentMarkSweepThread concurrentMarkSweepThread.cpp:69</span><br><span class=\"line\">ConcurrentMarkSweepThread::ConcurrentMarkSweepThread concurrentMarkSweepThread.cpp:49</span><br><span class=\"line\">ConcurrentMarkSweepThread::start concurrentMarkSweepThread.cpp:107</span><br><span class=\"line\">CMSCollector::CMSCollector concurrentMarkSweepGeneration.cpp:592</span><br><span class=\"line\">CMSCollector::CMSCollector concurrentMarkSweepGeneration.cpp:490</span><br><span class=\"line\">GenCollectedHeap::create_cms_collector genCollectedHeap.cpp:829</span><br><span class=\"line\">GenCollectedHeap::initialize genCollectedHeap.cpp:144</span><br><span class=\"line\">Universe::initialize_heap universe.cpp:762</span><br><span class=\"line\">universe_init universe.cpp:672</span><br><span class=\"line\">init_globals init.cpp:110</span><br><span class=\"line\">Threads::create_vm thread.cpp:3630</span><br><span class=\"line\">JNI_CreateJavaVM_inner jni.cpp:3937</span><br><span class=\"line\">JNI_CreateJavaVM jni.cpp:4032</span><br><span class=\"line\">InitializeJVM</span><br><span class=\"line\">JavaMain</span><br></pre></td></tr></table></figure>\n\n<p>通过简单的分析，会发现<code>ConcurrentMarkSweepThread</code>自己没有run()，但是它的父类<code>ConcurrentGCThread</code>中有，如下所示，run_service是一个纯虚函数（类似Java的抽象方法），自然在运行时会指向子类<code>ConcurrentMarkSweepThread</code>对<code>run_service</code>的实现。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void ConcurrentGCThread::run() &#123;</span><br><span class=\"line\">  initialize_in_thread();</span><br><span class=\"line\">  wait_for_universe_init();</span><br><span class=\"line\"></span><br><span class=\"line\">  run_service(); // virtual void run_service() = 0; 虚函数，指向子类ConcurrentMarkSweepThread的实现</span><br><span class=\"line\"></span><br><span class=\"line\">  terminate();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在<code>run_service</code>中<code>while (true)</code>的形式异常明显，暗示着这是一个生命周期很长的线程，只要没有被terminate，就会永远在后台执行。<code>ConcurrentMarkSweepThread</code>会在它的生命周期内，默认每隔<code>2000ms</code>就检查下，进程需不需要进行<code>background cms gc</code>。<code>sleepBeforeNextCycle()</code>描述了为什么是<code>2000ms</code>和什么样的情况下会需要GC，而<code>_collector-&gt;collect_in_background</code>会描述什么是<code>background</code>式的CMS。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void ConcurrentMarkSweepThread::run_service() &#123;</span><br><span class=\"line\">  assert(this == cmst(), &quot;just checking&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">  if (BindCMSThreadToCPU &amp;&amp; !os::bind_to_processor(CPUForCMSThread)) &#123;</span><br><span class=\"line\">    log_warning(gc)(&quot;Couldn&apos;t bind CMS thread to processor &quot; UINTX_FORMAT, CPUForCMSThread);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  while (!should_terminate()) &#123;</span><br><span class=\"line\">    sleepBeforeNextCycle();</span><br><span class=\"line\">    if (should_terminate()) break;</span><br><span class=\"line\">    GCIdMark gc_id_mark;</span><br><span class=\"line\">    GCCause::Cause cause = _collector-&gt;_full_gc_requested ?</span><br><span class=\"line\">      _collector-&gt;_full_gc_cause : GCCause::_cms_concurrent_mark;</span><br><span class=\"line\">    _collector-&gt;collect_in_background(cause);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // Check that the state of any protocol for synchronization</span><br><span class=\"line\">  // between background (CMS) and foreground collector is &quot;clean&quot;</span><br><span class=\"line\">  // (i.e. will not potentially block the foreground collector,</span><br><span class=\"line\">  // requiring action by us).</span><br><span class=\"line\">  verify_ok_to_terminate();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><code>CMSWaitDuration</code>默认宏定义为2000，调用<code>wait_on_cms_lock_for_scavenge(CMSWaitDuration)</code>后让当前线程等待，注意下它的注释，有3种情况当前的线程会被唤醒，<br> 下一次<code>synchronous GC</code><br> 一个并发Full gc请求<br> 2000ms的超时到达<br>当线程醒后，只有当满足<code>_collector-&gt;shouldConcurrentCollect()</code>才能跳出当前调用，才能在外层真正调用CMS。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void ConcurrentMarkSweepThread::sleepBeforeNextCycle() &#123;</span><br><span class=\"line\">  while (!should_terminate()) &#123;</span><br><span class=\"line\">    if(CMSWaitDuration &gt;= 0) &#123;</span><br><span class=\"line\">      // Wait until the next synchronous GC, a concurrent full gc</span><br><span class=\"line\">      // request or a timeout, whichever is earlier.</span><br><span class=\"line\">      wait_on_cms_lock_for_scavenge(CMSWaitDuration);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      // Wait until any cms_lock event or check interval not to call shouldConcurrentCollect permanently</span><br><span class=\"line\">      wait_on_cms_lock(CMSCheckInterval);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Check if we should start a CMS collection cycle</span><br><span class=\"line\">    if (_collector-&gt;shouldConcurrentCollect()) &#123;</span><br><span class=\"line\">      return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // .. collection criterion not yet met, let&apos;s go back</span><br><span class=\"line\">    // and wait some more</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>以下有8种Case会返回。重点分析下Case </p>\n<p>Case 4:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bool CMSCollector::shouldConcurrentCollect() &#123;</span><br><span class=\"line\">  // Case 1</span><br><span class=\"line\">  if (_full_gc_requested) &#123;</span><br><span class=\"line\">    log.print(&quot;CMSCollector: collect because of explicit  gc request (or GCLocker)&quot;);</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  // If the estimated time to complete a cms collection (cms_duration())</span><br><span class=\"line\">  // is less than the estimated time remaining until the cms generation</span><br><span class=\"line\">  // is full, start a collection.</span><br><span class=\"line\">  if (!UseCMSInitiatingOccupancyOnly) &#123;</span><br><span class=\"line\">    if (stats().valid()) &#123;</span><br><span class=\"line\">      // Case 2</span><br><span class=\"line\">      if (stats().time_until_cms_start() == 0.0) &#123;</span><br><span class=\"line\">        return true;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      // We want to conservatively collect somewhat early in order</span><br><span class=\"line\">      // to try and &quot;bootstrap&quot; our CMS/promotion statistics;</span><br><span class=\"line\">      // this branch will not fire after the first successful CMS</span><br><span class=\"line\">      // collection because the stats should then be valid.</span><br><span class=\"line\">      // Case 3</span><br><span class=\"line\">      if (_cmsGen-&gt;occupancy() &gt;= _bootstrap_occupancy) &#123;</span><br><span class=\"line\">        log.print(&quot; CMSCollector: collect for bootstrapping statistics: occupancy = %f, boot occupancy = %f&quot;,</span><br><span class=\"line\">                  _cmsGen-&gt;occupancy(), _bootstrap_occupancy);</span><br><span class=\"line\">        return true;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // Otherwise, we start a collection cycle if</span><br><span class=\"line\">  // old gen want a collection cycle started. Each may use</span><br><span class=\"line\">  // an appropriate criterion for making this decision.</span><br><span class=\"line\">  // XXX We need to make sure that the gen expansion</span><br><span class=\"line\">  // criterion dovetails well with this. XXX NEED TO FIX THIS</span><br><span class=\"line\">  // Case 4</span><br><span class=\"line\">  if (_cmsGen-&gt;should_concurrent_collect()) &#123;</span><br><span class=\"line\">    log.print(&quot;CMS old gen initiated&quot;);</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // We start a collection if we believe an incremental collection may fail;</span><br><span class=\"line\">  // this is not likely to be productive in practice because it&apos;s probably too</span><br><span class=\"line\">  // late anyway.</span><br><span class=\"line\">  GenCollectedHeap* gch = GenCollectedHeap::heap();</span><br><span class=\"line\">  assert(gch-&gt;collector_policy()-&gt;is_generation_policy(),</span><br><span class=\"line\">         &quot;You may want to check the correctness of the following&quot;);</span><br><span class=\"line\">  // Case 5</span><br><span class=\"line\">  if (gch-&gt;incremental_collection_will_fail(true /* consult_young */)) &#123;</span><br><span class=\"line\">    log.print(&quot;CMSCollector: collect because incremental collection will fail &quot;);</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // Case 6</span><br><span class=\"line\">  if (MetaspaceGC::should_concurrent_collect()) &#123;</span><br><span class=\"line\">    log.print(&quot;CMSCollector: collect for metadata allocation &quot;);</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // CMSTriggerInterval starts a CMS cycle if enough time has passed.</span><br><span class=\"line\">  if (CMSTriggerInterval &gt;= 0) &#123;</span><br><span class=\"line\">    // Case 7</span><br><span class=\"line\">    if (CMSTriggerInterval == 0) &#123;</span><br><span class=\"line\">      // Trigger always</span><br><span class=\"line\">      return true;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Check the CMS time since begin (we do not check the stats validity</span><br><span class=\"line\">    // as we want to be able to trigger the first CMS cycle as well)</span><br><span class=\"line\">    // Case 8</span><br><span class=\"line\">    if (stats().cms_time_since_begin() &gt;= (CMSTriggerInterval / ((double) MILLIUNITS))) &#123;</span><br><span class=\"line\">      if (stats().valid()) &#123;</span><br><span class=\"line\">        log.print(&quot;CMSCollector: collect because of trigger interval (time since last begin %3.7f secs)&quot;,</span><br><span class=\"line\">                  stats().cms_time_since_begin());</span><br><span class=\"line\">      &#125; else &#123;</span><br><span class=\"line\">        log.print(&quot;CMSCollector: collect because of trigger interval (first collection)&quot;);</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      return true;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  return false;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Case 5: 去询问下young区，下次如果发送ygc，在最坏的情况下，所有eden+survivor假如都不能被回收，都需要晋升，在old区有没有连续的内存来供应这些晋升的对象。如果连这些连续内存都没有，那就一定要CMS了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bool incremental_collection_will_fail(bool consult_young) &#123;</span><br><span class=\"line\">    // The first disjunct remembers if an incremental collection failed, even</span><br><span class=\"line\">    // when we thought (second disjunct) that it would not.</span><br><span class=\"line\">    return incremental_collection_failed() ||</span><br><span class=\"line\">           (consult_young &amp;&amp; !_young_gen-&gt;collection_attempt_is_safe());</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">bool DefNewGeneration::collection_attempt_is_safe() &#123;</span><br><span class=\"line\">  if (!to()-&gt;is_empty()) &#123;</span><br><span class=\"line\">    log_trace(gc)(&quot;:: to is not empty ::&quot;);</span><br><span class=\"line\">    return false;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  if (_old_gen == NULL) &#123;</span><br><span class=\"line\">    GenCollectedHeap* gch = GenCollectedHeap::heap();</span><br><span class=\"line\">    _old_gen = gch-&gt;old_gen();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  return _old_gen-&gt;promotion_attempt_is_safe(used()); </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">size_t DefNewGeneration::used() const &#123;</span><br><span class=\"line\">  return eden()-&gt;used()</span><br><span class=\"line\">       + from()-&gt;used();      // to() is only used during scavenge</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">bool Generation::promotion_attempt_is_safe(size_t max_promotion_in_bytes) const &#123;</span><br><span class=\"line\">  size_t available = max_contiguous_available();</span><br><span class=\"line\">  bool   res = (available &gt;= max_promotion_in_bytes);</span><br><span class=\"line\">  log_trace(gc)(&quot;Generation: promo attempt is%s safe: available(&quot; SIZE_FORMAT &quot;) %s max_promo(&quot; SIZE_FORMAT &quot;)&quot;,</span><br><span class=\"line\">                res? &quot;&quot;:&quot; not&quot;, available, res? &quot;&gt;=&quot;:&quot;&lt;&quot;, max_promotion_in_bytes);</span><br><span class=\"line\">  return res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p>##<br><a href=\"https://blog.csdn.net/foolishandstupid/article/details/77430875\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/foolishandstupid/article/details/77430875</a></p>\n<p>ParNew+CMS是Hotspot JVM中一对经典的GC组合，其中ParNew负责Young区的GC，CMS负责Old区的GC。</p>\n<p>JVM启动会调用<code>Universe::initialize_heap</code>初始化Heap，如果JVM启动参数中指定了<code>-XX:+UseConcMarkSweepGC</code>，初始化堆时会创建CMS收集器（cms colloector）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (collector_policy()-&gt;is_concurrent_mark_sweep_policy()) &#123;</span><br><span class=\"line\">    bool success = create_cms_collector();</span><br><span class=\"line\">    if (!success) return JNI_ENOMEM;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>忽略下中间部分细节，通过调试代码，最终会JVM会在<code>ConcurrentMarkSweepThread</code>的构造函数中启动该线程。JVM中C++对线程的抽象与Java非常类似，启动线程后，内核调度到该线程时，会执行它的run()方法。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Create &amp; start a CMS thread for this CMS collector</span><br><span class=\"line\">  _cmsThread = ConcurrentMarkSweepThread::start(this);</span><br></pre></td></tr></table></figure>\n\n<p>Stacktrace展示了CMS线程的启动时机。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ConcurrentGCThread::create_and_start concurrentGCThread.cpp:41</span><br><span class=\"line\">ConcurrentMarkSweepThread::ConcurrentMarkSweepThread concurrentMarkSweepThread.cpp:69</span><br><span class=\"line\">ConcurrentMarkSweepThread::ConcurrentMarkSweepThread concurrentMarkSweepThread.cpp:49</span><br><span class=\"line\">ConcurrentMarkSweepThread::start concurrentMarkSweepThread.cpp:107</span><br><span class=\"line\">CMSCollector::CMSCollector concurrentMarkSweepGeneration.cpp:592</span><br><span class=\"line\">CMSCollector::CMSCollector concurrentMarkSweepGeneration.cpp:490</span><br><span class=\"line\">GenCollectedHeap::create_cms_collector genCollectedHeap.cpp:829</span><br><span class=\"line\">GenCollectedHeap::initialize genCollectedHeap.cpp:144</span><br><span class=\"line\">Universe::initialize_heap universe.cpp:762</span><br><span class=\"line\">universe_init universe.cpp:672</span><br><span class=\"line\">init_globals init.cpp:110</span><br><span class=\"line\">Threads::create_vm thread.cpp:3630</span><br><span class=\"line\">JNI_CreateJavaVM_inner jni.cpp:3937</span><br><span class=\"line\">JNI_CreateJavaVM jni.cpp:4032</span><br><span class=\"line\">InitializeJVM</span><br><span class=\"line\">JavaMain</span><br></pre></td></tr></table></figure>\n\n<p>通过简单的分析，会发现<code>ConcurrentMarkSweepThread</code>自己没有run()，但是它的父类<code>ConcurrentGCThread</code>中有，如下所示，run_service是一个纯虚函数（类似Java的抽象方法），自然在运行时会指向子类<code>ConcurrentMarkSweepThread</code>对<code>run_service</code>的实现。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void ConcurrentGCThread::run() &#123;</span><br><span class=\"line\">  initialize_in_thread();</span><br><span class=\"line\">  wait_for_universe_init();</span><br><span class=\"line\"></span><br><span class=\"line\">  run_service(); // virtual void run_service() = 0; 虚函数，指向子类ConcurrentMarkSweepThread的实现</span><br><span class=\"line\"></span><br><span class=\"line\">  terminate();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在<code>run_service</code>中<code>while (true)</code>的形式异常明显，暗示着这是一个生命周期很长的线程，只要没有被terminate，就会永远在后台执行。<code>ConcurrentMarkSweepThread</code>会在它的生命周期内，默认每隔<code>2000ms</code>就检查下，进程需不需要进行<code>background cms gc</code>。<code>sleepBeforeNextCycle()</code>描述了为什么是<code>2000ms</code>和什么样的情况下会需要GC，而<code>_collector-&gt;collect_in_background</code>会描述什么是<code>background</code>式的CMS。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void ConcurrentMarkSweepThread::run_service() &#123;</span><br><span class=\"line\">  assert(this == cmst(), &quot;just checking&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">  if (BindCMSThreadToCPU &amp;&amp; !os::bind_to_processor(CPUForCMSThread)) &#123;</span><br><span class=\"line\">    log_warning(gc)(&quot;Couldn&apos;t bind CMS thread to processor &quot; UINTX_FORMAT, CPUForCMSThread);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  while (!should_terminate()) &#123;</span><br><span class=\"line\">    sleepBeforeNextCycle();</span><br><span class=\"line\">    if (should_terminate()) break;</span><br><span class=\"line\">    GCIdMark gc_id_mark;</span><br><span class=\"line\">    GCCause::Cause cause = _collector-&gt;_full_gc_requested ?</span><br><span class=\"line\">      _collector-&gt;_full_gc_cause : GCCause::_cms_concurrent_mark;</span><br><span class=\"line\">    _collector-&gt;collect_in_background(cause);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // Check that the state of any protocol for synchronization</span><br><span class=\"line\">  // between background (CMS) and foreground collector is &quot;clean&quot;</span><br><span class=\"line\">  // (i.e. will not potentially block the foreground collector,</span><br><span class=\"line\">  // requiring action by us).</span><br><span class=\"line\">  verify_ok_to_terminate();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><code>CMSWaitDuration</code>默认宏定义为2000，调用<code>wait_on_cms_lock_for_scavenge(CMSWaitDuration)</code>后让当前线程等待，注意下它的注释，有3种情况当前的线程会被唤醒，<br> 下一次<code>synchronous GC</code><br> 一个并发Full gc请求<br> 2000ms的超时到达<br>当线程醒后，只有当满足<code>_collector-&gt;shouldConcurrentCollect()</code>才能跳出当前调用，才能在外层真正调用CMS。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void ConcurrentMarkSweepThread::sleepBeforeNextCycle() &#123;</span><br><span class=\"line\">  while (!should_terminate()) &#123;</span><br><span class=\"line\">    if(CMSWaitDuration &gt;= 0) &#123;</span><br><span class=\"line\">      // Wait until the next synchronous GC, a concurrent full gc</span><br><span class=\"line\">      // request or a timeout, whichever is earlier.</span><br><span class=\"line\">      wait_on_cms_lock_for_scavenge(CMSWaitDuration);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      // Wait until any cms_lock event or check interval not to call shouldConcurrentCollect permanently</span><br><span class=\"line\">      wait_on_cms_lock(CMSCheckInterval);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // Check if we should start a CMS collection cycle</span><br><span class=\"line\">    if (_collector-&gt;shouldConcurrentCollect()) &#123;</span><br><span class=\"line\">      return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // .. collection criterion not yet met, let&apos;s go back</span><br><span class=\"line\">    // and wait some more</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>以下有8种Case会返回。重点分析下Case </p>\n<p>Case 4:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bool CMSCollector::shouldConcurrentCollect() &#123;</span><br><span class=\"line\">  // Case 1</span><br><span class=\"line\">  if (_full_gc_requested) &#123;</span><br><span class=\"line\">    log.print(&quot;CMSCollector: collect because of explicit  gc request (or GCLocker)&quot;);</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  // If the estimated time to complete a cms collection (cms_duration())</span><br><span class=\"line\">  // is less than the estimated time remaining until the cms generation</span><br><span class=\"line\">  // is full, start a collection.</span><br><span class=\"line\">  if (!UseCMSInitiatingOccupancyOnly) &#123;</span><br><span class=\"line\">    if (stats().valid()) &#123;</span><br><span class=\"line\">      // Case 2</span><br><span class=\"line\">      if (stats().time_until_cms_start() == 0.0) &#123;</span><br><span class=\"line\">        return true;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      // We want to conservatively collect somewhat early in order</span><br><span class=\"line\">      // to try and &quot;bootstrap&quot; our CMS/promotion statistics;</span><br><span class=\"line\">      // this branch will not fire after the first successful CMS</span><br><span class=\"line\">      // collection because the stats should then be valid.</span><br><span class=\"line\">      // Case 3</span><br><span class=\"line\">      if (_cmsGen-&gt;occupancy() &gt;= _bootstrap_occupancy) &#123;</span><br><span class=\"line\">        log.print(&quot; CMSCollector: collect for bootstrapping statistics: occupancy = %f, boot occupancy = %f&quot;,</span><br><span class=\"line\">                  _cmsGen-&gt;occupancy(), _bootstrap_occupancy);</span><br><span class=\"line\">        return true;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // Otherwise, we start a collection cycle if</span><br><span class=\"line\">  // old gen want a collection cycle started. Each may use</span><br><span class=\"line\">  // an appropriate criterion for making this decision.</span><br><span class=\"line\">  // XXX We need to make sure that the gen expansion</span><br><span class=\"line\">  // criterion dovetails well with this. XXX NEED TO FIX THIS</span><br><span class=\"line\">  // Case 4</span><br><span class=\"line\">  if (_cmsGen-&gt;should_concurrent_collect()) &#123;</span><br><span class=\"line\">    log.print(&quot;CMS old gen initiated&quot;);</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // We start a collection if we believe an incremental collection may fail;</span><br><span class=\"line\">  // this is not likely to be productive in practice because it&apos;s probably too</span><br><span class=\"line\">  // late anyway.</span><br><span class=\"line\">  GenCollectedHeap* gch = GenCollectedHeap::heap();</span><br><span class=\"line\">  assert(gch-&gt;collector_policy()-&gt;is_generation_policy(),</span><br><span class=\"line\">         &quot;You may want to check the correctness of the following&quot;);</span><br><span class=\"line\">  // Case 5</span><br><span class=\"line\">  if (gch-&gt;incremental_collection_will_fail(true /* consult_young */)) &#123;</span><br><span class=\"line\">    log.print(&quot;CMSCollector: collect because incremental collection will fail &quot;);</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // Case 6</span><br><span class=\"line\">  if (MetaspaceGC::should_concurrent_collect()) &#123;</span><br><span class=\"line\">    log.print(&quot;CMSCollector: collect for metadata allocation &quot;);</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // CMSTriggerInterval starts a CMS cycle if enough time has passed.</span><br><span class=\"line\">  if (CMSTriggerInterval &gt;= 0) &#123;</span><br><span class=\"line\">    // Case 7</span><br><span class=\"line\">    if (CMSTriggerInterval == 0) &#123;</span><br><span class=\"line\">      // Trigger always</span><br><span class=\"line\">      return true;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Check the CMS time since begin (we do not check the stats validity</span><br><span class=\"line\">    // as we want to be able to trigger the first CMS cycle as well)</span><br><span class=\"line\">    // Case 8</span><br><span class=\"line\">    if (stats().cms_time_since_begin() &gt;= (CMSTriggerInterval / ((double) MILLIUNITS))) &#123;</span><br><span class=\"line\">      if (stats().valid()) &#123;</span><br><span class=\"line\">        log.print(&quot;CMSCollector: collect because of trigger interval (time since last begin %3.7f secs)&quot;,</span><br><span class=\"line\">                  stats().cms_time_since_begin());</span><br><span class=\"line\">      &#125; else &#123;</span><br><span class=\"line\">        log.print(&quot;CMSCollector: collect because of trigger interval (first collection)&quot;);</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      return true;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  return false;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Case 5: 去询问下young区，下次如果发送ygc，在最坏的情况下，所有eden+survivor假如都不能被回收，都需要晋升，在old区有没有连续的内存来供应这些晋升的对象。如果连这些连续内存都没有，那就一定要CMS了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bool incremental_collection_will_fail(bool consult_young) &#123;</span><br><span class=\"line\">    // The first disjunct remembers if an incremental collection failed, even</span><br><span class=\"line\">    // when we thought (second disjunct) that it would not.</span><br><span class=\"line\">    return incremental_collection_failed() ||</span><br><span class=\"line\">           (consult_young &amp;&amp; !_young_gen-&gt;collection_attempt_is_safe());</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">bool DefNewGeneration::collection_attempt_is_safe() &#123;</span><br><span class=\"line\">  if (!to()-&gt;is_empty()) &#123;</span><br><span class=\"line\">    log_trace(gc)(&quot;:: to is not empty ::&quot;);</span><br><span class=\"line\">    return false;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  if (_old_gen == NULL) &#123;</span><br><span class=\"line\">    GenCollectedHeap* gch = GenCollectedHeap::heap();</span><br><span class=\"line\">    _old_gen = gch-&gt;old_gen();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  return _old_gen-&gt;promotion_attempt_is_safe(used()); </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">size_t DefNewGeneration::used() const &#123;</span><br><span class=\"line\">  return eden()-&gt;used()</span><br><span class=\"line\">       + from()-&gt;used();      // to() is only used during scavenge</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">bool Generation::promotion_attempt_is_safe(size_t max_promotion_in_bytes) const &#123;</span><br><span class=\"line\">  size_t available = max_contiguous_available();</span><br><span class=\"line\">  bool   res = (available &gt;= max_promotion_in_bytes);</span><br><span class=\"line\">  log_trace(gc)(&quot;Generation: promo attempt is%s safe: available(&quot; SIZE_FORMAT &quot;) %s max_promo(&quot; SIZE_FORMAT &quot;)&quot;,</span><br><span class=\"line\">                res? &quot;&quot;:&quot; not&quot;, available, res? &quot;&gt;=&quot;:&quot;&lt;&quot;, max_promotion_in_bytes);</span><br><span class=\"line\">  return res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"JVM-CMS","date":"2018-10-12T02:06:25.000Z","_content":"\n\nCollectedHeap\n  GenCollectedHeap\n  G1CollectedHeap\n  ParallelScavengeHeap\n\n\n### 还是杜兄的文章\nhttps://www.jianshu.com/p/78017c8b8e0f\n\n\n### CMS不是Full GC吧？\n\n### R大\n作者：RednaxelaFX\n链接：https://www.zhihu.com/question/63785052/answer/216407946\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n不知道题主是读了什么资料留下了“Java 8或者G1开始HotSpot才引入了card table / remembered set”的印象。但这个印象是错误的。HotSpot VM的GC，直到G1之前为止，其最基础的设计全部都是源自UC Berkeley在1980年代中期做的Berkeley Smalltalk。相关论文是David Ungar的Generation Scavenging。这个设计沿着 Berkeley Smalltalk -> Self -> Strongtalk -> HotSpot这样的血缘一路传承到了HotSpot VM里。这是一个分代式GC的设计，其中young generation分为1个eden区和2个survivor区，采用copying GC（又名scavenging）算法来收集。跨分代（old -> young）的引用通过粗粒度的card table来记录。回来看HotSpot VM里的GC实现，除了G1之外全部都是完全按照Berkeley Smalltalk的这个原始设计来做的。改变的只是经过多年的发展，把young GC从serial演进到了parallel，而在old generation上除了serial mark-compact之外也额外增加了parallel mark-compact（Parallel Old）和mostly-concurrent mark-sweep（CMS）。但是heap layout以及跨分代的引用的记录方式是完全没有改变的。反而G1是完全打破了这种heap layout设计，在整个GC堆上都采用了新的region-based设计——把GC堆划分为很多（例如1024）个相同大小的region，然后在上面动态地、逻辑地选择其中一些region作为eden region，一些作为survivor region，一些作为old generation region。其中属于young generation的region不需要记录outgoing reference的信息（或者从其它young generation出发的incoming reference的信息），因为这些region会在每次GC的时候都被完全扫描——G1里的三种GC模式，young、mixed和full，都保证会完全扫描young generation里的所有region。而属于old generation的region则可以被单独选出来放到mixed GC里去做收集，这些region就需要记录outgoing和incoming reference的信息。其中outgoing reference是直接通过跟HotSpot里其它GC一样的card table来记录的，而incoming reference则是通过G1特有的per-region remembered set结合card table来记录的。为此G1比以前的HotSpot GC新增了一种remembered set的设计，但是同时也使用了跟以前HotSpot VM里其它GC完全一样的card table。\n\n\n### 里面关于CMS产生碎片的图片很生动\nhttps://blog.csdn.net/zhanggang807/article/details/45956325\n\n\n``` \nCMSCollector::collect_in_background(GCCause::Cause cause) {\n  ...\n  while (_collectorState != Idling) {\n    log_debug(gc, state)(\"Thread \" INTPTR_FORMAT \" in CMS state %d\",\n                         p2i(Thread::current()), _collectorState);\n    // The foreground collector\n    //   holds the Heap_lock throughout its collection.\n    //   holds the CMS token (but not the lock)\n    //     except while it is waiting for the background collector to yield.\n    //\n    // The foreground collector should be blocked (not for long)\n    //   if the background collector is about to start a phase\n    //   executed with world stopped.  If the background\n    //   collector has already started such a phase, the\n    //   foreground collector is blocked waiting for the\n    //   Heap_lock.  The stop-world phases (InitialMarking and FinalMarking)\n    //   are executed in the VM thread.\n    //\n    // The locking order is\n    //   PendingListLock (PLL)  -- if applicable (FinalMarking)\n    //   Heap_lock  (both this & PLL locked in VM_CMS_Operation::prologue())\n    //   CMS token  (claimed in\n    //                stop_world_and_do() -->\n    //                  safepoint_synchronize() -->\n    //                    CMSThread::synchronize())\n\n    {\n      // Check if the FG collector wants us to yield.\n      CMSTokenSync x(true); // is cms thread\n      if (waitForForegroundGC()) {\n        // We yielded to a foreground GC, nothing more to be\n        // done this round.\n        assert(_foregroundGCShouldWait == false, \"We set it to false in \"\n               \"waitForForegroundGC()\");\n        log_debug(gc, state)(\"CMS Thread \" INTPTR_FORMAT \" exiting collection CMS state %d\",\n                             p2i(Thread::current()), _collectorState);\n        return;\n      } else {\n        // The background collector can run but check to see if the\n        // foreground collector has done a collection while the\n        // background collector was waiting to get the CGC_lock\n        // above.  If yes, break so that _foregroundGCShouldWait\n        // is cleared before returning.\n        if (_collectorState == Idling) {\n          break;\n        }\n      }\n    }\n\n    assert(_foregroundGCShouldWait, \"Foreground collector, if active, \"\n      \"should be waiting\");\n\n    switch (_collectorState) {\n      case InitialMarking:\n        {\n          ReleaseForegroundGC x(this);\n          stats().record_cms_begin();\n          VM_CMS_Initial_Mark initial_mark_op(this);\n          VMThread::execute(&initial_mark_op);\n        }\n        // The collector state may be any legal state at this point\n        // since the background collector may have yielded to the\n        // foreground collector.\n        break;\n      case Marking:\n        // initial marking in checkpointRootsInitialWork has been completed\n        if (markFromRoots()) { // we were successful\n          assert(_collectorState == Precleaning, \"Collector state should \"\n            \"have changed\");\n        } else {\n          assert(_foregroundGCIsActive, \"Internal state inconsistency\");\n        }\n        break;\n      case Precleaning:\n        // marking from roots in markFromRoots has been completed\n        preclean();\n        assert(_collectorState == AbortablePreclean ||\n               _collectorState == FinalMarking,\n               \"Collector state should have changed\");\n        break;\n      case AbortablePreclean:\n        abortable_preclean();\n        assert(_collectorState == FinalMarking, \"Collector state should \"\n          \"have changed\");\n        break;\n      case FinalMarking:\n        {\n          ReleaseForegroundGC x(this);\n\n          VM_CMS_Final_Remark final_remark_op(this);\n          VMThread::execute(&final_remark_op);\n        }\n        assert(_foregroundGCShouldWait, \"block post-condition\");\n        break;\n      case Sweeping:\n        // final marking in checkpointRootsFinal has been completed\n        sweep();\n        assert(_collectorState == Resizing, \"Collector state change \"\n          \"to Resizing must be done under the free_list_lock\");\n\n      case Resizing: {\n        // Sweeping has been completed...\n        // At this point the background collection has completed.\n        // Don't move the call to compute_new_size() down\n        // into code that might be executed if the background\n        // collection was preempted.\n        {\n          ReleaseForegroundGC x(this);   // unblock FG collection\n          MutexLockerEx       y(Heap_lock, Mutex::_no_safepoint_check_flag);\n          CMSTokenSync        z(true);   // not strictly needed.\n          if (_collectorState == Resizing) {\n            compute_new_size();\n            save_heap_summary();\n            _collectorState = Resetting;\n          } else {\n            assert(_collectorState == Idling, \"The state should only change\"\n                   \" because the foreground collector has finished the collection\");\n          }\n        }\n        break;\n      }\n      case Resetting:\n        // CMS heap resizing has been completed\n        reset_concurrent();\n        assert(_collectorState == Idling, \"Collector state should \"\n          \"have changed\");\n\n        MetaspaceGC::set_should_concurrent_collect(false);\n\n        stats().record_cms_end();\n        // Don't move the concurrent_phases_end() and compute_new_size()\n        // calls to here because a preempted background collection\n        // has it's state set to \"Resetting\".\n        break;\n      case Idling:\n      default:\n        ShouldNotReachHere();\n        break;\n    }\n    log_debug(gc, state)(\"  Thread \" INTPTR_FORMAT \" done - next CMS state %d\",\n                         p2i(Thread::current()), _collectorState);\n    assert(_foregroundGCShouldWait, \"block post-condition\");\n  }\n  ...\n}\n```\n\n\n","source":"_posts/JVM-GC-CMS.md","raw":"---\ntitle: JVM-CMS\ndate: 2018-10-12 10:06:25\ntags: JVM\n---\n\n\nCollectedHeap\n  GenCollectedHeap\n  G1CollectedHeap\n  ParallelScavengeHeap\n\n\n### 还是杜兄的文章\nhttps://www.jianshu.com/p/78017c8b8e0f\n\n\n### CMS不是Full GC吧？\n\n### R大\n作者：RednaxelaFX\n链接：https://www.zhihu.com/question/63785052/answer/216407946\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n不知道题主是读了什么资料留下了“Java 8或者G1开始HotSpot才引入了card table / remembered set”的印象。但这个印象是错误的。HotSpot VM的GC，直到G1之前为止，其最基础的设计全部都是源自UC Berkeley在1980年代中期做的Berkeley Smalltalk。相关论文是David Ungar的Generation Scavenging。这个设计沿着 Berkeley Smalltalk -> Self -> Strongtalk -> HotSpot这样的血缘一路传承到了HotSpot VM里。这是一个分代式GC的设计，其中young generation分为1个eden区和2个survivor区，采用copying GC（又名scavenging）算法来收集。跨分代（old -> young）的引用通过粗粒度的card table来记录。回来看HotSpot VM里的GC实现，除了G1之外全部都是完全按照Berkeley Smalltalk的这个原始设计来做的。改变的只是经过多年的发展，把young GC从serial演进到了parallel，而在old generation上除了serial mark-compact之外也额外增加了parallel mark-compact（Parallel Old）和mostly-concurrent mark-sweep（CMS）。但是heap layout以及跨分代的引用的记录方式是完全没有改变的。反而G1是完全打破了这种heap layout设计，在整个GC堆上都采用了新的region-based设计——把GC堆划分为很多（例如1024）个相同大小的region，然后在上面动态地、逻辑地选择其中一些region作为eden region，一些作为survivor region，一些作为old generation region。其中属于young generation的region不需要记录outgoing reference的信息（或者从其它young generation出发的incoming reference的信息），因为这些region会在每次GC的时候都被完全扫描——G1里的三种GC模式，young、mixed和full，都保证会完全扫描young generation里的所有region。而属于old generation的region则可以被单独选出来放到mixed GC里去做收集，这些region就需要记录outgoing和incoming reference的信息。其中outgoing reference是直接通过跟HotSpot里其它GC一样的card table来记录的，而incoming reference则是通过G1特有的per-region remembered set结合card table来记录的。为此G1比以前的HotSpot GC新增了一种remembered set的设计，但是同时也使用了跟以前HotSpot VM里其它GC完全一样的card table。\n\n\n### 里面关于CMS产生碎片的图片很生动\nhttps://blog.csdn.net/zhanggang807/article/details/45956325\n\n\n``` \nCMSCollector::collect_in_background(GCCause::Cause cause) {\n  ...\n  while (_collectorState != Idling) {\n    log_debug(gc, state)(\"Thread \" INTPTR_FORMAT \" in CMS state %d\",\n                         p2i(Thread::current()), _collectorState);\n    // The foreground collector\n    //   holds the Heap_lock throughout its collection.\n    //   holds the CMS token (but not the lock)\n    //     except while it is waiting for the background collector to yield.\n    //\n    // The foreground collector should be blocked (not for long)\n    //   if the background collector is about to start a phase\n    //   executed with world stopped.  If the background\n    //   collector has already started such a phase, the\n    //   foreground collector is blocked waiting for the\n    //   Heap_lock.  The stop-world phases (InitialMarking and FinalMarking)\n    //   are executed in the VM thread.\n    //\n    // The locking order is\n    //   PendingListLock (PLL)  -- if applicable (FinalMarking)\n    //   Heap_lock  (both this & PLL locked in VM_CMS_Operation::prologue())\n    //   CMS token  (claimed in\n    //                stop_world_and_do() -->\n    //                  safepoint_synchronize() -->\n    //                    CMSThread::synchronize())\n\n    {\n      // Check if the FG collector wants us to yield.\n      CMSTokenSync x(true); // is cms thread\n      if (waitForForegroundGC()) {\n        // We yielded to a foreground GC, nothing more to be\n        // done this round.\n        assert(_foregroundGCShouldWait == false, \"We set it to false in \"\n               \"waitForForegroundGC()\");\n        log_debug(gc, state)(\"CMS Thread \" INTPTR_FORMAT \" exiting collection CMS state %d\",\n                             p2i(Thread::current()), _collectorState);\n        return;\n      } else {\n        // The background collector can run but check to see if the\n        // foreground collector has done a collection while the\n        // background collector was waiting to get the CGC_lock\n        // above.  If yes, break so that _foregroundGCShouldWait\n        // is cleared before returning.\n        if (_collectorState == Idling) {\n          break;\n        }\n      }\n    }\n\n    assert(_foregroundGCShouldWait, \"Foreground collector, if active, \"\n      \"should be waiting\");\n\n    switch (_collectorState) {\n      case InitialMarking:\n        {\n          ReleaseForegroundGC x(this);\n          stats().record_cms_begin();\n          VM_CMS_Initial_Mark initial_mark_op(this);\n          VMThread::execute(&initial_mark_op);\n        }\n        // The collector state may be any legal state at this point\n        // since the background collector may have yielded to the\n        // foreground collector.\n        break;\n      case Marking:\n        // initial marking in checkpointRootsInitialWork has been completed\n        if (markFromRoots()) { // we were successful\n          assert(_collectorState == Precleaning, \"Collector state should \"\n            \"have changed\");\n        } else {\n          assert(_foregroundGCIsActive, \"Internal state inconsistency\");\n        }\n        break;\n      case Precleaning:\n        // marking from roots in markFromRoots has been completed\n        preclean();\n        assert(_collectorState == AbortablePreclean ||\n               _collectorState == FinalMarking,\n               \"Collector state should have changed\");\n        break;\n      case AbortablePreclean:\n        abortable_preclean();\n        assert(_collectorState == FinalMarking, \"Collector state should \"\n          \"have changed\");\n        break;\n      case FinalMarking:\n        {\n          ReleaseForegroundGC x(this);\n\n          VM_CMS_Final_Remark final_remark_op(this);\n          VMThread::execute(&final_remark_op);\n        }\n        assert(_foregroundGCShouldWait, \"block post-condition\");\n        break;\n      case Sweeping:\n        // final marking in checkpointRootsFinal has been completed\n        sweep();\n        assert(_collectorState == Resizing, \"Collector state change \"\n          \"to Resizing must be done under the free_list_lock\");\n\n      case Resizing: {\n        // Sweeping has been completed...\n        // At this point the background collection has completed.\n        // Don't move the call to compute_new_size() down\n        // into code that might be executed if the background\n        // collection was preempted.\n        {\n          ReleaseForegroundGC x(this);   // unblock FG collection\n          MutexLockerEx       y(Heap_lock, Mutex::_no_safepoint_check_flag);\n          CMSTokenSync        z(true);   // not strictly needed.\n          if (_collectorState == Resizing) {\n            compute_new_size();\n            save_heap_summary();\n            _collectorState = Resetting;\n          } else {\n            assert(_collectorState == Idling, \"The state should only change\"\n                   \" because the foreground collector has finished the collection\");\n          }\n        }\n        break;\n      }\n      case Resetting:\n        // CMS heap resizing has been completed\n        reset_concurrent();\n        assert(_collectorState == Idling, \"Collector state should \"\n          \"have changed\");\n\n        MetaspaceGC::set_should_concurrent_collect(false);\n\n        stats().record_cms_end();\n        // Don't move the concurrent_phases_end() and compute_new_size()\n        // calls to here because a preempted background collection\n        // has it's state set to \"Resetting\".\n        break;\n      case Idling:\n      default:\n        ShouldNotReachHere();\n        break;\n    }\n    log_debug(gc, state)(\"  Thread \" INTPTR_FORMAT \" done - next CMS state %d\",\n                         p2i(Thread::current()), _collectorState);\n    assert(_foregroundGCShouldWait, \"block post-condition\");\n  }\n  ...\n}\n```\n\n\n","slug":"JVM-GC-CMS","published":1,"updated":"2019-09-28T08:51:00.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o833001qv1np6vr72tha","content":"<p>CollectedHeap<br>  GenCollectedHeap<br>  G1CollectedHeap<br>  ParallelScavengeHeap</p>\n<h3 id=\"还是杜兄的文章\"><a href=\"#还是杜兄的文章\" class=\"headerlink\" title=\"还是杜兄的文章\"></a>还是杜兄的文章</h3><p><a href=\"https://www.jianshu.com/p/78017c8b8e0f\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/78017c8b8e0f</a></p>\n<h3 id=\"CMS不是Full-GC吧？\"><a href=\"#CMS不是Full-GC吧？\" class=\"headerlink\" title=\"CMS不是Full GC吧？\"></a>CMS不是Full GC吧？</h3><h3 id=\"R大\"><a href=\"#R大\" class=\"headerlink\" title=\"R大\"></a>R大</h3><p>作者：RednaxelaFX<br>链接：<a href=\"https://www.zhihu.com/question/63785052/answer/216407946\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/63785052/answer/216407946</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>\n<p>不知道题主是读了什么资料留下了“Java 8或者G1开始HotSpot才引入了card table / remembered set”的印象。但这个印象是错误的。HotSpot VM的GC，直到G1之前为止，其最基础的设计全部都是源自UC Berkeley在1980年代中期做的Berkeley Smalltalk。相关论文是David Ungar的Generation Scavenging。这个设计沿着 Berkeley Smalltalk -&gt; Self -&gt; Strongtalk -&gt; HotSpot这样的血缘一路传承到了HotSpot VM里。这是一个分代式GC的设计，其中young generation分为1个eden区和2个survivor区，采用copying GC（又名scavenging）算法来收集。跨分代（old -&gt; young）的引用通过粗粒度的card table来记录。回来看HotSpot VM里的GC实现，除了G1之外全部都是完全按照Berkeley Smalltalk的这个原始设计来做的。改变的只是经过多年的发展，把young GC从serial演进到了parallel，而在old generation上除了serial mark-compact之外也额外增加了parallel mark-compact（Parallel Old）和mostly-concurrent mark-sweep（CMS）。但是heap layout以及跨分代的引用的记录方式是完全没有改变的。反而G1是完全打破了这种heap layout设计，在整个GC堆上都采用了新的region-based设计——把GC堆划分为很多（例如1024）个相同大小的region，然后在上面动态地、逻辑地选择其中一些region作为eden region，一些作为survivor region，一些作为old generation region。其中属于young generation的region不需要记录outgoing reference的信息（或者从其它young generation出发的incoming reference的信息），因为这些region会在每次GC的时候都被完全扫描——G1里的三种GC模式，young、mixed和full，都保证会完全扫描young generation里的所有region。而属于old generation的region则可以被单独选出来放到mixed GC里去做收集，这些region就需要记录outgoing和incoming reference的信息。其中outgoing reference是直接通过跟HotSpot里其它GC一样的card table来记录的，而incoming reference则是通过G1特有的per-region remembered set结合card table来记录的。为此G1比以前的HotSpot GC新增了一种remembered set的设计，但是同时也使用了跟以前HotSpot VM里其它GC完全一样的card table。</p>\n<h3 id=\"里面关于CMS产生碎片的图片很生动\"><a href=\"#里面关于CMS产生碎片的图片很生动\" class=\"headerlink\" title=\"里面关于CMS产生碎片的图片很生动\"></a>里面关于CMS产生碎片的图片很生动</h3><p><a href=\"https://blog.csdn.net/zhanggang807/article/details/45956325\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zhanggang807/article/details/45956325</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CMSCollector::collect_in_background(GCCause::Cause cause) &#123;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  while (_collectorState != Idling) &#123;</span><br><span class=\"line\">    log_debug(gc, state)(&quot;Thread &quot; INTPTR_FORMAT &quot; in CMS state %d&quot;,</span><br><span class=\"line\">                         p2i(Thread::current()), _collectorState);</span><br><span class=\"line\">    // The foreground collector</span><br><span class=\"line\">    //   holds the Heap_lock throughout its collection.</span><br><span class=\"line\">    //   holds the CMS token (but not the lock)</span><br><span class=\"line\">    //     except while it is waiting for the background collector to yield.</span><br><span class=\"line\">    //</span><br><span class=\"line\">    // The foreground collector should be blocked (not for long)</span><br><span class=\"line\">    //   if the background collector is about to start a phase</span><br><span class=\"line\">    //   executed with world stopped.  If the background</span><br><span class=\"line\">    //   collector has already started such a phase, the</span><br><span class=\"line\">    //   foreground collector is blocked waiting for the</span><br><span class=\"line\">    //   Heap_lock.  The stop-world phases (InitialMarking and FinalMarking)</span><br><span class=\"line\">    //   are executed in the VM thread.</span><br><span class=\"line\">    //</span><br><span class=\"line\">    // The locking order is</span><br><span class=\"line\">    //   PendingListLock (PLL)  -- if applicable (FinalMarking)</span><br><span class=\"line\">    //   Heap_lock  (both this &amp; PLL locked in VM_CMS_Operation::prologue())</span><br><span class=\"line\">    //   CMS token  (claimed in</span><br><span class=\"line\">    //                stop_world_and_do() --&gt;</span><br><span class=\"line\">    //                  safepoint_synchronize() --&gt;</span><br><span class=\"line\">    //                    CMSThread::synchronize())</span><br><span class=\"line\"></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      // Check if the FG collector wants us to yield.</span><br><span class=\"line\">      CMSTokenSync x(true); // is cms thread</span><br><span class=\"line\">      if (waitForForegroundGC()) &#123;</span><br><span class=\"line\">        // We yielded to a foreground GC, nothing more to be</span><br><span class=\"line\">        // done this round.</span><br><span class=\"line\">        assert(_foregroundGCShouldWait == false, &quot;We set it to false in &quot;</span><br><span class=\"line\">               &quot;waitForForegroundGC()&quot;);</span><br><span class=\"line\">        log_debug(gc, state)(&quot;CMS Thread &quot; INTPTR_FORMAT &quot; exiting collection CMS state %d&quot;,</span><br><span class=\"line\">                             p2i(Thread::current()), _collectorState);</span><br><span class=\"line\">        return;</span><br><span class=\"line\">      &#125; else &#123;</span><br><span class=\"line\">        // The background collector can run but check to see if the</span><br><span class=\"line\">        // foreground collector has done a collection while the</span><br><span class=\"line\">        // background collector was waiting to get the CGC_lock</span><br><span class=\"line\">        // above.  If yes, break so that _foregroundGCShouldWait</span><br><span class=\"line\">        // is cleared before returning.</span><br><span class=\"line\">        if (_collectorState == Idling) &#123;</span><br><span class=\"line\">          break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    assert(_foregroundGCShouldWait, &quot;Foreground collector, if active, &quot;</span><br><span class=\"line\">      &quot;should be waiting&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    switch (_collectorState) &#123;</span><br><span class=\"line\">      case InitialMarking:</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          ReleaseForegroundGC x(this);</span><br><span class=\"line\">          stats().record_cms_begin();</span><br><span class=\"line\">          VM_CMS_Initial_Mark initial_mark_op(this);</span><br><span class=\"line\">          VMThread::execute(&amp;initial_mark_op);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // The collector state may be any legal state at this point</span><br><span class=\"line\">        // since the background collector may have yielded to the</span><br><span class=\"line\">        // foreground collector.</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case Marking:</span><br><span class=\"line\">        // initial marking in checkpointRootsInitialWork has been completed</span><br><span class=\"line\">        if (markFromRoots()) &#123; // we were successful</span><br><span class=\"line\">          assert(_collectorState == Precleaning, &quot;Collector state should &quot;</span><br><span class=\"line\">            &quot;have changed&quot;);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">          assert(_foregroundGCIsActive, &quot;Internal state inconsistency&quot;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case Precleaning:</span><br><span class=\"line\">        // marking from roots in markFromRoots has been completed</span><br><span class=\"line\">        preclean();</span><br><span class=\"line\">        assert(_collectorState == AbortablePreclean ||</span><br><span class=\"line\">               _collectorState == FinalMarking,</span><br><span class=\"line\">               &quot;Collector state should have changed&quot;);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case AbortablePreclean:</span><br><span class=\"line\">        abortable_preclean();</span><br><span class=\"line\">        assert(_collectorState == FinalMarking, &quot;Collector state should &quot;</span><br><span class=\"line\">          &quot;have changed&quot;);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case FinalMarking:</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          ReleaseForegroundGC x(this);</span><br><span class=\"line\"></span><br><span class=\"line\">          VM_CMS_Final_Remark final_remark_op(this);</span><br><span class=\"line\">          VMThread::execute(&amp;final_remark_op);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        assert(_foregroundGCShouldWait, &quot;block post-condition&quot;);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case Sweeping:</span><br><span class=\"line\">        // final marking in checkpointRootsFinal has been completed</span><br><span class=\"line\">        sweep();</span><br><span class=\"line\">        assert(_collectorState == Resizing, &quot;Collector state change &quot;</span><br><span class=\"line\">          &quot;to Resizing must be done under the free_list_lock&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">      case Resizing: &#123;</span><br><span class=\"line\">        // Sweeping has been completed...</span><br><span class=\"line\">        // At this point the background collection has completed.</span><br><span class=\"line\">        // Don&apos;t move the call to compute_new_size() down</span><br><span class=\"line\">        // into code that might be executed if the background</span><br><span class=\"line\">        // collection was preempted.</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          ReleaseForegroundGC x(this);   // unblock FG collection</span><br><span class=\"line\">          MutexLockerEx       y(Heap_lock, Mutex::_no_safepoint_check_flag);</span><br><span class=\"line\">          CMSTokenSync        z(true);   // not strictly needed.</span><br><span class=\"line\">          if (_collectorState == Resizing) &#123;</span><br><span class=\"line\">            compute_new_size();</span><br><span class=\"line\">            save_heap_summary();</span><br><span class=\"line\">            _collectorState = Resetting;</span><br><span class=\"line\">          &#125; else &#123;</span><br><span class=\"line\">            assert(_collectorState == Idling, &quot;The state should only change&quot;</span><br><span class=\"line\">                   &quot; because the foreground collector has finished the collection&quot;);</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      case Resetting:</span><br><span class=\"line\">        // CMS heap resizing has been completed</span><br><span class=\"line\">        reset_concurrent();</span><br><span class=\"line\">        assert(_collectorState == Idling, &quot;Collector state should &quot;</span><br><span class=\"line\">          &quot;have changed&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">        MetaspaceGC::set_should_concurrent_collect(false);</span><br><span class=\"line\"></span><br><span class=\"line\">        stats().record_cms_end();</span><br><span class=\"line\">        // Don&apos;t move the concurrent_phases_end() and compute_new_size()</span><br><span class=\"line\">        // calls to here because a preempted background collection</span><br><span class=\"line\">        // has it&apos;s state set to &quot;Resetting&quot;.</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case Idling:</span><br><span class=\"line\">      default:</span><br><span class=\"line\">        ShouldNotReachHere();</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    log_debug(gc, state)(&quot;  Thread &quot; INTPTR_FORMAT &quot; done - next CMS state %d&quot;,</span><br><span class=\"line\">                         p2i(Thread::current()), _collectorState);</span><br><span class=\"line\">    assert(_foregroundGCShouldWait, &quot;block post-condition&quot;);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<p>CollectedHeap<br>  GenCollectedHeap<br>  G1CollectedHeap<br>  ParallelScavengeHeap</p>\n<h3 id=\"还是杜兄的文章\"><a href=\"#还是杜兄的文章\" class=\"headerlink\" title=\"还是杜兄的文章\"></a>还是杜兄的文章</h3><p><a href=\"https://www.jianshu.com/p/78017c8b8e0f\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/78017c8b8e0f</a></p>\n<h3 id=\"CMS不是Full-GC吧？\"><a href=\"#CMS不是Full-GC吧？\" class=\"headerlink\" title=\"CMS不是Full GC吧？\"></a>CMS不是Full GC吧？</h3><h3 id=\"R大\"><a href=\"#R大\" class=\"headerlink\" title=\"R大\"></a>R大</h3><p>作者：RednaxelaFX<br>链接：<a href=\"https://www.zhihu.com/question/63785052/answer/216407946\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/63785052/answer/216407946</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>\n<p>不知道题主是读了什么资料留下了“Java 8或者G1开始HotSpot才引入了card table / remembered set”的印象。但这个印象是错误的。HotSpot VM的GC，直到G1之前为止，其最基础的设计全部都是源自UC Berkeley在1980年代中期做的Berkeley Smalltalk。相关论文是David Ungar的Generation Scavenging。这个设计沿着 Berkeley Smalltalk -&gt; Self -&gt; Strongtalk -&gt; HotSpot这样的血缘一路传承到了HotSpot VM里。这是一个分代式GC的设计，其中young generation分为1个eden区和2个survivor区，采用copying GC（又名scavenging）算法来收集。跨分代（old -&gt; young）的引用通过粗粒度的card table来记录。回来看HotSpot VM里的GC实现，除了G1之外全部都是完全按照Berkeley Smalltalk的这个原始设计来做的。改变的只是经过多年的发展，把young GC从serial演进到了parallel，而在old generation上除了serial mark-compact之外也额外增加了parallel mark-compact（Parallel Old）和mostly-concurrent mark-sweep（CMS）。但是heap layout以及跨分代的引用的记录方式是完全没有改变的。反而G1是完全打破了这种heap layout设计，在整个GC堆上都采用了新的region-based设计——把GC堆划分为很多（例如1024）个相同大小的region，然后在上面动态地、逻辑地选择其中一些region作为eden region，一些作为survivor region，一些作为old generation region。其中属于young generation的region不需要记录outgoing reference的信息（或者从其它young generation出发的incoming reference的信息），因为这些region会在每次GC的时候都被完全扫描——G1里的三种GC模式，young、mixed和full，都保证会完全扫描young generation里的所有region。而属于old generation的region则可以被单独选出来放到mixed GC里去做收集，这些region就需要记录outgoing和incoming reference的信息。其中outgoing reference是直接通过跟HotSpot里其它GC一样的card table来记录的，而incoming reference则是通过G1特有的per-region remembered set结合card table来记录的。为此G1比以前的HotSpot GC新增了一种remembered set的设计，但是同时也使用了跟以前HotSpot VM里其它GC完全一样的card table。</p>\n<h3 id=\"里面关于CMS产生碎片的图片很生动\"><a href=\"#里面关于CMS产生碎片的图片很生动\" class=\"headerlink\" title=\"里面关于CMS产生碎片的图片很生动\"></a>里面关于CMS产生碎片的图片很生动</h3><p><a href=\"https://blog.csdn.net/zhanggang807/article/details/45956325\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zhanggang807/article/details/45956325</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CMSCollector::collect_in_background(GCCause::Cause cause) &#123;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  while (_collectorState != Idling) &#123;</span><br><span class=\"line\">    log_debug(gc, state)(&quot;Thread &quot; INTPTR_FORMAT &quot; in CMS state %d&quot;,</span><br><span class=\"line\">                         p2i(Thread::current()), _collectorState);</span><br><span class=\"line\">    // The foreground collector</span><br><span class=\"line\">    //   holds the Heap_lock throughout its collection.</span><br><span class=\"line\">    //   holds the CMS token (but not the lock)</span><br><span class=\"line\">    //     except while it is waiting for the background collector to yield.</span><br><span class=\"line\">    //</span><br><span class=\"line\">    // The foreground collector should be blocked (not for long)</span><br><span class=\"line\">    //   if the background collector is about to start a phase</span><br><span class=\"line\">    //   executed with world stopped.  If the background</span><br><span class=\"line\">    //   collector has already started such a phase, the</span><br><span class=\"line\">    //   foreground collector is blocked waiting for the</span><br><span class=\"line\">    //   Heap_lock.  The stop-world phases (InitialMarking and FinalMarking)</span><br><span class=\"line\">    //   are executed in the VM thread.</span><br><span class=\"line\">    //</span><br><span class=\"line\">    // The locking order is</span><br><span class=\"line\">    //   PendingListLock (PLL)  -- if applicable (FinalMarking)</span><br><span class=\"line\">    //   Heap_lock  (both this &amp; PLL locked in VM_CMS_Operation::prologue())</span><br><span class=\"line\">    //   CMS token  (claimed in</span><br><span class=\"line\">    //                stop_world_and_do() --&gt;</span><br><span class=\"line\">    //                  safepoint_synchronize() --&gt;</span><br><span class=\"line\">    //                    CMSThread::synchronize())</span><br><span class=\"line\"></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      // Check if the FG collector wants us to yield.</span><br><span class=\"line\">      CMSTokenSync x(true); // is cms thread</span><br><span class=\"line\">      if (waitForForegroundGC()) &#123;</span><br><span class=\"line\">        // We yielded to a foreground GC, nothing more to be</span><br><span class=\"line\">        // done this round.</span><br><span class=\"line\">        assert(_foregroundGCShouldWait == false, &quot;We set it to false in &quot;</span><br><span class=\"line\">               &quot;waitForForegroundGC()&quot;);</span><br><span class=\"line\">        log_debug(gc, state)(&quot;CMS Thread &quot; INTPTR_FORMAT &quot; exiting collection CMS state %d&quot;,</span><br><span class=\"line\">                             p2i(Thread::current()), _collectorState);</span><br><span class=\"line\">        return;</span><br><span class=\"line\">      &#125; else &#123;</span><br><span class=\"line\">        // The background collector can run but check to see if the</span><br><span class=\"line\">        // foreground collector has done a collection while the</span><br><span class=\"line\">        // background collector was waiting to get the CGC_lock</span><br><span class=\"line\">        // above.  If yes, break so that _foregroundGCShouldWait</span><br><span class=\"line\">        // is cleared before returning.</span><br><span class=\"line\">        if (_collectorState == Idling) &#123;</span><br><span class=\"line\">          break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    assert(_foregroundGCShouldWait, &quot;Foreground collector, if active, &quot;</span><br><span class=\"line\">      &quot;should be waiting&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    switch (_collectorState) &#123;</span><br><span class=\"line\">      case InitialMarking:</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          ReleaseForegroundGC x(this);</span><br><span class=\"line\">          stats().record_cms_begin();</span><br><span class=\"line\">          VM_CMS_Initial_Mark initial_mark_op(this);</span><br><span class=\"line\">          VMThread::execute(&amp;initial_mark_op);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        // The collector state may be any legal state at this point</span><br><span class=\"line\">        // since the background collector may have yielded to the</span><br><span class=\"line\">        // foreground collector.</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case Marking:</span><br><span class=\"line\">        // initial marking in checkpointRootsInitialWork has been completed</span><br><span class=\"line\">        if (markFromRoots()) &#123; // we were successful</span><br><span class=\"line\">          assert(_collectorState == Precleaning, &quot;Collector state should &quot;</span><br><span class=\"line\">            &quot;have changed&quot;);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">          assert(_foregroundGCIsActive, &quot;Internal state inconsistency&quot;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case Precleaning:</span><br><span class=\"line\">        // marking from roots in markFromRoots has been completed</span><br><span class=\"line\">        preclean();</span><br><span class=\"line\">        assert(_collectorState == AbortablePreclean ||</span><br><span class=\"line\">               _collectorState == FinalMarking,</span><br><span class=\"line\">               &quot;Collector state should have changed&quot;);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case AbortablePreclean:</span><br><span class=\"line\">        abortable_preclean();</span><br><span class=\"line\">        assert(_collectorState == FinalMarking, &quot;Collector state should &quot;</span><br><span class=\"line\">          &quot;have changed&quot;);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case FinalMarking:</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          ReleaseForegroundGC x(this);</span><br><span class=\"line\"></span><br><span class=\"line\">          VM_CMS_Final_Remark final_remark_op(this);</span><br><span class=\"line\">          VMThread::execute(&amp;final_remark_op);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        assert(_foregroundGCShouldWait, &quot;block post-condition&quot;);</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case Sweeping:</span><br><span class=\"line\">        // final marking in checkpointRootsFinal has been completed</span><br><span class=\"line\">        sweep();</span><br><span class=\"line\">        assert(_collectorState == Resizing, &quot;Collector state change &quot;</span><br><span class=\"line\">          &quot;to Resizing must be done under the free_list_lock&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">      case Resizing: &#123;</span><br><span class=\"line\">        // Sweeping has been completed...</span><br><span class=\"line\">        // At this point the background collection has completed.</span><br><span class=\"line\">        // Don&apos;t move the call to compute_new_size() down</span><br><span class=\"line\">        // into code that might be executed if the background</span><br><span class=\"line\">        // collection was preempted.</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          ReleaseForegroundGC x(this);   // unblock FG collection</span><br><span class=\"line\">          MutexLockerEx       y(Heap_lock, Mutex::_no_safepoint_check_flag);</span><br><span class=\"line\">          CMSTokenSync        z(true);   // not strictly needed.</span><br><span class=\"line\">          if (_collectorState == Resizing) &#123;</span><br><span class=\"line\">            compute_new_size();</span><br><span class=\"line\">            save_heap_summary();</span><br><span class=\"line\">            _collectorState = Resetting;</span><br><span class=\"line\">          &#125; else &#123;</span><br><span class=\"line\">            assert(_collectorState == Idling, &quot;The state should only change&quot;</span><br><span class=\"line\">                   &quot; because the foreground collector has finished the collection&quot;);</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      case Resetting:</span><br><span class=\"line\">        // CMS heap resizing has been completed</span><br><span class=\"line\">        reset_concurrent();</span><br><span class=\"line\">        assert(_collectorState == Idling, &quot;Collector state should &quot;</span><br><span class=\"line\">          &quot;have changed&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">        MetaspaceGC::set_should_concurrent_collect(false);</span><br><span class=\"line\"></span><br><span class=\"line\">        stats().record_cms_end();</span><br><span class=\"line\">        // Don&apos;t move the concurrent_phases_end() and compute_new_size()</span><br><span class=\"line\">        // calls to here because a preempted background collection</span><br><span class=\"line\">        // has it&apos;s state set to &quot;Resetting&quot;.</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case Idling:</span><br><span class=\"line\">      default:</span><br><span class=\"line\">        ShouldNotReachHere();</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    log_debug(gc, state)(&quot;  Thread &quot; INTPTR_FORMAT &quot; done - next CMS state %d&quot;,</span><br><span class=\"line\">                         p2i(Thread::current()), _collectorState);</span><br><span class=\"line\">    assert(_foregroundGCShouldWait, &quot;block post-condition&quot;);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"JVM-GC-G1-FullGC","date":"2018-12-13T11:43:11.000Z","_content":"\n\n> The G1 garbage collector is designed to avoid full collections, but when the concurrent collections can't reclaim memory fast enough a fall back full GC will occur. The current implementation of the full GC for G1 uses a single threaded mark-sweep-compact algorithm. We intend to parallelize the mark-sweep-compact algorithm and use the same number of threads as the Young and Mixed collections do. The number of threads can be controlled by the -XX:ParallelGCThreads option, but this will also affect the number of threads used for Young and Mixed collections. http://openjdk.java.net/jeps/307\n\n从以上描述来看，以前G1的FullGC是用单线程去做MSC，\n\n```\nbool G1CollectedHeap::do_full_collection(bool explicit_gc,\n                                         bool clear_all_soft_refs) {\n  assert_at_safepoint(true /* should_be_vm_thread */);\n\n  if (GCLocker::check_active_before_gc()) {\n    return false;\n  }\n\n  STWGCTimer* gc_timer = G1MarkSweep::gc_timer();\n  gc_timer->register_gc_start();\n\n  SerialOldTracer* gc_tracer = G1MarkSweep::gc_tracer();\n  GCIdMark gc_id_mark;\n  gc_tracer->report_gc_start(gc_cause(), gc_timer->gc_start());\n\n  SvcGCMarker sgcm(SvcGCMarker::FULL);\n  ResourceMark rm;\n\n  print_heap_before_gc();\n  print_heap_regions();\n  trace_heap_before_gc(gc_tracer);\n\n  size_t metadata_prev_used = MetaspaceAux::used_bytes();\n\n  _verifier->verify_region_sets_optional();\n\n  const bool do_clear_all_soft_refs = clear_all_soft_refs ||\n                           collector_policy()->should_clear_all_soft_refs();\n\n  ClearedAllSoftRefs casr(do_clear_all_soft_refs, collector_policy());\n\n  {\n    IsGCActiveMark x;\n\n    // Timing\n    assert(!GCCause::is_user_requested_gc(gc_cause()) || explicit_gc, \"invariant\");\n    GCTraceCPUTime tcpu;\n\n    {\n      GCTraceTime(Info, gc) tm(\"Pause Full\", NULL, gc_cause(), true);\n      TraceCollectorStats tcs(g1mm()->full_collection_counters());\n      TraceMemoryManagerStats tms(true /* fullGC */, gc_cause());\n\n      G1HeapTransition heap_transition(this);\n      g1_policy()->record_full_collection_start();\n\n      // Note: When we have a more flexible GC logging framework that\n      // allows us to add optional attributes to a GC log record we\n      // could consider timing and reporting how long we wait in the\n      // following two methods.\n      wait_while_free_regions_coming();\n      // If we start the compaction before the CM threads finish\n      // scanning the root regions we might trip them over as we'll\n      // be moving objects / updating references. So let's wait until\n      // they are done. By telling them to abort, they should complete\n      // early.\n      _cm->root_regions()->abort();\n      _cm->root_regions()->wait_until_scan_finished();\n      append_secondary_free_list_if_not_empty_with_lock();\n\n      gc_prologue(true);\n      increment_total_collections(true /* full gc */);\n      increment_old_marking_cycles_started();\n\n      assert(used() == recalculate_used(), \"Should be equal\");\n\n      _verifier->verify_before_gc();\n\n      _verifier->check_bitmaps(\"Full GC Start\");\n      pre_full_gc_dump(gc_timer);\n\n#if defined(COMPILER2) || INCLUDE_JVMCI\n      DerivedPointerTable::clear();\n#endif\n\n      // Disable discovery and empty the discovered lists\n      // for the CM ref processor.\n      ref_processor_cm()->disable_discovery();\n      ref_processor_cm()->abandon_partial_discovery();\n      ref_processor_cm()->verify_no_references_recorded();\n\n      // Abandon current iterations of concurrent marking and concurrent\n      // refinement, if any are in progress.\n      concurrent_mark()->abort();\n\n      // Make sure we'll choose a new allocation region afterwards.\n      _allocator->release_mutator_alloc_region();\n      _allocator->abandon_gc_alloc_regions();\n      g1_rem_set()->cleanupHRRS();\n\n      // We may have added regions to the current incremental collection\n      // set between the last GC or pause and now. We need to clear the\n      // incremental collection set and then start rebuilding it afresh\n      // after this full GC.\n      abandon_collection_set(collection_set());\n\n      tear_down_region_sets(false /* free_list_only */);\n      collector_state()->set_gcs_are_young(true);\n\n      // See the comments in g1CollectedHeap.hpp and\n      // G1CollectedHeap::ref_processing_init() about\n      // how reference processing currently works in G1.\n\n      // Temporarily make discovery by the STW ref processor single threaded (non-MT).\n      ReferenceProcessorMTDiscoveryMutator stw_rp_disc_ser(ref_processor_stw(), false);\n\n      // Temporarily clear the STW ref processor's _is_alive_non_header field.\n      ReferenceProcessorIsAliveMutator stw_rp_is_alive_null(ref_processor_stw(), NULL);\n\n      ref_processor_stw()->enable_discovery();\n      ref_processor_stw()->setup_policy(do_clear_all_soft_refs);\n\n      // Do collection work\n      {\n        HandleMark hm;  // Discard invalid handles created during gc\n        G1MarkSweep::invoke_at_safepoint(ref_processor_stw(), do_clear_all_soft_refs);\n      }\n\n      assert(num_free_regions() == 0, \"we should not have added any free regions\");\n      rebuild_region_sets(false /* free_list_only */);\n\n      // Enqueue any discovered reference objects that have\n      // not been removed from the discovered lists.\n      ref_processor_stw()->enqueue_discovered_references();\n\n#if defined(COMPILER2) || INCLUDE_JVMCI\n      DerivedPointerTable::update_pointers();\n#endif\n\n      MemoryService::track_memory_usage();\n\n      assert(!ref_processor_stw()->discovery_enabled(), \"Postcondition\");\n      ref_processor_stw()->verify_no_references_recorded();\n\n      // Delete metaspaces for unloaded class loaders and clean up loader_data graph\n      ClassLoaderDataGraph::purge();\n      MetaspaceAux::verify_metrics();\n\n      // Note: since we've just done a full GC, concurrent\n      // marking is no longer active. Therefore we need not\n      // re-enable reference discovery for the CM ref processor.\n      // That will be done at the start of the next marking cycle.\n      assert(!ref_processor_cm()->discovery_enabled(), \"Postcondition\");\n      ref_processor_cm()->verify_no_references_recorded();\n\n      reset_gc_time_stamp();\n      // Since everything potentially moved, we will clear all remembered\n      // sets, and clear all cards.  Later we will rebuild remembered\n      // sets. We will also reset the GC time stamps of the regions.\n      clear_rsets_post_compaction();\n      check_gc_time_stamps();\n\n      resize_if_necessary_after_full_collection();\n\n      // We should do this after we potentially resize the heap so\n      // that all the COMMIT / UNCOMMIT events are generated before\n      // the compaction events.\n      print_hrm_post_compaction();\n\n      if (_hot_card_cache->use_cache()) {\n        _hot_card_cache->reset_card_counts();\n        _hot_card_cache->reset_hot_cache();\n      }\n\n      // Rebuild remembered sets of all regions.\n      uint n_workers =\n        AdaptiveSizePolicy::calc_active_workers(workers()->total_workers(),\n                                                workers()->active_workers(),\n                                                Threads::number_of_non_daemon_threads());\n      workers()->update_active_workers(n_workers);\n      log_info(gc,task)(\"Using %u workers of %u to rebuild remembered set\", n_workers, workers()->total_workers());\n\n      ParRebuildRSTask rebuild_rs_task(this);\n      workers()->run_task(&rebuild_rs_task);\n\n      // Rebuild the strong code root lists for each region\n      rebuild_strong_code_roots();\n\n      if (true) { // FIXME\n        MetaspaceGC::compute_new_size();\n      }\n\n#ifdef TRACESPINNING\n      ParallelTaskTerminator::print_termination_counts();\n#endif\n\n      // Discard all rset updates\n      JavaThread::dirty_card_queue_set().abandon_logs();\n      assert(dirty_card_queue_set().completed_buffers_num() == 0, \"DCQS should be empty\");\n\n      // At this point there should be no regions in the\n      // entire heap tagged as young.\n      assert(check_young_list_empty(), \"young list should be empty at this point\");\n\n      // Update the number of full collections that have been completed.\n      increment_old_marking_cycles_completed(false /* concurrent */);\n\n      _hrm.verify_optional();\n      _verifier->verify_region_sets_optional();\n\n      _verifier->verify_after_gc();\n\n      // Clear the previous marking bitmap, if needed for bitmap verification.\n      // Note we cannot do this when we clear the next marking bitmap in\n      // G1ConcurrentMark::abort() above since VerifyDuringGC verifies the\n      // objects marked during a full GC against the previous bitmap.\n      // But we need to clear it before calling check_bitmaps below since\n      // the full GC has compacted objects and updated TAMS but not updated\n      // the prev bitmap.\n      if (G1VerifyBitmaps) {\n        GCTraceTime(Debug, gc)(\"Clear Bitmap for Verification\");\n        _cm->clear_prev_bitmap(workers());\n      }\n      _verifier->check_bitmaps(\"Full GC End\");\n\n      // Start a new incremental collection set for the next pause\n      collection_set()->start_incremental_building();\n\n      clear_cset_fast_test();\n\n      _allocator->init_mutator_alloc_region();\n\n      g1_policy()->record_full_collection_end();\n\n      // We must call G1MonitoringSupport::update_sizes() in the same scoping level\n      // as an active TraceMemoryManagerStats object (i.e. before the destructor for the\n      // TraceMemoryManagerStats is called) so that the G1 memory pools are updated\n      // before any GC notifications are raised.\n      g1mm()->update_sizes();\n\n      gc_epilogue(true);\n\n      heap_transition.print();\n\n      print_heap_after_gc();\n      print_heap_regions();\n      trace_heap_after_gc(gc_tracer);\n\n      post_full_gc_dump(gc_timer);\n    }\n\n    gc_timer->register_gc_end();\n    gc_tracer->report_gc_end(gc_timer->gc_end(), gc_timer->time_partitions());\n  }\n\n  return true;\n}\n```\n","source":"_posts/JVM-GC-G1-FullGC.md","raw":"---\ntitle: JVM-GC-G1-FullGC\ndate: 2018-12-13 19:43:11\ntags: JVM\n---\n\n\n> The G1 garbage collector is designed to avoid full collections, but when the concurrent collections can't reclaim memory fast enough a fall back full GC will occur. The current implementation of the full GC for G1 uses a single threaded mark-sweep-compact algorithm. We intend to parallelize the mark-sweep-compact algorithm and use the same number of threads as the Young and Mixed collections do. The number of threads can be controlled by the -XX:ParallelGCThreads option, but this will also affect the number of threads used for Young and Mixed collections. http://openjdk.java.net/jeps/307\n\n从以上描述来看，以前G1的FullGC是用单线程去做MSC，\n\n```\nbool G1CollectedHeap::do_full_collection(bool explicit_gc,\n                                         bool clear_all_soft_refs) {\n  assert_at_safepoint(true /* should_be_vm_thread */);\n\n  if (GCLocker::check_active_before_gc()) {\n    return false;\n  }\n\n  STWGCTimer* gc_timer = G1MarkSweep::gc_timer();\n  gc_timer->register_gc_start();\n\n  SerialOldTracer* gc_tracer = G1MarkSweep::gc_tracer();\n  GCIdMark gc_id_mark;\n  gc_tracer->report_gc_start(gc_cause(), gc_timer->gc_start());\n\n  SvcGCMarker sgcm(SvcGCMarker::FULL);\n  ResourceMark rm;\n\n  print_heap_before_gc();\n  print_heap_regions();\n  trace_heap_before_gc(gc_tracer);\n\n  size_t metadata_prev_used = MetaspaceAux::used_bytes();\n\n  _verifier->verify_region_sets_optional();\n\n  const bool do_clear_all_soft_refs = clear_all_soft_refs ||\n                           collector_policy()->should_clear_all_soft_refs();\n\n  ClearedAllSoftRefs casr(do_clear_all_soft_refs, collector_policy());\n\n  {\n    IsGCActiveMark x;\n\n    // Timing\n    assert(!GCCause::is_user_requested_gc(gc_cause()) || explicit_gc, \"invariant\");\n    GCTraceCPUTime tcpu;\n\n    {\n      GCTraceTime(Info, gc) tm(\"Pause Full\", NULL, gc_cause(), true);\n      TraceCollectorStats tcs(g1mm()->full_collection_counters());\n      TraceMemoryManagerStats tms(true /* fullGC */, gc_cause());\n\n      G1HeapTransition heap_transition(this);\n      g1_policy()->record_full_collection_start();\n\n      // Note: When we have a more flexible GC logging framework that\n      // allows us to add optional attributes to a GC log record we\n      // could consider timing and reporting how long we wait in the\n      // following two methods.\n      wait_while_free_regions_coming();\n      // If we start the compaction before the CM threads finish\n      // scanning the root regions we might trip them over as we'll\n      // be moving objects / updating references. So let's wait until\n      // they are done. By telling them to abort, they should complete\n      // early.\n      _cm->root_regions()->abort();\n      _cm->root_regions()->wait_until_scan_finished();\n      append_secondary_free_list_if_not_empty_with_lock();\n\n      gc_prologue(true);\n      increment_total_collections(true /* full gc */);\n      increment_old_marking_cycles_started();\n\n      assert(used() == recalculate_used(), \"Should be equal\");\n\n      _verifier->verify_before_gc();\n\n      _verifier->check_bitmaps(\"Full GC Start\");\n      pre_full_gc_dump(gc_timer);\n\n#if defined(COMPILER2) || INCLUDE_JVMCI\n      DerivedPointerTable::clear();\n#endif\n\n      // Disable discovery and empty the discovered lists\n      // for the CM ref processor.\n      ref_processor_cm()->disable_discovery();\n      ref_processor_cm()->abandon_partial_discovery();\n      ref_processor_cm()->verify_no_references_recorded();\n\n      // Abandon current iterations of concurrent marking and concurrent\n      // refinement, if any are in progress.\n      concurrent_mark()->abort();\n\n      // Make sure we'll choose a new allocation region afterwards.\n      _allocator->release_mutator_alloc_region();\n      _allocator->abandon_gc_alloc_regions();\n      g1_rem_set()->cleanupHRRS();\n\n      // We may have added regions to the current incremental collection\n      // set between the last GC or pause and now. We need to clear the\n      // incremental collection set and then start rebuilding it afresh\n      // after this full GC.\n      abandon_collection_set(collection_set());\n\n      tear_down_region_sets(false /* free_list_only */);\n      collector_state()->set_gcs_are_young(true);\n\n      // See the comments in g1CollectedHeap.hpp and\n      // G1CollectedHeap::ref_processing_init() about\n      // how reference processing currently works in G1.\n\n      // Temporarily make discovery by the STW ref processor single threaded (non-MT).\n      ReferenceProcessorMTDiscoveryMutator stw_rp_disc_ser(ref_processor_stw(), false);\n\n      // Temporarily clear the STW ref processor's _is_alive_non_header field.\n      ReferenceProcessorIsAliveMutator stw_rp_is_alive_null(ref_processor_stw(), NULL);\n\n      ref_processor_stw()->enable_discovery();\n      ref_processor_stw()->setup_policy(do_clear_all_soft_refs);\n\n      // Do collection work\n      {\n        HandleMark hm;  // Discard invalid handles created during gc\n        G1MarkSweep::invoke_at_safepoint(ref_processor_stw(), do_clear_all_soft_refs);\n      }\n\n      assert(num_free_regions() == 0, \"we should not have added any free regions\");\n      rebuild_region_sets(false /* free_list_only */);\n\n      // Enqueue any discovered reference objects that have\n      // not been removed from the discovered lists.\n      ref_processor_stw()->enqueue_discovered_references();\n\n#if defined(COMPILER2) || INCLUDE_JVMCI\n      DerivedPointerTable::update_pointers();\n#endif\n\n      MemoryService::track_memory_usage();\n\n      assert(!ref_processor_stw()->discovery_enabled(), \"Postcondition\");\n      ref_processor_stw()->verify_no_references_recorded();\n\n      // Delete metaspaces for unloaded class loaders and clean up loader_data graph\n      ClassLoaderDataGraph::purge();\n      MetaspaceAux::verify_metrics();\n\n      // Note: since we've just done a full GC, concurrent\n      // marking is no longer active. Therefore we need not\n      // re-enable reference discovery for the CM ref processor.\n      // That will be done at the start of the next marking cycle.\n      assert(!ref_processor_cm()->discovery_enabled(), \"Postcondition\");\n      ref_processor_cm()->verify_no_references_recorded();\n\n      reset_gc_time_stamp();\n      // Since everything potentially moved, we will clear all remembered\n      // sets, and clear all cards.  Later we will rebuild remembered\n      // sets. We will also reset the GC time stamps of the regions.\n      clear_rsets_post_compaction();\n      check_gc_time_stamps();\n\n      resize_if_necessary_after_full_collection();\n\n      // We should do this after we potentially resize the heap so\n      // that all the COMMIT / UNCOMMIT events are generated before\n      // the compaction events.\n      print_hrm_post_compaction();\n\n      if (_hot_card_cache->use_cache()) {\n        _hot_card_cache->reset_card_counts();\n        _hot_card_cache->reset_hot_cache();\n      }\n\n      // Rebuild remembered sets of all regions.\n      uint n_workers =\n        AdaptiveSizePolicy::calc_active_workers(workers()->total_workers(),\n                                                workers()->active_workers(),\n                                                Threads::number_of_non_daemon_threads());\n      workers()->update_active_workers(n_workers);\n      log_info(gc,task)(\"Using %u workers of %u to rebuild remembered set\", n_workers, workers()->total_workers());\n\n      ParRebuildRSTask rebuild_rs_task(this);\n      workers()->run_task(&rebuild_rs_task);\n\n      // Rebuild the strong code root lists for each region\n      rebuild_strong_code_roots();\n\n      if (true) { // FIXME\n        MetaspaceGC::compute_new_size();\n      }\n\n#ifdef TRACESPINNING\n      ParallelTaskTerminator::print_termination_counts();\n#endif\n\n      // Discard all rset updates\n      JavaThread::dirty_card_queue_set().abandon_logs();\n      assert(dirty_card_queue_set().completed_buffers_num() == 0, \"DCQS should be empty\");\n\n      // At this point there should be no regions in the\n      // entire heap tagged as young.\n      assert(check_young_list_empty(), \"young list should be empty at this point\");\n\n      // Update the number of full collections that have been completed.\n      increment_old_marking_cycles_completed(false /* concurrent */);\n\n      _hrm.verify_optional();\n      _verifier->verify_region_sets_optional();\n\n      _verifier->verify_after_gc();\n\n      // Clear the previous marking bitmap, if needed for bitmap verification.\n      // Note we cannot do this when we clear the next marking bitmap in\n      // G1ConcurrentMark::abort() above since VerifyDuringGC verifies the\n      // objects marked during a full GC against the previous bitmap.\n      // But we need to clear it before calling check_bitmaps below since\n      // the full GC has compacted objects and updated TAMS but not updated\n      // the prev bitmap.\n      if (G1VerifyBitmaps) {\n        GCTraceTime(Debug, gc)(\"Clear Bitmap for Verification\");\n        _cm->clear_prev_bitmap(workers());\n      }\n      _verifier->check_bitmaps(\"Full GC End\");\n\n      // Start a new incremental collection set for the next pause\n      collection_set()->start_incremental_building();\n\n      clear_cset_fast_test();\n\n      _allocator->init_mutator_alloc_region();\n\n      g1_policy()->record_full_collection_end();\n\n      // We must call G1MonitoringSupport::update_sizes() in the same scoping level\n      // as an active TraceMemoryManagerStats object (i.e. before the destructor for the\n      // TraceMemoryManagerStats is called) so that the G1 memory pools are updated\n      // before any GC notifications are raised.\n      g1mm()->update_sizes();\n\n      gc_epilogue(true);\n\n      heap_transition.print();\n\n      print_heap_after_gc();\n      print_heap_regions();\n      trace_heap_after_gc(gc_tracer);\n\n      post_full_gc_dump(gc_timer);\n    }\n\n    gc_timer->register_gc_end();\n    gc_tracer->report_gc_end(gc_timer->gc_end(), gc_timer->time_partitions());\n  }\n\n  return true;\n}\n```\n","slug":"JVM-GC-G1-FullGC","published":1,"updated":"2019-09-28T08:51:00.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o833001rv1np5rrqsnic","content":"<blockquote>\n<p>The G1 garbage collector is designed to avoid full collections, but when the concurrent collections can’t reclaim memory fast enough a fall back full GC will occur. The current implementation of the full GC for G1 uses a single threaded mark-sweep-compact algorithm. We intend to parallelize the mark-sweep-compact algorithm and use the same number of threads as the Young and Mixed collections do. The number of threads can be controlled by the -XX:ParallelGCThreads option, but this will also affect the number of threads used for Young and Mixed collections. <a href=\"http://openjdk.java.net/jeps/307\" target=\"_blank\" rel=\"noopener\">http://openjdk.java.net/jeps/307</a></p>\n</blockquote>\n<p>从以上描述来看，以前G1的FullGC是用单线程去做MSC，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bool G1CollectedHeap::do_full_collection(bool explicit_gc,</span><br><span class=\"line\">                                         bool clear_all_soft_refs) &#123;</span><br><span class=\"line\">  assert_at_safepoint(true /* should_be_vm_thread */);</span><br><span class=\"line\"></span><br><span class=\"line\">  if (GCLocker::check_active_before_gc()) &#123;</span><br><span class=\"line\">    return false;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  STWGCTimer* gc_timer = G1MarkSweep::gc_timer();</span><br><span class=\"line\">  gc_timer-&gt;register_gc_start();</span><br><span class=\"line\"></span><br><span class=\"line\">  SerialOldTracer* gc_tracer = G1MarkSweep::gc_tracer();</span><br><span class=\"line\">  GCIdMark gc_id_mark;</span><br><span class=\"line\">  gc_tracer-&gt;report_gc_start(gc_cause(), gc_timer-&gt;gc_start());</span><br><span class=\"line\"></span><br><span class=\"line\">  SvcGCMarker sgcm(SvcGCMarker::FULL);</span><br><span class=\"line\">  ResourceMark rm;</span><br><span class=\"line\"></span><br><span class=\"line\">  print_heap_before_gc();</span><br><span class=\"line\">  print_heap_regions();</span><br><span class=\"line\">  trace_heap_before_gc(gc_tracer);</span><br><span class=\"line\"></span><br><span class=\"line\">  size_t metadata_prev_used = MetaspaceAux::used_bytes();</span><br><span class=\"line\"></span><br><span class=\"line\">  _verifier-&gt;verify_region_sets_optional();</span><br><span class=\"line\"></span><br><span class=\"line\">  const bool do_clear_all_soft_refs = clear_all_soft_refs ||</span><br><span class=\"line\">                           collector_policy()-&gt;should_clear_all_soft_refs();</span><br><span class=\"line\"></span><br><span class=\"line\">  ClearedAllSoftRefs casr(do_clear_all_soft_refs, collector_policy());</span><br><span class=\"line\"></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    IsGCActiveMark x;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Timing</span><br><span class=\"line\">    assert(!GCCause::is_user_requested_gc(gc_cause()) || explicit_gc, &quot;invariant&quot;);</span><br><span class=\"line\">    GCTraceCPUTime tcpu;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      GCTraceTime(Info, gc) tm(&quot;Pause Full&quot;, NULL, gc_cause(), true);</span><br><span class=\"line\">      TraceCollectorStats tcs(g1mm()-&gt;full_collection_counters());</span><br><span class=\"line\">      TraceMemoryManagerStats tms(true /* fullGC */, gc_cause());</span><br><span class=\"line\"></span><br><span class=\"line\">      G1HeapTransition heap_transition(this);</span><br><span class=\"line\">      g1_policy()-&gt;record_full_collection_start();</span><br><span class=\"line\"></span><br><span class=\"line\">      // Note: When we have a more flexible GC logging framework that</span><br><span class=\"line\">      // allows us to add optional attributes to a GC log record we</span><br><span class=\"line\">      // could consider timing and reporting how long we wait in the</span><br><span class=\"line\">      // following two methods.</span><br><span class=\"line\">      wait_while_free_regions_coming();</span><br><span class=\"line\">      // If we start the compaction before the CM threads finish</span><br><span class=\"line\">      // scanning the root regions we might trip them over as we&apos;ll</span><br><span class=\"line\">      // be moving objects / updating references. So let&apos;s wait until</span><br><span class=\"line\">      // they are done. By telling them to abort, they should complete</span><br><span class=\"line\">      // early.</span><br><span class=\"line\">      _cm-&gt;root_regions()-&gt;abort();</span><br><span class=\"line\">      _cm-&gt;root_regions()-&gt;wait_until_scan_finished();</span><br><span class=\"line\">      append_secondary_free_list_if_not_empty_with_lock();</span><br><span class=\"line\"></span><br><span class=\"line\">      gc_prologue(true);</span><br><span class=\"line\">      increment_total_collections(true /* full gc */);</span><br><span class=\"line\">      increment_old_marking_cycles_started();</span><br><span class=\"line\"></span><br><span class=\"line\">      assert(used() == recalculate_used(), &quot;Should be equal&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">      _verifier-&gt;verify_before_gc();</span><br><span class=\"line\"></span><br><span class=\"line\">      _verifier-&gt;check_bitmaps(&quot;Full GC Start&quot;);</span><br><span class=\"line\">      pre_full_gc_dump(gc_timer);</span><br><span class=\"line\"></span><br><span class=\"line\">#if defined(COMPILER2) || INCLUDE_JVMCI</span><br><span class=\"line\">      DerivedPointerTable::clear();</span><br><span class=\"line\">#endif</span><br><span class=\"line\"></span><br><span class=\"line\">      // Disable discovery and empty the discovered lists</span><br><span class=\"line\">      // for the CM ref processor.</span><br><span class=\"line\">      ref_processor_cm()-&gt;disable_discovery();</span><br><span class=\"line\">      ref_processor_cm()-&gt;abandon_partial_discovery();</span><br><span class=\"line\">      ref_processor_cm()-&gt;verify_no_references_recorded();</span><br><span class=\"line\"></span><br><span class=\"line\">      // Abandon current iterations of concurrent marking and concurrent</span><br><span class=\"line\">      // refinement, if any are in progress.</span><br><span class=\"line\">      concurrent_mark()-&gt;abort();</span><br><span class=\"line\"></span><br><span class=\"line\">      // Make sure we&apos;ll choose a new allocation region afterwards.</span><br><span class=\"line\">      _allocator-&gt;release_mutator_alloc_region();</span><br><span class=\"line\">      _allocator-&gt;abandon_gc_alloc_regions();</span><br><span class=\"line\">      g1_rem_set()-&gt;cleanupHRRS();</span><br><span class=\"line\"></span><br><span class=\"line\">      // We may have added regions to the current incremental collection</span><br><span class=\"line\">      // set between the last GC or pause and now. We need to clear the</span><br><span class=\"line\">      // incremental collection set and then start rebuilding it afresh</span><br><span class=\"line\">      // after this full GC.</span><br><span class=\"line\">      abandon_collection_set(collection_set());</span><br><span class=\"line\"></span><br><span class=\"line\">      tear_down_region_sets(false /* free_list_only */);</span><br><span class=\"line\">      collector_state()-&gt;set_gcs_are_young(true);</span><br><span class=\"line\"></span><br><span class=\"line\">      // See the comments in g1CollectedHeap.hpp and</span><br><span class=\"line\">      // G1CollectedHeap::ref_processing_init() about</span><br><span class=\"line\">      // how reference processing currently works in G1.</span><br><span class=\"line\"></span><br><span class=\"line\">      // Temporarily make discovery by the STW ref processor single threaded (non-MT).</span><br><span class=\"line\">      ReferenceProcessorMTDiscoveryMutator stw_rp_disc_ser(ref_processor_stw(), false);</span><br><span class=\"line\"></span><br><span class=\"line\">      // Temporarily clear the STW ref processor&apos;s _is_alive_non_header field.</span><br><span class=\"line\">      ReferenceProcessorIsAliveMutator stw_rp_is_alive_null(ref_processor_stw(), NULL);</span><br><span class=\"line\"></span><br><span class=\"line\">      ref_processor_stw()-&gt;enable_discovery();</span><br><span class=\"line\">      ref_processor_stw()-&gt;setup_policy(do_clear_all_soft_refs);</span><br><span class=\"line\"></span><br><span class=\"line\">      // Do collection work</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        HandleMark hm;  // Discard invalid handles created during gc</span><br><span class=\"line\">        G1MarkSweep::invoke_at_safepoint(ref_processor_stw(), do_clear_all_soft_refs);</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      assert(num_free_regions() == 0, &quot;we should not have added any free regions&quot;);</span><br><span class=\"line\">      rebuild_region_sets(false /* free_list_only */);</span><br><span class=\"line\"></span><br><span class=\"line\">      // Enqueue any discovered reference objects that have</span><br><span class=\"line\">      // not been removed from the discovered lists.</span><br><span class=\"line\">      ref_processor_stw()-&gt;enqueue_discovered_references();</span><br><span class=\"line\"></span><br><span class=\"line\">#if defined(COMPILER2) || INCLUDE_JVMCI</span><br><span class=\"line\">      DerivedPointerTable::update_pointers();</span><br><span class=\"line\">#endif</span><br><span class=\"line\"></span><br><span class=\"line\">      MemoryService::track_memory_usage();</span><br><span class=\"line\"></span><br><span class=\"line\">      assert(!ref_processor_stw()-&gt;discovery_enabled(), &quot;Postcondition&quot;);</span><br><span class=\"line\">      ref_processor_stw()-&gt;verify_no_references_recorded();</span><br><span class=\"line\"></span><br><span class=\"line\">      // Delete metaspaces for unloaded class loaders and clean up loader_data graph</span><br><span class=\"line\">      ClassLoaderDataGraph::purge();</span><br><span class=\"line\">      MetaspaceAux::verify_metrics();</span><br><span class=\"line\"></span><br><span class=\"line\">      // Note: since we&apos;ve just done a full GC, concurrent</span><br><span class=\"line\">      // marking is no longer active. Therefore we need not</span><br><span class=\"line\">      // re-enable reference discovery for the CM ref processor.</span><br><span class=\"line\">      // That will be done at the start of the next marking cycle.</span><br><span class=\"line\">      assert(!ref_processor_cm()-&gt;discovery_enabled(), &quot;Postcondition&quot;);</span><br><span class=\"line\">      ref_processor_cm()-&gt;verify_no_references_recorded();</span><br><span class=\"line\"></span><br><span class=\"line\">      reset_gc_time_stamp();</span><br><span class=\"line\">      // Since everything potentially moved, we will clear all remembered</span><br><span class=\"line\">      // sets, and clear all cards.  Later we will rebuild remembered</span><br><span class=\"line\">      // sets. We will also reset the GC time stamps of the regions.</span><br><span class=\"line\">      clear_rsets_post_compaction();</span><br><span class=\"line\">      check_gc_time_stamps();</span><br><span class=\"line\"></span><br><span class=\"line\">      resize_if_necessary_after_full_collection();</span><br><span class=\"line\"></span><br><span class=\"line\">      // We should do this after we potentially resize the heap so</span><br><span class=\"line\">      // that all the COMMIT / UNCOMMIT events are generated before</span><br><span class=\"line\">      // the compaction events.</span><br><span class=\"line\">      print_hrm_post_compaction();</span><br><span class=\"line\"></span><br><span class=\"line\">      if (_hot_card_cache-&gt;use_cache()) &#123;</span><br><span class=\"line\">        _hot_card_cache-&gt;reset_card_counts();</span><br><span class=\"line\">        _hot_card_cache-&gt;reset_hot_cache();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      // Rebuild remembered sets of all regions.</span><br><span class=\"line\">      uint n_workers =</span><br><span class=\"line\">        AdaptiveSizePolicy::calc_active_workers(workers()-&gt;total_workers(),</span><br><span class=\"line\">                                                workers()-&gt;active_workers(),</span><br><span class=\"line\">                                                Threads::number_of_non_daemon_threads());</span><br><span class=\"line\">      workers()-&gt;update_active_workers(n_workers);</span><br><span class=\"line\">      log_info(gc,task)(&quot;Using %u workers of %u to rebuild remembered set&quot;, n_workers, workers()-&gt;total_workers());</span><br><span class=\"line\"></span><br><span class=\"line\">      ParRebuildRSTask rebuild_rs_task(this);</span><br><span class=\"line\">      workers()-&gt;run_task(&amp;rebuild_rs_task);</span><br><span class=\"line\"></span><br><span class=\"line\">      // Rebuild the strong code root lists for each region</span><br><span class=\"line\">      rebuild_strong_code_roots();</span><br><span class=\"line\"></span><br><span class=\"line\">      if (true) &#123; // FIXME</span><br><span class=\"line\">        MetaspaceGC::compute_new_size();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">#ifdef TRACESPINNING</span><br><span class=\"line\">      ParallelTaskTerminator::print_termination_counts();</span><br><span class=\"line\">#endif</span><br><span class=\"line\"></span><br><span class=\"line\">      // Discard all rset updates</span><br><span class=\"line\">      JavaThread::dirty_card_queue_set().abandon_logs();</span><br><span class=\"line\">      assert(dirty_card_queue_set().completed_buffers_num() == 0, &quot;DCQS should be empty&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">      // At this point there should be no regions in the</span><br><span class=\"line\">      // entire heap tagged as young.</span><br><span class=\"line\">      assert(check_young_list_empty(), &quot;young list should be empty at this point&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">      // Update the number of full collections that have been completed.</span><br><span class=\"line\">      increment_old_marking_cycles_completed(false /* concurrent */);</span><br><span class=\"line\"></span><br><span class=\"line\">      _hrm.verify_optional();</span><br><span class=\"line\">      _verifier-&gt;verify_region_sets_optional();</span><br><span class=\"line\"></span><br><span class=\"line\">      _verifier-&gt;verify_after_gc();</span><br><span class=\"line\"></span><br><span class=\"line\">      // Clear the previous marking bitmap, if needed for bitmap verification.</span><br><span class=\"line\">      // Note we cannot do this when we clear the next marking bitmap in</span><br><span class=\"line\">      // G1ConcurrentMark::abort() above since VerifyDuringGC verifies the</span><br><span class=\"line\">      // objects marked during a full GC against the previous bitmap.</span><br><span class=\"line\">      // But we need to clear it before calling check_bitmaps below since</span><br><span class=\"line\">      // the full GC has compacted objects and updated TAMS but not updated</span><br><span class=\"line\">      // the prev bitmap.</span><br><span class=\"line\">      if (G1VerifyBitmaps) &#123;</span><br><span class=\"line\">        GCTraceTime(Debug, gc)(&quot;Clear Bitmap for Verification&quot;);</span><br><span class=\"line\">        _cm-&gt;clear_prev_bitmap(workers());</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      _verifier-&gt;check_bitmaps(&quot;Full GC End&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">      // Start a new incremental collection set for the next pause</span><br><span class=\"line\">      collection_set()-&gt;start_incremental_building();</span><br><span class=\"line\"></span><br><span class=\"line\">      clear_cset_fast_test();</span><br><span class=\"line\"></span><br><span class=\"line\">      _allocator-&gt;init_mutator_alloc_region();</span><br><span class=\"line\"></span><br><span class=\"line\">      g1_policy()-&gt;record_full_collection_end();</span><br><span class=\"line\"></span><br><span class=\"line\">      // We must call G1MonitoringSupport::update_sizes() in the same scoping level</span><br><span class=\"line\">      // as an active TraceMemoryManagerStats object (i.e. before the destructor for the</span><br><span class=\"line\">      // TraceMemoryManagerStats is called) so that the G1 memory pools are updated</span><br><span class=\"line\">      // before any GC notifications are raised.</span><br><span class=\"line\">      g1mm()-&gt;update_sizes();</span><br><span class=\"line\"></span><br><span class=\"line\">      gc_epilogue(true);</span><br><span class=\"line\"></span><br><span class=\"line\">      heap_transition.print();</span><br><span class=\"line\"></span><br><span class=\"line\">      print_heap_after_gc();</span><br><span class=\"line\">      print_heap_regions();</span><br><span class=\"line\">      trace_heap_after_gc(gc_tracer);</span><br><span class=\"line\"></span><br><span class=\"line\">      post_full_gc_dump(gc_timer);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    gc_timer-&gt;register_gc_end();</span><br><span class=\"line\">    gc_tracer-&gt;report_gc_end(gc_timer-&gt;gc_end(), gc_timer-&gt;time_partitions());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  return true;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>The G1 garbage collector is designed to avoid full collections, but when the concurrent collections can’t reclaim memory fast enough a fall back full GC will occur. The current implementation of the full GC for G1 uses a single threaded mark-sweep-compact algorithm. We intend to parallelize the mark-sweep-compact algorithm and use the same number of threads as the Young and Mixed collections do. The number of threads can be controlled by the -XX:ParallelGCThreads option, but this will also affect the number of threads used for Young and Mixed collections. <a href=\"http://openjdk.java.net/jeps/307\" target=\"_blank\" rel=\"noopener\">http://openjdk.java.net/jeps/307</a></p>\n</blockquote>\n<p>从以上描述来看，以前G1的FullGC是用单线程去做MSC，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bool G1CollectedHeap::do_full_collection(bool explicit_gc,</span><br><span class=\"line\">                                         bool clear_all_soft_refs) &#123;</span><br><span class=\"line\">  assert_at_safepoint(true /* should_be_vm_thread */);</span><br><span class=\"line\"></span><br><span class=\"line\">  if (GCLocker::check_active_before_gc()) &#123;</span><br><span class=\"line\">    return false;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  STWGCTimer* gc_timer = G1MarkSweep::gc_timer();</span><br><span class=\"line\">  gc_timer-&gt;register_gc_start();</span><br><span class=\"line\"></span><br><span class=\"line\">  SerialOldTracer* gc_tracer = G1MarkSweep::gc_tracer();</span><br><span class=\"line\">  GCIdMark gc_id_mark;</span><br><span class=\"line\">  gc_tracer-&gt;report_gc_start(gc_cause(), gc_timer-&gt;gc_start());</span><br><span class=\"line\"></span><br><span class=\"line\">  SvcGCMarker sgcm(SvcGCMarker::FULL);</span><br><span class=\"line\">  ResourceMark rm;</span><br><span class=\"line\"></span><br><span class=\"line\">  print_heap_before_gc();</span><br><span class=\"line\">  print_heap_regions();</span><br><span class=\"line\">  trace_heap_before_gc(gc_tracer);</span><br><span class=\"line\"></span><br><span class=\"line\">  size_t metadata_prev_used = MetaspaceAux::used_bytes();</span><br><span class=\"line\"></span><br><span class=\"line\">  _verifier-&gt;verify_region_sets_optional();</span><br><span class=\"line\"></span><br><span class=\"line\">  const bool do_clear_all_soft_refs = clear_all_soft_refs ||</span><br><span class=\"line\">                           collector_policy()-&gt;should_clear_all_soft_refs();</span><br><span class=\"line\"></span><br><span class=\"line\">  ClearedAllSoftRefs casr(do_clear_all_soft_refs, collector_policy());</span><br><span class=\"line\"></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    IsGCActiveMark x;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Timing</span><br><span class=\"line\">    assert(!GCCause::is_user_requested_gc(gc_cause()) || explicit_gc, &quot;invariant&quot;);</span><br><span class=\"line\">    GCTraceCPUTime tcpu;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      GCTraceTime(Info, gc) tm(&quot;Pause Full&quot;, NULL, gc_cause(), true);</span><br><span class=\"line\">      TraceCollectorStats tcs(g1mm()-&gt;full_collection_counters());</span><br><span class=\"line\">      TraceMemoryManagerStats tms(true /* fullGC */, gc_cause());</span><br><span class=\"line\"></span><br><span class=\"line\">      G1HeapTransition heap_transition(this);</span><br><span class=\"line\">      g1_policy()-&gt;record_full_collection_start();</span><br><span class=\"line\"></span><br><span class=\"line\">      // Note: When we have a more flexible GC logging framework that</span><br><span class=\"line\">      // allows us to add optional attributes to a GC log record we</span><br><span class=\"line\">      // could consider timing and reporting how long we wait in the</span><br><span class=\"line\">      // following two methods.</span><br><span class=\"line\">      wait_while_free_regions_coming();</span><br><span class=\"line\">      // If we start the compaction before the CM threads finish</span><br><span class=\"line\">      // scanning the root regions we might trip them over as we&apos;ll</span><br><span class=\"line\">      // be moving objects / updating references. So let&apos;s wait until</span><br><span class=\"line\">      // they are done. By telling them to abort, they should complete</span><br><span class=\"line\">      // early.</span><br><span class=\"line\">      _cm-&gt;root_regions()-&gt;abort();</span><br><span class=\"line\">      _cm-&gt;root_regions()-&gt;wait_until_scan_finished();</span><br><span class=\"line\">      append_secondary_free_list_if_not_empty_with_lock();</span><br><span class=\"line\"></span><br><span class=\"line\">      gc_prologue(true);</span><br><span class=\"line\">      increment_total_collections(true /* full gc */);</span><br><span class=\"line\">      increment_old_marking_cycles_started();</span><br><span class=\"line\"></span><br><span class=\"line\">      assert(used() == recalculate_used(), &quot;Should be equal&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">      _verifier-&gt;verify_before_gc();</span><br><span class=\"line\"></span><br><span class=\"line\">      _verifier-&gt;check_bitmaps(&quot;Full GC Start&quot;);</span><br><span class=\"line\">      pre_full_gc_dump(gc_timer);</span><br><span class=\"line\"></span><br><span class=\"line\">#if defined(COMPILER2) || INCLUDE_JVMCI</span><br><span class=\"line\">      DerivedPointerTable::clear();</span><br><span class=\"line\">#endif</span><br><span class=\"line\"></span><br><span class=\"line\">      // Disable discovery and empty the discovered lists</span><br><span class=\"line\">      // for the CM ref processor.</span><br><span class=\"line\">      ref_processor_cm()-&gt;disable_discovery();</span><br><span class=\"line\">      ref_processor_cm()-&gt;abandon_partial_discovery();</span><br><span class=\"line\">      ref_processor_cm()-&gt;verify_no_references_recorded();</span><br><span class=\"line\"></span><br><span class=\"line\">      // Abandon current iterations of concurrent marking and concurrent</span><br><span class=\"line\">      // refinement, if any are in progress.</span><br><span class=\"line\">      concurrent_mark()-&gt;abort();</span><br><span class=\"line\"></span><br><span class=\"line\">      // Make sure we&apos;ll choose a new allocation region afterwards.</span><br><span class=\"line\">      _allocator-&gt;release_mutator_alloc_region();</span><br><span class=\"line\">      _allocator-&gt;abandon_gc_alloc_regions();</span><br><span class=\"line\">      g1_rem_set()-&gt;cleanupHRRS();</span><br><span class=\"line\"></span><br><span class=\"line\">      // We may have added regions to the current incremental collection</span><br><span class=\"line\">      // set between the last GC or pause and now. We need to clear the</span><br><span class=\"line\">      // incremental collection set and then start rebuilding it afresh</span><br><span class=\"line\">      // after this full GC.</span><br><span class=\"line\">      abandon_collection_set(collection_set());</span><br><span class=\"line\"></span><br><span class=\"line\">      tear_down_region_sets(false /* free_list_only */);</span><br><span class=\"line\">      collector_state()-&gt;set_gcs_are_young(true);</span><br><span class=\"line\"></span><br><span class=\"line\">      // See the comments in g1CollectedHeap.hpp and</span><br><span class=\"line\">      // G1CollectedHeap::ref_processing_init() about</span><br><span class=\"line\">      // how reference processing currently works in G1.</span><br><span class=\"line\"></span><br><span class=\"line\">      // Temporarily make discovery by the STW ref processor single threaded (non-MT).</span><br><span class=\"line\">      ReferenceProcessorMTDiscoveryMutator stw_rp_disc_ser(ref_processor_stw(), false);</span><br><span class=\"line\"></span><br><span class=\"line\">      // Temporarily clear the STW ref processor&apos;s _is_alive_non_header field.</span><br><span class=\"line\">      ReferenceProcessorIsAliveMutator stw_rp_is_alive_null(ref_processor_stw(), NULL);</span><br><span class=\"line\"></span><br><span class=\"line\">      ref_processor_stw()-&gt;enable_discovery();</span><br><span class=\"line\">      ref_processor_stw()-&gt;setup_policy(do_clear_all_soft_refs);</span><br><span class=\"line\"></span><br><span class=\"line\">      // Do collection work</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        HandleMark hm;  // Discard invalid handles created during gc</span><br><span class=\"line\">        G1MarkSweep::invoke_at_safepoint(ref_processor_stw(), do_clear_all_soft_refs);</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      assert(num_free_regions() == 0, &quot;we should not have added any free regions&quot;);</span><br><span class=\"line\">      rebuild_region_sets(false /* free_list_only */);</span><br><span class=\"line\"></span><br><span class=\"line\">      // Enqueue any discovered reference objects that have</span><br><span class=\"line\">      // not been removed from the discovered lists.</span><br><span class=\"line\">      ref_processor_stw()-&gt;enqueue_discovered_references();</span><br><span class=\"line\"></span><br><span class=\"line\">#if defined(COMPILER2) || INCLUDE_JVMCI</span><br><span class=\"line\">      DerivedPointerTable::update_pointers();</span><br><span class=\"line\">#endif</span><br><span class=\"line\"></span><br><span class=\"line\">      MemoryService::track_memory_usage();</span><br><span class=\"line\"></span><br><span class=\"line\">      assert(!ref_processor_stw()-&gt;discovery_enabled(), &quot;Postcondition&quot;);</span><br><span class=\"line\">      ref_processor_stw()-&gt;verify_no_references_recorded();</span><br><span class=\"line\"></span><br><span class=\"line\">      // Delete metaspaces for unloaded class loaders and clean up loader_data graph</span><br><span class=\"line\">      ClassLoaderDataGraph::purge();</span><br><span class=\"line\">      MetaspaceAux::verify_metrics();</span><br><span class=\"line\"></span><br><span class=\"line\">      // Note: since we&apos;ve just done a full GC, concurrent</span><br><span class=\"line\">      // marking is no longer active. Therefore we need not</span><br><span class=\"line\">      // re-enable reference discovery for the CM ref processor.</span><br><span class=\"line\">      // That will be done at the start of the next marking cycle.</span><br><span class=\"line\">      assert(!ref_processor_cm()-&gt;discovery_enabled(), &quot;Postcondition&quot;);</span><br><span class=\"line\">      ref_processor_cm()-&gt;verify_no_references_recorded();</span><br><span class=\"line\"></span><br><span class=\"line\">      reset_gc_time_stamp();</span><br><span class=\"line\">      // Since everything potentially moved, we will clear all remembered</span><br><span class=\"line\">      // sets, and clear all cards.  Later we will rebuild remembered</span><br><span class=\"line\">      // sets. We will also reset the GC time stamps of the regions.</span><br><span class=\"line\">      clear_rsets_post_compaction();</span><br><span class=\"line\">      check_gc_time_stamps();</span><br><span class=\"line\"></span><br><span class=\"line\">      resize_if_necessary_after_full_collection();</span><br><span class=\"line\"></span><br><span class=\"line\">      // We should do this after we potentially resize the heap so</span><br><span class=\"line\">      // that all the COMMIT / UNCOMMIT events are generated before</span><br><span class=\"line\">      // the compaction events.</span><br><span class=\"line\">      print_hrm_post_compaction();</span><br><span class=\"line\"></span><br><span class=\"line\">      if (_hot_card_cache-&gt;use_cache()) &#123;</span><br><span class=\"line\">        _hot_card_cache-&gt;reset_card_counts();</span><br><span class=\"line\">        _hot_card_cache-&gt;reset_hot_cache();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      // Rebuild remembered sets of all regions.</span><br><span class=\"line\">      uint n_workers =</span><br><span class=\"line\">        AdaptiveSizePolicy::calc_active_workers(workers()-&gt;total_workers(),</span><br><span class=\"line\">                                                workers()-&gt;active_workers(),</span><br><span class=\"line\">                                                Threads::number_of_non_daemon_threads());</span><br><span class=\"line\">      workers()-&gt;update_active_workers(n_workers);</span><br><span class=\"line\">      log_info(gc,task)(&quot;Using %u workers of %u to rebuild remembered set&quot;, n_workers, workers()-&gt;total_workers());</span><br><span class=\"line\"></span><br><span class=\"line\">      ParRebuildRSTask rebuild_rs_task(this);</span><br><span class=\"line\">      workers()-&gt;run_task(&amp;rebuild_rs_task);</span><br><span class=\"line\"></span><br><span class=\"line\">      // Rebuild the strong code root lists for each region</span><br><span class=\"line\">      rebuild_strong_code_roots();</span><br><span class=\"line\"></span><br><span class=\"line\">      if (true) &#123; // FIXME</span><br><span class=\"line\">        MetaspaceGC::compute_new_size();</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">#ifdef TRACESPINNING</span><br><span class=\"line\">      ParallelTaskTerminator::print_termination_counts();</span><br><span class=\"line\">#endif</span><br><span class=\"line\"></span><br><span class=\"line\">      // Discard all rset updates</span><br><span class=\"line\">      JavaThread::dirty_card_queue_set().abandon_logs();</span><br><span class=\"line\">      assert(dirty_card_queue_set().completed_buffers_num() == 0, &quot;DCQS should be empty&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">      // At this point there should be no regions in the</span><br><span class=\"line\">      // entire heap tagged as young.</span><br><span class=\"line\">      assert(check_young_list_empty(), &quot;young list should be empty at this point&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">      // Update the number of full collections that have been completed.</span><br><span class=\"line\">      increment_old_marking_cycles_completed(false /* concurrent */);</span><br><span class=\"line\"></span><br><span class=\"line\">      _hrm.verify_optional();</span><br><span class=\"line\">      _verifier-&gt;verify_region_sets_optional();</span><br><span class=\"line\"></span><br><span class=\"line\">      _verifier-&gt;verify_after_gc();</span><br><span class=\"line\"></span><br><span class=\"line\">      // Clear the previous marking bitmap, if needed for bitmap verification.</span><br><span class=\"line\">      // Note we cannot do this when we clear the next marking bitmap in</span><br><span class=\"line\">      // G1ConcurrentMark::abort() above since VerifyDuringGC verifies the</span><br><span class=\"line\">      // objects marked during a full GC against the previous bitmap.</span><br><span class=\"line\">      // But we need to clear it before calling check_bitmaps below since</span><br><span class=\"line\">      // the full GC has compacted objects and updated TAMS but not updated</span><br><span class=\"line\">      // the prev bitmap.</span><br><span class=\"line\">      if (G1VerifyBitmaps) &#123;</span><br><span class=\"line\">        GCTraceTime(Debug, gc)(&quot;Clear Bitmap for Verification&quot;);</span><br><span class=\"line\">        _cm-&gt;clear_prev_bitmap(workers());</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      _verifier-&gt;check_bitmaps(&quot;Full GC End&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">      // Start a new incremental collection set for the next pause</span><br><span class=\"line\">      collection_set()-&gt;start_incremental_building();</span><br><span class=\"line\"></span><br><span class=\"line\">      clear_cset_fast_test();</span><br><span class=\"line\"></span><br><span class=\"line\">      _allocator-&gt;init_mutator_alloc_region();</span><br><span class=\"line\"></span><br><span class=\"line\">      g1_policy()-&gt;record_full_collection_end();</span><br><span class=\"line\"></span><br><span class=\"line\">      // We must call G1MonitoringSupport::update_sizes() in the same scoping level</span><br><span class=\"line\">      // as an active TraceMemoryManagerStats object (i.e. before the destructor for the</span><br><span class=\"line\">      // TraceMemoryManagerStats is called) so that the G1 memory pools are updated</span><br><span class=\"line\">      // before any GC notifications are raised.</span><br><span class=\"line\">      g1mm()-&gt;update_sizes();</span><br><span class=\"line\"></span><br><span class=\"line\">      gc_epilogue(true);</span><br><span class=\"line\"></span><br><span class=\"line\">      heap_transition.print();</span><br><span class=\"line\"></span><br><span class=\"line\">      print_heap_after_gc();</span><br><span class=\"line\">      print_heap_regions();</span><br><span class=\"line\">      trace_heap_after_gc(gc_tracer);</span><br><span class=\"line\"></span><br><span class=\"line\">      post_full_gc_dump(gc_timer);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    gc_timer-&gt;register_gc_end();</span><br><span class=\"line\">    gc_tracer-&gt;report_gc_end(gc_timer-&gt;gc_end(), gc_timer-&gt;time_partitions());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  return true;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"JVM-GC-G1-Tuning","date":"2018-12-24T08:27:27.000Z","_content":"\n\n主要参考\nhttp://presentations2015.s3.amazonaws.com/40_presentation.pdf\n\n\n## G1优化思路\n1. 第一部，确定系统类型\n吞吐优先，适用于大规模离线计算系统\n\n暂停时间优先，适用于实时计算并反馈的系统\n-XX:MaxGCPauseMillis=50\n\n## Safepoint优化\n如果连续打印以下日志\n```\n2018-12-18T15:14:27.423+0800: 88.781: Total time for which application threads were stopped: 0.0022266 seconds, Stopping threads took: 0.0005306 seconds\n2018-12-18T15:14:28.425+0800: 89.784: Total time for which application threads were stopped: 0.0024547 seconds, Stopping threads took: 0.0005578 seconds\n2018-12-18T15:14:29.428+0800: 90.787: Total time for which application threads were stopped: 0.0027979 seconds, Stopping threads took: 0.0006438 seconds\n2018-12-18T15:14:31.431+0800: 92.790: Total time for which application threads were stopped: 0.0028555 seconds, Stopping threads took: 0.0006590 seconds\n2018-12-18T15:14:32.434+0800: 93.793: Total time for which application threads were stopped: 0.0029690 seconds, Stopping threads took: 0.0006541 seconds\n2018-12-18T15:14:33.437+0800: 94.796: Total time for which application threads were stopped: 0.0031094 seconds, Stopping threads took: 0.0006861 seconds\n2018-12-18T15:14:34.441+0800: 95.799: Total time for which application threads were stopped: 0.0033426 seconds, Stopping threads took: 0.0007415 seconds\n```\n### 查看safepoint\n-XX:+PrintSafepointStatistics\n-XX:PrintSafepointStatisticsCount=1\n### Revoke Bias优化\n-XX:-UseBiasedLocking\n### 非常多的\"no vm operation\"优化，即所谓的Guaranteed Safepoint，用于做monitor的清理\n-XX:+UnlockDiagnosticVMOptions\n-XX:-DisplayVMOutput\n-XX:+LogVMOutput\n-XX:LogFile=/opt/app/logs/vm.log\n-XX:GuaranteedSafepointInterval=300000\n\n\n```\n完整启动参数\nset JAVA_OPTS\nJAVA_OPTS=\"-server -Xms17944m -Xmx17944m -Xss256k -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m\"\n\n# JAVA_OPT=\"$JAVA_OPT -XX:MaxDirectMemorySize=30g\"\n\n#performance Options\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseG1GC\"\n\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintSafepointStatistics\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:PrintSafepointStatisticsCount=1\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UnlockDiagnosticVMOptions\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:-DisplayVMOutput\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+LogVMOutput\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:LogFile=/opt/logs/cobar/vm.log\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:GuaranteedSafepointInterval=300000\"\n\nJAVA_OPTS=\"$JAVA_OPTS -XX:MaxGCPauseMillis=50\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:ParallelGCThreads=16\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:ConcGCThreads=4\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:SoftRefLRUPolicyMSPerMB=0\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+ParallelRefProcEnabled\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+DisableExplicitGC\"\nJAVA_OPTS=\"$JAVA_OPTS -verbose:gc\"\nJAVA_OPTS=\"$JAVA_OPTS -Xloggc:/opt/logs/cobar/%p_gc.log\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+AggressiveOpts\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:-UseBiasedLocking\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseFastAccessorMethods\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCDetails\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCDateStamps\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCApplicationStoppedTime\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintAdaptiveSizePolicy\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseGCLogFileRotation\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:NumberOfGCLogFiles=5\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:GCLogFileSize=30m\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:-OmitStackTraceInFastThrow\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+AlwaysPreTouch\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:MaxTenuringThreshold=15\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintHeapAtGC\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintFlagsFinal\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintPromotionFailure\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+HeapDumpOnOutOfMemoryError\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:HeapDumpPath=/opt/logs/cobar/java.hprof\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:ErrorFile=/opt/logs/cobar/hs_err_pid%p.log\"\n```\n\n\n\nhttp://blog.csdn.net/matt8/article/details/52298397\n\nhttps://www.ibm.com/developerworks/cn/java/j-lo-jvm-optimize-experience/index.html#icomments\n\nhttps://www.ibm.com/developerworks/cn/java/j-lo-JVMGarbageCollection/#icomments\n\nJava ReentrantLock（重入锁）带来的改变\n\n\n### 前言\n> ReentrantLock称为重入锁，它比内部锁synchronized拥有更强大的功能，它可中断、可定时，JDK5中，在高并发的情况下，它比synchronized有明显的性能优势，在JDK6中由于jvm的优化，两者差别不是很大。\n\n\nsynchronized原语和ReentrantLock在一般情况下没有什么区别，但是在非常复杂的同步应用中，请考虑使用ReentrantLock，特别是遇到下面2种需求的时候。\n1.某个线程在等待一个锁的控制权的这段时间需要中断\n2.需要分开处理一些wait-notify，ReentrantLock里面的Condition应用，能够控制notify哪个线程\n3.具有公平锁功能，每个到来的线程都将排队等候\n\n先说第一种情况，ReentrantLock的lock机制有2种，忽略中断锁和响应中断锁，这给我们带来了很大的灵活性。比如：如果A、B2个线程去竞争锁，A线程得到了锁，B线程等待，但是A线程这个时候实在有太多事情要处理，就是一直不返回，B线程可能就会等不及了，想中断自己，不再等待这个锁了，转而处理其他事情。这个时候ReentrantLock就提供了2种机制，第一，B线程中断自己（或者别的线程中断它），但是ReentrantLock不去响应，继续让B线程等待，你再怎么中断，我全当耳边风（synchronized原语就是如此）；第二，B线程中断自己（或者别的线程中断它），ReentrantLock处理了这个中断，并且不再等待这个锁的到来，完全放弃。（如果你没有了解java的中断机制，请参考下相关资料，再回头看这篇文章，80%的人根本没有真正理解什么是java的中断，呵呵）\n\n这里来做个试验，首先搞一个Buffer类，它有读操作和写操作，为了不读到脏数据，写和读都需要加锁，我们先用synchronized原语来加锁，如下：\n\n``` java\npackage com.eric.lock;\n\npublic class Buffer {\n\n    private Object lock;\n\n    public Buffer() {\n        lock = this;\n    }\n\n    public void write() {\n        synchronized (lock) {\n            long startTime = System.currentTimeMillis();\n            System.out.println(\"开始往这个buff写入数据…\");\n            // 模拟要处理很长时间\n            for (; ; ) {\n                if (System.currentTimeMillis() - startTime > Integer.MAX_VALUE)\n                    break;\n            }\n            System.out.println(\"终于写完了\");\n        }\n    }\n\n    public void read() {\n        synchronized (lock) {\n            System.out.println(\"从这个buff读数据\");\n        }\n    }\n}\n```\n\n接着，我们来定义2个线程，一个线程去写，一个线程去读。\n\nhttp://www.importnew.com/15311.html\nG1垃圾回收","source":"_posts/JVM-GC-G1-Tuning.md","raw":"---\ntitle: JVM-GC-G1-Tuning\ndate: 2018-12-24 16:27:27\ntags: JVM\n---\n\n\n主要参考\nhttp://presentations2015.s3.amazonaws.com/40_presentation.pdf\n\n\n## G1优化思路\n1. 第一部，确定系统类型\n吞吐优先，适用于大规模离线计算系统\n\n暂停时间优先，适用于实时计算并反馈的系统\n-XX:MaxGCPauseMillis=50\n\n## Safepoint优化\n如果连续打印以下日志\n```\n2018-12-18T15:14:27.423+0800: 88.781: Total time for which application threads were stopped: 0.0022266 seconds, Stopping threads took: 0.0005306 seconds\n2018-12-18T15:14:28.425+0800: 89.784: Total time for which application threads were stopped: 0.0024547 seconds, Stopping threads took: 0.0005578 seconds\n2018-12-18T15:14:29.428+0800: 90.787: Total time for which application threads were stopped: 0.0027979 seconds, Stopping threads took: 0.0006438 seconds\n2018-12-18T15:14:31.431+0800: 92.790: Total time for which application threads were stopped: 0.0028555 seconds, Stopping threads took: 0.0006590 seconds\n2018-12-18T15:14:32.434+0800: 93.793: Total time for which application threads were stopped: 0.0029690 seconds, Stopping threads took: 0.0006541 seconds\n2018-12-18T15:14:33.437+0800: 94.796: Total time for which application threads were stopped: 0.0031094 seconds, Stopping threads took: 0.0006861 seconds\n2018-12-18T15:14:34.441+0800: 95.799: Total time for which application threads were stopped: 0.0033426 seconds, Stopping threads took: 0.0007415 seconds\n```\n### 查看safepoint\n-XX:+PrintSafepointStatistics\n-XX:PrintSafepointStatisticsCount=1\n### Revoke Bias优化\n-XX:-UseBiasedLocking\n### 非常多的\"no vm operation\"优化，即所谓的Guaranteed Safepoint，用于做monitor的清理\n-XX:+UnlockDiagnosticVMOptions\n-XX:-DisplayVMOutput\n-XX:+LogVMOutput\n-XX:LogFile=/opt/app/logs/vm.log\n-XX:GuaranteedSafepointInterval=300000\n\n\n```\n完整启动参数\nset JAVA_OPTS\nJAVA_OPTS=\"-server -Xms17944m -Xmx17944m -Xss256k -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m\"\n\n# JAVA_OPT=\"$JAVA_OPT -XX:MaxDirectMemorySize=30g\"\n\n#performance Options\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseG1GC\"\n\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintSafepointStatistics\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:PrintSafepointStatisticsCount=1\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UnlockDiagnosticVMOptions\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:-DisplayVMOutput\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+LogVMOutput\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:LogFile=/opt/logs/cobar/vm.log\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:GuaranteedSafepointInterval=300000\"\n\nJAVA_OPTS=\"$JAVA_OPTS -XX:MaxGCPauseMillis=50\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:ParallelGCThreads=16\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:ConcGCThreads=4\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:SoftRefLRUPolicyMSPerMB=0\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+ParallelRefProcEnabled\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+DisableExplicitGC\"\nJAVA_OPTS=\"$JAVA_OPTS -verbose:gc\"\nJAVA_OPTS=\"$JAVA_OPTS -Xloggc:/opt/logs/cobar/%p_gc.log\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+AggressiveOpts\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:-UseBiasedLocking\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseFastAccessorMethods\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCDetails\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCDateStamps\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintGCApplicationStoppedTime\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintAdaptiveSizePolicy\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+UseGCLogFileRotation\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:NumberOfGCLogFiles=5\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:GCLogFileSize=30m\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:-OmitStackTraceInFastThrow\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+AlwaysPreTouch\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:MaxTenuringThreshold=15\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintHeapAtGC\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintFlagsFinal\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+PrintPromotionFailure\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:+HeapDumpOnOutOfMemoryError\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:HeapDumpPath=/opt/logs/cobar/java.hprof\"\nJAVA_OPTS=\"$JAVA_OPTS -XX:ErrorFile=/opt/logs/cobar/hs_err_pid%p.log\"\n```\n\n\n\nhttp://blog.csdn.net/matt8/article/details/52298397\n\nhttps://www.ibm.com/developerworks/cn/java/j-lo-jvm-optimize-experience/index.html#icomments\n\nhttps://www.ibm.com/developerworks/cn/java/j-lo-JVMGarbageCollection/#icomments\n\nJava ReentrantLock（重入锁）带来的改变\n\n\n### 前言\n> ReentrantLock称为重入锁，它比内部锁synchronized拥有更强大的功能，它可中断、可定时，JDK5中，在高并发的情况下，它比synchronized有明显的性能优势，在JDK6中由于jvm的优化，两者差别不是很大。\n\n\nsynchronized原语和ReentrantLock在一般情况下没有什么区别，但是在非常复杂的同步应用中，请考虑使用ReentrantLock，特别是遇到下面2种需求的时候。\n1.某个线程在等待一个锁的控制权的这段时间需要中断\n2.需要分开处理一些wait-notify，ReentrantLock里面的Condition应用，能够控制notify哪个线程\n3.具有公平锁功能，每个到来的线程都将排队等候\n\n先说第一种情况，ReentrantLock的lock机制有2种，忽略中断锁和响应中断锁，这给我们带来了很大的灵活性。比如：如果A、B2个线程去竞争锁，A线程得到了锁，B线程等待，但是A线程这个时候实在有太多事情要处理，就是一直不返回，B线程可能就会等不及了，想中断自己，不再等待这个锁了，转而处理其他事情。这个时候ReentrantLock就提供了2种机制，第一，B线程中断自己（或者别的线程中断它），但是ReentrantLock不去响应，继续让B线程等待，你再怎么中断，我全当耳边风（synchronized原语就是如此）；第二，B线程中断自己（或者别的线程中断它），ReentrantLock处理了这个中断，并且不再等待这个锁的到来，完全放弃。（如果你没有了解java的中断机制，请参考下相关资料，再回头看这篇文章，80%的人根本没有真正理解什么是java的中断，呵呵）\n\n这里来做个试验，首先搞一个Buffer类，它有读操作和写操作，为了不读到脏数据，写和读都需要加锁，我们先用synchronized原语来加锁，如下：\n\n``` java\npackage com.eric.lock;\n\npublic class Buffer {\n\n    private Object lock;\n\n    public Buffer() {\n        lock = this;\n    }\n\n    public void write() {\n        synchronized (lock) {\n            long startTime = System.currentTimeMillis();\n            System.out.println(\"开始往这个buff写入数据…\");\n            // 模拟要处理很长时间\n            for (; ; ) {\n                if (System.currentTimeMillis() - startTime > Integer.MAX_VALUE)\n                    break;\n            }\n            System.out.println(\"终于写完了\");\n        }\n    }\n\n    public void read() {\n        synchronized (lock) {\n            System.out.println(\"从这个buff读数据\");\n        }\n    }\n}\n```\n\n接着，我们来定义2个线程，一个线程去写，一个线程去读。\n\nhttp://www.importnew.com/15311.html\nG1垃圾回收","slug":"JVM-GC-G1-Tuning","published":1,"updated":"2019-09-28T08:51:00.868Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o834001sv1npfis7zyei","content":"<p>主要参考<br><a href=\"http://presentations2015.s3.amazonaws.com/40_presentation.pdf\" target=\"_blank\" rel=\"noopener\">http://presentations2015.s3.amazonaws.com/40_presentation.pdf</a></p>\n<h2 id=\"G1优化思路\"><a href=\"#G1优化思路\" class=\"headerlink\" title=\"G1优化思路\"></a>G1优化思路</h2><ol>\n<li>第一部，确定系统类型<br>吞吐优先，适用于大规模离线计算系统</li>\n</ol>\n<p>暂停时间优先，适用于实时计算并反馈的系统<br>-XX:MaxGCPauseMillis=50</p>\n<h2 id=\"Safepoint优化\"><a href=\"#Safepoint优化\" class=\"headerlink\" title=\"Safepoint优化\"></a>Safepoint优化</h2><p>如果连续打印以下日志</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2018-12-18T15:14:27.423+0800: 88.781: Total time for which application threads were stopped: 0.0022266 seconds, Stopping threads took: 0.0005306 seconds</span><br><span class=\"line\">2018-12-18T15:14:28.425+0800: 89.784: Total time for which application threads were stopped: 0.0024547 seconds, Stopping threads took: 0.0005578 seconds</span><br><span class=\"line\">2018-12-18T15:14:29.428+0800: 90.787: Total time for which application threads were stopped: 0.0027979 seconds, Stopping threads took: 0.0006438 seconds</span><br><span class=\"line\">2018-12-18T15:14:31.431+0800: 92.790: Total time for which application threads were stopped: 0.0028555 seconds, Stopping threads took: 0.0006590 seconds</span><br><span class=\"line\">2018-12-18T15:14:32.434+0800: 93.793: Total time for which application threads were stopped: 0.0029690 seconds, Stopping threads took: 0.0006541 seconds</span><br><span class=\"line\">2018-12-18T15:14:33.437+0800: 94.796: Total time for which application threads were stopped: 0.0031094 seconds, Stopping threads took: 0.0006861 seconds</span><br><span class=\"line\">2018-12-18T15:14:34.441+0800: 95.799: Total time for which application threads were stopped: 0.0033426 seconds, Stopping threads took: 0.0007415 seconds</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"查看safepoint\"><a href=\"#查看safepoint\" class=\"headerlink\" title=\"查看safepoint\"></a>查看safepoint</h3><p>-XX:+PrintSafepointStatistics<br>-XX:PrintSafepointStatisticsCount=1</p>\n<h3 id=\"Revoke-Bias优化\"><a href=\"#Revoke-Bias优化\" class=\"headerlink\" title=\"Revoke Bias优化\"></a>Revoke Bias优化</h3><p>-XX:-UseBiasedLocking</p>\n<h3 id=\"非常多的”no-vm-operation”优化，即所谓的Guaranteed-Safepoint，用于做monitor的清理\"><a href=\"#非常多的”no-vm-operation”优化，即所谓的Guaranteed-Safepoint，用于做monitor的清理\" class=\"headerlink\" title=\"非常多的”no vm operation”优化，即所谓的Guaranteed Safepoint，用于做monitor的清理\"></a>非常多的”no vm operation”优化，即所谓的Guaranteed Safepoint，用于做monitor的清理</h3><p>-XX:+UnlockDiagnosticVMOptions<br>-XX:-DisplayVMOutput<br>-XX:+LogVMOutput<br>-XX:LogFile=/opt/app/logs/vm.log<br>-XX:GuaranteedSafepointInterval=300000</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">完整启动参数</span><br><span class=\"line\">set JAVA_OPTS</span><br><span class=\"line\">JAVA_OPTS=&quot;-server -Xms17944m -Xmx17944m -Xss256k -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"># JAVA_OPT=&quot;$JAVA_OPT -XX:MaxDirectMemorySize=30g&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">#performance Options</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseG1GC&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintSafepointStatistics&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:PrintSafepointStatisticsCount=1&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UnlockDiagnosticVMOptions&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:-DisplayVMOutput&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+LogVMOutput&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:LogFile=/opt/logs/cobar/vm.log&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:GuaranteedSafepointInterval=300000&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:MaxGCPauseMillis=50&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:ParallelGCThreads=16&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:ConcGCThreads=4&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:SoftRefLRUPolicyMSPerMB=0&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+ParallelRefProcEnabled&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+DisableExplicitGC&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -verbose:gc&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Xloggc:/opt/logs/cobar/%p_gc.log&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+AggressiveOpts&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:-UseBiasedLocking&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseFastAccessorMethods&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCDetails&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCDateStamps&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCApplicationStoppedTime&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintAdaptiveSizePolicy&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseGCLogFileRotation&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:NumberOfGCLogFiles=5&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:GCLogFileSize=30m&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:-OmitStackTraceInFastThrow&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+AlwaysPreTouch&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:MaxTenuringThreshold=15&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintHeapAtGC&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintFlagsFinal&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintPromotionFailure&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+HeapDumpOnOutOfMemoryError&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:HeapDumpPath=/opt/logs/cobar/java.hprof&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:ErrorFile=/opt/logs/cobar/hs_err_pid%p.log&quot;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"http://blog.csdn.net/matt8/article/details/52298397\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/matt8/article/details/52298397</a></p>\n<p><a href=\"https://www.ibm.com/developerworks/cn/java/j-lo-jvm-optimize-experience/index.html#icomments\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/java/j-lo-jvm-optimize-experience/index.html#icomments</a></p>\n<p><a href=\"https://www.ibm.com/developerworks/cn/java/j-lo-JVMGarbageCollection/#icomments\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/java/j-lo-JVMGarbageCollection/#icomments</a></p>\n<p>Java ReentrantLock（重入锁）带来的改变</p>\n<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><blockquote>\n<p>ReentrantLock称为重入锁，它比内部锁synchronized拥有更强大的功能，它可中断、可定时，JDK5中，在高并发的情况下，它比synchronized有明显的性能优势，在JDK6中由于jvm的优化，两者差别不是很大。</p>\n</blockquote>\n<p>synchronized原语和ReentrantLock在一般情况下没有什么区别，但是在非常复杂的同步应用中，请考虑使用ReentrantLock，特别是遇到下面2种需求的时候。<br>1.某个线程在等待一个锁的控制权的这段时间需要中断<br>2.需要分开处理一些wait-notify，ReentrantLock里面的Condition应用，能够控制notify哪个线程<br>3.具有公平锁功能，每个到来的线程都将排队等候</p>\n<p>先说第一种情况，ReentrantLock的lock机制有2种，忽略中断锁和响应中断锁，这给我们带来了很大的灵活性。比如：如果A、B2个线程去竞争锁，A线程得到了锁，B线程等待，但是A线程这个时候实在有太多事情要处理，就是一直不返回，B线程可能就会等不及了，想中断自己，不再等待这个锁了，转而处理其他事情。这个时候ReentrantLock就提供了2种机制，第一，B线程中断自己（或者别的线程中断它），但是ReentrantLock不去响应，继续让B线程等待，你再怎么中断，我全当耳边风（synchronized原语就是如此）；第二，B线程中断自己（或者别的线程中断它），ReentrantLock处理了这个中断，并且不再等待这个锁的到来，完全放弃。（如果你没有了解java的中断机制，请参考下相关资料，再回头看这篇文章，80%的人根本没有真正理解什么是java的中断，呵呵）</p>\n<p>这里来做个试验，首先搞一个Buffer类，它有读操作和写操作，为了不读到脏数据，写和读都需要加锁，我们先用synchronized原语来加锁，如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.eric.lock;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Buffer</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> Object lock;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Buffer</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        lock = <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">write</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">synchronized</span> (lock) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">long</span> startTime = System.currentTimeMillis();</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"开始往这个buff写入数据…\"</span>);</span><br><span class=\"line\">            <span class=\"comment\">// 模拟要处理很长时间</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> (; ; ) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (System.currentTimeMillis() - startTime &gt; Integer.MAX_VALUE)</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"终于写完了\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">read</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">synchronized</span> (lock) &#123;</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"从这个buff读数据\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>接着，我们来定义2个线程，一个线程去写，一个线程去读。</p>\n<p><a href=\"http://www.importnew.com/15311.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/15311.html</a><br>G1垃圾回收</p>\n","site":{"data":{}},"excerpt":"","more":"<p>主要参考<br><a href=\"http://presentations2015.s3.amazonaws.com/40_presentation.pdf\" target=\"_blank\" rel=\"noopener\">http://presentations2015.s3.amazonaws.com/40_presentation.pdf</a></p>\n<h2 id=\"G1优化思路\"><a href=\"#G1优化思路\" class=\"headerlink\" title=\"G1优化思路\"></a>G1优化思路</h2><ol>\n<li>第一部，确定系统类型<br>吞吐优先，适用于大规模离线计算系统</li>\n</ol>\n<p>暂停时间优先，适用于实时计算并反馈的系统<br>-XX:MaxGCPauseMillis=50</p>\n<h2 id=\"Safepoint优化\"><a href=\"#Safepoint优化\" class=\"headerlink\" title=\"Safepoint优化\"></a>Safepoint优化</h2><p>如果连续打印以下日志</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2018-12-18T15:14:27.423+0800: 88.781: Total time for which application threads were stopped: 0.0022266 seconds, Stopping threads took: 0.0005306 seconds</span><br><span class=\"line\">2018-12-18T15:14:28.425+0800: 89.784: Total time for which application threads were stopped: 0.0024547 seconds, Stopping threads took: 0.0005578 seconds</span><br><span class=\"line\">2018-12-18T15:14:29.428+0800: 90.787: Total time for which application threads were stopped: 0.0027979 seconds, Stopping threads took: 0.0006438 seconds</span><br><span class=\"line\">2018-12-18T15:14:31.431+0800: 92.790: Total time for which application threads were stopped: 0.0028555 seconds, Stopping threads took: 0.0006590 seconds</span><br><span class=\"line\">2018-12-18T15:14:32.434+0800: 93.793: Total time for which application threads were stopped: 0.0029690 seconds, Stopping threads took: 0.0006541 seconds</span><br><span class=\"line\">2018-12-18T15:14:33.437+0800: 94.796: Total time for which application threads were stopped: 0.0031094 seconds, Stopping threads took: 0.0006861 seconds</span><br><span class=\"line\">2018-12-18T15:14:34.441+0800: 95.799: Total time for which application threads were stopped: 0.0033426 seconds, Stopping threads took: 0.0007415 seconds</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"查看safepoint\"><a href=\"#查看safepoint\" class=\"headerlink\" title=\"查看safepoint\"></a>查看safepoint</h3><p>-XX:+PrintSafepointStatistics<br>-XX:PrintSafepointStatisticsCount=1</p>\n<h3 id=\"Revoke-Bias优化\"><a href=\"#Revoke-Bias优化\" class=\"headerlink\" title=\"Revoke Bias优化\"></a>Revoke Bias优化</h3><p>-XX:-UseBiasedLocking</p>\n<h3 id=\"非常多的”no-vm-operation”优化，即所谓的Guaranteed-Safepoint，用于做monitor的清理\"><a href=\"#非常多的”no-vm-operation”优化，即所谓的Guaranteed-Safepoint，用于做monitor的清理\" class=\"headerlink\" title=\"非常多的”no vm operation”优化，即所谓的Guaranteed Safepoint，用于做monitor的清理\"></a>非常多的”no vm operation”优化，即所谓的Guaranteed Safepoint，用于做monitor的清理</h3><p>-XX:+UnlockDiagnosticVMOptions<br>-XX:-DisplayVMOutput<br>-XX:+LogVMOutput<br>-XX:LogFile=/opt/app/logs/vm.log<br>-XX:GuaranteedSafepointInterval=300000</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">完整启动参数</span><br><span class=\"line\">set JAVA_OPTS</span><br><span class=\"line\">JAVA_OPTS=&quot;-server -Xms17944m -Xmx17944m -Xss256k -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"># JAVA_OPT=&quot;$JAVA_OPT -XX:MaxDirectMemorySize=30g&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">#performance Options</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseG1GC&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintSafepointStatistics&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:PrintSafepointStatisticsCount=1&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UnlockDiagnosticVMOptions&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:-DisplayVMOutput&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+LogVMOutput&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:LogFile=/opt/logs/cobar/vm.log&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:GuaranteedSafepointInterval=300000&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:MaxGCPauseMillis=50&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:ParallelGCThreads=16&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:ConcGCThreads=4&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:SoftRefLRUPolicyMSPerMB=0&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+ParallelRefProcEnabled&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+DisableExplicitGC&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -verbose:gc&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -Xloggc:/opt/logs/cobar/%p_gc.log&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+AggressiveOpts&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:-UseBiasedLocking&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseFastAccessorMethods&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCDetails&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCDateStamps&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintGCApplicationStoppedTime&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintAdaptiveSizePolicy&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+UseGCLogFileRotation&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:NumberOfGCLogFiles=5&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:GCLogFileSize=30m&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:-OmitStackTraceInFastThrow&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+AlwaysPreTouch&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:MaxTenuringThreshold=15&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintHeapAtGC&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintFlagsFinal&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+PrintPromotionFailure&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:+HeapDumpOnOutOfMemoryError&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:HeapDumpPath=/opt/logs/cobar/java.hprof&quot;</span><br><span class=\"line\">JAVA_OPTS=&quot;$JAVA_OPTS -XX:ErrorFile=/opt/logs/cobar/hs_err_pid%p.log&quot;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"http://blog.csdn.net/matt8/article/details/52298397\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/matt8/article/details/52298397</a></p>\n<p><a href=\"https://www.ibm.com/developerworks/cn/java/j-lo-jvm-optimize-experience/index.html#icomments\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/java/j-lo-jvm-optimize-experience/index.html#icomments</a></p>\n<p><a href=\"https://www.ibm.com/developerworks/cn/java/j-lo-JVMGarbageCollection/#icomments\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/java/j-lo-JVMGarbageCollection/#icomments</a></p>\n<p>Java ReentrantLock（重入锁）带来的改变</p>\n<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><blockquote>\n<p>ReentrantLock称为重入锁，它比内部锁synchronized拥有更强大的功能，它可中断、可定时，JDK5中，在高并发的情况下，它比synchronized有明显的性能优势，在JDK6中由于jvm的优化，两者差别不是很大。</p>\n</blockquote>\n<p>synchronized原语和ReentrantLock在一般情况下没有什么区别，但是在非常复杂的同步应用中，请考虑使用ReentrantLock，特别是遇到下面2种需求的时候。<br>1.某个线程在等待一个锁的控制权的这段时间需要中断<br>2.需要分开处理一些wait-notify，ReentrantLock里面的Condition应用，能够控制notify哪个线程<br>3.具有公平锁功能，每个到来的线程都将排队等候</p>\n<p>先说第一种情况，ReentrantLock的lock机制有2种，忽略中断锁和响应中断锁，这给我们带来了很大的灵活性。比如：如果A、B2个线程去竞争锁，A线程得到了锁，B线程等待，但是A线程这个时候实在有太多事情要处理，就是一直不返回，B线程可能就会等不及了，想中断自己，不再等待这个锁了，转而处理其他事情。这个时候ReentrantLock就提供了2种机制，第一，B线程中断自己（或者别的线程中断它），但是ReentrantLock不去响应，继续让B线程等待，你再怎么中断，我全当耳边风（synchronized原语就是如此）；第二，B线程中断自己（或者别的线程中断它），ReentrantLock处理了这个中断，并且不再等待这个锁的到来，完全放弃。（如果你没有了解java的中断机制，请参考下相关资料，再回头看这篇文章，80%的人根本没有真正理解什么是java的中断，呵呵）</p>\n<p>这里来做个试验，首先搞一个Buffer类，它有读操作和写操作，为了不读到脏数据，写和读都需要加锁，我们先用synchronized原语来加锁，如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.eric.lock;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Buffer</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> Object lock;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Buffer</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        lock = <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">write</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">synchronized</span> (lock) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">long</span> startTime = System.currentTimeMillis();</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"开始往这个buff写入数据…\"</span>);</span><br><span class=\"line\">            <span class=\"comment\">// 模拟要处理很长时间</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> (; ; ) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (System.currentTimeMillis() - startTime &gt; Integer.MAX_VALUE)</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"终于写完了\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">read</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">synchronized</span> (lock) &#123;</span><br><span class=\"line\">            System.out.println(<span class=\"string\">\"从这个buff读数据\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>接着，我们来定义2个线程，一个线程去写，一个线程去读。</p>\n<p><a href=\"http://www.importnew.com/15311.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/15311.html</a><br>G1垃圾回收</p>\n"},{"title":"JVM-GC-G1-SATB","date":"2018-12-13T10:46:32.000Z","_content":"\nclass HeapRegion: public G1ContiguousSpace {\n\n  // The start of the unmarked area. The unmarked area extends from this\n  // word until the top and/or end of the region, and is the part\n  // of the region for which no marking was done, i.e. objects may\n  // have been allocated in this part since the last mark phase.\n  // \"prev\" is the top at the start of the last completed marking.\n  // \"next\" is the top at the start of the in-progress marking (if any.)\n  HeapWord* _prev_top_at_mark_start;\n  HeapWord* _next_top_at_mark_start;\n\n}","source":"_posts/JVM-GC-G1-SATB.md","raw":"---\ntitle: JVM-GC-G1-SATB\ndate: 2018-12-13 18:46:32\ntags: JVM\n---\n\nclass HeapRegion: public G1ContiguousSpace {\n\n  // The start of the unmarked area. The unmarked area extends from this\n  // word until the top and/or end of the region, and is the part\n  // of the region for which no marking was done, i.e. objects may\n  // have been allocated in this part since the last mark phase.\n  // \"prev\" is the top at the start of the last completed marking.\n  // \"next\" is the top at the start of the in-progress marking (if any.)\n  HeapWord* _prev_top_at_mark_start;\n  HeapWord* _next_top_at_mark_start;\n\n}","slug":"JVM-GC-G1-SATB","published":1,"updated":"2019-09-28T08:51:00.867Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o834001tv1npbyit37fg","content":"<p>class HeapRegion: public G1ContiguousSpace {</p>\n<p>  // The start of the unmarked area. The unmarked area extends from this<br>  // word until the top and/or end of the region, and is the part<br>  // of the region for which no marking was done, i.e. objects may<br>  // have been allocated in this part since the last mark phase.<br>  // “prev” is the top at the start of the last completed marking.<br>  // “next” is the top at the start of the in-progress marking (if any.)<br>  HeapWord* _prev_top_at_mark_start;<br>  HeapWord* _next_top_at_mark_start;</p>\n<p>}</p>\n","site":{"data":{}},"excerpt":"","more":"<p>class HeapRegion: public G1ContiguousSpace {</p>\n<p>  // The start of the unmarked area. The unmarked area extends from this<br>  // word until the top and/or end of the region, and is the part<br>  // of the region for which no marking was done, i.e. objects may<br>  // have been allocated in this part since the last mark phase.<br>  // “prev” is the top at the start of the last completed marking.<br>  // “next” is the top at the start of the in-progress marking (if any.)<br>  HeapWord* _prev_top_at_mark_start;<br>  HeapWord* _next_top_at_mark_start;</p>\n<p>}</p>\n"},{"title":"JVM-G1","date":"2018-10-12T02:06:33.000Z","_content":"\nhttps://www.oracle.com/technetwork/java/javase/tech/g1-intro-jsp-135488.html\n先翻译一遍\n\n### 美团技术文章写得好\nhttps://tech.meituan.com/g1.html\n\n### 这篇文章好像写得也不错\nhttps://www.cnblogs.com/yunxitalk/p/8987318.html\n\n### redhat里面的图看上去不错\nhttps://www.redhat.com/en/blog/part-1-introduction-g1-garbage-collector\nhttps://www.redhat.com/en/blog/collecting-and-reading-g1-garbage-collector-logs-part-2\n\n### R大不是盖的啊\nhttps://hllvm-group.iteye.com/group/topic/44381\n\n### 杜兄的文章写得很不错\nhttps://www.jianshu.com/p/a3e6a9de7a5d\n\n### Amazon 神PPT，写得很详细\nhttp://presentations2015.s3.amazonaws.com/40_presentation.pdf\n\n### younggc\n#### First phase: “Root Scanning”\n需要STW，从GC root开始扫描存活对象\nStatic and local objects are scanned\n\n#### Second phase: “Update RS”\n在上一轮中，有很多对象修改了引用，被load barrier放入了dirty card queue，需要把这部分的数据拿出来，更新Rset\nDrains the dirty card queue to update the RS\n\n#### Third phase: “Process RS”\n从GC Root的扫描无法彻底让Region和Region独立工作，需要借助于RSet，从RSet找到从Old区指向当前Region的区域（CardTable）\nDetect the Eden objects pointed by Old objects\n\n#### Fourth phase: “Object Copy”\nThe object graph is traversed\nLive objects copied to Survivor/Old regions\n\n#### Fifth phase: “Reference Processing”\nSoft, Weak, Phantom, Final, JNI Weak references\nAlways enable -XX:+ParallelRefProcEnabled\nMore details with -XX:+PrintReferenceGC\n\n### infoQ\nhttps://www.infoq.com/articles/tuning-tips-G1-GC\n\n\n// VM_operations for the G1 collector.\n// VM_GC_Operation:\n//   - VM_CGC_Operation\n//   - VM_G1CollectFull\n//   - VM_G1OperationWithAllocRequest\n//     - VM_G1CollectForAllocation\n//     - VM_G1IncCollectionPause\n\n\nhttps://zhuanlan.zhihu.com/p/22591838\n\n\n### 重要信息\nG1GC没有提供专门的FullGC，还是使用传统FullGC来对整个堆的垃圾进行收集。\n\n### Young GC的时间预测调用栈\nG1DefaultPolicy::predict_base_elapsed_time_ms g1DefaultPolicy.cpp:829\nG1DefaultPolicy::predict_base_elapsed_time_ms g1DefaultPolicy.cpp:837\nG1CollectionSet::finalize_young_part g1CollectionSet.cpp:363\nG1DefaultPolicy::finalize_collection_set g1DefaultPolicy.cpp:1137\nG1CollectedHeap::do_collection_pause_at_safepoint g1CollectedHeap.cpp:3162\nVM_G1IncCollectionPause::doit vm_operations_g1.cpp:148\nVM_Operation::evaluate vm_operations.cpp:66\nVMThread::evaluate_operation vmThread.cpp:348\nVMThread::loop vmThread.cpp:470\nVMThread::run vmThread.cpp:262\nthread_native_entry os_bsd.cpp:720\n_pthread_body 0x00007fff74974339\n_pthread_start 0x00007fff749772a7\nthread_start 0x00007fff74973445\n<unknown> 0x0000000000000000\n\n\n\n####        美团文章            ##########\nJava Hotspot G1 GC的一些关键技术\n2016年09月23日 作者: 小亮 文章链接 18946字 38分钟阅读\n前言\nG1 GC，全称Garbage-First Garbage Collector，通过-XX:+UseG1GC参数来启用，作为体验版随着JDK 6u14版本面世，在JDK 7u4版本发行时被正式推出，相信熟悉JVM的同学们都不会对它感到陌生。在JDK 9中，G1被提议设置为默认垃圾收集器（JEP 248）。在官网中，是这样描述G1的： > The Garbage-First (G1) collector is a server-style garbage collector, targeted for multi-processor machines with large memories. It meets garbage collection (GC) pause time goals with a high probability, while achieving high throughput. The G1 garbage collector is fully supported in Oracle JDK 7 update 4 and later releases. The G1 collector is designed for applications that: > * Can operate concurrently with applications threads like the CMS collector. > * Compact free space without lengthy GC induced pause times. > * Need more predictable GC pause durations. > * Do not want to sacrifice a lot of throughput performance. > * Do not require a much larger Java heap.\n\n从官网的描述中，我们知道G1是一种服务器端的垃圾收集器，应用在多处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集暂停时间的要求。它是专门针对以下应用场景设计的: * 像CMS收集器一样，能与应用程序线程并发执行。 * 整理空闲空间更快。 * 需要GC停顿时间更好预测。 * 不希望牺牲大量的吞吐性能。 * 不需要更大的Java Heap。\n\nG1收集器的设计目标是取代CMS收集器，它同CMS相比，在以下方面表现的更出色： * G1是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片。 * G1的Stop The World(STW)更可控，G1在停顿时间上添加了预测机制，用户可以指定期望停顿时间。\n\n有了以上的特性，难怪有人说它是一款驾驭一切的垃圾收集器（G1: One Garbage Collector To Rule Them All）。本文带大家来了解一下G1 GC的一些关键技术，为能正确的使用它，做好理论基础的铺垫。\n\nG1中几个重要概念\n在G1的实现过程中，引入了一些新的概念，对于实现高吞吐、没有内存碎片、收集时间可控等功能起到了关键作用。下面我们就一起看一下G1中的这几个重要概念。\n\nRegion\n传统的GC收集器将连续的内存空间划分为新生代、老年代和永久代（JDK 8去除了永久代，引入了元空间Metaspace），这种划分的特点是各代的存储地址（逻辑地址，下同）是连续的。如下图所示： 传统GC内存布局\n传统GC内存布局\n\n而G1的各代存储地址是不连续的，每一代都使用了n个不连续的大小相同的Region，每个Region占有一块连续的虚拟内存地址。如下图所示： g1 GC内存布局\ng1 GC内存布局\n\n在上图中，我们注意到还有一些Region标明了H，它代表Humongous，这表示这些Region存储的是巨大对象（humongous object，H-obj），即大小大于等于region一半的对象。H-obj有如下几个特征： * H-obj直接分配到了old gen，防止了反复拷贝移动。 * H-obj在global concurrent marking阶段的cleanup 和 full GC阶段回收。 * 在分配H-obj之前先检查是否超过 initiating heap occupancy percent和the marking threshold, 如果超过的话，就启动global concurrent marking，为的是提早回收，防止 evacuation failures 和 full GC。\n\n为了减少连续H-objs分配对GC的影响，需要把大对象变为普通的对象，建议增大Region size。\n\n一个Region的大小可以通过参数-XX:G1HeapRegionSize设定，取值范围从1M到32M，且是2的指数。如果不设定，那么G1会根据Heap大小自动决定。相关的设置代码如下：\n\n// share/vm/gc_implementation/g1/heapRegion.cpp\n// Minimum region size; we won't go lower than that.\n// We might want to decrease this in the future, to deal with small\n// heaps a bit more efficiently.\n#define MIN_REGION_SIZE  (      1024 * 1024 )\n// Maximum region size; we don't go higher than that. There's a good\n// reason for having an upper bound. We don't want regions to get too\n// large, otherwise cleanup's effectiveness would decrease as there\n// will be fewer opportunities to find totally empty regions after\n// marking.\n#define MAX_REGION_SIZE  ( 32 * 1024 * 1024 )\n// The automatic region size calculation will try to have around this\n// many regions in the heap (based on the min heap size).\n#define TARGET_REGION_NUMBER          2048\nvoid HeapRegion::setup_heap_region_size(size_t initial_heap_size, size_t max_heap_size) {\n  uintx region_size = G1HeapRegionSize;\n  if (FLAG_IS_DEFAULT(G1HeapRegionSize)) {\n    size_t average_heap_size = (initial_heap_size + max_heap_size) / 2;\n    region_size = MAX2(average_heap_size / TARGET_REGION_NUMBER,\n                       (uintx) MIN_REGION_SIZE);\n  }\n  int region_size_log = log2_long((jlong) region_size);\n  // Recalculate the region size to make sure it's a power of\n  // 2. This means that region_size is the largest power of 2 that's\n  // <= what we've calculated so far.\n  region_size = ((uintx)1 << region_size_log);\n  // Now make sure that we don't go over or under our limits.\n  if (region_size < MIN_REGION_SIZE) {\n    region_size = MIN_REGION_SIZE;\n  } else if (region_size > MAX_REGION_SIZE) {\n    region_size = MAX_REGION_SIZE;\n  }\n}\nSATB\n全称是Snapshot-At-The-Beginning，由字面理解，是GC开始时活着的对象的一个快照。它是通过Root Tracing得到的，作用是维持并发GC的正确性。 那么它是怎么维持并发GC的正确性的呢？根据三色标记算法，我们知道对象存在三种状态： * 白：对象没有被标记到，标记阶段结束后，会被当做垃圾回收掉。 * 灰：对象被标记了，但是它的field还没有被标记或标记完。 * 黑：对象被标记了，且它的所有field也被标记完了。\n\n由于并发阶段的存在，Mutator和Garbage Collector线程同时对对象进行修改，就会出现白对象漏标的情况，这种情况发生的前提是： * Mutator赋予一个黑对象该白对象的引用。 * Mutator删除了所有从灰对象到该白对象的直接或者间接引用。\n\n对于第一个条件，在并发标记阶段，如果该白对象是new出来的，并没有被灰对象持有，那么它会不会被漏标呢？Region中有两个top-at-mark-start（TAMS）指针，分别为prevTAMS和nextTAMS。在TAMS以上的对象是新分配的，这是一种隐式的标记。对于在GC时已经存在的白对象，如果它是活着的，它必然会被另一个对象引用，即条件二中的灰对象。如果灰对象到白对象的直接引用或者间接引用被替换了，或者删除了，白对象就会被漏标，从而导致被回收掉，这是非常严重的错误，所以SATB破坏了第二个条件。也就是说，一个对象的引用被替换时，可以通过write barrier 将旧引用记录下来。\n\n//  share/vm/gc_implementation/g1/g1SATBCardTableModRefBS.hpp\n// This notes that we don't need to access any BarrierSet data\n// structures, so this can be called from a static context.\ntemplate <class T> static void write_ref_field_pre_static(T* field, oop newVal) {\n  T heap_oop = oopDesc::load_heap_oop(field);\n  if (!oopDesc::is_null(heap_oop)) {\n    enqueue(oopDesc::decode_heap_oop(heap_oop));\n  }\n}\n// share/vm/gc_implementation/g1/g1SATBCardTableModRefBS.cpp\nvoid G1SATBCardTableModRefBS::enqueue(oop pre_val) {\n  // Nulls should have been already filtered.\n  assert(pre_val->is_oop(true), \"Error\");\n  if (!JavaThread::satb_mark_queue_set().is_active()) return;\n  Thread* thr = Thread::current();\n  if (thr->is_Java_thread()) {\n    JavaThread* jt = (JavaThread*)thr;\n    jt->satb_mark_queue().enqueue(pre_val);\n  } else {\n    MutexLockerEx x(Shared_SATB_Q_lock, Mutex::_no_safepoint_check_flag);\n    JavaThread::satb_mark_queue_set().shared_satb_queue()->enqueue(pre_val);\n  }\n}\nSATB也是有副作用的，如果被替换的白对象就是要被收集的垃圾，这次的标记会让它躲过GC，这就是float garbage。因为SATB的做法精度比较低，所以造成的float garbage也会比较多。\n\nRSet\n全称是Remembered Set，是辅助GC过程的一种结构，典型的空间换时间工具，和Card Table有些类似。还有一种数据结构也是辅助GC的：Collection Set（CSet），它记录了GC要收集的Region集合，集合里的Region可以是任意年代的。在GC的时候，对于old->young和old->old的跨代对象引用，只要扫描对应的CSet中的RSet即可。 逻辑上说每个Region都有一个RSet，RSet记录了其他Region中的对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）。而Card Table则是一种points-out（我引用了谁的对象）的结构，每个Card 覆盖一定范围的Heap（一般为512Bytes）。G1的RSet是在Card Table的基础上实现的：每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。 这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。\n\n下图表示了RSet、Card和Region的关系（出处）： Remembered Sets\nRemembered Sets\n\n上图中有三个Region，每个Region被分成了多个Card，在不同Region中的Card会相互引用，Region1中的Card中的对象引用了Region2中的Card中的对象，蓝色实线表示的就是points-out的关系，而在Region2的RSet中，记录了Region1的Card，即红色虚线表示的关系，这就是points-into。 而维系RSet中的引用关系靠post-write barrier和Concurrent refinement threads来维护，操作伪代码如下（出处）：\n\nvoid oop_field_store(oop* field, oop new_value) {\n  pre_write_barrier(field);             // pre-write barrier: for maintaining SATB invariant\n  *field = new_value;                   // the actual store\n  post_write_barrier(field, new_value); // post-write barrier: for tracking cross-region reference\n}\npost-write barrier记录了跨Region的引用更新，更新日志缓冲区则记录了那些包含更新引用的Cards。一旦缓冲区满了，Post-write barrier就停止服务了，会由Concurrent refinement threads处理这些缓冲区日志。 RSet究竟是怎么辅助GC的呢？在做YGC的时候，只需要选定young generation region的RSet作为根集，这些RSet记录了old->young的跨代引用，避免了扫描整个old generation。 而mixed gc的时候，old generation中记录了old->old的RSet，young->old的引用由扫描全部young generation region得到，这样也不用扫描全部old generation region。所以RSet的引入大大减少了GC的工作量。\n\nPause Prediction Model\nPause Prediction Model 即停顿预测模型。它在G1中的作用是： >G1 uses a pause prediction model to meet a user-defined pause time target and selects the number of regions to collect based on the specified pause time target.\n\nG1 GC是一个响应时间优先的GC算法，它与CMS最大的不同是，用户可以设定整个GC过程的期望停顿时间，参数-XX:MaxGCPauseMillis指定一个G1收集过程目标停顿时间，默认值200ms，不过它不是硬性条件，只是期望值。那么G1怎么满足用户的期望呢？就需要这个停顿预测模型了。G1根据这个模型统计计算出来的历史数据来预测本次收集需要选择的Region数量，从而尽量满足用户设定的目标停顿时间。 停顿预测模型是以衰减标准偏差为理论基础实现的：\n\n//  share/vm/gc_implementation/g1/g1CollectorPolicy.hpp\ndouble get_new_prediction(TruncatedSeq* seq) {\n    return MAX2(seq->davg() + sigma() * seq->dsd(),\n                seq->davg() * confidence_factor(seq->num()));\n}\n在这个预测计算公式中：davg表示衰减均值，sigma()返回一个系数，表示信赖度，dsd表示衰减标准偏差，confidence_factor表示可信度相关系数。而方法的参数TruncateSeq，顾名思义，是一个截断的序列，它只跟踪了序列中的最新的n个元素。\n\n在G1 GC过程中，每个可测量的步骤花费的时间都会记录到TruncateSeq（继承了AbsSeq）中，用来计算衰减均值、衰减变量，衰减标准偏差等：\n\n// src/share/vm/utilities/numberSeq.cpp\n\nvoid AbsSeq::add(double val) {\n  if (_num == 0) {\n    // if the sequence is empty, the davg is the same as the value\n    _davg = val;\n    // and the variance is 0\n    _dvariance = 0.0;\n  } else {\n    // otherwise, calculate both\n    _davg = (1.0 - _alpha) * val + _alpha * _davg;\n    double diff = val - _davg;\n    _dvariance = (1.0 - _alpha) * diff * diff + _alpha * _dvariance;\n  }\n}\n比如要预测一次GC过程中，RSet的更新时间，这个操作主要是将Dirty Card加入到RSet中，具体原理参考前面的RSet。每个Dirty Card的时间花费通过_cost_per_card_ms_seq来记录，具体预测代码如下：\n\n//  share/vm/gc_implementation/g1/g1CollectorPolicy.hpp\n\n double predict_rs_update_time_ms(size_t pending_cards) {\n    return (double) pending_cards * predict_cost_per_card_ms();\n }\n double predict_cost_per_card_ms() {\n    return get_new_prediction(_cost_per_card_ms_seq);\n }\nget_new_prediction就是我们开头说的方法，现在大家应该基本明白停顿预测模型的实现原理了。\n\nGC过程\n讲完了一些基本概念，下面我们就来看看G1的GC过程是怎样的。\n\nG1 GC模式\nG1提供了两种GC模式，Young GC和Mixed GC，两种都是完全Stop The World的。 * Young GC：选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC的时间开销。 * Mixed GC：选定所有年轻代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。\n\n由上面的描述可知，Mixed GC不是full GC，它只能回收部分老年代的Region，如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap。所以我们可以知道，G1是不提供full GC的。\n\n上文中，多次提到了global concurrent marking，它的执行过程类似CMS，但是不同的是，在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为四个步骤： * 初始标记（initial mark，STW）。它标记了从GC Root开始直接可达的对象。 * 并发标记（Concurrent Marking）。这个阶段从GC Root开始对heap中的对象标记，标记线程与应用程序线程并行执行，并且收集各个Region的存活对象信息。 * 最终标记（Remark，STW）。标记那些在并发标记阶段发生变化的对象，将被回收。 * 清除垃圾（Cleanup）。清除空Region（没有存活对象的），加入到free list。\n\n第一阶段initial mark是共用了Young GC的暂停，这是因为他们可以复用root scan操作，所以可以说global concurrent marking是伴随Young GC而发生的。第四阶段Cleanup只是回收了没有存活对象的Region，所以它并不需要STW。\n\nYoung GC发生的时机大家都知道，那什么时候发生Mixed GC呢？其实是由一些参数控制着的，另外也控制着哪些老年代Region会被选入CSet。 * G1HeapWastePercent：在global concurrent marking结束之后，我们可以知道old gen regions中有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到此参数，只有达到了，下次才会发生Mixed GC。 * G1MixedGCLiveThresholdPercent：old generation region中的存活对象的占比，只有在此参数之下，才会被选入CSet。 * G1MixedGCCountTarget：一次global concurrent marking之后，最多执行Mixed GC的次数。 * G1OldCSetRegionThresholdPercent：一次Mixed GC中能被选入CSet的最多old generation region数量。\n\n除了以上的参数，G1 GC相关的其他主要的参数有：\n\n参数\t含义\n-XX:G1HeapRegionSize=n\t设置Region大小，并非最终值\n-XX:MaxGCPauseMillis\t设置G1收集过程目标时间，默认值200ms，不是硬性条件\n-XX:G1NewSizePercent\t新生代最小值，默认值5%\n-XX:G1MaxNewSizePercent\t新生代最大值，默认值60%\n-XX:ParallelGCThreads\tSTW期间，并行GC线程数\n-XX:ConcGCThreads=n\t并发标记阶段，并行执行的线程数\n-XX:InitiatingHeapOccupancyPercent\t设置触发标记周期的 Java 堆占用率阈值。默认值是45%。这里的java堆占比指的是non_young_capacity_bytes，包括old+humongous\nGC日志\nG1收集器的日志与其他收集器有很大不同，源于G1独立的体系架构和数据结构，下面这两段日志来源于美团点评的CRM系统线上生产环境。\n\nYoung GC日志\n我们先来看看Young GC的日志：\n\n{Heap before GC invocations=12 (full 1):\n garbage-first heap   total 3145728K, used 336645K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000)\n  region size 1024K, 172 young (176128K), 13 survivors (13312K)\n Metaspace       used 29944K, capacity 30196K, committed 30464K, reserved 1077248K\n  class space    used 3391K, capacity 3480K, committed 3584K, reserved 1048576K\n2014-11-14T17:57:23.654+0800: 27.884: [GC pause (G1 Evacuation Pause) (young)\nDesired survivor size 11534336 bytes, new threshold 15 (max 15)\n- age   1:    5011600 bytes,    5011600 total\n 27.884: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 1461, predicted base time: 35.25 ms, remaining time: 64.75 ms, target pause time: 100.00 ms]\n 27.884: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 159 regions, survivors: 13 regions, predicted young region time: 44.09 ms]\n 27.884: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 159 regions, survivors: 13 regions, old: 0 regions, predicted pause time: 79.34 ms, target pause time: 100.00 ms]\n, 0.0158389 secs]\n   [Parallel Time: 8.1 ms, GC Workers: 4]\n      [GC Worker Start (ms): Min: 27884.5, Avg: 27884.5, Max: 27884.5, Diff: 0.1]\n      [Ext Root Scanning (ms): Min: 0.4, Avg: 0.8, Max: 1.2, Diff: 0.8, Sum: 3.1]\n      [Update RS (ms): Min: 0.0, Avg: 0.3, Max: 0.6, Diff: 0.6, Sum: 1.4]\n         [Processed Buffers: Min: 0, Avg: 2.8, Max: 5, Diff: 5, Sum: 11]\n      [Scan RS (ms): Min: 0.0, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 0.3]\n      [Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.6]\n      [Object Copy (ms): Min: 4.9, Avg: 5.1, Max: 5.2, Diff: 0.3, Sum: 20.4]\n      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n      [GC Worker Other (ms): Min: 0.0, Avg: 0.4, Max: 1.3, Diff: 1.3, Sum: 1.4]\n      [GC Worker Total (ms): Min: 6.4, Avg: 6.8, Max: 7.8, Diff: 1.4, Sum: 27.2]\n      [GC Worker End (ms): Min: 27891.0, Avg: 27891.3, Max: 27892.3, Diff: 1.3]\n   [Code Root Fixup: 0.5 ms]\n   [Code Root Migration: 1.3 ms]\n   [Code Root Purge: 0.0 ms]\n   [Clear CT: 0.2 ms]\n   [Other: 5.8 ms]\n      [Choose CSet: 0.0 ms]\n      [Ref Proc: 5.0 ms]\n      [Ref Enq: 0.1 ms]\n      [Redirty Cards: 0.0 ms]\n      [Free CSet: 0.2 ms]\n   [Eden: 159.0M(159.0M)->0.0B(301.0M) Survivors: 13.0M->11.0M Heap: 328.8M(3072.0M)->167.3M(3072.0M)]\nHeap after GC invocations=13 (full 1):\n garbage-first heap   total 3145728K, used 171269K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000)\n  region size 1024K, 11 young (11264K), 11 survivors (11264K)\n Metaspace       used 29944K, capacity 30196K, committed 30464K, reserved 1077248K\n  class space    used 3391K, capacity 3480K, committed 3584K, reserved 1048576K\n}\n [Times: user=0.05 sys=0.01, real=0.02 secs]\n每个过程的作用如下：\n\n* garbage-first heap total 3145728K, used 336645K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000) 这行表示使用了G1垃圾收集器，total heap 3145728K，使用了336645K。\n\n* region size 1024K, 172 young (176128K), 13 survivors (13312K) Region大小为1M，青年代占用了172个（共176128K），幸存区占用了13个（共13312K）。\n\n* Metaspace used 29944K, capacity 30196K, committed 30464K, reserved 1077248K class space used 3391K, capacity 3480K, committed 3584K, reserved 1048576K java 8的新特性，去掉永久区，添加了元数据区，这块不是本文重点，不再赘述。需要注意的是，之所以有committed和reserved，是因为没有设置MetaspaceSize=MaxMetaspaceSize。 * [GC pause (G1 Evacuation Pause) (young) GC原因，新生代minor GC。\n\n* [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 1461, predicted base time: 35.25 ms, remaining time: 64.75 ms, target pause time: 100.00 ms] 发生minor GC和full GC时，所有相关region都是要回收的。而发生并发GC时，会根据目标停顿时间动态选择部分垃圾对并多的Region回收，这一步就是选择Region。_pending_cards是关于RSet的Card Table。predicted base time是预测的扫描card table时间。\n\n* [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 159 regions, survivors: 13 regions, predicted young region time: 44.09 ms] 这一步是添加Region到collection set，新生代一共159个Region，13个幸存区Region，这也和之前的（172 young (176128K), 13 survivors (13312K)）吻合。预计收集时间是44.09 ms。\n\n* [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 159 regions, survivors: 13 regions, old: 0 regions, predicted pause time: 79.34 ms, target pause time: 100.00 ms] 这一步是对上面两步的总结。预计总收集时间79.34ms。 * [Parallel Time: 8.1 ms, GC Workers: 4] 由于收集过程是多线程并行（并发）进行，这里是4个线程，总共耗时8.1ms（wall clock time）\n\n* [GC Worker Start (ms): Min: 27884.5, Avg: 27884.5, Max: 27884.5, Diff: 0.1] 收集线程开始的时间，使用的是相对时间，Min是最早开始时间，Avg是平均开始时间，Max是最晚开始时间，Diff是Max-Min（此处的0.1貌似有问题）\n\n* [Ext Root Scanning (ms): Min: 0.4, Avg: 0.8, Max: 1.2, Diff: 0.8, Sum: 3.1] 扫描Roots花费的时间，Sum表示total cpu time，下同。\n\n* [Update RS (ms): Min: 0.0, Avg: 0.3, Max: 0.6, Diff: 0.6, Sum: 1.4] [Processed Buffers: Min: 0, Avg: 2.8, Max: 5, Diff: 5, Sum: 11] Update RS (ms)是每个线程花费在更新Remembered Set上的时间。\n\n* [Scan RS (ms): Min: 0.0, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 0.3] 扫描CS中的region对应的RSet，因为RSet是points-into，所以这样实现避免了扫描old generadion region，但是会产生float garbage。\n\n* [Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.6] 扫描code root耗时。code root指的是经过JIT编译后的代码里，引用了heap中的对象。引用关系保存在RSet中。\n\n* [Object Copy (ms): Min: 4.9, Avg: 5.1, Max: 5.2, Diff: 0.3, Sum: 20.4] 拷贝活的对象到新region的耗时。\n\n* [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] 线程结束，在结束前，它会检查其他线程是否还有未扫描完的引用，如果有，则”偷”过来，完成后再申请结束，这个时间是线程之前互相同步所花费的时间。\n\n* [GC Worker Other (ms): Min: 0.0, Avg: 0.4, Max: 1.3, Diff: 1.3, Sum: 1.4] 花费在其他工作上（未列出）的时间。\n\n* [GC Worker Total (ms): Min: 6.4, Avg: 6.8, Max: 7.8, Diff: 1.4, Sum: 27.2] 每个线程花费的时间和。\n\n* [GC Worker End (ms): Min: 27891.0, Avg: 27891.3, Max: 27892.3, Diff: 1.3] 每个线程结束的时间。\n\n* [Code Root Fixup: 0.5 ms] 用来将code root修正到正确的evacuate之后的对象位置所花费的时间。\n\n* [Code Root Migration: 1.3 ms] 更新code root 引用的耗时，code root中的引用因为对象的evacuation而需要更新。\n\n* [Code Root Purge: 0.0 ms] 清除code root的耗时，code root中的引用已经失效，不再指向Region中的对象，所以需要被清除。\n\n* [Clear CT: 0.2 ms] 清除card table的耗时。\n\n* [Other: 5.8 ms] [Choose CSet: 0.0 ms] [Ref Proc: 5.0 ms] [Ref Enq: 0.1 ms] [Redirty Cards: 0.0 ms] [Free CSet: 0.2 ms] 其他事项共耗时5.8ms，其他事项包括选择CSet，处理已用对象，引用入ReferenceQueues，释放CSet中的region到free list。\n\n* [Eden: 159.0M(159.0M)->0.0B(301.0M) Survivors: 13.0M->11.0M Heap: 328.8M(3072.0M)->167.3M(3072.0M)] 新生代清空了，下次扩容到301MB。\n\nglobal concurrent marking 日志\n对于global concurrent marking过程，它的日志如下所示：\n\n66955.252: [G1Ergonomics (Concurrent Cycles) request concurrent cycle initiation, reason: occupancy higher than threshold, occupancy: 1449132032 bytes, allocation request: 579608 bytes, threshold: 1449\n551430 bytes (45.00 %), source: concurrent humongous allocation]\n2014-12-10T11:13:09.532+0800: 66955.252: Application time: 2.5750418 seconds\n 66955.259: [G1Ergonomics (Concurrent Cycles) request concurrent cycle initiation, reason: requested by GC cause, GC cause: G1 Humongous Allocation]\n{Heap before GC invocations=1874 (full 4):\n garbage-first heap   total 3145728K, used 1281786K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000)\n  region size 1024K, 171 young (175104K), 27 survivors (27648K)\n Metaspace       used 116681K, capacity 137645K, committed 137984K, reserved 1171456K\n  class space    used 13082K, capacity 16290K, committed 16384K, reserved 1048576K\n 66955.259: [G1Ergonomics (Concurrent Cycles) initiate concurrent cycle, reason: concurrent cycle initiation requested]\n2014-12-10T11:13:09.539+0800: 66955.259: [GC pause (G1 Humongous Allocation) (young) (initial-mark)\n…….\n2014-12-10T11:13:09.597+0800: 66955.317: [GC concurrent-root-region-scan-start]\n2014-12-10T11:13:09.597+0800: 66955.318: Total time for which application threads were stopped: 0.0655753 seconds\n2014-12-10T11:13:09.610+0800: 66955.330: Application time: 0.0127071 seconds\n2014-12-10T11:13:09.614+0800: 66955.335: Total time for which application threads were stopped: 0.0043882 seconds\n2014-12-10T11:13:09.625+0800: 66955.346: [GC concurrent-root-region-scan-end, 0.0281351 secs]\n2014-12-10T11:13:09.625+0800: 66955.346: [GC concurrent-mark-start]\n2014-12-10T11:13:09.645+0800: 66955.365: Application time: 0.0306801 seconds\n2014-12-10T11:13:09.651+0800: 66955.371: Total time for which application threads were stopped: 0.0061326 seconds\n2014-12-10T11:13:10.212+0800: 66955.933: [GC concurrent-mark-end, 0.5871129 secs]\n2014-12-10T11:13:10.212+0800: 66955.933: Application time: 0.5613792 seconds\n2014-12-10T11:13:10.215+0800: 66955.935: [GC remark 66955.936: [GC ref-proc, 0.0235275 secs], 0.0320865 secs]\n [Times: user=0.05 sys=0.00, real=0.03 secs]\n2014-12-10T11:13:10.247+0800: 66955.968: Total time for which application threads were stopped: 0.0350098 seconds\n2014-12-10T11:13:10.248+0800: 66955.968: Application time: 0.0001691 seconds\n2014-12-10T11:13:10.250+0800: 66955.970: [GC cleanup 1178M->632M(3072M), 0.0060632 secs]\n [Times: user=0.02 sys=0.00, real=0.01 secs]\n2014-12-10T11:13:10.256+0800: 66955.977: Total time for which application threads were stopped: 0.0088462 seconds\n2014-12-10T11:13:10.257+0800: 66955.977: [GC concurrent-cleanup-start]\n2014-12-10T11:13:10.259+0800: 66955.979: [GC concurrent-cleanup-end, 0.0024743 secs\n这次发生global concurrent marking的原因是：humongous allocation，上面提过在巨大对象分配之前，会检测到old generation 使用占比是否超过了 initiating heap occupancy percent（45%），因为 1449132032(used)+ 579608(allocation request:) > 1449551430(threshold)，所以触发了本次global concurrent marking。对于具体执行过程，上面的表格已经详细讲解了。值得注意的是上文中所说的initial mark往往伴随着一次YGC，在日志中也有体现：GC pause (G1 Humongous Allocation) (young) (initial-mark)。\n\n后记\n因为篇幅的关系，也受限于能力水平，本文只是简单了介绍了G1 GC的基本原理，很多细节没有涉及到，所以说只能算是为研究和使用它的同学打开了一扇门。一个日本人专门写了一本书《徹底解剖「G1GC」 アルゴリズ》详细的介绍了G1 GC，这本书也被作者放到了GitHub上，详见参考文献5。另外，莫枢在这方面也研究的比较多，读者可以去高级语言虚拟机论坛向他请教，本文的很多内容也是我在此论坛上请教过后整理的。总而言之，G1是一款非常优秀的垃圾收集器，尽管还有些不完美（预测模型还不够智能），但是希望有更多的同学来使用它，研究它，提出好的建议，让它变的更加完善。\n\n参考文献\nGetting Started with the G1 Garbage Collector\n请教G1算法的原理\n关于incremental update与SATB的一点理解\nTips for Tuning the Garbage First Garbage Collector\ng1gc-impl-book\n垃圾优先型垃圾回收器调优\nUnderstanding G1 GC Logs\nG1: One Garbage Collector To Rule Them All\n系统, 到店, Hotspot, JVM, G1, GC, Java\n#看看其他前一篇: 美团数据库运维自动化系统构建之路 后一篇: 大促活动前团购系统流量预算和容量评估\n#一起聊聊\n如发现文章有错误、对内容有疑问，都可以关注美团技术团队微信公众号（meituantech），在后台给我们留言。\n\n美团技术团队微信二维码\n我们每周会挑选出一位热心小伙伴，送上一份精美的小礼品。快来扫码关注我们吧！\n\n一行代码，亿万生活。\n\n网站首页\n文章存档\n关于我们\n","source":"_posts/JVM-GC-G1.md","raw":"---\ntitle: JVM-G1\ndate: 2018-10-12 10:06:33\ntags: JVM\n---\n\nhttps://www.oracle.com/technetwork/java/javase/tech/g1-intro-jsp-135488.html\n先翻译一遍\n\n### 美团技术文章写得好\nhttps://tech.meituan.com/g1.html\n\n### 这篇文章好像写得也不错\nhttps://www.cnblogs.com/yunxitalk/p/8987318.html\n\n### redhat里面的图看上去不错\nhttps://www.redhat.com/en/blog/part-1-introduction-g1-garbage-collector\nhttps://www.redhat.com/en/blog/collecting-and-reading-g1-garbage-collector-logs-part-2\n\n### R大不是盖的啊\nhttps://hllvm-group.iteye.com/group/topic/44381\n\n### 杜兄的文章写得很不错\nhttps://www.jianshu.com/p/a3e6a9de7a5d\n\n### Amazon 神PPT，写得很详细\nhttp://presentations2015.s3.amazonaws.com/40_presentation.pdf\n\n### younggc\n#### First phase: “Root Scanning”\n需要STW，从GC root开始扫描存活对象\nStatic and local objects are scanned\n\n#### Second phase: “Update RS”\n在上一轮中，有很多对象修改了引用，被load barrier放入了dirty card queue，需要把这部分的数据拿出来，更新Rset\nDrains the dirty card queue to update the RS\n\n#### Third phase: “Process RS”\n从GC Root的扫描无法彻底让Region和Region独立工作，需要借助于RSet，从RSet找到从Old区指向当前Region的区域（CardTable）\nDetect the Eden objects pointed by Old objects\n\n#### Fourth phase: “Object Copy”\nThe object graph is traversed\nLive objects copied to Survivor/Old regions\n\n#### Fifth phase: “Reference Processing”\nSoft, Weak, Phantom, Final, JNI Weak references\nAlways enable -XX:+ParallelRefProcEnabled\nMore details with -XX:+PrintReferenceGC\n\n### infoQ\nhttps://www.infoq.com/articles/tuning-tips-G1-GC\n\n\n// VM_operations for the G1 collector.\n// VM_GC_Operation:\n//   - VM_CGC_Operation\n//   - VM_G1CollectFull\n//   - VM_G1OperationWithAllocRequest\n//     - VM_G1CollectForAllocation\n//     - VM_G1IncCollectionPause\n\n\nhttps://zhuanlan.zhihu.com/p/22591838\n\n\n### 重要信息\nG1GC没有提供专门的FullGC，还是使用传统FullGC来对整个堆的垃圾进行收集。\n\n### Young GC的时间预测调用栈\nG1DefaultPolicy::predict_base_elapsed_time_ms g1DefaultPolicy.cpp:829\nG1DefaultPolicy::predict_base_elapsed_time_ms g1DefaultPolicy.cpp:837\nG1CollectionSet::finalize_young_part g1CollectionSet.cpp:363\nG1DefaultPolicy::finalize_collection_set g1DefaultPolicy.cpp:1137\nG1CollectedHeap::do_collection_pause_at_safepoint g1CollectedHeap.cpp:3162\nVM_G1IncCollectionPause::doit vm_operations_g1.cpp:148\nVM_Operation::evaluate vm_operations.cpp:66\nVMThread::evaluate_operation vmThread.cpp:348\nVMThread::loop vmThread.cpp:470\nVMThread::run vmThread.cpp:262\nthread_native_entry os_bsd.cpp:720\n_pthread_body 0x00007fff74974339\n_pthread_start 0x00007fff749772a7\nthread_start 0x00007fff74973445\n<unknown> 0x0000000000000000\n\n\n\n####        美团文章            ##########\nJava Hotspot G1 GC的一些关键技术\n2016年09月23日 作者: 小亮 文章链接 18946字 38分钟阅读\n前言\nG1 GC，全称Garbage-First Garbage Collector，通过-XX:+UseG1GC参数来启用，作为体验版随着JDK 6u14版本面世，在JDK 7u4版本发行时被正式推出，相信熟悉JVM的同学们都不会对它感到陌生。在JDK 9中，G1被提议设置为默认垃圾收集器（JEP 248）。在官网中，是这样描述G1的： > The Garbage-First (G1) collector is a server-style garbage collector, targeted for multi-processor machines with large memories. It meets garbage collection (GC) pause time goals with a high probability, while achieving high throughput. The G1 garbage collector is fully supported in Oracle JDK 7 update 4 and later releases. The G1 collector is designed for applications that: > * Can operate concurrently with applications threads like the CMS collector. > * Compact free space without lengthy GC induced pause times. > * Need more predictable GC pause durations. > * Do not want to sacrifice a lot of throughput performance. > * Do not require a much larger Java heap.\n\n从官网的描述中，我们知道G1是一种服务器端的垃圾收集器，应用在多处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集暂停时间的要求。它是专门针对以下应用场景设计的: * 像CMS收集器一样，能与应用程序线程并发执行。 * 整理空闲空间更快。 * 需要GC停顿时间更好预测。 * 不希望牺牲大量的吞吐性能。 * 不需要更大的Java Heap。\n\nG1收集器的设计目标是取代CMS收集器，它同CMS相比，在以下方面表现的更出色： * G1是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片。 * G1的Stop The World(STW)更可控，G1在停顿时间上添加了预测机制，用户可以指定期望停顿时间。\n\n有了以上的特性，难怪有人说它是一款驾驭一切的垃圾收集器（G1: One Garbage Collector To Rule Them All）。本文带大家来了解一下G1 GC的一些关键技术，为能正确的使用它，做好理论基础的铺垫。\n\nG1中几个重要概念\n在G1的实现过程中，引入了一些新的概念，对于实现高吞吐、没有内存碎片、收集时间可控等功能起到了关键作用。下面我们就一起看一下G1中的这几个重要概念。\n\nRegion\n传统的GC收集器将连续的内存空间划分为新生代、老年代和永久代（JDK 8去除了永久代，引入了元空间Metaspace），这种划分的特点是各代的存储地址（逻辑地址，下同）是连续的。如下图所示： 传统GC内存布局\n传统GC内存布局\n\n而G1的各代存储地址是不连续的，每一代都使用了n个不连续的大小相同的Region，每个Region占有一块连续的虚拟内存地址。如下图所示： g1 GC内存布局\ng1 GC内存布局\n\n在上图中，我们注意到还有一些Region标明了H，它代表Humongous，这表示这些Region存储的是巨大对象（humongous object，H-obj），即大小大于等于region一半的对象。H-obj有如下几个特征： * H-obj直接分配到了old gen，防止了反复拷贝移动。 * H-obj在global concurrent marking阶段的cleanup 和 full GC阶段回收。 * 在分配H-obj之前先检查是否超过 initiating heap occupancy percent和the marking threshold, 如果超过的话，就启动global concurrent marking，为的是提早回收，防止 evacuation failures 和 full GC。\n\n为了减少连续H-objs分配对GC的影响，需要把大对象变为普通的对象，建议增大Region size。\n\n一个Region的大小可以通过参数-XX:G1HeapRegionSize设定，取值范围从1M到32M，且是2的指数。如果不设定，那么G1会根据Heap大小自动决定。相关的设置代码如下：\n\n// share/vm/gc_implementation/g1/heapRegion.cpp\n// Minimum region size; we won't go lower than that.\n// We might want to decrease this in the future, to deal with small\n// heaps a bit more efficiently.\n#define MIN_REGION_SIZE  (      1024 * 1024 )\n// Maximum region size; we don't go higher than that. There's a good\n// reason for having an upper bound. We don't want regions to get too\n// large, otherwise cleanup's effectiveness would decrease as there\n// will be fewer opportunities to find totally empty regions after\n// marking.\n#define MAX_REGION_SIZE  ( 32 * 1024 * 1024 )\n// The automatic region size calculation will try to have around this\n// many regions in the heap (based on the min heap size).\n#define TARGET_REGION_NUMBER          2048\nvoid HeapRegion::setup_heap_region_size(size_t initial_heap_size, size_t max_heap_size) {\n  uintx region_size = G1HeapRegionSize;\n  if (FLAG_IS_DEFAULT(G1HeapRegionSize)) {\n    size_t average_heap_size = (initial_heap_size + max_heap_size) / 2;\n    region_size = MAX2(average_heap_size / TARGET_REGION_NUMBER,\n                       (uintx) MIN_REGION_SIZE);\n  }\n  int region_size_log = log2_long((jlong) region_size);\n  // Recalculate the region size to make sure it's a power of\n  // 2. This means that region_size is the largest power of 2 that's\n  // <= what we've calculated so far.\n  region_size = ((uintx)1 << region_size_log);\n  // Now make sure that we don't go over or under our limits.\n  if (region_size < MIN_REGION_SIZE) {\n    region_size = MIN_REGION_SIZE;\n  } else if (region_size > MAX_REGION_SIZE) {\n    region_size = MAX_REGION_SIZE;\n  }\n}\nSATB\n全称是Snapshot-At-The-Beginning，由字面理解，是GC开始时活着的对象的一个快照。它是通过Root Tracing得到的，作用是维持并发GC的正确性。 那么它是怎么维持并发GC的正确性的呢？根据三色标记算法，我们知道对象存在三种状态： * 白：对象没有被标记到，标记阶段结束后，会被当做垃圾回收掉。 * 灰：对象被标记了，但是它的field还没有被标记或标记完。 * 黑：对象被标记了，且它的所有field也被标记完了。\n\n由于并发阶段的存在，Mutator和Garbage Collector线程同时对对象进行修改，就会出现白对象漏标的情况，这种情况发生的前提是： * Mutator赋予一个黑对象该白对象的引用。 * Mutator删除了所有从灰对象到该白对象的直接或者间接引用。\n\n对于第一个条件，在并发标记阶段，如果该白对象是new出来的，并没有被灰对象持有，那么它会不会被漏标呢？Region中有两个top-at-mark-start（TAMS）指针，分别为prevTAMS和nextTAMS。在TAMS以上的对象是新分配的，这是一种隐式的标记。对于在GC时已经存在的白对象，如果它是活着的，它必然会被另一个对象引用，即条件二中的灰对象。如果灰对象到白对象的直接引用或者间接引用被替换了，或者删除了，白对象就会被漏标，从而导致被回收掉，这是非常严重的错误，所以SATB破坏了第二个条件。也就是说，一个对象的引用被替换时，可以通过write barrier 将旧引用记录下来。\n\n//  share/vm/gc_implementation/g1/g1SATBCardTableModRefBS.hpp\n// This notes that we don't need to access any BarrierSet data\n// structures, so this can be called from a static context.\ntemplate <class T> static void write_ref_field_pre_static(T* field, oop newVal) {\n  T heap_oop = oopDesc::load_heap_oop(field);\n  if (!oopDesc::is_null(heap_oop)) {\n    enqueue(oopDesc::decode_heap_oop(heap_oop));\n  }\n}\n// share/vm/gc_implementation/g1/g1SATBCardTableModRefBS.cpp\nvoid G1SATBCardTableModRefBS::enqueue(oop pre_val) {\n  // Nulls should have been already filtered.\n  assert(pre_val->is_oop(true), \"Error\");\n  if (!JavaThread::satb_mark_queue_set().is_active()) return;\n  Thread* thr = Thread::current();\n  if (thr->is_Java_thread()) {\n    JavaThread* jt = (JavaThread*)thr;\n    jt->satb_mark_queue().enqueue(pre_val);\n  } else {\n    MutexLockerEx x(Shared_SATB_Q_lock, Mutex::_no_safepoint_check_flag);\n    JavaThread::satb_mark_queue_set().shared_satb_queue()->enqueue(pre_val);\n  }\n}\nSATB也是有副作用的，如果被替换的白对象就是要被收集的垃圾，这次的标记会让它躲过GC，这就是float garbage。因为SATB的做法精度比较低，所以造成的float garbage也会比较多。\n\nRSet\n全称是Remembered Set，是辅助GC过程的一种结构，典型的空间换时间工具，和Card Table有些类似。还有一种数据结构也是辅助GC的：Collection Set（CSet），它记录了GC要收集的Region集合，集合里的Region可以是任意年代的。在GC的时候，对于old->young和old->old的跨代对象引用，只要扫描对应的CSet中的RSet即可。 逻辑上说每个Region都有一个RSet，RSet记录了其他Region中的对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）。而Card Table则是一种points-out（我引用了谁的对象）的结构，每个Card 覆盖一定范围的Heap（一般为512Bytes）。G1的RSet是在Card Table的基础上实现的：每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。 这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。\n\n下图表示了RSet、Card和Region的关系（出处）： Remembered Sets\nRemembered Sets\n\n上图中有三个Region，每个Region被分成了多个Card，在不同Region中的Card会相互引用，Region1中的Card中的对象引用了Region2中的Card中的对象，蓝色实线表示的就是points-out的关系，而在Region2的RSet中，记录了Region1的Card，即红色虚线表示的关系，这就是points-into。 而维系RSet中的引用关系靠post-write barrier和Concurrent refinement threads来维护，操作伪代码如下（出处）：\n\nvoid oop_field_store(oop* field, oop new_value) {\n  pre_write_barrier(field);             // pre-write barrier: for maintaining SATB invariant\n  *field = new_value;                   // the actual store\n  post_write_barrier(field, new_value); // post-write barrier: for tracking cross-region reference\n}\npost-write barrier记录了跨Region的引用更新，更新日志缓冲区则记录了那些包含更新引用的Cards。一旦缓冲区满了，Post-write barrier就停止服务了，会由Concurrent refinement threads处理这些缓冲区日志。 RSet究竟是怎么辅助GC的呢？在做YGC的时候，只需要选定young generation region的RSet作为根集，这些RSet记录了old->young的跨代引用，避免了扫描整个old generation。 而mixed gc的时候，old generation中记录了old->old的RSet，young->old的引用由扫描全部young generation region得到，这样也不用扫描全部old generation region。所以RSet的引入大大减少了GC的工作量。\n\nPause Prediction Model\nPause Prediction Model 即停顿预测模型。它在G1中的作用是： >G1 uses a pause prediction model to meet a user-defined pause time target and selects the number of regions to collect based on the specified pause time target.\n\nG1 GC是一个响应时间优先的GC算法，它与CMS最大的不同是，用户可以设定整个GC过程的期望停顿时间，参数-XX:MaxGCPauseMillis指定一个G1收集过程目标停顿时间，默认值200ms，不过它不是硬性条件，只是期望值。那么G1怎么满足用户的期望呢？就需要这个停顿预测模型了。G1根据这个模型统计计算出来的历史数据来预测本次收集需要选择的Region数量，从而尽量满足用户设定的目标停顿时间。 停顿预测模型是以衰减标准偏差为理论基础实现的：\n\n//  share/vm/gc_implementation/g1/g1CollectorPolicy.hpp\ndouble get_new_prediction(TruncatedSeq* seq) {\n    return MAX2(seq->davg() + sigma() * seq->dsd(),\n                seq->davg() * confidence_factor(seq->num()));\n}\n在这个预测计算公式中：davg表示衰减均值，sigma()返回一个系数，表示信赖度，dsd表示衰减标准偏差，confidence_factor表示可信度相关系数。而方法的参数TruncateSeq，顾名思义，是一个截断的序列，它只跟踪了序列中的最新的n个元素。\n\n在G1 GC过程中，每个可测量的步骤花费的时间都会记录到TruncateSeq（继承了AbsSeq）中，用来计算衰减均值、衰减变量，衰减标准偏差等：\n\n// src/share/vm/utilities/numberSeq.cpp\n\nvoid AbsSeq::add(double val) {\n  if (_num == 0) {\n    // if the sequence is empty, the davg is the same as the value\n    _davg = val;\n    // and the variance is 0\n    _dvariance = 0.0;\n  } else {\n    // otherwise, calculate both\n    _davg = (1.0 - _alpha) * val + _alpha * _davg;\n    double diff = val - _davg;\n    _dvariance = (1.0 - _alpha) * diff * diff + _alpha * _dvariance;\n  }\n}\n比如要预测一次GC过程中，RSet的更新时间，这个操作主要是将Dirty Card加入到RSet中，具体原理参考前面的RSet。每个Dirty Card的时间花费通过_cost_per_card_ms_seq来记录，具体预测代码如下：\n\n//  share/vm/gc_implementation/g1/g1CollectorPolicy.hpp\n\n double predict_rs_update_time_ms(size_t pending_cards) {\n    return (double) pending_cards * predict_cost_per_card_ms();\n }\n double predict_cost_per_card_ms() {\n    return get_new_prediction(_cost_per_card_ms_seq);\n }\nget_new_prediction就是我们开头说的方法，现在大家应该基本明白停顿预测模型的实现原理了。\n\nGC过程\n讲完了一些基本概念，下面我们就来看看G1的GC过程是怎样的。\n\nG1 GC模式\nG1提供了两种GC模式，Young GC和Mixed GC，两种都是完全Stop The World的。 * Young GC：选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC的时间开销。 * Mixed GC：选定所有年轻代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。\n\n由上面的描述可知，Mixed GC不是full GC，它只能回收部分老年代的Region，如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap。所以我们可以知道，G1是不提供full GC的。\n\n上文中，多次提到了global concurrent marking，它的执行过程类似CMS，但是不同的是，在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为四个步骤： * 初始标记（initial mark，STW）。它标记了从GC Root开始直接可达的对象。 * 并发标记（Concurrent Marking）。这个阶段从GC Root开始对heap中的对象标记，标记线程与应用程序线程并行执行，并且收集各个Region的存活对象信息。 * 最终标记（Remark，STW）。标记那些在并发标记阶段发生变化的对象，将被回收。 * 清除垃圾（Cleanup）。清除空Region（没有存活对象的），加入到free list。\n\n第一阶段initial mark是共用了Young GC的暂停，这是因为他们可以复用root scan操作，所以可以说global concurrent marking是伴随Young GC而发生的。第四阶段Cleanup只是回收了没有存活对象的Region，所以它并不需要STW。\n\nYoung GC发生的时机大家都知道，那什么时候发生Mixed GC呢？其实是由一些参数控制着的，另外也控制着哪些老年代Region会被选入CSet。 * G1HeapWastePercent：在global concurrent marking结束之后，我们可以知道old gen regions中有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到此参数，只有达到了，下次才会发生Mixed GC。 * G1MixedGCLiveThresholdPercent：old generation region中的存活对象的占比，只有在此参数之下，才会被选入CSet。 * G1MixedGCCountTarget：一次global concurrent marking之后，最多执行Mixed GC的次数。 * G1OldCSetRegionThresholdPercent：一次Mixed GC中能被选入CSet的最多old generation region数量。\n\n除了以上的参数，G1 GC相关的其他主要的参数有：\n\n参数\t含义\n-XX:G1HeapRegionSize=n\t设置Region大小，并非最终值\n-XX:MaxGCPauseMillis\t设置G1收集过程目标时间，默认值200ms，不是硬性条件\n-XX:G1NewSizePercent\t新生代最小值，默认值5%\n-XX:G1MaxNewSizePercent\t新生代最大值，默认值60%\n-XX:ParallelGCThreads\tSTW期间，并行GC线程数\n-XX:ConcGCThreads=n\t并发标记阶段，并行执行的线程数\n-XX:InitiatingHeapOccupancyPercent\t设置触发标记周期的 Java 堆占用率阈值。默认值是45%。这里的java堆占比指的是non_young_capacity_bytes，包括old+humongous\nGC日志\nG1收集器的日志与其他收集器有很大不同，源于G1独立的体系架构和数据结构，下面这两段日志来源于美团点评的CRM系统线上生产环境。\n\nYoung GC日志\n我们先来看看Young GC的日志：\n\n{Heap before GC invocations=12 (full 1):\n garbage-first heap   total 3145728K, used 336645K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000)\n  region size 1024K, 172 young (176128K), 13 survivors (13312K)\n Metaspace       used 29944K, capacity 30196K, committed 30464K, reserved 1077248K\n  class space    used 3391K, capacity 3480K, committed 3584K, reserved 1048576K\n2014-11-14T17:57:23.654+0800: 27.884: [GC pause (G1 Evacuation Pause) (young)\nDesired survivor size 11534336 bytes, new threshold 15 (max 15)\n- age   1:    5011600 bytes,    5011600 total\n 27.884: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 1461, predicted base time: 35.25 ms, remaining time: 64.75 ms, target pause time: 100.00 ms]\n 27.884: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 159 regions, survivors: 13 regions, predicted young region time: 44.09 ms]\n 27.884: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 159 regions, survivors: 13 regions, old: 0 regions, predicted pause time: 79.34 ms, target pause time: 100.00 ms]\n, 0.0158389 secs]\n   [Parallel Time: 8.1 ms, GC Workers: 4]\n      [GC Worker Start (ms): Min: 27884.5, Avg: 27884.5, Max: 27884.5, Diff: 0.1]\n      [Ext Root Scanning (ms): Min: 0.4, Avg: 0.8, Max: 1.2, Diff: 0.8, Sum: 3.1]\n      [Update RS (ms): Min: 0.0, Avg: 0.3, Max: 0.6, Diff: 0.6, Sum: 1.4]\n         [Processed Buffers: Min: 0, Avg: 2.8, Max: 5, Diff: 5, Sum: 11]\n      [Scan RS (ms): Min: 0.0, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 0.3]\n      [Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.6]\n      [Object Copy (ms): Min: 4.9, Avg: 5.1, Max: 5.2, Diff: 0.3, Sum: 20.4]\n      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n      [GC Worker Other (ms): Min: 0.0, Avg: 0.4, Max: 1.3, Diff: 1.3, Sum: 1.4]\n      [GC Worker Total (ms): Min: 6.4, Avg: 6.8, Max: 7.8, Diff: 1.4, Sum: 27.2]\n      [GC Worker End (ms): Min: 27891.0, Avg: 27891.3, Max: 27892.3, Diff: 1.3]\n   [Code Root Fixup: 0.5 ms]\n   [Code Root Migration: 1.3 ms]\n   [Code Root Purge: 0.0 ms]\n   [Clear CT: 0.2 ms]\n   [Other: 5.8 ms]\n      [Choose CSet: 0.0 ms]\n      [Ref Proc: 5.0 ms]\n      [Ref Enq: 0.1 ms]\n      [Redirty Cards: 0.0 ms]\n      [Free CSet: 0.2 ms]\n   [Eden: 159.0M(159.0M)->0.0B(301.0M) Survivors: 13.0M->11.0M Heap: 328.8M(3072.0M)->167.3M(3072.0M)]\nHeap after GC invocations=13 (full 1):\n garbage-first heap   total 3145728K, used 171269K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000)\n  region size 1024K, 11 young (11264K), 11 survivors (11264K)\n Metaspace       used 29944K, capacity 30196K, committed 30464K, reserved 1077248K\n  class space    used 3391K, capacity 3480K, committed 3584K, reserved 1048576K\n}\n [Times: user=0.05 sys=0.01, real=0.02 secs]\n每个过程的作用如下：\n\n* garbage-first heap total 3145728K, used 336645K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000) 这行表示使用了G1垃圾收集器，total heap 3145728K，使用了336645K。\n\n* region size 1024K, 172 young (176128K), 13 survivors (13312K) Region大小为1M，青年代占用了172个（共176128K），幸存区占用了13个（共13312K）。\n\n* Metaspace used 29944K, capacity 30196K, committed 30464K, reserved 1077248K class space used 3391K, capacity 3480K, committed 3584K, reserved 1048576K java 8的新特性，去掉永久区，添加了元数据区，这块不是本文重点，不再赘述。需要注意的是，之所以有committed和reserved，是因为没有设置MetaspaceSize=MaxMetaspaceSize。 * [GC pause (G1 Evacuation Pause) (young) GC原因，新生代minor GC。\n\n* [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 1461, predicted base time: 35.25 ms, remaining time: 64.75 ms, target pause time: 100.00 ms] 发生minor GC和full GC时，所有相关region都是要回收的。而发生并发GC时，会根据目标停顿时间动态选择部分垃圾对并多的Region回收，这一步就是选择Region。_pending_cards是关于RSet的Card Table。predicted base time是预测的扫描card table时间。\n\n* [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 159 regions, survivors: 13 regions, predicted young region time: 44.09 ms] 这一步是添加Region到collection set，新生代一共159个Region，13个幸存区Region，这也和之前的（172 young (176128K), 13 survivors (13312K)）吻合。预计收集时间是44.09 ms。\n\n* [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 159 regions, survivors: 13 regions, old: 0 regions, predicted pause time: 79.34 ms, target pause time: 100.00 ms] 这一步是对上面两步的总结。预计总收集时间79.34ms。 * [Parallel Time: 8.1 ms, GC Workers: 4] 由于收集过程是多线程并行（并发）进行，这里是4个线程，总共耗时8.1ms（wall clock time）\n\n* [GC Worker Start (ms): Min: 27884.5, Avg: 27884.5, Max: 27884.5, Diff: 0.1] 收集线程开始的时间，使用的是相对时间，Min是最早开始时间，Avg是平均开始时间，Max是最晚开始时间，Diff是Max-Min（此处的0.1貌似有问题）\n\n* [Ext Root Scanning (ms): Min: 0.4, Avg: 0.8, Max: 1.2, Diff: 0.8, Sum: 3.1] 扫描Roots花费的时间，Sum表示total cpu time，下同。\n\n* [Update RS (ms): Min: 0.0, Avg: 0.3, Max: 0.6, Diff: 0.6, Sum: 1.4] [Processed Buffers: Min: 0, Avg: 2.8, Max: 5, Diff: 5, Sum: 11] Update RS (ms)是每个线程花费在更新Remembered Set上的时间。\n\n* [Scan RS (ms): Min: 0.0, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 0.3] 扫描CS中的region对应的RSet，因为RSet是points-into，所以这样实现避免了扫描old generadion region，但是会产生float garbage。\n\n* [Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.6] 扫描code root耗时。code root指的是经过JIT编译后的代码里，引用了heap中的对象。引用关系保存在RSet中。\n\n* [Object Copy (ms): Min: 4.9, Avg: 5.1, Max: 5.2, Diff: 0.3, Sum: 20.4] 拷贝活的对象到新region的耗时。\n\n* [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] 线程结束，在结束前，它会检查其他线程是否还有未扫描完的引用，如果有，则”偷”过来，完成后再申请结束，这个时间是线程之前互相同步所花费的时间。\n\n* [GC Worker Other (ms): Min: 0.0, Avg: 0.4, Max: 1.3, Diff: 1.3, Sum: 1.4] 花费在其他工作上（未列出）的时间。\n\n* [GC Worker Total (ms): Min: 6.4, Avg: 6.8, Max: 7.8, Diff: 1.4, Sum: 27.2] 每个线程花费的时间和。\n\n* [GC Worker End (ms): Min: 27891.0, Avg: 27891.3, Max: 27892.3, Diff: 1.3] 每个线程结束的时间。\n\n* [Code Root Fixup: 0.5 ms] 用来将code root修正到正确的evacuate之后的对象位置所花费的时间。\n\n* [Code Root Migration: 1.3 ms] 更新code root 引用的耗时，code root中的引用因为对象的evacuation而需要更新。\n\n* [Code Root Purge: 0.0 ms] 清除code root的耗时，code root中的引用已经失效，不再指向Region中的对象，所以需要被清除。\n\n* [Clear CT: 0.2 ms] 清除card table的耗时。\n\n* [Other: 5.8 ms] [Choose CSet: 0.0 ms] [Ref Proc: 5.0 ms] [Ref Enq: 0.1 ms] [Redirty Cards: 0.0 ms] [Free CSet: 0.2 ms] 其他事项共耗时5.8ms，其他事项包括选择CSet，处理已用对象，引用入ReferenceQueues，释放CSet中的region到free list。\n\n* [Eden: 159.0M(159.0M)->0.0B(301.0M) Survivors: 13.0M->11.0M Heap: 328.8M(3072.0M)->167.3M(3072.0M)] 新生代清空了，下次扩容到301MB。\n\nglobal concurrent marking 日志\n对于global concurrent marking过程，它的日志如下所示：\n\n66955.252: [G1Ergonomics (Concurrent Cycles) request concurrent cycle initiation, reason: occupancy higher than threshold, occupancy: 1449132032 bytes, allocation request: 579608 bytes, threshold: 1449\n551430 bytes (45.00 %), source: concurrent humongous allocation]\n2014-12-10T11:13:09.532+0800: 66955.252: Application time: 2.5750418 seconds\n 66955.259: [G1Ergonomics (Concurrent Cycles) request concurrent cycle initiation, reason: requested by GC cause, GC cause: G1 Humongous Allocation]\n{Heap before GC invocations=1874 (full 4):\n garbage-first heap   total 3145728K, used 1281786K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000)\n  region size 1024K, 171 young (175104K), 27 survivors (27648K)\n Metaspace       used 116681K, capacity 137645K, committed 137984K, reserved 1171456K\n  class space    used 13082K, capacity 16290K, committed 16384K, reserved 1048576K\n 66955.259: [G1Ergonomics (Concurrent Cycles) initiate concurrent cycle, reason: concurrent cycle initiation requested]\n2014-12-10T11:13:09.539+0800: 66955.259: [GC pause (G1 Humongous Allocation) (young) (initial-mark)\n…….\n2014-12-10T11:13:09.597+0800: 66955.317: [GC concurrent-root-region-scan-start]\n2014-12-10T11:13:09.597+0800: 66955.318: Total time for which application threads were stopped: 0.0655753 seconds\n2014-12-10T11:13:09.610+0800: 66955.330: Application time: 0.0127071 seconds\n2014-12-10T11:13:09.614+0800: 66955.335: Total time for which application threads were stopped: 0.0043882 seconds\n2014-12-10T11:13:09.625+0800: 66955.346: [GC concurrent-root-region-scan-end, 0.0281351 secs]\n2014-12-10T11:13:09.625+0800: 66955.346: [GC concurrent-mark-start]\n2014-12-10T11:13:09.645+0800: 66955.365: Application time: 0.0306801 seconds\n2014-12-10T11:13:09.651+0800: 66955.371: Total time for which application threads were stopped: 0.0061326 seconds\n2014-12-10T11:13:10.212+0800: 66955.933: [GC concurrent-mark-end, 0.5871129 secs]\n2014-12-10T11:13:10.212+0800: 66955.933: Application time: 0.5613792 seconds\n2014-12-10T11:13:10.215+0800: 66955.935: [GC remark 66955.936: [GC ref-proc, 0.0235275 secs], 0.0320865 secs]\n [Times: user=0.05 sys=0.00, real=0.03 secs]\n2014-12-10T11:13:10.247+0800: 66955.968: Total time for which application threads were stopped: 0.0350098 seconds\n2014-12-10T11:13:10.248+0800: 66955.968: Application time: 0.0001691 seconds\n2014-12-10T11:13:10.250+0800: 66955.970: [GC cleanup 1178M->632M(3072M), 0.0060632 secs]\n [Times: user=0.02 sys=0.00, real=0.01 secs]\n2014-12-10T11:13:10.256+0800: 66955.977: Total time for which application threads were stopped: 0.0088462 seconds\n2014-12-10T11:13:10.257+0800: 66955.977: [GC concurrent-cleanup-start]\n2014-12-10T11:13:10.259+0800: 66955.979: [GC concurrent-cleanup-end, 0.0024743 secs\n这次发生global concurrent marking的原因是：humongous allocation，上面提过在巨大对象分配之前，会检测到old generation 使用占比是否超过了 initiating heap occupancy percent（45%），因为 1449132032(used)+ 579608(allocation request:) > 1449551430(threshold)，所以触发了本次global concurrent marking。对于具体执行过程，上面的表格已经详细讲解了。值得注意的是上文中所说的initial mark往往伴随着一次YGC，在日志中也有体现：GC pause (G1 Humongous Allocation) (young) (initial-mark)。\n\n后记\n因为篇幅的关系，也受限于能力水平，本文只是简单了介绍了G1 GC的基本原理，很多细节没有涉及到，所以说只能算是为研究和使用它的同学打开了一扇门。一个日本人专门写了一本书《徹底解剖「G1GC」 アルゴリズ》详细的介绍了G1 GC，这本书也被作者放到了GitHub上，详见参考文献5。另外，莫枢在这方面也研究的比较多，读者可以去高级语言虚拟机论坛向他请教，本文的很多内容也是我在此论坛上请教过后整理的。总而言之，G1是一款非常优秀的垃圾收集器，尽管还有些不完美（预测模型还不够智能），但是希望有更多的同学来使用它，研究它，提出好的建议，让它变的更加完善。\n\n参考文献\nGetting Started with the G1 Garbage Collector\n请教G1算法的原理\n关于incremental update与SATB的一点理解\nTips for Tuning the Garbage First Garbage Collector\ng1gc-impl-book\n垃圾优先型垃圾回收器调优\nUnderstanding G1 GC Logs\nG1: One Garbage Collector To Rule Them All\n系统, 到店, Hotspot, JVM, G1, GC, Java\n#看看其他前一篇: 美团数据库运维自动化系统构建之路 后一篇: 大促活动前团购系统流量预算和容量评估\n#一起聊聊\n如发现文章有错误、对内容有疑问，都可以关注美团技术团队微信公众号（meituantech），在后台给我们留言。\n\n美团技术团队微信二维码\n我们每周会挑选出一位热心小伙伴，送上一份精美的小礼品。快来扫码关注我们吧！\n\n一行代码，亿万生活。\n\n网站首页\n文章存档\n关于我们\n","slug":"JVM-GC-G1","published":1,"updated":"2019-09-28T08:51:00.868Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o834001uv1npiwraclco","content":"<p><a href=\"https://www.oracle.com/technetwork/java/javase/tech/g1-intro-jsp-135488.html\" target=\"_blank\" rel=\"noopener\">https://www.oracle.com/technetwork/java/javase/tech/g1-intro-jsp-135488.html</a><br>先翻译一遍</p>\n<h3 id=\"美团技术文章写得好\"><a href=\"#美团技术文章写得好\" class=\"headerlink\" title=\"美团技术文章写得好\"></a>美团技术文章写得好</h3><p><a href=\"https://tech.meituan.com/g1.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/g1.html</a></p>\n<h3 id=\"这篇文章好像写得也不错\"><a href=\"#这篇文章好像写得也不错\" class=\"headerlink\" title=\"这篇文章好像写得也不错\"></a>这篇文章好像写得也不错</h3><p><a href=\"https://www.cnblogs.com/yunxitalk/p/8987318.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/yunxitalk/p/8987318.html</a></p>\n<h3 id=\"redhat里面的图看上去不错\"><a href=\"#redhat里面的图看上去不错\" class=\"headerlink\" title=\"redhat里面的图看上去不错\"></a>redhat里面的图看上去不错</h3><p><a href=\"https://www.redhat.com/en/blog/part-1-introduction-g1-garbage-collector\" target=\"_blank\" rel=\"noopener\">https://www.redhat.com/en/blog/part-1-introduction-g1-garbage-collector</a><br><a href=\"https://www.redhat.com/en/blog/collecting-and-reading-g1-garbage-collector-logs-part-2\" target=\"_blank\" rel=\"noopener\">https://www.redhat.com/en/blog/collecting-and-reading-g1-garbage-collector-logs-part-2</a></p>\n<h3 id=\"R大不是盖的啊\"><a href=\"#R大不是盖的啊\" class=\"headerlink\" title=\"R大不是盖的啊\"></a>R大不是盖的啊</h3><p><a href=\"https://hllvm-group.iteye.com/group/topic/44381\" target=\"_blank\" rel=\"noopener\">https://hllvm-group.iteye.com/group/topic/44381</a></p>\n<h3 id=\"杜兄的文章写得很不错\"><a href=\"#杜兄的文章写得很不错\" class=\"headerlink\" title=\"杜兄的文章写得很不错\"></a>杜兄的文章写得很不错</h3><p><a href=\"https://www.jianshu.com/p/a3e6a9de7a5d\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/a3e6a9de7a5d</a></p>\n<h3 id=\"Amazon-神PPT，写得很详细\"><a href=\"#Amazon-神PPT，写得很详细\" class=\"headerlink\" title=\"Amazon 神PPT，写得很详细\"></a>Amazon 神PPT，写得很详细</h3><p><a href=\"http://presentations2015.s3.amazonaws.com/40_presentation.pdf\" target=\"_blank\" rel=\"noopener\">http://presentations2015.s3.amazonaws.com/40_presentation.pdf</a></p>\n<h3 id=\"younggc\"><a href=\"#younggc\" class=\"headerlink\" title=\"younggc\"></a>younggc</h3><h4 id=\"First-phase-“Root-Scanning”\"><a href=\"#First-phase-“Root-Scanning”\" class=\"headerlink\" title=\"First phase: “Root Scanning”\"></a>First phase: “Root Scanning”</h4><p>需要STW，从GC root开始扫描存活对象<br>Static and local objects are scanned</p>\n<h4 id=\"Second-phase-“Update-RS”\"><a href=\"#Second-phase-“Update-RS”\" class=\"headerlink\" title=\"Second phase: “Update RS”\"></a>Second phase: “Update RS”</h4><p>在上一轮中，有很多对象修改了引用，被load barrier放入了dirty card queue，需要把这部分的数据拿出来，更新Rset<br>Drains the dirty card queue to update the RS</p>\n<h4 id=\"Third-phase-“Process-RS”\"><a href=\"#Third-phase-“Process-RS”\" class=\"headerlink\" title=\"Third phase: “Process RS”\"></a>Third phase: “Process RS”</h4><p>从GC Root的扫描无法彻底让Region和Region独立工作，需要借助于RSet，从RSet找到从Old区指向当前Region的区域（CardTable）<br>Detect the Eden objects pointed by Old objects</p>\n<h4 id=\"Fourth-phase-“Object-Copy”\"><a href=\"#Fourth-phase-“Object-Copy”\" class=\"headerlink\" title=\"Fourth phase: “Object Copy”\"></a>Fourth phase: “Object Copy”</h4><p>The object graph is traversed<br>Live objects copied to Survivor/Old regions</p>\n<h4 id=\"Fifth-phase-“Reference-Processing”\"><a href=\"#Fifth-phase-“Reference-Processing”\" class=\"headerlink\" title=\"Fifth phase: “Reference Processing”\"></a>Fifth phase: “Reference Processing”</h4><p>Soft, Weak, Phantom, Final, JNI Weak references<br>Always enable -XX:+ParallelRefProcEnabled<br>More details with -XX:+PrintReferenceGC</p>\n<h3 id=\"infoQ\"><a href=\"#infoQ\" class=\"headerlink\" title=\"infoQ\"></a>infoQ</h3><p><a href=\"https://www.infoq.com/articles/tuning-tips-G1-GC\" target=\"_blank\" rel=\"noopener\">https://www.infoq.com/articles/tuning-tips-G1-GC</a></p>\n<p>// VM_operations for the G1 collector.<br>// VM_GC_Operation:<br>//   - VM_CGC_Operation<br>//   - VM_G1CollectFull<br>//   - VM_G1OperationWithAllocRequest<br>//     - VM_G1CollectForAllocation<br>//     - VM_G1IncCollectionPause</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/22591838\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/22591838</a></p>\n<h3 id=\"重要信息\"><a href=\"#重要信息\" class=\"headerlink\" title=\"重要信息\"></a>重要信息</h3><p>G1GC没有提供专门的FullGC，还是使用传统FullGC来对整个堆的垃圾进行收集。</p>\n<h3 id=\"Young-GC的时间预测调用栈\"><a href=\"#Young-GC的时间预测调用栈\" class=\"headerlink\" title=\"Young GC的时间预测调用栈\"></a>Young GC的时间预测调用栈</h3><p>G1DefaultPolicy::predict_base_elapsed_time_ms g1DefaultPolicy.cpp:829<br>G1DefaultPolicy::predict_base_elapsed_time_ms g1DefaultPolicy.cpp:837<br>G1CollectionSet::finalize_young_part g1CollectionSet.cpp:363<br>G1DefaultPolicy::finalize_collection_set g1DefaultPolicy.cpp:1137<br>G1CollectedHeap::do_collection_pause_at_safepoint g1CollectedHeap.cpp:3162<br>VM_G1IncCollectionPause::doit vm_operations_g1.cpp:148<br>VM_Operation::evaluate vm_operations.cpp:66<br>VMThread::evaluate_operation vmThread.cpp:348<br>VMThread::loop vmThread.cpp:470<br>VMThread::run vmThread.cpp:262<br>thread_native_entry os_bsd.cpp:720<br>_pthread_body 0x00007fff74974339<br>_pthread_start 0x00007fff749772a7<br>thread_start 0x00007fff74973445<br><unknown> 0x0000000000000000</unknown></p>\n<h4 id=\"美团文章\"><a href=\"#美团文章\" class=\"headerlink\" title=\"美团文章\"></a>美团文章</h4><p>Java Hotspot G1 GC的一些关键技术<br>2016年09月23日 作者: 小亮 文章链接 18946字 38分钟阅读<br>前言<br>G1 GC，全称Garbage-First Garbage Collector，通过-XX:+UseG1GC参数来启用，作为体验版随着JDK 6u14版本面世，在JDK 7u4版本发行时被正式推出，相信熟悉JVM的同学们都不会对它感到陌生。在JDK 9中，G1被提议设置为默认垃圾收集器（JEP 248）。在官网中，是这样描述G1的： &gt; The Garbage-First (G1) collector is a server-style garbage collector, targeted for multi-processor machines with large memories. It meets garbage collection (GC) pause time goals with a high probability, while achieving high throughput. The G1 garbage collector is fully supported in Oracle JDK 7 update 4 and later releases. The G1 collector is designed for applications that: &gt; * Can operate concurrently with applications threads like the CMS collector. &gt; * Compact free space without lengthy GC induced pause times. &gt; * Need more predictable GC pause durations. &gt; * Do not want to sacrifice a lot of throughput performance. &gt; * Do not require a much larger Java heap.</p>\n<p>从官网的描述中，我们知道G1是一种服务器端的垃圾收集器，应用在多处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集暂停时间的要求。它是专门针对以下应用场景设计的: * 像CMS收集器一样，能与应用程序线程并发执行。 * 整理空闲空间更快。 * 需要GC停顿时间更好预测。 * 不希望牺牲大量的吞吐性能。 * 不需要更大的Java Heap。</p>\n<p>G1收集器的设计目标是取代CMS收集器，它同CMS相比，在以下方面表现的更出色： * G1是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片。 * G1的Stop The World(STW)更可控，G1在停顿时间上添加了预测机制，用户可以指定期望停顿时间。</p>\n<p>有了以上的特性，难怪有人说它是一款驾驭一切的垃圾收集器（G1: One Garbage Collector To Rule Them All）。本文带大家来了解一下G1 GC的一些关键技术，为能正确的使用它，做好理论基础的铺垫。</p>\n<p>G1中几个重要概念<br>在G1的实现过程中，引入了一些新的概念，对于实现高吞吐、没有内存碎片、收集时间可控等功能起到了关键作用。下面我们就一起看一下G1中的这几个重要概念。</p>\n<p>Region<br>传统的GC收集器将连续的内存空间划分为新生代、老年代和永久代（JDK 8去除了永久代，引入了元空间Metaspace），这种划分的特点是各代的存储地址（逻辑地址，下同）是连续的。如下图所示： 传统GC内存布局<br>传统GC内存布局</p>\n<p>而G1的各代存储地址是不连续的，每一代都使用了n个不连续的大小相同的Region，每个Region占有一块连续的虚拟内存地址。如下图所示： g1 GC内存布局<br>g1 GC内存布局</p>\n<p>在上图中，我们注意到还有一些Region标明了H，它代表Humongous，这表示这些Region存储的是巨大对象（humongous object，H-obj），即大小大于等于region一半的对象。H-obj有如下几个特征： * H-obj直接分配到了old gen，防止了反复拷贝移动。 * H-obj在global concurrent marking阶段的cleanup 和 full GC阶段回收。 * 在分配H-obj之前先检查是否超过 initiating heap occupancy percent和the marking threshold, 如果超过的话，就启动global concurrent marking，为的是提早回收，防止 evacuation failures 和 full GC。</p>\n<p>为了减少连续H-objs分配对GC的影响，需要把大对象变为普通的对象，建议增大Region size。</p>\n<p>一个Region的大小可以通过参数-XX:G1HeapRegionSize设定，取值范围从1M到32M，且是2的指数。如果不设定，那么G1会根据Heap大小自动决定。相关的设置代码如下：</p>\n<p>// share/vm/gc_implementation/g1/heapRegion.cpp<br>// Minimum region size; we won’t go lower than that.<br>// We might want to decrease this in the future, to deal with small<br>// heaps a bit more efficiently.<br>#define MIN_REGION_SIZE  (      1024 * 1024 )<br>// Maximum region size; we don’t go higher than that. There’s a good<br>// reason for having an upper bound. We don’t want regions to get too<br>// large, otherwise cleanup’s effectiveness would decrease as there<br>// will be fewer opportunities to find totally empty regions after<br>// marking.<br>#define MAX_REGION_SIZE  ( 32 * 1024 * 1024 )<br>// The automatic region size calculation will try to have around this<br>// many regions in the heap (based on the min heap size).<br>#define TARGET_REGION_NUMBER          2048<br>void HeapRegion::setup_heap_region_size(size_t initial_heap_size, size_t max_heap_size) {<br>  uintx region_size = G1HeapRegionSize;<br>  if (FLAG_IS_DEFAULT(G1HeapRegionSize)) {<br>    size_t average_heap_size = (initial_heap_size + max_heap_size) / 2;<br>    region_size = MAX2(average_heap_size / TARGET_REGION_NUMBER,<br>                       (uintx) MIN_REGION_SIZE);<br>  }<br>  int region_size_log = log2_long((jlong) region_size);<br>  // Recalculate the region size to make sure it’s a power of<br>  // 2. This means that region_size is the largest power of 2 that’s<br>  // &lt;= what we’ve calculated so far.<br>  region_size = ((uintx)1 &lt;&lt; region_size_log);<br>  // Now make sure that we don’t go over or under our limits.<br>  if (region_size &lt; MIN_REGION_SIZE) {<br>    region_size = MIN_REGION_SIZE;<br>  } else if (region_size &gt; MAX_REGION_SIZE) {<br>    region_size = MAX_REGION_SIZE;<br>  }<br>}<br>SATB<br>全称是Snapshot-At-The-Beginning，由字面理解，是GC开始时活着的对象的一个快照。它是通过Root Tracing得到的，作用是维持并发GC的正确性。 那么它是怎么维持并发GC的正确性的呢？根据三色标记算法，我们知道对象存在三种状态： * 白：对象没有被标记到，标记阶段结束后，会被当做垃圾回收掉。 * 灰：对象被标记了，但是它的field还没有被标记或标记完。 * 黑：对象被标记了，且它的所有field也被标记完了。</p>\n<p>由于并发阶段的存在，Mutator和Garbage Collector线程同时对对象进行修改，就会出现白对象漏标的情况，这种情况发生的前提是： * Mutator赋予一个黑对象该白对象的引用。 * Mutator删除了所有从灰对象到该白对象的直接或者间接引用。</p>\n<p>对于第一个条件，在并发标记阶段，如果该白对象是new出来的，并没有被灰对象持有，那么它会不会被漏标呢？Region中有两个top-at-mark-start（TAMS）指针，分别为prevTAMS和nextTAMS。在TAMS以上的对象是新分配的，这是一种隐式的标记。对于在GC时已经存在的白对象，如果它是活着的，它必然会被另一个对象引用，即条件二中的灰对象。如果灰对象到白对象的直接引用或者间接引用被替换了，或者删除了，白对象就会被漏标，从而导致被回收掉，这是非常严重的错误，所以SATB破坏了第二个条件。也就是说，一个对象的引用被替换时，可以通过write barrier 将旧引用记录下来。</p>\n<p>//  share/vm/gc_implementation/g1/g1SATBCardTableModRefBS.hpp<br>// This notes that we don’t need to access any BarrierSet data<br>// structures, so this can be called from a static context.<br>template <class t=\"\"> static void write_ref_field_pre_static(T* field, oop newVal) {<br>  T heap_oop = oopDesc::load_heap_oop(field);<br>  if (!oopDesc::is_null(heap_oop)) {<br>    enqueue(oopDesc::decode_heap_oop(heap_oop));<br>  }<br>}<br>// share/vm/gc_implementation/g1/g1SATBCardTableModRefBS.cpp<br>void G1SATBCardTableModRefBS::enqueue(oop pre_val) {<br>  // Nulls should have been already filtered.<br>  assert(pre_val-&gt;is_oop(true), “Error”);<br>  if (!JavaThread::satb_mark_queue_set().is_active()) return;<br>  Thread* thr = Thread::current();<br>  if (thr-&gt;is_Java_thread()) {<br>    JavaThread* jt = (JavaThread*)thr;<br>    jt-&gt;satb_mark_queue().enqueue(pre_val);<br>  } else {<br>    MutexLockerEx x(Shared_SATB_Q_lock, Mutex::_no_safepoint_check_flag);<br>    JavaThread::satb_mark_queue_set().shared_satb_queue()-&gt;enqueue(pre_val);<br>  }<br>}<br>SATB也是有副作用的，如果被替换的白对象就是要被收集的垃圾，这次的标记会让它躲过GC，这就是float garbage。因为SATB的做法精度比较低，所以造成的float garbage也会比较多。</class></p>\n<p>RSet<br>全称是Remembered Set，是辅助GC过程的一种结构，典型的空间换时间工具，和Card Table有些类似。还有一种数据结构也是辅助GC的：Collection Set（CSet），它记录了GC要收集的Region集合，集合里的Region可以是任意年代的。在GC的时候，对于old-&gt;young和old-&gt;old的跨代对象引用，只要扫描对应的CSet中的RSet即可。 逻辑上说每个Region都有一个RSet，RSet记录了其他Region中的对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）。而Card Table则是一种points-out（我引用了谁的对象）的结构，每个Card 覆盖一定范围的Heap（一般为512Bytes）。G1的RSet是在Card Table的基础上实现的：每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。 这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。</p>\n<p>下图表示了RSet、Card和Region的关系（出处）： Remembered Sets<br>Remembered Sets</p>\n<p>上图中有三个Region，每个Region被分成了多个Card，在不同Region中的Card会相互引用，Region1中的Card中的对象引用了Region2中的Card中的对象，蓝色实线表示的就是points-out的关系，而在Region2的RSet中，记录了Region1的Card，即红色虚线表示的关系，这就是points-into。 而维系RSet中的引用关系靠post-write barrier和Concurrent refinement threads来维护，操作伪代码如下（出处）：</p>\n<p>void oop_field_store(oop* field, oop new_value) {<br>  pre_write_barrier(field);             // pre-write barrier: for maintaining SATB invariant<br>  *field = new_value;                   // the actual store<br>  post_write_barrier(field, new_value); // post-write barrier: for tracking cross-region reference<br>}<br>post-write barrier记录了跨Region的引用更新，更新日志缓冲区则记录了那些包含更新引用的Cards。一旦缓冲区满了，Post-write barrier就停止服务了，会由Concurrent refinement threads处理这些缓冲区日志。 RSet究竟是怎么辅助GC的呢？在做YGC的时候，只需要选定young generation region的RSet作为根集，这些RSet记录了old-&gt;young的跨代引用，避免了扫描整个old generation。 而mixed gc的时候，old generation中记录了old-&gt;old的RSet，young-&gt;old的引用由扫描全部young generation region得到，这样也不用扫描全部old generation region。所以RSet的引入大大减少了GC的工作量。</p>\n<p>Pause Prediction Model<br>Pause Prediction Model 即停顿预测模型。它在G1中的作用是： &gt;G1 uses a pause prediction model to meet a user-defined pause time target and selects the number of regions to collect based on the specified pause time target.</p>\n<p>G1 GC是一个响应时间优先的GC算法，它与CMS最大的不同是，用户可以设定整个GC过程的期望停顿时间，参数-XX:MaxGCPauseMillis指定一个G1收集过程目标停顿时间，默认值200ms，不过它不是硬性条件，只是期望值。那么G1怎么满足用户的期望呢？就需要这个停顿预测模型了。G1根据这个模型统计计算出来的历史数据来预测本次收集需要选择的Region数量，从而尽量满足用户设定的目标停顿时间。 停顿预测模型是以衰减标准偏差为理论基础实现的：</p>\n<p>//  share/vm/gc_implementation/g1/g1CollectorPolicy.hpp<br>double get_new_prediction(TruncatedSeq* seq) {<br>    return MAX2(seq-&gt;davg() + sigma() * seq-&gt;dsd(),<br>                seq-&gt;davg() * confidence_factor(seq-&gt;num()));<br>}<br>在这个预测计算公式中：davg表示衰减均值，sigma()返回一个系数，表示信赖度，dsd表示衰减标准偏差，confidence_factor表示可信度相关系数。而方法的参数TruncateSeq，顾名思义，是一个截断的序列，它只跟踪了序列中的最新的n个元素。</p>\n<p>在G1 GC过程中，每个可测量的步骤花费的时间都会记录到TruncateSeq（继承了AbsSeq）中，用来计算衰减均值、衰减变量，衰减标准偏差等：</p>\n<p>// src/share/vm/utilities/numberSeq.cpp</p>\n<p>void AbsSeq::add(double val) {<br>  if (_num == 0) {<br>    // if the sequence is empty, the davg is the same as the value<br>    _davg = val;<br>    // and the variance is 0<br>    _dvariance = 0.0;<br>  } else {<br>    // otherwise, calculate both<br>    _davg = (1.0 - _alpha) * val + _alpha * _davg;<br>    double diff = val - _davg;<br>    _dvariance = (1.0 - _alpha) * diff * diff + _alpha * _dvariance;<br>  }<br>}<br>比如要预测一次GC过程中，RSet的更新时间，这个操作主要是将Dirty Card加入到RSet中，具体原理参考前面的RSet。每个Dirty Card的时间花费通过_cost_per_card_ms_seq来记录，具体预测代码如下：</p>\n<p>//  share/vm/gc_implementation/g1/g1CollectorPolicy.hpp</p>\n<p> double predict_rs_update_time_ms(size_t pending_cards) {<br>    return (double) pending_cards * predict_cost_per_card_ms();<br> }<br> double predict_cost_per_card_ms() {<br>    return get_new_prediction(_cost_per_card_ms_seq);<br> }<br>get_new_prediction就是我们开头说的方法，现在大家应该基本明白停顿预测模型的实现原理了。</p>\n<p>GC过程<br>讲完了一些基本概念，下面我们就来看看G1的GC过程是怎样的。</p>\n<p>G1 GC模式<br>G1提供了两种GC模式，Young GC和Mixed GC，两种都是完全Stop The World的。 * Young GC：选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC的时间开销。 * Mixed GC：选定所有年轻代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。</p>\n<p>由上面的描述可知，Mixed GC不是full GC，它只能回收部分老年代的Region，如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap。所以我们可以知道，G1是不提供full GC的。</p>\n<p>上文中，多次提到了global concurrent marking，它的执行过程类似CMS，但是不同的是，在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为四个步骤： * 初始标记（initial mark，STW）。它标记了从GC Root开始直接可达的对象。 * 并发标记（Concurrent Marking）。这个阶段从GC Root开始对heap中的对象标记，标记线程与应用程序线程并行执行，并且收集各个Region的存活对象信息。 * 最终标记（Remark，STW）。标记那些在并发标记阶段发生变化的对象，将被回收。 * 清除垃圾（Cleanup）。清除空Region（没有存活对象的），加入到free list。</p>\n<p>第一阶段initial mark是共用了Young GC的暂停，这是因为他们可以复用root scan操作，所以可以说global concurrent marking是伴随Young GC而发生的。第四阶段Cleanup只是回收了没有存活对象的Region，所以它并不需要STW。</p>\n<p>Young GC发生的时机大家都知道，那什么时候发生Mixed GC呢？其实是由一些参数控制着的，另外也控制着哪些老年代Region会被选入CSet。 * G1HeapWastePercent：在global concurrent marking结束之后，我们可以知道old gen regions中有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到此参数，只有达到了，下次才会发生Mixed GC。 * G1MixedGCLiveThresholdPercent：old generation region中的存活对象的占比，只有在此参数之下，才会被选入CSet。 * G1MixedGCCountTarget：一次global concurrent marking之后，最多执行Mixed GC的次数。 * G1OldCSetRegionThresholdPercent：一次Mixed GC中能被选入CSet的最多old generation region数量。</p>\n<p>除了以上的参数，G1 GC相关的其他主要的参数有：</p>\n<p>参数    含义<br>-XX:G1HeapRegionSize=n    设置Region大小，并非最终值<br>-XX:MaxGCPauseMillis    设置G1收集过程目标时间，默认值200ms，不是硬性条件<br>-XX:G1NewSizePercent    新生代最小值，默认值5%<br>-XX:G1MaxNewSizePercent    新生代最大值，默认值60%<br>-XX:ParallelGCThreads    STW期间，并行GC线程数<br>-XX:ConcGCThreads=n    并发标记阶段，并行执行的线程数<br>-XX:InitiatingHeapOccupancyPercent    设置触发标记周期的 Java 堆占用率阈值。默认值是45%。这里的java堆占比指的是non_young_capacity_bytes，包括old+humongous<br>GC日志<br>G1收集器的日志与其他收集器有很大不同，源于G1独立的体系架构和数据结构，下面这两段日志来源于美团点评的CRM系统线上生产环境。</p>\n<p>Young GC日志<br>我们先来看看Young GC的日志：</p>\n<p>{Heap before GC invocations=12 (full 1):<br> garbage-first heap   total 3145728K, used 336645K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000)<br>  region size 1024K, 172 young (176128K), 13 survivors (13312K)<br> Metaspace       used 29944K, capacity 30196K, committed 30464K, reserved 1077248K<br>  class space    used 3391K, capacity 3480K, committed 3584K, reserved 1048576K<br>2014-11-14T17:57:23.654+0800: 27.884: [GC pause (G1 Evacuation Pause) (young)<br>Desired survivor size 11534336 bytes, new threshold 15 (max 15)</p>\n<ul>\n<li>age   1:    5011600 bytes,    5011600 total<br>27.884: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 1461, predicted base time: 35.25 ms, remaining time: 64.75 ms, target pause time: 100.00 ms]<br>27.884: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 159 regions, survivors: 13 regions, predicted young region time: 44.09 ms]<br>27.884: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 159 regions, survivors: 13 regions, old: 0 regions, predicted pause time: 79.34 ms, target pause time: 100.00 ms]<br>, 0.0158389 secs]<br> [Parallel Time: 8.1 ms, GC Workers: 4]<pre><code>[GC Worker Start (ms): Min: 27884.5, Avg: 27884.5, Max: 27884.5, Diff: 0.1]\n[Ext Root Scanning (ms): Min: 0.4, Avg: 0.8, Max: 1.2, Diff: 0.8, Sum: 3.1]\n[Update RS (ms): Min: 0.0, Avg: 0.3, Max: 0.6, Diff: 0.6, Sum: 1.4]\n   [Processed Buffers: Min: 0, Avg: 2.8, Max: 5, Diff: 5, Sum: 11]\n[Scan RS (ms): Min: 0.0, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 0.3]\n[Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.6]\n[Object Copy (ms): Min: 4.9, Avg: 5.1, Max: 5.2, Diff: 0.3, Sum: 20.4]\n[Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n[GC Worker Other (ms): Min: 0.0, Avg: 0.4, Max: 1.3, Diff: 1.3, Sum: 1.4]\n[GC Worker Total (ms): Min: 6.4, Avg: 6.8, Max: 7.8, Diff: 1.4, Sum: 27.2]\n[GC Worker End (ms): Min: 27891.0, Avg: 27891.3, Max: 27892.3, Diff: 1.3]</code></pre> [Code Root Fixup: 0.5 ms]<br> [Code Root Migration: 1.3 ms]<br> [Code Root Purge: 0.0 ms]<br> [Clear CT: 0.2 ms]<br> [Other: 5.8 ms]<pre><code>[Choose CSet: 0.0 ms]\n[Ref Proc: 5.0 ms]\n[Ref Enq: 0.1 ms]\n[Redirty Cards: 0.0 ms]\n[Free CSet: 0.2 ms]</code></pre> [Eden: 159.0M(159.0M)-&gt;0.0B(301.0M) Survivors: 13.0M-&gt;11.0M Heap: 328.8M(3072.0M)-&gt;167.3M(3072.0M)]<br>Heap after GC invocations=13 (full 1):<br>garbage-first heap   total 3145728K, used 171269K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000)<br>region size 1024K, 11 young (11264K), 11 survivors (11264K)<br>Metaspace       used 29944K, capacity 30196K, committed 30464K, reserved 1077248K<br>class space    used 3391K, capacity 3480K, committed 3584K, reserved 1048576K<br>}<br>[Times: user=0.05 sys=0.01, real=0.02 secs]<br>每个过程的作用如下：</li>\n</ul>\n<ul>\n<li><p>garbage-first heap total 3145728K, used 336645K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000) 这行表示使用了G1垃圾收集器，total heap 3145728K，使用了336645K。</p>\n</li>\n<li><p>region size 1024K, 172 young (176128K), 13 survivors (13312K) Region大小为1M，青年代占用了172个（共176128K），幸存区占用了13个（共13312K）。</p>\n</li>\n<li><p>Metaspace used 29944K, capacity 30196K, committed 30464K, reserved 1077248K class space used 3391K, capacity 3480K, committed 3584K, reserved 1048576K java 8的新特性，去掉永久区，添加了元数据区，这块不是本文重点，不再赘述。需要注意的是，之所以有committed和reserved，是因为没有设置MetaspaceSize=MaxMetaspaceSize。 * [GC pause (G1 Evacuation Pause) (young) GC原因，新生代minor GC。</p>\n</li>\n<li><p>[G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 1461, predicted base time: 35.25 ms, remaining time: 64.75 ms, target pause time: 100.00 ms] 发生minor GC和full GC时，所有相关region都是要回收的。而发生并发GC时，会根据目标停顿时间动态选择部分垃圾对并多的Region回收，这一步就是选择Region。_pending_cards是关于RSet的Card Table。predicted base time是预测的扫描card table时间。</p>\n</li>\n<li><p>[G1Ergonomics (CSet Construction) add young regions to CSet, eden: 159 regions, survivors: 13 regions, predicted young region time: 44.09 ms] 这一步是添加Region到collection set，新生代一共159个Region，13个幸存区Region，这也和之前的（172 young (176128K), 13 survivors (13312K)）吻合。预计收集时间是44.09 ms。</p>\n</li>\n<li><p>[G1Ergonomics (CSet Construction) finish choosing CSet, eden: 159 regions, survivors: 13 regions, old: 0 regions, predicted pause time: 79.34 ms, target pause time: 100.00 ms] 这一步是对上面两步的总结。预计总收集时间79.34ms。 * [Parallel Time: 8.1 ms, GC Workers: 4] 由于收集过程是多线程并行（并发）进行，这里是4个线程，总共耗时8.1ms（wall clock time）</p>\n</li>\n<li><p>[GC Worker Start (ms): Min: 27884.5, Avg: 27884.5, Max: 27884.5, Diff: 0.1] 收集线程开始的时间，使用的是相对时间，Min是最早开始时间，Avg是平均开始时间，Max是最晚开始时间，Diff是Max-Min（此处的0.1貌似有问题）</p>\n</li>\n<li><p>[Ext Root Scanning (ms): Min: 0.4, Avg: 0.8, Max: 1.2, Diff: 0.8, Sum: 3.1] 扫描Roots花费的时间，Sum表示total cpu time，下同。</p>\n</li>\n<li><p>[Update RS (ms): Min: 0.0, Avg: 0.3, Max: 0.6, Diff: 0.6, Sum: 1.4] [Processed Buffers: Min: 0, Avg: 2.8, Max: 5, Diff: 5, Sum: 11] Update RS (ms)是每个线程花费在更新Remembered Set上的时间。</p>\n</li>\n<li><p>[Scan RS (ms): Min: 0.0, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 0.3] 扫描CS中的region对应的RSet，因为RSet是points-into，所以这样实现避免了扫描old generadion region，但是会产生float garbage。</p>\n</li>\n<li><p>[Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.6] 扫描code root耗时。code root指的是经过JIT编译后的代码里，引用了heap中的对象。引用关系保存在RSet中。</p>\n</li>\n<li><p>[Object Copy (ms): Min: 4.9, Avg: 5.1, Max: 5.2, Diff: 0.3, Sum: 20.4] 拷贝活的对象到新region的耗时。</p>\n</li>\n<li><p>[Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] 线程结束，在结束前，它会检查其他线程是否还有未扫描完的引用，如果有，则”偷”过来，完成后再申请结束，这个时间是线程之前互相同步所花费的时间。</p>\n</li>\n<li><p>[GC Worker Other (ms): Min: 0.0, Avg: 0.4, Max: 1.3, Diff: 1.3, Sum: 1.4] 花费在其他工作上（未列出）的时间。</p>\n</li>\n<li><p>[GC Worker Total (ms): Min: 6.4, Avg: 6.8, Max: 7.8, Diff: 1.4, Sum: 27.2] 每个线程花费的时间和。</p>\n</li>\n<li><p>[GC Worker End (ms): Min: 27891.0, Avg: 27891.3, Max: 27892.3, Diff: 1.3] 每个线程结束的时间。</p>\n</li>\n<li><p>[Code Root Fixup: 0.5 ms] 用来将code root修正到正确的evacuate之后的对象位置所花费的时间。</p>\n</li>\n<li><p>[Code Root Migration: 1.3 ms] 更新code root 引用的耗时，code root中的引用因为对象的evacuation而需要更新。</p>\n</li>\n<li><p>[Code Root Purge: 0.0 ms] 清除code root的耗时，code root中的引用已经失效，不再指向Region中的对象，所以需要被清除。</p>\n</li>\n<li><p>[Clear CT: 0.2 ms] 清除card table的耗时。</p>\n</li>\n<li><p>[Other: 5.8 ms] [Choose CSet: 0.0 ms] [Ref Proc: 5.0 ms] [Ref Enq: 0.1 ms] [Redirty Cards: 0.0 ms] [Free CSet: 0.2 ms] 其他事项共耗时5.8ms，其他事项包括选择CSet，处理已用对象，引用入ReferenceQueues，释放CSet中的region到free list。</p>\n</li>\n<li><p>[Eden: 159.0M(159.0M)-&gt;0.0B(301.0M) Survivors: 13.0M-&gt;11.0M Heap: 328.8M(3072.0M)-&gt;167.3M(3072.0M)] 新生代清空了，下次扩容到301MB。</p>\n</li>\n</ul>\n<p>global concurrent marking 日志<br>对于global concurrent marking过程，它的日志如下所示：</p>\n<p>66955.252: [G1Ergonomics (Concurrent Cycles) request concurrent cycle initiation, reason: occupancy higher than threshold, occupancy: 1449132032 bytes, allocation request: 579608 bytes, threshold: 1449<br>551430 bytes (45.00 %), source: concurrent humongous allocation]<br>2014-12-10T11:13:09.532+0800: 66955.252: Application time: 2.5750418 seconds<br> 66955.259: [G1Ergonomics (Concurrent Cycles) request concurrent cycle initiation, reason: requested by GC cause, GC cause: G1 Humongous Allocation]<br>{Heap before GC invocations=1874 (full 4):<br> garbage-first heap   total 3145728K, used 1281786K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000)<br>  region size 1024K, 171 young (175104K), 27 survivors (27648K)<br> Metaspace       used 116681K, capacity 137645K, committed 137984K, reserved 1171456K<br>  class space    used 13082K, capacity 16290K, committed 16384K, reserved 1048576K<br> 66955.259: [G1Ergonomics (Concurrent Cycles) initiate concurrent cycle, reason: concurrent cycle initiation requested]<br>2014-12-10T11:13:09.539+0800: 66955.259: [GC pause (G1 Humongous Allocation) (young) (initial-mark)<br>…….<br>2014-12-10T11:13:09.597+0800: 66955.317: [GC concurrent-root-region-scan-start]<br>2014-12-10T11:13:09.597+0800: 66955.318: Total time for which application threads were stopped: 0.0655753 seconds<br>2014-12-10T11:13:09.610+0800: 66955.330: Application time: 0.0127071 seconds<br>2014-12-10T11:13:09.614+0800: 66955.335: Total time for which application threads were stopped: 0.0043882 seconds<br>2014-12-10T11:13:09.625+0800: 66955.346: [GC concurrent-root-region-scan-end, 0.0281351 secs]<br>2014-12-10T11:13:09.625+0800: 66955.346: [GC concurrent-mark-start]<br>2014-12-10T11:13:09.645+0800: 66955.365: Application time: 0.0306801 seconds<br>2014-12-10T11:13:09.651+0800: 66955.371: Total time for which application threads were stopped: 0.0061326 seconds<br>2014-12-10T11:13:10.212+0800: 66955.933: [GC concurrent-mark-end, 0.5871129 secs]<br>2014-12-10T11:13:10.212+0800: 66955.933: Application time: 0.5613792 seconds<br>2014-12-10T11:13:10.215+0800: 66955.935: [GC remark 66955.936: [GC ref-proc, 0.0235275 secs], 0.0320865 secs]<br> [Times: user=0.05 sys=0.00, real=0.03 secs]<br>2014-12-10T11:13:10.247+0800: 66955.968: Total time for which application threads were stopped: 0.0350098 seconds<br>2014-12-10T11:13:10.248+0800: 66955.968: Application time: 0.0001691 seconds<br>2014-12-10T11:13:10.250+0800: 66955.970: [GC cleanup 1178M-&gt;632M(3072M), 0.0060632 secs]<br> [Times: user=0.02 sys=0.00, real=0.01 secs]<br>2014-12-10T11:13:10.256+0800: 66955.977: Total time for which application threads were stopped: 0.0088462 seconds<br>2014-12-10T11:13:10.257+0800: 66955.977: [GC concurrent-cleanup-start]<br>2014-12-10T11:13:10.259+0800: 66955.979: [GC concurrent-cleanup-end, 0.0024743 secs<br>这次发生global concurrent marking的原因是：humongous allocation，上面提过在巨大对象分配之前，会检测到old generation 使用占比是否超过了 initiating heap occupancy percent（45%），因为 1449132032(used)+ 579608(allocation request:) &gt; 1449551430(threshold)，所以触发了本次global concurrent marking。对于具体执行过程，上面的表格已经详细讲解了。值得注意的是上文中所说的initial mark往往伴随着一次YGC，在日志中也有体现：GC pause (G1 Humongous Allocation) (young) (initial-mark)。</p>\n<p>后记<br>因为篇幅的关系，也受限于能力水平，本文只是简单了介绍了G1 GC的基本原理，很多细节没有涉及到，所以说只能算是为研究和使用它的同学打开了一扇门。一个日本人专门写了一本书《徹底解剖「G1GC」 アルゴリズ》详细的介绍了G1 GC，这本书也被作者放到了GitHub上，详见参考文献5。另外，莫枢在这方面也研究的比较多，读者可以去高级语言虚拟机论坛向他请教，本文的很多内容也是我在此论坛上请教过后整理的。总而言之，G1是一款非常优秀的垃圾收集器，尽管还有些不完美（预测模型还不够智能），但是希望有更多的同学来使用它，研究它，提出好的建议，让它变的更加完善。</p>\n<p>参考文献<br>Getting Started with the G1 Garbage Collector<br>请教G1算法的原理<br>关于incremental update与SATB的一点理解<br>Tips for Tuning the Garbage First Garbage Collector<br>g1gc-impl-book<br>垃圾优先型垃圾回收器调优<br>Understanding G1 GC Logs<br>G1: One Garbage Collector To Rule Them All<br>系统, 到店, Hotspot, JVM, G1, GC, Java<br>#看看其他前一篇: 美团数据库运维自动化系统构建之路 后一篇: 大促活动前团购系统流量预算和容量评估<br>#一起聊聊<br>如发现文章有错误、对内容有疑问，都可以关注美团技术团队微信公众号（meituantech），在后台给我们留言。</p>\n<p>美团技术团队微信二维码<br>我们每周会挑选出一位热心小伙伴，送上一份精美的小礼品。快来扫码关注我们吧！</p>\n<p>一行代码，亿万生活。</p>\n<p>网站首页<br>文章存档<br>关于我们</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.oracle.com/technetwork/java/javase/tech/g1-intro-jsp-135488.html\" target=\"_blank\" rel=\"noopener\">https://www.oracle.com/technetwork/java/javase/tech/g1-intro-jsp-135488.html</a><br>先翻译一遍</p>\n<h3 id=\"美团技术文章写得好\"><a href=\"#美团技术文章写得好\" class=\"headerlink\" title=\"美团技术文章写得好\"></a>美团技术文章写得好</h3><p><a href=\"https://tech.meituan.com/g1.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/g1.html</a></p>\n<h3 id=\"这篇文章好像写得也不错\"><a href=\"#这篇文章好像写得也不错\" class=\"headerlink\" title=\"这篇文章好像写得也不错\"></a>这篇文章好像写得也不错</h3><p><a href=\"https://www.cnblogs.com/yunxitalk/p/8987318.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/yunxitalk/p/8987318.html</a></p>\n<h3 id=\"redhat里面的图看上去不错\"><a href=\"#redhat里面的图看上去不错\" class=\"headerlink\" title=\"redhat里面的图看上去不错\"></a>redhat里面的图看上去不错</h3><p><a href=\"https://www.redhat.com/en/blog/part-1-introduction-g1-garbage-collector\" target=\"_blank\" rel=\"noopener\">https://www.redhat.com/en/blog/part-1-introduction-g1-garbage-collector</a><br><a href=\"https://www.redhat.com/en/blog/collecting-and-reading-g1-garbage-collector-logs-part-2\" target=\"_blank\" rel=\"noopener\">https://www.redhat.com/en/blog/collecting-and-reading-g1-garbage-collector-logs-part-2</a></p>\n<h3 id=\"R大不是盖的啊\"><a href=\"#R大不是盖的啊\" class=\"headerlink\" title=\"R大不是盖的啊\"></a>R大不是盖的啊</h3><p><a href=\"https://hllvm-group.iteye.com/group/topic/44381\" target=\"_blank\" rel=\"noopener\">https://hllvm-group.iteye.com/group/topic/44381</a></p>\n<h3 id=\"杜兄的文章写得很不错\"><a href=\"#杜兄的文章写得很不错\" class=\"headerlink\" title=\"杜兄的文章写得很不错\"></a>杜兄的文章写得很不错</h3><p><a href=\"https://www.jianshu.com/p/a3e6a9de7a5d\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/a3e6a9de7a5d</a></p>\n<h3 id=\"Amazon-神PPT，写得很详细\"><a href=\"#Amazon-神PPT，写得很详细\" class=\"headerlink\" title=\"Amazon 神PPT，写得很详细\"></a>Amazon 神PPT，写得很详细</h3><p><a href=\"http://presentations2015.s3.amazonaws.com/40_presentation.pdf\" target=\"_blank\" rel=\"noopener\">http://presentations2015.s3.amazonaws.com/40_presentation.pdf</a></p>\n<h3 id=\"younggc\"><a href=\"#younggc\" class=\"headerlink\" title=\"younggc\"></a>younggc</h3><h4 id=\"First-phase-“Root-Scanning”\"><a href=\"#First-phase-“Root-Scanning”\" class=\"headerlink\" title=\"First phase: “Root Scanning”\"></a>First phase: “Root Scanning”</h4><p>需要STW，从GC root开始扫描存活对象<br>Static and local objects are scanned</p>\n<h4 id=\"Second-phase-“Update-RS”\"><a href=\"#Second-phase-“Update-RS”\" class=\"headerlink\" title=\"Second phase: “Update RS”\"></a>Second phase: “Update RS”</h4><p>在上一轮中，有很多对象修改了引用，被load barrier放入了dirty card queue，需要把这部分的数据拿出来，更新Rset<br>Drains the dirty card queue to update the RS</p>\n<h4 id=\"Third-phase-“Process-RS”\"><a href=\"#Third-phase-“Process-RS”\" class=\"headerlink\" title=\"Third phase: “Process RS”\"></a>Third phase: “Process RS”</h4><p>从GC Root的扫描无法彻底让Region和Region独立工作，需要借助于RSet，从RSet找到从Old区指向当前Region的区域（CardTable）<br>Detect the Eden objects pointed by Old objects</p>\n<h4 id=\"Fourth-phase-“Object-Copy”\"><a href=\"#Fourth-phase-“Object-Copy”\" class=\"headerlink\" title=\"Fourth phase: “Object Copy”\"></a>Fourth phase: “Object Copy”</h4><p>The object graph is traversed<br>Live objects copied to Survivor/Old regions</p>\n<h4 id=\"Fifth-phase-“Reference-Processing”\"><a href=\"#Fifth-phase-“Reference-Processing”\" class=\"headerlink\" title=\"Fifth phase: “Reference Processing”\"></a>Fifth phase: “Reference Processing”</h4><p>Soft, Weak, Phantom, Final, JNI Weak references<br>Always enable -XX:+ParallelRefProcEnabled<br>More details with -XX:+PrintReferenceGC</p>\n<h3 id=\"infoQ\"><a href=\"#infoQ\" class=\"headerlink\" title=\"infoQ\"></a>infoQ</h3><p><a href=\"https://www.infoq.com/articles/tuning-tips-G1-GC\" target=\"_blank\" rel=\"noopener\">https://www.infoq.com/articles/tuning-tips-G1-GC</a></p>\n<p>// VM_operations for the G1 collector.<br>// VM_GC_Operation:<br>//   - VM_CGC_Operation<br>//   - VM_G1CollectFull<br>//   - VM_G1OperationWithAllocRequest<br>//     - VM_G1CollectForAllocation<br>//     - VM_G1IncCollectionPause</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/22591838\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/22591838</a></p>\n<h3 id=\"重要信息\"><a href=\"#重要信息\" class=\"headerlink\" title=\"重要信息\"></a>重要信息</h3><p>G1GC没有提供专门的FullGC，还是使用传统FullGC来对整个堆的垃圾进行收集。</p>\n<h3 id=\"Young-GC的时间预测调用栈\"><a href=\"#Young-GC的时间预测调用栈\" class=\"headerlink\" title=\"Young GC的时间预测调用栈\"></a>Young GC的时间预测调用栈</h3><p>G1DefaultPolicy::predict_base_elapsed_time_ms g1DefaultPolicy.cpp:829<br>G1DefaultPolicy::predict_base_elapsed_time_ms g1DefaultPolicy.cpp:837<br>G1CollectionSet::finalize_young_part g1CollectionSet.cpp:363<br>G1DefaultPolicy::finalize_collection_set g1DefaultPolicy.cpp:1137<br>G1CollectedHeap::do_collection_pause_at_safepoint g1CollectedHeap.cpp:3162<br>VM_G1IncCollectionPause::doit vm_operations_g1.cpp:148<br>VM_Operation::evaluate vm_operations.cpp:66<br>VMThread::evaluate_operation vmThread.cpp:348<br>VMThread::loop vmThread.cpp:470<br>VMThread::run vmThread.cpp:262<br>thread_native_entry os_bsd.cpp:720<br>_pthread_body 0x00007fff74974339<br>_pthread_start 0x00007fff749772a7<br>thread_start 0x00007fff74973445<br><unknown> 0x0000000000000000</unknown></p>\n<h4 id=\"美团文章\"><a href=\"#美团文章\" class=\"headerlink\" title=\"美团文章\"></a>美团文章</h4><p>Java Hotspot G1 GC的一些关键技术<br>2016年09月23日 作者: 小亮 文章链接 18946字 38分钟阅读<br>前言<br>G1 GC，全称Garbage-First Garbage Collector，通过-XX:+UseG1GC参数来启用，作为体验版随着JDK 6u14版本面世，在JDK 7u4版本发行时被正式推出，相信熟悉JVM的同学们都不会对它感到陌生。在JDK 9中，G1被提议设置为默认垃圾收集器（JEP 248）。在官网中，是这样描述G1的： &gt; The Garbage-First (G1) collector is a server-style garbage collector, targeted for multi-processor machines with large memories. It meets garbage collection (GC) pause time goals with a high probability, while achieving high throughput. The G1 garbage collector is fully supported in Oracle JDK 7 update 4 and later releases. The G1 collector is designed for applications that: &gt; * Can operate concurrently with applications threads like the CMS collector. &gt; * Compact free space without lengthy GC induced pause times. &gt; * Need more predictable GC pause durations. &gt; * Do not want to sacrifice a lot of throughput performance. &gt; * Do not require a much larger Java heap.</p>\n<p>从官网的描述中，我们知道G1是一种服务器端的垃圾收集器，应用在多处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集暂停时间的要求。它是专门针对以下应用场景设计的: * 像CMS收集器一样，能与应用程序线程并发执行。 * 整理空闲空间更快。 * 需要GC停顿时间更好预测。 * 不希望牺牲大量的吞吐性能。 * 不需要更大的Java Heap。</p>\n<p>G1收集器的设计目标是取代CMS收集器，它同CMS相比，在以下方面表现的更出色： * G1是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片。 * G1的Stop The World(STW)更可控，G1在停顿时间上添加了预测机制，用户可以指定期望停顿时间。</p>\n<p>有了以上的特性，难怪有人说它是一款驾驭一切的垃圾收集器（G1: One Garbage Collector To Rule Them All）。本文带大家来了解一下G1 GC的一些关键技术，为能正确的使用它，做好理论基础的铺垫。</p>\n<p>G1中几个重要概念<br>在G1的实现过程中，引入了一些新的概念，对于实现高吞吐、没有内存碎片、收集时间可控等功能起到了关键作用。下面我们就一起看一下G1中的这几个重要概念。</p>\n<p>Region<br>传统的GC收集器将连续的内存空间划分为新生代、老年代和永久代（JDK 8去除了永久代，引入了元空间Metaspace），这种划分的特点是各代的存储地址（逻辑地址，下同）是连续的。如下图所示： 传统GC内存布局<br>传统GC内存布局</p>\n<p>而G1的各代存储地址是不连续的，每一代都使用了n个不连续的大小相同的Region，每个Region占有一块连续的虚拟内存地址。如下图所示： g1 GC内存布局<br>g1 GC内存布局</p>\n<p>在上图中，我们注意到还有一些Region标明了H，它代表Humongous，这表示这些Region存储的是巨大对象（humongous object，H-obj），即大小大于等于region一半的对象。H-obj有如下几个特征： * H-obj直接分配到了old gen，防止了反复拷贝移动。 * H-obj在global concurrent marking阶段的cleanup 和 full GC阶段回收。 * 在分配H-obj之前先检查是否超过 initiating heap occupancy percent和the marking threshold, 如果超过的话，就启动global concurrent marking，为的是提早回收，防止 evacuation failures 和 full GC。</p>\n<p>为了减少连续H-objs分配对GC的影响，需要把大对象变为普通的对象，建议增大Region size。</p>\n<p>一个Region的大小可以通过参数-XX:G1HeapRegionSize设定，取值范围从1M到32M，且是2的指数。如果不设定，那么G1会根据Heap大小自动决定。相关的设置代码如下：</p>\n<p>// share/vm/gc_implementation/g1/heapRegion.cpp<br>// Minimum region size; we won’t go lower than that.<br>// We might want to decrease this in the future, to deal with small<br>// heaps a bit more efficiently.<br>#define MIN_REGION_SIZE  (      1024 * 1024 )<br>// Maximum region size; we don’t go higher than that. There’s a good<br>// reason for having an upper bound. We don’t want regions to get too<br>// large, otherwise cleanup’s effectiveness would decrease as there<br>// will be fewer opportunities to find totally empty regions after<br>// marking.<br>#define MAX_REGION_SIZE  ( 32 * 1024 * 1024 )<br>// The automatic region size calculation will try to have around this<br>// many regions in the heap (based on the min heap size).<br>#define TARGET_REGION_NUMBER          2048<br>void HeapRegion::setup_heap_region_size(size_t initial_heap_size, size_t max_heap_size) {<br>  uintx region_size = G1HeapRegionSize;<br>  if (FLAG_IS_DEFAULT(G1HeapRegionSize)) {<br>    size_t average_heap_size = (initial_heap_size + max_heap_size) / 2;<br>    region_size = MAX2(average_heap_size / TARGET_REGION_NUMBER,<br>                       (uintx) MIN_REGION_SIZE);<br>  }<br>  int region_size_log = log2_long((jlong) region_size);<br>  // Recalculate the region size to make sure it’s a power of<br>  // 2. This means that region_size is the largest power of 2 that’s<br>  // &lt;= what we’ve calculated so far.<br>  region_size = ((uintx)1 &lt;&lt; region_size_log);<br>  // Now make sure that we don’t go over or under our limits.<br>  if (region_size &lt; MIN_REGION_SIZE) {<br>    region_size = MIN_REGION_SIZE;<br>  } else if (region_size &gt; MAX_REGION_SIZE) {<br>    region_size = MAX_REGION_SIZE;<br>  }<br>}<br>SATB<br>全称是Snapshot-At-The-Beginning，由字面理解，是GC开始时活着的对象的一个快照。它是通过Root Tracing得到的，作用是维持并发GC的正确性。 那么它是怎么维持并发GC的正确性的呢？根据三色标记算法，我们知道对象存在三种状态： * 白：对象没有被标记到，标记阶段结束后，会被当做垃圾回收掉。 * 灰：对象被标记了，但是它的field还没有被标记或标记完。 * 黑：对象被标记了，且它的所有field也被标记完了。</p>\n<p>由于并发阶段的存在，Mutator和Garbage Collector线程同时对对象进行修改，就会出现白对象漏标的情况，这种情况发生的前提是： * Mutator赋予一个黑对象该白对象的引用。 * Mutator删除了所有从灰对象到该白对象的直接或者间接引用。</p>\n<p>对于第一个条件，在并发标记阶段，如果该白对象是new出来的，并没有被灰对象持有，那么它会不会被漏标呢？Region中有两个top-at-mark-start（TAMS）指针，分别为prevTAMS和nextTAMS。在TAMS以上的对象是新分配的，这是一种隐式的标记。对于在GC时已经存在的白对象，如果它是活着的，它必然会被另一个对象引用，即条件二中的灰对象。如果灰对象到白对象的直接引用或者间接引用被替换了，或者删除了，白对象就会被漏标，从而导致被回收掉，这是非常严重的错误，所以SATB破坏了第二个条件。也就是说，一个对象的引用被替换时，可以通过write barrier 将旧引用记录下来。</p>\n<p>//  share/vm/gc_implementation/g1/g1SATBCardTableModRefBS.hpp<br>// This notes that we don’t need to access any BarrierSet data<br>// structures, so this can be called from a static context.<br>template <class t=\"\"> static void write_ref_field_pre_static(T* field, oop newVal) {<br>  T heap_oop = oopDesc::load_heap_oop(field);<br>  if (!oopDesc::is_null(heap_oop)) {<br>    enqueue(oopDesc::decode_heap_oop(heap_oop));<br>  }<br>}<br>// share/vm/gc_implementation/g1/g1SATBCardTableModRefBS.cpp<br>void G1SATBCardTableModRefBS::enqueue(oop pre_val) {<br>  // Nulls should have been already filtered.<br>  assert(pre_val-&gt;is_oop(true), “Error”);<br>  if (!JavaThread::satb_mark_queue_set().is_active()) return;<br>  Thread* thr = Thread::current();<br>  if (thr-&gt;is_Java_thread()) {<br>    JavaThread* jt = (JavaThread*)thr;<br>    jt-&gt;satb_mark_queue().enqueue(pre_val);<br>  } else {<br>    MutexLockerEx x(Shared_SATB_Q_lock, Mutex::_no_safepoint_check_flag);<br>    JavaThread::satb_mark_queue_set().shared_satb_queue()-&gt;enqueue(pre_val);<br>  }<br>}<br>SATB也是有副作用的，如果被替换的白对象就是要被收集的垃圾，这次的标记会让它躲过GC，这就是float garbage。因为SATB的做法精度比较低，所以造成的float garbage也会比较多。</class></p>\n<p>RSet<br>全称是Remembered Set，是辅助GC过程的一种结构，典型的空间换时间工具，和Card Table有些类似。还有一种数据结构也是辅助GC的：Collection Set（CSet），它记录了GC要收集的Region集合，集合里的Region可以是任意年代的。在GC的时候，对于old-&gt;young和old-&gt;old的跨代对象引用，只要扫描对应的CSet中的RSet即可。 逻辑上说每个Region都有一个RSet，RSet记录了其他Region中的对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）。而Card Table则是一种points-out（我引用了谁的对象）的结构，每个Card 覆盖一定范围的Heap（一般为512Bytes）。G1的RSet是在Card Table的基础上实现的：每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。 这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。</p>\n<p>下图表示了RSet、Card和Region的关系（出处）： Remembered Sets<br>Remembered Sets</p>\n<p>上图中有三个Region，每个Region被分成了多个Card，在不同Region中的Card会相互引用，Region1中的Card中的对象引用了Region2中的Card中的对象，蓝色实线表示的就是points-out的关系，而在Region2的RSet中，记录了Region1的Card，即红色虚线表示的关系，这就是points-into。 而维系RSet中的引用关系靠post-write barrier和Concurrent refinement threads来维护，操作伪代码如下（出处）：</p>\n<p>void oop_field_store(oop* field, oop new_value) {<br>  pre_write_barrier(field);             // pre-write barrier: for maintaining SATB invariant<br>  *field = new_value;                   // the actual store<br>  post_write_barrier(field, new_value); // post-write barrier: for tracking cross-region reference<br>}<br>post-write barrier记录了跨Region的引用更新，更新日志缓冲区则记录了那些包含更新引用的Cards。一旦缓冲区满了，Post-write barrier就停止服务了，会由Concurrent refinement threads处理这些缓冲区日志。 RSet究竟是怎么辅助GC的呢？在做YGC的时候，只需要选定young generation region的RSet作为根集，这些RSet记录了old-&gt;young的跨代引用，避免了扫描整个old generation。 而mixed gc的时候，old generation中记录了old-&gt;old的RSet，young-&gt;old的引用由扫描全部young generation region得到，这样也不用扫描全部old generation region。所以RSet的引入大大减少了GC的工作量。</p>\n<p>Pause Prediction Model<br>Pause Prediction Model 即停顿预测模型。它在G1中的作用是： &gt;G1 uses a pause prediction model to meet a user-defined pause time target and selects the number of regions to collect based on the specified pause time target.</p>\n<p>G1 GC是一个响应时间优先的GC算法，它与CMS最大的不同是，用户可以设定整个GC过程的期望停顿时间，参数-XX:MaxGCPauseMillis指定一个G1收集过程目标停顿时间，默认值200ms，不过它不是硬性条件，只是期望值。那么G1怎么满足用户的期望呢？就需要这个停顿预测模型了。G1根据这个模型统计计算出来的历史数据来预测本次收集需要选择的Region数量，从而尽量满足用户设定的目标停顿时间。 停顿预测模型是以衰减标准偏差为理论基础实现的：</p>\n<p>//  share/vm/gc_implementation/g1/g1CollectorPolicy.hpp<br>double get_new_prediction(TruncatedSeq* seq) {<br>    return MAX2(seq-&gt;davg() + sigma() * seq-&gt;dsd(),<br>                seq-&gt;davg() * confidence_factor(seq-&gt;num()));<br>}<br>在这个预测计算公式中：davg表示衰减均值，sigma()返回一个系数，表示信赖度，dsd表示衰减标准偏差，confidence_factor表示可信度相关系数。而方法的参数TruncateSeq，顾名思义，是一个截断的序列，它只跟踪了序列中的最新的n个元素。</p>\n<p>在G1 GC过程中，每个可测量的步骤花费的时间都会记录到TruncateSeq（继承了AbsSeq）中，用来计算衰减均值、衰减变量，衰减标准偏差等：</p>\n<p>// src/share/vm/utilities/numberSeq.cpp</p>\n<p>void AbsSeq::add(double val) {<br>  if (_num == 0) {<br>    // if the sequence is empty, the davg is the same as the value<br>    _davg = val;<br>    // and the variance is 0<br>    _dvariance = 0.0;<br>  } else {<br>    // otherwise, calculate both<br>    _davg = (1.0 - _alpha) * val + _alpha * _davg;<br>    double diff = val - _davg;<br>    _dvariance = (1.0 - _alpha) * diff * diff + _alpha * _dvariance;<br>  }<br>}<br>比如要预测一次GC过程中，RSet的更新时间，这个操作主要是将Dirty Card加入到RSet中，具体原理参考前面的RSet。每个Dirty Card的时间花费通过_cost_per_card_ms_seq来记录，具体预测代码如下：</p>\n<p>//  share/vm/gc_implementation/g1/g1CollectorPolicy.hpp</p>\n<p> double predict_rs_update_time_ms(size_t pending_cards) {<br>    return (double) pending_cards * predict_cost_per_card_ms();<br> }<br> double predict_cost_per_card_ms() {<br>    return get_new_prediction(_cost_per_card_ms_seq);<br> }<br>get_new_prediction就是我们开头说的方法，现在大家应该基本明白停顿预测模型的实现原理了。</p>\n<p>GC过程<br>讲完了一些基本概念，下面我们就来看看G1的GC过程是怎样的。</p>\n<p>G1 GC模式<br>G1提供了两种GC模式，Young GC和Mixed GC，两种都是完全Stop The World的。 * Young GC：选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC的时间开销。 * Mixed GC：选定所有年轻代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。</p>\n<p>由上面的描述可知，Mixed GC不是full GC，它只能回收部分老年代的Region，如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap。所以我们可以知道，G1是不提供full GC的。</p>\n<p>上文中，多次提到了global concurrent marking，它的执行过程类似CMS，但是不同的是，在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为四个步骤： * 初始标记（initial mark，STW）。它标记了从GC Root开始直接可达的对象。 * 并发标记（Concurrent Marking）。这个阶段从GC Root开始对heap中的对象标记，标记线程与应用程序线程并行执行，并且收集各个Region的存活对象信息。 * 最终标记（Remark，STW）。标记那些在并发标记阶段发生变化的对象，将被回收。 * 清除垃圾（Cleanup）。清除空Region（没有存活对象的），加入到free list。</p>\n<p>第一阶段initial mark是共用了Young GC的暂停，这是因为他们可以复用root scan操作，所以可以说global concurrent marking是伴随Young GC而发生的。第四阶段Cleanup只是回收了没有存活对象的Region，所以它并不需要STW。</p>\n<p>Young GC发生的时机大家都知道，那什么时候发生Mixed GC呢？其实是由一些参数控制着的，另外也控制着哪些老年代Region会被选入CSet。 * G1HeapWastePercent：在global concurrent marking结束之后，我们可以知道old gen regions中有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到此参数，只有达到了，下次才会发生Mixed GC。 * G1MixedGCLiveThresholdPercent：old generation region中的存活对象的占比，只有在此参数之下，才会被选入CSet。 * G1MixedGCCountTarget：一次global concurrent marking之后，最多执行Mixed GC的次数。 * G1OldCSetRegionThresholdPercent：一次Mixed GC中能被选入CSet的最多old generation region数量。</p>\n<p>除了以上的参数，G1 GC相关的其他主要的参数有：</p>\n<p>参数    含义<br>-XX:G1HeapRegionSize=n    设置Region大小，并非最终值<br>-XX:MaxGCPauseMillis    设置G1收集过程目标时间，默认值200ms，不是硬性条件<br>-XX:G1NewSizePercent    新生代最小值，默认值5%<br>-XX:G1MaxNewSizePercent    新生代最大值，默认值60%<br>-XX:ParallelGCThreads    STW期间，并行GC线程数<br>-XX:ConcGCThreads=n    并发标记阶段，并行执行的线程数<br>-XX:InitiatingHeapOccupancyPercent    设置触发标记周期的 Java 堆占用率阈值。默认值是45%。这里的java堆占比指的是non_young_capacity_bytes，包括old+humongous<br>GC日志<br>G1收集器的日志与其他收集器有很大不同，源于G1独立的体系架构和数据结构，下面这两段日志来源于美团点评的CRM系统线上生产环境。</p>\n<p>Young GC日志<br>我们先来看看Young GC的日志：</p>\n<p>{Heap before GC invocations=12 (full 1):<br> garbage-first heap   total 3145728K, used 336645K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000)<br>  region size 1024K, 172 young (176128K), 13 survivors (13312K)<br> Metaspace       used 29944K, capacity 30196K, committed 30464K, reserved 1077248K<br>  class space    used 3391K, capacity 3480K, committed 3584K, reserved 1048576K<br>2014-11-14T17:57:23.654+0800: 27.884: [GC pause (G1 Evacuation Pause) (young)<br>Desired survivor size 11534336 bytes, new threshold 15 (max 15)</p>\n<ul>\n<li>age   1:    5011600 bytes,    5011600 total<br>27.884: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 1461, predicted base time: 35.25 ms, remaining time: 64.75 ms, target pause time: 100.00 ms]<br>27.884: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 159 regions, survivors: 13 regions, predicted young region time: 44.09 ms]<br>27.884: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 159 regions, survivors: 13 regions, old: 0 regions, predicted pause time: 79.34 ms, target pause time: 100.00 ms]<br>, 0.0158389 secs]<br> [Parallel Time: 8.1 ms, GC Workers: 4]<pre><code>[GC Worker Start (ms): Min: 27884.5, Avg: 27884.5, Max: 27884.5, Diff: 0.1]\n[Ext Root Scanning (ms): Min: 0.4, Avg: 0.8, Max: 1.2, Diff: 0.8, Sum: 3.1]\n[Update RS (ms): Min: 0.0, Avg: 0.3, Max: 0.6, Diff: 0.6, Sum: 1.4]\n   [Processed Buffers: Min: 0, Avg: 2.8, Max: 5, Diff: 5, Sum: 11]\n[Scan RS (ms): Min: 0.0, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 0.3]\n[Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.6]\n[Object Copy (ms): Min: 4.9, Avg: 5.1, Max: 5.2, Diff: 0.3, Sum: 20.4]\n[Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n[GC Worker Other (ms): Min: 0.0, Avg: 0.4, Max: 1.3, Diff: 1.3, Sum: 1.4]\n[GC Worker Total (ms): Min: 6.4, Avg: 6.8, Max: 7.8, Diff: 1.4, Sum: 27.2]\n[GC Worker End (ms): Min: 27891.0, Avg: 27891.3, Max: 27892.3, Diff: 1.3]</code></pre> [Code Root Fixup: 0.5 ms]<br> [Code Root Migration: 1.3 ms]<br> [Code Root Purge: 0.0 ms]<br> [Clear CT: 0.2 ms]<br> [Other: 5.8 ms]<pre><code>[Choose CSet: 0.0 ms]\n[Ref Proc: 5.0 ms]\n[Ref Enq: 0.1 ms]\n[Redirty Cards: 0.0 ms]\n[Free CSet: 0.2 ms]</code></pre> [Eden: 159.0M(159.0M)-&gt;0.0B(301.0M) Survivors: 13.0M-&gt;11.0M Heap: 328.8M(3072.0M)-&gt;167.3M(3072.0M)]<br>Heap after GC invocations=13 (full 1):<br>garbage-first heap   total 3145728K, used 171269K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000)<br>region size 1024K, 11 young (11264K), 11 survivors (11264K)<br>Metaspace       used 29944K, capacity 30196K, committed 30464K, reserved 1077248K<br>class space    used 3391K, capacity 3480K, committed 3584K, reserved 1048576K<br>}<br>[Times: user=0.05 sys=0.01, real=0.02 secs]<br>每个过程的作用如下：</li>\n</ul>\n<ul>\n<li><p>garbage-first heap total 3145728K, used 336645K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000) 这行表示使用了G1垃圾收集器，total heap 3145728K，使用了336645K。</p>\n</li>\n<li><p>region size 1024K, 172 young (176128K), 13 survivors (13312K) Region大小为1M，青年代占用了172个（共176128K），幸存区占用了13个（共13312K）。</p>\n</li>\n<li><p>Metaspace used 29944K, capacity 30196K, committed 30464K, reserved 1077248K class space used 3391K, capacity 3480K, committed 3584K, reserved 1048576K java 8的新特性，去掉永久区，添加了元数据区，这块不是本文重点，不再赘述。需要注意的是，之所以有committed和reserved，是因为没有设置MetaspaceSize=MaxMetaspaceSize。 * [GC pause (G1 Evacuation Pause) (young) GC原因，新生代minor GC。</p>\n</li>\n<li><p>[G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 1461, predicted base time: 35.25 ms, remaining time: 64.75 ms, target pause time: 100.00 ms] 发生minor GC和full GC时，所有相关region都是要回收的。而发生并发GC时，会根据目标停顿时间动态选择部分垃圾对并多的Region回收，这一步就是选择Region。_pending_cards是关于RSet的Card Table。predicted base time是预测的扫描card table时间。</p>\n</li>\n<li><p>[G1Ergonomics (CSet Construction) add young regions to CSet, eden: 159 regions, survivors: 13 regions, predicted young region time: 44.09 ms] 这一步是添加Region到collection set，新生代一共159个Region，13个幸存区Region，这也和之前的（172 young (176128K), 13 survivors (13312K)）吻合。预计收集时间是44.09 ms。</p>\n</li>\n<li><p>[G1Ergonomics (CSet Construction) finish choosing CSet, eden: 159 regions, survivors: 13 regions, old: 0 regions, predicted pause time: 79.34 ms, target pause time: 100.00 ms] 这一步是对上面两步的总结。预计总收集时间79.34ms。 * [Parallel Time: 8.1 ms, GC Workers: 4] 由于收集过程是多线程并行（并发）进行，这里是4个线程，总共耗时8.1ms（wall clock time）</p>\n</li>\n<li><p>[GC Worker Start (ms): Min: 27884.5, Avg: 27884.5, Max: 27884.5, Diff: 0.1] 收集线程开始的时间，使用的是相对时间，Min是最早开始时间，Avg是平均开始时间，Max是最晚开始时间，Diff是Max-Min（此处的0.1貌似有问题）</p>\n</li>\n<li><p>[Ext Root Scanning (ms): Min: 0.4, Avg: 0.8, Max: 1.2, Diff: 0.8, Sum: 3.1] 扫描Roots花费的时间，Sum表示total cpu time，下同。</p>\n</li>\n<li><p>[Update RS (ms): Min: 0.0, Avg: 0.3, Max: 0.6, Diff: 0.6, Sum: 1.4] [Processed Buffers: Min: 0, Avg: 2.8, Max: 5, Diff: 5, Sum: 11] Update RS (ms)是每个线程花费在更新Remembered Set上的时间。</p>\n</li>\n<li><p>[Scan RS (ms): Min: 0.0, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 0.3] 扫描CS中的region对应的RSet，因为RSet是points-into，所以这样实现避免了扫描old generadion region，但是会产生float garbage。</p>\n</li>\n<li><p>[Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.6] 扫描code root耗时。code root指的是经过JIT编译后的代码里，引用了heap中的对象。引用关系保存在RSet中。</p>\n</li>\n<li><p>[Object Copy (ms): Min: 4.9, Avg: 5.1, Max: 5.2, Diff: 0.3, Sum: 20.4] 拷贝活的对象到新region的耗时。</p>\n</li>\n<li><p>[Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] 线程结束，在结束前，它会检查其他线程是否还有未扫描完的引用，如果有，则”偷”过来，完成后再申请结束，这个时间是线程之前互相同步所花费的时间。</p>\n</li>\n<li><p>[GC Worker Other (ms): Min: 0.0, Avg: 0.4, Max: 1.3, Diff: 1.3, Sum: 1.4] 花费在其他工作上（未列出）的时间。</p>\n</li>\n<li><p>[GC Worker Total (ms): Min: 6.4, Avg: 6.8, Max: 7.8, Diff: 1.4, Sum: 27.2] 每个线程花费的时间和。</p>\n</li>\n<li><p>[GC Worker End (ms): Min: 27891.0, Avg: 27891.3, Max: 27892.3, Diff: 1.3] 每个线程结束的时间。</p>\n</li>\n<li><p>[Code Root Fixup: 0.5 ms] 用来将code root修正到正确的evacuate之后的对象位置所花费的时间。</p>\n</li>\n<li><p>[Code Root Migration: 1.3 ms] 更新code root 引用的耗时，code root中的引用因为对象的evacuation而需要更新。</p>\n</li>\n<li><p>[Code Root Purge: 0.0 ms] 清除code root的耗时，code root中的引用已经失效，不再指向Region中的对象，所以需要被清除。</p>\n</li>\n<li><p>[Clear CT: 0.2 ms] 清除card table的耗时。</p>\n</li>\n<li><p>[Other: 5.8 ms] [Choose CSet: 0.0 ms] [Ref Proc: 5.0 ms] [Ref Enq: 0.1 ms] [Redirty Cards: 0.0 ms] [Free CSet: 0.2 ms] 其他事项共耗时5.8ms，其他事项包括选择CSet，处理已用对象，引用入ReferenceQueues，释放CSet中的region到free list。</p>\n</li>\n<li><p>[Eden: 159.0M(159.0M)-&gt;0.0B(301.0M) Survivors: 13.0M-&gt;11.0M Heap: 328.8M(3072.0M)-&gt;167.3M(3072.0M)] 新生代清空了，下次扩容到301MB。</p>\n</li>\n</ul>\n<p>global concurrent marking 日志<br>对于global concurrent marking过程，它的日志如下所示：</p>\n<p>66955.252: [G1Ergonomics (Concurrent Cycles) request concurrent cycle initiation, reason: occupancy higher than threshold, occupancy: 1449132032 bytes, allocation request: 579608 bytes, threshold: 1449<br>551430 bytes (45.00 %), source: concurrent humongous allocation]<br>2014-12-10T11:13:09.532+0800: 66955.252: Application time: 2.5750418 seconds<br> 66955.259: [G1Ergonomics (Concurrent Cycles) request concurrent cycle initiation, reason: requested by GC cause, GC cause: G1 Humongous Allocation]<br>{Heap before GC invocations=1874 (full 4):<br> garbage-first heap   total 3145728K, used 1281786K [0x0000000700000000, 0x00000007c0000000, 0x00000007c0000000)<br>  region size 1024K, 171 young (175104K), 27 survivors (27648K)<br> Metaspace       used 116681K, capacity 137645K, committed 137984K, reserved 1171456K<br>  class space    used 13082K, capacity 16290K, committed 16384K, reserved 1048576K<br> 66955.259: [G1Ergonomics (Concurrent Cycles) initiate concurrent cycle, reason: concurrent cycle initiation requested]<br>2014-12-10T11:13:09.539+0800: 66955.259: [GC pause (G1 Humongous Allocation) (young) (initial-mark)<br>…….<br>2014-12-10T11:13:09.597+0800: 66955.317: [GC concurrent-root-region-scan-start]<br>2014-12-10T11:13:09.597+0800: 66955.318: Total time for which application threads were stopped: 0.0655753 seconds<br>2014-12-10T11:13:09.610+0800: 66955.330: Application time: 0.0127071 seconds<br>2014-12-10T11:13:09.614+0800: 66955.335: Total time for which application threads were stopped: 0.0043882 seconds<br>2014-12-10T11:13:09.625+0800: 66955.346: [GC concurrent-root-region-scan-end, 0.0281351 secs]<br>2014-12-10T11:13:09.625+0800: 66955.346: [GC concurrent-mark-start]<br>2014-12-10T11:13:09.645+0800: 66955.365: Application time: 0.0306801 seconds<br>2014-12-10T11:13:09.651+0800: 66955.371: Total time for which application threads were stopped: 0.0061326 seconds<br>2014-12-10T11:13:10.212+0800: 66955.933: [GC concurrent-mark-end, 0.5871129 secs]<br>2014-12-10T11:13:10.212+0800: 66955.933: Application time: 0.5613792 seconds<br>2014-12-10T11:13:10.215+0800: 66955.935: [GC remark 66955.936: [GC ref-proc, 0.0235275 secs], 0.0320865 secs]<br> [Times: user=0.05 sys=0.00, real=0.03 secs]<br>2014-12-10T11:13:10.247+0800: 66955.968: Total time for which application threads were stopped: 0.0350098 seconds<br>2014-12-10T11:13:10.248+0800: 66955.968: Application time: 0.0001691 seconds<br>2014-12-10T11:13:10.250+0800: 66955.970: [GC cleanup 1178M-&gt;632M(3072M), 0.0060632 secs]<br> [Times: user=0.02 sys=0.00, real=0.01 secs]<br>2014-12-10T11:13:10.256+0800: 66955.977: Total time for which application threads were stopped: 0.0088462 seconds<br>2014-12-10T11:13:10.257+0800: 66955.977: [GC concurrent-cleanup-start]<br>2014-12-10T11:13:10.259+0800: 66955.979: [GC concurrent-cleanup-end, 0.0024743 secs<br>这次发生global concurrent marking的原因是：humongous allocation，上面提过在巨大对象分配之前，会检测到old generation 使用占比是否超过了 initiating heap occupancy percent（45%），因为 1449132032(used)+ 579608(allocation request:) &gt; 1449551430(threshold)，所以触发了本次global concurrent marking。对于具体执行过程，上面的表格已经详细讲解了。值得注意的是上文中所说的initial mark往往伴随着一次YGC，在日志中也有体现：GC pause (G1 Humongous Allocation) (young) (initial-mark)。</p>\n<p>后记<br>因为篇幅的关系，也受限于能力水平，本文只是简单了介绍了G1 GC的基本原理，很多细节没有涉及到，所以说只能算是为研究和使用它的同学打开了一扇门。一个日本人专门写了一本书《徹底解剖「G1GC」 アルゴリズ》详细的介绍了G1 GC，这本书也被作者放到了GitHub上，详见参考文献5。另外，莫枢在这方面也研究的比较多，读者可以去高级语言虚拟机论坛向他请教，本文的很多内容也是我在此论坛上请教过后整理的。总而言之，G1是一款非常优秀的垃圾收集器，尽管还有些不完美（预测模型还不够智能），但是希望有更多的同学来使用它，研究它，提出好的建议，让它变的更加完善。</p>\n<p>参考文献<br>Getting Started with the G1 Garbage Collector<br>请教G1算法的原理<br>关于incremental update与SATB的一点理解<br>Tips for Tuning the Garbage First Garbage Collector<br>g1gc-impl-book<br>垃圾优先型垃圾回收器调优<br>Understanding G1 GC Logs<br>G1: One Garbage Collector To Rule Them All<br>系统, 到店, Hotspot, JVM, G1, GC, Java<br>#看看其他前一篇: 美团数据库运维自动化系统构建之路 后一篇: 大促活动前团购系统流量预算和容量评估<br>#一起聊聊<br>如发现文章有错误、对内容有疑问，都可以关注美团技术团队微信公众号（meituantech），在后台给我们留言。</p>\n<p>美团技术团队微信二维码<br>我们每周会挑选出一位热心小伙伴，送上一份精美的小礼品。快来扫码关注我们吧！</p>\n<p>一行代码，亿万生活。</p>\n<p>网站首页<br>文章存档<br>关于我们</p>\n"},{"title":"JVM-GC-SystemGC","date":"2018-12-06T03:23:47.000Z","_content":"\n\nSystem.gc()调用后，JVM不会立刻就触发Full GC。\n\n### 相关参数","source":"_posts/JVM-GC-SystemGC.md","raw":"---\ntitle: JVM-GC-SystemGC\ndate: 2018-12-06 11:23:47\ntags: JVM\n---\n\n\nSystem.gc()调用后，JVM不会立刻就触发Full GC。\n\n### 相关参数","slug":"JVM-GC-SystemGC","published":1,"updated":"2019-09-28T08:51:00.868Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o835001vv1npo9z10au5","content":"<p>System.gc()调用后，JVM不会立刻就触发Full GC。</p>\n<h3 id=\"相关参数\"><a href=\"#相关参数\" class=\"headerlink\" title=\"相关参数\"></a>相关参数</h3>","site":{"data":{}},"excerpt":"","more":"<p>System.gc()调用后，JVM不会立刻就触发Full GC。</p>\n<h3 id=\"相关参数\"><a href=\"#相关参数\" class=\"headerlink\" title=\"相关参数\"></a>相关参数</h3>"},{"title":"JVM-GC-ParNew","date":"2018-11-20T02:37:47.000Z","_content":"\n\n### 动态年龄阈值计算\nhttps://blog.csdn.net/FoolishAndStupid/article/details/77596050\n\n### 疑问\nyoung gc只是会复制存活对象，也就是说需要找到所有活的对象，而不是去找到所有死的对象?\n\n### young gc 过程\n```\nvoid ParNewGeneration::collect(bool   full,\n                               bool   clear_all_soft_refs,\n                               size_t size,\n                               bool   is_tlab) {\n  assert(full || size > 0, \"otherwise we don't want to collect\");\n\n  GenCollectedHeap* gch = GenCollectedHeap::heap();\n\n  _gc_timer->register_gc_start();\n\n  AdaptiveSizePolicy* size_policy = gch->gen_policy()->size_policy();\n  WorkGang* workers = gch->workers();\n  assert(workers != NULL, \"Need workgang for parallel work\");\n  uint active_workers =\n       AdaptiveSizePolicy::calc_active_workers(workers->total_workers(),\n                                               workers->active_workers(),\n                                               Threads::number_of_non_daemon_threads());\n  active_workers = workers->update_active_workers(active_workers);\n  log_info(gc,task)(\"Using %u workers of %u for evacuation\", active_workers, workers->total_workers());\n\n  _old_gen = gch->old_gen();\n\n  // If the next generation is too full to accommodate worst-case promotion\n  // from this generation, pass on collection; let the next generation\n  // do it.\n  if (!collection_attempt_is_safe()) {\n    gch->set_incremental_collection_failed();  // slight lie, in that we did not even attempt one\n    return;\n  }\n  assert(to()->is_empty(), \"Else not collection_attempt_is_safe\");\n\n  _gc_tracer.report_gc_start(gch->gc_cause(), _gc_timer->gc_start());\n  gch->trace_heap_before_gc(gc_tracer());\n\n  init_assuming_no_promotion_failure();\n\n  if (UseAdaptiveSizePolicy) {\n    set_survivor_overflow(false);\n    size_policy->minor_collection_begin();\n  }\n\n  GCTraceTime(Trace, gc, phases) t1(\"ParNew\", NULL, gch->gc_cause());\n\n  age_table()->clear();\n  to()->clear(SpaceDecorator::Mangle);\n\n  gch->save_marks();\n\n  // Set the correct parallelism (number of queues) in the reference processor\n  ref_processor()->set_active_mt_degree(active_workers);\n\n  // Need to initialize the preserved marks before the ThreadStateSet c'tor.\n  _preserved_marks_set.init(active_workers);\n\n  // Always set the terminator for the active number of workers\n  // because only those workers go through the termination protocol.\n  ParallelTaskTerminator _term(active_workers, task_queues());\n  ParScanThreadStateSet thread_state_set(active_workers,\n                                         *to(), *this, *_old_gen, *task_queues(),\n                                         _overflow_stacks, _preserved_marks_set,\n                                         desired_plab_sz(), _term);\n\n  thread_state_set.reset(active_workers, promotion_failed());\n\n  {\n    StrongRootsScope srs(active_workers);\n\n    ParNewGenTask tsk(this, _old_gen, reserved().end(), &thread_state_set, &srs);\n    gch->rem_set()->prepare_for_younger_refs_iterate(true);\n    // It turns out that even when we're using 1 thread, doing the work in a\n    // separate thread causes wide variance in run times.  We can't help this\n    // in the multi-threaded case, but we special-case n=1 here to get\n    // repeatable measurements of the 1-thread overhead of the parallel code.\n    // Might multiple workers ever be used?  If yes, initialization\n    // has been done such that the single threaded path should not be used.\n    if (workers->total_workers() > 1) {\n      workers->run_task(&tsk);\n    } else {\n      tsk.work(0);\n    }\n  }\n\n  thread_state_set.reset(0 /* Bad value in debug if not reset */,\n                         promotion_failed());\n\n  // Trace and reset failed promotion info.\n  if (promotion_failed()) {\n    thread_state_set.trace_promotion_failed(gc_tracer());\n  }\n\n  // Process (weak) reference objects found during scavenge.\n  ReferenceProcessor* rp = ref_processor();\n  IsAliveClosure is_alive(this);\n  ScanWeakRefClosure scan_weak_ref(this);\n  KeepAliveClosure keep_alive(&scan_weak_ref);\n  ScanClosure               scan_without_gc_barrier(this, false);\n  ScanClosureWithParBarrier scan_with_gc_barrier(this, true);\n  set_promo_failure_scan_stack_closure(&scan_without_gc_barrier);\n  EvacuateFollowersClosureGeneral evacuate_followers(gch,\n    &scan_without_gc_barrier, &scan_with_gc_barrier);\n  rp->setup_policy(clear_all_soft_refs);\n  // Can  the mt_degree be set later (at run_task() time would be best)?\n  rp->set_active_mt_degree(active_workers);\n  ReferenceProcessorStats stats;\n  if (rp->processing_is_mt()) {\n    ParNewRefProcTaskExecutor task_executor(*this, *_old_gen, thread_state_set);\n    stats = rp->process_discovered_references(&is_alive, &keep_alive,\n                                              &evacuate_followers, &task_executor,\n                                              _gc_timer);\n  } else {\n    thread_state_set.flush();\n    gch->save_marks();\n    stats = rp->process_discovered_references(&is_alive, &keep_alive,\n                                              &evacuate_followers, NULL,\n                                              _gc_timer);\n  }\n  _gc_tracer.report_gc_reference_stats(stats);\n  _gc_tracer.report_tenuring_threshold(tenuring_threshold());\n\n  if (!promotion_failed()) {\n    // Swap the survivor spaces.\n    eden()->clear(SpaceDecorator::Mangle);\n    from()->clear(SpaceDecorator::Mangle);\n    if (ZapUnusedHeapArea) {\n      // This is now done here because of the piece-meal mangling which\n      // can check for valid mangling at intermediate points in the\n      // collection(s).  When a young collection fails to collect\n      // sufficient space resizing of the young generation can occur\n      // and redistribute the spaces in the young generation.  Mangle\n      // here so that unzapped regions don't get distributed to\n      // other spaces.\n      to()->mangle_unused_area();\n    }\n    swap_spaces();\n\n    // A successful scavenge should restart the GC time limit count which is\n    // for full GC's.\n    size_policy->reset_gc_overhead_limit_count();\n\n    assert(to()->is_empty(), \"to space should be empty now\");\n\n    adjust_desired_tenuring_threshold();\n  } else {\n    handle_promotion_failed(gch, thread_state_set);\n  }\n  _preserved_marks_set.reclaim();\n  // set new iteration safe limit for the survivor spaces\n  from()->set_concurrent_iteration_safe_limit(from()->top());\n  to()->set_concurrent_iteration_safe_limit(to()->top());\n\n  plab_stats()->adjust_desired_plab_sz();\n\n  TASKQUEUE_STATS_ONLY(thread_state_set.print_termination_stats());\n  TASKQUEUE_STATS_ONLY(thread_state_set.print_taskqueue_stats());\n\n  if (UseAdaptiveSizePolicy) {\n    size_policy->minor_collection_end(gch->gc_cause());\n    size_policy->avg_survived()->sample(from()->used());\n  }\n\n  // We need to use a monotonically non-decreasing time in ms\n  // or we will see time-warp warnings and os::javaTimeMillis()\n  // does not guarantee monotonicity.\n  jlong now = os::javaTimeNanos() / NANOSECS_PER_MILLISEC;\n  update_time_of_last_gc(now);\n\n  rp->set_enqueuing_is_done(true);\n  if (rp->processing_is_mt()) {\n    ParNewRefProcTaskExecutor task_executor(*this, *_old_gen, thread_state_set);\n    rp->enqueue_discovered_references(&task_executor);\n  } else {\n    rp->enqueue_discovered_references(NULL);\n  }\n  rp->verify_no_references_recorded();\n\n  gch->trace_heap_after_gc(gc_tracer());\n\n  _gc_timer->register_gc_end();\n\n  _gc_tracer.report_gc_end(_gc_timer->gc_end(), _gc_timer->time_partitions());\n}\n\n```","source":"_posts/JVM-GC-ParNew.md","raw":"---\ntitle: JVM-GC-ParNew\ndate: 2018-11-20 10:37:47\ntags: JVM\n---\n\n\n### 动态年龄阈值计算\nhttps://blog.csdn.net/FoolishAndStupid/article/details/77596050\n\n### 疑问\nyoung gc只是会复制存活对象，也就是说需要找到所有活的对象，而不是去找到所有死的对象?\n\n### young gc 过程\n```\nvoid ParNewGeneration::collect(bool   full,\n                               bool   clear_all_soft_refs,\n                               size_t size,\n                               bool   is_tlab) {\n  assert(full || size > 0, \"otherwise we don't want to collect\");\n\n  GenCollectedHeap* gch = GenCollectedHeap::heap();\n\n  _gc_timer->register_gc_start();\n\n  AdaptiveSizePolicy* size_policy = gch->gen_policy()->size_policy();\n  WorkGang* workers = gch->workers();\n  assert(workers != NULL, \"Need workgang for parallel work\");\n  uint active_workers =\n       AdaptiveSizePolicy::calc_active_workers(workers->total_workers(),\n                                               workers->active_workers(),\n                                               Threads::number_of_non_daemon_threads());\n  active_workers = workers->update_active_workers(active_workers);\n  log_info(gc,task)(\"Using %u workers of %u for evacuation\", active_workers, workers->total_workers());\n\n  _old_gen = gch->old_gen();\n\n  // If the next generation is too full to accommodate worst-case promotion\n  // from this generation, pass on collection; let the next generation\n  // do it.\n  if (!collection_attempt_is_safe()) {\n    gch->set_incremental_collection_failed();  // slight lie, in that we did not even attempt one\n    return;\n  }\n  assert(to()->is_empty(), \"Else not collection_attempt_is_safe\");\n\n  _gc_tracer.report_gc_start(gch->gc_cause(), _gc_timer->gc_start());\n  gch->trace_heap_before_gc(gc_tracer());\n\n  init_assuming_no_promotion_failure();\n\n  if (UseAdaptiveSizePolicy) {\n    set_survivor_overflow(false);\n    size_policy->minor_collection_begin();\n  }\n\n  GCTraceTime(Trace, gc, phases) t1(\"ParNew\", NULL, gch->gc_cause());\n\n  age_table()->clear();\n  to()->clear(SpaceDecorator::Mangle);\n\n  gch->save_marks();\n\n  // Set the correct parallelism (number of queues) in the reference processor\n  ref_processor()->set_active_mt_degree(active_workers);\n\n  // Need to initialize the preserved marks before the ThreadStateSet c'tor.\n  _preserved_marks_set.init(active_workers);\n\n  // Always set the terminator for the active number of workers\n  // because only those workers go through the termination protocol.\n  ParallelTaskTerminator _term(active_workers, task_queues());\n  ParScanThreadStateSet thread_state_set(active_workers,\n                                         *to(), *this, *_old_gen, *task_queues(),\n                                         _overflow_stacks, _preserved_marks_set,\n                                         desired_plab_sz(), _term);\n\n  thread_state_set.reset(active_workers, promotion_failed());\n\n  {\n    StrongRootsScope srs(active_workers);\n\n    ParNewGenTask tsk(this, _old_gen, reserved().end(), &thread_state_set, &srs);\n    gch->rem_set()->prepare_for_younger_refs_iterate(true);\n    // It turns out that even when we're using 1 thread, doing the work in a\n    // separate thread causes wide variance in run times.  We can't help this\n    // in the multi-threaded case, but we special-case n=1 here to get\n    // repeatable measurements of the 1-thread overhead of the parallel code.\n    // Might multiple workers ever be used?  If yes, initialization\n    // has been done such that the single threaded path should not be used.\n    if (workers->total_workers() > 1) {\n      workers->run_task(&tsk);\n    } else {\n      tsk.work(0);\n    }\n  }\n\n  thread_state_set.reset(0 /* Bad value in debug if not reset */,\n                         promotion_failed());\n\n  // Trace and reset failed promotion info.\n  if (promotion_failed()) {\n    thread_state_set.trace_promotion_failed(gc_tracer());\n  }\n\n  // Process (weak) reference objects found during scavenge.\n  ReferenceProcessor* rp = ref_processor();\n  IsAliveClosure is_alive(this);\n  ScanWeakRefClosure scan_weak_ref(this);\n  KeepAliveClosure keep_alive(&scan_weak_ref);\n  ScanClosure               scan_without_gc_barrier(this, false);\n  ScanClosureWithParBarrier scan_with_gc_barrier(this, true);\n  set_promo_failure_scan_stack_closure(&scan_without_gc_barrier);\n  EvacuateFollowersClosureGeneral evacuate_followers(gch,\n    &scan_without_gc_barrier, &scan_with_gc_barrier);\n  rp->setup_policy(clear_all_soft_refs);\n  // Can  the mt_degree be set later (at run_task() time would be best)?\n  rp->set_active_mt_degree(active_workers);\n  ReferenceProcessorStats stats;\n  if (rp->processing_is_mt()) {\n    ParNewRefProcTaskExecutor task_executor(*this, *_old_gen, thread_state_set);\n    stats = rp->process_discovered_references(&is_alive, &keep_alive,\n                                              &evacuate_followers, &task_executor,\n                                              _gc_timer);\n  } else {\n    thread_state_set.flush();\n    gch->save_marks();\n    stats = rp->process_discovered_references(&is_alive, &keep_alive,\n                                              &evacuate_followers, NULL,\n                                              _gc_timer);\n  }\n  _gc_tracer.report_gc_reference_stats(stats);\n  _gc_tracer.report_tenuring_threshold(tenuring_threshold());\n\n  if (!promotion_failed()) {\n    // Swap the survivor spaces.\n    eden()->clear(SpaceDecorator::Mangle);\n    from()->clear(SpaceDecorator::Mangle);\n    if (ZapUnusedHeapArea) {\n      // This is now done here because of the piece-meal mangling which\n      // can check for valid mangling at intermediate points in the\n      // collection(s).  When a young collection fails to collect\n      // sufficient space resizing of the young generation can occur\n      // and redistribute the spaces in the young generation.  Mangle\n      // here so that unzapped regions don't get distributed to\n      // other spaces.\n      to()->mangle_unused_area();\n    }\n    swap_spaces();\n\n    // A successful scavenge should restart the GC time limit count which is\n    // for full GC's.\n    size_policy->reset_gc_overhead_limit_count();\n\n    assert(to()->is_empty(), \"to space should be empty now\");\n\n    adjust_desired_tenuring_threshold();\n  } else {\n    handle_promotion_failed(gch, thread_state_set);\n  }\n  _preserved_marks_set.reclaim();\n  // set new iteration safe limit for the survivor spaces\n  from()->set_concurrent_iteration_safe_limit(from()->top());\n  to()->set_concurrent_iteration_safe_limit(to()->top());\n\n  plab_stats()->adjust_desired_plab_sz();\n\n  TASKQUEUE_STATS_ONLY(thread_state_set.print_termination_stats());\n  TASKQUEUE_STATS_ONLY(thread_state_set.print_taskqueue_stats());\n\n  if (UseAdaptiveSizePolicy) {\n    size_policy->minor_collection_end(gch->gc_cause());\n    size_policy->avg_survived()->sample(from()->used());\n  }\n\n  // We need to use a monotonically non-decreasing time in ms\n  // or we will see time-warp warnings and os::javaTimeMillis()\n  // does not guarantee monotonicity.\n  jlong now = os::javaTimeNanos() / NANOSECS_PER_MILLISEC;\n  update_time_of_last_gc(now);\n\n  rp->set_enqueuing_is_done(true);\n  if (rp->processing_is_mt()) {\n    ParNewRefProcTaskExecutor task_executor(*this, *_old_gen, thread_state_set);\n    rp->enqueue_discovered_references(&task_executor);\n  } else {\n    rp->enqueue_discovered_references(NULL);\n  }\n  rp->verify_no_references_recorded();\n\n  gch->trace_heap_after_gc(gc_tracer());\n\n  _gc_timer->register_gc_end();\n\n  _gc_tracer.report_gc_end(_gc_timer->gc_end(), _gc_timer->time_partitions());\n}\n\n```","slug":"JVM-GC-ParNew","published":1,"updated":"2019-09-28T08:51:00.868Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o835001wv1np8ia04f4k","content":"<h3 id=\"动态年龄阈值计算\"><a href=\"#动态年龄阈值计算\" class=\"headerlink\" title=\"动态年龄阈值计算\"></a>动态年龄阈值计算</h3><p><a href=\"https://blog.csdn.net/FoolishAndStupid/article/details/77596050\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/FoolishAndStupid/article/details/77596050</a></p>\n<h3 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h3><p>young gc只是会复制存活对象，也就是说需要找到所有活的对象，而不是去找到所有死的对象?</p>\n<h3 id=\"young-gc-过程\"><a href=\"#young-gc-过程\" class=\"headerlink\" title=\"young gc 过程\"></a>young gc 过程</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void ParNewGeneration::collect(bool   full,</span><br><span class=\"line\">                               bool   clear_all_soft_refs,</span><br><span class=\"line\">                               size_t size,</span><br><span class=\"line\">                               bool   is_tlab) &#123;</span><br><span class=\"line\">  assert(full || size &gt; 0, &quot;otherwise we don&apos;t want to collect&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">  GenCollectedHeap* gch = GenCollectedHeap::heap();</span><br><span class=\"line\"></span><br><span class=\"line\">  _gc_timer-&gt;register_gc_start();</span><br><span class=\"line\"></span><br><span class=\"line\">  AdaptiveSizePolicy* size_policy = gch-&gt;gen_policy()-&gt;size_policy();</span><br><span class=\"line\">  WorkGang* workers = gch-&gt;workers();</span><br><span class=\"line\">  assert(workers != NULL, &quot;Need workgang for parallel work&quot;);</span><br><span class=\"line\">  uint active_workers =</span><br><span class=\"line\">       AdaptiveSizePolicy::calc_active_workers(workers-&gt;total_workers(),</span><br><span class=\"line\">                                               workers-&gt;active_workers(),</span><br><span class=\"line\">                                               Threads::number_of_non_daemon_threads());</span><br><span class=\"line\">  active_workers = workers-&gt;update_active_workers(active_workers);</span><br><span class=\"line\">  log_info(gc,task)(&quot;Using %u workers of %u for evacuation&quot;, active_workers, workers-&gt;total_workers());</span><br><span class=\"line\"></span><br><span class=\"line\">  _old_gen = gch-&gt;old_gen();</span><br><span class=\"line\"></span><br><span class=\"line\">  // If the next generation is too full to accommodate worst-case promotion</span><br><span class=\"line\">  // from this generation, pass on collection; let the next generation</span><br><span class=\"line\">  // do it.</span><br><span class=\"line\">  if (!collection_attempt_is_safe()) &#123;</span><br><span class=\"line\">    gch-&gt;set_incremental_collection_failed();  // slight lie, in that we did not even attempt one</span><br><span class=\"line\">    return;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  assert(to()-&gt;is_empty(), &quot;Else not collection_attempt_is_safe&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">  _gc_tracer.report_gc_start(gch-&gt;gc_cause(), _gc_timer-&gt;gc_start());</span><br><span class=\"line\">  gch-&gt;trace_heap_before_gc(gc_tracer());</span><br><span class=\"line\"></span><br><span class=\"line\">  init_assuming_no_promotion_failure();</span><br><span class=\"line\"></span><br><span class=\"line\">  if (UseAdaptiveSizePolicy) &#123;</span><br><span class=\"line\">    set_survivor_overflow(false);</span><br><span class=\"line\">    size_policy-&gt;minor_collection_begin();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  GCTraceTime(Trace, gc, phases) t1(&quot;ParNew&quot;, NULL, gch-&gt;gc_cause());</span><br><span class=\"line\"></span><br><span class=\"line\">  age_table()-&gt;clear();</span><br><span class=\"line\">  to()-&gt;clear(SpaceDecorator::Mangle);</span><br><span class=\"line\"></span><br><span class=\"line\">  gch-&gt;save_marks();</span><br><span class=\"line\"></span><br><span class=\"line\">  // Set the correct parallelism (number of queues) in the reference processor</span><br><span class=\"line\">  ref_processor()-&gt;set_active_mt_degree(active_workers);</span><br><span class=\"line\"></span><br><span class=\"line\">  // Need to initialize the preserved marks before the ThreadStateSet c&apos;tor.</span><br><span class=\"line\">  _preserved_marks_set.init(active_workers);</span><br><span class=\"line\"></span><br><span class=\"line\">  // Always set the terminator for the active number of workers</span><br><span class=\"line\">  // because only those workers go through the termination protocol.</span><br><span class=\"line\">  ParallelTaskTerminator _term(active_workers, task_queues());</span><br><span class=\"line\">  ParScanThreadStateSet thread_state_set(active_workers,</span><br><span class=\"line\">                                         *to(), *this, *_old_gen, *task_queues(),</span><br><span class=\"line\">                                         _overflow_stacks, _preserved_marks_set,</span><br><span class=\"line\">                                         desired_plab_sz(), _term);</span><br><span class=\"line\"></span><br><span class=\"line\">  thread_state_set.reset(active_workers, promotion_failed());</span><br><span class=\"line\"></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    StrongRootsScope srs(active_workers);</span><br><span class=\"line\"></span><br><span class=\"line\">    ParNewGenTask tsk(this, _old_gen, reserved().end(), &amp;thread_state_set, &amp;srs);</span><br><span class=\"line\">    gch-&gt;rem_set()-&gt;prepare_for_younger_refs_iterate(true);</span><br><span class=\"line\">    // It turns out that even when we&apos;re using 1 thread, doing the work in a</span><br><span class=\"line\">    // separate thread causes wide variance in run times.  We can&apos;t help this</span><br><span class=\"line\">    // in the multi-threaded case, but we special-case n=1 here to get</span><br><span class=\"line\">    // repeatable measurements of the 1-thread overhead of the parallel code.</span><br><span class=\"line\">    // Might multiple workers ever be used?  If yes, initialization</span><br><span class=\"line\">    // has been done such that the single threaded path should not be used.</span><br><span class=\"line\">    if (workers-&gt;total_workers() &gt; 1) &#123;</span><br><span class=\"line\">      workers-&gt;run_task(&amp;tsk);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      tsk.work(0);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  thread_state_set.reset(0 /* Bad value in debug if not reset */,</span><br><span class=\"line\">                         promotion_failed());</span><br><span class=\"line\"></span><br><span class=\"line\">  // Trace and reset failed promotion info.</span><br><span class=\"line\">  if (promotion_failed()) &#123;</span><br><span class=\"line\">    thread_state_set.trace_promotion_failed(gc_tracer());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // Process (weak) reference objects found during scavenge.</span><br><span class=\"line\">  ReferenceProcessor* rp = ref_processor();</span><br><span class=\"line\">  IsAliveClosure is_alive(this);</span><br><span class=\"line\">  ScanWeakRefClosure scan_weak_ref(this);</span><br><span class=\"line\">  KeepAliveClosure keep_alive(&amp;scan_weak_ref);</span><br><span class=\"line\">  ScanClosure               scan_without_gc_barrier(this, false);</span><br><span class=\"line\">  ScanClosureWithParBarrier scan_with_gc_barrier(this, true);</span><br><span class=\"line\">  set_promo_failure_scan_stack_closure(&amp;scan_without_gc_barrier);</span><br><span class=\"line\">  EvacuateFollowersClosureGeneral evacuate_followers(gch,</span><br><span class=\"line\">    &amp;scan_without_gc_barrier, &amp;scan_with_gc_barrier);</span><br><span class=\"line\">  rp-&gt;setup_policy(clear_all_soft_refs);</span><br><span class=\"line\">  // Can  the mt_degree be set later (at run_task() time would be best)?</span><br><span class=\"line\">  rp-&gt;set_active_mt_degree(active_workers);</span><br><span class=\"line\">  ReferenceProcessorStats stats;</span><br><span class=\"line\">  if (rp-&gt;processing_is_mt()) &#123;</span><br><span class=\"line\">    ParNewRefProcTaskExecutor task_executor(*this, *_old_gen, thread_state_set);</span><br><span class=\"line\">    stats = rp-&gt;process_discovered_references(&amp;is_alive, &amp;keep_alive,</span><br><span class=\"line\">                                              &amp;evacuate_followers, &amp;task_executor,</span><br><span class=\"line\">                                              _gc_timer);</span><br><span class=\"line\">  &#125; else &#123;</span><br><span class=\"line\">    thread_state_set.flush();</span><br><span class=\"line\">    gch-&gt;save_marks();</span><br><span class=\"line\">    stats = rp-&gt;process_discovered_references(&amp;is_alive, &amp;keep_alive,</span><br><span class=\"line\">                                              &amp;evacuate_followers, NULL,</span><br><span class=\"line\">                                              _gc_timer);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  _gc_tracer.report_gc_reference_stats(stats);</span><br><span class=\"line\">  _gc_tracer.report_tenuring_threshold(tenuring_threshold());</span><br><span class=\"line\"></span><br><span class=\"line\">  if (!promotion_failed()) &#123;</span><br><span class=\"line\">    // Swap the survivor spaces.</span><br><span class=\"line\">    eden()-&gt;clear(SpaceDecorator::Mangle);</span><br><span class=\"line\">    from()-&gt;clear(SpaceDecorator::Mangle);</span><br><span class=\"line\">    if (ZapUnusedHeapArea) &#123;</span><br><span class=\"line\">      // This is now done here because of the piece-meal mangling which</span><br><span class=\"line\">      // can check for valid mangling at intermediate points in the</span><br><span class=\"line\">      // collection(s).  When a young collection fails to collect</span><br><span class=\"line\">      // sufficient space resizing of the young generation can occur</span><br><span class=\"line\">      // and redistribute the spaces in the young generation.  Mangle</span><br><span class=\"line\">      // here so that unzapped regions don&apos;t get distributed to</span><br><span class=\"line\">      // other spaces.</span><br><span class=\"line\">      to()-&gt;mangle_unused_area();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    swap_spaces();</span><br><span class=\"line\"></span><br><span class=\"line\">    // A successful scavenge should restart the GC time limit count which is</span><br><span class=\"line\">    // for full GC&apos;s.</span><br><span class=\"line\">    size_policy-&gt;reset_gc_overhead_limit_count();</span><br><span class=\"line\"></span><br><span class=\"line\">    assert(to()-&gt;is_empty(), &quot;to space should be empty now&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    adjust_desired_tenuring_threshold();</span><br><span class=\"line\">  &#125; else &#123;</span><br><span class=\"line\">    handle_promotion_failed(gch, thread_state_set);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  _preserved_marks_set.reclaim();</span><br><span class=\"line\">  // set new iteration safe limit for the survivor spaces</span><br><span class=\"line\">  from()-&gt;set_concurrent_iteration_safe_limit(from()-&gt;top());</span><br><span class=\"line\">  to()-&gt;set_concurrent_iteration_safe_limit(to()-&gt;top());</span><br><span class=\"line\"></span><br><span class=\"line\">  plab_stats()-&gt;adjust_desired_plab_sz();</span><br><span class=\"line\"></span><br><span class=\"line\">  TASKQUEUE_STATS_ONLY(thread_state_set.print_termination_stats());</span><br><span class=\"line\">  TASKQUEUE_STATS_ONLY(thread_state_set.print_taskqueue_stats());</span><br><span class=\"line\"></span><br><span class=\"line\">  if (UseAdaptiveSizePolicy) &#123;</span><br><span class=\"line\">    size_policy-&gt;minor_collection_end(gch-&gt;gc_cause());</span><br><span class=\"line\">    size_policy-&gt;avg_survived()-&gt;sample(from()-&gt;used());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // We need to use a monotonically non-decreasing time in ms</span><br><span class=\"line\">  // or we will see time-warp warnings and os::javaTimeMillis()</span><br><span class=\"line\">  // does not guarantee monotonicity.</span><br><span class=\"line\">  jlong now = os::javaTimeNanos() / NANOSECS_PER_MILLISEC;</span><br><span class=\"line\">  update_time_of_last_gc(now);</span><br><span class=\"line\"></span><br><span class=\"line\">  rp-&gt;set_enqueuing_is_done(true);</span><br><span class=\"line\">  if (rp-&gt;processing_is_mt()) &#123;</span><br><span class=\"line\">    ParNewRefProcTaskExecutor task_executor(*this, *_old_gen, thread_state_set);</span><br><span class=\"line\">    rp-&gt;enqueue_discovered_references(&amp;task_executor);</span><br><span class=\"line\">  &#125; else &#123;</span><br><span class=\"line\">    rp-&gt;enqueue_discovered_references(NULL);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  rp-&gt;verify_no_references_recorded();</span><br><span class=\"line\"></span><br><span class=\"line\">  gch-&gt;trace_heap_after_gc(gc_tracer());</span><br><span class=\"line\"></span><br><span class=\"line\">  _gc_timer-&gt;register_gc_end();</span><br><span class=\"line\"></span><br><span class=\"line\">  _gc_tracer.report_gc_end(_gc_timer-&gt;gc_end(), _gc_timer-&gt;time_partitions());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"动态年龄阈值计算\"><a href=\"#动态年龄阈值计算\" class=\"headerlink\" title=\"动态年龄阈值计算\"></a>动态年龄阈值计算</h3><p><a href=\"https://blog.csdn.net/FoolishAndStupid/article/details/77596050\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/FoolishAndStupid/article/details/77596050</a></p>\n<h3 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h3><p>young gc只是会复制存活对象，也就是说需要找到所有活的对象，而不是去找到所有死的对象?</p>\n<h3 id=\"young-gc-过程\"><a href=\"#young-gc-过程\" class=\"headerlink\" title=\"young gc 过程\"></a>young gc 过程</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void ParNewGeneration::collect(bool   full,</span><br><span class=\"line\">                               bool   clear_all_soft_refs,</span><br><span class=\"line\">                               size_t size,</span><br><span class=\"line\">                               bool   is_tlab) &#123;</span><br><span class=\"line\">  assert(full || size &gt; 0, &quot;otherwise we don&apos;t want to collect&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">  GenCollectedHeap* gch = GenCollectedHeap::heap();</span><br><span class=\"line\"></span><br><span class=\"line\">  _gc_timer-&gt;register_gc_start();</span><br><span class=\"line\"></span><br><span class=\"line\">  AdaptiveSizePolicy* size_policy = gch-&gt;gen_policy()-&gt;size_policy();</span><br><span class=\"line\">  WorkGang* workers = gch-&gt;workers();</span><br><span class=\"line\">  assert(workers != NULL, &quot;Need workgang for parallel work&quot;);</span><br><span class=\"line\">  uint active_workers =</span><br><span class=\"line\">       AdaptiveSizePolicy::calc_active_workers(workers-&gt;total_workers(),</span><br><span class=\"line\">                                               workers-&gt;active_workers(),</span><br><span class=\"line\">                                               Threads::number_of_non_daemon_threads());</span><br><span class=\"line\">  active_workers = workers-&gt;update_active_workers(active_workers);</span><br><span class=\"line\">  log_info(gc,task)(&quot;Using %u workers of %u for evacuation&quot;, active_workers, workers-&gt;total_workers());</span><br><span class=\"line\"></span><br><span class=\"line\">  _old_gen = gch-&gt;old_gen();</span><br><span class=\"line\"></span><br><span class=\"line\">  // If the next generation is too full to accommodate worst-case promotion</span><br><span class=\"line\">  // from this generation, pass on collection; let the next generation</span><br><span class=\"line\">  // do it.</span><br><span class=\"line\">  if (!collection_attempt_is_safe()) &#123;</span><br><span class=\"line\">    gch-&gt;set_incremental_collection_failed();  // slight lie, in that we did not even attempt one</span><br><span class=\"line\">    return;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  assert(to()-&gt;is_empty(), &quot;Else not collection_attempt_is_safe&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">  _gc_tracer.report_gc_start(gch-&gt;gc_cause(), _gc_timer-&gt;gc_start());</span><br><span class=\"line\">  gch-&gt;trace_heap_before_gc(gc_tracer());</span><br><span class=\"line\"></span><br><span class=\"line\">  init_assuming_no_promotion_failure();</span><br><span class=\"line\"></span><br><span class=\"line\">  if (UseAdaptiveSizePolicy) &#123;</span><br><span class=\"line\">    set_survivor_overflow(false);</span><br><span class=\"line\">    size_policy-&gt;minor_collection_begin();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  GCTraceTime(Trace, gc, phases) t1(&quot;ParNew&quot;, NULL, gch-&gt;gc_cause());</span><br><span class=\"line\"></span><br><span class=\"line\">  age_table()-&gt;clear();</span><br><span class=\"line\">  to()-&gt;clear(SpaceDecorator::Mangle);</span><br><span class=\"line\"></span><br><span class=\"line\">  gch-&gt;save_marks();</span><br><span class=\"line\"></span><br><span class=\"line\">  // Set the correct parallelism (number of queues) in the reference processor</span><br><span class=\"line\">  ref_processor()-&gt;set_active_mt_degree(active_workers);</span><br><span class=\"line\"></span><br><span class=\"line\">  // Need to initialize the preserved marks before the ThreadStateSet c&apos;tor.</span><br><span class=\"line\">  _preserved_marks_set.init(active_workers);</span><br><span class=\"line\"></span><br><span class=\"line\">  // Always set the terminator for the active number of workers</span><br><span class=\"line\">  // because only those workers go through the termination protocol.</span><br><span class=\"line\">  ParallelTaskTerminator _term(active_workers, task_queues());</span><br><span class=\"line\">  ParScanThreadStateSet thread_state_set(active_workers,</span><br><span class=\"line\">                                         *to(), *this, *_old_gen, *task_queues(),</span><br><span class=\"line\">                                         _overflow_stacks, _preserved_marks_set,</span><br><span class=\"line\">                                         desired_plab_sz(), _term);</span><br><span class=\"line\"></span><br><span class=\"line\">  thread_state_set.reset(active_workers, promotion_failed());</span><br><span class=\"line\"></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    StrongRootsScope srs(active_workers);</span><br><span class=\"line\"></span><br><span class=\"line\">    ParNewGenTask tsk(this, _old_gen, reserved().end(), &amp;thread_state_set, &amp;srs);</span><br><span class=\"line\">    gch-&gt;rem_set()-&gt;prepare_for_younger_refs_iterate(true);</span><br><span class=\"line\">    // It turns out that even when we&apos;re using 1 thread, doing the work in a</span><br><span class=\"line\">    // separate thread causes wide variance in run times.  We can&apos;t help this</span><br><span class=\"line\">    // in the multi-threaded case, but we special-case n=1 here to get</span><br><span class=\"line\">    // repeatable measurements of the 1-thread overhead of the parallel code.</span><br><span class=\"line\">    // Might multiple workers ever be used?  If yes, initialization</span><br><span class=\"line\">    // has been done such that the single threaded path should not be used.</span><br><span class=\"line\">    if (workers-&gt;total_workers() &gt; 1) &#123;</span><br><span class=\"line\">      workers-&gt;run_task(&amp;tsk);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      tsk.work(0);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  thread_state_set.reset(0 /* Bad value in debug if not reset */,</span><br><span class=\"line\">                         promotion_failed());</span><br><span class=\"line\"></span><br><span class=\"line\">  // Trace and reset failed promotion info.</span><br><span class=\"line\">  if (promotion_failed()) &#123;</span><br><span class=\"line\">    thread_state_set.trace_promotion_failed(gc_tracer());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // Process (weak) reference objects found during scavenge.</span><br><span class=\"line\">  ReferenceProcessor* rp = ref_processor();</span><br><span class=\"line\">  IsAliveClosure is_alive(this);</span><br><span class=\"line\">  ScanWeakRefClosure scan_weak_ref(this);</span><br><span class=\"line\">  KeepAliveClosure keep_alive(&amp;scan_weak_ref);</span><br><span class=\"line\">  ScanClosure               scan_without_gc_barrier(this, false);</span><br><span class=\"line\">  ScanClosureWithParBarrier scan_with_gc_barrier(this, true);</span><br><span class=\"line\">  set_promo_failure_scan_stack_closure(&amp;scan_without_gc_barrier);</span><br><span class=\"line\">  EvacuateFollowersClosureGeneral evacuate_followers(gch,</span><br><span class=\"line\">    &amp;scan_without_gc_barrier, &amp;scan_with_gc_barrier);</span><br><span class=\"line\">  rp-&gt;setup_policy(clear_all_soft_refs);</span><br><span class=\"line\">  // Can  the mt_degree be set later (at run_task() time would be best)?</span><br><span class=\"line\">  rp-&gt;set_active_mt_degree(active_workers);</span><br><span class=\"line\">  ReferenceProcessorStats stats;</span><br><span class=\"line\">  if (rp-&gt;processing_is_mt()) &#123;</span><br><span class=\"line\">    ParNewRefProcTaskExecutor task_executor(*this, *_old_gen, thread_state_set);</span><br><span class=\"line\">    stats = rp-&gt;process_discovered_references(&amp;is_alive, &amp;keep_alive,</span><br><span class=\"line\">                                              &amp;evacuate_followers, &amp;task_executor,</span><br><span class=\"line\">                                              _gc_timer);</span><br><span class=\"line\">  &#125; else &#123;</span><br><span class=\"line\">    thread_state_set.flush();</span><br><span class=\"line\">    gch-&gt;save_marks();</span><br><span class=\"line\">    stats = rp-&gt;process_discovered_references(&amp;is_alive, &amp;keep_alive,</span><br><span class=\"line\">                                              &amp;evacuate_followers, NULL,</span><br><span class=\"line\">                                              _gc_timer);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  _gc_tracer.report_gc_reference_stats(stats);</span><br><span class=\"line\">  _gc_tracer.report_tenuring_threshold(tenuring_threshold());</span><br><span class=\"line\"></span><br><span class=\"line\">  if (!promotion_failed()) &#123;</span><br><span class=\"line\">    // Swap the survivor spaces.</span><br><span class=\"line\">    eden()-&gt;clear(SpaceDecorator::Mangle);</span><br><span class=\"line\">    from()-&gt;clear(SpaceDecorator::Mangle);</span><br><span class=\"line\">    if (ZapUnusedHeapArea) &#123;</span><br><span class=\"line\">      // This is now done here because of the piece-meal mangling which</span><br><span class=\"line\">      // can check for valid mangling at intermediate points in the</span><br><span class=\"line\">      // collection(s).  When a young collection fails to collect</span><br><span class=\"line\">      // sufficient space resizing of the young generation can occur</span><br><span class=\"line\">      // and redistribute the spaces in the young generation.  Mangle</span><br><span class=\"line\">      // here so that unzapped regions don&apos;t get distributed to</span><br><span class=\"line\">      // other spaces.</span><br><span class=\"line\">      to()-&gt;mangle_unused_area();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    swap_spaces();</span><br><span class=\"line\"></span><br><span class=\"line\">    // A successful scavenge should restart the GC time limit count which is</span><br><span class=\"line\">    // for full GC&apos;s.</span><br><span class=\"line\">    size_policy-&gt;reset_gc_overhead_limit_count();</span><br><span class=\"line\"></span><br><span class=\"line\">    assert(to()-&gt;is_empty(), &quot;to space should be empty now&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    adjust_desired_tenuring_threshold();</span><br><span class=\"line\">  &#125; else &#123;</span><br><span class=\"line\">    handle_promotion_failed(gch, thread_state_set);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  _preserved_marks_set.reclaim();</span><br><span class=\"line\">  // set new iteration safe limit for the survivor spaces</span><br><span class=\"line\">  from()-&gt;set_concurrent_iteration_safe_limit(from()-&gt;top());</span><br><span class=\"line\">  to()-&gt;set_concurrent_iteration_safe_limit(to()-&gt;top());</span><br><span class=\"line\"></span><br><span class=\"line\">  plab_stats()-&gt;adjust_desired_plab_sz();</span><br><span class=\"line\"></span><br><span class=\"line\">  TASKQUEUE_STATS_ONLY(thread_state_set.print_termination_stats());</span><br><span class=\"line\">  TASKQUEUE_STATS_ONLY(thread_state_set.print_taskqueue_stats());</span><br><span class=\"line\"></span><br><span class=\"line\">  if (UseAdaptiveSizePolicy) &#123;</span><br><span class=\"line\">    size_policy-&gt;minor_collection_end(gch-&gt;gc_cause());</span><br><span class=\"line\">    size_policy-&gt;avg_survived()-&gt;sample(from()-&gt;used());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // We need to use a monotonically non-decreasing time in ms</span><br><span class=\"line\">  // or we will see time-warp warnings and os::javaTimeMillis()</span><br><span class=\"line\">  // does not guarantee monotonicity.</span><br><span class=\"line\">  jlong now = os::javaTimeNanos() / NANOSECS_PER_MILLISEC;</span><br><span class=\"line\">  update_time_of_last_gc(now);</span><br><span class=\"line\"></span><br><span class=\"line\">  rp-&gt;set_enqueuing_is_done(true);</span><br><span class=\"line\">  if (rp-&gt;processing_is_mt()) &#123;</span><br><span class=\"line\">    ParNewRefProcTaskExecutor task_executor(*this, *_old_gen, thread_state_set);</span><br><span class=\"line\">    rp-&gt;enqueue_discovered_references(&amp;task_executor);</span><br><span class=\"line\">  &#125; else &#123;</span><br><span class=\"line\">    rp-&gt;enqueue_discovered_references(NULL);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  rp-&gt;verify_no_references_recorded();</span><br><span class=\"line\"></span><br><span class=\"line\">  gch-&gt;trace_heap_after_gc(gc_tracer());</span><br><span class=\"line\"></span><br><span class=\"line\">  _gc_timer-&gt;register_gc_end();</span><br><span class=\"line\"></span><br><span class=\"line\">  _gc_tracer.report_gc_end(_gc_timer-&gt;gc_end(), _gc_timer-&gt;time_partitions());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"JVM-GC-Write-barrier","date":"2018-12-20T11:01:43.000Z","_content":"\n\n### 在不同的场景中，Write Barrier有着不太一样的语义\nA write barrier in a garbage collector is a fragment of code emitted by the compiler immediately before every store operation to ensure that (e.g.) generational invariants are maintained. A write barrier in a memory system, also known as a memory barrier, is a hardware-specific compiler intrinsic that ensures that all preceding memory operations \"happen before\" all subsequent ones.[citation needed]","source":"_posts/JVM-GC-Write-barrier.md","raw":"---\ntitle: JVM-GC-Write-barrier\ndate: 2018-12-20 19:01:43\ntags: JVM\n---\n\n\n### 在不同的场景中，Write Barrier有着不太一样的语义\nA write barrier in a garbage collector is a fragment of code emitted by the compiler immediately before every store operation to ensure that (e.g.) generational invariants are maintained. A write barrier in a memory system, also known as a memory barrier, is a hardware-specific compiler intrinsic that ensures that all preceding memory operations \"happen before\" all subsequent ones.[citation needed]","slug":"JVM-GC-Write-barrier","published":1,"updated":"2019-09-28T08:51:00.868Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o836001xv1npogvlzch9","content":"<h3 id=\"在不同的场景中，Write-Barrier有着不太一样的语义\"><a href=\"#在不同的场景中，Write-Barrier有着不太一样的语义\" class=\"headerlink\" title=\"在不同的场景中，Write Barrier有着不太一样的语义\"></a>在不同的场景中，Write Barrier有着不太一样的语义</h3><p>A write barrier in a garbage collector is a fragment of code emitted by the compiler immediately before every store operation to ensure that (e.g.) generational invariants are maintained. A write barrier in a memory system, also known as a memory barrier, is a hardware-specific compiler intrinsic that ensures that all preceding memory operations “happen before” all subsequent ones.[citation needed]</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"在不同的场景中，Write-Barrier有着不太一样的语义\"><a href=\"#在不同的场景中，Write-Barrier有着不太一样的语义\" class=\"headerlink\" title=\"在不同的场景中，Write Barrier有着不太一样的语义\"></a>在不同的场景中，Write Barrier有着不太一样的语义</h3><p>A write barrier in a garbage collector is a fragment of code emitted by the compiler immediately before every store operation to ensure that (e.g.) generational invariants are maintained. A write barrier in a memory system, also known as a memory barrier, is a hardware-specific compiler intrinsic that ensures that all preceding memory operations “happen before” all subsequent ones.[citation needed]</p>\n"},{"title":"JVM-Greys","date":"2018-10-22T09:22:21.000Z","_content":"\n\n## https://www.jianshu.com/p/e53658ecae5b\nillegal ENV, please set $JAVA_HOME to JDK6+\n## 需要指向java-sdk而不是jre\nstart greys failed, because : com.sun.tools.attach.VirtualMachineDescriptor\n\n","source":"_posts/JVM-Greys.md","raw":"---\ntitle: JVM-Greys\ndate: 2018-10-22 17:22:21\ntags: JVM\n---\n\n\n## https://www.jianshu.com/p/e53658ecae5b\nillegal ENV, please set $JAVA_HOME to JDK6+\n## 需要指向java-sdk而不是jre\nstart greys failed, because : com.sun.tools.attach.VirtualMachineDescriptor\n\n","slug":"JVM-Greys","published":1,"updated":"2019-09-28T08:51:00.869Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o836001yv1npujrirlsc","content":"<h2 id=\"https-www-jianshu-com-p-e53658ecae5b\"><a href=\"#https-www-jianshu-com-p-e53658ecae5b\" class=\"headerlink\" title=\"https://www.jianshu.com/p/e53658ecae5b\"></a><a href=\"https://www.jianshu.com/p/e53658ecae5b\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/e53658ecae5b</a></h2><p>illegal ENV, please set $JAVA_HOME to JDK6+</p>\n<h2 id=\"需要指向java-sdk而不是jre\"><a href=\"#需要指向java-sdk而不是jre\" class=\"headerlink\" title=\"需要指向java-sdk而不是jre\"></a>需要指向java-sdk而不是jre</h2><p>start greys failed, because : com.sun.tools.attach.VirtualMachineDescriptor</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"https-www-jianshu-com-p-e53658ecae5b\"><a href=\"#https-www-jianshu-com-p-e53658ecae5b\" class=\"headerlink\" title=\"https://www.jianshu.com/p/e53658ecae5b\"></a><a href=\"https://www.jianshu.com/p/e53658ecae5b\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/e53658ecae5b</a></h2><p>illegal ENV, please set $JAVA_HOME to JDK6+</p>\n<h2 id=\"需要指向java-sdk而不是jre\"><a href=\"#需要指向java-sdk而不是jre\" class=\"headerlink\" title=\"需要指向java-sdk而不是jre\"></a>需要指向java-sdk而不是jre</h2><p>start greys failed, because : com.sun.tools.attach.VirtualMachineDescriptor</p>\n"},{"title":"JVM-GC-log","date":"2018-12-03T11:24:49.000Z","_content":"\n\n### 知乎大神\nhttps://www.zhihu.com/question/57722838\n\n```\nroot     28033  169 73.9 1099400184 48649296 ? Sl   Sep25 169373:13 /bin/java -server -Xms8g -Xmx8g -Xmn4g -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC -XX:+ParallelRefProcEnabled -XX:ConcGCThreads=8 -XX:ParallelGCThreads=8 -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -XX:+PrintHeapAtGC -verbose:gc -Xloggc:/opt/logs/rocketmq/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m -XX:-OmitStackTraceInFastThrow -XX:+AlwaysPreTouch -XX:-UseBiasedLocking -Djava.ext.dirs=/opt/app/rocketmq/bin/../lib -cp .:/opt/app/rocketmq/bin/../conf: com.alibaba.rocketmq.broker.BrokerStartup -c /opt/app/rocketmq/conf/broker-bb.properties\n```\n\n``` RocketMQ G1GC\n2018-12-03T19:25:54.072+0800: 5993997.460: Total time for which application threads were stopped: 0.1773895 seconds, Stopping threads took:\n0.0001456 seconds\n{Heap before GC invocations=221684 (full 0):\n garbage-first heap   total 8388608K, used 5827981K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)\n  region size 16384K, 256 young (4194304K), 12 survivors (196608K)\n Metaspace       used 20710K, capacity 21158K, committed 21376K, reserved 1069056K\n  class space    used 1954K, capacity 2110K, committed 2176K, reserved 1048576K\n2018-12-03T19:26:06.584+0800: 5994009.973: [GC pause (G1 Evacuation Pause) (young)\nDesired survivor size 268435456 bytes, new threshold 15 (max 15)\n- age   1:   42091200 bytes,   42091200 total\n- age   2:   16620824 bytes,   58712024 total\n- age   3:    7993816 bytes,   66705840 total\n- age   4:    4589584 bytes,   71295424 total\n- age   5:    2678752 bytes,   73974176 total\n- age   6:    1463136 bytes,   75437312 total\n- age   7:    1306248 bytes,   76743560 total\n- age   8:    1120960 bytes,   77864520 total\n- age   9:    1029392 bytes,   78893912 total\n- age  10:    1034696 bytes,   79928608 total\n- age  11:     917248 bytes,   80845856 total\n- age  12:     815552 bytes,   81661408 total\n- age  13:     768432 bytes,   82429840 total\n- age  14:     757120 bytes,   83186960 total\n- age  15:     753560 bytes,   83940520 total\n 5994009.973: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 75717, predicted base time: 49.80 ms, remaining time: 150.20 ms, target pause time: 200.00 ms]\n 5994009.973: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 244 regions, survivors: 12 regions, predicted young region time: 96.66 ms]\n 5994009.973: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 244 regions, survivors: 12 regions, old: 0 regions, predicted pause time: 146.47 ms, target pause time: 200.00 ms]\n2018-12-03T19:26:06.735+0800: 5994010.123: [SoftReference, 12 refs, 0.0009291 secs]2018-12-03T19:26:06.735+0800: 5994010.124: [WeakReference, 0 refs, 0.0004160 secs]2018-12-03T19:26:06.736+0800: 5994010.125: [FinalReference, 241242 refs, 0.0263976 secs]2018-12-03T19:26:06.762+0800: 5994010.151: [PhantomReference, 0 refs, 18 refs, 0.0009041 secs]2018-12-03T19:26:06.763+0800: 5994010.152: [JNI Weak Reference, 0.0000129 secs], 0.1830687 secs]\n   [Parallel Time: 150.0 ms, GC Workers: 8]\n      [GC Worker Start (ms): Min: 5994009972.9, Avg: 5994009973.0, Max: 5994009973.1, Diff: 0.1]\n      [Ext Root Scanning (ms): Min: 0.3, Avg: 0.5, Max: 1.1, Diff: 0.8, Sum: 3.8]\n      [Update RS (ms): Min: 17.0, Avg: 17.7, Max: 17.8, Diff: 0.8, Sum: 141.2]\n         [Processed Buffers: Min: 45, Avg: 52.6, Max: 71, Diff: 26, Sum: 421]\n      [Scan RS (ms): Min: 52.7, Avg: 53.5, Max: 53.8, Diff: 1.1, Sum: 428.4]\n      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1]\n      [Object Copy (ms): Min: 77.7, Avg: 77.9, Max: 78.9, Diff: 1.2, Sum: 623.2]\n      [Termination (ms): Min: 0.0, Avg: 0.2, Max: 0.2, Diff: 0.2, Sum: 1.6]\n         [Termination Attempts: Min: 1, Avg: 442.4, Max: 552, Diff: 551, Sum: 3539]\n      [GC Worker Other (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.1, Sum: 0.7]\n      [GC Worker Total (ms): Min: 149.8, Avg: 149.9, Max: 150.0, Diff: 0.2, Sum: 1198.8]\n      [GC Worker End (ms): Min: 5994010122.8, Avg: 5994010122.9, Max: 5994010122.9, Diff: 0.1]\n   [Code Root Fixup: 0.0 ms]\n   [Code Root Purge: 0.0 ms]\n   [Clear CT: 0.6 ms]\n   [Other: 32.4 ms]\n      [Choose CSet: 0.0 ms]\n      [Ref Proc: 29.1 ms]\n      [Ref Enq: 1.2 ms]\n      [Redirty Cards: 0.6 ms]\n      [Humongous Register: 0.0 ms]\n      [Humongous Reclaim: 0.0 ms]\n      [Free CSet: 1.0 ms]\n   [Eden: 3904.0M(3904.0M)->0.0B(3904.0M) Survivors: 192.0M->192.0M Heap: 5691.4M(8192.0M)->1788.4M(8192.0M)]\nHeap after GC invocations=221685 (full 0):\n garbage-first heap   total 8388608K, used 1831342K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)\n  region size 16384K, 12 young (196608K), 12 survivors (196608K)\n Metaspace       used 20710K, capacity 21158K, committed 21376K, reserved 1069056K\n  class space    used 1954K, capacity 2110K, committed 2176K, reserved 1048576K\n}\n [Times: user=0.00 sys=0.00, real=0.18 secs]\n```\n\n\n```\nvoid RuntimeService::record_safepoint_end() {\n  HS_PRIVATE_SAFEPOINT_END();\n\n  // Print the time interval for which the app was stopped\n  // during the current safepoint operation.\n  log_info(safepoint)(\"Total time for which application threads were stopped: %3.7f seconds, Stopping threads took: %3.7f seconds\",\n                      last_safepoint_time_sec(), _last_safepoint_sync_time_sec);\n\n  // update the time stamp to begin recording app time\n  _app_timer.update();\n  if (UsePerfData) {\n    _safepoint_time_ticks->inc(_safepoint_timer.ticks_since_update());\n  }\n}\n```","source":"_posts/JVM-GC-log.md","raw":"---\ntitle: JVM-GC-log\ndate: 2018-12-03 19:24:49\ntags: JVM\n---\n\n\n### 知乎大神\nhttps://www.zhihu.com/question/57722838\n\n```\nroot     28033  169 73.9 1099400184 48649296 ? Sl   Sep25 169373:13 /bin/java -server -Xms8g -Xmx8g -Xmn4g -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC -XX:+ParallelRefProcEnabled -XX:ConcGCThreads=8 -XX:ParallelGCThreads=8 -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -XX:+PrintHeapAtGC -verbose:gc -Xloggc:/opt/logs/rocketmq/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m -XX:-OmitStackTraceInFastThrow -XX:+AlwaysPreTouch -XX:-UseBiasedLocking -Djava.ext.dirs=/opt/app/rocketmq/bin/../lib -cp .:/opt/app/rocketmq/bin/../conf: com.alibaba.rocketmq.broker.BrokerStartup -c /opt/app/rocketmq/conf/broker-bb.properties\n```\n\n``` RocketMQ G1GC\n2018-12-03T19:25:54.072+0800: 5993997.460: Total time for which application threads were stopped: 0.1773895 seconds, Stopping threads took:\n0.0001456 seconds\n{Heap before GC invocations=221684 (full 0):\n garbage-first heap   total 8388608K, used 5827981K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)\n  region size 16384K, 256 young (4194304K), 12 survivors (196608K)\n Metaspace       used 20710K, capacity 21158K, committed 21376K, reserved 1069056K\n  class space    used 1954K, capacity 2110K, committed 2176K, reserved 1048576K\n2018-12-03T19:26:06.584+0800: 5994009.973: [GC pause (G1 Evacuation Pause) (young)\nDesired survivor size 268435456 bytes, new threshold 15 (max 15)\n- age   1:   42091200 bytes,   42091200 total\n- age   2:   16620824 bytes,   58712024 total\n- age   3:    7993816 bytes,   66705840 total\n- age   4:    4589584 bytes,   71295424 total\n- age   5:    2678752 bytes,   73974176 total\n- age   6:    1463136 bytes,   75437312 total\n- age   7:    1306248 bytes,   76743560 total\n- age   8:    1120960 bytes,   77864520 total\n- age   9:    1029392 bytes,   78893912 total\n- age  10:    1034696 bytes,   79928608 total\n- age  11:     917248 bytes,   80845856 total\n- age  12:     815552 bytes,   81661408 total\n- age  13:     768432 bytes,   82429840 total\n- age  14:     757120 bytes,   83186960 total\n- age  15:     753560 bytes,   83940520 total\n 5994009.973: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 75717, predicted base time: 49.80 ms, remaining time: 150.20 ms, target pause time: 200.00 ms]\n 5994009.973: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 244 regions, survivors: 12 regions, predicted young region time: 96.66 ms]\n 5994009.973: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 244 regions, survivors: 12 regions, old: 0 regions, predicted pause time: 146.47 ms, target pause time: 200.00 ms]\n2018-12-03T19:26:06.735+0800: 5994010.123: [SoftReference, 12 refs, 0.0009291 secs]2018-12-03T19:26:06.735+0800: 5994010.124: [WeakReference, 0 refs, 0.0004160 secs]2018-12-03T19:26:06.736+0800: 5994010.125: [FinalReference, 241242 refs, 0.0263976 secs]2018-12-03T19:26:06.762+0800: 5994010.151: [PhantomReference, 0 refs, 18 refs, 0.0009041 secs]2018-12-03T19:26:06.763+0800: 5994010.152: [JNI Weak Reference, 0.0000129 secs], 0.1830687 secs]\n   [Parallel Time: 150.0 ms, GC Workers: 8]\n      [GC Worker Start (ms): Min: 5994009972.9, Avg: 5994009973.0, Max: 5994009973.1, Diff: 0.1]\n      [Ext Root Scanning (ms): Min: 0.3, Avg: 0.5, Max: 1.1, Diff: 0.8, Sum: 3.8]\n      [Update RS (ms): Min: 17.0, Avg: 17.7, Max: 17.8, Diff: 0.8, Sum: 141.2]\n         [Processed Buffers: Min: 45, Avg: 52.6, Max: 71, Diff: 26, Sum: 421]\n      [Scan RS (ms): Min: 52.7, Avg: 53.5, Max: 53.8, Diff: 1.1, Sum: 428.4]\n      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1]\n      [Object Copy (ms): Min: 77.7, Avg: 77.9, Max: 78.9, Diff: 1.2, Sum: 623.2]\n      [Termination (ms): Min: 0.0, Avg: 0.2, Max: 0.2, Diff: 0.2, Sum: 1.6]\n         [Termination Attempts: Min: 1, Avg: 442.4, Max: 552, Diff: 551, Sum: 3539]\n      [GC Worker Other (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.1, Sum: 0.7]\n      [GC Worker Total (ms): Min: 149.8, Avg: 149.9, Max: 150.0, Diff: 0.2, Sum: 1198.8]\n      [GC Worker End (ms): Min: 5994010122.8, Avg: 5994010122.9, Max: 5994010122.9, Diff: 0.1]\n   [Code Root Fixup: 0.0 ms]\n   [Code Root Purge: 0.0 ms]\n   [Clear CT: 0.6 ms]\n   [Other: 32.4 ms]\n      [Choose CSet: 0.0 ms]\n      [Ref Proc: 29.1 ms]\n      [Ref Enq: 1.2 ms]\n      [Redirty Cards: 0.6 ms]\n      [Humongous Register: 0.0 ms]\n      [Humongous Reclaim: 0.0 ms]\n      [Free CSet: 1.0 ms]\n   [Eden: 3904.0M(3904.0M)->0.0B(3904.0M) Survivors: 192.0M->192.0M Heap: 5691.4M(8192.0M)->1788.4M(8192.0M)]\nHeap after GC invocations=221685 (full 0):\n garbage-first heap   total 8388608K, used 1831342K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)\n  region size 16384K, 12 young (196608K), 12 survivors (196608K)\n Metaspace       used 20710K, capacity 21158K, committed 21376K, reserved 1069056K\n  class space    used 1954K, capacity 2110K, committed 2176K, reserved 1048576K\n}\n [Times: user=0.00 sys=0.00, real=0.18 secs]\n```\n\n\n```\nvoid RuntimeService::record_safepoint_end() {\n  HS_PRIVATE_SAFEPOINT_END();\n\n  // Print the time interval for which the app was stopped\n  // during the current safepoint operation.\n  log_info(safepoint)(\"Total time for which application threads were stopped: %3.7f seconds, Stopping threads took: %3.7f seconds\",\n                      last_safepoint_time_sec(), _last_safepoint_sync_time_sec);\n\n  // update the time stamp to begin recording app time\n  _app_timer.update();\n  if (UsePerfData) {\n    _safepoint_time_ticks->inc(_safepoint_timer.ticks_since_update());\n  }\n}\n```","slug":"JVM-GC-log","published":1,"updated":"2019-09-28T08:51:00.869Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o837001zv1npsb3rk71b","content":"<h3 id=\"知乎大神\"><a href=\"#知乎大神\" class=\"headerlink\" title=\"知乎大神\"></a>知乎大神</h3><p><a href=\"https://www.zhihu.com/question/57722838\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/57722838</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root     28033  169 73.9 1099400184 48649296 ? Sl   Sep25 169373:13 /bin/java -server -Xms8g -Xmx8g -Xmn4g -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC -XX:+ParallelRefProcEnabled -XX:ConcGCThreads=8 -XX:ParallelGCThreads=8 -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -XX:+PrintHeapAtGC -verbose:gc -Xloggc:/opt/logs/rocketmq/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m -XX:-OmitStackTraceInFastThrow -XX:+AlwaysPreTouch -XX:-UseBiasedLocking -Djava.ext.dirs=/opt/app/rocketmq/bin/../lib -cp .:/opt/app/rocketmq/bin/../conf: com.alibaba.rocketmq.broker.BrokerStartup -c /opt/app/rocketmq/conf/broker-bb.properties</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><figcaption><span>G1GC</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2018-12-03T19:25:54.072+0800: 5993997.460: Total time for which application threads were stopped: 0.1773895 seconds, Stopping threads took:</span><br><span class=\"line\">0.0001456 seconds</span><br><span class=\"line\">&#123;Heap before GC invocations=221684 (full 0):</span><br><span class=\"line\"> garbage-first heap   total 8388608K, used 5827981K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)</span><br><span class=\"line\">  region size 16384K, 256 young (4194304K), 12 survivors (196608K)</span><br><span class=\"line\"> Metaspace       used 20710K, capacity 21158K, committed 21376K, reserved 1069056K</span><br><span class=\"line\">  class space    used 1954K, capacity 2110K, committed 2176K, reserved 1048576K</span><br><span class=\"line\">2018-12-03T19:26:06.584+0800: 5994009.973: [GC pause (G1 Evacuation Pause) (young)</span><br><span class=\"line\">Desired survivor size 268435456 bytes, new threshold 15 (max 15)</span><br><span class=\"line\">- age   1:   42091200 bytes,   42091200 total</span><br><span class=\"line\">- age   2:   16620824 bytes,   58712024 total</span><br><span class=\"line\">- age   3:    7993816 bytes,   66705840 total</span><br><span class=\"line\">- age   4:    4589584 bytes,   71295424 total</span><br><span class=\"line\">- age   5:    2678752 bytes,   73974176 total</span><br><span class=\"line\">- age   6:    1463136 bytes,   75437312 total</span><br><span class=\"line\">- age   7:    1306248 bytes,   76743560 total</span><br><span class=\"line\">- age   8:    1120960 bytes,   77864520 total</span><br><span class=\"line\">- age   9:    1029392 bytes,   78893912 total</span><br><span class=\"line\">- age  10:    1034696 bytes,   79928608 total</span><br><span class=\"line\">- age  11:     917248 bytes,   80845856 total</span><br><span class=\"line\">- age  12:     815552 bytes,   81661408 total</span><br><span class=\"line\">- age  13:     768432 bytes,   82429840 total</span><br><span class=\"line\">- age  14:     757120 bytes,   83186960 total</span><br><span class=\"line\">- age  15:     753560 bytes,   83940520 total</span><br><span class=\"line\"> 5994009.973: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 75717, predicted base time: 49.80 ms, remaining time: 150.20 ms, target pause time: 200.00 ms]</span><br><span class=\"line\"> 5994009.973: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 244 regions, survivors: 12 regions, predicted young region time: 96.66 ms]</span><br><span class=\"line\"> 5994009.973: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 244 regions, survivors: 12 regions, old: 0 regions, predicted pause time: 146.47 ms, target pause time: 200.00 ms]</span><br><span class=\"line\">2018-12-03T19:26:06.735+0800: 5994010.123: [SoftReference, 12 refs, 0.0009291 secs]2018-12-03T19:26:06.735+0800: 5994010.124: [WeakReference, 0 refs, 0.0004160 secs]2018-12-03T19:26:06.736+0800: 5994010.125: [FinalReference, 241242 refs, 0.0263976 secs]2018-12-03T19:26:06.762+0800: 5994010.151: [PhantomReference, 0 refs, 18 refs, 0.0009041 secs]2018-12-03T19:26:06.763+0800: 5994010.152: [JNI Weak Reference, 0.0000129 secs], 0.1830687 secs]</span><br><span class=\"line\">   [Parallel Time: 150.0 ms, GC Workers: 8]</span><br><span class=\"line\">      [GC Worker Start (ms): Min: 5994009972.9, Avg: 5994009973.0, Max: 5994009973.1, Diff: 0.1]</span><br><span class=\"line\">      [Ext Root Scanning (ms): Min: 0.3, Avg: 0.5, Max: 1.1, Diff: 0.8, Sum: 3.8]</span><br><span class=\"line\">      [Update RS (ms): Min: 17.0, Avg: 17.7, Max: 17.8, Diff: 0.8, Sum: 141.2]</span><br><span class=\"line\">         [Processed Buffers: Min: 45, Avg: 52.6, Max: 71, Diff: 26, Sum: 421]</span><br><span class=\"line\">      [Scan RS (ms): Min: 52.7, Avg: 53.5, Max: 53.8, Diff: 1.1, Sum: 428.4]</span><br><span class=\"line\">      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1]</span><br><span class=\"line\">      [Object Copy (ms): Min: 77.7, Avg: 77.9, Max: 78.9, Diff: 1.2, Sum: 623.2]</span><br><span class=\"line\">      [Termination (ms): Min: 0.0, Avg: 0.2, Max: 0.2, Diff: 0.2, Sum: 1.6]</span><br><span class=\"line\">         [Termination Attempts: Min: 1, Avg: 442.4, Max: 552, Diff: 551, Sum: 3539]</span><br><span class=\"line\">      [GC Worker Other (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.1, Sum: 0.7]</span><br><span class=\"line\">      [GC Worker Total (ms): Min: 149.8, Avg: 149.9, Max: 150.0, Diff: 0.2, Sum: 1198.8]</span><br><span class=\"line\">      [GC Worker End (ms): Min: 5994010122.8, Avg: 5994010122.9, Max: 5994010122.9, Diff: 0.1]</span><br><span class=\"line\">   [Code Root Fixup: 0.0 ms]</span><br><span class=\"line\">   [Code Root Purge: 0.0 ms]</span><br><span class=\"line\">   [Clear CT: 0.6 ms]</span><br><span class=\"line\">   [Other: 32.4 ms]</span><br><span class=\"line\">      [Choose CSet: 0.0 ms]</span><br><span class=\"line\">      [Ref Proc: 29.1 ms]</span><br><span class=\"line\">      [Ref Enq: 1.2 ms]</span><br><span class=\"line\">      [Redirty Cards: 0.6 ms]</span><br><span class=\"line\">      [Humongous Register: 0.0 ms]</span><br><span class=\"line\">      [Humongous Reclaim: 0.0 ms]</span><br><span class=\"line\">      [Free CSet: 1.0 ms]</span><br><span class=\"line\">   [Eden: 3904.0M(3904.0M)-&gt;0.0B(3904.0M) Survivors: 192.0M-&gt;192.0M Heap: 5691.4M(8192.0M)-&gt;1788.4M(8192.0M)]</span><br><span class=\"line\">Heap after GC invocations=221685 (full 0):</span><br><span class=\"line\"> garbage-first heap   total 8388608K, used 1831342K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)</span><br><span class=\"line\">  region size 16384K, 12 young (196608K), 12 survivors (196608K)</span><br><span class=\"line\"> Metaspace       used 20710K, capacity 21158K, committed 21376K, reserved 1069056K</span><br><span class=\"line\">  class space    used 1954K, capacity 2110K, committed 2176K, reserved 1048576K</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> [Times: user=0.00 sys=0.00, real=0.18 secs]</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void RuntimeService::record_safepoint_end() &#123;</span><br><span class=\"line\">  HS_PRIVATE_SAFEPOINT_END();</span><br><span class=\"line\"></span><br><span class=\"line\">  // Print the time interval for which the app was stopped</span><br><span class=\"line\">  // during the current safepoint operation.</span><br><span class=\"line\">  log_info(safepoint)(&quot;Total time for which application threads were stopped: %3.7f seconds, Stopping threads took: %3.7f seconds&quot;,</span><br><span class=\"line\">                      last_safepoint_time_sec(), _last_safepoint_sync_time_sec);</span><br><span class=\"line\"></span><br><span class=\"line\">  // update the time stamp to begin recording app time</span><br><span class=\"line\">  _app_timer.update();</span><br><span class=\"line\">  if (UsePerfData) &#123;</span><br><span class=\"line\">    _safepoint_time_ticks-&gt;inc(_safepoint_timer.ticks_since_update());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"知乎大神\"><a href=\"#知乎大神\" class=\"headerlink\" title=\"知乎大神\"></a>知乎大神</h3><p><a href=\"https://www.zhihu.com/question/57722838\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/57722838</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root     28033  169 73.9 1099400184 48649296 ? Sl   Sep25 169373:13 /bin/java -server -Xms8g -Xmx8g -Xmn4g -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC -XX:+ParallelRefProcEnabled -XX:ConcGCThreads=8 -XX:ParallelGCThreads=8 -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -XX:+PrintHeapAtGC -verbose:gc -Xloggc:/opt/logs/rocketmq/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m -XX:-OmitStackTraceInFastThrow -XX:+AlwaysPreTouch -XX:-UseBiasedLocking -Djava.ext.dirs=/opt/app/rocketmq/bin/../lib -cp .:/opt/app/rocketmq/bin/../conf: com.alibaba.rocketmq.broker.BrokerStartup -c /opt/app/rocketmq/conf/broker-bb.properties</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><figcaption><span>G1GC</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2018-12-03T19:25:54.072+0800: 5993997.460: Total time for which application threads were stopped: 0.1773895 seconds, Stopping threads took:</span><br><span class=\"line\">0.0001456 seconds</span><br><span class=\"line\">&#123;Heap before GC invocations=221684 (full 0):</span><br><span class=\"line\"> garbage-first heap   total 8388608K, used 5827981K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)</span><br><span class=\"line\">  region size 16384K, 256 young (4194304K), 12 survivors (196608K)</span><br><span class=\"line\"> Metaspace       used 20710K, capacity 21158K, committed 21376K, reserved 1069056K</span><br><span class=\"line\">  class space    used 1954K, capacity 2110K, committed 2176K, reserved 1048576K</span><br><span class=\"line\">2018-12-03T19:26:06.584+0800: 5994009.973: [GC pause (G1 Evacuation Pause) (young)</span><br><span class=\"line\">Desired survivor size 268435456 bytes, new threshold 15 (max 15)</span><br><span class=\"line\">- age   1:   42091200 bytes,   42091200 total</span><br><span class=\"line\">- age   2:   16620824 bytes,   58712024 total</span><br><span class=\"line\">- age   3:    7993816 bytes,   66705840 total</span><br><span class=\"line\">- age   4:    4589584 bytes,   71295424 total</span><br><span class=\"line\">- age   5:    2678752 bytes,   73974176 total</span><br><span class=\"line\">- age   6:    1463136 bytes,   75437312 total</span><br><span class=\"line\">- age   7:    1306248 bytes,   76743560 total</span><br><span class=\"line\">- age   8:    1120960 bytes,   77864520 total</span><br><span class=\"line\">- age   9:    1029392 bytes,   78893912 total</span><br><span class=\"line\">- age  10:    1034696 bytes,   79928608 total</span><br><span class=\"line\">- age  11:     917248 bytes,   80845856 total</span><br><span class=\"line\">- age  12:     815552 bytes,   81661408 total</span><br><span class=\"line\">- age  13:     768432 bytes,   82429840 total</span><br><span class=\"line\">- age  14:     757120 bytes,   83186960 total</span><br><span class=\"line\">- age  15:     753560 bytes,   83940520 total</span><br><span class=\"line\"> 5994009.973: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 75717, predicted base time: 49.80 ms, remaining time: 150.20 ms, target pause time: 200.00 ms]</span><br><span class=\"line\"> 5994009.973: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 244 regions, survivors: 12 regions, predicted young region time: 96.66 ms]</span><br><span class=\"line\"> 5994009.973: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 244 regions, survivors: 12 regions, old: 0 regions, predicted pause time: 146.47 ms, target pause time: 200.00 ms]</span><br><span class=\"line\">2018-12-03T19:26:06.735+0800: 5994010.123: [SoftReference, 12 refs, 0.0009291 secs]2018-12-03T19:26:06.735+0800: 5994010.124: [WeakReference, 0 refs, 0.0004160 secs]2018-12-03T19:26:06.736+0800: 5994010.125: [FinalReference, 241242 refs, 0.0263976 secs]2018-12-03T19:26:06.762+0800: 5994010.151: [PhantomReference, 0 refs, 18 refs, 0.0009041 secs]2018-12-03T19:26:06.763+0800: 5994010.152: [JNI Weak Reference, 0.0000129 secs], 0.1830687 secs]</span><br><span class=\"line\">   [Parallel Time: 150.0 ms, GC Workers: 8]</span><br><span class=\"line\">      [GC Worker Start (ms): Min: 5994009972.9, Avg: 5994009973.0, Max: 5994009973.1, Diff: 0.1]</span><br><span class=\"line\">      [Ext Root Scanning (ms): Min: 0.3, Avg: 0.5, Max: 1.1, Diff: 0.8, Sum: 3.8]</span><br><span class=\"line\">      [Update RS (ms): Min: 17.0, Avg: 17.7, Max: 17.8, Diff: 0.8, Sum: 141.2]</span><br><span class=\"line\">         [Processed Buffers: Min: 45, Avg: 52.6, Max: 71, Diff: 26, Sum: 421]</span><br><span class=\"line\">      [Scan RS (ms): Min: 52.7, Avg: 53.5, Max: 53.8, Diff: 1.1, Sum: 428.4]</span><br><span class=\"line\">      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1]</span><br><span class=\"line\">      [Object Copy (ms): Min: 77.7, Avg: 77.9, Max: 78.9, Diff: 1.2, Sum: 623.2]</span><br><span class=\"line\">      [Termination (ms): Min: 0.0, Avg: 0.2, Max: 0.2, Diff: 0.2, Sum: 1.6]</span><br><span class=\"line\">         [Termination Attempts: Min: 1, Avg: 442.4, Max: 552, Diff: 551, Sum: 3539]</span><br><span class=\"line\">      [GC Worker Other (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.1, Sum: 0.7]</span><br><span class=\"line\">      [GC Worker Total (ms): Min: 149.8, Avg: 149.9, Max: 150.0, Diff: 0.2, Sum: 1198.8]</span><br><span class=\"line\">      [GC Worker End (ms): Min: 5994010122.8, Avg: 5994010122.9, Max: 5994010122.9, Diff: 0.1]</span><br><span class=\"line\">   [Code Root Fixup: 0.0 ms]</span><br><span class=\"line\">   [Code Root Purge: 0.0 ms]</span><br><span class=\"line\">   [Clear CT: 0.6 ms]</span><br><span class=\"line\">   [Other: 32.4 ms]</span><br><span class=\"line\">      [Choose CSet: 0.0 ms]</span><br><span class=\"line\">      [Ref Proc: 29.1 ms]</span><br><span class=\"line\">      [Ref Enq: 1.2 ms]</span><br><span class=\"line\">      [Redirty Cards: 0.6 ms]</span><br><span class=\"line\">      [Humongous Register: 0.0 ms]</span><br><span class=\"line\">      [Humongous Reclaim: 0.0 ms]</span><br><span class=\"line\">      [Free CSet: 1.0 ms]</span><br><span class=\"line\">   [Eden: 3904.0M(3904.0M)-&gt;0.0B(3904.0M) Survivors: 192.0M-&gt;192.0M Heap: 5691.4M(8192.0M)-&gt;1788.4M(8192.0M)]</span><br><span class=\"line\">Heap after GC invocations=221685 (full 0):</span><br><span class=\"line\"> garbage-first heap   total 8388608K, used 1831342K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)</span><br><span class=\"line\">  region size 16384K, 12 young (196608K), 12 survivors (196608K)</span><br><span class=\"line\"> Metaspace       used 20710K, capacity 21158K, committed 21376K, reserved 1069056K</span><br><span class=\"line\">  class space    used 1954K, capacity 2110K, committed 2176K, reserved 1048576K</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> [Times: user=0.00 sys=0.00, real=0.18 secs]</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void RuntimeService::record_safepoint_end() &#123;</span><br><span class=\"line\">  HS_PRIVATE_SAFEPOINT_END();</span><br><span class=\"line\"></span><br><span class=\"line\">  // Print the time interval for which the app was stopped</span><br><span class=\"line\">  // during the current safepoint operation.</span><br><span class=\"line\">  log_info(safepoint)(&quot;Total time for which application threads were stopped: %3.7f seconds, Stopping threads took: %3.7f seconds&quot;,</span><br><span class=\"line\">                      last_safepoint_time_sec(), _last_safepoint_sync_time_sec);</span><br><span class=\"line\"></span><br><span class=\"line\">  // update the time stamp to begin recording app time</span><br><span class=\"line\">  _app_timer.update();</span><br><span class=\"line\">  if (UsePerfData) &#123;</span><br><span class=\"line\">    _safepoint_time_ticks-&gt;inc(_safepoint_timer.ticks_since_update());</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"JVM-GC","date":"2018-08-11T07:20:17.000Z","_content":"\n### 写得很精彩\nhttp://blog.chriscs.com/2017/06/20/g1-vs-cms/\n\n\n### GC用到的算法\nhttps://www.iecc.com/gclist/GC-algorithms.html\n\n### GC Roots\n1. 线程方法栈内引用 Student s = new Student() 中的 s\n2. 静态引用 static\n3. 常量引用 const\n4. jni线程方法栈内引用\n\n### minor gc & major gc & full gc， what are the definitions of them?\nhttps://plumbr.io/blog/garbage-collection/minor-gc-vs-major-gc-vs-full-gc\n\n### oracle's blog -- CMS GC log\nhttps://blogs.oracle.com/poonam/understanding-cms-gc-logs\n\n### 分代内存比例\nhttps://blog.csdn.net/Muyundefeng/article/details/72667863\n\n### cms与g1的区别\nhttp://www.woowen.com/java/2016/12/10/G1%20CMS%E5%8C%BA%E5%88%AB/\n\nhttps://www.jianshu.com/p/35cd012eeb8c\n\n### g1gc log format\nhttps://blogs.oracle.com/poonam/understanding-g1-gc-logs\n\n### 画图画起来，这个GC原理画得很不错，可以借鉴\nhttps://www.jianshu.com/p/314272e6d35b\n\n### 调试GC源码\n```\n// The same dtrace probe can't be inserted in two different files, so we\n// have to call it here, so it's only in one file.  Can't create new probes\n// for the other file anymore.   The dtrace probes have to remain stable.\nvoid VM_GC_Operation::notify_gc_begin(bool full) {\n  HOTSPOT_GC_BEGIN(\n                   full);\n  HS_DTRACE_WORKAROUND_TAIL_CALL_BUG();\n}\n\nVMThread::execute(VM_Operation*) vmThread.cpp:594\nG1CollectedHeap::do_collection_pause(unsigned long, unsigned int, bool*, GCCause::Cause) g1CollectedHeap.cpp:2741\nG1CollectedHeap::attempt_allocation_slow(unsigned long, unsigned char, unsigned int*, unsigned int*) g1CollectedHeap.cpp:588\nG1CollectedHeap::attempt_allocation(unsigned long, unsigned int*, unsigned int*) g1CollectedHeap.cpp:853\nG1CollectedHeap::mem_allocate(unsigned long, bool*) g1CollectedHeap.cpp:485\nCollectedHeap::common_mem_allocate_noinit(KlassHandle, unsigned long, Thread*) collectedHeap.inline.hpp:149\nCollectedHeap::common_mem_allocate_init(KlassHandle, unsigned long, Thread*) collectedHeap.inline.hpp:190\nCollectedHeap::array_allocate(KlassHandle, int, int, Thread*) collectedHeap.inline.hpp:241\nTypeArrayKlass::allocate_common(int, bool, Thread*) typeArrayKlass.cpp:109\nTypeArrayKlass::allocate(int, Thread*) typeArrayKlass.hpp:67\noopFactory::new_typeArray(BasicType, int, Thread*) oopFactory.cpp:56\nRuntime1::new_type_array(JavaThread*, Klass*, int) c1_Runtime1.cpp:351\n<unknown> 0x000000010d498ec9\n<unknown> 0x000000010d84f0ae\n<unknown> 0x000000010d2244a3\n<unknown> 0x000000010d2199f1\nJavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:410\nos::os_exception_wrapper(void (*)(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*), JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) os_bsd.cpp:3682\nJavaCalls::call(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:306\njni_invoke_static(JNIEnv_*, JavaValue*, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) jni.cpp:1119\n::jni_CallStaticVoidMethod(JNIEnv *, jclass, jmethodID, ...) jni.cpp:1989\nJavaMain 0x0000000105b69c90\n_pthread_body 0x00007fffc9ad493b\n_pthread_start 0x00007fffc9ad4887\nthread_start 0x00007fffc9ad408d\n```\n\n\n### 从两个角度来理解GC\n1. GC线程本身是串行的单线程，还是并行的多线程\n2. GC线程和应用线程是并行的，还是应用线程会完全停止\n\n\n疑问\neden区域的垃圾对象和存活对象是怎么分辨出来的？\n\n发生了一次YGC，为什么O的占用率变小了？\n```\n\n[jump@mq4-broker001 ~]$ sudo jstat -gcutil 20003 1000 100\n  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT \n  0.00 100.00  92.16   3.57  97.01  89.12   5339   37.997     0    0.000   37.997\n  0.00 100.00  92.54   3.57  97.01  89.12   5339   37.997     0    0.000   37.997\n  0.00 100.00  92.91   3.57  97.01  89.12   5339   37.997     0    0.000   37.997\n  0.00 100.00  93.66   3.57  97.01  89.12   5339   37.997     0    0.000   37.997\n  0.00 100.00  94.03   3.57  97.01  89.12   5339   37.997     0    0.000   37.997\n  0.00 100.00  94.78   3.57  97.01  89.12   5339   37.997     0    0.000   37.997\n  0.00 100.00   1.12   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   1.49   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   1.87   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   2.61   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   3.36   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   3.36   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   3.36   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   4.48   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  \n  \n  [jump@mq4-broker001 bin]$ sudo jinfo -flags 20003\n  Attaching to process ID 20003, please wait...\n  Debugger attached successfully.\n  Server compiler detected.\n  JVM version is 25.181-b13\n  Non-default VM flags: -XX:+AlwaysPreTouch -XX:CICompilerCount=4 -XX:ConcGCThreads=8 -XX:+DisableExplicitGC -XX:G1HeapRegionSize=16777216 -XX:G1ReservePercent=25 -XX:GCLogFileSize=31457280 -XX:InitialHeapSize=8589934592 -XX:InitiatingHeapOccupancyPercent=30 -XX:MarkStackSize=4194304 -XX:MaxDirectMemorySize=32212254720 -XX:MaxHeapSize=8589934592 -XX:MaxNewSize=4294967296 -XX:MinHeapDeltaBytes=16777216 -XX:NewSize=4294967296 -XX:NumberOfGCLogFiles=5 -XX:-OmitStackTraceInFastThrow -XX:ParallelGCThreads=8 -XX:+ParallelRefProcEnabled -XX:+PrintAdaptiveSizePolicy -XX:+PrintFlagsFinal -XX:+PrintGC -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:-UseBiasedLocking -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC -XX:+UseGCLogFileRotation -XX:-UseLargePages \n  Command line:  -Xms8g -Xmx8g -Xmn4g -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC -XX:+ParallelRefProcEnabled -XX:ConcGCThreads=8 -XX:ParallelGCThreads=8 -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -XX:+PrintHeapAtGC -verbose:gc -Xloggc:/opt/logs/rocketmq/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m -XX:-OmitStackTraceInFastThrow -XX:+AlwaysPreTouch -XX:MaxDirectMemorySize=30g -XX:-UseLargePages -XX:-UseBiasedLocking -Djava.ext.dirs=/jre/lib/ext:/opt/app/rocketmq/bin/../lib\n```","source":"_posts/JVM-GC.md","raw":"---\ntitle: JVM-GC\ndate: 2018-08-11 15:20:17\ntags: JVM\n---\n\n### 写得很精彩\nhttp://blog.chriscs.com/2017/06/20/g1-vs-cms/\n\n\n### GC用到的算法\nhttps://www.iecc.com/gclist/GC-algorithms.html\n\n### GC Roots\n1. 线程方法栈内引用 Student s = new Student() 中的 s\n2. 静态引用 static\n3. 常量引用 const\n4. jni线程方法栈内引用\n\n### minor gc & major gc & full gc， what are the definitions of them?\nhttps://plumbr.io/blog/garbage-collection/minor-gc-vs-major-gc-vs-full-gc\n\n### oracle's blog -- CMS GC log\nhttps://blogs.oracle.com/poonam/understanding-cms-gc-logs\n\n### 分代内存比例\nhttps://blog.csdn.net/Muyundefeng/article/details/72667863\n\n### cms与g1的区别\nhttp://www.woowen.com/java/2016/12/10/G1%20CMS%E5%8C%BA%E5%88%AB/\n\nhttps://www.jianshu.com/p/35cd012eeb8c\n\n### g1gc log format\nhttps://blogs.oracle.com/poonam/understanding-g1-gc-logs\n\n### 画图画起来，这个GC原理画得很不错，可以借鉴\nhttps://www.jianshu.com/p/314272e6d35b\n\n### 调试GC源码\n```\n// The same dtrace probe can't be inserted in two different files, so we\n// have to call it here, so it's only in one file.  Can't create new probes\n// for the other file anymore.   The dtrace probes have to remain stable.\nvoid VM_GC_Operation::notify_gc_begin(bool full) {\n  HOTSPOT_GC_BEGIN(\n                   full);\n  HS_DTRACE_WORKAROUND_TAIL_CALL_BUG();\n}\n\nVMThread::execute(VM_Operation*) vmThread.cpp:594\nG1CollectedHeap::do_collection_pause(unsigned long, unsigned int, bool*, GCCause::Cause) g1CollectedHeap.cpp:2741\nG1CollectedHeap::attempt_allocation_slow(unsigned long, unsigned char, unsigned int*, unsigned int*) g1CollectedHeap.cpp:588\nG1CollectedHeap::attempt_allocation(unsigned long, unsigned int*, unsigned int*) g1CollectedHeap.cpp:853\nG1CollectedHeap::mem_allocate(unsigned long, bool*) g1CollectedHeap.cpp:485\nCollectedHeap::common_mem_allocate_noinit(KlassHandle, unsigned long, Thread*) collectedHeap.inline.hpp:149\nCollectedHeap::common_mem_allocate_init(KlassHandle, unsigned long, Thread*) collectedHeap.inline.hpp:190\nCollectedHeap::array_allocate(KlassHandle, int, int, Thread*) collectedHeap.inline.hpp:241\nTypeArrayKlass::allocate_common(int, bool, Thread*) typeArrayKlass.cpp:109\nTypeArrayKlass::allocate(int, Thread*) typeArrayKlass.hpp:67\noopFactory::new_typeArray(BasicType, int, Thread*) oopFactory.cpp:56\nRuntime1::new_type_array(JavaThread*, Klass*, int) c1_Runtime1.cpp:351\n<unknown> 0x000000010d498ec9\n<unknown> 0x000000010d84f0ae\n<unknown> 0x000000010d2244a3\n<unknown> 0x000000010d2199f1\nJavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:410\nos::os_exception_wrapper(void (*)(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*), JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) os_bsd.cpp:3682\nJavaCalls::call(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:306\njni_invoke_static(JNIEnv_*, JavaValue*, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) jni.cpp:1119\n::jni_CallStaticVoidMethod(JNIEnv *, jclass, jmethodID, ...) jni.cpp:1989\nJavaMain 0x0000000105b69c90\n_pthread_body 0x00007fffc9ad493b\n_pthread_start 0x00007fffc9ad4887\nthread_start 0x00007fffc9ad408d\n```\n\n\n### 从两个角度来理解GC\n1. GC线程本身是串行的单线程，还是并行的多线程\n2. GC线程和应用线程是并行的，还是应用线程会完全停止\n\n\n疑问\neden区域的垃圾对象和存活对象是怎么分辨出来的？\n\n发生了一次YGC，为什么O的占用率变小了？\n```\n\n[jump@mq4-broker001 ~]$ sudo jstat -gcutil 20003 1000 100\n  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT \n  0.00 100.00  92.16   3.57  97.01  89.12   5339   37.997     0    0.000   37.997\n  0.00 100.00  92.54   3.57  97.01  89.12   5339   37.997     0    0.000   37.997\n  0.00 100.00  92.91   3.57  97.01  89.12   5339   37.997     0    0.000   37.997\n  0.00 100.00  93.66   3.57  97.01  89.12   5339   37.997     0    0.000   37.997\n  0.00 100.00  94.03   3.57  97.01  89.12   5339   37.997     0    0.000   37.997\n  0.00 100.00  94.78   3.57  97.01  89.12   5339   37.997     0    0.000   37.997\n  0.00 100.00   1.12   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   1.49   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   1.87   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   2.61   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   3.36   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   3.36   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   3.36   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  0.00 100.00   4.48   3.54  97.01  89.12   5340   38.005     0    0.000   38.005\n  \n  \n  [jump@mq4-broker001 bin]$ sudo jinfo -flags 20003\n  Attaching to process ID 20003, please wait...\n  Debugger attached successfully.\n  Server compiler detected.\n  JVM version is 25.181-b13\n  Non-default VM flags: -XX:+AlwaysPreTouch -XX:CICompilerCount=4 -XX:ConcGCThreads=8 -XX:+DisableExplicitGC -XX:G1HeapRegionSize=16777216 -XX:G1ReservePercent=25 -XX:GCLogFileSize=31457280 -XX:InitialHeapSize=8589934592 -XX:InitiatingHeapOccupancyPercent=30 -XX:MarkStackSize=4194304 -XX:MaxDirectMemorySize=32212254720 -XX:MaxHeapSize=8589934592 -XX:MaxNewSize=4294967296 -XX:MinHeapDeltaBytes=16777216 -XX:NewSize=4294967296 -XX:NumberOfGCLogFiles=5 -XX:-OmitStackTraceInFastThrow -XX:ParallelGCThreads=8 -XX:+ParallelRefProcEnabled -XX:+PrintAdaptiveSizePolicy -XX:+PrintFlagsFinal -XX:+PrintGC -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:-UseBiasedLocking -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC -XX:+UseGCLogFileRotation -XX:-UseLargePages \n  Command line:  -Xms8g -Xmx8g -Xmn4g -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC -XX:+ParallelRefProcEnabled -XX:ConcGCThreads=8 -XX:ParallelGCThreads=8 -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -XX:+PrintHeapAtGC -verbose:gc -Xloggc:/opt/logs/rocketmq/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m -XX:-OmitStackTraceInFastThrow -XX:+AlwaysPreTouch -XX:MaxDirectMemorySize=30g -XX:-UseLargePages -XX:-UseBiasedLocking -Djava.ext.dirs=/jre/lib/ext:/opt/app/rocketmq/bin/../lib\n```","slug":"JVM-GC","published":1,"updated":"2019-09-28T08:51:00.869Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8390020v1npbtqkcimc","content":"<h3 id=\"写得很精彩\"><a href=\"#写得很精彩\" class=\"headerlink\" title=\"写得很精彩\"></a>写得很精彩</h3><p><a href=\"http://blog.chriscs.com/2017/06/20/g1-vs-cms/\" target=\"_blank\" rel=\"noopener\">http://blog.chriscs.com/2017/06/20/g1-vs-cms/</a></p>\n<h3 id=\"GC用到的算法\"><a href=\"#GC用到的算法\" class=\"headerlink\" title=\"GC用到的算法\"></a>GC用到的算法</h3><p><a href=\"https://www.iecc.com/gclist/GC-algorithms.html\" target=\"_blank\" rel=\"noopener\">https://www.iecc.com/gclist/GC-algorithms.html</a></p>\n<h3 id=\"GC-Roots\"><a href=\"#GC-Roots\" class=\"headerlink\" title=\"GC Roots\"></a>GC Roots</h3><ol>\n<li>线程方法栈内引用 Student s = new Student() 中的 s</li>\n<li>静态引用 static</li>\n<li>常量引用 const</li>\n<li>jni线程方法栈内引用</li>\n</ol>\n<h3 id=\"minor-gc-amp-major-gc-amp-full-gc，-what-are-the-definitions-of-them\"><a href=\"#minor-gc-amp-major-gc-amp-full-gc，-what-are-the-definitions-of-them\" class=\"headerlink\" title=\"minor gc &amp; major gc &amp; full gc， what are the definitions of them?\"></a>minor gc &amp; major gc &amp; full gc， what are the definitions of them?</h3><p><a href=\"https://plumbr.io/blog/garbage-collection/minor-gc-vs-major-gc-vs-full-gc\" target=\"_blank\" rel=\"noopener\">https://plumbr.io/blog/garbage-collection/minor-gc-vs-major-gc-vs-full-gc</a></p>\n<h3 id=\"oracle’s-blog-–-CMS-GC-log\"><a href=\"#oracle’s-blog-–-CMS-GC-log\" class=\"headerlink\" title=\"oracle’s blog – CMS GC log\"></a>oracle’s blog – CMS GC log</h3><p><a href=\"https://blogs.oracle.com/poonam/understanding-cms-gc-logs\" target=\"_blank\" rel=\"noopener\">https://blogs.oracle.com/poonam/understanding-cms-gc-logs</a></p>\n<h3 id=\"分代内存比例\"><a href=\"#分代内存比例\" class=\"headerlink\" title=\"分代内存比例\"></a>分代内存比例</h3><p><a href=\"https://blog.csdn.net/Muyundefeng/article/details/72667863\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Muyundefeng/article/details/72667863</a></p>\n<h3 id=\"cms与g1的区别\"><a href=\"#cms与g1的区别\" class=\"headerlink\" title=\"cms与g1的区别\"></a>cms与g1的区别</h3><p><a href=\"http://www.woowen.com/java/2016/12/10/G1%20CMS%E5%8C%BA%E5%88%AB/\" target=\"_blank\" rel=\"noopener\">http://www.woowen.com/java/2016/12/10/G1%20CMS%E5%8C%BA%E5%88%AB/</a></p>\n<p><a href=\"https://www.jianshu.com/p/35cd012eeb8c\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/35cd012eeb8c</a></p>\n<h3 id=\"g1gc-log-format\"><a href=\"#g1gc-log-format\" class=\"headerlink\" title=\"g1gc log format\"></a>g1gc log format</h3><p><a href=\"https://blogs.oracle.com/poonam/understanding-g1-gc-logs\" target=\"_blank\" rel=\"noopener\">https://blogs.oracle.com/poonam/understanding-g1-gc-logs</a></p>\n<h3 id=\"画图画起来，这个GC原理画得很不错，可以借鉴\"><a href=\"#画图画起来，这个GC原理画得很不错，可以借鉴\" class=\"headerlink\" title=\"画图画起来，这个GC原理画得很不错，可以借鉴\"></a>画图画起来，这个GC原理画得很不错，可以借鉴</h3><p><a href=\"https://www.jianshu.com/p/314272e6d35b\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/314272e6d35b</a></p>\n<h3 id=\"调试GC源码\"><a href=\"#调试GC源码\" class=\"headerlink\" title=\"调试GC源码\"></a>调试GC源码</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// The same dtrace probe can&apos;t be inserted in two different files, so we</span><br><span class=\"line\">// have to call it here, so it&apos;s only in one file.  Can&apos;t create new probes</span><br><span class=\"line\">// for the other file anymore.   The dtrace probes have to remain stable.</span><br><span class=\"line\">void VM_GC_Operation::notify_gc_begin(bool full) &#123;</span><br><span class=\"line\">  HOTSPOT_GC_BEGIN(</span><br><span class=\"line\">                   full);</span><br><span class=\"line\">  HS_DTRACE_WORKAROUND_TAIL_CALL_BUG();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">VMThread::execute(VM_Operation*) vmThread.cpp:594</span><br><span class=\"line\">G1CollectedHeap::do_collection_pause(unsigned long, unsigned int, bool*, GCCause::Cause) g1CollectedHeap.cpp:2741</span><br><span class=\"line\">G1CollectedHeap::attempt_allocation_slow(unsigned long, unsigned char, unsigned int*, unsigned int*) g1CollectedHeap.cpp:588</span><br><span class=\"line\">G1CollectedHeap::attempt_allocation(unsigned long, unsigned int*, unsigned int*) g1CollectedHeap.cpp:853</span><br><span class=\"line\">G1CollectedHeap::mem_allocate(unsigned long, bool*) g1CollectedHeap.cpp:485</span><br><span class=\"line\">CollectedHeap::common_mem_allocate_noinit(KlassHandle, unsigned long, Thread*) collectedHeap.inline.hpp:149</span><br><span class=\"line\">CollectedHeap::common_mem_allocate_init(KlassHandle, unsigned long, Thread*) collectedHeap.inline.hpp:190</span><br><span class=\"line\">CollectedHeap::array_allocate(KlassHandle, int, int, Thread*) collectedHeap.inline.hpp:241</span><br><span class=\"line\">TypeArrayKlass::allocate_common(int, bool, Thread*) typeArrayKlass.cpp:109</span><br><span class=\"line\">TypeArrayKlass::allocate(int, Thread*) typeArrayKlass.hpp:67</span><br><span class=\"line\">oopFactory::new_typeArray(BasicType, int, Thread*) oopFactory.cpp:56</span><br><span class=\"line\">Runtime1::new_type_array(JavaThread*, Klass*, int) c1_Runtime1.cpp:351</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010d498ec9</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010d84f0ae</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010d2244a3</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010d2199f1</span><br><span class=\"line\">JavaCalls::call_helper(JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*) javaCalls.cpp:410</span><br><span class=\"line\">os::os_exception_wrapper(void (*)(JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*), JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*) os_bsd.cpp:3682</span><br><span class=\"line\">JavaCalls::call(JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*) javaCalls.cpp:306</span><br><span class=\"line\">jni_invoke_static(JNIEnv_*, JavaValue*, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) jni.cpp:1119</span><br><span class=\"line\">::jni_CallStaticVoidMethod(JNIEnv *, jclass, jmethodID, ...) jni.cpp:1989</span><br><span class=\"line\">JavaMain 0x0000000105b69c90</span><br><span class=\"line\">_pthread_body 0x00007fffc9ad493b</span><br><span class=\"line\">_pthread_start 0x00007fffc9ad4887</span><br><span class=\"line\">thread_start 0x00007fffc9ad408d</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"从两个角度来理解GC\"><a href=\"#从两个角度来理解GC\" class=\"headerlink\" title=\"从两个角度来理解GC\"></a>从两个角度来理解GC</h3><ol>\n<li>GC线程本身是串行的单线程，还是并行的多线程</li>\n<li>GC线程和应用线程是并行的，还是应用线程会完全停止</li>\n</ol>\n<p>疑问<br>eden区域的垃圾对象和存活对象是怎么分辨出来的？</p>\n<p>发生了一次YGC，为什么O的占用率变小了？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">[jump@mq4-broker001 ~]$ sudo jstat -gcutil 20003 1000 100</span><br><span class=\"line\">  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT </span><br><span class=\"line\">  0.00 100.00  92.16   3.57  97.01  89.12   5339   37.997     0    0.000   37.997</span><br><span class=\"line\">  0.00 100.00  92.54   3.57  97.01  89.12   5339   37.997     0    0.000   37.997</span><br><span class=\"line\">  0.00 100.00  92.91   3.57  97.01  89.12   5339   37.997     0    0.000   37.997</span><br><span class=\"line\">  0.00 100.00  93.66   3.57  97.01  89.12   5339   37.997     0    0.000   37.997</span><br><span class=\"line\">  0.00 100.00  94.03   3.57  97.01  89.12   5339   37.997     0    0.000   37.997</span><br><span class=\"line\">  0.00 100.00  94.78   3.57  97.01  89.12   5339   37.997     0    0.000   37.997</span><br><span class=\"line\">  0.00 100.00   1.12   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   1.49   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   1.87   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   2.61   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   3.36   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   3.36   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   3.36   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   4.48   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  </span><br><span class=\"line\">  </span><br><span class=\"line\">  [jump@mq4-broker001 bin]$ sudo jinfo -flags 20003</span><br><span class=\"line\">  Attaching to process ID 20003, please wait...</span><br><span class=\"line\">  Debugger attached successfully.</span><br><span class=\"line\">  Server compiler detected.</span><br><span class=\"line\">  JVM version is 25.181-b13</span><br><span class=\"line\">  Non-default VM flags: -XX:+AlwaysPreTouch -XX:CICompilerCount=4 -XX:ConcGCThreads=8 -XX:+DisableExplicitGC -XX:G1HeapRegionSize=16777216 -XX:G1ReservePercent=25 -XX:GCLogFileSize=31457280 -XX:InitialHeapSize=8589934592 -XX:InitiatingHeapOccupancyPercent=30 -XX:MarkStackSize=4194304 -XX:MaxDirectMemorySize=32212254720 -XX:MaxHeapSize=8589934592 -XX:MaxNewSize=4294967296 -XX:MinHeapDeltaBytes=16777216 -XX:NewSize=4294967296 -XX:NumberOfGCLogFiles=5 -XX:-OmitStackTraceInFastThrow -XX:ParallelGCThreads=8 -XX:+ParallelRefProcEnabled -XX:+PrintAdaptiveSizePolicy -XX:+PrintFlagsFinal -XX:+PrintGC -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:-UseBiasedLocking -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC -XX:+UseGCLogFileRotation -XX:-UseLargePages </span><br><span class=\"line\">  Command line:  -Xms8g -Xmx8g -Xmn4g -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC -XX:+ParallelRefProcEnabled -XX:ConcGCThreads=8 -XX:ParallelGCThreads=8 -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -XX:+PrintHeapAtGC -verbose:gc -Xloggc:/opt/logs/rocketmq/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m -XX:-OmitStackTraceInFastThrow -XX:+AlwaysPreTouch -XX:MaxDirectMemorySize=30g -XX:-UseLargePages -XX:-UseBiasedLocking -Djava.ext.dirs=/jre/lib/ext:/opt/app/rocketmq/bin/../lib</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"写得很精彩\"><a href=\"#写得很精彩\" class=\"headerlink\" title=\"写得很精彩\"></a>写得很精彩</h3><p><a href=\"http://blog.chriscs.com/2017/06/20/g1-vs-cms/\" target=\"_blank\" rel=\"noopener\">http://blog.chriscs.com/2017/06/20/g1-vs-cms/</a></p>\n<h3 id=\"GC用到的算法\"><a href=\"#GC用到的算法\" class=\"headerlink\" title=\"GC用到的算法\"></a>GC用到的算法</h3><p><a href=\"https://www.iecc.com/gclist/GC-algorithms.html\" target=\"_blank\" rel=\"noopener\">https://www.iecc.com/gclist/GC-algorithms.html</a></p>\n<h3 id=\"GC-Roots\"><a href=\"#GC-Roots\" class=\"headerlink\" title=\"GC Roots\"></a>GC Roots</h3><ol>\n<li>线程方法栈内引用 Student s = new Student() 中的 s</li>\n<li>静态引用 static</li>\n<li>常量引用 const</li>\n<li>jni线程方法栈内引用</li>\n</ol>\n<h3 id=\"minor-gc-amp-major-gc-amp-full-gc，-what-are-the-definitions-of-them\"><a href=\"#minor-gc-amp-major-gc-amp-full-gc，-what-are-the-definitions-of-them\" class=\"headerlink\" title=\"minor gc &amp; major gc &amp; full gc， what are the definitions of them?\"></a>minor gc &amp; major gc &amp; full gc， what are the definitions of them?</h3><p><a href=\"https://plumbr.io/blog/garbage-collection/minor-gc-vs-major-gc-vs-full-gc\" target=\"_blank\" rel=\"noopener\">https://plumbr.io/blog/garbage-collection/minor-gc-vs-major-gc-vs-full-gc</a></p>\n<h3 id=\"oracle’s-blog-–-CMS-GC-log\"><a href=\"#oracle’s-blog-–-CMS-GC-log\" class=\"headerlink\" title=\"oracle’s blog – CMS GC log\"></a>oracle’s blog – CMS GC log</h3><p><a href=\"https://blogs.oracle.com/poonam/understanding-cms-gc-logs\" target=\"_blank\" rel=\"noopener\">https://blogs.oracle.com/poonam/understanding-cms-gc-logs</a></p>\n<h3 id=\"分代内存比例\"><a href=\"#分代内存比例\" class=\"headerlink\" title=\"分代内存比例\"></a>分代内存比例</h3><p><a href=\"https://blog.csdn.net/Muyundefeng/article/details/72667863\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Muyundefeng/article/details/72667863</a></p>\n<h3 id=\"cms与g1的区别\"><a href=\"#cms与g1的区别\" class=\"headerlink\" title=\"cms与g1的区别\"></a>cms与g1的区别</h3><p><a href=\"http://www.woowen.com/java/2016/12/10/G1%20CMS%E5%8C%BA%E5%88%AB/\" target=\"_blank\" rel=\"noopener\">http://www.woowen.com/java/2016/12/10/G1%20CMS%E5%8C%BA%E5%88%AB/</a></p>\n<p><a href=\"https://www.jianshu.com/p/35cd012eeb8c\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/35cd012eeb8c</a></p>\n<h3 id=\"g1gc-log-format\"><a href=\"#g1gc-log-format\" class=\"headerlink\" title=\"g1gc log format\"></a>g1gc log format</h3><p><a href=\"https://blogs.oracle.com/poonam/understanding-g1-gc-logs\" target=\"_blank\" rel=\"noopener\">https://blogs.oracle.com/poonam/understanding-g1-gc-logs</a></p>\n<h3 id=\"画图画起来，这个GC原理画得很不错，可以借鉴\"><a href=\"#画图画起来，这个GC原理画得很不错，可以借鉴\" class=\"headerlink\" title=\"画图画起来，这个GC原理画得很不错，可以借鉴\"></a>画图画起来，这个GC原理画得很不错，可以借鉴</h3><p><a href=\"https://www.jianshu.com/p/314272e6d35b\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/314272e6d35b</a></p>\n<h3 id=\"调试GC源码\"><a href=\"#调试GC源码\" class=\"headerlink\" title=\"调试GC源码\"></a>调试GC源码</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// The same dtrace probe can&apos;t be inserted in two different files, so we</span><br><span class=\"line\">// have to call it here, so it&apos;s only in one file.  Can&apos;t create new probes</span><br><span class=\"line\">// for the other file anymore.   The dtrace probes have to remain stable.</span><br><span class=\"line\">void VM_GC_Operation::notify_gc_begin(bool full) &#123;</span><br><span class=\"line\">  HOTSPOT_GC_BEGIN(</span><br><span class=\"line\">                   full);</span><br><span class=\"line\">  HS_DTRACE_WORKAROUND_TAIL_CALL_BUG();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">VMThread::execute(VM_Operation*) vmThread.cpp:594</span><br><span class=\"line\">G1CollectedHeap::do_collection_pause(unsigned long, unsigned int, bool*, GCCause::Cause) g1CollectedHeap.cpp:2741</span><br><span class=\"line\">G1CollectedHeap::attempt_allocation_slow(unsigned long, unsigned char, unsigned int*, unsigned int*) g1CollectedHeap.cpp:588</span><br><span class=\"line\">G1CollectedHeap::attempt_allocation(unsigned long, unsigned int*, unsigned int*) g1CollectedHeap.cpp:853</span><br><span class=\"line\">G1CollectedHeap::mem_allocate(unsigned long, bool*) g1CollectedHeap.cpp:485</span><br><span class=\"line\">CollectedHeap::common_mem_allocate_noinit(KlassHandle, unsigned long, Thread*) collectedHeap.inline.hpp:149</span><br><span class=\"line\">CollectedHeap::common_mem_allocate_init(KlassHandle, unsigned long, Thread*) collectedHeap.inline.hpp:190</span><br><span class=\"line\">CollectedHeap::array_allocate(KlassHandle, int, int, Thread*) collectedHeap.inline.hpp:241</span><br><span class=\"line\">TypeArrayKlass::allocate_common(int, bool, Thread*) typeArrayKlass.cpp:109</span><br><span class=\"line\">TypeArrayKlass::allocate(int, Thread*) typeArrayKlass.hpp:67</span><br><span class=\"line\">oopFactory::new_typeArray(BasicType, int, Thread*) oopFactory.cpp:56</span><br><span class=\"line\">Runtime1::new_type_array(JavaThread*, Klass*, int) c1_Runtime1.cpp:351</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010d498ec9</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010d84f0ae</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010d2244a3</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010d2199f1</span><br><span class=\"line\">JavaCalls::call_helper(JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*) javaCalls.cpp:410</span><br><span class=\"line\">os::os_exception_wrapper(void (*)(JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*), JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*) os_bsd.cpp:3682</span><br><span class=\"line\">JavaCalls::call(JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*) javaCalls.cpp:306</span><br><span class=\"line\">jni_invoke_static(JNIEnv_*, JavaValue*, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) jni.cpp:1119</span><br><span class=\"line\">::jni_CallStaticVoidMethod(JNIEnv *, jclass, jmethodID, ...) jni.cpp:1989</span><br><span class=\"line\">JavaMain 0x0000000105b69c90</span><br><span class=\"line\">_pthread_body 0x00007fffc9ad493b</span><br><span class=\"line\">_pthread_start 0x00007fffc9ad4887</span><br><span class=\"line\">thread_start 0x00007fffc9ad408d</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"从两个角度来理解GC\"><a href=\"#从两个角度来理解GC\" class=\"headerlink\" title=\"从两个角度来理解GC\"></a>从两个角度来理解GC</h3><ol>\n<li>GC线程本身是串行的单线程，还是并行的多线程</li>\n<li>GC线程和应用线程是并行的，还是应用线程会完全停止</li>\n</ol>\n<p>疑问<br>eden区域的垃圾对象和存活对象是怎么分辨出来的？</p>\n<p>发生了一次YGC，为什么O的占用率变小了？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">[jump@mq4-broker001 ~]$ sudo jstat -gcutil 20003 1000 100</span><br><span class=\"line\">  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT </span><br><span class=\"line\">  0.00 100.00  92.16   3.57  97.01  89.12   5339   37.997     0    0.000   37.997</span><br><span class=\"line\">  0.00 100.00  92.54   3.57  97.01  89.12   5339   37.997     0    0.000   37.997</span><br><span class=\"line\">  0.00 100.00  92.91   3.57  97.01  89.12   5339   37.997     0    0.000   37.997</span><br><span class=\"line\">  0.00 100.00  93.66   3.57  97.01  89.12   5339   37.997     0    0.000   37.997</span><br><span class=\"line\">  0.00 100.00  94.03   3.57  97.01  89.12   5339   37.997     0    0.000   37.997</span><br><span class=\"line\">  0.00 100.00  94.78   3.57  97.01  89.12   5339   37.997     0    0.000   37.997</span><br><span class=\"line\">  0.00 100.00   1.12   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   1.49   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   1.87   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   2.61   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   3.36   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   3.36   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   3.36   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  0.00 100.00   4.48   3.54  97.01  89.12   5340   38.005     0    0.000   38.005</span><br><span class=\"line\">  </span><br><span class=\"line\">  </span><br><span class=\"line\">  [jump@mq4-broker001 bin]$ sudo jinfo -flags 20003</span><br><span class=\"line\">  Attaching to process ID 20003, please wait...</span><br><span class=\"line\">  Debugger attached successfully.</span><br><span class=\"line\">  Server compiler detected.</span><br><span class=\"line\">  JVM version is 25.181-b13</span><br><span class=\"line\">  Non-default VM flags: -XX:+AlwaysPreTouch -XX:CICompilerCount=4 -XX:ConcGCThreads=8 -XX:+DisableExplicitGC -XX:G1HeapRegionSize=16777216 -XX:G1ReservePercent=25 -XX:GCLogFileSize=31457280 -XX:InitialHeapSize=8589934592 -XX:InitiatingHeapOccupancyPercent=30 -XX:MarkStackSize=4194304 -XX:MaxDirectMemorySize=32212254720 -XX:MaxHeapSize=8589934592 -XX:MaxNewSize=4294967296 -XX:MinHeapDeltaBytes=16777216 -XX:NewSize=4294967296 -XX:NumberOfGCLogFiles=5 -XX:-OmitStackTraceInFastThrow -XX:ParallelGCThreads=8 -XX:+ParallelRefProcEnabled -XX:+PrintAdaptiveSizePolicy -XX:+PrintFlagsFinal -XX:+PrintGC -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:-UseBiasedLocking -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC -XX:+UseGCLogFileRotation -XX:-UseLargePages </span><br><span class=\"line\">  Command line:  -Xms8g -Xmx8g -Xmn4g -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC -XX:+ParallelRefProcEnabled -XX:ConcGCThreads=8 -XX:ParallelGCThreads=8 -XX:+PrintFlagsFinal -XX:+PrintReferenceGC -XX:+PrintTenuringDistribution -XX:+PrintHeapAtGC -verbose:gc -Xloggc:/opt/logs/rocketmq/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m -XX:-OmitStackTraceInFastThrow -XX:+AlwaysPreTouch -XX:MaxDirectMemorySize=30g -XX:-UseLargePages -XX:-UseBiasedLocking -Djava.ext.dirs=/jre/lib/ext:/opt/app/rocketmq/bin/../lib</span><br></pre></td></tr></table></figure>"},{"title":"JVM-Interpreter","date":"2018-10-09T06:57:11.000Z","_content":"\n\n### 牛逼的文章\nhttps://blog.csdn.net/new_abc/article/details/53639050\n\n### klassVtable\n``` Conditional Breakpoint\nthis->_klass._value->_name->equals(\"OopAndKlass\", 11)\n```\n\n```\nklassVtable::initialize_vtable(bool, Thread*) klassVtable.cpp:163\nInstanceKlass::link_class_impl(instanceKlassHandle, bool, Thread*) instanceKlass.cpp:631\nInstanceKlass::link_class(Thread*) instanceKlass.cpp:506\nget_class_declared_methods_helper(JNIEnv_*, _jclass*, unsigned char, bool, Klass*, Thread*) jvm.cpp:1818\n::JVM_GetClassDeclaredMethods(JNIEnv *, jclass, jboolean) jvm.cpp:1871\n<unknown> 0x000000010e4acbb0\n<unknown> 0x000000010e48a220\n<unknown> 0x000000010e48a220\n<unknown> 0x000000010e48a220\n<unknown> 0x000000010e48a220\n<unknown> 0x000000010e48a220\n<unknown> 0x000000010e48a4a3\n<unknown> 0x000000010e47f9f1\nJavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:410\nos::os_exception_wrapper(void (*)(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*), JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) os_bsd.cpp:3682\nJavaCalls::call(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:306\njni_invoke_static(JNIEnv_*, JavaValue*, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) jni.cpp:1119\n::jni_CallStaticObjectMethod(JNIEnv *, jclass, jmethodID, ...) jni.cpp:1846\nLoadMainClass 0x000000010b351ab5\nJavaMain 0x000000010b35080d\n_pthread_body 0x00007fffc136e93b\n_pthread_start 0x00007fffc136e887\nthread_start 0x00007fffc136e08d\n```\n\n\n```\n// Initialize the vtable and interface table after\n// methods have been rewritten since rewrite may\n// fabricate new Method*s.\n// also does loader constraint checking\n//\n// initialize_vtable and initialize_itable need to be rerun for\n// a shared class if the class is not loaded by the NULL classloader.\nClassLoaderData * loader_data = this_k->class_loader_data();\nif (!(this_k->is_shared() &&\n    loader_data->is_the_null_class_loader_data())) {\nResourceMark rm(THREAD);\nthis_k->vtable()->initialize_vtable(true, CHECK_false);\nthis_k->itable()->initialize_itable(true, CHECK_false);\n}\n```","source":"_posts/JVM-Interpreter.md","raw":"---\ntitle: JVM-Interpreter\ndate: 2018-10-09 14:57:11\ntags: JVM\n---\n\n\n### 牛逼的文章\nhttps://blog.csdn.net/new_abc/article/details/53639050\n\n### klassVtable\n``` Conditional Breakpoint\nthis->_klass._value->_name->equals(\"OopAndKlass\", 11)\n```\n\n```\nklassVtable::initialize_vtable(bool, Thread*) klassVtable.cpp:163\nInstanceKlass::link_class_impl(instanceKlassHandle, bool, Thread*) instanceKlass.cpp:631\nInstanceKlass::link_class(Thread*) instanceKlass.cpp:506\nget_class_declared_methods_helper(JNIEnv_*, _jclass*, unsigned char, bool, Klass*, Thread*) jvm.cpp:1818\n::JVM_GetClassDeclaredMethods(JNIEnv *, jclass, jboolean) jvm.cpp:1871\n<unknown> 0x000000010e4acbb0\n<unknown> 0x000000010e48a220\n<unknown> 0x000000010e48a220\n<unknown> 0x000000010e48a220\n<unknown> 0x000000010e48a220\n<unknown> 0x000000010e48a220\n<unknown> 0x000000010e48a4a3\n<unknown> 0x000000010e47f9f1\nJavaCalls::call_helper(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:410\nos::os_exception_wrapper(void (*)(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*), JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) os_bsd.cpp:3682\nJavaCalls::call(JavaValue*, methodHandle const&, JavaCallArguments*, Thread*) javaCalls.cpp:306\njni_invoke_static(JNIEnv_*, JavaValue*, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) jni.cpp:1119\n::jni_CallStaticObjectMethod(JNIEnv *, jclass, jmethodID, ...) jni.cpp:1846\nLoadMainClass 0x000000010b351ab5\nJavaMain 0x000000010b35080d\n_pthread_body 0x00007fffc136e93b\n_pthread_start 0x00007fffc136e887\nthread_start 0x00007fffc136e08d\n```\n\n\n```\n// Initialize the vtable and interface table after\n// methods have been rewritten since rewrite may\n// fabricate new Method*s.\n// also does loader constraint checking\n//\n// initialize_vtable and initialize_itable need to be rerun for\n// a shared class if the class is not loaded by the NULL classloader.\nClassLoaderData * loader_data = this_k->class_loader_data();\nif (!(this_k->is_shared() &&\n    loader_data->is_the_null_class_loader_data())) {\nResourceMark rm(THREAD);\nthis_k->vtable()->initialize_vtable(true, CHECK_false);\nthis_k->itable()->initialize_itable(true, CHECK_false);\n}\n```","slug":"JVM-Interpreter","published":1,"updated":"2019-09-28T08:51:00.869Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83a0021v1np9wbmwao9","content":"<h3 id=\"牛逼的文章\"><a href=\"#牛逼的文章\" class=\"headerlink\" title=\"牛逼的文章\"></a>牛逼的文章</h3><p><a href=\"https://blog.csdn.net/new_abc/article/details/53639050\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/new_abc/article/details/53639050</a></p>\n<h3 id=\"klassVtable\"><a href=\"#klassVtable\" class=\"headerlink\" title=\"klassVtable\"></a>klassVtable</h3><figure class=\"highlight plain\"><figcaption><span>Breakpoint</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">this-&gt;_klass._value-&gt;_name-&gt;equals(&quot;OopAndKlass&quot;, 11)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">klassVtable::initialize_vtable(bool, Thread*) klassVtable.cpp:163</span><br><span class=\"line\">InstanceKlass::link_class_impl(instanceKlassHandle, bool, Thread*) instanceKlass.cpp:631</span><br><span class=\"line\">InstanceKlass::link_class(Thread*) instanceKlass.cpp:506</span><br><span class=\"line\">get_class_declared_methods_helper(JNIEnv_*, _jclass*, unsigned char, bool, Klass*, Thread*) jvm.cpp:1818</span><br><span class=\"line\">::JVM_GetClassDeclaredMethods(JNIEnv *, jclass, jboolean) jvm.cpp:1871</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e4acbb0</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e48a220</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e48a220</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e48a220</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e48a220</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e48a220</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e48a4a3</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e47f9f1</span><br><span class=\"line\">JavaCalls::call_helper(JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*) javaCalls.cpp:410</span><br><span class=\"line\">os::os_exception_wrapper(void (*)(JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*), JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*) os_bsd.cpp:3682</span><br><span class=\"line\">JavaCalls::call(JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*) javaCalls.cpp:306</span><br><span class=\"line\">jni_invoke_static(JNIEnv_*, JavaValue*, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) jni.cpp:1119</span><br><span class=\"line\">::jni_CallStaticObjectMethod(JNIEnv *, jclass, jmethodID, ...) jni.cpp:1846</span><br><span class=\"line\">LoadMainClass 0x000000010b351ab5</span><br><span class=\"line\">JavaMain 0x000000010b35080d</span><br><span class=\"line\">_pthread_body 0x00007fffc136e93b</span><br><span class=\"line\">_pthread_start 0x00007fffc136e887</span><br><span class=\"line\">thread_start 0x00007fffc136e08d</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Initialize the vtable and interface table after</span><br><span class=\"line\">// methods have been rewritten since rewrite may</span><br><span class=\"line\">// fabricate new Method*s.</span><br><span class=\"line\">// also does loader constraint checking</span><br><span class=\"line\">//</span><br><span class=\"line\">// initialize_vtable and initialize_itable need to be rerun for</span><br><span class=\"line\">// a shared class if the class is not loaded by the NULL classloader.</span><br><span class=\"line\">ClassLoaderData * loader_data = this_k-&gt;class_loader_data();</span><br><span class=\"line\">if (!(this_k-&gt;is_shared() &amp;&amp;</span><br><span class=\"line\">    loader_data-&gt;is_the_null_class_loader_data())) &#123;</span><br><span class=\"line\">ResourceMark rm(THREAD);</span><br><span class=\"line\">this_k-&gt;vtable()-&gt;initialize_vtable(true, CHECK_false);</span><br><span class=\"line\">this_k-&gt;itable()-&gt;initialize_itable(true, CHECK_false);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"牛逼的文章\"><a href=\"#牛逼的文章\" class=\"headerlink\" title=\"牛逼的文章\"></a>牛逼的文章</h3><p><a href=\"https://blog.csdn.net/new_abc/article/details/53639050\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/new_abc/article/details/53639050</a></p>\n<h3 id=\"klassVtable\"><a href=\"#klassVtable\" class=\"headerlink\" title=\"klassVtable\"></a>klassVtable</h3><figure class=\"highlight plain\"><figcaption><span>Breakpoint</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">this-&gt;_klass._value-&gt;_name-&gt;equals(&quot;OopAndKlass&quot;, 11)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">klassVtable::initialize_vtable(bool, Thread*) klassVtable.cpp:163</span><br><span class=\"line\">InstanceKlass::link_class_impl(instanceKlassHandle, bool, Thread*) instanceKlass.cpp:631</span><br><span class=\"line\">InstanceKlass::link_class(Thread*) instanceKlass.cpp:506</span><br><span class=\"line\">get_class_declared_methods_helper(JNIEnv_*, _jclass*, unsigned char, bool, Klass*, Thread*) jvm.cpp:1818</span><br><span class=\"line\">::JVM_GetClassDeclaredMethods(JNIEnv *, jclass, jboolean) jvm.cpp:1871</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e4acbb0</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e48a220</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e48a220</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e48a220</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e48a220</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e48a220</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e48a4a3</span><br><span class=\"line\">&lt;unknown&gt; 0x000000010e47f9f1</span><br><span class=\"line\">JavaCalls::call_helper(JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*) javaCalls.cpp:410</span><br><span class=\"line\">os::os_exception_wrapper(void (*)(JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*), JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*) os_bsd.cpp:3682</span><br><span class=\"line\">JavaCalls::call(JavaValue*, methodHandle const&amp;, JavaCallArguments*, Thread*) javaCalls.cpp:306</span><br><span class=\"line\">jni_invoke_static(JNIEnv_*, JavaValue*, _jobject*, JNICallType, _jmethodID*, JNI_ArgumentPusher*, Thread*) jni.cpp:1119</span><br><span class=\"line\">::jni_CallStaticObjectMethod(JNIEnv *, jclass, jmethodID, ...) jni.cpp:1846</span><br><span class=\"line\">LoadMainClass 0x000000010b351ab5</span><br><span class=\"line\">JavaMain 0x000000010b35080d</span><br><span class=\"line\">_pthread_body 0x00007fffc136e93b</span><br><span class=\"line\">_pthread_start 0x00007fffc136e887</span><br><span class=\"line\">thread_start 0x00007fffc136e08d</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Initialize the vtable and interface table after</span><br><span class=\"line\">// methods have been rewritten since rewrite may</span><br><span class=\"line\">// fabricate new Method*s.</span><br><span class=\"line\">// also does loader constraint checking</span><br><span class=\"line\">//</span><br><span class=\"line\">// initialize_vtable and initialize_itable need to be rerun for</span><br><span class=\"line\">// a shared class if the class is not loaded by the NULL classloader.</span><br><span class=\"line\">ClassLoaderData * loader_data = this_k-&gt;class_loader_data();</span><br><span class=\"line\">if (!(this_k-&gt;is_shared() &amp;&amp;</span><br><span class=\"line\">    loader_data-&gt;is_the_null_class_loader_data())) &#123;</span><br><span class=\"line\">ResourceMark rm(THREAD);</span><br><span class=\"line\">this_k-&gt;vtable()-&gt;initialize_vtable(true, CHECK_false);</span><br><span class=\"line\">this_k-&gt;itable()-&gt;initialize_itable(true, CHECK_false);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"JVM-JMH","date":"2018-11-07T07:03:25.000Z","_content":"\n\nhttps://blog.csdn.net/lxbjkben/article/details/79410740\n\nR大\n在HotSpot VM上跑microbenchmark切记不要在main()里跑循环计时就完事。这是典型错误。重要的事情重复三遍：请用JMH，请用JMH，请用JMH。除非非常了解HotSpot的实现细节，在main里这样跑循环计时得到的结果其实对一般程序员来说根本没有任何意义，因为无法解释。\n\n\n\n\nhttps://blog.csdn.net/lxbjkben/article/details/79410740","source":"_posts/JVM-JMH.md","raw":"---\ntitle: JVM-JMH\ndate: 2018-11-07 15:03:25\ntags: JVM\n---\n\n\nhttps://blog.csdn.net/lxbjkben/article/details/79410740\n\nR大\n在HotSpot VM上跑microbenchmark切记不要在main()里跑循环计时就完事。这是典型错误。重要的事情重复三遍：请用JMH，请用JMH，请用JMH。除非非常了解HotSpot的实现细节，在main里这样跑循环计时得到的结果其实对一般程序员来说根本没有任何意义，因为无法解释。\n\n\n\n\nhttps://blog.csdn.net/lxbjkben/article/details/79410740","slug":"JVM-JMH","published":1,"updated":"2019-09-28T08:51:00.869Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83a0022v1npsg3dhx9p","content":"<p><a href=\"https://blog.csdn.net/lxbjkben/article/details/79410740\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lxbjkben/article/details/79410740</a></p>\n<p>R大<br>在HotSpot VM上跑microbenchmark切记不要在main()里跑循环计时就完事。这是典型错误。重要的事情重复三遍：请用JMH，请用JMH，请用JMH。除非非常了解HotSpot的实现细节，在main里这样跑循环计时得到的结果其实对一般程序员来说根本没有任何意义，因为无法解释。</p>\n<p><a href=\"https://blog.csdn.net/lxbjkben/article/details/79410740\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lxbjkben/article/details/79410740</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/lxbjkben/article/details/79410740\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lxbjkben/article/details/79410740</a></p>\n<p>R大<br>在HotSpot VM上跑microbenchmark切记不要在main()里跑循环计时就完事。这是典型错误。重要的事情重复三遍：请用JMH，请用JMH，请用JMH。除非非常了解HotSpot的实现细节，在main里这样跑循环计时得到的结果其实对一般程序员来说根本没有任何意义，因为无法解释。</p>\n<p><a href=\"https://blog.csdn.net/lxbjkben/article/details/79410740\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lxbjkben/article/details/79410740</a></p>\n"},{"title":"JVM-Lock","date":"2017-11-06T02:16:02.000Z","_content":"\n### 里面对锁升级的描述的图挺好的\nhttps://www.jianshu.com/p/36eedeb3f912\n\n```\nabstract static class Sync extends AbstractQueuedSynchronizer {\n        private static final long serialVersionUID = -5179523762034025860L;\n\n        /**\n         * Performs {@link Lock#lock}. The main reason for subclassing\n         * is to allow fast path for nonfair version.\n         */\n        abstract void lock();\n\n        /**\n         * Performs non-fair tryLock.  tryAcquire is implemented in\n         * subclasses, but both need nonfair try for trylock method.\n         */\n        final boolean nonfairTryAcquire(int acquires) {\n            final Thread current = Thread.currentThread();\n            int c = getState();\n            if (c == 0) {\n                if (compareAndSetState(0, acquires)) {\n                    setExclusiveOwnerThread(current);\n                    return true;\n                }\n            }\n            else if (current == getExclusiveOwnerThread()) {\n                int nextc = c + acquires;\n                if (nextc < 0) // overflow\n                    throw new Error(\"Maximum lock count exceeded\");\n                setState(nextc);\n                return true;\n            }\n            return false;\n        }\n\n        protected final boolean tryRelease(int releases) {\n            int c = getState() - releases;\n            if (Thread.currentThread() != getExclusiveOwnerThread())\n                throw new IllegalMonitorStateException();\n            boolean free = false;\n            if (c == 0) {\n                free = true;\n                setExclusiveOwnerThread(null);\n            }\n            setState(c);\n            return free;\n        }\n        \n    }\n```","source":"_posts/JVM-Lock.md","raw":"---\ntitle: JVM-Lock\ndate: 2017-11-06 10:16:02\ntags: JVM\n---\n\n### 里面对锁升级的描述的图挺好的\nhttps://www.jianshu.com/p/36eedeb3f912\n\n```\nabstract static class Sync extends AbstractQueuedSynchronizer {\n        private static final long serialVersionUID = -5179523762034025860L;\n\n        /**\n         * Performs {@link Lock#lock}. The main reason for subclassing\n         * is to allow fast path for nonfair version.\n         */\n        abstract void lock();\n\n        /**\n         * Performs non-fair tryLock.  tryAcquire is implemented in\n         * subclasses, but both need nonfair try for trylock method.\n         */\n        final boolean nonfairTryAcquire(int acquires) {\n            final Thread current = Thread.currentThread();\n            int c = getState();\n            if (c == 0) {\n                if (compareAndSetState(0, acquires)) {\n                    setExclusiveOwnerThread(current);\n                    return true;\n                }\n            }\n            else if (current == getExclusiveOwnerThread()) {\n                int nextc = c + acquires;\n                if (nextc < 0) // overflow\n                    throw new Error(\"Maximum lock count exceeded\");\n                setState(nextc);\n                return true;\n            }\n            return false;\n        }\n\n        protected final boolean tryRelease(int releases) {\n            int c = getState() - releases;\n            if (Thread.currentThread() != getExclusiveOwnerThread())\n                throw new IllegalMonitorStateException();\n            boolean free = false;\n            if (c == 0) {\n                free = true;\n                setExclusiveOwnerThread(null);\n            }\n            setState(c);\n            return free;\n        }\n        \n    }\n```","slug":"JVM-Lock","published":1,"updated":"2019-09-28T08:51:00.870Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83b0023v1npbps519sz","content":"<h3 id=\"里面对锁升级的描述的图挺好的\"><a href=\"#里面对锁升级的描述的图挺好的\" class=\"headerlink\" title=\"里面对锁升级的描述的图挺好的\"></a>里面对锁升级的描述的图挺好的</h3><p><a href=\"https://www.jianshu.com/p/36eedeb3f912\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/36eedeb3f912</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">abstract static class Sync extends AbstractQueuedSynchronizer &#123;</span><br><span class=\"line\">        private static final long serialVersionUID = -5179523762034025860L;</span><br><span class=\"line\"></span><br><span class=\"line\">        /**</span><br><span class=\"line\">         * Performs &#123;@link Lock#lock&#125;. The main reason for subclassing</span><br><span class=\"line\">         * is to allow fast path for nonfair version.</span><br><span class=\"line\">         */</span><br><span class=\"line\">        abstract void lock();</span><br><span class=\"line\"></span><br><span class=\"line\">        /**</span><br><span class=\"line\">         * Performs non-fair tryLock.  tryAcquire is implemented in</span><br><span class=\"line\">         * subclasses, but both need nonfair try for trylock method.</span><br><span class=\"line\">         */</span><br><span class=\"line\">        final boolean nonfairTryAcquire(int acquires) &#123;</span><br><span class=\"line\">            final Thread current = Thread.currentThread();</span><br><span class=\"line\">            int c = getState();</span><br><span class=\"line\">            if (c == 0) &#123;</span><br><span class=\"line\">                if (compareAndSetState(0, acquires)) &#123;</span><br><span class=\"line\">                    setExclusiveOwnerThread(current);</span><br><span class=\"line\">                    return true;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            else if (current == getExclusiveOwnerThread()) &#123;</span><br><span class=\"line\">                int nextc = c + acquires;</span><br><span class=\"line\">                if (nextc &lt; 0) // overflow</span><br><span class=\"line\">                    throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class=\"line\">                setState(nextc);</span><br><span class=\"line\">                return true;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            return false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        protected final boolean tryRelease(int releases) &#123;</span><br><span class=\"line\">            int c = getState() - releases;</span><br><span class=\"line\">            if (Thread.currentThread() != getExclusiveOwnerThread())</span><br><span class=\"line\">                throw new IllegalMonitorStateException();</span><br><span class=\"line\">            boolean free = false;</span><br><span class=\"line\">            if (c == 0) &#123;</span><br><span class=\"line\">                free = true;</span><br><span class=\"line\">                setExclusiveOwnerThread(null);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            setState(c);</span><br><span class=\"line\">            return free;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        </span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"里面对锁升级的描述的图挺好的\"><a href=\"#里面对锁升级的描述的图挺好的\" class=\"headerlink\" title=\"里面对锁升级的描述的图挺好的\"></a>里面对锁升级的描述的图挺好的</h3><p><a href=\"https://www.jianshu.com/p/36eedeb3f912\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/36eedeb3f912</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">abstract static class Sync extends AbstractQueuedSynchronizer &#123;</span><br><span class=\"line\">        private static final long serialVersionUID = -5179523762034025860L;</span><br><span class=\"line\"></span><br><span class=\"line\">        /**</span><br><span class=\"line\">         * Performs &#123;@link Lock#lock&#125;. The main reason for subclassing</span><br><span class=\"line\">         * is to allow fast path for nonfair version.</span><br><span class=\"line\">         */</span><br><span class=\"line\">        abstract void lock();</span><br><span class=\"line\"></span><br><span class=\"line\">        /**</span><br><span class=\"line\">         * Performs non-fair tryLock.  tryAcquire is implemented in</span><br><span class=\"line\">         * subclasses, but both need nonfair try for trylock method.</span><br><span class=\"line\">         */</span><br><span class=\"line\">        final boolean nonfairTryAcquire(int acquires) &#123;</span><br><span class=\"line\">            final Thread current = Thread.currentThread();</span><br><span class=\"line\">            int c = getState();</span><br><span class=\"line\">            if (c == 0) &#123;</span><br><span class=\"line\">                if (compareAndSetState(0, acquires)) &#123;</span><br><span class=\"line\">                    setExclusiveOwnerThread(current);</span><br><span class=\"line\">                    return true;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            else if (current == getExclusiveOwnerThread()) &#123;</span><br><span class=\"line\">                int nextc = c + acquires;</span><br><span class=\"line\">                if (nextc &lt; 0) // overflow</span><br><span class=\"line\">                    throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class=\"line\">                setState(nextc);</span><br><span class=\"line\">                return true;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            return false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        protected final boolean tryRelease(int releases) &#123;</span><br><span class=\"line\">            int c = getState() - releases;</span><br><span class=\"line\">            if (Thread.currentThread() != getExclusiveOwnerThread())</span><br><span class=\"line\">                throw new IllegalMonitorStateException();</span><br><span class=\"line\">            boolean free = false;</span><br><span class=\"line\">            if (c == 0) &#123;</span><br><span class=\"line\">                free = true;</span><br><span class=\"line\">                setExclusiveOwnerThread(null);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            setState(c);</span><br><span class=\"line\">            return free;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        </span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>"},{"title":"JVM-NIO-Epoll-and-Kqueue","date":"2019-02-04T05:47:15.000Z","_content":"\n\nhttps://www.cnblogs.com/moonz-wu/p/4740908.html\n\n```\nimplRegister(SelectionKeyImpl):227, KQueueSelectorImpl (sun.nio.ch), KQueueSelectorImpl.java\nregister(AbstractSelectableChannel, int, Object):132, SelectorImpl (sun.nio.ch), SelectorImpl.java\nregister(Selector, int, Object):212, AbstractSelectableChannel (java.nio.channels.spi), AbstractSelectableChannel.java\ndoRegister():386, AbstractNioChannel (io.netty.channel.nio), AbstractNioChannel.java\nregister0(ChannelPromise):508, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java\naccess$200(AbstractChannel$AbstractUnsafe, ChannelPromise):427, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java\nrun():486, AbstractChannel$AbstractUnsafe$1 (io.netty.channel), AbstractChannel.java\nsafeExecute$$$capture(Runnable):163, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java\nsafeExecute(Runnable):-1, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java\n - Async stack trace\naddTask:-1, SingleThreadEventExecutor (io.netty.util.concurrent)\nexecute:756, SingleThreadEventExecutor (io.netty.util.concurrent)\nregister:483, AbstractChannel$AbstractUnsafe (io.netty.channel)\nregister:80, SingleThreadEventLoop (io.netty.channel)\nregister:74, SingleThreadEventLoop (io.netty.channel)\nregister:86, MultithreadEventLoopGroup (io.netty.channel)\nchannelRead:255, ServerBootstrap$ServerBootstrapAcceptor (io.netty.bootstrap)\ninvokeChannelRead:362, AbstractChannelHandlerContext (io.netty.channel)\ninvokeChannelRead:348, AbstractChannelHandlerContext (io.netty.channel)\nfireChannelRead:340, AbstractChannelHandlerContext (io.netty.channel)\nchannelRead:1408, DefaultChannelPipeline$HeadContext (io.netty.channel)\ninvokeChannelRead:362, AbstractChannelHandlerContext (io.netty.channel)\ninvokeChannelRead:348, AbstractChannelHandlerContext (io.netty.channel)\nfireChannelRead:930, DefaultChannelPipeline (io.netty.channel)\nread:93, AbstractNioMessageChannel$NioMessageUnsafe (io.netty.channel.nio)\nprocessSelectedKey:677, NioEventLoop (io.netty.channel.nio)\nprocessSelectedKeysOptimized:612, NioEventLoop (io.netty.channel.nio)\nprocessSelectedKeys:529, NioEventLoop (io.netty.channel.nio)\nrun:491, NioEventLoop (io.netty.channel.nio)\nrun:905, SingleThreadEventExecutor$5 (io.netty.util.concurrent)\nrun:748, Thread (java.lang)\n```\n\n```\nclass KQueueSelectorImpl extends SelectorImpl {\n\n    private HashMap<Integer, KQueueSelectorImpl.MapEntry> fdMap;\n\n    KQueueSelectorImpl(SelectorProvider var1) {\n        xxx\n        this.fdMap = new HashMap();\n        xxx\n    }\n\n    protected void implRegister(SelectionKeyImpl var1) {\n        if (this.closed) {\n            throw new ClosedSelectorException();\n        } else {\n            int var2 = IOUtil.fdVal(var1.channel.getFD());\n            this.fdMap.put(var2, new KQueueSelectorImpl.MapEntry(var1));\n            ++this.totalChannels;\n            this.keys.add(var1);\n        }\n    }\n\n    protected void implDereg(SelectionKeyImpl var1) throws IOException {\n        int var2 = var1.channel.getFDVal();\n        this.fdMap.remove(var2);\n        this.kqueueWrapper.release(var1.channel);\n        --this.totalChannels;\n        this.keys.remove(var1);\n        this.selectedKeys.remove(var1);\n        this.deregister(var1);\n        SelectableChannel var3 = var1.channel();\n        if (!var3.isOpen() && !var3.isRegistered()) {\n            ((SelChImpl)var3).kill();\n        }\n\n    }\n}\n```","source":"_posts/JVM-NIO-Epoll-and-Kqueue.md","raw":"---\ntitle: JVM-NIO-Epoll-and-Kqueue\ndate: 2019-02-04 13:47:15\ntags: JVM\n---\n\n\nhttps://www.cnblogs.com/moonz-wu/p/4740908.html\n\n```\nimplRegister(SelectionKeyImpl):227, KQueueSelectorImpl (sun.nio.ch), KQueueSelectorImpl.java\nregister(AbstractSelectableChannel, int, Object):132, SelectorImpl (sun.nio.ch), SelectorImpl.java\nregister(Selector, int, Object):212, AbstractSelectableChannel (java.nio.channels.spi), AbstractSelectableChannel.java\ndoRegister():386, AbstractNioChannel (io.netty.channel.nio), AbstractNioChannel.java\nregister0(ChannelPromise):508, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java\naccess$200(AbstractChannel$AbstractUnsafe, ChannelPromise):427, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java\nrun():486, AbstractChannel$AbstractUnsafe$1 (io.netty.channel), AbstractChannel.java\nsafeExecute$$$capture(Runnable):163, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java\nsafeExecute(Runnable):-1, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java\n - Async stack trace\naddTask:-1, SingleThreadEventExecutor (io.netty.util.concurrent)\nexecute:756, SingleThreadEventExecutor (io.netty.util.concurrent)\nregister:483, AbstractChannel$AbstractUnsafe (io.netty.channel)\nregister:80, SingleThreadEventLoop (io.netty.channel)\nregister:74, SingleThreadEventLoop (io.netty.channel)\nregister:86, MultithreadEventLoopGroup (io.netty.channel)\nchannelRead:255, ServerBootstrap$ServerBootstrapAcceptor (io.netty.bootstrap)\ninvokeChannelRead:362, AbstractChannelHandlerContext (io.netty.channel)\ninvokeChannelRead:348, AbstractChannelHandlerContext (io.netty.channel)\nfireChannelRead:340, AbstractChannelHandlerContext (io.netty.channel)\nchannelRead:1408, DefaultChannelPipeline$HeadContext (io.netty.channel)\ninvokeChannelRead:362, AbstractChannelHandlerContext (io.netty.channel)\ninvokeChannelRead:348, AbstractChannelHandlerContext (io.netty.channel)\nfireChannelRead:930, DefaultChannelPipeline (io.netty.channel)\nread:93, AbstractNioMessageChannel$NioMessageUnsafe (io.netty.channel.nio)\nprocessSelectedKey:677, NioEventLoop (io.netty.channel.nio)\nprocessSelectedKeysOptimized:612, NioEventLoop (io.netty.channel.nio)\nprocessSelectedKeys:529, NioEventLoop (io.netty.channel.nio)\nrun:491, NioEventLoop (io.netty.channel.nio)\nrun:905, SingleThreadEventExecutor$5 (io.netty.util.concurrent)\nrun:748, Thread (java.lang)\n```\n\n```\nclass KQueueSelectorImpl extends SelectorImpl {\n\n    private HashMap<Integer, KQueueSelectorImpl.MapEntry> fdMap;\n\n    KQueueSelectorImpl(SelectorProvider var1) {\n        xxx\n        this.fdMap = new HashMap();\n        xxx\n    }\n\n    protected void implRegister(SelectionKeyImpl var1) {\n        if (this.closed) {\n            throw new ClosedSelectorException();\n        } else {\n            int var2 = IOUtil.fdVal(var1.channel.getFD());\n            this.fdMap.put(var2, new KQueueSelectorImpl.MapEntry(var1));\n            ++this.totalChannels;\n            this.keys.add(var1);\n        }\n    }\n\n    protected void implDereg(SelectionKeyImpl var1) throws IOException {\n        int var2 = var1.channel.getFDVal();\n        this.fdMap.remove(var2);\n        this.kqueueWrapper.release(var1.channel);\n        --this.totalChannels;\n        this.keys.remove(var1);\n        this.selectedKeys.remove(var1);\n        this.deregister(var1);\n        SelectableChannel var3 = var1.channel();\n        if (!var3.isOpen() && !var3.isRegistered()) {\n            ((SelChImpl)var3).kill();\n        }\n\n    }\n}\n```","slug":"JVM-NIO-Epoll-and-Kqueue","published":1,"updated":"2019-09-28T08:51:00.870Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83b0024v1npfybbhxhn","content":"<p><a href=\"https://www.cnblogs.com/moonz-wu/p/4740908.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/moonz-wu/p/4740908.html</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">implRegister(SelectionKeyImpl):227, KQueueSelectorImpl (sun.nio.ch), KQueueSelectorImpl.java</span><br><span class=\"line\">register(AbstractSelectableChannel, int, Object):132, SelectorImpl (sun.nio.ch), SelectorImpl.java</span><br><span class=\"line\">register(Selector, int, Object):212, AbstractSelectableChannel (java.nio.channels.spi), AbstractSelectableChannel.java</span><br><span class=\"line\">doRegister():386, AbstractNioChannel (io.netty.channel.nio), AbstractNioChannel.java</span><br><span class=\"line\">register0(ChannelPromise):508, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java</span><br><span class=\"line\">access$200(AbstractChannel$AbstractUnsafe, ChannelPromise):427, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java</span><br><span class=\"line\">run():486, AbstractChannel$AbstractUnsafe$1 (io.netty.channel), AbstractChannel.java</span><br><span class=\"line\">safeExecute$$$capture(Runnable):163, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java</span><br><span class=\"line\">safeExecute(Runnable):-1, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java</span><br><span class=\"line\"> - Async stack trace</span><br><span class=\"line\">addTask:-1, SingleThreadEventExecutor (io.netty.util.concurrent)</span><br><span class=\"line\">execute:756, SingleThreadEventExecutor (io.netty.util.concurrent)</span><br><span class=\"line\">register:483, AbstractChannel$AbstractUnsafe (io.netty.channel)</span><br><span class=\"line\">register:80, SingleThreadEventLoop (io.netty.channel)</span><br><span class=\"line\">register:74, SingleThreadEventLoop (io.netty.channel)</span><br><span class=\"line\">register:86, MultithreadEventLoopGroup (io.netty.channel)</span><br><span class=\"line\">channelRead:255, ServerBootstrap$ServerBootstrapAcceptor (io.netty.bootstrap)</span><br><span class=\"line\">invokeChannelRead:362, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">invokeChannelRead:348, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">fireChannelRead:340, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">channelRead:1408, DefaultChannelPipeline$HeadContext (io.netty.channel)</span><br><span class=\"line\">invokeChannelRead:362, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">invokeChannelRead:348, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">fireChannelRead:930, DefaultChannelPipeline (io.netty.channel)</span><br><span class=\"line\">read:93, AbstractNioMessageChannel$NioMessageUnsafe (io.netty.channel.nio)</span><br><span class=\"line\">processSelectedKey:677, NioEventLoop (io.netty.channel.nio)</span><br><span class=\"line\">processSelectedKeysOptimized:612, NioEventLoop (io.netty.channel.nio)</span><br><span class=\"line\">processSelectedKeys:529, NioEventLoop (io.netty.channel.nio)</span><br><span class=\"line\">run:491, NioEventLoop (io.netty.channel.nio)</span><br><span class=\"line\">run:905, SingleThreadEventExecutor$5 (io.netty.util.concurrent)</span><br><span class=\"line\">run:748, Thread (java.lang)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class KQueueSelectorImpl extends SelectorImpl &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    private HashMap&lt;Integer, KQueueSelectorImpl.MapEntry&gt; fdMap;</span><br><span class=\"line\"></span><br><span class=\"line\">    KQueueSelectorImpl(SelectorProvider var1) &#123;</span><br><span class=\"line\">        xxx</span><br><span class=\"line\">        this.fdMap = new HashMap();</span><br><span class=\"line\">        xxx</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    protected void implRegister(SelectionKeyImpl var1) &#123;</span><br><span class=\"line\">        if (this.closed) &#123;</span><br><span class=\"line\">            throw new ClosedSelectorException();</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            int var2 = IOUtil.fdVal(var1.channel.getFD());</span><br><span class=\"line\">            this.fdMap.put(var2, new KQueueSelectorImpl.MapEntry(var1));</span><br><span class=\"line\">            ++this.totalChannels;</span><br><span class=\"line\">            this.keys.add(var1);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    protected void implDereg(SelectionKeyImpl var1) throws IOException &#123;</span><br><span class=\"line\">        int var2 = var1.channel.getFDVal();</span><br><span class=\"line\">        this.fdMap.remove(var2);</span><br><span class=\"line\">        this.kqueueWrapper.release(var1.channel);</span><br><span class=\"line\">        --this.totalChannels;</span><br><span class=\"line\">        this.keys.remove(var1);</span><br><span class=\"line\">        this.selectedKeys.remove(var1);</span><br><span class=\"line\">        this.deregister(var1);</span><br><span class=\"line\">        SelectableChannel var3 = var1.channel();</span><br><span class=\"line\">        if (!var3.isOpen() &amp;&amp; !var3.isRegistered()) &#123;</span><br><span class=\"line\">            ((SelChImpl)var3).kill();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.cnblogs.com/moonz-wu/p/4740908.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/moonz-wu/p/4740908.html</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">implRegister(SelectionKeyImpl):227, KQueueSelectorImpl (sun.nio.ch), KQueueSelectorImpl.java</span><br><span class=\"line\">register(AbstractSelectableChannel, int, Object):132, SelectorImpl (sun.nio.ch), SelectorImpl.java</span><br><span class=\"line\">register(Selector, int, Object):212, AbstractSelectableChannel (java.nio.channels.spi), AbstractSelectableChannel.java</span><br><span class=\"line\">doRegister():386, AbstractNioChannel (io.netty.channel.nio), AbstractNioChannel.java</span><br><span class=\"line\">register0(ChannelPromise):508, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java</span><br><span class=\"line\">access$200(AbstractChannel$AbstractUnsafe, ChannelPromise):427, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java</span><br><span class=\"line\">run():486, AbstractChannel$AbstractUnsafe$1 (io.netty.channel), AbstractChannel.java</span><br><span class=\"line\">safeExecute$$$capture(Runnable):163, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java</span><br><span class=\"line\">safeExecute(Runnable):-1, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java</span><br><span class=\"line\"> - Async stack trace</span><br><span class=\"line\">addTask:-1, SingleThreadEventExecutor (io.netty.util.concurrent)</span><br><span class=\"line\">execute:756, SingleThreadEventExecutor (io.netty.util.concurrent)</span><br><span class=\"line\">register:483, AbstractChannel$AbstractUnsafe (io.netty.channel)</span><br><span class=\"line\">register:80, SingleThreadEventLoop (io.netty.channel)</span><br><span class=\"line\">register:74, SingleThreadEventLoop (io.netty.channel)</span><br><span class=\"line\">register:86, MultithreadEventLoopGroup (io.netty.channel)</span><br><span class=\"line\">channelRead:255, ServerBootstrap$ServerBootstrapAcceptor (io.netty.bootstrap)</span><br><span class=\"line\">invokeChannelRead:362, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">invokeChannelRead:348, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">fireChannelRead:340, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">channelRead:1408, DefaultChannelPipeline$HeadContext (io.netty.channel)</span><br><span class=\"line\">invokeChannelRead:362, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">invokeChannelRead:348, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">fireChannelRead:930, DefaultChannelPipeline (io.netty.channel)</span><br><span class=\"line\">read:93, AbstractNioMessageChannel$NioMessageUnsafe (io.netty.channel.nio)</span><br><span class=\"line\">processSelectedKey:677, NioEventLoop (io.netty.channel.nio)</span><br><span class=\"line\">processSelectedKeysOptimized:612, NioEventLoop (io.netty.channel.nio)</span><br><span class=\"line\">processSelectedKeys:529, NioEventLoop (io.netty.channel.nio)</span><br><span class=\"line\">run:491, NioEventLoop (io.netty.channel.nio)</span><br><span class=\"line\">run:905, SingleThreadEventExecutor$5 (io.netty.util.concurrent)</span><br><span class=\"line\">run:748, Thread (java.lang)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class KQueueSelectorImpl extends SelectorImpl &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    private HashMap&lt;Integer, KQueueSelectorImpl.MapEntry&gt; fdMap;</span><br><span class=\"line\"></span><br><span class=\"line\">    KQueueSelectorImpl(SelectorProvider var1) &#123;</span><br><span class=\"line\">        xxx</span><br><span class=\"line\">        this.fdMap = new HashMap();</span><br><span class=\"line\">        xxx</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    protected void implRegister(SelectionKeyImpl var1) &#123;</span><br><span class=\"line\">        if (this.closed) &#123;</span><br><span class=\"line\">            throw new ClosedSelectorException();</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            int var2 = IOUtil.fdVal(var1.channel.getFD());</span><br><span class=\"line\">            this.fdMap.put(var2, new KQueueSelectorImpl.MapEntry(var1));</span><br><span class=\"line\">            ++this.totalChannels;</span><br><span class=\"line\">            this.keys.add(var1);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    protected void implDereg(SelectionKeyImpl var1) throws IOException &#123;</span><br><span class=\"line\">        int var2 = var1.channel.getFDVal();</span><br><span class=\"line\">        this.fdMap.remove(var2);</span><br><span class=\"line\">        this.kqueueWrapper.release(var1.channel);</span><br><span class=\"line\">        --this.totalChannels;</span><br><span class=\"line\">        this.keys.remove(var1);</span><br><span class=\"line\">        this.selectedKeys.remove(var1);</span><br><span class=\"line\">        this.deregister(var1);</span><br><span class=\"line\">        SelectableChannel var3 = var1.channel();</span><br><span class=\"line\">        if (!var3.isOpen() &amp;&amp; !var3.isRegistered()) &#123;</span><br><span class=\"line\">            ((SelChImpl)var3).kill();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"JVM-Native-memory-tracker","date":"2018-09-25T12:04:32.000Z","_content":"\nJava内存之本地内存分析神器： NMT 和 pmap\n\nhttps://blog.csdn.net/jicahoo/article/details/50933469\n\n首先，你要在Java启动项中，加入启动项： -XX:NativeMemoryTracking=detail 然后，重新启动Java程序。执行如下命令： jcmd 14179 VM.native_memory detail 你会在标准输出得到类似下面的内容（本文去掉了许多与本文无关或者重复的信息）：\n\n\nhttps://my.oschina.net/foxty/blog/1934968\n这篇文章写得也非常详细","source":"_posts/JVM-Native-memory-tracking.md","raw":"---\ntitle: JVM-Native-memory-tracker\ndate: 2018-09-25 20:04:32\ntags: JVM\n---\n\nJava内存之本地内存分析神器： NMT 和 pmap\n\nhttps://blog.csdn.net/jicahoo/article/details/50933469\n\n首先，你要在Java启动项中，加入启动项： -XX:NativeMemoryTracking=detail 然后，重新启动Java程序。执行如下命令： jcmd 14179 VM.native_memory detail 你会在标准输出得到类似下面的内容（本文去掉了许多与本文无关或者重复的信息）：\n\n\nhttps://my.oschina.net/foxty/blog/1934968\n这篇文章写得也非常详细","slug":"JVM-Native-memory-tracking","published":1,"updated":"2019-09-28T08:51:00.870Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83b0025v1npkafl49es","content":"<p>Java内存之本地内存分析神器： NMT 和 pmap</p>\n<p><a href=\"https://blog.csdn.net/jicahoo/article/details/50933469\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jicahoo/article/details/50933469</a></p>\n<p>首先，你要在Java启动项中，加入启动项： -XX:NativeMemoryTracking=detail 然后，重新启动Java程序。执行如下命令： jcmd 14179 VM.native_memory detail 你会在标准输出得到类似下面的内容（本文去掉了许多与本文无关或者重复的信息）：</p>\n<p><a href=\"https://my.oschina.net/foxty/blog/1934968\" target=\"_blank\" rel=\"noopener\">https://my.oschina.net/foxty/blog/1934968</a><br>这篇文章写得也非常详细</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Java内存之本地内存分析神器： NMT 和 pmap</p>\n<p><a href=\"https://blog.csdn.net/jicahoo/article/details/50933469\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jicahoo/article/details/50933469</a></p>\n<p>首先，你要在Java启动项中，加入启动项： -XX:NativeMemoryTracking=detail 然后，重新启动Java程序。执行如下命令： jcmd 14179 VM.native_memory detail 你会在标准输出得到类似下面的内容（本文去掉了许多与本文无关或者重复的信息）：</p>\n<p><a href=\"https://my.oschina.net/foxty/blog/1934968\" target=\"_blank\" rel=\"noopener\">https://my.oschina.net/foxty/blog/1934968</a><br>这篇文章写得也非常详细</p>\n"},{"title":"JVM-Oop-Klass","date":"2018-12-07T01:37:45.000Z","_content":"\n\n```\nclass oopDesc {\n  friend class VMStructs;\n  friend class JVMCIVMStructs;\n private:\n  volatile markOop _mark; // typedef class markOopDesc* markOop\n  union _metadata {\n    Klass*      _klass;\n    narrowKlass _compressed_klass;\n  } _metadata;\n\n  // Fast access to barrier set. Must be initialized.\n  static BarrierSet* _bs;\n}\n```","source":"_posts/JVM-Oop-Klass.md","raw":"---\ntitle: JVM-Oop-Klass\ndate: 2018-12-07 09:37:45\ntags: JVM\n---\n\n\n```\nclass oopDesc {\n  friend class VMStructs;\n  friend class JVMCIVMStructs;\n private:\n  volatile markOop _mark; // typedef class markOopDesc* markOop\n  union _metadata {\n    Klass*      _klass;\n    narrowKlass _compressed_klass;\n  } _metadata;\n\n  // Fast access to barrier set. Must be initialized.\n  static BarrierSet* _bs;\n}\n```","slug":"JVM-Oop-Klass","published":1,"updated":"2019-09-28T08:51:00.870Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83c0026v1npxrz6y25d","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class oopDesc &#123;</span><br><span class=\"line\">  friend class VMStructs;</span><br><span class=\"line\">  friend class JVMCIVMStructs;</span><br><span class=\"line\"> private:</span><br><span class=\"line\">  volatile markOop _mark; // typedef class markOopDesc* markOop</span><br><span class=\"line\">  union _metadata &#123;</span><br><span class=\"line\">    Klass*      _klass;</span><br><span class=\"line\">    narrowKlass _compressed_klass;</span><br><span class=\"line\">  &#125; _metadata;</span><br><span class=\"line\"></span><br><span class=\"line\">  // Fast access to barrier set. Must be initialized.</span><br><span class=\"line\">  static BarrierSet* _bs;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class oopDesc &#123;</span><br><span class=\"line\">  friend class VMStructs;</span><br><span class=\"line\">  friend class JVMCIVMStructs;</span><br><span class=\"line\"> private:</span><br><span class=\"line\">  volatile markOop _mark; // typedef class markOopDesc* markOop</span><br><span class=\"line\">  union _metadata &#123;</span><br><span class=\"line\">    Klass*      _klass;</span><br><span class=\"line\">    narrowKlass _compressed_klass;</span><br><span class=\"line\">  &#125; _metadata;</span><br><span class=\"line\"></span><br><span class=\"line\">  // Fast access to barrier set. Must be initialized.</span><br><span class=\"line\">  static BarrierSet* _bs;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"JVM-Off-Heap-Memory","date":"2017-12-02T07:05:06.000Z","_content":"\n\n### 问什么需要用堆外内存？\n除了速度快，还有什么优点？\n\n### 参考资料\nhttp://www.jianshu.com/p/007052ee3773\nfull gc是怎么回收堆外内存的？\n\nhttp://www.cnblogs.com/holoyong/p/7266240.html\n\nCleaner是PhantomReference的子类，并通过自身的next和prev字段维护的一个双向链表。PhantomReference的作用在于跟踪垃圾回收过程，并不会对对象的垃圾回收过程造成任何的影响。\n所以cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); 用于对当前构造的DirectByteBuffer对象的垃圾回收过程进行跟踪。\n当DirectByteBuffer对象从pending状态 ——> enqueue状态时，会触发Cleaner的clean()，而Cleaner的clean()的方法会实现通过unsafe对堆外内存的释放。\n\n作者：tomas家的小拨浪鼓\n链接：https://www.jianshu.com/p/007052ee3773\n来源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n","source":"_posts/JVM-Off-Heap-Memory.md","raw":"---\ntitle: JVM-Off-Heap-Memory\ndate: 2017-12-02 15:05:06\ntags: JVM\n---\n\n\n### 问什么需要用堆外内存？\n除了速度快，还有什么优点？\n\n### 参考资料\nhttp://www.jianshu.com/p/007052ee3773\nfull gc是怎么回收堆外内存的？\n\nhttp://www.cnblogs.com/holoyong/p/7266240.html\n\nCleaner是PhantomReference的子类，并通过自身的next和prev字段维护的一个双向链表。PhantomReference的作用在于跟踪垃圾回收过程，并不会对对象的垃圾回收过程造成任何的影响。\n所以cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); 用于对当前构造的DirectByteBuffer对象的垃圾回收过程进行跟踪。\n当DirectByteBuffer对象从pending状态 ——> enqueue状态时，会触发Cleaner的clean()，而Cleaner的clean()的方法会实现通过unsafe对堆外内存的释放。\n\n作者：tomas家的小拨浪鼓\n链接：https://www.jianshu.com/p/007052ee3773\n来源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n","slug":"JVM-Off-Heap-Memory","published":1,"updated":"2019-09-28T08:51:00.870Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83c0027v1npcgz1djbk","content":"<h3 id=\"问什么需要用堆外内存？\"><a href=\"#问什么需要用堆外内存？\" class=\"headerlink\" title=\"问什么需要用堆外内存？\"></a>问什么需要用堆外内存？</h3><p>除了速度快，还有什么优点？</p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><p><a href=\"http://www.jianshu.com/p/007052ee3773\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/007052ee3773</a><br>full gc是怎么回收堆外内存的？</p>\n<p><a href=\"http://www.cnblogs.com/holoyong/p/7266240.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/holoyong/p/7266240.html</a></p>\n<p>Cleaner是PhantomReference的子类，并通过自身的next和prev字段维护的一个双向链表。PhantomReference的作用在于跟踪垃圾回收过程，并不会对对象的垃圾回收过程造成任何的影响。<br>所以cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); 用于对当前构造的DirectByteBuffer对象的垃圾回收过程进行跟踪。<br>当DirectByteBuffer对象从pending状态 ——&gt; enqueue状态时，会触发Cleaner的clean()，而Cleaner的clean()的方法会实现通过unsafe对堆外内存的释放。</p>\n<p>作者：tomas家的小拨浪鼓<br>链接：<a href=\"https://www.jianshu.com/p/007052ee3773\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/007052ee3773</a><br>来源：简书<br>简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"问什么需要用堆外内存？\"><a href=\"#问什么需要用堆外内存？\" class=\"headerlink\" title=\"问什么需要用堆外内存？\"></a>问什么需要用堆外内存？</h3><p>除了速度快，还有什么优点？</p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><p><a href=\"http://www.jianshu.com/p/007052ee3773\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/007052ee3773</a><br>full gc是怎么回收堆外内存的？</p>\n<p><a href=\"http://www.cnblogs.com/holoyong/p/7266240.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/holoyong/p/7266240.html</a></p>\n<p>Cleaner是PhantomReference的子类，并通过自身的next和prev字段维护的一个双向链表。PhantomReference的作用在于跟踪垃圾回收过程，并不会对对象的垃圾回收过程造成任何的影响。<br>所以cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); 用于对当前构造的DirectByteBuffer对象的垃圾回收过程进行跟踪。<br>当DirectByteBuffer对象从pending状态 ——&gt; enqueue状态时，会触发Cleaner的clean()，而Cleaner的clean()的方法会实现通过unsafe对堆外内存的释放。</p>\n<p>作者：tomas家的小拨浪鼓<br>链接：<a href=\"https://www.jianshu.com/p/007052ee3773\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/007052ee3773</a><br>来源：简书<br>简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p>\n"},{"title":"JVM-ParNew-and-CMS","date":"2018-11-21T03:36:15.000Z","_content":"\n\n### 源码体系整理\nhttps://.com/diagraming/5bf3b28ee4b018141e78d8ceprocesson","source":"_posts/JVM-ParNew-and-CMS.md","raw":"---\ntitle: JVM-ParNew-and-CMS\ndate: 2018-11-21 11:36:15\ntags: JVM\n---\n\n\n### 源码体系整理\nhttps://.com/diagraming/5bf3b28ee4b018141e78d8ceprocesson","slug":"JVM-ParNew-and-CMS","published":1,"updated":"2019-09-28T08:51:00.870Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83d0028v1npj8ncszcv","content":"<h3 id=\"源码体系整理\"><a href=\"#源码体系整理\" class=\"headerlink\" title=\"源码体系整理\"></a>源码体系整理</h3><p>https://.com/diagraming/5bf3b28ee4b018141e78d8ceprocesson</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"源码体系整理\"><a href=\"#源码体系整理\" class=\"headerlink\" title=\"源码体系整理\"></a>源码体系整理</h3><p>https://.com/diagraming/5bf3b28ee4b018141e78d8ceprocesson</p>\n"},{"title":"JVM-ParNewGC","date":"2018-10-12T02:05:19.000Z","_content":"\n```\nParNewGeneration::collect(bool, bool, unsigned long, bool) parNewGeneration.cpp:884\nGenCollectedHeap::collect_generation(Generation*, bool, unsigned long, bool, bool, bool, bool) genCollectedHeap.cpp:385\nGenCollectedHeap::do_collection(bool, bool, unsigned long, bool, GenCollectedHeap::GenerationType) genCollectedHeap.cpp:471\nGenCollectorPolicy::satisfy_failed_allocation(unsigned long, bool) collectorPolicy.cpp:738\nGenCollectedHeap::satisfy_failed_allocation(unsigned long, bool) genCollectedHeap.cpp:554\nVM_GenCollectForAllocation::doit() vmGCOperations.cpp:163\nVM_Operation::evaluate() vm_operations.cpp:66\nVMThread::evaluate_operation(VM_Operation*) vmThread.cpp:348\nVMThread::loop() vmThread.cpp:470\nVMThread::run() vmThread.cpp:262\nthread_native_entry(Thread*) os_bsd.cpp:720\n_pthread_body 0x00007fff9cc8193b\n_pthread_start 0x00007fff9cc81887\nthread_start 0x00007fff9cc8108d\n```","source":"_posts/JVM-ParNewGC.md","raw":"---\ntitle: JVM-ParNewGC\ndate: 2018-10-12 10:05:19\ntags: JVM\n---\n\n```\nParNewGeneration::collect(bool, bool, unsigned long, bool) parNewGeneration.cpp:884\nGenCollectedHeap::collect_generation(Generation*, bool, unsigned long, bool, bool, bool, bool) genCollectedHeap.cpp:385\nGenCollectedHeap::do_collection(bool, bool, unsigned long, bool, GenCollectedHeap::GenerationType) genCollectedHeap.cpp:471\nGenCollectorPolicy::satisfy_failed_allocation(unsigned long, bool) collectorPolicy.cpp:738\nGenCollectedHeap::satisfy_failed_allocation(unsigned long, bool) genCollectedHeap.cpp:554\nVM_GenCollectForAllocation::doit() vmGCOperations.cpp:163\nVM_Operation::evaluate() vm_operations.cpp:66\nVMThread::evaluate_operation(VM_Operation*) vmThread.cpp:348\nVMThread::loop() vmThread.cpp:470\nVMThread::run() vmThread.cpp:262\nthread_native_entry(Thread*) os_bsd.cpp:720\n_pthread_body 0x00007fff9cc8193b\n_pthread_start 0x00007fff9cc81887\nthread_start 0x00007fff9cc8108d\n```","slug":"JVM-ParNewGC","published":1,"updated":"2019-09-28T08:51:00.870Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83d0029v1np53x4rdv7","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ParNewGeneration::collect(bool, bool, unsigned long, bool) parNewGeneration.cpp:884</span><br><span class=\"line\">GenCollectedHeap::collect_generation(Generation*, bool, unsigned long, bool, bool, bool, bool) genCollectedHeap.cpp:385</span><br><span class=\"line\">GenCollectedHeap::do_collection(bool, bool, unsigned long, bool, GenCollectedHeap::GenerationType) genCollectedHeap.cpp:471</span><br><span class=\"line\">GenCollectorPolicy::satisfy_failed_allocation(unsigned long, bool) collectorPolicy.cpp:738</span><br><span class=\"line\">GenCollectedHeap::satisfy_failed_allocation(unsigned long, bool) genCollectedHeap.cpp:554</span><br><span class=\"line\">VM_GenCollectForAllocation::doit() vmGCOperations.cpp:163</span><br><span class=\"line\">VM_Operation::evaluate() vm_operations.cpp:66</span><br><span class=\"line\">VMThread::evaluate_operation(VM_Operation*) vmThread.cpp:348</span><br><span class=\"line\">VMThread::loop() vmThread.cpp:470</span><br><span class=\"line\">VMThread::run() vmThread.cpp:262</span><br><span class=\"line\">thread_native_entry(Thread*) os_bsd.cpp:720</span><br><span class=\"line\">_pthread_body 0x00007fff9cc8193b</span><br><span class=\"line\">_pthread_start 0x00007fff9cc81887</span><br><span class=\"line\">thread_start 0x00007fff9cc8108d</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ParNewGeneration::collect(bool, bool, unsigned long, bool) parNewGeneration.cpp:884</span><br><span class=\"line\">GenCollectedHeap::collect_generation(Generation*, bool, unsigned long, bool, bool, bool, bool) genCollectedHeap.cpp:385</span><br><span class=\"line\">GenCollectedHeap::do_collection(bool, bool, unsigned long, bool, GenCollectedHeap::GenerationType) genCollectedHeap.cpp:471</span><br><span class=\"line\">GenCollectorPolicy::satisfy_failed_allocation(unsigned long, bool) collectorPolicy.cpp:738</span><br><span class=\"line\">GenCollectedHeap::satisfy_failed_allocation(unsigned long, bool) genCollectedHeap.cpp:554</span><br><span class=\"line\">VM_GenCollectForAllocation::doit() vmGCOperations.cpp:163</span><br><span class=\"line\">VM_Operation::evaluate() vm_operations.cpp:66</span><br><span class=\"line\">VMThread::evaluate_operation(VM_Operation*) vmThread.cpp:348</span><br><span class=\"line\">VMThread::loop() vmThread.cpp:470</span><br><span class=\"line\">VMThread::run() vmThread.cpp:262</span><br><span class=\"line\">thread_native_entry(Thread*) os_bsd.cpp:720</span><br><span class=\"line\">_pthread_body 0x00007fff9cc8193b</span><br><span class=\"line\">_pthread_start 0x00007fff9cc81887</span><br><span class=\"line\">thread_start 0x00007fff9cc8108d</span><br></pre></td></tr></table></figure>"},{"title":"JVM-Park-Unpark","date":"2018-08-15T01:52:45.000Z","_content":"\nJava并发的工具非常多，但是底层都是基于sun.misc.Unsafe#park和sun.misc.Unsafe#unpark这两个native，本文就来研究下究竟park和unpark表达的语义是什么。\n\n首先，看Java doc\n```\n    // LockSupport class\n    /**\n     * Disables the current thread for thread scheduling purposes unless the\n     * permit is available.\n     *\n     * <p>If the permit is available then it is consumed and the call\n     * returns immediately; otherwise the current thread becomes disabled\n     * for thread scheduling purposes and lies dormant until one of three\n     * things happens:\n     *\n     * <ul>\n     *\n     * <li>Some other thread invokes {@link #unpark unpark} with the\n     * current thread as the target; or\n     *\n     * <li>Some other thread {@linkplain Thread#interrupt interrupts}\n     * the current thread; or\n     *\n     * <li>The call spuriously (that is, for no reason) returns.\n     * </ul>\n     *\n     * <p>This method does <em>not</em> report which of these caused the\n     * method to return. Callers should re-check the conditions which caused\n     * the thread to park in the first place. Callers may also determine,\n     * for example, the interrupt status of the thread upon return.\n     */\n    public static void park() {\n        UNSAFE.park(false, 0L);\n    }\n```\npark方法没有参数，结合注释，想表达的意思是，线程A自己调用park()，将禁止线程调度器对A自己的调度，当然方法自然是阻塞住的。\n而要让线程调度器重新调度A，需要任意一个以下事情发生：\n1. 另外一个线程B调用unpark(A)时，并且参数是阻塞的那个A线程，线程A将被重新调度\n2. 另外一个线程B调用interrupt(A)时\n3. 不合逻辑的调用\n\n重要的是第一条\n\n\n\n### park()和unpark在jvm层是怎么实现的？\n参考\nhttps://blog.csdn.net/hengyunabc/article/details/28126139","source":"_posts/JVM-Park-Unpark.md","raw":"---\ntitle: JVM-Park-Unpark\ndate: 2018-08-15 09:52:45\ntags: JVM\n---\n\nJava并发的工具非常多，但是底层都是基于sun.misc.Unsafe#park和sun.misc.Unsafe#unpark这两个native，本文就来研究下究竟park和unpark表达的语义是什么。\n\n首先，看Java doc\n```\n    // LockSupport class\n    /**\n     * Disables the current thread for thread scheduling purposes unless the\n     * permit is available.\n     *\n     * <p>If the permit is available then it is consumed and the call\n     * returns immediately; otherwise the current thread becomes disabled\n     * for thread scheduling purposes and lies dormant until one of three\n     * things happens:\n     *\n     * <ul>\n     *\n     * <li>Some other thread invokes {@link #unpark unpark} with the\n     * current thread as the target; or\n     *\n     * <li>Some other thread {@linkplain Thread#interrupt interrupts}\n     * the current thread; or\n     *\n     * <li>The call spuriously (that is, for no reason) returns.\n     * </ul>\n     *\n     * <p>This method does <em>not</em> report which of these caused the\n     * method to return. Callers should re-check the conditions which caused\n     * the thread to park in the first place. Callers may also determine,\n     * for example, the interrupt status of the thread upon return.\n     */\n    public static void park() {\n        UNSAFE.park(false, 0L);\n    }\n```\npark方法没有参数，结合注释，想表达的意思是，线程A自己调用park()，将禁止线程调度器对A自己的调度，当然方法自然是阻塞住的。\n而要让线程调度器重新调度A，需要任意一个以下事情发生：\n1. 另外一个线程B调用unpark(A)时，并且参数是阻塞的那个A线程，线程A将被重新调度\n2. 另外一个线程B调用interrupt(A)时\n3. 不合逻辑的调用\n\n重要的是第一条\n\n\n\n### park()和unpark在jvm层是怎么实现的？\n参考\nhttps://blog.csdn.net/hengyunabc/article/details/28126139","slug":"JVM-Park-Unpark","published":1,"updated":"2019-09-28T08:51:00.870Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83d002av1nptmx7ltfu","content":"<p>Java并发的工具非常多，但是底层都是基于sun.misc.Unsafe#park和sun.misc.Unsafe#unpark这两个native，本文就来研究下究竟park和unpark表达的语义是什么。</p>\n<p>首先，看Java doc</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// LockSupport class</span><br><span class=\"line\">/**</span><br><span class=\"line\"> * Disables the current thread for thread scheduling purposes unless the</span><br><span class=\"line\"> * permit is available.</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * &lt;p&gt;If the permit is available then it is consumed and the call</span><br><span class=\"line\"> * returns immediately; otherwise the current thread becomes disabled</span><br><span class=\"line\"> * for thread scheduling purposes and lies dormant until one of three</span><br><span class=\"line\"> * things happens:</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * &lt;ul&gt;</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * &lt;li&gt;Some other thread invokes &#123;@link #unpark unpark&#125; with the</span><br><span class=\"line\"> * current thread as the target; or</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * &lt;li&gt;Some other thread &#123;@linkplain Thread#interrupt interrupts&#125;</span><br><span class=\"line\"> * the current thread; or</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * &lt;li&gt;The call spuriously (that is, for no reason) returns.</span><br><span class=\"line\"> * &lt;/ul&gt;</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * &lt;p&gt;This method does &lt;em&gt;not&lt;/em&gt; report which of these caused the</span><br><span class=\"line\"> * method to return. Callers should re-check the conditions which caused</span><br><span class=\"line\"> * the thread to park in the first place. Callers may also determine,</span><br><span class=\"line\"> * for example, the interrupt status of the thread upon return.</span><br><span class=\"line\"> */</span><br><span class=\"line\">public static void park() &#123;</span><br><span class=\"line\">    UNSAFE.park(false, 0L);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>park方法没有参数，结合注释，想表达的意思是，线程A自己调用park()，将禁止线程调度器对A自己的调度，当然方法自然是阻塞住的。<br>而要让线程调度器重新调度A，需要任意一个以下事情发生：</p>\n<ol>\n<li>另外一个线程B调用unpark(A)时，并且参数是阻塞的那个A线程，线程A将被重新调度</li>\n<li>另外一个线程B调用interrupt(A)时</li>\n<li>不合逻辑的调用</li>\n</ol>\n<p>重要的是第一条</p>\n<h3 id=\"park-和unpark在jvm层是怎么实现的？\"><a href=\"#park-和unpark在jvm层是怎么实现的？\" class=\"headerlink\" title=\"park()和unpark在jvm层是怎么实现的？\"></a>park()和unpark在jvm层是怎么实现的？</h3><p>参考<br><a href=\"https://blog.csdn.net/hengyunabc/article/details/28126139\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/hengyunabc/article/details/28126139</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Java并发的工具非常多，但是底层都是基于sun.misc.Unsafe#park和sun.misc.Unsafe#unpark这两个native，本文就来研究下究竟park和unpark表达的语义是什么。</p>\n<p>首先，看Java doc</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// LockSupport class</span><br><span class=\"line\">/**</span><br><span class=\"line\"> * Disables the current thread for thread scheduling purposes unless the</span><br><span class=\"line\"> * permit is available.</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * &lt;p&gt;If the permit is available then it is consumed and the call</span><br><span class=\"line\"> * returns immediately; otherwise the current thread becomes disabled</span><br><span class=\"line\"> * for thread scheduling purposes and lies dormant until one of three</span><br><span class=\"line\"> * things happens:</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * &lt;ul&gt;</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * &lt;li&gt;Some other thread invokes &#123;@link #unpark unpark&#125; with the</span><br><span class=\"line\"> * current thread as the target; or</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * &lt;li&gt;Some other thread &#123;@linkplain Thread#interrupt interrupts&#125;</span><br><span class=\"line\"> * the current thread; or</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * &lt;li&gt;The call spuriously (that is, for no reason) returns.</span><br><span class=\"line\"> * &lt;/ul&gt;</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * &lt;p&gt;This method does &lt;em&gt;not&lt;/em&gt; report which of these caused the</span><br><span class=\"line\"> * method to return. Callers should re-check the conditions which caused</span><br><span class=\"line\"> * the thread to park in the first place. Callers may also determine,</span><br><span class=\"line\"> * for example, the interrupt status of the thread upon return.</span><br><span class=\"line\"> */</span><br><span class=\"line\">public static void park() &#123;</span><br><span class=\"line\">    UNSAFE.park(false, 0L);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>park方法没有参数，结合注释，想表达的意思是，线程A自己调用park()，将禁止线程调度器对A自己的调度，当然方法自然是阻塞住的。<br>而要让线程调度器重新调度A，需要任意一个以下事情发生：</p>\n<ol>\n<li>另外一个线程B调用unpark(A)时，并且参数是阻塞的那个A线程，线程A将被重新调度</li>\n<li>另外一个线程B调用interrupt(A)时</li>\n<li>不合逻辑的调用</li>\n</ol>\n<p>重要的是第一条</p>\n<h3 id=\"park-和unpark在jvm层是怎么实现的？\"><a href=\"#park-和unpark在jvm层是怎么实现的？\" class=\"headerlink\" title=\"park()和unpark在jvm层是怎么实现的？\"></a>park()和unpark在jvm层是怎么实现的？</h3><p>参考<br><a href=\"https://blog.csdn.net/hengyunabc/article/details/28126139\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/hengyunabc/article/details/28126139</a></p>\n"},{"title":"JVM-Polymorphism","date":"2018-10-08T13:30:08.000Z","_content":"\nJava 的方法调用有两类，动态方法调用与静态方法调用。静态方法调用是指对于类的静态方法的调用方式，是静态绑定的；而动态方法调用需要有方法调用所作用的对象，是动态绑定的。类调用 (invokestatic) 是在编译时就已经确定好具体调用方法的情况。实例调用 (invokevirtual)则是在调用的时候才确定具体的调用方法，这就是动态绑定，也是多态要解决的核心问题。JVM 的方法调用指令有四个，分别是 invokestatic，invokespecial，invokesvirtual 和 invokeinterface。前两个是静态绑定，后两个是动态绑定的。本文也可以说是对于JVM后两种调用实现的考察。\n\n\n### 这篇文章讲得很好\nhttps://www.ibm.com/developerworks/cn/java/j-lo-polymorph/index.html","source":"_posts/JVM-Polymorphism.md","raw":"---\ntitle: JVM-Polymorphism\ndate: 2018-10-08 21:30:08\ntags: JVM\n---\n\nJava 的方法调用有两类，动态方法调用与静态方法调用。静态方法调用是指对于类的静态方法的调用方式，是静态绑定的；而动态方法调用需要有方法调用所作用的对象，是动态绑定的。类调用 (invokestatic) 是在编译时就已经确定好具体调用方法的情况。实例调用 (invokevirtual)则是在调用的时候才确定具体的调用方法，这就是动态绑定，也是多态要解决的核心问题。JVM 的方法调用指令有四个，分别是 invokestatic，invokespecial，invokesvirtual 和 invokeinterface。前两个是静态绑定，后两个是动态绑定的。本文也可以说是对于JVM后两种调用实现的考察。\n\n\n### 这篇文章讲得很好\nhttps://www.ibm.com/developerworks/cn/java/j-lo-polymorph/index.html","slug":"JVM-Polymorphism","published":1,"updated":"2019-09-28T08:51:00.870Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83e002bv1npitglfpld","content":"<p>Java 的方法调用有两类，动态方法调用与静态方法调用。静态方法调用是指对于类的静态方法的调用方式，是静态绑定的；而动态方法调用需要有方法调用所作用的对象，是动态绑定的。类调用 (invokestatic) 是在编译时就已经确定好具体调用方法的情况。实例调用 (invokevirtual)则是在调用的时候才确定具体的调用方法，这就是动态绑定，也是多态要解决的核心问题。JVM 的方法调用指令有四个，分别是 invokestatic，invokespecial，invokesvirtual 和 invokeinterface。前两个是静态绑定，后两个是动态绑定的。本文也可以说是对于JVM后两种调用实现的考察。</p>\n<h3 id=\"这篇文章讲得很好\"><a href=\"#这篇文章讲得很好\" class=\"headerlink\" title=\"这篇文章讲得很好\"></a>这篇文章讲得很好</h3><p><a href=\"https://www.ibm.com/developerworks/cn/java/j-lo-polymorph/index.html\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/java/j-lo-polymorph/index.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Java 的方法调用有两类，动态方法调用与静态方法调用。静态方法调用是指对于类的静态方法的调用方式，是静态绑定的；而动态方法调用需要有方法调用所作用的对象，是动态绑定的。类调用 (invokestatic) 是在编译时就已经确定好具体调用方法的情况。实例调用 (invokevirtual)则是在调用的时候才确定具体的调用方法，这就是动态绑定，也是多态要解决的核心问题。JVM 的方法调用指令有四个，分别是 invokestatic，invokespecial，invokesvirtual 和 invokeinterface。前两个是静态绑定，后两个是动态绑定的。本文也可以说是对于JVM后两种调用实现的考察。</p>\n<h3 id=\"这篇文章讲得很好\"><a href=\"#这篇文章讲得很好\" class=\"headerlink\" title=\"这篇文章讲得很好\"></a>这篇文章讲得很好</h3><p><a href=\"https://www.ibm.com/developerworks/cn/java/j-lo-polymorph/index.html\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/java/j-lo-polymorph/index.html</a></p>\n"},{"title":"JVM-Profiling","date":"2017-11-07T07:36:54.000Z","_content":"\nhttps://yq.aliyun.com/articles/2390\n\n### heap dump\njmap -dump:format=b,file=heap.bin [java_process_id]","source":"_posts/JVM-Profiling.md","raw":"---\ntitle: JVM-Profiling\ndate: 2017-11-07 15:36:54\ntags: JVM\n---\n\nhttps://yq.aliyun.com/articles/2390\n\n### heap dump\njmap -dump:format=b,file=heap.bin [java_process_id]","slug":"JVM-Profiling","published":1,"updated":"2019-09-28T08:51:00.871Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83e002cv1np0pl6k3ym","content":"<p><a href=\"https://yq.aliyun.com/articles/2390\" target=\"_blank\" rel=\"noopener\">https://yq.aliyun.com/articles/2390</a></p>\n<h3 id=\"heap-dump\"><a href=\"#heap-dump\" class=\"headerlink\" title=\"heap dump\"></a>heap dump</h3><p>jmap -dump:format=b,file=heap.bin [java_process_id]</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://yq.aliyun.com/articles/2390\" target=\"_blank\" rel=\"noopener\">https://yq.aliyun.com/articles/2390</a></p>\n<h3 id=\"heap-dump\"><a href=\"#heap-dump\" class=\"headerlink\" title=\"heap dump\"></a>heap dump</h3><p>jmap -dump:format=b,file=heap.bin [java_process_id]</p>\n"},{"title":"JVM-JIT","date":"2018-09-29T07:27:11.000Z","_content":"\n\n### 查看JIT\njstat -printcompilation [pid] 1000\n\n\n### jvm调优之分层编译\nhttps://www.jianshu.com/p/318617435789\n```\n除了纯编译和默认的mixed之外，jvm 从jdk6u25 之后，引入了分层编译。HotSpot 内置两种编译器，分别是client启动时的c1编译器和server启动时的c2编译器，c2在将代码编译成机器代码的时候需要搜集大量的统计信息以便在编译的时候进行优化，因此编译出来的代码执行效率比较高，代价是程序启动时间比较长，而且需要执行比较长的时间，才能达到最高性能；与之相反， c1的目标是使程序尽快进入编译执行的阶段，所以在编译前需要搜集的信息比c2要少，编译速度因此提高很多，但是付出的代价是编译之后的代码执行效率比较低，但尽管如此，c1编译出来的代码在性能上比解释执行的性能已经有很大的提升，所以所谓的分层编译，就是一种折中方式，在系统执行初期，执行频率比较高的代码先被c1编译器编译，以便尽快进入编译执行，然后随着时间的推移，执行频率较高的代码再被c2编译器编译，以达到最高的性能。\n```\n\n\n\n``` src/share/vm/runtime/globals.hpp\n  develop(intx, HugeMethodLimit,  8000,                                     \\\n          \"Don't compile methods larger than this if \"                      \\\n          \"+DontCompileHugeMethods\") \n```\n\n``` src/share/vm/runtime/compilationPolicy.cpp\n// Returns true if m is allowed to be compiled\nbool CompilationPolicy::can_be_compiled(methodHandle m, int comp_level) {\n  // allow any levels for WhiteBox\n  assert(WhiteBoxAPI || comp_level == CompLevel_all || is_compile(comp_level), \"illegal compilation level\");\n\n  if (m->is_abstract()) return false;\n  if (DontCompileHugeMethods && m->code_size() > HugeMethodLimit) return false;\n\n  // Math intrinsics should never be compiled as this can lead to\n  // monotonicity problems because the interpreter will prefer the\n  // compiled code to the intrinsic version.  This can't happen in\n  // production because the invocation counter can't be incremented\n  // but we shouldn't expose the system to this problem in testing\n  // modes.\n  if (!AbstractInterpreter::can_be_compiled(m)) {\n    return false;\n  }\n  if (comp_level == CompLevel_all) {\n    if (TieredCompilation) {\n      // enough to be compilable at any level for tiered\n      return !m->is_not_compilable(CompLevel_simple) || !m->is_not_compilable(CompLevel_full_optimization);\n    } else {\n      // must be compilable at available level for non-tiered\n      return !m->is_not_compilable(CompLevel_highest_tier);\n    }\n  } else if (is_compile(comp_level)) {\n    return !m->is_not_compilable(comp_level);\n  }\n  return false;\n}\n```\n\n","source":"_posts/JVM-JIT.md","raw":"---\ntitle: JVM-JIT\ndate: 2018-09-29 15:27:11\ntags: JVM\n---\n\n\n### 查看JIT\njstat -printcompilation [pid] 1000\n\n\n### jvm调优之分层编译\nhttps://www.jianshu.com/p/318617435789\n```\n除了纯编译和默认的mixed之外，jvm 从jdk6u25 之后，引入了分层编译。HotSpot 内置两种编译器，分别是client启动时的c1编译器和server启动时的c2编译器，c2在将代码编译成机器代码的时候需要搜集大量的统计信息以便在编译的时候进行优化，因此编译出来的代码执行效率比较高，代价是程序启动时间比较长，而且需要执行比较长的时间，才能达到最高性能；与之相反， c1的目标是使程序尽快进入编译执行的阶段，所以在编译前需要搜集的信息比c2要少，编译速度因此提高很多，但是付出的代价是编译之后的代码执行效率比较低，但尽管如此，c1编译出来的代码在性能上比解释执行的性能已经有很大的提升，所以所谓的分层编译，就是一种折中方式，在系统执行初期，执行频率比较高的代码先被c1编译器编译，以便尽快进入编译执行，然后随着时间的推移，执行频率较高的代码再被c2编译器编译，以达到最高的性能。\n```\n\n\n\n``` src/share/vm/runtime/globals.hpp\n  develop(intx, HugeMethodLimit,  8000,                                     \\\n          \"Don't compile methods larger than this if \"                      \\\n          \"+DontCompileHugeMethods\") \n```\n\n``` src/share/vm/runtime/compilationPolicy.cpp\n// Returns true if m is allowed to be compiled\nbool CompilationPolicy::can_be_compiled(methodHandle m, int comp_level) {\n  // allow any levels for WhiteBox\n  assert(WhiteBoxAPI || comp_level == CompLevel_all || is_compile(comp_level), \"illegal compilation level\");\n\n  if (m->is_abstract()) return false;\n  if (DontCompileHugeMethods && m->code_size() > HugeMethodLimit) return false;\n\n  // Math intrinsics should never be compiled as this can lead to\n  // monotonicity problems because the interpreter will prefer the\n  // compiled code to the intrinsic version.  This can't happen in\n  // production because the invocation counter can't be incremented\n  // but we shouldn't expose the system to this problem in testing\n  // modes.\n  if (!AbstractInterpreter::can_be_compiled(m)) {\n    return false;\n  }\n  if (comp_level == CompLevel_all) {\n    if (TieredCompilation) {\n      // enough to be compilable at any level for tiered\n      return !m->is_not_compilable(CompLevel_simple) || !m->is_not_compilable(CompLevel_full_optimization);\n    } else {\n      // must be compilable at available level for non-tiered\n      return !m->is_not_compilable(CompLevel_highest_tier);\n    }\n  } else if (is_compile(comp_level)) {\n    return !m->is_not_compilable(comp_level);\n  }\n  return false;\n}\n```\n\n","slug":"JVM-JIT","published":1,"updated":"2019-09-28T08:51:00.869Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83f002dv1np1t2qf2jv","content":"<h3 id=\"查看JIT\"><a href=\"#查看JIT\" class=\"headerlink\" title=\"查看JIT\"></a>查看JIT</h3><p>jstat -printcompilation [pid] 1000</p>\n<h3 id=\"jvm调优之分层编译\"><a href=\"#jvm调优之分层编译\" class=\"headerlink\" title=\"jvm调优之分层编译\"></a>jvm调优之分层编译</h3><p><a href=\"https://www.jianshu.com/p/318617435789\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/318617435789</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">除了纯编译和默认的mixed之外，jvm 从jdk6u25 之后，引入了分层编译。HotSpot 内置两种编译器，分别是client启动时的c1编译器和server启动时的c2编译器，c2在将代码编译成机器代码的时候需要搜集大量的统计信息以便在编译的时候进行优化，因此编译出来的代码执行效率比较高，代价是程序启动时间比较长，而且需要执行比较长的时间，才能达到最高性能；与之相反， c1的目标是使程序尽快进入编译执行的阶段，所以在编译前需要搜集的信息比c2要少，编译速度因此提高很多，但是付出的代价是编译之后的代码执行效率比较低，但尽管如此，c1编译出来的代码在性能上比解释执行的性能已经有很大的提升，所以所谓的分层编译，就是一种折中方式，在系统执行初期，执行频率比较高的代码先被c1编译器编译，以便尽快进入编译执行，然后随着时间的推移，执行频率较高的代码再被c2编译器编译，以达到最高的性能。</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">develop(intx, HugeMethodLimit,  8000,                                     \\</span><br><span class=\"line\">        &quot;Don&apos;t compile methods larger than this if &quot;                      \\</span><br><span class=\"line\">        &quot;+DontCompileHugeMethods&quot;)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Returns true if m is allowed to be compiled</span><br><span class=\"line\">bool CompilationPolicy::can_be_compiled(methodHandle m, int comp_level) &#123;</span><br><span class=\"line\">  // allow any levels for WhiteBox</span><br><span class=\"line\">  assert(WhiteBoxAPI || comp_level == CompLevel_all || is_compile(comp_level), &quot;illegal compilation level&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">  if (m-&gt;is_abstract()) return false;</span><br><span class=\"line\">  if (DontCompileHugeMethods &amp;&amp; m-&gt;code_size() &gt; HugeMethodLimit) return false;</span><br><span class=\"line\"></span><br><span class=\"line\">  // Math intrinsics should never be compiled as this can lead to</span><br><span class=\"line\">  // monotonicity problems because the interpreter will prefer the</span><br><span class=\"line\">  // compiled code to the intrinsic version.  This can&apos;t happen in</span><br><span class=\"line\">  // production because the invocation counter can&apos;t be incremented</span><br><span class=\"line\">  // but we shouldn&apos;t expose the system to this problem in testing</span><br><span class=\"line\">  // modes.</span><br><span class=\"line\">  if (!AbstractInterpreter::can_be_compiled(m)) &#123;</span><br><span class=\"line\">    return false;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  if (comp_level == CompLevel_all) &#123;</span><br><span class=\"line\">    if (TieredCompilation) &#123;</span><br><span class=\"line\">      // enough to be compilable at any level for tiered</span><br><span class=\"line\">      return !m-&gt;is_not_compilable(CompLevel_simple) || !m-&gt;is_not_compilable(CompLevel_full_optimization);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      // must be compilable at available level for non-tiered</span><br><span class=\"line\">      return !m-&gt;is_not_compilable(CompLevel_highest_tier);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125; else if (is_compile(comp_level)) &#123;</span><br><span class=\"line\">    return !m-&gt;is_not_compilable(comp_level);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  return false;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"查看JIT\"><a href=\"#查看JIT\" class=\"headerlink\" title=\"查看JIT\"></a>查看JIT</h3><p>jstat -printcompilation [pid] 1000</p>\n<h3 id=\"jvm调优之分层编译\"><a href=\"#jvm调优之分层编译\" class=\"headerlink\" title=\"jvm调优之分层编译\"></a>jvm调优之分层编译</h3><p><a href=\"https://www.jianshu.com/p/318617435789\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/318617435789</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">除了纯编译和默认的mixed之外，jvm 从jdk6u25 之后，引入了分层编译。HotSpot 内置两种编译器，分别是client启动时的c1编译器和server启动时的c2编译器，c2在将代码编译成机器代码的时候需要搜集大量的统计信息以便在编译的时候进行优化，因此编译出来的代码执行效率比较高，代价是程序启动时间比较长，而且需要执行比较长的时间，才能达到最高性能；与之相反， c1的目标是使程序尽快进入编译执行的阶段，所以在编译前需要搜集的信息比c2要少，编译速度因此提高很多，但是付出的代价是编译之后的代码执行效率比较低，但尽管如此，c1编译出来的代码在性能上比解释执行的性能已经有很大的提升，所以所谓的分层编译，就是一种折中方式，在系统执行初期，执行频率比较高的代码先被c1编译器编译，以便尽快进入编译执行，然后随着时间的推移，执行频率较高的代码再被c2编译器编译，以达到最高的性能。</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">develop(intx, HugeMethodLimit,  8000,                                     \\</span><br><span class=\"line\">        &quot;Don&apos;t compile methods larger than this if &quot;                      \\</span><br><span class=\"line\">        &quot;+DontCompileHugeMethods&quot;)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Returns true if m is allowed to be compiled</span><br><span class=\"line\">bool CompilationPolicy::can_be_compiled(methodHandle m, int comp_level) &#123;</span><br><span class=\"line\">  // allow any levels for WhiteBox</span><br><span class=\"line\">  assert(WhiteBoxAPI || comp_level == CompLevel_all || is_compile(comp_level), &quot;illegal compilation level&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">  if (m-&gt;is_abstract()) return false;</span><br><span class=\"line\">  if (DontCompileHugeMethods &amp;&amp; m-&gt;code_size() &gt; HugeMethodLimit) return false;</span><br><span class=\"line\"></span><br><span class=\"line\">  // Math intrinsics should never be compiled as this can lead to</span><br><span class=\"line\">  // monotonicity problems because the interpreter will prefer the</span><br><span class=\"line\">  // compiled code to the intrinsic version.  This can&apos;t happen in</span><br><span class=\"line\">  // production because the invocation counter can&apos;t be incremented</span><br><span class=\"line\">  // but we shouldn&apos;t expose the system to this problem in testing</span><br><span class=\"line\">  // modes.</span><br><span class=\"line\">  if (!AbstractInterpreter::can_be_compiled(m)) &#123;</span><br><span class=\"line\">    return false;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  if (comp_level == CompLevel_all) &#123;</span><br><span class=\"line\">    if (TieredCompilation) &#123;</span><br><span class=\"line\">      // enough to be compilable at any level for tiered</span><br><span class=\"line\">      return !m-&gt;is_not_compilable(CompLevel_simple) || !m-&gt;is_not_compilable(CompLevel_full_optimization);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      // must be compilable at available level for non-tiered</span><br><span class=\"line\">      return !m-&gt;is_not_compilable(CompLevel_highest_tier);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125; else if (is_compile(comp_level)) &#123;</span><br><span class=\"line\">    return !m-&gt;is_not_compilable(comp_level);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  return false;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"JVM-Safepoint","date":"2018-10-04T08:22:34.000Z","_content":"\nhttps://blog.csdn.net/column/details/talk-about-jvm.html\n\n### 言简意赅\nhttps://juejin.im/post/5c0cd964f265da616e4c4340\n\n### 这篇写得很好\nhttps://blog.csdn.net/iter_zc/article/details/41847887\n\n### 这个要掌握\nhttps://www.lmax.com/blog/staff-blogs/2015/08/05/jvm-guaranteed-safepoints/\nhttp://www.importnew.com/16068.html\n如果线程非常多，可以用`GuaranteedSafepointInterval`提高”保证安全点”的执行频率，这样会有效减少暂停。\n\n### 江南白衣本衣\nhttp://www.10tiao.com/html/698/201808/2247483961/1.html\nhttp://calvin1978.blogcn.com/articles/safepoint.html\n\n### stackoverflow上的safepoint问题\nhttps://stackoverflow.com/questions/20134769/how-to-get-java-stacks-when-jvm-cant-reach-a-safepoint\n\n### 知乎\nhttps://www.zhihu.com/search?type=content&q=safepoint\n\n怎么看这段日志，结合GC日志和Safepoint就明白了，注意下，最后一条GC是不会显示`Total time for which application threads`的\n```\nHeap after GC invocations=30 (full 0):\n garbage-first heap   total 18374656K, used 1386562K [0x000000035e800000, 0x000000035f004618, 0x00000007c0000000)\n  region size 8192K, 14 young (114688K), 14 survivors (114688K)\n Metaspace       used 21800K, capacity 22150K, committed 22400K, reserved 1069056K\n  class space    used 2333K, capacity 2416K, committed 2432K, reserved 1048576K\n}\n [Times: user=0.28 sys=0.02, real=0.08 secs]\n2018-12-18T16:10:18.180+0800: 3439.538: Total time for which application threads were stopped: 0.1329005 seconds, Stopping threads took: 0.0095877 seconds\n2018-12-18T16:10:19.227+0800: 3440.586: Total time for which application threads were stopped: 0.0472667 seconds, Stopping threads took: 0.0095095 seconds\n2018-12-18T16:10:20.273+0800: 3441.632: Total time for which application threads were stopped: 0.0460854 seconds, Stopping threads took: 0.0094629 seconds\n2018-12-18T16:11:12.324+0800: 3493.682: Total time for which application threads were stopped: 0.0464605 seconds, Stopping threads took: 0.0094669 seconds\n2018-12-18T16:11:18.371+0800: 3499.729: Total time for which application threads were stopped: 0.0466823 seconds, Stopping threads took: 0.0094960 seconds\n2018-12-18T16:11:21.417+0800: 3502.775: Total time for which application threads were stopped: 0.0456646 seconds, Stopping threads took: 0.0093249 seconds\n2018-12-18T16:11:26.463+0800: 3507.822: Total time for which application threads were stopped: 0.0463651 seconds, Stopping threads took: 0.0094908 seconds\n2018-12-18T16:11:44.512+0800: 3525.870: Total time for which application threads were stopped: 0.0467351 seconds, Stopping threads took: 0.0094312 seconds\n2018-12-18T19:09:18.204+0800: 14179.563: [GC pause (G1 Evacuation Pause) (young) 14179.572: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 26650, predicted base time: 63.14 ms, remaining time: 0.00 ms, target pause time: 50.00 ms]\n 14179.572: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 100 regions, survivors: 12 regions, predicted young region time: 8.18 ms]\n 14179.572: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 100 regions, survivors: 12 regions, old: 0 regions, predicted pause time: 71.32 ms, target pause time: 50.00 ms]\n, 0.0791549 secs]\n   [Parallel Time: 39.9 ms, GC Workers: 8]\n      [GC Worker Start (ms): Min: 14179586.9, Avg: 14179587.0, Max: 14179587.2, Diff: 0.2]\n      [Ext Root Scanning (ms): Min: 18.2, Avg: 18.5, Max: 19.5, Diff: 1.2, Sum: 148.3]\n      [Update RS (ms): Min: 12.6, Avg: 13.5, Max: 13.6, Diff: 1.0, Sum: 107.6]\n         [Processed Buffers: Min: 2394, Avg: 2568.1, Max: 2899, Diff: 505, Sum: 20545]\n      [Scan RS (ms): Min: 1.1, Avg: 1.1, Max: 1.2, Diff: 0.1, Sum: 9.0]\n      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n      [Object Copy (ms): Min: 6.2, Avg: 6.3, Max: 6.4, Diff: 0.2, Sum: 50.4]\n      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n         [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 8]\n      [GC Worker Other (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.1, Sum: 0.8]\n      [GC Worker Total (ms): Min: 39.4, Avg: 39.5, Max: 39.7, Diff: 0.3, Sum: 316.3]\n      [GC Worker End (ms): Min: 14179626.5, Avg: 14179626.6, Max: 14179626.6, Diff: 0.1]\n   [Code Root Fixup: 0.1 ms]\n   [Code Root Purge: 0.0 ms]\n   [Clear CT: 0.4 ms]\n   [Other: 38.8 ms]\n      [Choose CSet: 0.0 ms]\n      [Ref Proc: 3.6 ms]\n      [Ref Enq: 0.2 ms]\n      [Redirty Cards: 0.2 ms]\n      [Humongous Register: 0.1 ms]\n      [Humongous Reclaim: 0.0 ms]\n      [Free CSet: 0.2 ms]\n   [Eden: 800.0M(800.0M)->0.0B(784.0M) Survivors: 96.0M->112.0M Heap: 4178.0M(17.5G)->3408.0M(17.5G)]\nHeap after GC invocations=137 (full 0):\n garbage-first heap   total 18374656K, used 3489792K [0x000000035e800000, 0x000000035f004618, 0x00000007c0000000)\n  region size 8192K, 14 young (114688K), 14 survivors (114688K)\n Metaspace       used 21988K, capacity 22278K, committed 22400K, reserved 1069056K\n  class space    used 2342K, capacity 2416K, committed 2432K, reserved 1048576K\n}\n [Times: user=0.29 sys=0.00, real=0.09 secs]\n```\n```\n3439.405: G1IncCollectionPause             [   24775          0              1    ]      [     0     0     9    33    83    ]  0\n3440.538: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n3441.586: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n3493.636: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n3499.683: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n3502.729: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n3507.776: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n3525.823: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n14179.520: G1IncCollectionPause             [   24775          0              0    ]      [     0     0     6    33    85    ]  0\n```\n\n\n### 奇怪日志 Stopping threads took: 1.7947183 seconds\n```\n{Heap before GC invocations=64561 (full 0):\n garbage-first heap   total 8388608K, used 5195988K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)\n  region size 16384K, 256 young (4194304K), 1 survivors (16384K)\n Metaspace       used 24248K, capacity 25174K, committed 25472K, reserved 1073152K\n  class space    used 2341K, capacity 2570K, committed 2688K, reserved 1048576K\n2018-12-21T00:43:08.483+0800: 3836207.662: [GC pause (G1 Evacuation Pause) (young)\nDesired survivor size 268435456 bytes, new threshold 15 (max 15)\n- age   1:    1204016 bytes,    1204016 total\n- age   2:     116808 bytes,    1320824 total\n- age   3:      22992 bytes,    1343816 total\n- age   4:      31216 bytes,    1375032 total\n- age   5:      18072 bytes,    1393104 total\n- age   6:      21472 bytes,    1414576 total\n- age   7:      14512 bytes,    1429088 total\n- age   8:      16472 bytes,    1445560 total\n- age   9:      13664 bytes,    1459224 total\n- age  10:      12784 bytes,    1472008 total\n- age  11:      12888 bytes,    1484896 total\n- age  12:      11040 bytes,    1495936 total\n- age  13:      35480 bytes,    1531416 total\n- age  14:      11008 bytes,    1542424 total\n- age  15:      11360 bytes,    1553784 total\n 3836207.662: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 3421, predicted base time: 6.10 ms, remaining time: 193\n.90 ms, target pause time: 200.00 ms]\n 3836207.662: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 255 regions, survivors: 1 regions, predicted young region t\nime: 0.99 ms]\n 3836207.662: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 255 regions, survivors: 1 regions, old: 0 regions, predicted pau\nse time: 7.09 ms, target pause time: 200.00 ms]\n2018-12-21T00:43:08.487+0800: 3836207.666: [SoftReference, 0 refs, 0.0008333 secs]2018-12-21T00:43:08.487+0800: 3836207.666: [WeakReference, 0 refs, 0.0004842 secs]2018-12-21T00:43:08.488+0800: 3836207.667: [FinalReference, 36 refs, 0.0003903 secs]2018-12-21T00:43:08.488+0800: 3836207.667: [PhantomReference, 0 refs, 1 refs, 0.0011838 secs]2018-12-21T00:43:08.490+0800: 3836207.669: [JNI Weak Reference, 0.0000125 secs], 0.0076618 secs]\n   [Parallel Time: 2.9 ms, GC Workers: 8]\n      [GC Worker Start (ms): Min: 3836207662.5, Avg: 3836207662.6, Max: 3836207662.7, Diff: 0.2]\n      [Ext Root Scanning (ms): Min: 0.5, Avg: 0.6, Max: 0.7, Diff: 0.2, Sum: 5.1]\n      [Update RS (ms): Min: 0.7, Avg: 0.8, Max: 0.9, Diff: 0.2, Sum: 6.5]\n         [Processed Buffers: Min: 3, Avg: 14.1, Max: 28, Diff: 25, Sum: 113]\n      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.4]\n      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n      [Object Copy (ms): Min: 0.9, Avg: 1.0, Max: 1.1, Diff: 0.1, Sum: 8.0]\n      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n         [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 8]\n      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.3]\n      [GC Worker Total (ms): Min: 2.4, Avg: 2.6, Max: 2.6, Diff: 0.2, Sum: 20.4]\n      [GC Worker End (ms): Min: 3836207665.1, Avg: 3836207665.2, Max: 3836207665.2, Diff: 0.1]\n   [Code Root Fixup: 0.0 ms]\n   [Code Root Purge: 0.0 ms]\n   [Clear CT: 0.4 ms]\n   [Other: 4.3 ms]\n      [Choose CSet: 0.0 ms]\n      [Ref Proc: 3.2 ms]\n      [Ref Enq: 0.2 ms]\n      [Redirty Cards: 0.2 ms]\n      [Humongous Register: 0.0 ms]\n      [Humongous Reclaim: 0.0 ms]\n      [Free CSet: 0.3 ms]\n   [Eden: 4080.0M(4080.0M)->0.0B(4080.0M) Survivors: 16.0M->16.0M Heap: 5074.2M(8192.0M)->994.1M(8192.0M)]\nHeap after GC invocations=64562 (full 0):\n garbage-first heap   total 8388608K, used 1017975K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)\n  region size 16384K, 1 young (16384K), 1 survivors (16384K)\n Metaspace       used 24248K, capacity 25174K, committed 25472K, reserved 1073152K\n  class space    used 2341K, capacity 2570K, committed 2688K, reserved 1048576K\n}\n [Times: user=0.00 sys=0.00, real=0.01 secs]\n2018-12-21T00:43:08.491+0800: 3836207.670: Total time for which application threads were stopped: 1.8036386 seconds, Stopping threads took: 1.7947183 seconds\n```\n\n### 疑问 page_trap_count=1 代表什么，系统有STW\n         vmop                    [threads: total initially_running wait_to_block]    [time: spin block sync cleanup vmop] page_trap_count\n380.671: G1IncCollectionPause             [     167          1              2    ]      [     0     0     0     0    14    ]  1\n\n### 日志\n-XX:+PrintSafepointStatistics\n```\n         vmop                    [threads: total initially_running wait_to_block]    [time: spin block sync cleanup vmop] page_trap_count\n0.265: Deoptimize                       [       9          0              0    ]      [     0     0     0     0     0    ]  0\n0.312: G1IncCollectionPause             [       9          0              0    ]      [     0     0     0     0    11    ]  0\n0.366: Deoptimize                       [      10          0              0    ]      [     0     0     0     0     0    ]  0\n0.369: Deoptimize                       [      10          0              0    ]      [     0     0     0     0     0    ]  0\n0.376: G1IncCollectionPause             [      10          0              0    ]      [     0     0     0     0     6    ]  0\n0.432: Deoptimize                       [      12          0              0    ]      [     0     0     0     0     0    ]  0\n0.532: G1IncCollectionPause             [      12          0              0    ]      [     0     0     0     0     4    ]  0\n0.644: G1IncCollectionPause             [      12          1              0    ]      [     0     0     0     0     8    ]  0\n0.678: G1IncCollectionPause             [      12          0              0    ]      [     0     0     0     0     9    ]  0\n0.715: G1IncCollectionPause             [      12          1              0    ]      [     0     0     0     0     8    ]  0\n0.917: EnableBiasedLocking              [      12          0              0    ]      [     0     0     0     0     0    ]  0\n0.961: G1IncCollectionPause             [      13          0              0    ]      [     0     0     0     0     4    ]  0\n0.967: RevokeBias                       [      14          1              1    ]      [     2     0     2     0     0    ]  0\n0.974: RevokeBias                       [      14          0              2    ]      [     0     0     0     0     0    ]  0\n0.982: G1IncCollectionPause             [      14          1              2    ]      [     3     0     4     0     7    ]  0\n1.003: G1IncCollectionPause             [      14          0              0    ]      [     0     0     0     0     3    ]  0\n1.007: G1IncCollectionPause             [      14          0              0    ]      [     0     0     0     0     2    ]  0\n1.010: G1IncCollectionPause             [      14          0              0    ]      [     0     0     0     0     5    ]  0\n1.016: G1IncCollectionPause             [      14          0              1    ]      [     0     0     0     0     5    ]  0\n1.028: G1IncCollectionPause             [      16          0              1    ]      [     0     0     0     0     8    ]  0\n1.040: G1IncCollectionPause             [      16          0              2    ]      [     0     0     0     0    44    ]  0\n1.086: CGC_Operation                    [      16          0              0    ]      [     0     0     0     0    13    ]  0\n1.100: CGC_Operation                    [      16          0              0    ]      [     0     0     0     0     0    ]  0\n1.110: G1IncCollectionPause             [      18          1              1    ]      [     0     0     0     0    67    ]  0\n1.179: G1IncCollectionPause             [      20          0              0    ]      [     0     0     0     0    47    ]  0\n1.228: G1IncCollectionPause             [      20          0              0    ]      [     0     0     0     0    39    ]  0\n1.268: RevokeBias                       [      22          0              1    ]      [     0     0     0     0     0    ]  0\n1.269: RevokeBias                       [      23          0              1    ]      [     0     0     0     0     0    ]  0\n2.269: no vm operation                  [      25          0              0    ]      [     0     0     0     0     0    ]  0\n6.665: RevokeBias                       [      28          0              0    ]      [     0     0     0     0     0    ]  0\n```\n\n### 源码\n```\nvoid VMThread::execute(VM_Operation* op) {\n  Thread* t = Thread::current();\n\n  if (!t->is_VM_thread()) {\n    SkipGCALot sgcalot(t);    // avoid re-entrant attempts to gc-a-lot\n    // JavaThread or WatcherThread\n    bool concurrent = op->evaluate_concurrently();\n    // only blocking VM operations need to verify the caller's safepoint state:\n    if (!concurrent) {\n      t->check_for_valid_safepoint_state(true);\n    }\n\n    // New request from Java thread, evaluate prologue\n    if (!op->doit_prologue()) {\n      return;   // op was cancelled\n    }\n\n    // Setup VM_operations for execution\n    op->set_calling_thread(t, Thread::get_priority(t));\n\n    // It does not make sense to execute the epilogue, if the VM operation object is getting\n    // deallocated by the VM thread.\n    bool execute_epilog = !op->is_cheap_allocated();\n    assert(!concurrent || op->is_cheap_allocated(), \"concurrent => cheap_allocated\");\n\n    // Get ticket number for non-concurrent VM operations\n    int ticket = 0;\n    if (!concurrent) {\n      ticket = t->vm_operation_ticket();\n    }\n\n    // Add VM operation to list of waiting threads. We are guaranteed not to block while holding the\n    // VMOperationQueue_lock, so we can block without a safepoint check. This allows vm operation requests\n    // to be queued up during a safepoint synchronization.\n    {\n      VMOperationQueue_lock->lock_without_safepoint_check();\n      bool ok = _vm_queue->add(op);\n    op->set_timestamp(os::javaTimeMillis());\n      VMOperationQueue_lock->notify();\n      VMOperationQueue_lock->unlock();\n      // VM_Operation got skipped\n      if (!ok) {\n        assert(concurrent, \"can only skip concurrent tasks\");\n        if (op->is_cheap_allocated()) delete op;\n        return;\n      }\n    }\n\n    if (!concurrent) {\n      // Wait for completion of request (non-concurrent)\n      // Note: only a JavaThread triggers the safepoint check when locking\n      MutexLocker mu(VMOperationRequest_lock);\n      while(t->vm_operation_completed_count() < ticket) {\n        VMOperationRequest_lock->wait(!t->is_Java_thread());\n      }\n    }\n\n    if (execute_epilog) {\n      op->doit_epilogue();\n    }\n  } else {\n    // invoked by VM thread; usually nested VM operation\n    assert(t->is_VM_thread(), \"must be a VM thread\");\n    VM_Operation* prev_vm_operation = vm_operation();\n    if (prev_vm_operation != NULL) {\n      // Check the VM operation allows nested VM operation. This normally not the case, e.g., the compiler\n      // does not allow nested scavenges or compiles.\n      if (!prev_vm_operation->allow_nested_vm_operations()) {\n        fatal(\"Nested VM operation %s requested by operation %s\",\n              op->name(), vm_operation()->name());\n      }\n      op->set_calling_thread(prev_vm_operation->calling_thread(), prev_vm_operation->priority());\n    }\n\n    EventMark em(\"Executing %s VM operation: %s\", prev_vm_operation ? \"nested\" : \"\", op->name());\n\n    // Release all internal handles after operation is evaluated\n    HandleMark hm(t);\n    _cur_vm_operation = op;\n\n    if (op->evaluate_at_safepoint() && !SafepointSynchronize::is_at_safepoint()) {\n      SafepointSynchronize::begin();\n      op->evaluate();\n      SafepointSynchronize::end();\n    } else {\n      op->evaluate();\n    }\n\n    // Free memory if needed\n    if (op->is_cheap_allocated()) delete op;\n\n    _cur_vm_operation = prev_vm_operation;\n  }\n}\n```","source":"_posts/JVM-Safepoint.md","raw":"---\ntitle: JVM-Safepoint\ndate: 2018-10-04 16:22:34\ntags: JVM\n---\n\nhttps://blog.csdn.net/column/details/talk-about-jvm.html\n\n### 言简意赅\nhttps://juejin.im/post/5c0cd964f265da616e4c4340\n\n### 这篇写得很好\nhttps://blog.csdn.net/iter_zc/article/details/41847887\n\n### 这个要掌握\nhttps://www.lmax.com/blog/staff-blogs/2015/08/05/jvm-guaranteed-safepoints/\nhttp://www.importnew.com/16068.html\n如果线程非常多，可以用`GuaranteedSafepointInterval`提高”保证安全点”的执行频率，这样会有效减少暂停。\n\n### 江南白衣本衣\nhttp://www.10tiao.com/html/698/201808/2247483961/1.html\nhttp://calvin1978.blogcn.com/articles/safepoint.html\n\n### stackoverflow上的safepoint问题\nhttps://stackoverflow.com/questions/20134769/how-to-get-java-stacks-when-jvm-cant-reach-a-safepoint\n\n### 知乎\nhttps://www.zhihu.com/search?type=content&q=safepoint\n\n怎么看这段日志，结合GC日志和Safepoint就明白了，注意下，最后一条GC是不会显示`Total time for which application threads`的\n```\nHeap after GC invocations=30 (full 0):\n garbage-first heap   total 18374656K, used 1386562K [0x000000035e800000, 0x000000035f004618, 0x00000007c0000000)\n  region size 8192K, 14 young (114688K), 14 survivors (114688K)\n Metaspace       used 21800K, capacity 22150K, committed 22400K, reserved 1069056K\n  class space    used 2333K, capacity 2416K, committed 2432K, reserved 1048576K\n}\n [Times: user=0.28 sys=0.02, real=0.08 secs]\n2018-12-18T16:10:18.180+0800: 3439.538: Total time for which application threads were stopped: 0.1329005 seconds, Stopping threads took: 0.0095877 seconds\n2018-12-18T16:10:19.227+0800: 3440.586: Total time for which application threads were stopped: 0.0472667 seconds, Stopping threads took: 0.0095095 seconds\n2018-12-18T16:10:20.273+0800: 3441.632: Total time for which application threads were stopped: 0.0460854 seconds, Stopping threads took: 0.0094629 seconds\n2018-12-18T16:11:12.324+0800: 3493.682: Total time for which application threads were stopped: 0.0464605 seconds, Stopping threads took: 0.0094669 seconds\n2018-12-18T16:11:18.371+0800: 3499.729: Total time for which application threads were stopped: 0.0466823 seconds, Stopping threads took: 0.0094960 seconds\n2018-12-18T16:11:21.417+0800: 3502.775: Total time for which application threads were stopped: 0.0456646 seconds, Stopping threads took: 0.0093249 seconds\n2018-12-18T16:11:26.463+0800: 3507.822: Total time for which application threads were stopped: 0.0463651 seconds, Stopping threads took: 0.0094908 seconds\n2018-12-18T16:11:44.512+0800: 3525.870: Total time for which application threads were stopped: 0.0467351 seconds, Stopping threads took: 0.0094312 seconds\n2018-12-18T19:09:18.204+0800: 14179.563: [GC pause (G1 Evacuation Pause) (young) 14179.572: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 26650, predicted base time: 63.14 ms, remaining time: 0.00 ms, target pause time: 50.00 ms]\n 14179.572: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 100 regions, survivors: 12 regions, predicted young region time: 8.18 ms]\n 14179.572: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 100 regions, survivors: 12 regions, old: 0 regions, predicted pause time: 71.32 ms, target pause time: 50.00 ms]\n, 0.0791549 secs]\n   [Parallel Time: 39.9 ms, GC Workers: 8]\n      [GC Worker Start (ms): Min: 14179586.9, Avg: 14179587.0, Max: 14179587.2, Diff: 0.2]\n      [Ext Root Scanning (ms): Min: 18.2, Avg: 18.5, Max: 19.5, Diff: 1.2, Sum: 148.3]\n      [Update RS (ms): Min: 12.6, Avg: 13.5, Max: 13.6, Diff: 1.0, Sum: 107.6]\n         [Processed Buffers: Min: 2394, Avg: 2568.1, Max: 2899, Diff: 505, Sum: 20545]\n      [Scan RS (ms): Min: 1.1, Avg: 1.1, Max: 1.2, Diff: 0.1, Sum: 9.0]\n      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n      [Object Copy (ms): Min: 6.2, Avg: 6.3, Max: 6.4, Diff: 0.2, Sum: 50.4]\n      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n         [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 8]\n      [GC Worker Other (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.1, Sum: 0.8]\n      [GC Worker Total (ms): Min: 39.4, Avg: 39.5, Max: 39.7, Diff: 0.3, Sum: 316.3]\n      [GC Worker End (ms): Min: 14179626.5, Avg: 14179626.6, Max: 14179626.6, Diff: 0.1]\n   [Code Root Fixup: 0.1 ms]\n   [Code Root Purge: 0.0 ms]\n   [Clear CT: 0.4 ms]\n   [Other: 38.8 ms]\n      [Choose CSet: 0.0 ms]\n      [Ref Proc: 3.6 ms]\n      [Ref Enq: 0.2 ms]\n      [Redirty Cards: 0.2 ms]\n      [Humongous Register: 0.1 ms]\n      [Humongous Reclaim: 0.0 ms]\n      [Free CSet: 0.2 ms]\n   [Eden: 800.0M(800.0M)->0.0B(784.0M) Survivors: 96.0M->112.0M Heap: 4178.0M(17.5G)->3408.0M(17.5G)]\nHeap after GC invocations=137 (full 0):\n garbage-first heap   total 18374656K, used 3489792K [0x000000035e800000, 0x000000035f004618, 0x00000007c0000000)\n  region size 8192K, 14 young (114688K), 14 survivors (114688K)\n Metaspace       used 21988K, capacity 22278K, committed 22400K, reserved 1069056K\n  class space    used 2342K, capacity 2416K, committed 2432K, reserved 1048576K\n}\n [Times: user=0.29 sys=0.00, real=0.09 secs]\n```\n```\n3439.405: G1IncCollectionPause             [   24775          0              1    ]      [     0     0     9    33    83    ]  0\n3440.538: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n3441.586: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n3493.636: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n3499.683: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n3502.729: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n3507.776: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n3525.823: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0\n14179.520: G1IncCollectionPause             [   24775          0              0    ]      [     0     0     6    33    85    ]  0\n```\n\n\n### 奇怪日志 Stopping threads took: 1.7947183 seconds\n```\n{Heap before GC invocations=64561 (full 0):\n garbage-first heap   total 8388608K, used 5195988K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)\n  region size 16384K, 256 young (4194304K), 1 survivors (16384K)\n Metaspace       used 24248K, capacity 25174K, committed 25472K, reserved 1073152K\n  class space    used 2341K, capacity 2570K, committed 2688K, reserved 1048576K\n2018-12-21T00:43:08.483+0800: 3836207.662: [GC pause (G1 Evacuation Pause) (young)\nDesired survivor size 268435456 bytes, new threshold 15 (max 15)\n- age   1:    1204016 bytes,    1204016 total\n- age   2:     116808 bytes,    1320824 total\n- age   3:      22992 bytes,    1343816 total\n- age   4:      31216 bytes,    1375032 total\n- age   5:      18072 bytes,    1393104 total\n- age   6:      21472 bytes,    1414576 total\n- age   7:      14512 bytes,    1429088 total\n- age   8:      16472 bytes,    1445560 total\n- age   9:      13664 bytes,    1459224 total\n- age  10:      12784 bytes,    1472008 total\n- age  11:      12888 bytes,    1484896 total\n- age  12:      11040 bytes,    1495936 total\n- age  13:      35480 bytes,    1531416 total\n- age  14:      11008 bytes,    1542424 total\n- age  15:      11360 bytes,    1553784 total\n 3836207.662: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 3421, predicted base time: 6.10 ms, remaining time: 193\n.90 ms, target pause time: 200.00 ms]\n 3836207.662: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 255 regions, survivors: 1 regions, predicted young region t\nime: 0.99 ms]\n 3836207.662: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 255 regions, survivors: 1 regions, old: 0 regions, predicted pau\nse time: 7.09 ms, target pause time: 200.00 ms]\n2018-12-21T00:43:08.487+0800: 3836207.666: [SoftReference, 0 refs, 0.0008333 secs]2018-12-21T00:43:08.487+0800: 3836207.666: [WeakReference, 0 refs, 0.0004842 secs]2018-12-21T00:43:08.488+0800: 3836207.667: [FinalReference, 36 refs, 0.0003903 secs]2018-12-21T00:43:08.488+0800: 3836207.667: [PhantomReference, 0 refs, 1 refs, 0.0011838 secs]2018-12-21T00:43:08.490+0800: 3836207.669: [JNI Weak Reference, 0.0000125 secs], 0.0076618 secs]\n   [Parallel Time: 2.9 ms, GC Workers: 8]\n      [GC Worker Start (ms): Min: 3836207662.5, Avg: 3836207662.6, Max: 3836207662.7, Diff: 0.2]\n      [Ext Root Scanning (ms): Min: 0.5, Avg: 0.6, Max: 0.7, Diff: 0.2, Sum: 5.1]\n      [Update RS (ms): Min: 0.7, Avg: 0.8, Max: 0.9, Diff: 0.2, Sum: 6.5]\n         [Processed Buffers: Min: 3, Avg: 14.1, Max: 28, Diff: 25, Sum: 113]\n      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.4]\n      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n      [Object Copy (ms): Min: 0.9, Avg: 1.0, Max: 1.1, Diff: 0.1, Sum: 8.0]\n      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n         [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 8]\n      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.3]\n      [GC Worker Total (ms): Min: 2.4, Avg: 2.6, Max: 2.6, Diff: 0.2, Sum: 20.4]\n      [GC Worker End (ms): Min: 3836207665.1, Avg: 3836207665.2, Max: 3836207665.2, Diff: 0.1]\n   [Code Root Fixup: 0.0 ms]\n   [Code Root Purge: 0.0 ms]\n   [Clear CT: 0.4 ms]\n   [Other: 4.3 ms]\n      [Choose CSet: 0.0 ms]\n      [Ref Proc: 3.2 ms]\n      [Ref Enq: 0.2 ms]\n      [Redirty Cards: 0.2 ms]\n      [Humongous Register: 0.0 ms]\n      [Humongous Reclaim: 0.0 ms]\n      [Free CSet: 0.3 ms]\n   [Eden: 4080.0M(4080.0M)->0.0B(4080.0M) Survivors: 16.0M->16.0M Heap: 5074.2M(8192.0M)->994.1M(8192.0M)]\nHeap after GC invocations=64562 (full 0):\n garbage-first heap   total 8388608K, used 1017975K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)\n  region size 16384K, 1 young (16384K), 1 survivors (16384K)\n Metaspace       used 24248K, capacity 25174K, committed 25472K, reserved 1073152K\n  class space    used 2341K, capacity 2570K, committed 2688K, reserved 1048576K\n}\n [Times: user=0.00 sys=0.00, real=0.01 secs]\n2018-12-21T00:43:08.491+0800: 3836207.670: Total time for which application threads were stopped: 1.8036386 seconds, Stopping threads took: 1.7947183 seconds\n```\n\n### 疑问 page_trap_count=1 代表什么，系统有STW\n         vmop                    [threads: total initially_running wait_to_block]    [time: spin block sync cleanup vmop] page_trap_count\n380.671: G1IncCollectionPause             [     167          1              2    ]      [     0     0     0     0    14    ]  1\n\n### 日志\n-XX:+PrintSafepointStatistics\n```\n         vmop                    [threads: total initially_running wait_to_block]    [time: spin block sync cleanup vmop] page_trap_count\n0.265: Deoptimize                       [       9          0              0    ]      [     0     0     0     0     0    ]  0\n0.312: G1IncCollectionPause             [       9          0              0    ]      [     0     0     0     0    11    ]  0\n0.366: Deoptimize                       [      10          0              0    ]      [     0     0     0     0     0    ]  0\n0.369: Deoptimize                       [      10          0              0    ]      [     0     0     0     0     0    ]  0\n0.376: G1IncCollectionPause             [      10          0              0    ]      [     0     0     0     0     6    ]  0\n0.432: Deoptimize                       [      12          0              0    ]      [     0     0     0     0     0    ]  0\n0.532: G1IncCollectionPause             [      12          0              0    ]      [     0     0     0     0     4    ]  0\n0.644: G1IncCollectionPause             [      12          1              0    ]      [     0     0     0     0     8    ]  0\n0.678: G1IncCollectionPause             [      12          0              0    ]      [     0     0     0     0     9    ]  0\n0.715: G1IncCollectionPause             [      12          1              0    ]      [     0     0     0     0     8    ]  0\n0.917: EnableBiasedLocking              [      12          0              0    ]      [     0     0     0     0     0    ]  0\n0.961: G1IncCollectionPause             [      13          0              0    ]      [     0     0     0     0     4    ]  0\n0.967: RevokeBias                       [      14          1              1    ]      [     2     0     2     0     0    ]  0\n0.974: RevokeBias                       [      14          0              2    ]      [     0     0     0     0     0    ]  0\n0.982: G1IncCollectionPause             [      14          1              2    ]      [     3     0     4     0     7    ]  0\n1.003: G1IncCollectionPause             [      14          0              0    ]      [     0     0     0     0     3    ]  0\n1.007: G1IncCollectionPause             [      14          0              0    ]      [     0     0     0     0     2    ]  0\n1.010: G1IncCollectionPause             [      14          0              0    ]      [     0     0     0     0     5    ]  0\n1.016: G1IncCollectionPause             [      14          0              1    ]      [     0     0     0     0     5    ]  0\n1.028: G1IncCollectionPause             [      16          0              1    ]      [     0     0     0     0     8    ]  0\n1.040: G1IncCollectionPause             [      16          0              2    ]      [     0     0     0     0    44    ]  0\n1.086: CGC_Operation                    [      16          0              0    ]      [     0     0     0     0    13    ]  0\n1.100: CGC_Operation                    [      16          0              0    ]      [     0     0     0     0     0    ]  0\n1.110: G1IncCollectionPause             [      18          1              1    ]      [     0     0     0     0    67    ]  0\n1.179: G1IncCollectionPause             [      20          0              0    ]      [     0     0     0     0    47    ]  0\n1.228: G1IncCollectionPause             [      20          0              0    ]      [     0     0     0     0    39    ]  0\n1.268: RevokeBias                       [      22          0              1    ]      [     0     0     0     0     0    ]  0\n1.269: RevokeBias                       [      23          0              1    ]      [     0     0     0     0     0    ]  0\n2.269: no vm operation                  [      25          0              0    ]      [     0     0     0     0     0    ]  0\n6.665: RevokeBias                       [      28          0              0    ]      [     0     0     0     0     0    ]  0\n```\n\n### 源码\n```\nvoid VMThread::execute(VM_Operation* op) {\n  Thread* t = Thread::current();\n\n  if (!t->is_VM_thread()) {\n    SkipGCALot sgcalot(t);    // avoid re-entrant attempts to gc-a-lot\n    // JavaThread or WatcherThread\n    bool concurrent = op->evaluate_concurrently();\n    // only blocking VM operations need to verify the caller's safepoint state:\n    if (!concurrent) {\n      t->check_for_valid_safepoint_state(true);\n    }\n\n    // New request from Java thread, evaluate prologue\n    if (!op->doit_prologue()) {\n      return;   // op was cancelled\n    }\n\n    // Setup VM_operations for execution\n    op->set_calling_thread(t, Thread::get_priority(t));\n\n    // It does not make sense to execute the epilogue, if the VM operation object is getting\n    // deallocated by the VM thread.\n    bool execute_epilog = !op->is_cheap_allocated();\n    assert(!concurrent || op->is_cheap_allocated(), \"concurrent => cheap_allocated\");\n\n    // Get ticket number for non-concurrent VM operations\n    int ticket = 0;\n    if (!concurrent) {\n      ticket = t->vm_operation_ticket();\n    }\n\n    // Add VM operation to list of waiting threads. We are guaranteed not to block while holding the\n    // VMOperationQueue_lock, so we can block without a safepoint check. This allows vm operation requests\n    // to be queued up during a safepoint synchronization.\n    {\n      VMOperationQueue_lock->lock_without_safepoint_check();\n      bool ok = _vm_queue->add(op);\n    op->set_timestamp(os::javaTimeMillis());\n      VMOperationQueue_lock->notify();\n      VMOperationQueue_lock->unlock();\n      // VM_Operation got skipped\n      if (!ok) {\n        assert(concurrent, \"can only skip concurrent tasks\");\n        if (op->is_cheap_allocated()) delete op;\n        return;\n      }\n    }\n\n    if (!concurrent) {\n      // Wait for completion of request (non-concurrent)\n      // Note: only a JavaThread triggers the safepoint check when locking\n      MutexLocker mu(VMOperationRequest_lock);\n      while(t->vm_operation_completed_count() < ticket) {\n        VMOperationRequest_lock->wait(!t->is_Java_thread());\n      }\n    }\n\n    if (execute_epilog) {\n      op->doit_epilogue();\n    }\n  } else {\n    // invoked by VM thread; usually nested VM operation\n    assert(t->is_VM_thread(), \"must be a VM thread\");\n    VM_Operation* prev_vm_operation = vm_operation();\n    if (prev_vm_operation != NULL) {\n      // Check the VM operation allows nested VM operation. This normally not the case, e.g., the compiler\n      // does not allow nested scavenges or compiles.\n      if (!prev_vm_operation->allow_nested_vm_operations()) {\n        fatal(\"Nested VM operation %s requested by operation %s\",\n              op->name(), vm_operation()->name());\n      }\n      op->set_calling_thread(prev_vm_operation->calling_thread(), prev_vm_operation->priority());\n    }\n\n    EventMark em(\"Executing %s VM operation: %s\", prev_vm_operation ? \"nested\" : \"\", op->name());\n\n    // Release all internal handles after operation is evaluated\n    HandleMark hm(t);\n    _cur_vm_operation = op;\n\n    if (op->evaluate_at_safepoint() && !SafepointSynchronize::is_at_safepoint()) {\n      SafepointSynchronize::begin();\n      op->evaluate();\n      SafepointSynchronize::end();\n    } else {\n      op->evaluate();\n    }\n\n    // Free memory if needed\n    if (op->is_cheap_allocated()) delete op;\n\n    _cur_vm_operation = prev_vm_operation;\n  }\n}\n```","slug":"JVM-Safepoint","published":1,"updated":"2019-09-28T08:51:00.871Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83f002ev1npjbezdwai","content":"<p><a href=\"https://blog.csdn.net/column/details/talk-about-jvm.html\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/column/details/talk-about-jvm.html</a></p>\n<h3 id=\"言简意赅\"><a href=\"#言简意赅\" class=\"headerlink\" title=\"言简意赅\"></a>言简意赅</h3><p><a href=\"https://juejin.im/post/5c0cd964f265da616e4c4340\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5c0cd964f265da616e4c4340</a></p>\n<h3 id=\"这篇写得很好\"><a href=\"#这篇写得很好\" class=\"headerlink\" title=\"这篇写得很好\"></a>这篇写得很好</h3><p><a href=\"https://blog.csdn.net/iter_zc/article/details/41847887\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/iter_zc/article/details/41847887</a></p>\n<h3 id=\"这个要掌握\"><a href=\"#这个要掌握\" class=\"headerlink\" title=\"这个要掌握\"></a>这个要掌握</h3><p><a href=\"https://www.lmax.com/blog/staff-blogs/2015/08/05/jvm-guaranteed-safepoints/\" target=\"_blank\" rel=\"noopener\">https://www.lmax.com/blog/staff-blogs/2015/08/05/jvm-guaranteed-safepoints/</a><br><a href=\"http://www.importnew.com/16068.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/16068.html</a><br>如果线程非常多，可以用<code>GuaranteedSafepointInterval</code>提高”保证安全点”的执行频率，这样会有效减少暂停。</p>\n<h3 id=\"江南白衣本衣\"><a href=\"#江南白衣本衣\" class=\"headerlink\" title=\"江南白衣本衣\"></a>江南白衣本衣</h3><p><a href=\"http://www.10tiao.com/html/698/201808/2247483961/1.html\" target=\"_blank\" rel=\"noopener\">http://www.10tiao.com/html/698/201808/2247483961/1.html</a><br><a href=\"http://calvin1978.blogcn.com/articles/safepoint.html\" target=\"_blank\" rel=\"noopener\">http://calvin1978.blogcn.com/articles/safepoint.html</a></p>\n<h3 id=\"stackoverflow上的safepoint问题\"><a href=\"#stackoverflow上的safepoint问题\" class=\"headerlink\" title=\"stackoverflow上的safepoint问题\"></a>stackoverflow上的safepoint问题</h3><p><a href=\"https://stackoverflow.com/questions/20134769/how-to-get-java-stacks-when-jvm-cant-reach-a-safepoint\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/20134769/how-to-get-java-stacks-when-jvm-cant-reach-a-safepoint</a></p>\n<h3 id=\"知乎\"><a href=\"#知乎\" class=\"headerlink\" title=\"知乎\"></a>知乎</h3><p><a href=\"https://www.zhihu.com/search?type=content&amp;q=safepoint\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/search?type=content&amp;q=safepoint</a></p>\n<p>怎么看这段日志，结合GC日志和Safepoint就明白了，注意下，最后一条GC是不会显示<code>Total time for which application threads</code>的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Heap after GC invocations=30 (full 0):</span><br><span class=\"line\"> garbage-first heap   total 18374656K, used 1386562K [0x000000035e800000, 0x000000035f004618, 0x00000007c0000000)</span><br><span class=\"line\">  region size 8192K, 14 young (114688K), 14 survivors (114688K)</span><br><span class=\"line\"> Metaspace       used 21800K, capacity 22150K, committed 22400K, reserved 1069056K</span><br><span class=\"line\">  class space    used 2333K, capacity 2416K, committed 2432K, reserved 1048576K</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> [Times: user=0.28 sys=0.02, real=0.08 secs]</span><br><span class=\"line\">2018-12-18T16:10:18.180+0800: 3439.538: Total time for which application threads were stopped: 0.1329005 seconds, Stopping threads took: 0.0095877 seconds</span><br><span class=\"line\">2018-12-18T16:10:19.227+0800: 3440.586: Total time for which application threads were stopped: 0.0472667 seconds, Stopping threads took: 0.0095095 seconds</span><br><span class=\"line\">2018-12-18T16:10:20.273+0800: 3441.632: Total time for which application threads were stopped: 0.0460854 seconds, Stopping threads took: 0.0094629 seconds</span><br><span class=\"line\">2018-12-18T16:11:12.324+0800: 3493.682: Total time for which application threads were stopped: 0.0464605 seconds, Stopping threads took: 0.0094669 seconds</span><br><span class=\"line\">2018-12-18T16:11:18.371+0800: 3499.729: Total time for which application threads were stopped: 0.0466823 seconds, Stopping threads took: 0.0094960 seconds</span><br><span class=\"line\">2018-12-18T16:11:21.417+0800: 3502.775: Total time for which application threads were stopped: 0.0456646 seconds, Stopping threads took: 0.0093249 seconds</span><br><span class=\"line\">2018-12-18T16:11:26.463+0800: 3507.822: Total time for which application threads were stopped: 0.0463651 seconds, Stopping threads took: 0.0094908 seconds</span><br><span class=\"line\">2018-12-18T16:11:44.512+0800: 3525.870: Total time for which application threads were stopped: 0.0467351 seconds, Stopping threads took: 0.0094312 seconds</span><br><span class=\"line\">2018-12-18T19:09:18.204+0800: 14179.563: [GC pause (G1 Evacuation Pause) (young) 14179.572: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 26650, predicted base time: 63.14 ms, remaining time: 0.00 ms, target pause time: 50.00 ms]</span><br><span class=\"line\"> 14179.572: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 100 regions, survivors: 12 regions, predicted young region time: 8.18 ms]</span><br><span class=\"line\"> 14179.572: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 100 regions, survivors: 12 regions, old: 0 regions, predicted pause time: 71.32 ms, target pause time: 50.00 ms]</span><br><span class=\"line\">, 0.0791549 secs]</span><br><span class=\"line\">   [Parallel Time: 39.9 ms, GC Workers: 8]</span><br><span class=\"line\">      [GC Worker Start (ms): Min: 14179586.9, Avg: 14179587.0, Max: 14179587.2, Diff: 0.2]</span><br><span class=\"line\">      [Ext Root Scanning (ms): Min: 18.2, Avg: 18.5, Max: 19.5, Diff: 1.2, Sum: 148.3]</span><br><span class=\"line\">      [Update RS (ms): Min: 12.6, Avg: 13.5, Max: 13.6, Diff: 1.0, Sum: 107.6]</span><br><span class=\"line\">         [Processed Buffers: Min: 2394, Avg: 2568.1, Max: 2899, Diff: 505, Sum: 20545]</span><br><span class=\"line\">      [Scan RS (ms): Min: 1.1, Avg: 1.1, Max: 1.2, Diff: 0.1, Sum: 9.0]</span><br><span class=\"line\">      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class=\"line\">      [Object Copy (ms): Min: 6.2, Avg: 6.3, Max: 6.4, Diff: 0.2, Sum: 50.4]</span><br><span class=\"line\">      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class=\"line\">         [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 8]</span><br><span class=\"line\">      [GC Worker Other (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.1, Sum: 0.8]</span><br><span class=\"line\">      [GC Worker Total (ms): Min: 39.4, Avg: 39.5, Max: 39.7, Diff: 0.3, Sum: 316.3]</span><br><span class=\"line\">      [GC Worker End (ms): Min: 14179626.5, Avg: 14179626.6, Max: 14179626.6, Diff: 0.1]</span><br><span class=\"line\">   [Code Root Fixup: 0.1 ms]</span><br><span class=\"line\">   [Code Root Purge: 0.0 ms]</span><br><span class=\"line\">   [Clear CT: 0.4 ms]</span><br><span class=\"line\">   [Other: 38.8 ms]</span><br><span class=\"line\">      [Choose CSet: 0.0 ms]</span><br><span class=\"line\">      [Ref Proc: 3.6 ms]</span><br><span class=\"line\">      [Ref Enq: 0.2 ms]</span><br><span class=\"line\">      [Redirty Cards: 0.2 ms]</span><br><span class=\"line\">      [Humongous Register: 0.1 ms]</span><br><span class=\"line\">      [Humongous Reclaim: 0.0 ms]</span><br><span class=\"line\">      [Free CSet: 0.2 ms]</span><br><span class=\"line\">   [Eden: 800.0M(800.0M)-&gt;0.0B(784.0M) Survivors: 96.0M-&gt;112.0M Heap: 4178.0M(17.5G)-&gt;3408.0M(17.5G)]</span><br><span class=\"line\">Heap after GC invocations=137 (full 0):</span><br><span class=\"line\"> garbage-first heap   total 18374656K, used 3489792K [0x000000035e800000, 0x000000035f004618, 0x00000007c0000000)</span><br><span class=\"line\">  region size 8192K, 14 young (114688K), 14 survivors (114688K)</span><br><span class=\"line\"> Metaspace       used 21988K, capacity 22278K, committed 22400K, reserved 1069056K</span><br><span class=\"line\">  class space    used 2342K, capacity 2416K, committed 2432K, reserved 1048576K</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> [Times: user=0.29 sys=0.00, real=0.09 secs]</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3439.405: G1IncCollectionPause             [   24775          0              1    ]      [     0     0     9    33    83    ]  0</span><br><span class=\"line\">3440.538: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">3441.586: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">3493.636: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">3499.683: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">3502.729: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">3507.776: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">3525.823: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">14179.520: G1IncCollectionPause             [   24775          0              0    ]      [     0     0     6    33    85    ]  0</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"奇怪日志-Stopping-threads-took-1-7947183-seconds\"><a href=\"#奇怪日志-Stopping-threads-took-1-7947183-seconds\" class=\"headerlink\" title=\"奇怪日志 Stopping threads took: 1.7947183 seconds\"></a>奇怪日志 Stopping threads took: 1.7947183 seconds</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;Heap before GC invocations=64561 (full 0):</span><br><span class=\"line\"> garbage-first heap   total 8388608K, used 5195988K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)</span><br><span class=\"line\">  region size 16384K, 256 young (4194304K), 1 survivors (16384K)</span><br><span class=\"line\"> Metaspace       used 24248K, capacity 25174K, committed 25472K, reserved 1073152K</span><br><span class=\"line\">  class space    used 2341K, capacity 2570K, committed 2688K, reserved 1048576K</span><br><span class=\"line\">2018-12-21T00:43:08.483+0800: 3836207.662: [GC pause (G1 Evacuation Pause) (young)</span><br><span class=\"line\">Desired survivor size 268435456 bytes, new threshold 15 (max 15)</span><br><span class=\"line\">- age   1:    1204016 bytes,    1204016 total</span><br><span class=\"line\">- age   2:     116808 bytes,    1320824 total</span><br><span class=\"line\">- age   3:      22992 bytes,    1343816 total</span><br><span class=\"line\">- age   4:      31216 bytes,    1375032 total</span><br><span class=\"line\">- age   5:      18072 bytes,    1393104 total</span><br><span class=\"line\">- age   6:      21472 bytes,    1414576 total</span><br><span class=\"line\">- age   7:      14512 bytes,    1429088 total</span><br><span class=\"line\">- age   8:      16472 bytes,    1445560 total</span><br><span class=\"line\">- age   9:      13664 bytes,    1459224 total</span><br><span class=\"line\">- age  10:      12784 bytes,    1472008 total</span><br><span class=\"line\">- age  11:      12888 bytes,    1484896 total</span><br><span class=\"line\">- age  12:      11040 bytes,    1495936 total</span><br><span class=\"line\">- age  13:      35480 bytes,    1531416 total</span><br><span class=\"line\">- age  14:      11008 bytes,    1542424 total</span><br><span class=\"line\">- age  15:      11360 bytes,    1553784 total</span><br><span class=\"line\"> 3836207.662: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 3421, predicted base time: 6.10 ms, remaining time: 193</span><br><span class=\"line\">.90 ms, target pause time: 200.00 ms]</span><br><span class=\"line\"> 3836207.662: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 255 regions, survivors: 1 regions, predicted young region t</span><br><span class=\"line\">ime: 0.99 ms]</span><br><span class=\"line\"> 3836207.662: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 255 regions, survivors: 1 regions, old: 0 regions, predicted pau</span><br><span class=\"line\">se time: 7.09 ms, target pause time: 200.00 ms]</span><br><span class=\"line\">2018-12-21T00:43:08.487+0800: 3836207.666: [SoftReference, 0 refs, 0.0008333 secs]2018-12-21T00:43:08.487+0800: 3836207.666: [WeakReference, 0 refs, 0.0004842 secs]2018-12-21T00:43:08.488+0800: 3836207.667: [FinalReference, 36 refs, 0.0003903 secs]2018-12-21T00:43:08.488+0800: 3836207.667: [PhantomReference, 0 refs, 1 refs, 0.0011838 secs]2018-12-21T00:43:08.490+0800: 3836207.669: [JNI Weak Reference, 0.0000125 secs], 0.0076618 secs]</span><br><span class=\"line\">   [Parallel Time: 2.9 ms, GC Workers: 8]</span><br><span class=\"line\">      [GC Worker Start (ms): Min: 3836207662.5, Avg: 3836207662.6, Max: 3836207662.7, Diff: 0.2]</span><br><span class=\"line\">      [Ext Root Scanning (ms): Min: 0.5, Avg: 0.6, Max: 0.7, Diff: 0.2, Sum: 5.1]</span><br><span class=\"line\">      [Update RS (ms): Min: 0.7, Avg: 0.8, Max: 0.9, Diff: 0.2, Sum: 6.5]</span><br><span class=\"line\">         [Processed Buffers: Min: 3, Avg: 14.1, Max: 28, Diff: 25, Sum: 113]</span><br><span class=\"line\">      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.4]</span><br><span class=\"line\">      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class=\"line\">      [Object Copy (ms): Min: 0.9, Avg: 1.0, Max: 1.1, Diff: 0.1, Sum: 8.0]</span><br><span class=\"line\">      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class=\"line\">         [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 8]</span><br><span class=\"line\">      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.3]</span><br><span class=\"line\">      [GC Worker Total (ms): Min: 2.4, Avg: 2.6, Max: 2.6, Diff: 0.2, Sum: 20.4]</span><br><span class=\"line\">      [GC Worker End (ms): Min: 3836207665.1, Avg: 3836207665.2, Max: 3836207665.2, Diff: 0.1]</span><br><span class=\"line\">   [Code Root Fixup: 0.0 ms]</span><br><span class=\"line\">   [Code Root Purge: 0.0 ms]</span><br><span class=\"line\">   [Clear CT: 0.4 ms]</span><br><span class=\"line\">   [Other: 4.3 ms]</span><br><span class=\"line\">      [Choose CSet: 0.0 ms]</span><br><span class=\"line\">      [Ref Proc: 3.2 ms]</span><br><span class=\"line\">      [Ref Enq: 0.2 ms]</span><br><span class=\"line\">      [Redirty Cards: 0.2 ms]</span><br><span class=\"line\">      [Humongous Register: 0.0 ms]</span><br><span class=\"line\">      [Humongous Reclaim: 0.0 ms]</span><br><span class=\"line\">      [Free CSet: 0.3 ms]</span><br><span class=\"line\">   [Eden: 4080.0M(4080.0M)-&gt;0.0B(4080.0M) Survivors: 16.0M-&gt;16.0M Heap: 5074.2M(8192.0M)-&gt;994.1M(8192.0M)]</span><br><span class=\"line\">Heap after GC invocations=64562 (full 0):</span><br><span class=\"line\"> garbage-first heap   total 8388608K, used 1017975K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)</span><br><span class=\"line\">  region size 16384K, 1 young (16384K), 1 survivors (16384K)</span><br><span class=\"line\"> Metaspace       used 24248K, capacity 25174K, committed 25472K, reserved 1073152K</span><br><span class=\"line\">  class space    used 2341K, capacity 2570K, committed 2688K, reserved 1048576K</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> [Times: user=0.00 sys=0.00, real=0.01 secs]</span><br><span class=\"line\">2018-12-21T00:43:08.491+0800: 3836207.670: Total time for which application threads were stopped: 1.8036386 seconds, Stopping threads took: 1.7947183 seconds</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"疑问-page-trap-count-1-代表什么，系统有STW\"><a href=\"#疑问-page-trap-count-1-代表什么，系统有STW\" class=\"headerlink\" title=\"疑问 page_trap_count=1 代表什么，系统有STW\"></a>疑问 page_trap_count=1 代表什么，系统有STW</h3><pre><code>vmop                    [threads: total initially_running wait_to_block]    [time: spin block sync cleanup vmop] page_trap_count</code></pre><p>380.671: G1IncCollectionPause             [     167          1              2    ]      [     0     0     0     0    14    ]  1</p>\n<h3 id=\"日志\"><a href=\"#日志\" class=\"headerlink\" title=\"日志\"></a>日志</h3><p>-XX:+PrintSafepointStatistics</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">         vmop                    [threads: total initially_running wait_to_block]    [time: spin block sync cleanup vmop] page_trap_count</span><br><span class=\"line\">0.265: Deoptimize                       [       9          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">0.312: G1IncCollectionPause             [       9          0              0    ]      [     0     0     0     0    11    ]  0</span><br><span class=\"line\">0.366: Deoptimize                       [      10          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">0.369: Deoptimize                       [      10          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">0.376: G1IncCollectionPause             [      10          0              0    ]      [     0     0     0     0     6    ]  0</span><br><span class=\"line\">0.432: Deoptimize                       [      12          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">0.532: G1IncCollectionPause             [      12          0              0    ]      [     0     0     0     0     4    ]  0</span><br><span class=\"line\">0.644: G1IncCollectionPause             [      12          1              0    ]      [     0     0     0     0     8    ]  0</span><br><span class=\"line\">0.678: G1IncCollectionPause             [      12          0              0    ]      [     0     0     0     0     9    ]  0</span><br><span class=\"line\">0.715: G1IncCollectionPause             [      12          1              0    ]      [     0     0     0     0     8    ]  0</span><br><span class=\"line\">0.917: EnableBiasedLocking              [      12          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">0.961: G1IncCollectionPause             [      13          0              0    ]      [     0     0     0     0     4    ]  0</span><br><span class=\"line\">0.967: RevokeBias                       [      14          1              1    ]      [     2     0     2     0     0    ]  0</span><br><span class=\"line\">0.974: RevokeBias                       [      14          0              2    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">0.982: G1IncCollectionPause             [      14          1              2    ]      [     3     0     4     0     7    ]  0</span><br><span class=\"line\">1.003: G1IncCollectionPause             [      14          0              0    ]      [     0     0     0     0     3    ]  0</span><br><span class=\"line\">1.007: G1IncCollectionPause             [      14          0              0    ]      [     0     0     0     0     2    ]  0</span><br><span class=\"line\">1.010: G1IncCollectionPause             [      14          0              0    ]      [     0     0     0     0     5    ]  0</span><br><span class=\"line\">1.016: G1IncCollectionPause             [      14          0              1    ]      [     0     0     0     0     5    ]  0</span><br><span class=\"line\">1.028: G1IncCollectionPause             [      16          0              1    ]      [     0     0     0     0     8    ]  0</span><br><span class=\"line\">1.040: G1IncCollectionPause             [      16          0              2    ]      [     0     0     0     0    44    ]  0</span><br><span class=\"line\">1.086: CGC_Operation                    [      16          0              0    ]      [     0     0     0     0    13    ]  0</span><br><span class=\"line\">1.100: CGC_Operation                    [      16          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">1.110: G1IncCollectionPause             [      18          1              1    ]      [     0     0     0     0    67    ]  0</span><br><span class=\"line\">1.179: G1IncCollectionPause             [      20          0              0    ]      [     0     0     0     0    47    ]  0</span><br><span class=\"line\">1.228: G1IncCollectionPause             [      20          0              0    ]      [     0     0     0     0    39    ]  0</span><br><span class=\"line\">1.268: RevokeBias                       [      22          0              1    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">1.269: RevokeBias                       [      23          0              1    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">2.269: no vm operation                  [      25          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">6.665: RevokeBias                       [      28          0              0    ]      [     0     0     0     0     0    ]  0</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"源码\"><a href=\"#源码\" class=\"headerlink\" title=\"源码\"></a>源码</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void VMThread::execute(VM_Operation* op) &#123;</span><br><span class=\"line\">  Thread* t = Thread::current();</span><br><span class=\"line\"></span><br><span class=\"line\">  if (!t-&gt;is_VM_thread()) &#123;</span><br><span class=\"line\">    SkipGCALot sgcalot(t);    // avoid re-entrant attempts to gc-a-lot</span><br><span class=\"line\">    // JavaThread or WatcherThread</span><br><span class=\"line\">    bool concurrent = op-&gt;evaluate_concurrently();</span><br><span class=\"line\">    // only blocking VM operations need to verify the caller&apos;s safepoint state:</span><br><span class=\"line\">    if (!concurrent) &#123;</span><br><span class=\"line\">      t-&gt;check_for_valid_safepoint_state(true);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // New request from Java thread, evaluate prologue</span><br><span class=\"line\">    if (!op-&gt;doit_prologue()) &#123;</span><br><span class=\"line\">      return;   // op was cancelled</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Setup VM_operations for execution</span><br><span class=\"line\">    op-&gt;set_calling_thread(t, Thread::get_priority(t));</span><br><span class=\"line\"></span><br><span class=\"line\">    // It does not make sense to execute the epilogue, if the VM operation object is getting</span><br><span class=\"line\">    // deallocated by the VM thread.</span><br><span class=\"line\">    bool execute_epilog = !op-&gt;is_cheap_allocated();</span><br><span class=\"line\">    assert(!concurrent || op-&gt;is_cheap_allocated(), &quot;concurrent =&gt; cheap_allocated&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    // Get ticket number for non-concurrent VM operations</span><br><span class=\"line\">    int ticket = 0;</span><br><span class=\"line\">    if (!concurrent) &#123;</span><br><span class=\"line\">      ticket = t-&gt;vm_operation_ticket();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Add VM operation to list of waiting threads. We are guaranteed not to block while holding the</span><br><span class=\"line\">    // VMOperationQueue_lock, so we can block without a safepoint check. This allows vm operation requests</span><br><span class=\"line\">    // to be queued up during a safepoint synchronization.</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      VMOperationQueue_lock-&gt;lock_without_safepoint_check();</span><br><span class=\"line\">      bool ok = _vm_queue-&gt;add(op);</span><br><span class=\"line\">    op-&gt;set_timestamp(os::javaTimeMillis());</span><br><span class=\"line\">      VMOperationQueue_lock-&gt;notify();</span><br><span class=\"line\">      VMOperationQueue_lock-&gt;unlock();</span><br><span class=\"line\">      // VM_Operation got skipped</span><br><span class=\"line\">      if (!ok) &#123;</span><br><span class=\"line\">        assert(concurrent, &quot;can only skip concurrent tasks&quot;);</span><br><span class=\"line\">        if (op-&gt;is_cheap_allocated()) delete op;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (!concurrent) &#123;</span><br><span class=\"line\">      // Wait for completion of request (non-concurrent)</span><br><span class=\"line\">      // Note: only a JavaThread triggers the safepoint check when locking</span><br><span class=\"line\">      MutexLocker mu(VMOperationRequest_lock);</span><br><span class=\"line\">      while(t-&gt;vm_operation_completed_count() &lt; ticket) &#123;</span><br><span class=\"line\">        VMOperationRequest_lock-&gt;wait(!t-&gt;is_Java_thread());</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (execute_epilog) &#123;</span><br><span class=\"line\">      op-&gt;doit_epilogue();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125; else &#123;</span><br><span class=\"line\">    // invoked by VM thread; usually nested VM operation</span><br><span class=\"line\">    assert(t-&gt;is_VM_thread(), &quot;must be a VM thread&quot;);</span><br><span class=\"line\">    VM_Operation* prev_vm_operation = vm_operation();</span><br><span class=\"line\">    if (prev_vm_operation != NULL) &#123;</span><br><span class=\"line\">      // Check the VM operation allows nested VM operation. This normally not the case, e.g., the compiler</span><br><span class=\"line\">      // does not allow nested scavenges or compiles.</span><br><span class=\"line\">      if (!prev_vm_operation-&gt;allow_nested_vm_operations()) &#123;</span><br><span class=\"line\">        fatal(&quot;Nested VM operation %s requested by operation %s&quot;,</span><br><span class=\"line\">              op-&gt;name(), vm_operation()-&gt;name());</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      op-&gt;set_calling_thread(prev_vm_operation-&gt;calling_thread(), prev_vm_operation-&gt;priority());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    EventMark em(&quot;Executing %s VM operation: %s&quot;, prev_vm_operation ? &quot;nested&quot; : &quot;&quot;, op-&gt;name());</span><br><span class=\"line\"></span><br><span class=\"line\">    // Release all internal handles after operation is evaluated</span><br><span class=\"line\">    HandleMark hm(t);</span><br><span class=\"line\">    _cur_vm_operation = op;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (op-&gt;evaluate_at_safepoint() &amp;&amp; !SafepointSynchronize::is_at_safepoint()) &#123;</span><br><span class=\"line\">      SafepointSynchronize::begin();</span><br><span class=\"line\">      op-&gt;evaluate();</span><br><span class=\"line\">      SafepointSynchronize::end();</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      op-&gt;evaluate();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Free memory if needed</span><br><span class=\"line\">    if (op-&gt;is_cheap_allocated()) delete op;</span><br><span class=\"line\"></span><br><span class=\"line\">    _cur_vm_operation = prev_vm_operation;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/column/details/talk-about-jvm.html\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/column/details/talk-about-jvm.html</a></p>\n<h3 id=\"言简意赅\"><a href=\"#言简意赅\" class=\"headerlink\" title=\"言简意赅\"></a>言简意赅</h3><p><a href=\"https://juejin.im/post/5c0cd964f265da616e4c4340\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5c0cd964f265da616e4c4340</a></p>\n<h3 id=\"这篇写得很好\"><a href=\"#这篇写得很好\" class=\"headerlink\" title=\"这篇写得很好\"></a>这篇写得很好</h3><p><a href=\"https://blog.csdn.net/iter_zc/article/details/41847887\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/iter_zc/article/details/41847887</a></p>\n<h3 id=\"这个要掌握\"><a href=\"#这个要掌握\" class=\"headerlink\" title=\"这个要掌握\"></a>这个要掌握</h3><p><a href=\"https://www.lmax.com/blog/staff-blogs/2015/08/05/jvm-guaranteed-safepoints/\" target=\"_blank\" rel=\"noopener\">https://www.lmax.com/blog/staff-blogs/2015/08/05/jvm-guaranteed-safepoints/</a><br><a href=\"http://www.importnew.com/16068.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/16068.html</a><br>如果线程非常多，可以用<code>GuaranteedSafepointInterval</code>提高”保证安全点”的执行频率，这样会有效减少暂停。</p>\n<h3 id=\"江南白衣本衣\"><a href=\"#江南白衣本衣\" class=\"headerlink\" title=\"江南白衣本衣\"></a>江南白衣本衣</h3><p><a href=\"http://www.10tiao.com/html/698/201808/2247483961/1.html\" target=\"_blank\" rel=\"noopener\">http://www.10tiao.com/html/698/201808/2247483961/1.html</a><br><a href=\"http://calvin1978.blogcn.com/articles/safepoint.html\" target=\"_blank\" rel=\"noopener\">http://calvin1978.blogcn.com/articles/safepoint.html</a></p>\n<h3 id=\"stackoverflow上的safepoint问题\"><a href=\"#stackoverflow上的safepoint问题\" class=\"headerlink\" title=\"stackoverflow上的safepoint问题\"></a>stackoverflow上的safepoint问题</h3><p><a href=\"https://stackoverflow.com/questions/20134769/how-to-get-java-stacks-when-jvm-cant-reach-a-safepoint\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/20134769/how-to-get-java-stacks-when-jvm-cant-reach-a-safepoint</a></p>\n<h3 id=\"知乎\"><a href=\"#知乎\" class=\"headerlink\" title=\"知乎\"></a>知乎</h3><p><a href=\"https://www.zhihu.com/search?type=content&amp;q=safepoint\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/search?type=content&amp;q=safepoint</a></p>\n<p>怎么看这段日志，结合GC日志和Safepoint就明白了，注意下，最后一条GC是不会显示<code>Total time for which application threads</code>的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Heap after GC invocations=30 (full 0):</span><br><span class=\"line\"> garbage-first heap   total 18374656K, used 1386562K [0x000000035e800000, 0x000000035f004618, 0x00000007c0000000)</span><br><span class=\"line\">  region size 8192K, 14 young (114688K), 14 survivors (114688K)</span><br><span class=\"line\"> Metaspace       used 21800K, capacity 22150K, committed 22400K, reserved 1069056K</span><br><span class=\"line\">  class space    used 2333K, capacity 2416K, committed 2432K, reserved 1048576K</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> [Times: user=0.28 sys=0.02, real=0.08 secs]</span><br><span class=\"line\">2018-12-18T16:10:18.180+0800: 3439.538: Total time for which application threads were stopped: 0.1329005 seconds, Stopping threads took: 0.0095877 seconds</span><br><span class=\"line\">2018-12-18T16:10:19.227+0800: 3440.586: Total time for which application threads were stopped: 0.0472667 seconds, Stopping threads took: 0.0095095 seconds</span><br><span class=\"line\">2018-12-18T16:10:20.273+0800: 3441.632: Total time for which application threads were stopped: 0.0460854 seconds, Stopping threads took: 0.0094629 seconds</span><br><span class=\"line\">2018-12-18T16:11:12.324+0800: 3493.682: Total time for which application threads were stopped: 0.0464605 seconds, Stopping threads took: 0.0094669 seconds</span><br><span class=\"line\">2018-12-18T16:11:18.371+0800: 3499.729: Total time for which application threads were stopped: 0.0466823 seconds, Stopping threads took: 0.0094960 seconds</span><br><span class=\"line\">2018-12-18T16:11:21.417+0800: 3502.775: Total time for which application threads were stopped: 0.0456646 seconds, Stopping threads took: 0.0093249 seconds</span><br><span class=\"line\">2018-12-18T16:11:26.463+0800: 3507.822: Total time for which application threads were stopped: 0.0463651 seconds, Stopping threads took: 0.0094908 seconds</span><br><span class=\"line\">2018-12-18T16:11:44.512+0800: 3525.870: Total time for which application threads were stopped: 0.0467351 seconds, Stopping threads took: 0.0094312 seconds</span><br><span class=\"line\">2018-12-18T19:09:18.204+0800: 14179.563: [GC pause (G1 Evacuation Pause) (young) 14179.572: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 26650, predicted base time: 63.14 ms, remaining time: 0.00 ms, target pause time: 50.00 ms]</span><br><span class=\"line\"> 14179.572: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 100 regions, survivors: 12 regions, predicted young region time: 8.18 ms]</span><br><span class=\"line\"> 14179.572: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 100 regions, survivors: 12 regions, old: 0 regions, predicted pause time: 71.32 ms, target pause time: 50.00 ms]</span><br><span class=\"line\">, 0.0791549 secs]</span><br><span class=\"line\">   [Parallel Time: 39.9 ms, GC Workers: 8]</span><br><span class=\"line\">      [GC Worker Start (ms): Min: 14179586.9, Avg: 14179587.0, Max: 14179587.2, Diff: 0.2]</span><br><span class=\"line\">      [Ext Root Scanning (ms): Min: 18.2, Avg: 18.5, Max: 19.5, Diff: 1.2, Sum: 148.3]</span><br><span class=\"line\">      [Update RS (ms): Min: 12.6, Avg: 13.5, Max: 13.6, Diff: 1.0, Sum: 107.6]</span><br><span class=\"line\">         [Processed Buffers: Min: 2394, Avg: 2568.1, Max: 2899, Diff: 505, Sum: 20545]</span><br><span class=\"line\">      [Scan RS (ms): Min: 1.1, Avg: 1.1, Max: 1.2, Diff: 0.1, Sum: 9.0]</span><br><span class=\"line\">      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class=\"line\">      [Object Copy (ms): Min: 6.2, Avg: 6.3, Max: 6.4, Diff: 0.2, Sum: 50.4]</span><br><span class=\"line\">      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class=\"line\">         [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 8]</span><br><span class=\"line\">      [GC Worker Other (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.1, Sum: 0.8]</span><br><span class=\"line\">      [GC Worker Total (ms): Min: 39.4, Avg: 39.5, Max: 39.7, Diff: 0.3, Sum: 316.3]</span><br><span class=\"line\">      [GC Worker End (ms): Min: 14179626.5, Avg: 14179626.6, Max: 14179626.6, Diff: 0.1]</span><br><span class=\"line\">   [Code Root Fixup: 0.1 ms]</span><br><span class=\"line\">   [Code Root Purge: 0.0 ms]</span><br><span class=\"line\">   [Clear CT: 0.4 ms]</span><br><span class=\"line\">   [Other: 38.8 ms]</span><br><span class=\"line\">      [Choose CSet: 0.0 ms]</span><br><span class=\"line\">      [Ref Proc: 3.6 ms]</span><br><span class=\"line\">      [Ref Enq: 0.2 ms]</span><br><span class=\"line\">      [Redirty Cards: 0.2 ms]</span><br><span class=\"line\">      [Humongous Register: 0.1 ms]</span><br><span class=\"line\">      [Humongous Reclaim: 0.0 ms]</span><br><span class=\"line\">      [Free CSet: 0.2 ms]</span><br><span class=\"line\">   [Eden: 800.0M(800.0M)-&gt;0.0B(784.0M) Survivors: 96.0M-&gt;112.0M Heap: 4178.0M(17.5G)-&gt;3408.0M(17.5G)]</span><br><span class=\"line\">Heap after GC invocations=137 (full 0):</span><br><span class=\"line\"> garbage-first heap   total 18374656K, used 3489792K [0x000000035e800000, 0x000000035f004618, 0x00000007c0000000)</span><br><span class=\"line\">  region size 8192K, 14 young (114688K), 14 survivors (114688K)</span><br><span class=\"line\"> Metaspace       used 21988K, capacity 22278K, committed 22400K, reserved 1069056K</span><br><span class=\"line\">  class space    used 2342K, capacity 2416K, committed 2432K, reserved 1048576K</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> [Times: user=0.29 sys=0.00, real=0.09 secs]</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3439.405: G1IncCollectionPause             [   24775          0              1    ]      [     0     0     9    33    83    ]  0</span><br><span class=\"line\">3440.538: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">3441.586: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">3493.636: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">3499.683: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">3502.729: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">3507.776: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">3525.823: no vm operation                  [   24775          0              0    ]      [     0     0     9    33     0    ]  0</span><br><span class=\"line\">14179.520: G1IncCollectionPause             [   24775          0              0    ]      [     0     0     6    33    85    ]  0</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"奇怪日志-Stopping-threads-took-1-7947183-seconds\"><a href=\"#奇怪日志-Stopping-threads-took-1-7947183-seconds\" class=\"headerlink\" title=\"奇怪日志 Stopping threads took: 1.7947183 seconds\"></a>奇怪日志 Stopping threads took: 1.7947183 seconds</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;Heap before GC invocations=64561 (full 0):</span><br><span class=\"line\"> garbage-first heap   total 8388608K, used 5195988K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)</span><br><span class=\"line\">  region size 16384K, 256 young (4194304K), 1 survivors (16384K)</span><br><span class=\"line\"> Metaspace       used 24248K, capacity 25174K, committed 25472K, reserved 1073152K</span><br><span class=\"line\">  class space    used 2341K, capacity 2570K, committed 2688K, reserved 1048576K</span><br><span class=\"line\">2018-12-21T00:43:08.483+0800: 3836207.662: [GC pause (G1 Evacuation Pause) (young)</span><br><span class=\"line\">Desired survivor size 268435456 bytes, new threshold 15 (max 15)</span><br><span class=\"line\">- age   1:    1204016 bytes,    1204016 total</span><br><span class=\"line\">- age   2:     116808 bytes,    1320824 total</span><br><span class=\"line\">- age   3:      22992 bytes,    1343816 total</span><br><span class=\"line\">- age   4:      31216 bytes,    1375032 total</span><br><span class=\"line\">- age   5:      18072 bytes,    1393104 total</span><br><span class=\"line\">- age   6:      21472 bytes,    1414576 total</span><br><span class=\"line\">- age   7:      14512 bytes,    1429088 total</span><br><span class=\"line\">- age   8:      16472 bytes,    1445560 total</span><br><span class=\"line\">- age   9:      13664 bytes,    1459224 total</span><br><span class=\"line\">- age  10:      12784 bytes,    1472008 total</span><br><span class=\"line\">- age  11:      12888 bytes,    1484896 total</span><br><span class=\"line\">- age  12:      11040 bytes,    1495936 total</span><br><span class=\"line\">- age  13:      35480 bytes,    1531416 total</span><br><span class=\"line\">- age  14:      11008 bytes,    1542424 total</span><br><span class=\"line\">- age  15:      11360 bytes,    1553784 total</span><br><span class=\"line\"> 3836207.662: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 3421, predicted base time: 6.10 ms, remaining time: 193</span><br><span class=\"line\">.90 ms, target pause time: 200.00 ms]</span><br><span class=\"line\"> 3836207.662: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 255 regions, survivors: 1 regions, predicted young region t</span><br><span class=\"line\">ime: 0.99 ms]</span><br><span class=\"line\"> 3836207.662: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 255 regions, survivors: 1 regions, old: 0 regions, predicted pau</span><br><span class=\"line\">se time: 7.09 ms, target pause time: 200.00 ms]</span><br><span class=\"line\">2018-12-21T00:43:08.487+0800: 3836207.666: [SoftReference, 0 refs, 0.0008333 secs]2018-12-21T00:43:08.487+0800: 3836207.666: [WeakReference, 0 refs, 0.0004842 secs]2018-12-21T00:43:08.488+0800: 3836207.667: [FinalReference, 36 refs, 0.0003903 secs]2018-12-21T00:43:08.488+0800: 3836207.667: [PhantomReference, 0 refs, 1 refs, 0.0011838 secs]2018-12-21T00:43:08.490+0800: 3836207.669: [JNI Weak Reference, 0.0000125 secs], 0.0076618 secs]</span><br><span class=\"line\">   [Parallel Time: 2.9 ms, GC Workers: 8]</span><br><span class=\"line\">      [GC Worker Start (ms): Min: 3836207662.5, Avg: 3836207662.6, Max: 3836207662.7, Diff: 0.2]</span><br><span class=\"line\">      [Ext Root Scanning (ms): Min: 0.5, Avg: 0.6, Max: 0.7, Diff: 0.2, Sum: 5.1]</span><br><span class=\"line\">      [Update RS (ms): Min: 0.7, Avg: 0.8, Max: 0.9, Diff: 0.2, Sum: 6.5]</span><br><span class=\"line\">         [Processed Buffers: Min: 3, Avg: 14.1, Max: 28, Diff: 25, Sum: 113]</span><br><span class=\"line\">      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.4]</span><br><span class=\"line\">      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class=\"line\">      [Object Copy (ms): Min: 0.9, Avg: 1.0, Max: 1.1, Diff: 0.1, Sum: 8.0]</span><br><span class=\"line\">      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]</span><br><span class=\"line\">         [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 8]</span><br><span class=\"line\">      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.3]</span><br><span class=\"line\">      [GC Worker Total (ms): Min: 2.4, Avg: 2.6, Max: 2.6, Diff: 0.2, Sum: 20.4]</span><br><span class=\"line\">      [GC Worker End (ms): Min: 3836207665.1, Avg: 3836207665.2, Max: 3836207665.2, Diff: 0.1]</span><br><span class=\"line\">   [Code Root Fixup: 0.0 ms]</span><br><span class=\"line\">   [Code Root Purge: 0.0 ms]</span><br><span class=\"line\">   [Clear CT: 0.4 ms]</span><br><span class=\"line\">   [Other: 4.3 ms]</span><br><span class=\"line\">      [Choose CSet: 0.0 ms]</span><br><span class=\"line\">      [Ref Proc: 3.2 ms]</span><br><span class=\"line\">      [Ref Enq: 0.2 ms]</span><br><span class=\"line\">      [Redirty Cards: 0.2 ms]</span><br><span class=\"line\">      [Humongous Register: 0.0 ms]</span><br><span class=\"line\">      [Humongous Reclaim: 0.0 ms]</span><br><span class=\"line\">      [Free CSet: 0.3 ms]</span><br><span class=\"line\">   [Eden: 4080.0M(4080.0M)-&gt;0.0B(4080.0M) Survivors: 16.0M-&gt;16.0M Heap: 5074.2M(8192.0M)-&gt;994.1M(8192.0M)]</span><br><span class=\"line\">Heap after GC invocations=64562 (full 0):</span><br><span class=\"line\"> garbage-first heap   total 8388608K, used 1017975K [0x00000005c0000000, 0x00000005c1001000, 0x00000007c0000000)</span><br><span class=\"line\">  region size 16384K, 1 young (16384K), 1 survivors (16384K)</span><br><span class=\"line\"> Metaspace       used 24248K, capacity 25174K, committed 25472K, reserved 1073152K</span><br><span class=\"line\">  class space    used 2341K, capacity 2570K, committed 2688K, reserved 1048576K</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> [Times: user=0.00 sys=0.00, real=0.01 secs]</span><br><span class=\"line\">2018-12-21T00:43:08.491+0800: 3836207.670: Total time for which application threads were stopped: 1.8036386 seconds, Stopping threads took: 1.7947183 seconds</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"疑问-page-trap-count-1-代表什么，系统有STW\"><a href=\"#疑问-page-trap-count-1-代表什么，系统有STW\" class=\"headerlink\" title=\"疑问 page_trap_count=1 代表什么，系统有STW\"></a>疑问 page_trap_count=1 代表什么，系统有STW</h3><pre><code>vmop                    [threads: total initially_running wait_to_block]    [time: spin block sync cleanup vmop] page_trap_count</code></pre><p>380.671: G1IncCollectionPause             [     167          1              2    ]      [     0     0     0     0    14    ]  1</p>\n<h3 id=\"日志\"><a href=\"#日志\" class=\"headerlink\" title=\"日志\"></a>日志</h3><p>-XX:+PrintSafepointStatistics</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">         vmop                    [threads: total initially_running wait_to_block]    [time: spin block sync cleanup vmop] page_trap_count</span><br><span class=\"line\">0.265: Deoptimize                       [       9          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">0.312: G1IncCollectionPause             [       9          0              0    ]      [     0     0     0     0    11    ]  0</span><br><span class=\"line\">0.366: Deoptimize                       [      10          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">0.369: Deoptimize                       [      10          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">0.376: G1IncCollectionPause             [      10          0              0    ]      [     0     0     0     0     6    ]  0</span><br><span class=\"line\">0.432: Deoptimize                       [      12          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">0.532: G1IncCollectionPause             [      12          0              0    ]      [     0     0     0     0     4    ]  0</span><br><span class=\"line\">0.644: G1IncCollectionPause             [      12          1              0    ]      [     0     0     0     0     8    ]  0</span><br><span class=\"line\">0.678: G1IncCollectionPause             [      12          0              0    ]      [     0     0     0     0     9    ]  0</span><br><span class=\"line\">0.715: G1IncCollectionPause             [      12          1              0    ]      [     0     0     0     0     8    ]  0</span><br><span class=\"line\">0.917: EnableBiasedLocking              [      12          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">0.961: G1IncCollectionPause             [      13          0              0    ]      [     0     0     0     0     4    ]  0</span><br><span class=\"line\">0.967: RevokeBias                       [      14          1              1    ]      [     2     0     2     0     0    ]  0</span><br><span class=\"line\">0.974: RevokeBias                       [      14          0              2    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">0.982: G1IncCollectionPause             [      14          1              2    ]      [     3     0     4     0     7    ]  0</span><br><span class=\"line\">1.003: G1IncCollectionPause             [      14          0              0    ]      [     0     0     0     0     3    ]  0</span><br><span class=\"line\">1.007: G1IncCollectionPause             [      14          0              0    ]      [     0     0     0     0     2    ]  0</span><br><span class=\"line\">1.010: G1IncCollectionPause             [      14          0              0    ]      [     0     0     0     0     5    ]  0</span><br><span class=\"line\">1.016: G1IncCollectionPause             [      14          0              1    ]      [     0     0     0     0     5    ]  0</span><br><span class=\"line\">1.028: G1IncCollectionPause             [      16          0              1    ]      [     0     0     0     0     8    ]  0</span><br><span class=\"line\">1.040: G1IncCollectionPause             [      16          0              2    ]      [     0     0     0     0    44    ]  0</span><br><span class=\"line\">1.086: CGC_Operation                    [      16          0              0    ]      [     0     0     0     0    13    ]  0</span><br><span class=\"line\">1.100: CGC_Operation                    [      16          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">1.110: G1IncCollectionPause             [      18          1              1    ]      [     0     0     0     0    67    ]  0</span><br><span class=\"line\">1.179: G1IncCollectionPause             [      20          0              0    ]      [     0     0     0     0    47    ]  0</span><br><span class=\"line\">1.228: G1IncCollectionPause             [      20          0              0    ]      [     0     0     0     0    39    ]  0</span><br><span class=\"line\">1.268: RevokeBias                       [      22          0              1    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">1.269: RevokeBias                       [      23          0              1    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">2.269: no vm operation                  [      25          0              0    ]      [     0     0     0     0     0    ]  0</span><br><span class=\"line\">6.665: RevokeBias                       [      28          0              0    ]      [     0     0     0     0     0    ]  0</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"源码\"><a href=\"#源码\" class=\"headerlink\" title=\"源码\"></a>源码</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">void VMThread::execute(VM_Operation* op) &#123;</span><br><span class=\"line\">  Thread* t = Thread::current();</span><br><span class=\"line\"></span><br><span class=\"line\">  if (!t-&gt;is_VM_thread()) &#123;</span><br><span class=\"line\">    SkipGCALot sgcalot(t);    // avoid re-entrant attempts to gc-a-lot</span><br><span class=\"line\">    // JavaThread or WatcherThread</span><br><span class=\"line\">    bool concurrent = op-&gt;evaluate_concurrently();</span><br><span class=\"line\">    // only blocking VM operations need to verify the caller&apos;s safepoint state:</span><br><span class=\"line\">    if (!concurrent) &#123;</span><br><span class=\"line\">      t-&gt;check_for_valid_safepoint_state(true);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // New request from Java thread, evaluate prologue</span><br><span class=\"line\">    if (!op-&gt;doit_prologue()) &#123;</span><br><span class=\"line\">      return;   // op was cancelled</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Setup VM_operations for execution</span><br><span class=\"line\">    op-&gt;set_calling_thread(t, Thread::get_priority(t));</span><br><span class=\"line\"></span><br><span class=\"line\">    // It does not make sense to execute the epilogue, if the VM operation object is getting</span><br><span class=\"line\">    // deallocated by the VM thread.</span><br><span class=\"line\">    bool execute_epilog = !op-&gt;is_cheap_allocated();</span><br><span class=\"line\">    assert(!concurrent || op-&gt;is_cheap_allocated(), &quot;concurrent =&gt; cheap_allocated&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    // Get ticket number for non-concurrent VM operations</span><br><span class=\"line\">    int ticket = 0;</span><br><span class=\"line\">    if (!concurrent) &#123;</span><br><span class=\"line\">      ticket = t-&gt;vm_operation_ticket();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Add VM operation to list of waiting threads. We are guaranteed not to block while holding the</span><br><span class=\"line\">    // VMOperationQueue_lock, so we can block without a safepoint check. This allows vm operation requests</span><br><span class=\"line\">    // to be queued up during a safepoint synchronization.</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      VMOperationQueue_lock-&gt;lock_without_safepoint_check();</span><br><span class=\"line\">      bool ok = _vm_queue-&gt;add(op);</span><br><span class=\"line\">    op-&gt;set_timestamp(os::javaTimeMillis());</span><br><span class=\"line\">      VMOperationQueue_lock-&gt;notify();</span><br><span class=\"line\">      VMOperationQueue_lock-&gt;unlock();</span><br><span class=\"line\">      // VM_Operation got skipped</span><br><span class=\"line\">      if (!ok) &#123;</span><br><span class=\"line\">        assert(concurrent, &quot;can only skip concurrent tasks&quot;);</span><br><span class=\"line\">        if (op-&gt;is_cheap_allocated()) delete op;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (!concurrent) &#123;</span><br><span class=\"line\">      // Wait for completion of request (non-concurrent)</span><br><span class=\"line\">      // Note: only a JavaThread triggers the safepoint check when locking</span><br><span class=\"line\">      MutexLocker mu(VMOperationRequest_lock);</span><br><span class=\"line\">      while(t-&gt;vm_operation_completed_count() &lt; ticket) &#123;</span><br><span class=\"line\">        VMOperationRequest_lock-&gt;wait(!t-&gt;is_Java_thread());</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (execute_epilog) &#123;</span><br><span class=\"line\">      op-&gt;doit_epilogue();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125; else &#123;</span><br><span class=\"line\">    // invoked by VM thread; usually nested VM operation</span><br><span class=\"line\">    assert(t-&gt;is_VM_thread(), &quot;must be a VM thread&quot;);</span><br><span class=\"line\">    VM_Operation* prev_vm_operation = vm_operation();</span><br><span class=\"line\">    if (prev_vm_operation != NULL) &#123;</span><br><span class=\"line\">      // Check the VM operation allows nested VM operation. This normally not the case, e.g., the compiler</span><br><span class=\"line\">      // does not allow nested scavenges or compiles.</span><br><span class=\"line\">      if (!prev_vm_operation-&gt;allow_nested_vm_operations()) &#123;</span><br><span class=\"line\">        fatal(&quot;Nested VM operation %s requested by operation %s&quot;,</span><br><span class=\"line\">              op-&gt;name(), vm_operation()-&gt;name());</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      op-&gt;set_calling_thread(prev_vm_operation-&gt;calling_thread(), prev_vm_operation-&gt;priority());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    EventMark em(&quot;Executing %s VM operation: %s&quot;, prev_vm_operation ? &quot;nested&quot; : &quot;&quot;, op-&gt;name());</span><br><span class=\"line\"></span><br><span class=\"line\">    // Release all internal handles after operation is evaluated</span><br><span class=\"line\">    HandleMark hm(t);</span><br><span class=\"line\">    _cur_vm_operation = op;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (op-&gt;evaluate_at_safepoint() &amp;&amp; !SafepointSynchronize::is_at_safepoint()) &#123;</span><br><span class=\"line\">      SafepointSynchronize::begin();</span><br><span class=\"line\">      op-&gt;evaluate();</span><br><span class=\"line\">      SafepointSynchronize::end();</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      op-&gt;evaluate();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Free memory if needed</span><br><span class=\"line\">    if (op-&gt;is_cheap_allocated()) delete op;</span><br><span class=\"line\"></span><br><span class=\"line\">    _cur_vm_operation = prev_vm_operation;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"JVM-SoftReference","date":"2018-11-30T01:54:43.000Z","_content":"\n\n\n\n\n```\n// NOTE: process_phase*() are largely similar, and at a high level\n// merely iterate over the extant list applying a predicate to\n// each of its elements and possibly removing that element from the\n// list and applying some further closures to that element.\n// We should consider the possibility of replacing these\n// process_phase*() methods by abstracting them into\n// a single general iterator invocation that receives appropriate\n// closures that accomplish this work.\n\n// (SoftReferences only) Traverse the list and remove any SoftReferences whose\n// referents are not alive, but that should be kept alive for policy reasons.\n// Keep alive the transitive closure of all such referents.\nvoid\nReferenceProcessor::process_phase1(DiscoveredList&    refs_list,\n                                   ReferencePolicy*   policy,\n                                   BoolObjectClosure* is_alive,\n                                   OopClosure*        keep_alive,\n                                   VoidClosure*       complete_gc) {\n  assert(policy != NULL, \"Must have a non-NULL policy\");\n  DiscoveredListIterator iter(refs_list, keep_alive, is_alive);\n  // Decide which softly reachable refs should be kept alive.\n  while (iter.has_next()) {\n    iter.load_ptrs(DEBUG_ONLY(!discovery_is_atomic() /* allow_null_referent */));\n    bool referent_is_dead = (iter.referent() != NULL) && !iter.is_referent_alive();\n    if (referent_is_dead &&\n        !policy->should_clear_reference(iter.obj(), _soft_ref_timestamp_clock)) {\n      log_develop_trace(gc, ref)(\"Dropping reference (\" INTPTR_FORMAT \": %s\"  \") by policy\",\n                                 p2i(iter.obj()), iter.obj()->klass()->internal_name());\n      // Remove Reference object from list\n      iter.remove();\n      // keep the referent around\n      iter.make_referent_alive();\n      iter.move_to_next();\n    } else {\n      iter.next();\n    }\n  }\n  // Close the reachable set\n  complete_gc->do_void();\n  log_develop_trace(gc, ref)(\" Dropped \" SIZE_FORMAT \" dead Refs out of \" SIZE_FORMAT \" discovered Refs by policy, from list \" INTPTR_FORMAT,\n                             iter.removed(), iter.processed(), p2i(&refs_list));\n}\n```\n\n\n\n相关JVM参数\n-XX:SoftRefLRUPolicyMSPerMB=0\n-XX:+ParallelRefProcEnabled\n-XX:+PrintReferenceGC\n\n-XX:SoftRefLRUPolicyMSPerMB=N 这个参数比较有用的，官方解释是：Soft reference在虚拟机中比在客户集中存活的更长一些。其清除频率可以用命令行参数 -XX:SoftRefLRUPolicyMSPerMB=<N>来控制，这可以指定每兆堆空闲空间的 soft reference 保持存活（一旦它不强可达了）的毫秒数，这意味着每兆堆中的空闲空间中的 soft reference 会（在最后一个强引用被回收之后）存活1秒钟。注意，这是一个近似的值，因为  soft reference 只会在垃圾回收时才会被清除，而垃圾回收并不总在发生。系统默认为一秒，我觉得没必要等1秒，客户集中不用就立刻清除，改为 -XX:SoftRefLRUPolicyMSPerMB=0；\n\n作者：MangoDai\n链接：https://www.jianshu.com/p/3eb976e03457\n来源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n\n### 疑问\nReferenceQueue在哪里，如果有ReferenceQueue，就可以查看到SoftReference的清理情况","source":"_posts/JVM-SoftReference.md","raw":"---\ntitle: JVM-SoftReference\ndate: 2018-11-30 09:54:43\ntags: JVM\n---\n\n\n\n\n\n```\n// NOTE: process_phase*() are largely similar, and at a high level\n// merely iterate over the extant list applying a predicate to\n// each of its elements and possibly removing that element from the\n// list and applying some further closures to that element.\n// We should consider the possibility of replacing these\n// process_phase*() methods by abstracting them into\n// a single general iterator invocation that receives appropriate\n// closures that accomplish this work.\n\n// (SoftReferences only) Traverse the list and remove any SoftReferences whose\n// referents are not alive, but that should be kept alive for policy reasons.\n// Keep alive the transitive closure of all such referents.\nvoid\nReferenceProcessor::process_phase1(DiscoveredList&    refs_list,\n                                   ReferencePolicy*   policy,\n                                   BoolObjectClosure* is_alive,\n                                   OopClosure*        keep_alive,\n                                   VoidClosure*       complete_gc) {\n  assert(policy != NULL, \"Must have a non-NULL policy\");\n  DiscoveredListIterator iter(refs_list, keep_alive, is_alive);\n  // Decide which softly reachable refs should be kept alive.\n  while (iter.has_next()) {\n    iter.load_ptrs(DEBUG_ONLY(!discovery_is_atomic() /* allow_null_referent */));\n    bool referent_is_dead = (iter.referent() != NULL) && !iter.is_referent_alive();\n    if (referent_is_dead &&\n        !policy->should_clear_reference(iter.obj(), _soft_ref_timestamp_clock)) {\n      log_develop_trace(gc, ref)(\"Dropping reference (\" INTPTR_FORMAT \": %s\"  \") by policy\",\n                                 p2i(iter.obj()), iter.obj()->klass()->internal_name());\n      // Remove Reference object from list\n      iter.remove();\n      // keep the referent around\n      iter.make_referent_alive();\n      iter.move_to_next();\n    } else {\n      iter.next();\n    }\n  }\n  // Close the reachable set\n  complete_gc->do_void();\n  log_develop_trace(gc, ref)(\" Dropped \" SIZE_FORMAT \" dead Refs out of \" SIZE_FORMAT \" discovered Refs by policy, from list \" INTPTR_FORMAT,\n                             iter.removed(), iter.processed(), p2i(&refs_list));\n}\n```\n\n\n\n相关JVM参数\n-XX:SoftRefLRUPolicyMSPerMB=0\n-XX:+ParallelRefProcEnabled\n-XX:+PrintReferenceGC\n\n-XX:SoftRefLRUPolicyMSPerMB=N 这个参数比较有用的，官方解释是：Soft reference在虚拟机中比在客户集中存活的更长一些。其清除频率可以用命令行参数 -XX:SoftRefLRUPolicyMSPerMB=<N>来控制，这可以指定每兆堆空闲空间的 soft reference 保持存活（一旦它不强可达了）的毫秒数，这意味着每兆堆中的空闲空间中的 soft reference 会（在最后一个强引用被回收之后）存活1秒钟。注意，这是一个近似的值，因为  soft reference 只会在垃圾回收时才会被清除，而垃圾回收并不总在发生。系统默认为一秒，我觉得没必要等1秒，客户集中不用就立刻清除，改为 -XX:SoftRefLRUPolicyMSPerMB=0；\n\n作者：MangoDai\n链接：https://www.jianshu.com/p/3eb976e03457\n来源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n\n### 疑问\nReferenceQueue在哪里，如果有ReferenceQueue，就可以查看到SoftReference的清理情况","slug":"JVM-SoftReference","published":1,"updated":"2019-09-28T08:51:00.871Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83f002fv1np0eta9y8m","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// NOTE: process_phase*() are largely similar, and at a high level</span><br><span class=\"line\">// merely iterate over the extant list applying a predicate to</span><br><span class=\"line\">// each of its elements and possibly removing that element from the</span><br><span class=\"line\">// list and applying some further closures to that element.</span><br><span class=\"line\">// We should consider the possibility of replacing these</span><br><span class=\"line\">// process_phase*() methods by abstracting them into</span><br><span class=\"line\">// a single general iterator invocation that receives appropriate</span><br><span class=\"line\">// closures that accomplish this work.</span><br><span class=\"line\"></span><br><span class=\"line\">// (SoftReferences only) Traverse the list and remove any SoftReferences whose</span><br><span class=\"line\">// referents are not alive, but that should be kept alive for policy reasons.</span><br><span class=\"line\">// Keep alive the transitive closure of all such referents.</span><br><span class=\"line\">void</span><br><span class=\"line\">ReferenceProcessor::process_phase1(DiscoveredList&amp;    refs_list,</span><br><span class=\"line\">                                   ReferencePolicy*   policy,</span><br><span class=\"line\">                                   BoolObjectClosure* is_alive,</span><br><span class=\"line\">                                   OopClosure*        keep_alive,</span><br><span class=\"line\">                                   VoidClosure*       complete_gc) &#123;</span><br><span class=\"line\">  assert(policy != NULL, &quot;Must have a non-NULL policy&quot;);</span><br><span class=\"line\">  DiscoveredListIterator iter(refs_list, keep_alive, is_alive);</span><br><span class=\"line\">  // Decide which softly reachable refs should be kept alive.</span><br><span class=\"line\">  while (iter.has_next()) &#123;</span><br><span class=\"line\">    iter.load_ptrs(DEBUG_ONLY(!discovery_is_atomic() /* allow_null_referent */));</span><br><span class=\"line\">    bool referent_is_dead = (iter.referent() != NULL) &amp;&amp; !iter.is_referent_alive();</span><br><span class=\"line\">    if (referent_is_dead &amp;&amp;</span><br><span class=\"line\">        !policy-&gt;should_clear_reference(iter.obj(), _soft_ref_timestamp_clock)) &#123;</span><br><span class=\"line\">      log_develop_trace(gc, ref)(&quot;Dropping reference (&quot; INTPTR_FORMAT &quot;: %s&quot;  &quot;) by policy&quot;,</span><br><span class=\"line\">                                 p2i(iter.obj()), iter.obj()-&gt;klass()-&gt;internal_name());</span><br><span class=\"line\">      // Remove Reference object from list</span><br><span class=\"line\">      iter.remove();</span><br><span class=\"line\">      // keep the referent around</span><br><span class=\"line\">      iter.make_referent_alive();</span><br><span class=\"line\">      iter.move_to_next();</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      iter.next();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  // Close the reachable set</span><br><span class=\"line\">  complete_gc-&gt;do_void();</span><br><span class=\"line\">  log_develop_trace(gc, ref)(&quot; Dropped &quot; SIZE_FORMAT &quot; dead Refs out of &quot; SIZE_FORMAT &quot; discovered Refs by policy, from list &quot; INTPTR_FORMAT,</span><br><span class=\"line\">                             iter.removed(), iter.processed(), p2i(&amp;refs_list));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>相关JVM参数<br>-XX:SoftRefLRUPolicyMSPerMB=0<br>-XX:+ParallelRefProcEnabled<br>-XX:+PrintReferenceGC</p>\n<p>-XX:SoftRefLRUPolicyMSPerMB=N 这个参数比较有用的，官方解释是：Soft reference在虚拟机中比在客户集中存活的更长一些。其清除频率可以用命令行参数 -XX:SoftRefLRUPolicyMSPerMB=<n>来控制，这可以指定每兆堆空闲空间的 soft reference 保持存活（一旦它不强可达了）的毫秒数，这意味着每兆堆中的空闲空间中的 soft reference 会（在最后一个强引用被回收之后）存活1秒钟。注意，这是一个近似的值，因为  soft reference 只会在垃圾回收时才会被清除，而垃圾回收并不总在发生。系统默认为一秒，我觉得没必要等1秒，客户集中不用就立刻清除，改为 -XX:SoftRefLRUPolicyMSPerMB=0；</n></p>\n<p>作者：MangoDai<br>链接：<a href=\"https://www.jianshu.com/p/3eb976e03457\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/3eb976e03457</a><br>来源：简书<br>简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p>\n<h3 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h3><p>ReferenceQueue在哪里，如果有ReferenceQueue，就可以查看到SoftReference的清理情况</p>\n","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// NOTE: process_phase*() are largely similar, and at a high level</span><br><span class=\"line\">// merely iterate over the extant list applying a predicate to</span><br><span class=\"line\">// each of its elements and possibly removing that element from the</span><br><span class=\"line\">// list and applying some further closures to that element.</span><br><span class=\"line\">// We should consider the possibility of replacing these</span><br><span class=\"line\">// process_phase*() methods by abstracting them into</span><br><span class=\"line\">// a single general iterator invocation that receives appropriate</span><br><span class=\"line\">// closures that accomplish this work.</span><br><span class=\"line\"></span><br><span class=\"line\">// (SoftReferences only) Traverse the list and remove any SoftReferences whose</span><br><span class=\"line\">// referents are not alive, but that should be kept alive for policy reasons.</span><br><span class=\"line\">// Keep alive the transitive closure of all such referents.</span><br><span class=\"line\">void</span><br><span class=\"line\">ReferenceProcessor::process_phase1(DiscoveredList&amp;    refs_list,</span><br><span class=\"line\">                                   ReferencePolicy*   policy,</span><br><span class=\"line\">                                   BoolObjectClosure* is_alive,</span><br><span class=\"line\">                                   OopClosure*        keep_alive,</span><br><span class=\"line\">                                   VoidClosure*       complete_gc) &#123;</span><br><span class=\"line\">  assert(policy != NULL, &quot;Must have a non-NULL policy&quot;);</span><br><span class=\"line\">  DiscoveredListIterator iter(refs_list, keep_alive, is_alive);</span><br><span class=\"line\">  // Decide which softly reachable refs should be kept alive.</span><br><span class=\"line\">  while (iter.has_next()) &#123;</span><br><span class=\"line\">    iter.load_ptrs(DEBUG_ONLY(!discovery_is_atomic() /* allow_null_referent */));</span><br><span class=\"line\">    bool referent_is_dead = (iter.referent() != NULL) &amp;&amp; !iter.is_referent_alive();</span><br><span class=\"line\">    if (referent_is_dead &amp;&amp;</span><br><span class=\"line\">        !policy-&gt;should_clear_reference(iter.obj(), _soft_ref_timestamp_clock)) &#123;</span><br><span class=\"line\">      log_develop_trace(gc, ref)(&quot;Dropping reference (&quot; INTPTR_FORMAT &quot;: %s&quot;  &quot;) by policy&quot;,</span><br><span class=\"line\">                                 p2i(iter.obj()), iter.obj()-&gt;klass()-&gt;internal_name());</span><br><span class=\"line\">      // Remove Reference object from list</span><br><span class=\"line\">      iter.remove();</span><br><span class=\"line\">      // keep the referent around</span><br><span class=\"line\">      iter.make_referent_alive();</span><br><span class=\"line\">      iter.move_to_next();</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      iter.next();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  // Close the reachable set</span><br><span class=\"line\">  complete_gc-&gt;do_void();</span><br><span class=\"line\">  log_develop_trace(gc, ref)(&quot; Dropped &quot; SIZE_FORMAT &quot; dead Refs out of &quot; SIZE_FORMAT &quot; discovered Refs by policy, from list &quot; INTPTR_FORMAT,</span><br><span class=\"line\">                             iter.removed(), iter.processed(), p2i(&amp;refs_list));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>相关JVM参数<br>-XX:SoftRefLRUPolicyMSPerMB=0<br>-XX:+ParallelRefProcEnabled<br>-XX:+PrintReferenceGC</p>\n<p>-XX:SoftRefLRUPolicyMSPerMB=N 这个参数比较有用的，官方解释是：Soft reference在虚拟机中比在客户集中存活的更长一些。其清除频率可以用命令行参数 -XX:SoftRefLRUPolicyMSPerMB=<n>来控制，这可以指定每兆堆空闲空间的 soft reference 保持存活（一旦它不强可达了）的毫秒数，这意味着每兆堆中的空闲空间中的 soft reference 会（在最后一个强引用被回收之后）存活1秒钟。注意，这是一个近似的值，因为  soft reference 只会在垃圾回收时才会被清除，而垃圾回收并不总在发生。系统默认为一秒，我觉得没必要等1秒，客户集中不用就立刻清除，改为 -XX:SoftRefLRUPolicyMSPerMB=0；</n></p>\n<p>作者：MangoDai<br>链接：<a href=\"https://www.jianshu.com/p/3eb976e03457\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/3eb976e03457</a><br>来源：简书<br>简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p>\n<h3 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h3><p>ReferenceQueue在哪里，如果有ReferenceQueue，就可以查看到SoftReference的清理情况</p>\n"},{"title":"JVM-Heap","date":"2018-10-07T08:38:55.000Z","_content":"\n\n### 写得超赞\nhttps://www.cnblogs.com/iceAeterNa/p/4877549.html\n\nUniverse::initialize_heap() universe.cpp:755\nuniverse_init() universe.cpp:672\ninit_globals() init.cpp:110\nThreads::create_vm(JavaVMInitArgs*, bool*) thread.cpp:3630\nJNI_CreateJavaVM_inner(JavaVM_**, void**, void*) jni.cpp:3937\n::JNI_CreateJavaVM(JavaVM **, void **, void *) jni.cpp:4032\nInitializeJVM 0x0000000104767e50\nJavaMain 0x000000010476702c\n_pthread_body 0x00007fffc9ad493b\n_pthread_start 0x00007fffc9ad4887\nthread_start 0x00007fffc9ad408d\n\n``` c++\nCollectedHeap* Universe::create_heap() {\n  assert(_collectedHeap == NULL, \"Heap already created\");\n#if !INCLUDE_ALL_GCS\n  if (UseParallelGC) {\n    fatal(\"UseParallelGC not supported in this VM.\");\n  } else if (UseG1GC) {\n    fatal(\"UseG1GC not supported in this VM.\");\n  } else if (UseConcMarkSweepGC) {\n    fatal(\"UseConcMarkSweepGC not supported in this VM.\");\n#else\n  if (UseParallelGC) {\n    return Universe::create_heap_with_policy<ParallelScavengeHeap, GenerationSizer>();\n  } else if (UseG1GC) {\n    return Universe::create_heap_with_policy<G1CollectedHeap, G1CollectorPolicy>();\n  } else if (UseConcMarkSweepGC) {\n    return Universe::create_heap_with_policy<GenCollectedHeap, ConcurrentMarkSweepPolicy>();\n#endif\n  } else if (UseSerialGC) {\n    return Universe::create_heap_with_policy<GenCollectedHeap, MarkSweepPolicy>();\n  }\n\n  ShouldNotReachHere();\n  return NULL;\n}\n```\n\n``` c++\njint GenCollectedHeap::initialize() {\n  CollectedHeap::pre_initialize();\n\n  // While there are no constraints in the GC code that HeapWordSize\n  // be any particular value, there are multiple other areas in the\n  // system which believe this to be true (e.g. oop->object_size in some\n  // cases incorrectly returns the size in wordSize units rather than\n  // HeapWordSize).\n  guarantee(HeapWordSize == wordSize, \"HeapWordSize must equal wordSize\");\n\n  // Allocate space for the heap.\n\n  char* heap_address;\n  ReservedSpace heap_rs;\n\n  size_t heap_alignment = collector_policy()->heap_alignment();\n\n  heap_address = allocate(heap_alignment, &heap_rs);\n\n  if (!heap_rs.is_reserved()) {\n    vm_shutdown_during_initialization(\n      \"Could not reserve enough space for object heap\");\n    return JNI_ENOMEM;\n  }\n\n  initialize_reserved_region((HeapWord*)heap_rs.base(), (HeapWord*)(heap_rs.base() + heap_rs.size()));\n\n  _rem_set = collector_policy()->create_rem_set(reserved_region());\n  set_barrier_set(rem_set()->bs());\n\n  ReservedSpace young_rs = heap_rs.first_part(gen_policy()->young_gen_spec()->max_size(), false, false);\n  _young_gen = gen_policy()->young_gen_spec()->init(young_rs, rem_set());\n  heap_rs = heap_rs.last_part(gen_policy()->young_gen_spec()->max_size());\n\n  ReservedSpace old_rs = heap_rs.first_part(gen_policy()->old_gen_spec()->max_size(), false, false);\n  _old_gen = gen_policy()->old_gen_spec()->init(old_rs, rem_set());\n  clear_incremental_collection_failed();\n\n#if INCLUDE_ALL_GCS\n  // If we are running CMS, create the collector responsible\n  // for collecting the CMS generations.\n  if (collector_policy()->is_concurrent_mark_sweep_policy()) {\n    bool success = create_cms_collector();\n    if (!success) return JNI_ENOMEM;\n  }\n#endif // INCLUDE_ALL_GCS\n\n  return JNI_OK;\n}\n```","source":"_posts/JVM-Heap.md","raw":"---\ntitle: JVM-Heap\ndate: 2018-10-07 16:38:55\ntags: JVM\n---\n\n\n### 写得超赞\nhttps://www.cnblogs.com/iceAeterNa/p/4877549.html\n\nUniverse::initialize_heap() universe.cpp:755\nuniverse_init() universe.cpp:672\ninit_globals() init.cpp:110\nThreads::create_vm(JavaVMInitArgs*, bool*) thread.cpp:3630\nJNI_CreateJavaVM_inner(JavaVM_**, void**, void*) jni.cpp:3937\n::JNI_CreateJavaVM(JavaVM **, void **, void *) jni.cpp:4032\nInitializeJVM 0x0000000104767e50\nJavaMain 0x000000010476702c\n_pthread_body 0x00007fffc9ad493b\n_pthread_start 0x00007fffc9ad4887\nthread_start 0x00007fffc9ad408d\n\n``` c++\nCollectedHeap* Universe::create_heap() {\n  assert(_collectedHeap == NULL, \"Heap already created\");\n#if !INCLUDE_ALL_GCS\n  if (UseParallelGC) {\n    fatal(\"UseParallelGC not supported in this VM.\");\n  } else if (UseG1GC) {\n    fatal(\"UseG1GC not supported in this VM.\");\n  } else if (UseConcMarkSweepGC) {\n    fatal(\"UseConcMarkSweepGC not supported in this VM.\");\n#else\n  if (UseParallelGC) {\n    return Universe::create_heap_with_policy<ParallelScavengeHeap, GenerationSizer>();\n  } else if (UseG1GC) {\n    return Universe::create_heap_with_policy<G1CollectedHeap, G1CollectorPolicy>();\n  } else if (UseConcMarkSweepGC) {\n    return Universe::create_heap_with_policy<GenCollectedHeap, ConcurrentMarkSweepPolicy>();\n#endif\n  } else if (UseSerialGC) {\n    return Universe::create_heap_with_policy<GenCollectedHeap, MarkSweepPolicy>();\n  }\n\n  ShouldNotReachHere();\n  return NULL;\n}\n```\n\n``` c++\njint GenCollectedHeap::initialize() {\n  CollectedHeap::pre_initialize();\n\n  // While there are no constraints in the GC code that HeapWordSize\n  // be any particular value, there are multiple other areas in the\n  // system which believe this to be true (e.g. oop->object_size in some\n  // cases incorrectly returns the size in wordSize units rather than\n  // HeapWordSize).\n  guarantee(HeapWordSize == wordSize, \"HeapWordSize must equal wordSize\");\n\n  // Allocate space for the heap.\n\n  char* heap_address;\n  ReservedSpace heap_rs;\n\n  size_t heap_alignment = collector_policy()->heap_alignment();\n\n  heap_address = allocate(heap_alignment, &heap_rs);\n\n  if (!heap_rs.is_reserved()) {\n    vm_shutdown_during_initialization(\n      \"Could not reserve enough space for object heap\");\n    return JNI_ENOMEM;\n  }\n\n  initialize_reserved_region((HeapWord*)heap_rs.base(), (HeapWord*)(heap_rs.base() + heap_rs.size()));\n\n  _rem_set = collector_policy()->create_rem_set(reserved_region());\n  set_barrier_set(rem_set()->bs());\n\n  ReservedSpace young_rs = heap_rs.first_part(gen_policy()->young_gen_spec()->max_size(), false, false);\n  _young_gen = gen_policy()->young_gen_spec()->init(young_rs, rem_set());\n  heap_rs = heap_rs.last_part(gen_policy()->young_gen_spec()->max_size());\n\n  ReservedSpace old_rs = heap_rs.first_part(gen_policy()->old_gen_spec()->max_size(), false, false);\n  _old_gen = gen_policy()->old_gen_spec()->init(old_rs, rem_set());\n  clear_incremental_collection_failed();\n\n#if INCLUDE_ALL_GCS\n  // If we are running CMS, create the collector responsible\n  // for collecting the CMS generations.\n  if (collector_policy()->is_concurrent_mark_sweep_policy()) {\n    bool success = create_cms_collector();\n    if (!success) return JNI_ENOMEM;\n  }\n#endif // INCLUDE_ALL_GCS\n\n  return JNI_OK;\n}\n```","slug":"JVM-Heap","published":1,"updated":"2019-10-18T03:58:46.748Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83g002gv1np2dmz65su","content":"<h3 id=\"写得超赞\"><a href=\"#写得超赞\" class=\"headerlink\" title=\"写得超赞\"></a>写得超赞</h3><p><a href=\"https://www.cnblogs.com/iceAeterNa/p/4877549.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/iceAeterNa/p/4877549.html</a></p>\n<p>Universe::initialize_heap() universe.cpp:755<br>universe_init() universe.cpp:672<br>init_globals() init.cpp:110<br>Threads::create_vm(JavaVMInitArgs<em>, bool</em>) thread.cpp:3630<br>JNI_CreateJavaVM_inner(JavaVM_<strong>, void</strong>, void<em>) jni.cpp:3937<br>::JNI_CreateJavaVM(JavaVM *</em>, void **, void *) jni.cpp:4032<br>InitializeJVM 0x0000000104767e50<br>JavaMain 0x000000010476702c<br>_pthread_body 0x00007fffc9ad493b<br>_pthread_start 0x00007fffc9ad4887<br>thread_start 0x00007fffc9ad408d</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CollectedHeap* Universe::create_heap() &#123;</span><br><span class=\"line\">  assert(_collectedHeap == <span class=\"literal\">NULL</span>, <span class=\"string\">\"Heap already created\"</span>);</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">if</span> !INCLUDE_ALL_GCS</span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (UseParallelGC) &#123;</span><br><span class=\"line\">    fatal(<span class=\"string\">\"UseParallelGC not supported in this VM.\"</span>);</span><br><span class=\"line\">  &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (UseG1GC) &#123;</span><br><span class=\"line\">    fatal(<span class=\"string\">\"UseG1GC not supported in this VM.\"</span>);</span><br><span class=\"line\">  &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (UseConcMarkSweepGC) &#123;</span><br><span class=\"line\">    fatal(<span class=\"string\">\"UseConcMarkSweepGC not supported in this VM.\"</span>);</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">else</span></span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (UseParallelGC) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Universe::create_heap_with_policy&lt;ParallelScavengeHeap, GenerationSizer&gt;();</span><br><span class=\"line\">  &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (UseG1GC) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Universe::create_heap_with_policy&lt;G1CollectedHeap, G1CollectorPolicy&gt;();</span><br><span class=\"line\">  &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (UseConcMarkSweepGC) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Universe::create_heap_with_policy&lt;GenCollectedHeap, ConcurrentMarkSweepPolicy&gt;();</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\">  &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (UseSerialGC) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Universe::create_heap_with_policy&lt;GenCollectedHeap, MarkSweepPolicy&gt;();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  ShouldNotReachHere();</span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jint GenCollectedHeap::initialize() &#123;</span><br><span class=\"line\">  CollectedHeap::pre_initialize();</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// While there are no constraints in the GC code that HeapWordSize</span></span><br><span class=\"line\">  <span class=\"comment\">// be any particular value, there are multiple other areas in the</span></span><br><span class=\"line\">  <span class=\"comment\">// system which believe this to be true (e.g. oop-&gt;object_size in some</span></span><br><span class=\"line\">  <span class=\"comment\">// cases incorrectly returns the size in wordSize units rather than</span></span><br><span class=\"line\">  <span class=\"comment\">// HeapWordSize).</span></span><br><span class=\"line\">  guarantee(HeapWordSize == wordSize, <span class=\"string\">\"HeapWordSize must equal wordSize\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// Allocate space for the heap.</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">char</span>* heap_address;</span><br><span class=\"line\">  ReservedSpace heap_rs;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">size_t</span> heap_alignment = collector_policy()-&gt;heap_alignment();</span><br><span class=\"line\"></span><br><span class=\"line\">  heap_address = allocate(heap_alignment, &amp;heap_rs);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (!heap_rs.is_reserved()) &#123;</span><br><span class=\"line\">    vm_shutdown_during_initialization(</span><br><span class=\"line\">      <span class=\"string\">\"Could not reserve enough space for object heap\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> JNI_ENOMEM;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  initialize_reserved_region((HeapWord*)heap_rs.base(), (HeapWord*)(heap_rs.base() + heap_rs.size()));</span><br><span class=\"line\"></span><br><span class=\"line\">  _rem_set = collector_policy()-&gt;create_rem_set(reserved_region());</span><br><span class=\"line\">  set_barrier_set(rem_set()-&gt;bs());</span><br><span class=\"line\"></span><br><span class=\"line\">  ReservedSpace young_rs = heap_rs.first_part(gen_policy()-&gt;young_gen_spec()-&gt;max_size(), <span class=\"literal\">false</span>, <span class=\"literal\">false</span>);</span><br><span class=\"line\">  _young_gen = gen_policy()-&gt;young_gen_spec()-&gt;init(young_rs, rem_set());</span><br><span class=\"line\">  heap_rs = heap_rs.last_part(gen_policy()-&gt;young_gen_spec()-&gt;max_size());</span><br><span class=\"line\"></span><br><span class=\"line\">  ReservedSpace old_rs = heap_rs.first_part(gen_policy()-&gt;old_gen_spec()-&gt;max_size(), <span class=\"literal\">false</span>, <span class=\"literal\">false</span>);</span><br><span class=\"line\">  _old_gen = gen_policy()-&gt;old_gen_spec()-&gt;init(old_rs, rem_set());</span><br><span class=\"line\">  clear_incremental_collection_failed();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">if</span> INCLUDE_ALL_GCS</span></span><br><span class=\"line\">  <span class=\"comment\">// If we are running CMS, create the collector responsible</span></span><br><span class=\"line\">  <span class=\"comment\">// for collecting the CMS generations.</span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (collector_policy()-&gt;is_concurrent_mark_sweep_policy()) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">bool</span> success = create_cms_collector();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!success) <span class=\"keyword\">return</span> JNI_ENOMEM;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span> <span class=\"comment\">// INCLUDE_ALL_GCS</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> JNI_OK;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"写得超赞\"><a href=\"#写得超赞\" class=\"headerlink\" title=\"写得超赞\"></a>写得超赞</h3><p><a href=\"https://www.cnblogs.com/iceAeterNa/p/4877549.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/iceAeterNa/p/4877549.html</a></p>\n<p>Universe::initialize_heap() universe.cpp:755<br>universe_init() universe.cpp:672<br>init_globals() init.cpp:110<br>Threads::create_vm(JavaVMInitArgs<em>, bool</em>) thread.cpp:3630<br>JNI_CreateJavaVM_inner(JavaVM_<strong>, void</strong>, void<em>) jni.cpp:3937<br>::JNI_CreateJavaVM(JavaVM *</em>, void **, void *) jni.cpp:4032<br>InitializeJVM 0x0000000104767e50<br>JavaMain 0x000000010476702c<br>_pthread_body 0x00007fffc9ad493b<br>_pthread_start 0x00007fffc9ad4887<br>thread_start 0x00007fffc9ad408d</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CollectedHeap* Universe::create_heap() &#123;</span><br><span class=\"line\">  assert(_collectedHeap == <span class=\"literal\">NULL</span>, <span class=\"string\">\"Heap already created\"</span>);</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">if</span> !INCLUDE_ALL_GCS</span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (UseParallelGC) &#123;</span><br><span class=\"line\">    fatal(<span class=\"string\">\"UseParallelGC not supported in this VM.\"</span>);</span><br><span class=\"line\">  &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (UseG1GC) &#123;</span><br><span class=\"line\">    fatal(<span class=\"string\">\"UseG1GC not supported in this VM.\"</span>);</span><br><span class=\"line\">  &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (UseConcMarkSweepGC) &#123;</span><br><span class=\"line\">    fatal(<span class=\"string\">\"UseConcMarkSweepGC not supported in this VM.\"</span>);</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">else</span></span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (UseParallelGC) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Universe::create_heap_with_policy&lt;ParallelScavengeHeap, GenerationSizer&gt;();</span><br><span class=\"line\">  &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (UseG1GC) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Universe::create_heap_with_policy&lt;G1CollectedHeap, G1CollectorPolicy&gt;();</span><br><span class=\"line\">  &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (UseConcMarkSweepGC) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Universe::create_heap_with_policy&lt;GenCollectedHeap, ConcurrentMarkSweepPolicy&gt;();</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\">  &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (UseSerialGC) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Universe::create_heap_with_policy&lt;GenCollectedHeap, MarkSweepPolicy&gt;();</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  ShouldNotReachHere();</span><br><span class=\"line\">  <span class=\"keyword\">return</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jint GenCollectedHeap::initialize() &#123;</span><br><span class=\"line\">  CollectedHeap::pre_initialize();</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// While there are no constraints in the GC code that HeapWordSize</span></span><br><span class=\"line\">  <span class=\"comment\">// be any particular value, there are multiple other areas in the</span></span><br><span class=\"line\">  <span class=\"comment\">// system which believe this to be true (e.g. oop-&gt;object_size in some</span></span><br><span class=\"line\">  <span class=\"comment\">// cases incorrectly returns the size in wordSize units rather than</span></span><br><span class=\"line\">  <span class=\"comment\">// HeapWordSize).</span></span><br><span class=\"line\">  guarantee(HeapWordSize == wordSize, <span class=\"string\">\"HeapWordSize must equal wordSize\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// Allocate space for the heap.</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">char</span>* heap_address;</span><br><span class=\"line\">  ReservedSpace heap_rs;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">size_t</span> heap_alignment = collector_policy()-&gt;heap_alignment();</span><br><span class=\"line\"></span><br><span class=\"line\">  heap_address = allocate(heap_alignment, &amp;heap_rs);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (!heap_rs.is_reserved()) &#123;</span><br><span class=\"line\">    vm_shutdown_during_initialization(</span><br><span class=\"line\">      <span class=\"string\">\"Could not reserve enough space for object heap\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> JNI_ENOMEM;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  initialize_reserved_region((HeapWord*)heap_rs.base(), (HeapWord*)(heap_rs.base() + heap_rs.size()));</span><br><span class=\"line\"></span><br><span class=\"line\">  _rem_set = collector_policy()-&gt;create_rem_set(reserved_region());</span><br><span class=\"line\">  set_barrier_set(rem_set()-&gt;bs());</span><br><span class=\"line\"></span><br><span class=\"line\">  ReservedSpace young_rs = heap_rs.first_part(gen_policy()-&gt;young_gen_spec()-&gt;max_size(), <span class=\"literal\">false</span>, <span class=\"literal\">false</span>);</span><br><span class=\"line\">  _young_gen = gen_policy()-&gt;young_gen_spec()-&gt;init(young_rs, rem_set());</span><br><span class=\"line\">  heap_rs = heap_rs.last_part(gen_policy()-&gt;young_gen_spec()-&gt;max_size());</span><br><span class=\"line\"></span><br><span class=\"line\">  ReservedSpace old_rs = heap_rs.first_part(gen_policy()-&gt;old_gen_spec()-&gt;max_size(), <span class=\"literal\">false</span>, <span class=\"literal\">false</span>);</span><br><span class=\"line\">  _old_gen = gen_policy()-&gt;old_gen_spec()-&gt;init(old_rs, rem_set());</span><br><span class=\"line\">  clear_incremental_collection_failed();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">if</span> INCLUDE_ALL_GCS</span></span><br><span class=\"line\">  <span class=\"comment\">// If we are running CMS, create the collector responsible</span></span><br><span class=\"line\">  <span class=\"comment\">// for collecting the CMS generations.</span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (collector_policy()-&gt;is_concurrent_mark_sweep_policy()) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">bool</span> success = create_cms_collector();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!success) <span class=\"keyword\">return</span> JNI_ENOMEM;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span> <span class=\"comment\">// INCLUDE_ALL_GCS</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"keyword\">return</span> JNI_OK;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"JVM-TLAB","date":"2018-11-15T02:32:24.000Z","_content":"\n\n### 疑问\n按照我的理解，TLAB应该是JavaThread在申请内存时，在JavaThread Local上直接分配内存，如果TLAB的内存也不够了，那么再给该JavaThread分配TLAB。那么，Java中new Thread()难道还需要创建TLAB？这样这个操作不是显得有点重么？\n\n\n\n在JVM的线程类定义中，有一个TLAB字段\n``` thread.hpp\nclass Thread: public ThreadShadow {\n    private:\n    ThreadLocalAllocBuffer _tlab;                 // Thread-local eden\n}\n```\n\n\n### TLAB从Eden区划出范围\n```\nThreadLocalAllocBuffer::initialize threadLocalAllocBuffer.cpp:182\nThreadLocalAllocBuffer::fill threadLocalAllocBuffer.cpp:173\nCollectedHeap::allocate_from_tlab_slow collectedHeap.cpp:322\nCollectedHeap::allocate_from_tlab collectedHeap.inline.hpp:203\nCollectedHeap::common_mem_allocate_noinit collectedHeap.inline.hpp:141\nCollectedHeap::common_mem_allocate_init collectedHeap.inline.hpp:190\nCollectedHeap::array_allocate collectedHeap.inline.hpp:241\nTypeArrayKlass::allocate_common typeArrayKlass.cpp:109\nTypeArrayKlass::allocate typeArrayKlass.hpp:67\noopFactory::new_intArray oopFactory.hpp:50\nSystemDictionary::initialize systemDictionary.cpp:2078\nUniverse::genesis universe.cpp:317\nuniverse2_init universe.cpp:977\ninit_globals init.cpp:122\nThreads::create_vm thread.cpp:3630\nJNI_CreateJavaVM_inner jni.cpp:3937\nJNI_CreateJavaVM jni.cpp:4032\nInitializeJVM 0x0000000100005e50\nJavaMain 0x000000010000502c\n_pthread_body 0x00007fff942c793b\n_pthread_start 0x00007fff942c7887\nthread_start 0x00007fff942c708d\n<unknown> 0x0000000000000000\n```","source":"_posts/JVM-TLAB.md","raw":"---\ntitle: JVM-TLAB\ndate: 2018-11-15 10:32:24\ntags: JVM\n---\n\n\n### 疑问\n按照我的理解，TLAB应该是JavaThread在申请内存时，在JavaThread Local上直接分配内存，如果TLAB的内存也不够了，那么再给该JavaThread分配TLAB。那么，Java中new Thread()难道还需要创建TLAB？这样这个操作不是显得有点重么？\n\n\n\n在JVM的线程类定义中，有一个TLAB字段\n``` thread.hpp\nclass Thread: public ThreadShadow {\n    private:\n    ThreadLocalAllocBuffer _tlab;                 // Thread-local eden\n}\n```\n\n\n### TLAB从Eden区划出范围\n```\nThreadLocalAllocBuffer::initialize threadLocalAllocBuffer.cpp:182\nThreadLocalAllocBuffer::fill threadLocalAllocBuffer.cpp:173\nCollectedHeap::allocate_from_tlab_slow collectedHeap.cpp:322\nCollectedHeap::allocate_from_tlab collectedHeap.inline.hpp:203\nCollectedHeap::common_mem_allocate_noinit collectedHeap.inline.hpp:141\nCollectedHeap::common_mem_allocate_init collectedHeap.inline.hpp:190\nCollectedHeap::array_allocate collectedHeap.inline.hpp:241\nTypeArrayKlass::allocate_common typeArrayKlass.cpp:109\nTypeArrayKlass::allocate typeArrayKlass.hpp:67\noopFactory::new_intArray oopFactory.hpp:50\nSystemDictionary::initialize systemDictionary.cpp:2078\nUniverse::genesis universe.cpp:317\nuniverse2_init universe.cpp:977\ninit_globals init.cpp:122\nThreads::create_vm thread.cpp:3630\nJNI_CreateJavaVM_inner jni.cpp:3937\nJNI_CreateJavaVM jni.cpp:4032\nInitializeJVM 0x0000000100005e50\nJavaMain 0x000000010000502c\n_pthread_body 0x00007fff942c793b\n_pthread_start 0x00007fff942c7887\nthread_start 0x00007fff942c708d\n<unknown> 0x0000000000000000\n```","slug":"JVM-TLAB","published":1,"updated":"2019-09-28T08:51:00.878Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83h002hv1npthdghg5t","content":"<h3 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h3><p>按照我的理解，TLAB应该是JavaThread在申请内存时，在JavaThread Local上直接分配内存，如果TLAB的内存也不够了，那么再给该JavaThread分配TLAB。那么，Java中new Thread()难道还需要创建TLAB？这样这个操作不是显得有点重么？</p>\n<p>在JVM的线程类定义中，有一个TLAB字段</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class Thread: public ThreadShadow &#123;</span><br><span class=\"line\">    private:</span><br><span class=\"line\">    ThreadLocalAllocBuffer _tlab;                 // Thread-local eden</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"TLAB从Eden区划出范围\"><a href=\"#TLAB从Eden区划出范围\" class=\"headerlink\" title=\"TLAB从Eden区划出范围\"></a>TLAB从Eden区划出范围</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ThreadLocalAllocBuffer::initialize threadLocalAllocBuffer.cpp:182</span><br><span class=\"line\">ThreadLocalAllocBuffer::fill threadLocalAllocBuffer.cpp:173</span><br><span class=\"line\">CollectedHeap::allocate_from_tlab_slow collectedHeap.cpp:322</span><br><span class=\"line\">CollectedHeap::allocate_from_tlab collectedHeap.inline.hpp:203</span><br><span class=\"line\">CollectedHeap::common_mem_allocate_noinit collectedHeap.inline.hpp:141</span><br><span class=\"line\">CollectedHeap::common_mem_allocate_init collectedHeap.inline.hpp:190</span><br><span class=\"line\">CollectedHeap::array_allocate collectedHeap.inline.hpp:241</span><br><span class=\"line\">TypeArrayKlass::allocate_common typeArrayKlass.cpp:109</span><br><span class=\"line\">TypeArrayKlass::allocate typeArrayKlass.hpp:67</span><br><span class=\"line\">oopFactory::new_intArray oopFactory.hpp:50</span><br><span class=\"line\">SystemDictionary::initialize systemDictionary.cpp:2078</span><br><span class=\"line\">Universe::genesis universe.cpp:317</span><br><span class=\"line\">universe2_init universe.cpp:977</span><br><span class=\"line\">init_globals init.cpp:122</span><br><span class=\"line\">Threads::create_vm thread.cpp:3630</span><br><span class=\"line\">JNI_CreateJavaVM_inner jni.cpp:3937</span><br><span class=\"line\">JNI_CreateJavaVM jni.cpp:4032</span><br><span class=\"line\">InitializeJVM 0x0000000100005e50</span><br><span class=\"line\">JavaMain 0x000000010000502c</span><br><span class=\"line\">_pthread_body 0x00007fff942c793b</span><br><span class=\"line\">_pthread_start 0x00007fff942c7887</span><br><span class=\"line\">thread_start 0x00007fff942c708d</span><br><span class=\"line\">&lt;unknown&gt; 0x0000000000000000</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h3><p>按照我的理解，TLAB应该是JavaThread在申请内存时，在JavaThread Local上直接分配内存，如果TLAB的内存也不够了，那么再给该JavaThread分配TLAB。那么，Java中new Thread()难道还需要创建TLAB？这样这个操作不是显得有点重么？</p>\n<p>在JVM的线程类定义中，有一个TLAB字段</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class Thread: public ThreadShadow &#123;</span><br><span class=\"line\">    private:</span><br><span class=\"line\">    ThreadLocalAllocBuffer _tlab;                 // Thread-local eden</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"TLAB从Eden区划出范围\"><a href=\"#TLAB从Eden区划出范围\" class=\"headerlink\" title=\"TLAB从Eden区划出范围\"></a>TLAB从Eden区划出范围</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ThreadLocalAllocBuffer::initialize threadLocalAllocBuffer.cpp:182</span><br><span class=\"line\">ThreadLocalAllocBuffer::fill threadLocalAllocBuffer.cpp:173</span><br><span class=\"line\">CollectedHeap::allocate_from_tlab_slow collectedHeap.cpp:322</span><br><span class=\"line\">CollectedHeap::allocate_from_tlab collectedHeap.inline.hpp:203</span><br><span class=\"line\">CollectedHeap::common_mem_allocate_noinit collectedHeap.inline.hpp:141</span><br><span class=\"line\">CollectedHeap::common_mem_allocate_init collectedHeap.inline.hpp:190</span><br><span class=\"line\">CollectedHeap::array_allocate collectedHeap.inline.hpp:241</span><br><span class=\"line\">TypeArrayKlass::allocate_common typeArrayKlass.cpp:109</span><br><span class=\"line\">TypeArrayKlass::allocate typeArrayKlass.hpp:67</span><br><span class=\"line\">oopFactory::new_intArray oopFactory.hpp:50</span><br><span class=\"line\">SystemDictionary::initialize systemDictionary.cpp:2078</span><br><span class=\"line\">Universe::genesis universe.cpp:317</span><br><span class=\"line\">universe2_init universe.cpp:977</span><br><span class=\"line\">init_globals init.cpp:122</span><br><span class=\"line\">Threads::create_vm thread.cpp:3630</span><br><span class=\"line\">JNI_CreateJavaVM_inner jni.cpp:3937</span><br><span class=\"line\">JNI_CreateJavaVM jni.cpp:4032</span><br><span class=\"line\">InitializeJVM 0x0000000100005e50</span><br><span class=\"line\">JavaMain 0x000000010000502c</span><br><span class=\"line\">_pthread_body 0x00007fff942c793b</span><br><span class=\"line\">_pthread_start 0x00007fff942c7887</span><br><span class=\"line\">thread_start 0x00007fff942c708d</span><br><span class=\"line\">&lt;unknown&gt; 0x0000000000000000</span><br></pre></td></tr></table></figure>"},{"title":"JVM-Synchronized","date":"2018-08-16T01:47:06.000Z","_content":"\n### 死磕系列\nhttp://cmsblogs.com/?p=2071\n\n\n理解Synchronized的关键，在于真正去理解什么是多线程的对于临界区的竞争。\n1. 多个线程访问一个临界区，只要它们进来的时候是有先有后的（串行），这个就不是竞争关系。\n\nFAQ:\n我有个问题。\nHotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。\n1. 一个线程获取到锁，别的线程不就是处于竞争锁的状态吗，为什么文中说\"大多数情况下，不存在多线程竞争\"？\n2. “总是由同一线程多次获得”，线程执行完不就销毁吗，为什么还多次获得?\n\n1. 一个线程获取到锁并不意味着别的线程处于竞争锁的状态，只要它们轮流进入critical section没有重叠互不干扰，那就不存在竞争，这在critical section比较短小的情况下是极可能的。\n2. “总是由同一线程获得”是指一个线程执行过程中先后多次访问了被synchronized保护的代码段，这时偏向锁就发挥作用了，因为同一线程进入自己把持的偏向锁不需要CAS，而且出来时也并不主动释放锁，所以开销很小。\n\n\nhttps://www.jianshu.com/p/36eedeb3f912\n\nFAQ\n## 在JDK没有优化synchronized之前，它到底在性能上有什么问题？\n在没有优化之前，synchronized几乎等同于操作系统的mutex。如果一个线程获取了临界资源，那么其它的线程将会被阻塞，如果要唤醒，要需要从内核态进行唤醒。\n\n\n### 同步的原理\n\nJVM规范规定JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处， JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个 monitor 与之关联，当且一个monitor 被持有后，它将处于锁定状态。线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 的所有权，即尝试获得对象的锁。\n\n### Java对象头\n\n锁存在Java对象头里。如果对象是数组类型，则虚拟机用3个Word（字宽）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，一字宽等于四字节，即32bit。\n\n| 长度 | 内容 | 说明 |\n| --------- |:-----------:|:-----------|\n| 32/64bit | Mark Word | 存储对象的hashCode或锁信息等\n| 32/64bit | Class Metadata Address | 存储到对象类型数据的指针\n| 32/64bit | Array length | 数组的长度（如果当前对象是数组）\n\nJava对象头里的Mark Word里默认存储对象的HashCode，分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如下：\n\n25 bit\t4bit\t1bit\n是否是偏向锁\t2bit\n锁标志位\n无锁状态\t对象的hashCode\t对象分代年龄\t0\t01\n\n在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据：\n![你想输入的替代文字](JVM-Lock/markword_state.jpg)\n\n### 几种锁的类型\n\n**线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。**\nJava SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。\n**锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。**\n\n#### 偏向锁\nHotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护。\n![你想输入的替代文字](JVM-Lock/biased_lock_flow.jpg)\n\n##### 偏向锁的进一步理解\n偏向锁的释放不需要做任何事情，这也就意味着加过偏向锁的MarkValue会一直保留偏向锁的状态，因此即便同一个线程持续不断地加锁解锁，也是没有开销的。\n\n另一方面，偏向锁比轻量锁更容易被终结，轻量锁是在有锁竞争出现时升级为重量锁，而一般偏向锁是在有不同线程申请锁时升级为轻量锁，这也就意味着假如一个对象先被线程1加锁解锁，再被线程2加锁解锁，这过程中没有锁冲突，也一样会发生偏向锁失效，不同的是这回要先退化为无锁的状态，再加轻量锁，如图：\n\n另外，JVM对那种会有多线程加锁，但不存在锁竞争的情况也做了优化，听起来比较拗口，但在现实应用中确实是可能出现这种情况，因为线程之前除了互斥之外也可能发生同步关系，被同步的两个线程（一前一后）对共享对象锁的竞争很可能是没有冲突的。对这种情况，JVM用一个epoch表示一个偏向锁的时间戳（真实地生成一个时间戳代价还是蛮大的，因此这里应当理解为一种类似时间戳的identifier），对epoch，官方是这么解释的：\n\n##### 偏向锁的获取\n\n当一个线程访问同步块并获取锁时，**会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁**，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。\n\n##### 偏向锁的撤销\n\n**偏向锁使用了一种等到竞争出现才释放锁的机制**，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。\n\n##### 偏向锁的设置\n\n关闭偏向锁：偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。\n\n#### 自旋锁\n\n线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。同时我们可以发现，很多对象锁的锁定状态只会持续很短的一段时间，例如整数的自加操作，在很短的时间内阻塞并唤醒线程显然不值得，为此引入了自旋锁。\n所谓“自旋”，就是让线程去执行一个无意义的循环，循环结束后再去重新竞争锁，如果竞争不到继续循环，循环过程中线程会一直处于running状态，但是基于JVM的线程调度，会出让时间片，所以其他线程依旧有申请锁和释放锁的机会。\n自旋锁省去了阻塞锁的时间空间（队列的维护等）开销，但是长时间自旋就变成了“忙式等待”，忙式等待显然还不如阻塞锁。所以自旋的次数一般控制在一个范围内，例如10,100等，在超出这个范围后，自旋锁会升级为阻塞锁。\n对自旋锁周期的选择上，HotSpot认为最佳时间应是一个线程上下文切换的时间，但目前并没有做到。经过调查，目前只是通过汇编暂停了几个CPU周期，除了自旋周期选择，HotSpot还进行许多其他的自旋优化策略，具体如下：\n如果平均负载小于CPUs则一直自旋\n如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞\n如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞 如果CPU处于节电模式则停止自旋\n自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差）\n\n#### 轻量级锁\n\n##### 轻量级锁加锁\n\n线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。**然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，则自旋获取锁，当自旋获取锁仍然失败时，表示存在其他线程竞争锁(两条或两条以上的线程竞争同一个锁)，则轻量级锁会膨胀成重量级锁。**\n\n##### 轻量级锁解锁\n\n**轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示同步过程已完成。**如果失败，表示有其他线程尝试过获取该锁，则要在释放锁的同时唤醒被挂起的线程。下图是两个线程同时争夺锁，导致锁膨胀的流程图。\n\n![你想输入的替代文字](JVM-Lock/light_lock_flow.jpg)\n\n### 锁的优缺点总结\n\n| 锁 | 优点 | 缺点 | 适用场景 |\n| --------- |:-----------:|:-----------|:-----------|\n| 偏向锁\t | 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距 | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 | 适用于只有一个线程访问同步块场景\n| 轻量级锁 | 竞争的线程不会阻塞，提高了程序的响应速度 | 如果始终得不到锁竞争的线程使用自旋会消耗CPU | 追求响应时间,锁占用时间很短\n| 重量级锁 | 线程竞争不使用自旋，不会消耗CPU | 线程阻塞，响应时间缓慢 | 追求吞吐量,锁占用时间较长\n\n> 内容参考：http://luojinping.com/2015/07/09/java%E9%94%81%E4%BC%98%E5%8C%96/\n\n\n","source":"_posts/JVM-Synchronized.md","raw":"---\ntitle: JVM-Synchronized\ndate: 2018-08-16 09:47:06\ntags: JVM\n---\n\n### 死磕系列\nhttp://cmsblogs.com/?p=2071\n\n\n理解Synchronized的关键，在于真正去理解什么是多线程的对于临界区的竞争。\n1. 多个线程访问一个临界区，只要它们进来的时候是有先有后的（串行），这个就不是竞争关系。\n\nFAQ:\n我有个问题。\nHotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。\n1. 一个线程获取到锁，别的线程不就是处于竞争锁的状态吗，为什么文中说\"大多数情况下，不存在多线程竞争\"？\n2. “总是由同一线程多次获得”，线程执行完不就销毁吗，为什么还多次获得?\n\n1. 一个线程获取到锁并不意味着别的线程处于竞争锁的状态，只要它们轮流进入critical section没有重叠互不干扰，那就不存在竞争，这在critical section比较短小的情况下是极可能的。\n2. “总是由同一线程获得”是指一个线程执行过程中先后多次访问了被synchronized保护的代码段，这时偏向锁就发挥作用了，因为同一线程进入自己把持的偏向锁不需要CAS，而且出来时也并不主动释放锁，所以开销很小。\n\n\nhttps://www.jianshu.com/p/36eedeb3f912\n\nFAQ\n## 在JDK没有优化synchronized之前，它到底在性能上有什么问题？\n在没有优化之前，synchronized几乎等同于操作系统的mutex。如果一个线程获取了临界资源，那么其它的线程将会被阻塞，如果要唤醒，要需要从内核态进行唤醒。\n\n\n### 同步的原理\n\nJVM规范规定JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处， JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个 monitor 与之关联，当且一个monitor 被持有后，它将处于锁定状态。线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 的所有权，即尝试获得对象的锁。\n\n### Java对象头\n\n锁存在Java对象头里。如果对象是数组类型，则虚拟机用3个Word（字宽）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，一字宽等于四字节，即32bit。\n\n| 长度 | 内容 | 说明 |\n| --------- |:-----------:|:-----------|\n| 32/64bit | Mark Word | 存储对象的hashCode或锁信息等\n| 32/64bit | Class Metadata Address | 存储到对象类型数据的指针\n| 32/64bit | Array length | 数组的长度（如果当前对象是数组）\n\nJava对象头里的Mark Word里默认存储对象的HashCode，分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如下：\n\n25 bit\t4bit\t1bit\n是否是偏向锁\t2bit\n锁标志位\n无锁状态\t对象的hashCode\t对象分代年龄\t0\t01\n\n在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据：\n![你想输入的替代文字](JVM-Lock/markword_state.jpg)\n\n### 几种锁的类型\n\n**线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。**\nJava SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。\n**锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。**\n\n#### 偏向锁\nHotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护。\n![你想输入的替代文字](JVM-Lock/biased_lock_flow.jpg)\n\n##### 偏向锁的进一步理解\n偏向锁的释放不需要做任何事情，这也就意味着加过偏向锁的MarkValue会一直保留偏向锁的状态，因此即便同一个线程持续不断地加锁解锁，也是没有开销的。\n\n另一方面，偏向锁比轻量锁更容易被终结，轻量锁是在有锁竞争出现时升级为重量锁，而一般偏向锁是在有不同线程申请锁时升级为轻量锁，这也就意味着假如一个对象先被线程1加锁解锁，再被线程2加锁解锁，这过程中没有锁冲突，也一样会发生偏向锁失效，不同的是这回要先退化为无锁的状态，再加轻量锁，如图：\n\n另外，JVM对那种会有多线程加锁，但不存在锁竞争的情况也做了优化，听起来比较拗口，但在现实应用中确实是可能出现这种情况，因为线程之前除了互斥之外也可能发生同步关系，被同步的两个线程（一前一后）对共享对象锁的竞争很可能是没有冲突的。对这种情况，JVM用一个epoch表示一个偏向锁的时间戳（真实地生成一个时间戳代价还是蛮大的，因此这里应当理解为一种类似时间戳的identifier），对epoch，官方是这么解释的：\n\n##### 偏向锁的获取\n\n当一个线程访问同步块并获取锁时，**会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁**，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。\n\n##### 偏向锁的撤销\n\n**偏向锁使用了一种等到竞争出现才释放锁的机制**，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。\n\n##### 偏向锁的设置\n\n关闭偏向锁：偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。\n\n#### 自旋锁\n\n线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。同时我们可以发现，很多对象锁的锁定状态只会持续很短的一段时间，例如整数的自加操作，在很短的时间内阻塞并唤醒线程显然不值得，为此引入了自旋锁。\n所谓“自旋”，就是让线程去执行一个无意义的循环，循环结束后再去重新竞争锁，如果竞争不到继续循环，循环过程中线程会一直处于running状态，但是基于JVM的线程调度，会出让时间片，所以其他线程依旧有申请锁和释放锁的机会。\n自旋锁省去了阻塞锁的时间空间（队列的维护等）开销，但是长时间自旋就变成了“忙式等待”，忙式等待显然还不如阻塞锁。所以自旋的次数一般控制在一个范围内，例如10,100等，在超出这个范围后，自旋锁会升级为阻塞锁。\n对自旋锁周期的选择上，HotSpot认为最佳时间应是一个线程上下文切换的时间，但目前并没有做到。经过调查，目前只是通过汇编暂停了几个CPU周期，除了自旋周期选择，HotSpot还进行许多其他的自旋优化策略，具体如下：\n如果平均负载小于CPUs则一直自旋\n如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞\n如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞 如果CPU处于节电模式则停止自旋\n自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差）\n\n#### 轻量级锁\n\n##### 轻量级锁加锁\n\n线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。**然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，则自旋获取锁，当自旋获取锁仍然失败时，表示存在其他线程竞争锁(两条或两条以上的线程竞争同一个锁)，则轻量级锁会膨胀成重量级锁。**\n\n##### 轻量级锁解锁\n\n**轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示同步过程已完成。**如果失败，表示有其他线程尝试过获取该锁，则要在释放锁的同时唤醒被挂起的线程。下图是两个线程同时争夺锁，导致锁膨胀的流程图。\n\n![你想输入的替代文字](JVM-Lock/light_lock_flow.jpg)\n\n### 锁的优缺点总结\n\n| 锁 | 优点 | 缺点 | 适用场景 |\n| --------- |:-----------:|:-----------|:-----------|\n| 偏向锁\t | 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距 | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 | 适用于只有一个线程访问同步块场景\n| 轻量级锁 | 竞争的线程不会阻塞，提高了程序的响应速度 | 如果始终得不到锁竞争的线程使用自旋会消耗CPU | 追求响应时间,锁占用时间很短\n| 重量级锁 | 线程竞争不使用自旋，不会消耗CPU | 线程阻塞，响应时间缓慢 | 追求吞吐量,锁占用时间较长\n\n> 内容参考：http://luojinping.com/2015/07/09/java%E9%94%81%E4%BC%98%E5%8C%96/\n\n\n","slug":"JVM-Synchronized","published":1,"updated":"2019-09-28T08:51:00.871Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83h002iv1np6gqeefys","content":"<h3 id=\"死磕系列\"><a href=\"#死磕系列\" class=\"headerlink\" title=\"死磕系列\"></a>死磕系列</h3><p><a href=\"http://cmsblogs.com/?p=2071\" target=\"_blank\" rel=\"noopener\">http://cmsblogs.com/?p=2071</a></p>\n<p>理解Synchronized的关键，在于真正去理解什么是多线程的对于临界区的竞争。</p>\n<ol>\n<li>多个线程访问一个临界区，只要它们进来的时候是有先有后的（串行），这个就不是竞争关系。</li>\n</ol>\n<p>FAQ:<br>我有个问题。<br>HotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。</p>\n<ol>\n<li><p>一个线程获取到锁，别的线程不就是处于竞争锁的状态吗，为什么文中说”大多数情况下，不存在多线程竞争”？</p>\n</li>\n<li><p>“总是由同一线程多次获得”，线程执行完不就销毁吗，为什么还多次获得?</p>\n</li>\n<li><p>一个线程获取到锁并不意味着别的线程处于竞争锁的状态，只要它们轮流进入critical section没有重叠互不干扰，那就不存在竞争，这在critical section比较短小的情况下是极可能的。</p>\n</li>\n<li><p>“总是由同一线程获得”是指一个线程执行过程中先后多次访问了被synchronized保护的代码段，这时偏向锁就发挥作用了，因为同一线程进入自己把持的偏向锁不需要CAS，而且出来时也并不主动释放锁，所以开销很小。</p>\n</li>\n</ol>\n<p><a href=\"https://www.jianshu.com/p/36eedeb3f912\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/36eedeb3f912</a></p>\n<p>FAQ</p>\n<h2 id=\"在JDK没有优化synchronized之前，它到底在性能上有什么问题？\"><a href=\"#在JDK没有优化synchronized之前，它到底在性能上有什么问题？\" class=\"headerlink\" title=\"在JDK没有优化synchronized之前，它到底在性能上有什么问题？\"></a>在JDK没有优化synchronized之前，它到底在性能上有什么问题？</h2><p>在没有优化之前，synchronized几乎等同于操作系统的mutex。如果一个线程获取了临界资源，那么其它的线程将会被阻塞，如果要唤醒，要需要从内核态进行唤醒。</p>\n<h3 id=\"同步的原理\"><a href=\"#同步的原理\" class=\"headerlink\" title=\"同步的原理\"></a>同步的原理</h3><p>JVM规范规定JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处， JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个 monitor 与之关联，当且一个monitor 被持有后，它将处于锁定状态。线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 的所有权，即尝试获得对象的锁。</p>\n<h3 id=\"Java对象头\"><a href=\"#Java对象头\" class=\"headerlink\" title=\"Java对象头\"></a>Java对象头</h3><p>锁存在Java对象头里。如果对象是数组类型，则虚拟机用3个Word（字宽）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，一字宽等于四字节，即32bit。</p>\n<table>\n<thead>\n<tr>\n<th>长度</th>\n<th align=\"center\">内容</th>\n<th align=\"left\">说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>32/64bit</td>\n<td align=\"center\">Mark Word</td>\n<td align=\"left\">存储对象的hashCode或锁信息等</td>\n</tr>\n<tr>\n<td>32/64bit</td>\n<td align=\"center\">Class Metadata Address</td>\n<td align=\"left\">存储到对象类型数据的指针</td>\n</tr>\n<tr>\n<td>32/64bit</td>\n<td align=\"center\">Array length</td>\n<td align=\"left\">数组的长度（如果当前对象是数组）</td>\n</tr>\n</tbody></table>\n<p>Java对象头里的Mark Word里默认存储对象的HashCode，分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如下：</p>\n<p>25 bit    4bit    1bit<br>是否是偏向锁    2bit<br>锁标志位<br>无锁状态    对象的hashCode    对象分代年龄    0    01</p>\n<p>在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据：<br><img src=\"/2018/08/16/JVM-Synchronized/JVM-Lock/markword_state.jpg\" alt=\"你想输入的替代文字\"></p>\n<h3 id=\"几种锁的类型\"><a href=\"#几种锁的类型\" class=\"headerlink\" title=\"几种锁的类型\"></a>几种锁的类型</h3><p><strong>线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。</strong><br>Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。<br><strong>锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。</strong></p>\n<h4 id=\"偏向锁\"><a href=\"#偏向锁\" class=\"headerlink\" title=\"偏向锁\"></a>偏向锁</h4><p>Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护。<br><img src=\"/2018/08/16/JVM-Synchronized/JVM-Lock/biased_lock_flow.jpg\" alt=\"你想输入的替代文字\"></p>\n<h5 id=\"偏向锁的进一步理解\"><a href=\"#偏向锁的进一步理解\" class=\"headerlink\" title=\"偏向锁的进一步理解\"></a>偏向锁的进一步理解</h5><p>偏向锁的释放不需要做任何事情，这也就意味着加过偏向锁的MarkValue会一直保留偏向锁的状态，因此即便同一个线程持续不断地加锁解锁，也是没有开销的。</p>\n<p>另一方面，偏向锁比轻量锁更容易被终结，轻量锁是在有锁竞争出现时升级为重量锁，而一般偏向锁是在有不同线程申请锁时升级为轻量锁，这也就意味着假如一个对象先被线程1加锁解锁，再被线程2加锁解锁，这过程中没有锁冲突，也一样会发生偏向锁失效，不同的是这回要先退化为无锁的状态，再加轻量锁，如图：</p>\n<p>另外，JVM对那种会有多线程加锁，但不存在锁竞争的情况也做了优化，听起来比较拗口，但在现实应用中确实是可能出现这种情况，因为线程之前除了互斥之外也可能发生同步关系，被同步的两个线程（一前一后）对共享对象锁的竞争很可能是没有冲突的。对这种情况，JVM用一个epoch表示一个偏向锁的时间戳（真实地生成一个时间戳代价还是蛮大的，因此这里应当理解为一种类似时间戳的identifier），对epoch，官方是这么解释的：</p>\n<h5 id=\"偏向锁的获取\"><a href=\"#偏向锁的获取\" class=\"headerlink\" title=\"偏向锁的获取\"></a>偏向锁的获取</h5><p>当一个线程访问同步块并获取锁时，<strong>会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁</strong>，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。</p>\n<h5 id=\"偏向锁的撤销\"><a href=\"#偏向锁的撤销\" class=\"headerlink\" title=\"偏向锁的撤销\"></a>偏向锁的撤销</h5><p><strong>偏向锁使用了一种等到竞争出现才释放锁的机制</strong>，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。</p>\n<h5 id=\"偏向锁的设置\"><a href=\"#偏向锁的设置\" class=\"headerlink\" title=\"偏向锁的设置\"></a>偏向锁的设置</h5><p>关闭偏向锁：偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。</p>\n<h4 id=\"自旋锁\"><a href=\"#自旋锁\" class=\"headerlink\" title=\"自旋锁\"></a>自旋锁</h4><p>线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。同时我们可以发现，很多对象锁的锁定状态只会持续很短的一段时间，例如整数的自加操作，在很短的时间内阻塞并唤醒线程显然不值得，为此引入了自旋锁。<br>所谓“自旋”，就是让线程去执行一个无意义的循环，循环结束后再去重新竞争锁，如果竞争不到继续循环，循环过程中线程会一直处于running状态，但是基于JVM的线程调度，会出让时间片，所以其他线程依旧有申请锁和释放锁的机会。<br>自旋锁省去了阻塞锁的时间空间（队列的维护等）开销，但是长时间自旋就变成了“忙式等待”，忙式等待显然还不如阻塞锁。所以自旋的次数一般控制在一个范围内，例如10,100等，在超出这个范围后，自旋锁会升级为阻塞锁。<br>对自旋锁周期的选择上，HotSpot认为最佳时间应是一个线程上下文切换的时间，但目前并没有做到。经过调查，目前只是通过汇编暂停了几个CPU周期，除了自旋周期选择，HotSpot还进行许多其他的自旋优化策略，具体如下：<br>如果平均负载小于CPUs则一直自旋<br>如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞<br>如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞 如果CPU处于节电模式则停止自旋<br>自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差）</p>\n<h4 id=\"轻量级锁\"><a href=\"#轻量级锁\" class=\"headerlink\" title=\"轻量级锁\"></a>轻量级锁</h4><h5 id=\"轻量级锁加锁\"><a href=\"#轻量级锁加锁\" class=\"headerlink\" title=\"轻量级锁加锁\"></a>轻量级锁加锁</h5><p>线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。<strong>然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，则自旋获取锁，当自旋获取锁仍然失败时，表示存在其他线程竞争锁(两条或两条以上的线程竞争同一个锁)，则轻量级锁会膨胀成重量级锁。</strong></p>\n<h5 id=\"轻量级锁解锁\"><a href=\"#轻量级锁解锁\" class=\"headerlink\" title=\"轻量级锁解锁\"></a>轻量级锁解锁</h5><p><strong>轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示同步过程已完成。</strong>如果失败，表示有其他线程尝试过获取该锁，则要在释放锁的同时唤醒被挂起的线程。下图是两个线程同时争夺锁，导致锁膨胀的流程图。</p>\n<p><img src=\"/2018/08/16/JVM-Synchronized/JVM-Lock/light_lock_flow.jpg\" alt=\"你想输入的替代文字\"></p>\n<h3 id=\"锁的优缺点总结\"><a href=\"#锁的优缺点总结\" class=\"headerlink\" title=\"锁的优缺点总结\"></a>锁的优缺点总结</h3><table>\n<thead>\n<tr>\n<th>锁</th>\n<th align=\"center\">优点</th>\n<th align=\"left\">缺点</th>\n<th align=\"left\">适用场景</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>偏向锁</td>\n<td align=\"center\">加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距</td>\n<td align=\"left\">如果线程间存在锁竞争，会带来额外的锁撤销的消耗</td>\n<td align=\"left\">适用于只有一个线程访问同步块场景</td>\n</tr>\n<tr>\n<td>轻量级锁</td>\n<td align=\"center\">竞争的线程不会阻塞，提高了程序的响应速度</td>\n<td align=\"left\">如果始终得不到锁竞争的线程使用自旋会消耗CPU</td>\n<td align=\"left\">追求响应时间,锁占用时间很短</td>\n</tr>\n<tr>\n<td>重量级锁</td>\n<td align=\"center\">线程竞争不使用自旋，不会消耗CPU</td>\n<td align=\"left\">线程阻塞，响应时间缓慢</td>\n<td align=\"left\">追求吞吐量,锁占用时间较长</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>内容参考：<a href=\"http://luojinping.com/2015/07/09/java%E9%94%81%E4%BC%98%E5%8C%96/\" target=\"_blank\" rel=\"noopener\">http://luojinping.com/2015/07/09/java%E9%94%81%E4%BC%98%E5%8C%96/</a></p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"死磕系列\"><a href=\"#死磕系列\" class=\"headerlink\" title=\"死磕系列\"></a>死磕系列</h3><p><a href=\"http://cmsblogs.com/?p=2071\" target=\"_blank\" rel=\"noopener\">http://cmsblogs.com/?p=2071</a></p>\n<p>理解Synchronized的关键，在于真正去理解什么是多线程的对于临界区的竞争。</p>\n<ol>\n<li>多个线程访问一个临界区，只要它们进来的时候是有先有后的（串行），这个就不是竞争关系。</li>\n</ol>\n<p>FAQ:<br>我有个问题。<br>HotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。</p>\n<ol>\n<li><p>一个线程获取到锁，别的线程不就是处于竞争锁的状态吗，为什么文中说”大多数情况下，不存在多线程竞争”？</p>\n</li>\n<li><p>“总是由同一线程多次获得”，线程执行完不就销毁吗，为什么还多次获得?</p>\n</li>\n<li><p>一个线程获取到锁并不意味着别的线程处于竞争锁的状态，只要它们轮流进入critical section没有重叠互不干扰，那就不存在竞争，这在critical section比较短小的情况下是极可能的。</p>\n</li>\n<li><p>“总是由同一线程获得”是指一个线程执行过程中先后多次访问了被synchronized保护的代码段，这时偏向锁就发挥作用了，因为同一线程进入自己把持的偏向锁不需要CAS，而且出来时也并不主动释放锁，所以开销很小。</p>\n</li>\n</ol>\n<p><a href=\"https://www.jianshu.com/p/36eedeb3f912\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/36eedeb3f912</a></p>\n<p>FAQ</p>\n<h2 id=\"在JDK没有优化synchronized之前，它到底在性能上有什么问题？\"><a href=\"#在JDK没有优化synchronized之前，它到底在性能上有什么问题？\" class=\"headerlink\" title=\"在JDK没有优化synchronized之前，它到底在性能上有什么问题？\"></a>在JDK没有优化synchronized之前，它到底在性能上有什么问题？</h2><p>在没有优化之前，synchronized几乎等同于操作系统的mutex。如果一个线程获取了临界资源，那么其它的线程将会被阻塞，如果要唤醒，要需要从内核态进行唤醒。</p>\n<h3 id=\"同步的原理\"><a href=\"#同步的原理\" class=\"headerlink\" title=\"同步的原理\"></a>同步的原理</h3><p>JVM规范规定JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处， JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个 monitor 与之关联，当且一个monitor 被持有后，它将处于锁定状态。线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 的所有权，即尝试获得对象的锁。</p>\n<h3 id=\"Java对象头\"><a href=\"#Java对象头\" class=\"headerlink\" title=\"Java对象头\"></a>Java对象头</h3><p>锁存在Java对象头里。如果对象是数组类型，则虚拟机用3个Word（字宽）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，一字宽等于四字节，即32bit。</p>\n<table>\n<thead>\n<tr>\n<th>长度</th>\n<th align=\"center\">内容</th>\n<th align=\"left\">说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>32/64bit</td>\n<td align=\"center\">Mark Word</td>\n<td align=\"left\">存储对象的hashCode或锁信息等</td>\n</tr>\n<tr>\n<td>32/64bit</td>\n<td align=\"center\">Class Metadata Address</td>\n<td align=\"left\">存储到对象类型数据的指针</td>\n</tr>\n<tr>\n<td>32/64bit</td>\n<td align=\"center\">Array length</td>\n<td align=\"left\">数组的长度（如果当前对象是数组）</td>\n</tr>\n</tbody></table>\n<p>Java对象头里的Mark Word里默认存储对象的HashCode，分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如下：</p>\n<p>25 bit    4bit    1bit<br>是否是偏向锁    2bit<br>锁标志位<br>无锁状态    对象的hashCode    对象分代年龄    0    01</p>\n<p>在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据：<br><img src=\"/2018/08/16/JVM-Synchronized/JVM-Lock/markword_state.jpg\" alt=\"你想输入的替代文字\"></p>\n<h3 id=\"几种锁的类型\"><a href=\"#几种锁的类型\" class=\"headerlink\" title=\"几种锁的类型\"></a>几种锁的类型</h3><p><strong>线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。</strong><br>Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。<br><strong>锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。</strong></p>\n<h4 id=\"偏向锁\"><a href=\"#偏向锁\" class=\"headerlink\" title=\"偏向锁\"></a>偏向锁</h4><p>Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护。<br><img src=\"/2018/08/16/JVM-Synchronized/JVM-Lock/biased_lock_flow.jpg\" alt=\"你想输入的替代文字\"></p>\n<h5 id=\"偏向锁的进一步理解\"><a href=\"#偏向锁的进一步理解\" class=\"headerlink\" title=\"偏向锁的进一步理解\"></a>偏向锁的进一步理解</h5><p>偏向锁的释放不需要做任何事情，这也就意味着加过偏向锁的MarkValue会一直保留偏向锁的状态，因此即便同一个线程持续不断地加锁解锁，也是没有开销的。</p>\n<p>另一方面，偏向锁比轻量锁更容易被终结，轻量锁是在有锁竞争出现时升级为重量锁，而一般偏向锁是在有不同线程申请锁时升级为轻量锁，这也就意味着假如一个对象先被线程1加锁解锁，再被线程2加锁解锁，这过程中没有锁冲突，也一样会发生偏向锁失效，不同的是这回要先退化为无锁的状态，再加轻量锁，如图：</p>\n<p>另外，JVM对那种会有多线程加锁，但不存在锁竞争的情况也做了优化，听起来比较拗口，但在现实应用中确实是可能出现这种情况，因为线程之前除了互斥之外也可能发生同步关系，被同步的两个线程（一前一后）对共享对象锁的竞争很可能是没有冲突的。对这种情况，JVM用一个epoch表示一个偏向锁的时间戳（真实地生成一个时间戳代价还是蛮大的，因此这里应当理解为一种类似时间戳的identifier），对epoch，官方是这么解释的：</p>\n<h5 id=\"偏向锁的获取\"><a href=\"#偏向锁的获取\" class=\"headerlink\" title=\"偏向锁的获取\"></a>偏向锁的获取</h5><p>当一个线程访问同步块并获取锁时，<strong>会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁</strong>，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。</p>\n<h5 id=\"偏向锁的撤销\"><a href=\"#偏向锁的撤销\" class=\"headerlink\" title=\"偏向锁的撤销\"></a>偏向锁的撤销</h5><p><strong>偏向锁使用了一种等到竞争出现才释放锁的机制</strong>，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。</p>\n<h5 id=\"偏向锁的设置\"><a href=\"#偏向锁的设置\" class=\"headerlink\" title=\"偏向锁的设置\"></a>偏向锁的设置</h5><p>关闭偏向锁：偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。</p>\n<h4 id=\"自旋锁\"><a href=\"#自旋锁\" class=\"headerlink\" title=\"自旋锁\"></a>自旋锁</h4><p>线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。同时我们可以发现，很多对象锁的锁定状态只会持续很短的一段时间，例如整数的自加操作，在很短的时间内阻塞并唤醒线程显然不值得，为此引入了自旋锁。<br>所谓“自旋”，就是让线程去执行一个无意义的循环，循环结束后再去重新竞争锁，如果竞争不到继续循环，循环过程中线程会一直处于running状态，但是基于JVM的线程调度，会出让时间片，所以其他线程依旧有申请锁和释放锁的机会。<br>自旋锁省去了阻塞锁的时间空间（队列的维护等）开销，但是长时间自旋就变成了“忙式等待”，忙式等待显然还不如阻塞锁。所以自旋的次数一般控制在一个范围内，例如10,100等，在超出这个范围后，自旋锁会升级为阻塞锁。<br>对自旋锁周期的选择上，HotSpot认为最佳时间应是一个线程上下文切换的时间，但目前并没有做到。经过调查，目前只是通过汇编暂停了几个CPU周期，除了自旋周期选择，HotSpot还进行许多其他的自旋优化策略，具体如下：<br>如果平均负载小于CPUs则一直自旋<br>如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞<br>如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞 如果CPU处于节电模式则停止自旋<br>自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差）</p>\n<h4 id=\"轻量级锁\"><a href=\"#轻量级锁\" class=\"headerlink\" title=\"轻量级锁\"></a>轻量级锁</h4><h5 id=\"轻量级锁加锁\"><a href=\"#轻量级锁加锁\" class=\"headerlink\" title=\"轻量级锁加锁\"></a>轻量级锁加锁</h5><p>线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。<strong>然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，则自旋获取锁，当自旋获取锁仍然失败时，表示存在其他线程竞争锁(两条或两条以上的线程竞争同一个锁)，则轻量级锁会膨胀成重量级锁。</strong></p>\n<h5 id=\"轻量级锁解锁\"><a href=\"#轻量级锁解锁\" class=\"headerlink\" title=\"轻量级锁解锁\"></a>轻量级锁解锁</h5><p><strong>轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示同步过程已完成。</strong>如果失败，表示有其他线程尝试过获取该锁，则要在释放锁的同时唤醒被挂起的线程。下图是两个线程同时争夺锁，导致锁膨胀的流程图。</p>\n<p><img src=\"/2018/08/16/JVM-Synchronized/JVM-Lock/light_lock_flow.jpg\" alt=\"你想输入的替代文字\"></p>\n<h3 id=\"锁的优缺点总结\"><a href=\"#锁的优缺点总结\" class=\"headerlink\" title=\"锁的优缺点总结\"></a>锁的优缺点总结</h3><table>\n<thead>\n<tr>\n<th>锁</th>\n<th align=\"center\">优点</th>\n<th align=\"left\">缺点</th>\n<th align=\"left\">适用场景</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>偏向锁</td>\n<td align=\"center\">加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距</td>\n<td align=\"left\">如果线程间存在锁竞争，会带来额外的锁撤销的消耗</td>\n<td align=\"left\">适用于只有一个线程访问同步块场景</td>\n</tr>\n<tr>\n<td>轻量级锁</td>\n<td align=\"center\">竞争的线程不会阻塞，提高了程序的响应速度</td>\n<td align=\"left\">如果始终得不到锁竞争的线程使用自旋会消耗CPU</td>\n<td align=\"left\">追求响应时间,锁占用时间很短</td>\n</tr>\n<tr>\n<td>重量级锁</td>\n<td align=\"center\">线程竞争不使用自旋，不会消耗CPU</td>\n<td align=\"left\">线程阻塞，响应时间缓慢</td>\n<td align=\"left\">追求吞吐量,锁占用时间较长</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>内容参考：<a href=\"http://luojinping.com/2015/07/09/java%E9%94%81%E4%BC%98%E5%8C%96/\" target=\"_blank\" rel=\"noopener\">http://luojinping.com/2015/07/09/java%E9%94%81%E4%BC%98%E5%8C%96/</a></p>\n</blockquote>\n"},{"title":"JVM-Valotile","date":"2018-11-20T12:36:21.000Z","_content":"\n### 示例代码\nhttps://www.cnblogs.com/chenyangyao/p/5269622.html\n\n### Volatile的两层语义\n\n### Volatile能不能实现原子性？\n看说的是什么原子性，如果是Access atomicity，那时可以的。如果是++的原子性，那时不行的。\n\n\n### 多线程程序产生顺序问题的原因\n1. CPU执行指令是Pipeline形式执行的，而不是一条条执行。在Pipeline模式下执行，任意一条指令的生效时间是不一样的\n2. 指令自身的优化，在单线程中没有前后依赖的变量读写，可以进行重排序优化。读操作往下优化，写错话往上优化。\n3. CacheLine\n\n\n\nhttps://www.jianshu.com/p/ef8de88b1343\n\n\n### importjava 深度文章\nhttp://www.importnew.com/29860.html\nJMM内存模型\n在上面描述中可以看到硬件为我们提供了很多的额外指令来保证程序的正确性。但是也带来了复杂性。JMM为了方便我们理解和使用，提供了一些抽象概念的内存屏障。注意，下文开始讨论的内存屏障都是指的是JMM的抽象内存屏障，它并不代表实际的cpu操作指令，而是代表一种效果。\n\nLoadLoad Barriers\n该屏障保证了在屏障前的读取操作效果先于屏障后的读取操作效果发生。在各个不同平台上会插入的编译指令不相同，可能的一种做法是插入也被称之为smp_rmb指令，强制处理完成当前的invalidate queue中的内容\nStoreStore Barriers\n该屏障保证了在屏障前的写操作效果先于屏障后的写操作效果发生。可能的做法是使用smp_wmb指令，而且是使用该指令中，将后续写入数据先写入到store buffer的那种处理方式。因为这种方式消耗比较小\nLoadStore Barriers\n该屏障保证了屏障前的读操作效果先于屏障后的写操作效果发生。\nStoreLoad Barriers\n该屏障保证了屏障前的写操作效果先于屏障后的读操作效果发生。该屏障兼具上面三者的功能，是开销最大的一种屏障。可能的做法就是插入一个smp_mb指令来完成。\n\n内存屏障在volatile关键中的使用\n内存屏障在很多地方使用，这里主要说下对于volatile关键字，内存屏障的使用方式。\n\n在每个volatile写操作的前面插入一个StoreStore屏障。\n在每个volatile写操作的后面插入一个StoreLoad屏障。\n在每个volatile读操作的后面插入一个LoadLoad屏障。\n在每个volatile读操作的后面插入一个LoadStore屏障。\n上面的内存屏障方式主要是规定了在处理器级别的一些重排序要求。而JMM本身，对于volatile变量在编译器级别的重排序也制定了相关的规则。可以用下面的图来表示\n\nhttps://www.cnblogs.com/yzwall/p/6661528.html\n\n\n```\nprivate volatile int handlerState = INIT;\n\n\n/**\n     * Makes best possible effort to detect if {@link ChannelHandler#handlerAdded(ChannelHandlerContext)} was called\n     * yet. If not return {@code false} and if called or could not detect return {@code true}.\n     *\n     * If this method returns {@code true} we will not invoke the {@link ChannelHandler} but just forward the event.\n     * This is needed as {@link DefaultChannelPipeline} may already put the {@link ChannelHandler} in the linked-list\n     * but not called {@link ChannelHandler#handlerAdded(ChannelHandlerContext)}.\n     */\n    private boolean invokeHandler() {\n        // Store in local variable to reduce volatile reads.\n        int handlerState = this.handlerState;\n        return handlerState == ADD_COMPLETE || (!ordered && handlerState == ADD_PENDING);\n    }\n```","source":"_posts/JVM-Valotile.md","raw":"---\ntitle: JVM-Valotile\ndate: 2018-11-20 20:36:21\ntags: JVM\n---\n\n### 示例代码\nhttps://www.cnblogs.com/chenyangyao/p/5269622.html\n\n### Volatile的两层语义\n\n### Volatile能不能实现原子性？\n看说的是什么原子性，如果是Access atomicity，那时可以的。如果是++的原子性，那时不行的。\n\n\n### 多线程程序产生顺序问题的原因\n1. CPU执行指令是Pipeline形式执行的，而不是一条条执行。在Pipeline模式下执行，任意一条指令的生效时间是不一样的\n2. 指令自身的优化，在单线程中没有前后依赖的变量读写，可以进行重排序优化。读操作往下优化，写错话往上优化。\n3. CacheLine\n\n\n\nhttps://www.jianshu.com/p/ef8de88b1343\n\n\n### importjava 深度文章\nhttp://www.importnew.com/29860.html\nJMM内存模型\n在上面描述中可以看到硬件为我们提供了很多的额外指令来保证程序的正确性。但是也带来了复杂性。JMM为了方便我们理解和使用，提供了一些抽象概念的内存屏障。注意，下文开始讨论的内存屏障都是指的是JMM的抽象内存屏障，它并不代表实际的cpu操作指令，而是代表一种效果。\n\nLoadLoad Barriers\n该屏障保证了在屏障前的读取操作效果先于屏障后的读取操作效果发生。在各个不同平台上会插入的编译指令不相同，可能的一种做法是插入也被称之为smp_rmb指令，强制处理完成当前的invalidate queue中的内容\nStoreStore Barriers\n该屏障保证了在屏障前的写操作效果先于屏障后的写操作效果发生。可能的做法是使用smp_wmb指令，而且是使用该指令中，将后续写入数据先写入到store buffer的那种处理方式。因为这种方式消耗比较小\nLoadStore Barriers\n该屏障保证了屏障前的读操作效果先于屏障后的写操作效果发生。\nStoreLoad Barriers\n该屏障保证了屏障前的写操作效果先于屏障后的读操作效果发生。该屏障兼具上面三者的功能，是开销最大的一种屏障。可能的做法就是插入一个smp_mb指令来完成。\n\n内存屏障在volatile关键中的使用\n内存屏障在很多地方使用，这里主要说下对于volatile关键字，内存屏障的使用方式。\n\n在每个volatile写操作的前面插入一个StoreStore屏障。\n在每个volatile写操作的后面插入一个StoreLoad屏障。\n在每个volatile读操作的后面插入一个LoadLoad屏障。\n在每个volatile读操作的后面插入一个LoadStore屏障。\n上面的内存屏障方式主要是规定了在处理器级别的一些重排序要求。而JMM本身，对于volatile变量在编译器级别的重排序也制定了相关的规则。可以用下面的图来表示\n\nhttps://www.cnblogs.com/yzwall/p/6661528.html\n\n\n```\nprivate volatile int handlerState = INIT;\n\n\n/**\n     * Makes best possible effort to detect if {@link ChannelHandler#handlerAdded(ChannelHandlerContext)} was called\n     * yet. If not return {@code false} and if called or could not detect return {@code true}.\n     *\n     * If this method returns {@code true} we will not invoke the {@link ChannelHandler} but just forward the event.\n     * This is needed as {@link DefaultChannelPipeline} may already put the {@link ChannelHandler} in the linked-list\n     * but not called {@link ChannelHandler#handlerAdded(ChannelHandlerContext)}.\n     */\n    private boolean invokeHandler() {\n        // Store in local variable to reduce volatile reads.\n        int handlerState = this.handlerState;\n        return handlerState == ADD_COMPLETE || (!ordered && handlerState == ADD_PENDING);\n    }\n```","slug":"JVM-Valotile","published":1,"updated":"2019-11-28T12:36:54.160Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83i002jv1npr5frk354","content":"<h3 id=\"示例代码\"><a href=\"#示例代码\" class=\"headerlink\" title=\"示例代码\"></a>示例代码</h3><p><a href=\"https://www.cnblogs.com/chenyangyao/p/5269622.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/chenyangyao/p/5269622.html</a></p>\n<h3 id=\"Volatile的两层语义\"><a href=\"#Volatile的两层语义\" class=\"headerlink\" title=\"Volatile的两层语义\"></a>Volatile的两层语义</h3><h3 id=\"Volatile能不能实现原子性？\"><a href=\"#Volatile能不能实现原子性？\" class=\"headerlink\" title=\"Volatile能不能实现原子性？\"></a>Volatile能不能实现原子性？</h3><p>看说的是什么原子性，如果是Access atomicity，那时可以的。如果是++的原子性，那时不行的。</p>\n<h3 id=\"多线程程序产生顺序问题的原因\"><a href=\"#多线程程序产生顺序问题的原因\" class=\"headerlink\" title=\"多线程程序产生顺序问题的原因\"></a>多线程程序产生顺序问题的原因</h3><ol>\n<li>CPU执行指令是Pipeline形式执行的，而不是一条条执行。在Pipeline模式下执行，任意一条指令的生效时间是不一样的</li>\n<li>指令自身的优化，在单线程中没有前后依赖的变量读写，可以进行重排序优化。读操作往下优化，写错话往上优化。</li>\n<li>CacheLine</li>\n</ol>\n<p><a href=\"https://www.jianshu.com/p/ef8de88b1343\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/ef8de88b1343</a></p>\n<h3 id=\"importjava-深度文章\"><a href=\"#importjava-深度文章\" class=\"headerlink\" title=\"importjava 深度文章\"></a>importjava 深度文章</h3><p><a href=\"http://www.importnew.com/29860.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/29860.html</a><br>JMM内存模型<br>在上面描述中可以看到硬件为我们提供了很多的额外指令来保证程序的正确性。但是也带来了复杂性。JMM为了方便我们理解和使用，提供了一些抽象概念的内存屏障。注意，下文开始讨论的内存屏障都是指的是JMM的抽象内存屏障，它并不代表实际的cpu操作指令，而是代表一种效果。</p>\n<p>LoadLoad Barriers<br>该屏障保证了在屏障前的读取操作效果先于屏障后的读取操作效果发生。在各个不同平台上会插入的编译指令不相同，可能的一种做法是插入也被称之为smp_rmb指令，强制处理完成当前的invalidate queue中的内容<br>StoreStore Barriers<br>该屏障保证了在屏障前的写操作效果先于屏障后的写操作效果发生。可能的做法是使用smp_wmb指令，而且是使用该指令中，将后续写入数据先写入到store buffer的那种处理方式。因为这种方式消耗比较小<br>LoadStore Barriers<br>该屏障保证了屏障前的读操作效果先于屏障后的写操作效果发生。<br>StoreLoad Barriers<br>该屏障保证了屏障前的写操作效果先于屏障后的读操作效果发生。该屏障兼具上面三者的功能，是开销最大的一种屏障。可能的做法就是插入一个smp_mb指令来完成。</p>\n<p>内存屏障在volatile关键中的使用<br>内存屏障在很多地方使用，这里主要说下对于volatile关键字，内存屏障的使用方式。</p>\n<p>在每个volatile写操作的前面插入一个StoreStore屏障。<br>在每个volatile写操作的后面插入一个StoreLoad屏障。<br>在每个volatile读操作的后面插入一个LoadLoad屏障。<br>在每个volatile读操作的后面插入一个LoadStore屏障。<br>上面的内存屏障方式主要是规定了在处理器级别的一些重排序要求。而JMM本身，对于volatile变量在编译器级别的重排序也制定了相关的规则。可以用下面的图来表示</p>\n<p><a href=\"https://www.cnblogs.com/yzwall/p/6661528.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/yzwall/p/6661528.html</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private volatile int handlerState = INIT;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">/**</span><br><span class=\"line\">     * Makes best possible effort to detect if &#123;@link ChannelHandler#handlerAdded(ChannelHandlerContext)&#125; was called</span><br><span class=\"line\">     * yet. If not return &#123;@code false&#125; and if called or could not detect return &#123;@code true&#125;.</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * If this method returns &#123;@code true&#125; we will not invoke the &#123;@link ChannelHandler&#125; but just forward the event.</span><br><span class=\"line\">     * This is needed as &#123;@link DefaultChannelPipeline&#125; may already put the &#123;@link ChannelHandler&#125; in the linked-list</span><br><span class=\"line\">     * but not called &#123;@link ChannelHandler#handlerAdded(ChannelHandlerContext)&#125;.</span><br><span class=\"line\">     */</span><br><span class=\"line\">    private boolean invokeHandler() &#123;</span><br><span class=\"line\">        // Store in local variable to reduce volatile reads.</span><br><span class=\"line\">        int handlerState = this.handlerState;</span><br><span class=\"line\">        return handlerState == ADD_COMPLETE || (!ordered &amp;&amp; handlerState == ADD_PENDING);</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"示例代码\"><a href=\"#示例代码\" class=\"headerlink\" title=\"示例代码\"></a>示例代码</h3><p><a href=\"https://www.cnblogs.com/chenyangyao/p/5269622.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/chenyangyao/p/5269622.html</a></p>\n<h3 id=\"Volatile的两层语义\"><a href=\"#Volatile的两层语义\" class=\"headerlink\" title=\"Volatile的两层语义\"></a>Volatile的两层语义</h3><h3 id=\"Volatile能不能实现原子性？\"><a href=\"#Volatile能不能实现原子性？\" class=\"headerlink\" title=\"Volatile能不能实现原子性？\"></a>Volatile能不能实现原子性？</h3><p>看说的是什么原子性，如果是Access atomicity，那时可以的。如果是++的原子性，那时不行的。</p>\n<h3 id=\"多线程程序产生顺序问题的原因\"><a href=\"#多线程程序产生顺序问题的原因\" class=\"headerlink\" title=\"多线程程序产生顺序问题的原因\"></a>多线程程序产生顺序问题的原因</h3><ol>\n<li>CPU执行指令是Pipeline形式执行的，而不是一条条执行。在Pipeline模式下执行，任意一条指令的生效时间是不一样的</li>\n<li>指令自身的优化，在单线程中没有前后依赖的变量读写，可以进行重排序优化。读操作往下优化，写错话往上优化。</li>\n<li>CacheLine</li>\n</ol>\n<p><a href=\"https://www.jianshu.com/p/ef8de88b1343\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/ef8de88b1343</a></p>\n<h3 id=\"importjava-深度文章\"><a href=\"#importjava-深度文章\" class=\"headerlink\" title=\"importjava 深度文章\"></a>importjava 深度文章</h3><p><a href=\"http://www.importnew.com/29860.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/29860.html</a><br>JMM内存模型<br>在上面描述中可以看到硬件为我们提供了很多的额外指令来保证程序的正确性。但是也带来了复杂性。JMM为了方便我们理解和使用，提供了一些抽象概念的内存屏障。注意，下文开始讨论的内存屏障都是指的是JMM的抽象内存屏障，它并不代表实际的cpu操作指令，而是代表一种效果。</p>\n<p>LoadLoad Barriers<br>该屏障保证了在屏障前的读取操作效果先于屏障后的读取操作效果发生。在各个不同平台上会插入的编译指令不相同，可能的一种做法是插入也被称之为smp_rmb指令，强制处理完成当前的invalidate queue中的内容<br>StoreStore Barriers<br>该屏障保证了在屏障前的写操作效果先于屏障后的写操作效果发生。可能的做法是使用smp_wmb指令，而且是使用该指令中，将后续写入数据先写入到store buffer的那种处理方式。因为这种方式消耗比较小<br>LoadStore Barriers<br>该屏障保证了屏障前的读操作效果先于屏障后的写操作效果发生。<br>StoreLoad Barriers<br>该屏障保证了屏障前的写操作效果先于屏障后的读操作效果发生。该屏障兼具上面三者的功能，是开销最大的一种屏障。可能的做法就是插入一个smp_mb指令来完成。</p>\n<p>内存屏障在volatile关键中的使用<br>内存屏障在很多地方使用，这里主要说下对于volatile关键字，内存屏障的使用方式。</p>\n<p>在每个volatile写操作的前面插入一个StoreStore屏障。<br>在每个volatile写操作的后面插入一个StoreLoad屏障。<br>在每个volatile读操作的后面插入一个LoadLoad屏障。<br>在每个volatile读操作的后面插入一个LoadStore屏障。<br>上面的内存屏障方式主要是规定了在处理器级别的一些重排序要求。而JMM本身，对于volatile变量在编译器级别的重排序也制定了相关的规则。可以用下面的图来表示</p>\n<p><a href=\"https://www.cnblogs.com/yzwall/p/6661528.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/yzwall/p/6661528.html</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private volatile int handlerState = INIT;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">/**</span><br><span class=\"line\">     * Makes best possible effort to detect if &#123;@link ChannelHandler#handlerAdded(ChannelHandlerContext)&#125; was called</span><br><span class=\"line\">     * yet. If not return &#123;@code false&#125; and if called or could not detect return &#123;@code true&#125;.</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * If this method returns &#123;@code true&#125; we will not invoke the &#123;@link ChannelHandler&#125; but just forward the event.</span><br><span class=\"line\">     * This is needed as &#123;@link DefaultChannelPipeline&#125; may already put the &#123;@link ChannelHandler&#125; in the linked-list</span><br><span class=\"line\">     * but not called &#123;@link ChannelHandler#handlerAdded(ChannelHandlerContext)&#125;.</span><br><span class=\"line\">     */</span><br><span class=\"line\">    private boolean invokeHandler() &#123;</span><br><span class=\"line\">        // Store in local variable to reduce volatile reads.</span><br><span class=\"line\">        int handlerState = this.handlerState;</span><br><span class=\"line\">        return handlerState == ADD_COMPLETE || (!ordered &amp;&amp; handlerState == ADD_PENDING);</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>"},{"title":"Kafka-Blogs","date":"2019-08-30T12:44:18.000Z","_content":"\n\nhttps://blog.csdn.net/lizhitao/article/details/39499283","source":"_posts/Kafka-Blogs.md","raw":"---\ntitle: Kafka-Blogs\ndate: 2019-08-30 20:44:18\ntags: Kafka\n---\n\n\nhttps://blog.csdn.net/lizhitao/article/details/39499283","slug":"Kafka-Blogs","published":1,"updated":"2019-09-28T08:51:00.879Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83i002kv1npvub2yvzm","content":"<p><a href=\"https://blog.csdn.net/lizhitao/article/details/39499283\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lizhitao/article/details/39499283</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/lizhitao/article/details/39499283\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lizhitao/article/details/39499283</a></p>\n"},{"title":"JVM——线程中断","date":"2017-11-09T12:36:45.000Z","_content":"\n\nhttp://luojinping.com/2015/04/13/Java%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD/","source":"_posts/JVM-Thread-interupt.md","raw":"---\ntitle: JVM——线程中断\ndate: 2017-11-09 20:36:45\ntags: JVM\n---\n\n\nhttp://luojinping.com/2015/04/13/Java%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD/","slug":"JVM-Thread-interupt","published":1,"updated":"2019-09-28T08:51:00.878Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83j002lv1npbannn7hu","content":"<p><a href=\"http://luojinping.com/2015/04/13/Java%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD/\" target=\"_blank\" rel=\"noopener\">http://luojinping.com/2015/04/13/Java%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://luojinping.com/2015/04/13/Java%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD/\" target=\"_blank\" rel=\"noopener\">http://luojinping.com/2015/04/13/Java%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD/</a></p>\n"},{"title":"Kafka-Broker-Message-Producing","date":"2019-08-05T03:48:49.000Z","_content":"\n## 这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\n```\nprivate def analyzeAndValidateRecords(records: MemoryRecords, isFromClient: Boolean): LogAppendInfo = {\n    var shallowMessageCount = 0\n    var validBytesCount = 0\n    var firstOffset: Option[Long] = None\n    var lastOffset = -1L\n    var sourceCodec: CompressionCodec = NoCompressionCodec\n    var monotonic = true\n    var maxTimestamp = RecordBatch.NO_TIMESTAMP\n    var offsetOfMaxTimestamp = -1L\n    var readFirstMessage = false\n    var lastOffsetOfFirstBatch = -1L\n\n    for (batch <- records.batches.asScala) {\n      // we only validate V2 and higher to avoid potential compatibility issues with older clients\n      if (batch.magic >= RecordBatch.MAGIC_VALUE_V2 && isFromClient && batch.baseOffset != 0)\n        throw new InvalidRecordException(s\"The baseOffset of the record batch in the append to $topicPartition should \" +\n          s\"be 0, but it is ${batch.baseOffset}\")\n\n      // update the first offset if on the first message. For magic versions older than 2, we use the last offset\n      // to avoid the need to decompress the data (the last offset can be obtained directly from the wrapper message).\n      // For magic version 2, we can get the first offset directly from the batch header.\n      // When appending to the leader, we will update LogAppendInfo.baseOffset with the correct value. In the follower\n      // case, validation will be more lenient.\n      // Also indicate whether we have the accurate first offset or not\n      if (!readFirstMessage) {\n        if (batch.magic >= RecordBatch.MAGIC_VALUE_V2)\n          firstOffset = Some(batch.baseOffset)\n        lastOffsetOfFirstBatch = batch.lastOffset\n        readFirstMessage = true\n      }\n\n      // check that offsets are monotonically increasing\n      if (lastOffset >= batch.lastOffset)\n        monotonic = false\n\n      // update the last offset seen\n      lastOffset = batch.lastOffset\n\n      // Check if the message sizes are valid.\n      val batchSize = batch.sizeInBytes\n      if (batchSize > config.maxMessageSize) {\n        brokerTopicStats.topicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)\n        brokerTopicStats.allTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)\n        throw new RecordTooLargeException(s\"The record batch size in the append to $topicPartition is $batchSize bytes \" +\n          s\"which exceeds the maximum configured value of ${config.maxMessageSize}.\")\n      }\n\n      // check the validity of the message by checking CRC\n      batch.ensureValid()\n\n      if (batch.maxTimestamp > maxTimestamp) {\n        maxTimestamp = batch.maxTimestamp\n        offsetOfMaxTimestamp = lastOffset\n      }\n\n      shallowMessageCount += 1\n      validBytesCount += batchSize\n\n      val messageCodec = CompressionCodec.getCompressionCodec(batch.compressionType.id)\n      if (messageCodec != NoCompressionCodec)\n        sourceCodec = messageCodec\n    }\n\n    // Apply broker-side compression if any\n    val targetCodec = BrokerCompressionCodec.getTargetCompressionCodec(config.compressionType, sourceCodec)\n    LogAppendInfo(firstOffset, lastOffset, maxTimestamp, offsetOfMaxTimestamp, RecordBatch.NO_TIMESTAMP, logStartOffset,\n      RecordConversionStats.EMPTY, sourceCodec, targetCodec, shallowMessageCount, validBytesCount, monotonic, lastOffsetOfFirstBatch)\n  }\n```\n\n\n<init>(ByteBuffer):57, MemoryRecords (org.apache.kafka.common.record), MemoryRecords.java\nreadableRecords(ByteBuffer):425, MemoryRecords (org.apache.kafka.common.record), MemoryRecords.java\nread(ByteBuffer):561, Type$11 (org.apache.kafka.common.protocol.types), Type.java\nread(ByteBuffer):544, Type$11 (org.apache.kafka.common.protocol.types), Type.java\nread(ByteBuffer):106, Schema (org.apache.kafka.common.protocol.types), Schema.java\nread(ByteBuffer):27, Schema (org.apache.kafka.common.protocol.types), Schema.java\nread(ByteBuffer):78, ArrayOf (org.apache.kafka.common.protocol.types), ArrayOf.java\nread(ByteBuffer):106, Schema (org.apache.kafka.common.protocol.types), Schema.java\nread(ByteBuffer):27, Schema (org.apache.kafka.common.protocol.types), Schema.java\nread(ByteBuffer):78, ArrayOf (org.apache.kafka.common.protocol.types), ArrayOf.java\nread(ByteBuffer):106, Schema (org.apache.kafka.common.protocol.types), Schema.java\nparseRequest(short, ByteBuffer):297, ApiKeys (org.apache.kafka.common.protocol), ApiKeys.java\nparseRequest(ByteBuffer):63, RequestContext (org.apache.kafka.common.requests), RequestContext.java\n<init>(int, RequestContext, long, MemoryPool, ByteBuffer, RequestChannel$Metrics):89, RequestChannel$Request (kafka.network), RequestChannel.scala\n$anonfun$processCompletedReceives$1(Processor, NetworkReceive):891, Processor (kafka.network), SocketServer.scala\n$anonfun$processCompletedReceives$1$adapted(Processor, NetworkReceive):873, Processor (kafka.network), SocketServer.scala\napply(Object):-1, 214985191 (kafka.network.Processor$$Lambda$686), Unknown Source\nforeach(Function1):941, Iterator (scala.collection), Iterator.scala\nforeach$(Iterator, Function1):941, Iterator (scala.collection), Iterator.scala\nforeach(Function1):1429, AbstractIterator (scala.collection), Iterator.scala\nforeach(Function1):74, IterableLike (scala.collection), IterableLike.scala\nforeach$(IterableLike, Function1):73, IterableLike (scala.collection), IterableLike.scala\nforeach(Function1):56, AbstractIterable (scala.collection), Iterable.scala\nprocessCompletedReceives():873, Processor (kafka.network), SocketServer.scala\nrun():763, Processor (kafka.network), SocketServer.scala\nrun():748, Thread (java.lang), Thread.java","source":"_posts/Kafka-Broker-Message-Producing.md","raw":"---\ntitle: Kafka-Broker-Message-Producing\ndate: 2019-08-05 11:48:49\ntags: Kafka\n---\n\n## 这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\n```\nprivate def analyzeAndValidateRecords(records: MemoryRecords, isFromClient: Boolean): LogAppendInfo = {\n    var shallowMessageCount = 0\n    var validBytesCount = 0\n    var firstOffset: Option[Long] = None\n    var lastOffset = -1L\n    var sourceCodec: CompressionCodec = NoCompressionCodec\n    var monotonic = true\n    var maxTimestamp = RecordBatch.NO_TIMESTAMP\n    var offsetOfMaxTimestamp = -1L\n    var readFirstMessage = false\n    var lastOffsetOfFirstBatch = -1L\n\n    for (batch <- records.batches.asScala) {\n      // we only validate V2 and higher to avoid potential compatibility issues with older clients\n      if (batch.magic >= RecordBatch.MAGIC_VALUE_V2 && isFromClient && batch.baseOffset != 0)\n        throw new InvalidRecordException(s\"The baseOffset of the record batch in the append to $topicPartition should \" +\n          s\"be 0, but it is ${batch.baseOffset}\")\n\n      // update the first offset if on the first message. For magic versions older than 2, we use the last offset\n      // to avoid the need to decompress the data (the last offset can be obtained directly from the wrapper message).\n      // For magic version 2, we can get the first offset directly from the batch header.\n      // When appending to the leader, we will update LogAppendInfo.baseOffset with the correct value. In the follower\n      // case, validation will be more lenient.\n      // Also indicate whether we have the accurate first offset or not\n      if (!readFirstMessage) {\n        if (batch.magic >= RecordBatch.MAGIC_VALUE_V2)\n          firstOffset = Some(batch.baseOffset)\n        lastOffsetOfFirstBatch = batch.lastOffset\n        readFirstMessage = true\n      }\n\n      // check that offsets are monotonically increasing\n      if (lastOffset >= batch.lastOffset)\n        monotonic = false\n\n      // update the last offset seen\n      lastOffset = batch.lastOffset\n\n      // Check if the message sizes are valid.\n      val batchSize = batch.sizeInBytes\n      if (batchSize > config.maxMessageSize) {\n        brokerTopicStats.topicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)\n        brokerTopicStats.allTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)\n        throw new RecordTooLargeException(s\"The record batch size in the append to $topicPartition is $batchSize bytes \" +\n          s\"which exceeds the maximum configured value of ${config.maxMessageSize}.\")\n      }\n\n      // check the validity of the message by checking CRC\n      batch.ensureValid()\n\n      if (batch.maxTimestamp > maxTimestamp) {\n        maxTimestamp = batch.maxTimestamp\n        offsetOfMaxTimestamp = lastOffset\n      }\n\n      shallowMessageCount += 1\n      validBytesCount += batchSize\n\n      val messageCodec = CompressionCodec.getCompressionCodec(batch.compressionType.id)\n      if (messageCodec != NoCompressionCodec)\n        sourceCodec = messageCodec\n    }\n\n    // Apply broker-side compression if any\n    val targetCodec = BrokerCompressionCodec.getTargetCompressionCodec(config.compressionType, sourceCodec)\n    LogAppendInfo(firstOffset, lastOffset, maxTimestamp, offsetOfMaxTimestamp, RecordBatch.NO_TIMESTAMP, logStartOffset,\n      RecordConversionStats.EMPTY, sourceCodec, targetCodec, shallowMessageCount, validBytesCount, monotonic, lastOffsetOfFirstBatch)\n  }\n```\n\n\n<init>(ByteBuffer):57, MemoryRecords (org.apache.kafka.common.record), MemoryRecords.java\nreadableRecords(ByteBuffer):425, MemoryRecords (org.apache.kafka.common.record), MemoryRecords.java\nread(ByteBuffer):561, Type$11 (org.apache.kafka.common.protocol.types), Type.java\nread(ByteBuffer):544, Type$11 (org.apache.kafka.common.protocol.types), Type.java\nread(ByteBuffer):106, Schema (org.apache.kafka.common.protocol.types), Schema.java\nread(ByteBuffer):27, Schema (org.apache.kafka.common.protocol.types), Schema.java\nread(ByteBuffer):78, ArrayOf (org.apache.kafka.common.protocol.types), ArrayOf.java\nread(ByteBuffer):106, Schema (org.apache.kafka.common.protocol.types), Schema.java\nread(ByteBuffer):27, Schema (org.apache.kafka.common.protocol.types), Schema.java\nread(ByteBuffer):78, ArrayOf (org.apache.kafka.common.protocol.types), ArrayOf.java\nread(ByteBuffer):106, Schema (org.apache.kafka.common.protocol.types), Schema.java\nparseRequest(short, ByteBuffer):297, ApiKeys (org.apache.kafka.common.protocol), ApiKeys.java\nparseRequest(ByteBuffer):63, RequestContext (org.apache.kafka.common.requests), RequestContext.java\n<init>(int, RequestContext, long, MemoryPool, ByteBuffer, RequestChannel$Metrics):89, RequestChannel$Request (kafka.network), RequestChannel.scala\n$anonfun$processCompletedReceives$1(Processor, NetworkReceive):891, Processor (kafka.network), SocketServer.scala\n$anonfun$processCompletedReceives$1$adapted(Processor, NetworkReceive):873, Processor (kafka.network), SocketServer.scala\napply(Object):-1, 214985191 (kafka.network.Processor$$Lambda$686), Unknown Source\nforeach(Function1):941, Iterator (scala.collection), Iterator.scala\nforeach$(Iterator, Function1):941, Iterator (scala.collection), Iterator.scala\nforeach(Function1):1429, AbstractIterator (scala.collection), Iterator.scala\nforeach(Function1):74, IterableLike (scala.collection), IterableLike.scala\nforeach$(IterableLike, Function1):73, IterableLike (scala.collection), IterableLike.scala\nforeach(Function1):56, AbstractIterable (scala.collection), Iterable.scala\nprocessCompletedReceives():873, Processor (kafka.network), SocketServer.scala\nrun():763, Processor (kafka.network), SocketServer.scala\nrun():748, Thread (java.lang), Thread.java","slug":"Kafka-Broker-Message-Producing","published":1,"updated":"2019-09-28T08:51:00.879Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83k002mv1npl1hllwjp","content":"<h2 id=\"这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\"><a href=\"#这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\" class=\"headerlink\" title=\"这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\"></a>这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private def analyzeAndValidateRecords(records: MemoryRecords, isFromClient: Boolean): LogAppendInfo = &#123;</span><br><span class=\"line\">    var shallowMessageCount = 0</span><br><span class=\"line\">    var validBytesCount = 0</span><br><span class=\"line\">    var firstOffset: Option[Long] = None</span><br><span class=\"line\">    var lastOffset = -1L</span><br><span class=\"line\">    var sourceCodec: CompressionCodec = NoCompressionCodec</span><br><span class=\"line\">    var monotonic = true</span><br><span class=\"line\">    var maxTimestamp = RecordBatch.NO_TIMESTAMP</span><br><span class=\"line\">    var offsetOfMaxTimestamp = -1L</span><br><span class=\"line\">    var readFirstMessage = false</span><br><span class=\"line\">    var lastOffsetOfFirstBatch = -1L</span><br><span class=\"line\"></span><br><span class=\"line\">    for (batch &lt;- records.batches.asScala) &#123;</span><br><span class=\"line\">      // we only validate V2 and higher to avoid potential compatibility issues with older clients</span><br><span class=\"line\">      if (batch.magic &gt;= RecordBatch.MAGIC_VALUE_V2 &amp;&amp; isFromClient &amp;&amp; batch.baseOffset != 0)</span><br><span class=\"line\">        throw new InvalidRecordException(s&quot;The baseOffset of the record batch in the append to $topicPartition should &quot; +</span><br><span class=\"line\">          s&quot;be 0, but it is $&#123;batch.baseOffset&#125;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">      // update the first offset if on the first message. For magic versions older than 2, we use the last offset</span><br><span class=\"line\">      // to avoid the need to decompress the data (the last offset can be obtained directly from the wrapper message).</span><br><span class=\"line\">      // For magic version 2, we can get the first offset directly from the batch header.</span><br><span class=\"line\">      // When appending to the leader, we will update LogAppendInfo.baseOffset with the correct value. In the follower</span><br><span class=\"line\">      // case, validation will be more lenient.</span><br><span class=\"line\">      // Also indicate whether we have the accurate first offset or not</span><br><span class=\"line\">      if (!readFirstMessage) &#123;</span><br><span class=\"line\">        if (batch.magic &gt;= RecordBatch.MAGIC_VALUE_V2)</span><br><span class=\"line\">          firstOffset = Some(batch.baseOffset)</span><br><span class=\"line\">        lastOffsetOfFirstBatch = batch.lastOffset</span><br><span class=\"line\">        readFirstMessage = true</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      // check that offsets are monotonically increasing</span><br><span class=\"line\">      if (lastOffset &gt;= batch.lastOffset)</span><br><span class=\"line\">        monotonic = false</span><br><span class=\"line\"></span><br><span class=\"line\">      // update the last offset seen</span><br><span class=\"line\">      lastOffset = batch.lastOffset</span><br><span class=\"line\"></span><br><span class=\"line\">      // Check if the message sizes are valid.</span><br><span class=\"line\">      val batchSize = batch.sizeInBytes</span><br><span class=\"line\">      if (batchSize &gt; config.maxMessageSize) &#123;</span><br><span class=\"line\">        brokerTopicStats.topicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)</span><br><span class=\"line\">        brokerTopicStats.allTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)</span><br><span class=\"line\">        throw new RecordTooLargeException(s&quot;The record batch size in the append to $topicPartition is $batchSize bytes &quot; +</span><br><span class=\"line\">          s&quot;which exceeds the maximum configured value of $&#123;config.maxMessageSize&#125;.&quot;)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      // check the validity of the message by checking CRC</span><br><span class=\"line\">      batch.ensureValid()</span><br><span class=\"line\"></span><br><span class=\"line\">      if (batch.maxTimestamp &gt; maxTimestamp) &#123;</span><br><span class=\"line\">        maxTimestamp = batch.maxTimestamp</span><br><span class=\"line\">        offsetOfMaxTimestamp = lastOffset</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      shallowMessageCount += 1</span><br><span class=\"line\">      validBytesCount += batchSize</span><br><span class=\"line\"></span><br><span class=\"line\">      val messageCodec = CompressionCodec.getCompressionCodec(batch.compressionType.id)</span><br><span class=\"line\">      if (messageCodec != NoCompressionCodec)</span><br><span class=\"line\">        sourceCodec = messageCodec</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Apply broker-side compression if any</span><br><span class=\"line\">    val targetCodec = BrokerCompressionCodec.getTargetCompressionCodec(config.compressionType, sourceCodec)</span><br><span class=\"line\">    LogAppendInfo(firstOffset, lastOffset, maxTimestamp, offsetOfMaxTimestamp, RecordBatch.NO_TIMESTAMP, logStartOffset,</span><br><span class=\"line\">      RecordConversionStats.EMPTY, sourceCodec, targetCodec, shallowMessageCount, validBytesCount, monotonic, lastOffsetOfFirstBatch)</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<p><init>(ByteBuffer):57, MemoryRecords (org.apache.kafka.common.record), MemoryRecords.java<br>readableRecords(ByteBuffer):425, MemoryRecords (org.apache.kafka.common.record), MemoryRecords.java<br>read(ByteBuffer):561, Type$11 (org.apache.kafka.common.protocol.types), Type.java<br>read(ByteBuffer):544, Type$11 (org.apache.kafka.common.protocol.types), Type.java<br>read(ByteBuffer):106, Schema (org.apache.kafka.common.protocol.types), Schema.java<br>read(ByteBuffer):27, Schema (org.apache.kafka.common.protocol.types), Schema.java<br>read(ByteBuffer):78, ArrayOf (org.apache.kafka.common.protocol.types), ArrayOf.java<br>read(ByteBuffer):106, Schema (org.apache.kafka.common.protocol.types), Schema.java<br>read(ByteBuffer):27, Schema (org.apache.kafka.common.protocol.types), Schema.java<br>read(ByteBuffer):78, ArrayOf (org.apache.kafka.common.protocol.types), ArrayOf.java<br>read(ByteBuffer):106, Schema (org.apache.kafka.common.protocol.types), Schema.java<br>parseRequest(short, ByteBuffer):297, ApiKeys (org.apache.kafka.common.protocol), ApiKeys.java<br>parseRequest(ByteBuffer):63, RequestContext (org.apache.kafka.common.requests), RequestContext.java<br><init>(int, RequestContext, long, MemoryPool, ByteBuffer, RequestChannel$Metrics):89, RequestChannel$Request (kafka.network), RequestChannel.scala<br>$anonfun$processCompletedReceives$1(Processor, NetworkReceive):891, Processor (kafka.network), SocketServer.scala<br>$anonfun$processCompletedReceives$1$adapted(Processor, NetworkReceive):873, Processor (kafka.network), SocketServer.scala<br>apply(Object):-1, 214985191 (kafka.network.Processor$$Lambda$686), Unknown Source<br>foreach(Function1):941, Iterator (scala.collection), Iterator.scala<br>foreach$(Iterator, Function1):941, Iterator (scala.collection), Iterator.scala<br>foreach(Function1):1429, AbstractIterator (scala.collection), Iterator.scala<br>foreach(Function1):74, IterableLike (scala.collection), IterableLike.scala<br>foreach$(IterableLike, Function1):73, IterableLike (scala.collection), IterableLike.scala<br>foreach(Function1):56, AbstractIterable (scala.collection), Iterable.scala<br>processCompletedReceives():873, Processor (kafka.network), SocketServer.scala<br>run():763, Processor (kafka.network), SocketServer.scala<br>run():748, Thread (java.lang), Thread.java</init></init></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\"><a href=\"#这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\" class=\"headerlink\" title=\"这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\"></a>这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private def analyzeAndValidateRecords(records: MemoryRecords, isFromClient: Boolean): LogAppendInfo = &#123;</span><br><span class=\"line\">    var shallowMessageCount = 0</span><br><span class=\"line\">    var validBytesCount = 0</span><br><span class=\"line\">    var firstOffset: Option[Long] = None</span><br><span class=\"line\">    var lastOffset = -1L</span><br><span class=\"line\">    var sourceCodec: CompressionCodec = NoCompressionCodec</span><br><span class=\"line\">    var monotonic = true</span><br><span class=\"line\">    var maxTimestamp = RecordBatch.NO_TIMESTAMP</span><br><span class=\"line\">    var offsetOfMaxTimestamp = -1L</span><br><span class=\"line\">    var readFirstMessage = false</span><br><span class=\"line\">    var lastOffsetOfFirstBatch = -1L</span><br><span class=\"line\"></span><br><span class=\"line\">    for (batch &lt;- records.batches.asScala) &#123;</span><br><span class=\"line\">      // we only validate V2 and higher to avoid potential compatibility issues with older clients</span><br><span class=\"line\">      if (batch.magic &gt;= RecordBatch.MAGIC_VALUE_V2 &amp;&amp; isFromClient &amp;&amp; batch.baseOffset != 0)</span><br><span class=\"line\">        throw new InvalidRecordException(s&quot;The baseOffset of the record batch in the append to $topicPartition should &quot; +</span><br><span class=\"line\">          s&quot;be 0, but it is $&#123;batch.baseOffset&#125;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">      // update the first offset if on the first message. For magic versions older than 2, we use the last offset</span><br><span class=\"line\">      // to avoid the need to decompress the data (the last offset can be obtained directly from the wrapper message).</span><br><span class=\"line\">      // For magic version 2, we can get the first offset directly from the batch header.</span><br><span class=\"line\">      // When appending to the leader, we will update LogAppendInfo.baseOffset with the correct value. In the follower</span><br><span class=\"line\">      // case, validation will be more lenient.</span><br><span class=\"line\">      // Also indicate whether we have the accurate first offset or not</span><br><span class=\"line\">      if (!readFirstMessage) &#123;</span><br><span class=\"line\">        if (batch.magic &gt;= RecordBatch.MAGIC_VALUE_V2)</span><br><span class=\"line\">          firstOffset = Some(batch.baseOffset)</span><br><span class=\"line\">        lastOffsetOfFirstBatch = batch.lastOffset</span><br><span class=\"line\">        readFirstMessage = true</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      // check that offsets are monotonically increasing</span><br><span class=\"line\">      if (lastOffset &gt;= batch.lastOffset)</span><br><span class=\"line\">        monotonic = false</span><br><span class=\"line\"></span><br><span class=\"line\">      // update the last offset seen</span><br><span class=\"line\">      lastOffset = batch.lastOffset</span><br><span class=\"line\"></span><br><span class=\"line\">      // Check if the message sizes are valid.</span><br><span class=\"line\">      val batchSize = batch.sizeInBytes</span><br><span class=\"line\">      if (batchSize &gt; config.maxMessageSize) &#123;</span><br><span class=\"line\">        brokerTopicStats.topicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)</span><br><span class=\"line\">        brokerTopicStats.allTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)</span><br><span class=\"line\">        throw new RecordTooLargeException(s&quot;The record batch size in the append to $topicPartition is $batchSize bytes &quot; +</span><br><span class=\"line\">          s&quot;which exceeds the maximum configured value of $&#123;config.maxMessageSize&#125;.&quot;)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      // check the validity of the message by checking CRC</span><br><span class=\"line\">      batch.ensureValid()</span><br><span class=\"line\"></span><br><span class=\"line\">      if (batch.maxTimestamp &gt; maxTimestamp) &#123;</span><br><span class=\"line\">        maxTimestamp = batch.maxTimestamp</span><br><span class=\"line\">        offsetOfMaxTimestamp = lastOffset</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      shallowMessageCount += 1</span><br><span class=\"line\">      validBytesCount += batchSize</span><br><span class=\"line\"></span><br><span class=\"line\">      val messageCodec = CompressionCodec.getCompressionCodec(batch.compressionType.id)</span><br><span class=\"line\">      if (messageCodec != NoCompressionCodec)</span><br><span class=\"line\">        sourceCodec = messageCodec</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Apply broker-side compression if any</span><br><span class=\"line\">    val targetCodec = BrokerCompressionCodec.getTargetCompressionCodec(config.compressionType, sourceCodec)</span><br><span class=\"line\">    LogAppendInfo(firstOffset, lastOffset, maxTimestamp, offsetOfMaxTimestamp, RecordBatch.NO_TIMESTAMP, logStartOffset,</span><br><span class=\"line\">      RecordConversionStats.EMPTY, sourceCodec, targetCodec, shallowMessageCount, validBytesCount, monotonic, lastOffsetOfFirstBatch)</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<p><init>(ByteBuffer):57, MemoryRecords (org.apache.kafka.common.record), MemoryRecords.java<br>readableRecords(ByteBuffer):425, MemoryRecords (org.apache.kafka.common.record), MemoryRecords.java<br>read(ByteBuffer):561, Type$11 (org.apache.kafka.common.protocol.types), Type.java<br>read(ByteBuffer):544, Type$11 (org.apache.kafka.common.protocol.types), Type.java<br>read(ByteBuffer):106, Schema (org.apache.kafka.common.protocol.types), Schema.java<br>read(ByteBuffer):27, Schema (org.apache.kafka.common.protocol.types), Schema.java<br>read(ByteBuffer):78, ArrayOf (org.apache.kafka.common.protocol.types), ArrayOf.java<br>read(ByteBuffer):106, Schema (org.apache.kafka.common.protocol.types), Schema.java<br>read(ByteBuffer):27, Schema (org.apache.kafka.common.protocol.types), Schema.java<br>read(ByteBuffer):78, ArrayOf (org.apache.kafka.common.protocol.types), ArrayOf.java<br>read(ByteBuffer):106, Schema (org.apache.kafka.common.protocol.types), Schema.java<br>parseRequest(short, ByteBuffer):297, ApiKeys (org.apache.kafka.common.protocol), ApiKeys.java<br>parseRequest(ByteBuffer):63, RequestContext (org.apache.kafka.common.requests), RequestContext.java<br><init>(int, RequestContext, long, MemoryPool, ByteBuffer, RequestChannel$Metrics):89, RequestChannel$Request (kafka.network), RequestChannel.scala<br>$anonfun$processCompletedReceives$1(Processor, NetworkReceive):891, Processor (kafka.network), SocketServer.scala<br>$anonfun$processCompletedReceives$1$adapted(Processor, NetworkReceive):873, Processor (kafka.network), SocketServer.scala<br>apply(Object):-1, 214985191 (kafka.network.Processor$$Lambda$686), Unknown Source<br>foreach(Function1):941, Iterator (scala.collection), Iterator.scala<br>foreach$(Iterator, Function1):941, Iterator (scala.collection), Iterator.scala<br>foreach(Function1):1429, AbstractIterator (scala.collection), Iterator.scala<br>foreach(Function1):74, IterableLike (scala.collection), IterableLike.scala<br>foreach$(IterableLike, Function1):73, IterableLike (scala.collection), IterableLike.scala<br>foreach(Function1):56, AbstractIterable (scala.collection), Iterable.scala<br>processCompletedReceives():873, Processor (kafka.network), SocketServer.scala<br>run():763, Processor (kafka.network), SocketServer.scala<br>run():748, Thread (java.lang), Thread.java</init></init></p>\n"},{"title":"Kafka-Streaming","date":"2019-08-22T06:15:54.000Z","_content":"\nkafka_2.12-2.3.0\n\nbin/kafka-server-start.sh config/server.properties\n\nbin/kafka-console-producer.sh --broker-list localhost:9092 --topic streams-plaintext-input\n\nbin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \\\n    --topic streams-wordcount-output \\\n    --from-beginning \\\n    --formatter kafka.tools.DefaultMessageFormatter \\\n    --property print.key=true \\\n    --property print.value=true \\\n    --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer \\\n    --property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer","source":"_posts/Kafka-Streaming.md","raw":"---\ntitle: Kafka-Streaming\ndate: 2019-08-22 14:15:54\ntags:\n---\n\nkafka_2.12-2.3.0\n\nbin/kafka-server-start.sh config/server.properties\n\nbin/kafka-console-producer.sh --broker-list localhost:9092 --topic streams-plaintext-input\n\nbin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \\\n    --topic streams-wordcount-output \\\n    --from-beginning \\\n    --formatter kafka.tools.DefaultMessageFormatter \\\n    --property print.key=true \\\n    --property print.value=true \\\n    --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer \\\n    --property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer","slug":"Kafka-Streaming","published":1,"updated":"2019-09-28T08:51:00.881Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83k002nv1npihysz1ai","content":"<p>kafka_2.12-2.3.0</p>\n<p>bin/kafka-server-start.sh config/server.properties</p>\n<p>bin/kafka-console-producer.sh –broker-list localhost:9092 –topic streams-plaintext-input</p>\n<p>bin/kafka-console-consumer.sh –bootstrap-server localhost:9092 <br>    –topic streams-wordcount-output <br>    –from-beginning <br>    –formatter kafka.tools.DefaultMessageFormatter <br>    –property print.key=true <br>    –property print.value=true <br>    –property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer <br>    –property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer</p>\n","site":{"data":{}},"excerpt":"","more":"<p>kafka_2.12-2.3.0</p>\n<p>bin/kafka-server-start.sh config/server.properties</p>\n<p>bin/kafka-console-producer.sh –broker-list localhost:9092 –topic streams-plaintext-input</p>\n<p>bin/kafka-console-consumer.sh –bootstrap-server localhost:9092 <br>    –topic streams-wordcount-output <br>    –from-beginning <br>    –formatter kafka.tools.DefaultMessageFormatter <br>    –property print.key=true <br>    –property print.value=true <br>    –property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer <br>    –property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer</p>\n"},{"title":"JVM-Volatile-impl","date":"2018-10-26T02:20:57.000Z","_content":"\n\nhttp://www.importnew.com/27863.html","source":"_posts/JVM-Volatile-impl.md","raw":"---\ntitle: JVM-Volatile-impl\ndate: 2018-10-26 10:20:57\ntags: JVM\n---\n\n\nhttp://www.importnew.com/27863.html","slug":"JVM-Volatile-impl","published":1,"updated":"2019-09-28T08:51:00.879Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83l002ov1nplw4xm9ta","content":"<p><a href=\"http://www.importnew.com/27863.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/27863.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://www.importnew.com/27863.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/27863.html</a></p>\n"},{"title":"Kafka-Opertion-Tools","date":"2019-11-19T09:11:26.000Z","_content":"\n默认全部在KAFKA_HOME执行命令\n\n## 启动\nbin/kafka-server-start.sh config/server.properties","source":"_posts/Kafka-Opertion-Tools.md","raw":"---\ntitle: Kafka-Opertion-Tools\ndate: 2019-11-19 17:11:26\ntags:\n---\n\n默认全部在KAFKA_HOME执行命令\n\n## 启动\nbin/kafka-server-start.sh config/server.properties","slug":"Kafka-Opertion-Tools","published":1,"updated":"2019-11-19T09:12:49.818Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83l002pv1np40svlqil","content":"<p>默认全部在KAFKA_HOME执行命令</p>\n<h2 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h2><p>bin/kafka-server-start.sh config/server.properties</p>\n","site":{"data":{}},"excerpt":"","more":"<p>默认全部在KAFKA_HOME执行命令</p>\n<h2 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h2><p>bin/kafka-server-start.sh config/server.properties</p>\n"},{"title":"LevelDB-Code-Analysis-Bloom-Filter","date":"2019-04-11T03:22:10.000Z","_content":"","source":"_posts/LevelDB-Code-Analysis-Bloom-Filter.md","raw":"---\ntitle: LevelDB-Code-Analysis-Bloom-Filter\ndate: 2019-04-11 11:22:10\ntags:\n---\n","slug":"LevelDB-Code-Analysis-Bloom-Filter","published":1,"updated":"2019-09-28T08:51:00.882Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83m002qv1npeqiuifkv","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Kafka——高速低延时之秘诀「Page Cache」","date":"2017-11-12T14:47:44.000Z","_content":"\n\n> 一切的秘密，都在下面的几篇文章中\n\nhttp://blog.csdn.net/tototuzuoquan/article/details/73437890\n\nhttp://www.jianshu.com/p/eba0067b1e1a\n大神作者\n\nhttps://tech.meituan.com/kafka-fs-design-theory.html\n\n\n_java.nio.channels.FileChannel_\n`public abstract void force(boolean metaData) throws java.io.IOException`\nForces any updates to this channel's file to be written to the storage device that contains it.\nIf this channel's file resides on a local storage device then when this method returns it is guaranteed that all changes made to the file since this channel was created, or since this method was last invoked, will have been written to that device. This is useful for ensuring that critical information is not lost in the event of a system crash.\nIf the file does not reside on a local device then no such guarantee is made.\nThe metaData parameter can be used to limit the number of I/O operations that this method is required to perform. Passing false for this parameter indicates that only updates to the file's content need be written to storage; passing true indicates that updates to both the file's content and metadata must be written, which generally requires at least one more I/O operation. Whether this parameter actually has any effect is dependent upon the underlying operating system and is therefore unspecified.\nInvoking this method may cause an I/O operation to occur even if the channel was only opened for reading. Some operating systems, for example, maintain a last-access time as part of a file's metadata, and this time is updated whenever the file is read. Whether or not this is actually done is system-dependent and is therefore unspecified.\nThis method is only guaranteed to force changes that were made to this channel's file via the methods defined in this class. **It may or may not force changes that were made by modifying the content of a mapped byte buffer obtained by invoking the map method. Invoking the force method of the mapped byte buffer will force changes made to the buffer's content to be written.**\n\n_java.nio.MappedByteBuffer_\n`public final MappedByteBuffer force()`\nForces any changes made to this buffer's content to be written to the storage device containing the mapped file.\nIf the file mapped into this buffer resides on a local storage device then when this method returns it is guaranteed that all changes made to the buffer since it was created, or since this method was last invoked, will have been written to that device.\nIf the file does not reside on a local device then no such guarantee is made.\nIf this buffer was not mapped in read/write mode (java.nio.channels.FileChannel.MapMode.READ_WRITE) then invoking this method has no effect.\n\n\n### Don't fear the filesystem!\n\nKafka relies heavily on the filesystem for storing and caching messages. There is a general perception that \"disks are slow\" which makes people skeptical that a persistent structure can offer competitive performance. In fact disks are both much slower and much faster than people expect depending on how they are used; and a properly designed disk structure can often be as fast as the network.\n\nThe key fact about disk performance is that the throughput of hard drives has been diverging from the latency of a disk seek for the last decade. As a result the performance of linear writes on a JBOD configuration with six 7200rpm SATA RAID-5 array is about 600MB/sec but the performance of random writes is only about 100k/sec—a difference of over 6000X. These linear reads and writes are the most predictable of all usage patterns, and are heavily optimized by the operating system. A modern operating system provides read-ahead and write-behind techniques that prefetch data in large block multiples and group smaller logical writes into large physical writes. A further discussion of this issue can be found in this ACM Queue article; they actually find that sequential disk access can in some cases be faster than random memory access!\n\n![你想输入的替代文字](Kafka-High-performance-design-with-pagecache/disk_read_write_speed.jpg)\n\nTo compensate for this performance divergence, modern operating systems have become increasingly aggressive in their use of main memory for disk caching. A modern OS will happily divert all free memory to disk caching with little performance penalty when the memory is reclaimed. All disk reads and writes will go through this unified cache. This feature cannot easily be turned off without using direct I/O, so even if a process maintains an in-process cache of the data, this data will likely be duplicated in OS pagecache, effectively storing everything twice.\n\nFurthermore, we are building on top of the JVM, and anyone who has spent any time with Java memory usage knows two things:\n\nThe memory overhead of objects is very high, often doubling the size of the data stored (or worse).\nJava garbage collection becomes increasingly fiddly and slow as the in-heap data increases.\nAs a result of these factors using the filesystem and relying on pagecache is superior to maintaining an in-memory cache or other structure—we at least double the available cache by having automatic access to all free memory, and likely double again by storing a compact byte structure rather than individual objects. Doing so will result in a cache of up to 28-30GB on a 32GB machine without GC penalties. Furthermore, this cache will stay warm even if the service is restarted, whereas the in-process cache will need to be rebuilt in memory (which for a 10GB cache may take 10 minutes) or else it will need to start with a completely cold cache (which likely means terrible initial performance). This also greatly simplifies the code as all logic for maintaining coherency between the cache and filesystem is now in the OS, which tends to do so more efficiently and more correctly than one-off in-process attempts. If your disk usage favors linear reads then read-ahead is effectively pre-populating this cache with useful data on each disk read.\n\nThis suggests a design which is very simple: rather than maintain as much as possible in-memory and flush it all out to the filesystem in a panic when we run out of space, we invert that. All data is immediately written to a persistent log on the filesystem without necessarily flushing to disk. In effect this just means that it is transferred into the kernel's pagecache.\n\nThis style of pagecache-centric design is described in an article on the design of Varnish here (along with a healthy dose of arrogance).\n\n### sendfile\n\nsendfile() copies data between one file descriptor and another.\n\nBecause this copying is done within the kernel, sendfile() is more\nefficient than the combination of read(2) and write(2), which would\nrequire transferring data to and from user space.\n\n![你想输入的替代文字](Kafka-High-performance-design-with-pagecache/read_write.gif)\n\nconventional read and write\n\n\n关于脏页，有什么需要注意的？\n\nhttp://blog.csdn.net/stark_summer/article/details/50144591\n\nTips\n1. Kafka官方并不建议通过Broker端的log.flush.interval.messages和log.flush.interval.ms来强制写盘，认为数据的可靠性应该通过Replica来保证，而强制Flush数据到磁盘会对整体性能产生影响。\n2. 可以通过调整/proc/sys/vm/dirty_background_ratio和/proc/sys/vm/dirty_ratio来调优性能。\na. 脏页率超过第一个指标会启动pdflush开始Flush Dirty PageCache。\nb. 脏页率超过第二个指标会阻塞所有的写操作来进行Flush。\nc. 根据不同的业务需求可以适当的降低dirty_background_ratio和提高dirty_ratio。","source":"_posts/Kafka-High-performance-design-with-pagecache.md","raw":"---\ntitle: Kafka——高速低延时之秘诀「Page Cache」\ndate: 2017-11-12 22:47:44\ntags: Kafka\n---\n\n\n> 一切的秘密，都在下面的几篇文章中\n\nhttp://blog.csdn.net/tototuzuoquan/article/details/73437890\n\nhttp://www.jianshu.com/p/eba0067b1e1a\n大神作者\n\nhttps://tech.meituan.com/kafka-fs-design-theory.html\n\n\n_java.nio.channels.FileChannel_\n`public abstract void force(boolean metaData) throws java.io.IOException`\nForces any updates to this channel's file to be written to the storage device that contains it.\nIf this channel's file resides on a local storage device then when this method returns it is guaranteed that all changes made to the file since this channel was created, or since this method was last invoked, will have been written to that device. This is useful for ensuring that critical information is not lost in the event of a system crash.\nIf the file does not reside on a local device then no such guarantee is made.\nThe metaData parameter can be used to limit the number of I/O operations that this method is required to perform. Passing false for this parameter indicates that only updates to the file's content need be written to storage; passing true indicates that updates to both the file's content and metadata must be written, which generally requires at least one more I/O operation. Whether this parameter actually has any effect is dependent upon the underlying operating system and is therefore unspecified.\nInvoking this method may cause an I/O operation to occur even if the channel was only opened for reading. Some operating systems, for example, maintain a last-access time as part of a file's metadata, and this time is updated whenever the file is read. Whether or not this is actually done is system-dependent and is therefore unspecified.\nThis method is only guaranteed to force changes that were made to this channel's file via the methods defined in this class. **It may or may not force changes that were made by modifying the content of a mapped byte buffer obtained by invoking the map method. Invoking the force method of the mapped byte buffer will force changes made to the buffer's content to be written.**\n\n_java.nio.MappedByteBuffer_\n`public final MappedByteBuffer force()`\nForces any changes made to this buffer's content to be written to the storage device containing the mapped file.\nIf the file mapped into this buffer resides on a local storage device then when this method returns it is guaranteed that all changes made to the buffer since it was created, or since this method was last invoked, will have been written to that device.\nIf the file does not reside on a local device then no such guarantee is made.\nIf this buffer was not mapped in read/write mode (java.nio.channels.FileChannel.MapMode.READ_WRITE) then invoking this method has no effect.\n\n\n### Don't fear the filesystem!\n\nKafka relies heavily on the filesystem for storing and caching messages. There is a general perception that \"disks are slow\" which makes people skeptical that a persistent structure can offer competitive performance. In fact disks are both much slower and much faster than people expect depending on how they are used; and a properly designed disk structure can often be as fast as the network.\n\nThe key fact about disk performance is that the throughput of hard drives has been diverging from the latency of a disk seek for the last decade. As a result the performance of linear writes on a JBOD configuration with six 7200rpm SATA RAID-5 array is about 600MB/sec but the performance of random writes is only about 100k/sec—a difference of over 6000X. These linear reads and writes are the most predictable of all usage patterns, and are heavily optimized by the operating system. A modern operating system provides read-ahead and write-behind techniques that prefetch data in large block multiples and group smaller logical writes into large physical writes. A further discussion of this issue can be found in this ACM Queue article; they actually find that sequential disk access can in some cases be faster than random memory access!\n\n![你想输入的替代文字](Kafka-High-performance-design-with-pagecache/disk_read_write_speed.jpg)\n\nTo compensate for this performance divergence, modern operating systems have become increasingly aggressive in their use of main memory for disk caching. A modern OS will happily divert all free memory to disk caching with little performance penalty when the memory is reclaimed. All disk reads and writes will go through this unified cache. This feature cannot easily be turned off without using direct I/O, so even if a process maintains an in-process cache of the data, this data will likely be duplicated in OS pagecache, effectively storing everything twice.\n\nFurthermore, we are building on top of the JVM, and anyone who has spent any time with Java memory usage knows two things:\n\nThe memory overhead of objects is very high, often doubling the size of the data stored (or worse).\nJava garbage collection becomes increasingly fiddly and slow as the in-heap data increases.\nAs a result of these factors using the filesystem and relying on pagecache is superior to maintaining an in-memory cache or other structure—we at least double the available cache by having automatic access to all free memory, and likely double again by storing a compact byte structure rather than individual objects. Doing so will result in a cache of up to 28-30GB on a 32GB machine without GC penalties. Furthermore, this cache will stay warm even if the service is restarted, whereas the in-process cache will need to be rebuilt in memory (which for a 10GB cache may take 10 minutes) or else it will need to start with a completely cold cache (which likely means terrible initial performance). This also greatly simplifies the code as all logic for maintaining coherency between the cache and filesystem is now in the OS, which tends to do so more efficiently and more correctly than one-off in-process attempts. If your disk usage favors linear reads then read-ahead is effectively pre-populating this cache with useful data on each disk read.\n\nThis suggests a design which is very simple: rather than maintain as much as possible in-memory and flush it all out to the filesystem in a panic when we run out of space, we invert that. All data is immediately written to a persistent log on the filesystem without necessarily flushing to disk. In effect this just means that it is transferred into the kernel's pagecache.\n\nThis style of pagecache-centric design is described in an article on the design of Varnish here (along with a healthy dose of arrogance).\n\n### sendfile\n\nsendfile() copies data between one file descriptor and another.\n\nBecause this copying is done within the kernel, sendfile() is more\nefficient than the combination of read(2) and write(2), which would\nrequire transferring data to and from user space.\n\n![你想输入的替代文字](Kafka-High-performance-design-with-pagecache/read_write.gif)\n\nconventional read and write\n\n\n关于脏页，有什么需要注意的？\n\nhttp://blog.csdn.net/stark_summer/article/details/50144591\n\nTips\n1. Kafka官方并不建议通过Broker端的log.flush.interval.messages和log.flush.interval.ms来强制写盘，认为数据的可靠性应该通过Replica来保证，而强制Flush数据到磁盘会对整体性能产生影响。\n2. 可以通过调整/proc/sys/vm/dirty_background_ratio和/proc/sys/vm/dirty_ratio来调优性能。\na. 脏页率超过第一个指标会启动pdflush开始Flush Dirty PageCache。\nb. 脏页率超过第二个指标会阻塞所有的写操作来进行Flush。\nc. 根据不同的业务需求可以适当的降低dirty_background_ratio和提高dirty_ratio。","slug":"Kafka-High-performance-design-with-pagecache","published":1,"updated":"2019-09-28T08:51:00.879Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83m002rv1npnw0qiuo9","content":"<blockquote>\n<p>一切的秘密，都在下面的几篇文章中</p>\n</blockquote>\n<p><a href=\"http://blog.csdn.net/tototuzuoquan/article/details/73437890\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/tototuzuoquan/article/details/73437890</a></p>\n<p><a href=\"http://www.jianshu.com/p/eba0067b1e1a\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/eba0067b1e1a</a><br>大神作者</p>\n<p><a href=\"https://tech.meituan.com/kafka-fs-design-theory.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/kafka-fs-design-theory.html</a></p>\n<p><em>java.nio.channels.FileChannel</em><br><code>public abstract void force(boolean metaData) throws java.io.IOException</code><br>Forces any updates to this channel’s file to be written to the storage device that contains it.<br>If this channel’s file resides on a local storage device then when this method returns it is guaranteed that all changes made to the file since this channel was created, or since this method was last invoked, will have been written to that device. This is useful for ensuring that critical information is not lost in the event of a system crash.<br>If the file does not reside on a local device then no such guarantee is made.<br>The metaData parameter can be used to limit the number of I/O operations that this method is required to perform. Passing false for this parameter indicates that only updates to the file’s content need be written to storage; passing true indicates that updates to both the file’s content and metadata must be written, which generally requires at least one more I/O operation. Whether this parameter actually has any effect is dependent upon the underlying operating system and is therefore unspecified.<br>Invoking this method may cause an I/O operation to occur even if the channel was only opened for reading. Some operating systems, for example, maintain a last-access time as part of a file’s metadata, and this time is updated whenever the file is read. Whether or not this is actually done is system-dependent and is therefore unspecified.<br>This method is only guaranteed to force changes that were made to this channel’s file via the methods defined in this class. <strong>It may or may not force changes that were made by modifying the content of a mapped byte buffer obtained by invoking the map method. Invoking the force method of the mapped byte buffer will force changes made to the buffer’s content to be written.</strong></p>\n<p><em>java.nio.MappedByteBuffer</em><br><code>public final MappedByteBuffer force()</code><br>Forces any changes made to this buffer’s content to be written to the storage device containing the mapped file.<br>If the file mapped into this buffer resides on a local storage device then when this method returns it is guaranteed that all changes made to the buffer since it was created, or since this method was last invoked, will have been written to that device.<br>If the file does not reside on a local device then no such guarantee is made.<br>If this buffer was not mapped in read/write mode (java.nio.channels.FileChannel.MapMode.READ_WRITE) then invoking this method has no effect.</p>\n<h3 id=\"Don’t-fear-the-filesystem\"><a href=\"#Don’t-fear-the-filesystem\" class=\"headerlink\" title=\"Don’t fear the filesystem!\"></a>Don’t fear the filesystem!</h3><p>Kafka relies heavily on the filesystem for storing and caching messages. There is a general perception that “disks are slow” which makes people skeptical that a persistent structure can offer competitive performance. In fact disks are both much slower and much faster than people expect depending on how they are used; and a properly designed disk structure can often be as fast as the network.</p>\n<p>The key fact about disk performance is that the throughput of hard drives has been diverging from the latency of a disk seek for the last decade. As a result the performance of linear writes on a JBOD configuration with six 7200rpm SATA RAID-5 array is about 600MB/sec but the performance of random writes is only about 100k/sec—a difference of over 6000X. These linear reads and writes are the most predictable of all usage patterns, and are heavily optimized by the operating system. A modern operating system provides read-ahead and write-behind techniques that prefetch data in large block multiples and group smaller logical writes into large physical writes. A further discussion of this issue can be found in this ACM Queue article; they actually find that sequential disk access can in some cases be faster than random memory access!</p>\n<p><img src=\"/2017/11/12/Kafka-High-performance-design-with-pagecache/disk_read_write_speed.jpg\" alt=\"你想输入的替代文字\"></p>\n<p>To compensate for this performance divergence, modern operating systems have become increasingly aggressive in their use of main memory for disk caching. A modern OS will happily divert all free memory to disk caching with little performance penalty when the memory is reclaimed. All disk reads and writes will go through this unified cache. This feature cannot easily be turned off without using direct I/O, so even if a process maintains an in-process cache of the data, this data will likely be duplicated in OS pagecache, effectively storing everything twice.</p>\n<p>Furthermore, we are building on top of the JVM, and anyone who has spent any time with Java memory usage knows two things:</p>\n<p>The memory overhead of objects is very high, often doubling the size of the data stored (or worse).<br>Java garbage collection becomes increasingly fiddly and slow as the in-heap data increases.<br>As a result of these factors using the filesystem and relying on pagecache is superior to maintaining an in-memory cache or other structure—we at least double the available cache by having automatic access to all free memory, and likely double again by storing a compact byte structure rather than individual objects. Doing so will result in a cache of up to 28-30GB on a 32GB machine without GC penalties. Furthermore, this cache will stay warm even if the service is restarted, whereas the in-process cache will need to be rebuilt in memory (which for a 10GB cache may take 10 minutes) or else it will need to start with a completely cold cache (which likely means terrible initial performance). This also greatly simplifies the code as all logic for maintaining coherency between the cache and filesystem is now in the OS, which tends to do so more efficiently and more correctly than one-off in-process attempts. If your disk usage favors linear reads then read-ahead is effectively pre-populating this cache with useful data on each disk read.</p>\n<p>This suggests a design which is very simple: rather than maintain as much as possible in-memory and flush it all out to the filesystem in a panic when we run out of space, we invert that. All data is immediately written to a persistent log on the filesystem without necessarily flushing to disk. In effect this just means that it is transferred into the kernel’s pagecache.</p>\n<p>This style of pagecache-centric design is described in an article on the design of Varnish here (along with a healthy dose of arrogance).</p>\n<h3 id=\"sendfile\"><a href=\"#sendfile\" class=\"headerlink\" title=\"sendfile\"></a>sendfile</h3><p>sendfile() copies data between one file descriptor and another.</p>\n<p>Because this copying is done within the kernel, sendfile() is more<br>efficient than the combination of read(2) and write(2), which would<br>require transferring data to and from user space.</p>\n<p><img src=\"/2017/11/12/Kafka-High-performance-design-with-pagecache/read_write.gif\" alt=\"你想输入的替代文字\"></p>\n<p>conventional read and write</p>\n<p>关于脏页，有什么需要注意的？</p>\n<p><a href=\"http://blog.csdn.net/stark_summer/article/details/50144591\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/stark_summer/article/details/50144591</a></p>\n<p>Tips</p>\n<ol>\n<li>Kafka官方并不建议通过Broker端的log.flush.interval.messages和log.flush.interval.ms来强制写盘，认为数据的可靠性应该通过Replica来保证，而强制Flush数据到磁盘会对整体性能产生影响。</li>\n<li>可以通过调整/proc/sys/vm/dirty_background_ratio和/proc/sys/vm/dirty_ratio来调优性能。<br>a. 脏页率超过第一个指标会启动pdflush开始Flush Dirty PageCache。<br>b. 脏页率超过第二个指标会阻塞所有的写操作来进行Flush。<br>c. 根据不同的业务需求可以适当的降低dirty_background_ratio和提高dirty_ratio。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>一切的秘密，都在下面的几篇文章中</p>\n</blockquote>\n<p><a href=\"http://blog.csdn.net/tototuzuoquan/article/details/73437890\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/tototuzuoquan/article/details/73437890</a></p>\n<p><a href=\"http://www.jianshu.com/p/eba0067b1e1a\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/eba0067b1e1a</a><br>大神作者</p>\n<p><a href=\"https://tech.meituan.com/kafka-fs-design-theory.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/kafka-fs-design-theory.html</a></p>\n<p><em>java.nio.channels.FileChannel</em><br><code>public abstract void force(boolean metaData) throws java.io.IOException</code><br>Forces any updates to this channel’s file to be written to the storage device that contains it.<br>If this channel’s file resides on a local storage device then when this method returns it is guaranteed that all changes made to the file since this channel was created, or since this method was last invoked, will have been written to that device. This is useful for ensuring that critical information is not lost in the event of a system crash.<br>If the file does not reside on a local device then no such guarantee is made.<br>The metaData parameter can be used to limit the number of I/O operations that this method is required to perform. Passing false for this parameter indicates that only updates to the file’s content need be written to storage; passing true indicates that updates to both the file’s content and metadata must be written, which generally requires at least one more I/O operation. Whether this parameter actually has any effect is dependent upon the underlying operating system and is therefore unspecified.<br>Invoking this method may cause an I/O operation to occur even if the channel was only opened for reading. Some operating systems, for example, maintain a last-access time as part of a file’s metadata, and this time is updated whenever the file is read. Whether or not this is actually done is system-dependent and is therefore unspecified.<br>This method is only guaranteed to force changes that were made to this channel’s file via the methods defined in this class. <strong>It may or may not force changes that were made by modifying the content of a mapped byte buffer obtained by invoking the map method. Invoking the force method of the mapped byte buffer will force changes made to the buffer’s content to be written.</strong></p>\n<p><em>java.nio.MappedByteBuffer</em><br><code>public final MappedByteBuffer force()</code><br>Forces any changes made to this buffer’s content to be written to the storage device containing the mapped file.<br>If the file mapped into this buffer resides on a local storage device then when this method returns it is guaranteed that all changes made to the buffer since it was created, or since this method was last invoked, will have been written to that device.<br>If the file does not reside on a local device then no such guarantee is made.<br>If this buffer was not mapped in read/write mode (java.nio.channels.FileChannel.MapMode.READ_WRITE) then invoking this method has no effect.</p>\n<h3 id=\"Don’t-fear-the-filesystem\"><a href=\"#Don’t-fear-the-filesystem\" class=\"headerlink\" title=\"Don’t fear the filesystem!\"></a>Don’t fear the filesystem!</h3><p>Kafka relies heavily on the filesystem for storing and caching messages. There is a general perception that “disks are slow” which makes people skeptical that a persistent structure can offer competitive performance. In fact disks are both much slower and much faster than people expect depending on how they are used; and a properly designed disk structure can often be as fast as the network.</p>\n<p>The key fact about disk performance is that the throughput of hard drives has been diverging from the latency of a disk seek for the last decade. As a result the performance of linear writes on a JBOD configuration with six 7200rpm SATA RAID-5 array is about 600MB/sec but the performance of random writes is only about 100k/sec—a difference of over 6000X. These linear reads and writes are the most predictable of all usage patterns, and are heavily optimized by the operating system. A modern operating system provides read-ahead and write-behind techniques that prefetch data in large block multiples and group smaller logical writes into large physical writes. A further discussion of this issue can be found in this ACM Queue article; they actually find that sequential disk access can in some cases be faster than random memory access!</p>\n<p><img src=\"/2017/11/12/Kafka-High-performance-design-with-pagecache/disk_read_write_speed.jpg\" alt=\"你想输入的替代文字\"></p>\n<p>To compensate for this performance divergence, modern operating systems have become increasingly aggressive in their use of main memory for disk caching. A modern OS will happily divert all free memory to disk caching with little performance penalty when the memory is reclaimed. All disk reads and writes will go through this unified cache. This feature cannot easily be turned off without using direct I/O, so even if a process maintains an in-process cache of the data, this data will likely be duplicated in OS pagecache, effectively storing everything twice.</p>\n<p>Furthermore, we are building on top of the JVM, and anyone who has spent any time with Java memory usage knows two things:</p>\n<p>The memory overhead of objects is very high, often doubling the size of the data stored (or worse).<br>Java garbage collection becomes increasingly fiddly and slow as the in-heap data increases.<br>As a result of these factors using the filesystem and relying on pagecache is superior to maintaining an in-memory cache or other structure—we at least double the available cache by having automatic access to all free memory, and likely double again by storing a compact byte structure rather than individual objects. Doing so will result in a cache of up to 28-30GB on a 32GB machine without GC penalties. Furthermore, this cache will stay warm even if the service is restarted, whereas the in-process cache will need to be rebuilt in memory (which for a 10GB cache may take 10 minutes) or else it will need to start with a completely cold cache (which likely means terrible initial performance). This also greatly simplifies the code as all logic for maintaining coherency between the cache and filesystem is now in the OS, which tends to do so more efficiently and more correctly than one-off in-process attempts. If your disk usage favors linear reads then read-ahead is effectively pre-populating this cache with useful data on each disk read.</p>\n<p>This suggests a design which is very simple: rather than maintain as much as possible in-memory and flush it all out to the filesystem in a panic when we run out of space, we invert that. All data is immediately written to a persistent log on the filesystem without necessarily flushing to disk. In effect this just means that it is transferred into the kernel’s pagecache.</p>\n<p>This style of pagecache-centric design is described in an article on the design of Varnish here (along with a healthy dose of arrogance).</p>\n<h3 id=\"sendfile\"><a href=\"#sendfile\" class=\"headerlink\" title=\"sendfile\"></a>sendfile</h3><p>sendfile() copies data between one file descriptor and another.</p>\n<p>Because this copying is done within the kernel, sendfile() is more<br>efficient than the combination of read(2) and write(2), which would<br>require transferring data to and from user space.</p>\n<p><img src=\"/2017/11/12/Kafka-High-performance-design-with-pagecache/read_write.gif\" alt=\"你想输入的替代文字\"></p>\n<p>conventional read and write</p>\n<p>关于脏页，有什么需要注意的？</p>\n<p><a href=\"http://blog.csdn.net/stark_summer/article/details/50144591\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/stark_summer/article/details/50144591</a></p>\n<p>Tips</p>\n<ol>\n<li>Kafka官方并不建议通过Broker端的log.flush.interval.messages和log.flush.interval.ms来强制写盘，认为数据的可靠性应该通过Replica来保证，而强制Flush数据到磁盘会对整体性能产生影响。</li>\n<li>可以通过调整/proc/sys/vm/dirty_background_ratio和/proc/sys/vm/dirty_ratio来调优性能。<br>a. 脏页率超过第一个指标会启动pdflush开始Flush Dirty PageCache。<br>b. 脏页率超过第二个指标会阻塞所有的写操作来进行Flush。<br>c. 根据不同的业务需求可以适当的降低dirty_background_ratio和提高dirty_ratio。</li>\n</ol>\n"},{"title":"Kafka-FAQ","date":"2017-11-17T07:33:16.000Z","_content":"### 大量精品文章和面试问题\nhttps://blog.csdn.net/u013256816\n比较好的总结\nhttps://juejin.im/post/5ddf5659518825782d599641?utm_source=gold_browser_extension\n\n### Kafka发送怎么保证顺序？\n\n### Kafka异步发送能不能保证顺序？\n\n### Kafka能不能保证不丢消息（只要多数机器不挂）？\n\n### Kafka能不能保证消费顺序？\n\n### Kafka写CommitLog时用了什么锁机制?\n\nsync;lock-free;reentrant lock,用了哪一种？\n\nkafka.log.Log#append\nlock synchronized {\n}\n\n### Kafka生产者批量发送了消息，那Broker是把消息一条一存么？\n不是，是把几条连续的消息存在一起，在外层公用同一个offset\n\n### kafka消费者fetch的消息正好在某个批次中间的消息，怎么办？\n\n\n### Kafka Consumer Rebalance流程是怎么样的？\n1. Consumer查找GroupCoordinator，向它发送Join请求\n2. Broker收到Join请求后，创建一个Group，并且把创建的Consumer作为Consumer的Leader\n```\n// @ kafka.coordinator.group.GroupMetadata#add\ndef add(member: MemberMetadata) {\n  if (members.isEmpty)\n    this.protocolType = Some(member.protocolType)\n\n  assert(groupId == member.groupId)\n  assert(this.protocolType.orNull == member.protocolType)\n  assert(supportsProtocols(member.protocols))\n\n  if (leaderId.isEmpty)\n    leaderId = Some(member.memberId)\n  members.put(member.memberId, member)\n}\n```\n3. Broker并不会直接给发送Join请求的Consumer响应，而是会启动延时任务，等待一段时间，然后再给所有的Consumer响应\n```\n// @ kafka.coordinator.group.GroupCoordinator#prepareRebalance\nprivate def prepareRebalance(group: GroupMetadata) {\n  // if any members are awaiting sync, cancel their request and have them rejoin\n  if (group.is(AwaitingSync))\n    resetAndPropagateAssignmentError(group, Errors.REBALANCE_IN_PROGRESS)\n\n  val delayedRebalance = if (group.is(Empty))\n    new InitialDelayedJoin(this,\n      joinPurgatory,\n      group,\n      groupConfig.groupInitialRebalanceDelayMs,\n      groupConfig.groupInitialRebalanceDelayMs,\n      max(group.rebalanceTimeoutMs - groupConfig.groupInitialRebalanceDelayMs, 0))\n  else\n    new DelayedJoin(this, group, group.rebalanceTimeoutMs)\n\n  group.transitionTo(PreparingRebalance)\n\n  info(s\"Preparing to rebalance group ${group.groupId} with old generation ${group.generationId} \" +\n    s\"(${Topic.GROUP_METADATA_TOPIC_NAME}-${partitionFor(group.groupId)})\")\n\n  val groupKey = GroupKey(group.groupId)\n  joinPurgatory.tryCompleteElseWatch(delayedRebalance, Seq(groupKey))\n}\n```\n4. 各个Consumer收到来自Group coordinator的响应后，会查看自己是不是这个Consumer Group中的Consumer Leader\n```\n// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator.JoinGroupResponseHandler#handle\nAbstractCoordinator.this.generation = new Generation(joinResponse.generationId(),\n        joinResponse.memberId(), joinResponse.groupProtocol());\nif (joinResponse.isLeader()) {\n    onJoinLeader(joinResponse).chain(future);\n} else {\n    onJoinFollower().chain(future);\n}\n```\n5. 作为Leader的Consumer需要根据自己Rebalance算法，把rebalance的结果通过发送Sync请求反馈给Group Coordinator\n```\n// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator#onJoinLeader\nprivate RequestFuture<ByteBuffer> onJoinLeader(JoinGroupResponse joinResponse) {\n    try {\n        // perform the leader synchronization and send back the assignment for the group\n        Map<String, ByteBuffer> groupAssignment = performAssignment(joinResponse.leaderId(), joinResponse.groupProtocol(),\n                joinResponse.members());\n\n        SyncGroupRequest.Builder requestBuilder =\n                new SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId, groupAssignment);\n        log.debug(\"Sending leader SyncGroup to coordinator {}: {}\", this.coordinator, requestBuilder);\n        return sendSyncGroupRequest(requestBuilder);\n    } catch (RuntimeException e) {\n        return RequestFuture.failure(e);\n    }\n}\n```\n6. 而那些普通的Consumer也需要发送一个空的Sync请求\n```\n// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator#onJoinFollower\nprivate RequestFuture<ByteBuffer> onJoinFollower() {\n    // send follower's sync group with an empty assignment\n    SyncGroupRequest.Builder requestBuilder =\n            new SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId,\n                    Collections.<String, ByteBuffer>emptyMap());\n    log.debug(\"Sending follower SyncGroup to coordinator {}: {}\", this.coordinator, requestBuilder);\n    return sendSyncGroupRequest(requestBuilder);\n}\n```\n7. 所有的Consumer根据Sync请求的响应，更新自己的\n```\n// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator.SyncGroupResponseHandler#handle\nErrors error = syncResponse.error();\nif (error == Errors.NONE) {\n    sensors.syncLatency.record(response.requestLatencyMs());\n    future.complete(syncResponse.memberAssignment());\n}\n\n// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator#joinGroupIfNeeded\nvoid joinGroupIfNeeded() {\n    while (needRejoin() || rejoinIncomplete()) {\n        // ...\n\n        RequestFuture<ByteBuffer> future = initiateJoinGroup();\n        client.poll(future);\n\n        if (future.succeeded()) {\n            onJoinComplete(generation.generationId, generation.memberId, generation.protocol, future.value());\n\n            // We reset the join group future only after the completion callback returns. This ensures\n            // that if the callback is woken up, we will retry it on the next joinGroupIfNeeded.\n            resetJoinGroupFuture();\n            needsJoinPrepare = true;\n        } else {\n            // ...\n        }\n    }\n}\n\n// @ org.apache.kafka.clients.consumer.internals.ConsumerCoordinator#onJoinComplete\nprotected void onJoinComplete(int generation,\n                              String memberId,\n                              String assignmentStrategy,\n                              ByteBuffer assignmentBuffer) {\n    // ...\n    Assignment assignment = ConsumerProtocol.deserializeAssignment(assignmentBuffer);\n\n    // ...\n\n    // update partition assignment\n    subscriptions.assignFromSubscribed(assignment.partitions());\n\n    // ...\n}\n```\n\n### 怎么监控kafka page cache刷盘时间？\n\n\n### Kafka shallowOffset是什么意思？\n\n### Kafka的Retention是怎么工作的？不符合retention的日志什么时候会被清理掉？\n\n### Kafka发送者怎么保证是有序的？\nMAX_IN_FLIGHT_REQUESTS_PER_CONNECTION = 1， 为什么？\n不等于1的话，会有什么效果？\n\n### Consumer coordinator是什么？\n\n### Group coordinator是什么？\n\n### __consumer_offset的某一个partition挂了，kafka broker中的controller会给它选一个新的Leader，这个过程是怎么样的？\n\n### 怎么获取Kafka Consumer的Lag\n\n### Kafka是一个batch一压缩，还是一条消息一压缩？\n每一个消息都会压缩\n\n### Kafka是怎么实现幂等的？\nBroker以(producer, topic, partition)为维度，维护一份Map</*(producer, topic, partition)*/, /*sequence*/>，Producer每发送一条消息(好像是以Batch为单位的??)，都会将sequence++；如果同一个Producer对于某一个(topic, partition)发送了两个sequence一样的消息，后面发送的那个将被丢弃掉。\n实现原理：\n)Producer在初始化时，会向Broker申请一个ProducerId\n)Broker处理ProducerId申请请求，从序列段中申请一个唯一ID\n)Producer在发送消息时，会将加一的sequence发在消息体中，一起发送\n```\n// @ org.apache.kafka.clients.producer.internals.RecordAccumulator#drain\n\n// Additionally, we update the next sequence number bound for the partition,\n// and also have the transaction manager track the batch so as to ensure\n// that sequence ordering is maintained even if we receive out of order\n// responses.\nbatch.setProducerState(producerIdAndEpoch, transactionManager.sequenceNumber(batch.topicPartition), isTransactional);\n\n\n// @ org.apache.kafka.common.record.DefaultRecordBatch#incrementSequence\nstatic int incrementSequence(int baseSequence, int increment) {\n    if (baseSequence > Integer.MAX_VALUE - increment)\n        return increment - (Integer.MAX_VALUE - baseSequence) - 1;\n    return baseSequence + increment;\n}\n```\n)Broker如果收到了sequence一样的消息，丢弃后直接返回。\n```\n// @ \n// if this is a client produce request, there will be up to 5 batches which could have been duplicated.\n// If we find a duplicate, we return the metadata of the appended batch to the client.\nif (isFromClient) {\n  maybeLastEntry.flatMap(_.findDuplicateBatch(batch)).foreach { duplicate =>\n    return (updatedProducers, completedTxns.toList, Some(duplicate))\n  }\n}\n```\n\n\n### Kafka Consumer关闭后，怎么触发Rebalance？\n``` \n// @ org.apache.kafka.clients.consumer.internals.ConsumerCoordinator#needRejoin\npublic boolean needRejoin() {\n    if (!subscriptions.partitionsAutoAssigned())\n        return false;\n\n    // we need to rejoin if we performed the assignment and metadata has changed\n    if (assignmentSnapshot != null && !assignmentSnapshot.equals(metadataSnapshot))\n        return true;\n\n    // we need to join if our subscription has changed since the last join\n    if (joinedSubscription != null && !joinedSubscription.equals(subscriptions.subscription()))\n        return true;\n\n    return super.needRejoin();\n}\n```\n\n### Kafka创建Topic的过程，和我们想象中有点不一样\n1. 生成(topic, partition)replica的assignment\n```\ndef createTopic(zkUtils: ZkUtils,\n                topic: String,\n                partitions: Int,\n                replicationFactor: Int,\n                topicConfig: Properties = new Properties,\n                rackAwareMode: RackAwareMode = RackAwareMode.Enforced) {\n  val brokerMetadatas = getBrokerMetadatas(zkUtils, rackAwareMode)\n  val replicaAssignment = AdminUtils.assignReplicasToBrokers(brokerMetadatas, partitions, replicationFactor)\n  AdminUtils.createOrUpdateTopicPartitionAssignmentPathInZK(zkUtils, topic, replicaAssignment, topicConfig)\n}\n```\n2. 将生成的replica assignment写到ZK上\n```\n// create the partition assignment\nwriteTopicPartitionAssignment(zkUtils, topic, partitionReplicaAssignment, update)\n```\n3. Broker监听到这个ZK变化，然后开始调用状态机，使replica和topic上线\n```\ncase class TopicChange(topics: Set[String]) extends ControllerEvent {\n\n  def state = ControllerState.TopicChange\n\n  override def process(): Unit = {\n    if (!isActive) return\n    val newTopics = topics -- controllerContext.allTopics\n    val deletedTopics = controllerContext.allTopics -- topics\n    controllerContext.allTopics = topics\n\n    val addedPartitionReplicaAssignment = zkUtils.getReplicaAssignmentForTopics(newTopics.toSeq)\n    controllerContext.partitionReplicaAssignment = controllerContext.partitionReplicaAssignment.filter(p =>\n      !deletedTopics.contains(p._1.topic))\n    controllerContext.partitionReplicaAssignment.++=(addedPartitionReplicaAssignment)\n    info(\"New topics: [%s], deleted topics: [%s], new partition replica assignment [%s]\".format(newTopics,\n      deletedTopics, addedPartitionReplicaAssignment))\n    if (newTopics.nonEmpty)\n      onNewTopicCreation(newTopics, addedPartitionReplicaAssignment.keySet)\n  }\n}\n\n/**\n  * This callback is invoked by the topic change callback with the list of failed brokers as input.\n  * It does the following -\n  * 1. Move the newly created partitions to the NewPartition state\n  * 2. Move the newly created partitions from NewPartition->OnlinePartition state\n  */\ndef onNewPartitionCreation(newPartitions: Set[TopicAndPartition]) {\n  info(\"New partition creation callback for %s\".format(newPartitions.mkString(\",\")))\n  partitionStateMachine.handleStateChanges(newPartitions, NewPartition)\n  replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), NewReplica)\n  partitionStateMachine.handleStateChanges(newPartitions, OnlinePartition, offlinePartitionSelector)\n  replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), OnlineReplica)\n}\n```\n\n### Kafka的__consumer_offset一共有50个partition，那么我指定的某一个(topic, partition)的是被这50个__consumer_offset中的哪个管理的？\n```\ncase FindCoordinatorRequest.CoordinatorType.GROUP =>\n  val partition = groupCoordinator.partitionFor(findCoordinatorRequest.coordinatorKey)\n  val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)\n  (partition, metadata)\n```\nhttp://matt33.com/2017/10/22/consumer-join-group/\n\n### Kafka中有哪些功能是这样的模式：1. 修改ZK； 2. Broker监听到ZK变化； 3. Broker 根据ZK变化进行逻辑响应\n1. Topic创建时，replica的assignment\n2. Topic的Reassignment\n\n\n### Kafka Consumer消费流程\n1. rebalance\n2. 获取assign的(topic, partition)的消费位点\n3. \n\n### Kafka Broker在做\"Join Request\"处理时，需要等待一个timeout的时间，好让所有相关的consumer都能来得及join进来？这个是怎么实现的？\n```\nprivate def prepareRebalance(group: GroupMetadata) {\n  // if any members are awaiting sync, cancel their request and have them rejoin\n  if (group.is(AwaitingSync))\n    resetAndPropagateAssignmentError(group, Errors.REBALANCE_IN_PROGRESS)\n\n  val delayedRebalance = if (group.is(Empty))\n    new InitialDelayedJoin(this,\n      joinPurgatory,\n      group,\n      groupConfig.groupInitialRebalanceDelayMs,\n      groupConfig.groupInitialRebalanceDelayMs,\n      max(group.rebalanceTimeoutMs - groupConfig.groupInitialRebalanceDelayMs, 0))\n  else\n    new DelayedJoin(this, group, group.rebalanceTimeoutMs)\n\n  group.transitionTo(PreparingRebalance)\n\n  info(s\"Preparing to rebalance group ${group.groupId} with old generation ${group.generationId} \" +\n    s\"(${Topic.GROUP_METADATA_TOPIC_NAME}-${partitionFor(group.groupId)})\")\n\n  val groupKey = GroupKey(group.groupId)\n  joinPurgatory.tryCompleteElseWatch(delayedRebalance, Seq(groupKey))\n}\n```\n\n### 如果(topic, partiton)的leader在Broker3，Producer是怎么发送消息给Broker3的，是需要在启动的时候连接所有的Broker么？\n\n### 如果需要消费在Broker2上的（topic, partition），Consumer是怎么去连接Broker2的，Consumer会连接整个集群所有的Broker么？\n1. 先找GroupCoordinator，连接一台负载最低的机器，发送`Find Coordinator`命令\n```\nprotected synchronized RequestFuture<Void> lookupCoordinator() {\n    if (findCoordinatorFuture == null) {\n        // find a node to ask about the coordinator\n        Node node = this.client.leastLoadedNode();\n        if (node == null) {\n            log.debug(\"No broker available to send FindCoordinator request\");\n            return RequestFuture.noBrokersAvailable();\n        } else\n            findCoordinatorFuture = sendFindCoordinatorRequest(node);\n    }\n    return findCoordinatorFuture;\n}\n```\n\n### SkimpyOffsetMap 算是一个非常大的问题啊，万一消息被错误得compact怎么办呢？\n\n### 假如我手动提交消息的offset，现在我业务处理失败，那么我消费端不提交offset，那么Kafka会把这个消息怎么处理呀？后续消费端还是否能够消费到？\n\n\n### 当某一个Partition的Leader挂了，Controller会为其选出一个新的Leader，这时是ISR中随便选一个么？\n按照我的理解，应该是去选一个LEO最大的吧，完全错误\n请分析这段代码\n参考这篇：\nhttps://www.jianshu.com/p/13548893bf31\nhttp://ifeve.com/kafka-controller/\n\n真实日志\n```\nkafka1/controller.log:[2019-10-04 08:26:01,376] DEBUG [PartitionStateMachine controllerId=1] After leader election, leader cache for krp-0 is updated to (Leader:2,ISR:2,1,LeaderEpoch:1,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)\n➜  /tmp grep -R \": current leader =\" kafka*\nkafka1/controller.log:[2019-10-04 08:26:01,313] DEBUG [ControlledShutdownLeaderSelector]: Partition krp-0 : current leader = 3, new leader = 2 (kafka.controller.ControlledShutdownLeaderSelector)\n\n\nin kafka3/controller.log\n[2019-10-04 08:26:02,132] INFO [controller-event-thread]: Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)\n[2019-10-04 08:26:02,132] INFO [controller-event-thread]: Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)\n[2019-10-04 08:26:02,133] INFO [controller-event-thread]: Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)\n[2019-10-04 08:26:02,133] DEBUG [Controller id=3] Resigning (kafka.controller.KafkaController)\n[2019-10-04 08:26:02,133] DEBUG [Controller id=3] De-registering IsrChangeNotificationListener (kafka.controller.KafkaController)\n[2019-10-04 08:26:02,134] DEBUG [Controller id=3] De-registering logDirEventNotificationListener (kafka.controller.KafkaController)\n[2019-10-04 08:26:02,135] INFO [PartitionStateMachine controllerId=3] Stopped partition state machine (kafka.controller.PartitionStateMachine)\n[2019-10-04 08:26:02,136] INFO [ReplicaStateMachine controllerId=3] Stopped replica state machine (kafka.controller.ReplicaStateMachine)\n[2019-10-04 08:26:02,137] INFO [Controller id=3] Resigned (kafka.controller.KafkaController)\n\nin kafka1/controller.log\n[2019-10-04 08:26:01,300] INFO [Controller id=1] Shutting down broker 3 (kafka.controller.KafkaController)\n[2019-10-04 08:26:01,301] DEBUG [Controller id=1] All shutting down brokers: 3 (kafka.controller.KafkaController)\n[2019-10-04 08:26:01,302] DEBUG [Controller id=1] Live brokers: 1,2 (kafka.controller.KafkaController)\n[2019-10-04 08:26:01,308] INFO [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions krp-0 (kafka.controller.PartitionStateMachine)\n[2019-10-04 08:26:01,313] DEBUG [ControlledShutdownLeaderSelector]: Partition krp-0 : current leader = 3, new leader = 2 (kafka.controller.ControlledShutdownLeaderSelector)\n[2019-10-04 08:26:01,376] DEBUG [PartitionStateMachine controllerId=1] After leader election, leader cache for krp-0 is updated to (Leader:2,ISR:2,1,LeaderEpoch:1,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)\n\nin kafka1/state-change.log\nkafka1/state-change.log:[2019-10-04 08:26:01,376] TRACE [Controller id=1 epoch=1] Changed partition krp-0 from OnlinePartition to OnlinePartition with leader 2 (state.change.logger)\n```\nclass ControlledShutdownLeaderSelector(controllerContext: ControllerContext) extends PartitionLeaderSelector with Logging {\n\n  logIdent = \"[ControlledShutdownLeaderSelector]: \"\n\n  def selectLeader(topicAndPartition: TopicAndPartition,\n                   currentLeaderAndIsr: LeaderAndIsr): (LeaderAndIsr, Seq[Int]) = {\n    val currentIsr = currentLeaderAndIsr.isr\n    val assignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)\n    val liveAssignedReplicas = assignedReplicas.filter(r => controllerContext.isReplicaOnline(r, topicAndPartition, true))\n\n    val newIsr = currentIsr.filter(brokerId => !controllerContext.shuttingDownBrokerIds.contains(brokerId))\n    liveAssignedReplicas.find(newIsr.contains) match {\n      case Some(newLeader) =>\n        debug(s\"Partition $topicAndPartition : current leader = ${currentLeaderAndIsr.leader}, new leader = $newLeader\")\n        val newLeaderAndIsr = currentLeaderAndIsr.newLeaderAndIsr(newLeader, newIsr)\n        (newLeaderAndIsr, liveAssignedReplicas)\n      case None =>\n        throw new StateChangeFailedException(s\"No other replicas in ISR ${currentIsr.mkString(\",\")} for $topicAndPartition \" +\n          s\"besides shutting down brokers ${controllerContext.shuttingDownBrokerIds.mkString(\",\")}\")\n    }\n  }\n}\n\n\n### Consumer怎么去监控Rebalance事件？\n添加ConsumerRebalanceListener监听器\n\n### 为什么要引入epoch？\n这个KIP写得非常清楚。\n原先Truncate到HighWatermark处，但是这样做是有问题的，原因是Follower的HighWatermark是在消息存储后的下一轮RPC才获取到Leader的HighWatermark（Follower把消息接收后，然后发起FetchRPC告知Leader，Leader将自己的HighWatermark+1，这时Leader的返回值中含有最新的HighWatermark，但是如果这时Leader没有新的数据，这个Fetch请求就是一个长轮询请求，Follower将会延迟一段时间拿到最新的HighWatermark），这时如果Follower重启了，它将会把Leader已经确认过的HighWatermark对应的数据给Truncate掉。如果Leader这时也挂了，那么Follower将会成为新的Leader，中间的数据将会对消费者永久丢失。\n\nhttps://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation#KIP-101-AlterReplicationProtocoltouseLeaderEpochratherthanHighWatermarkforTruncation-Scenario1:HighWatermarkTruncationfollowedbyImmediateLeaderElection\n\n### 日志truncate是怎么一回事？\n\n1. ISR = {A, B, C}, HighWatermark = m1\n\nA: Leader    B: Follower  C: Follower\n|   m1  |    |   m1  |    |   m1  |\n|   m2  |    |   m2  |\n|   m3  |\n\n2. A Crashes, New Leader: B, Question:这里C有可能成为Leader么？\n\nA: Crash     B: Leader    C: Follower\n|   m1  |    |   m1  |    |   m1  |\n|   m2  |    |   m2  |  > |   m2  |\n|   m3  |\n\n3. Send More messages\n\nA: Crash     B: Leader    C: Follower\n|   m1  |    |   m1  |    |   m1  |\n|   m2  |    |   m2  |    |   m2  |\n|   m3  |    |   m4  |  > |   m4  |\n             |   m5  |  > |   m5  |\n             |   m6  |  > |   m6  |\n\n4. A back to work, 之前commit到m1,Truncate m1之后的所有数据(这一步很重要),这个逻辑需要关注\nISR = {B, C}\n\nA: Folloer   B: Leader    C: Follower\n|   m1  |    |   m1  |    |   m1  |\n             |   m2  |    |   m2  |\n             |   m4  |  > |   m4  |\n             |   m5  |  > |   m5  |\n             |   m6  |  > |   m6  |\n\n5. A逐渐追上Leader\nISR = {A, B, C}\n\nA: Folloer   B: Leader    C: Follower\n|   m1  |    |   m1  |    |   m1  |\n|   m2  |  < |   m2  |    |   m2  |\n|   m4  |  < |   m4  |  > |   m4  |\n|   m5  |  < |   m5  |  > |   m5  |\n|   m6  |  < |   m6  |  > |   m6  |\n\n\n第4步中，A恢复后，是主动要truncate日志，还是新的Leader要求它去truncate日志？看下面的实现，貌似是follower会主动根据leader的epoch进行日志切割\n\n```\n/**\n    * - Truncate the log to the leader's offset for each partition's epoch.\n    * - If the leader's offset is greater, we stick with the Log End Offset\n    *   otherwise we truncate to the leaders offset.\n    * - If the leader replied with undefined epoch offset we must use the high watermark\n    */\n  override def maybeTruncate(fetchedEpochs: Map[TopicPartition, EpochEndOffset]): ResultWithPartitions[Map[TopicPartition, Long]] = {\n    val truncationPoints = scala.collection.mutable.HashMap.empty[TopicPartition, Long]\n    val partitionsWithError = mutable.Set[TopicPartition]()\n\n    fetchedEpochs.foreach { case (tp, epochOffset) =>\n      try {\n        val replica = replicaMgr.getReplicaOrException(tp)\n\n        if (epochOffset.hasError) {\n          info(s\"Retrying leaderEpoch request for partition ${replica.topicPartition} as the leader reported an error: ${epochOffset.error}\")\n          partitionsWithError += tp\n        } else {\n          val truncationOffset =\n            if (epochOffset.endOffset == UNDEFINED_EPOCH_OFFSET)\n              highWatermark(replica, epochOffset)\n            else if (epochOffset.endOffset >= replica.logEndOffset.messageOffset)\n              logEndOffset(replica, epochOffset)\n            else\n              epochOffset.endOffset\n\n          replicaMgr.logManager.truncateTo(Map(tp -> truncationOffset))\n          truncationPoints.put(tp, truncationOffset)\n        }\n      } catch {\n        case e: KafkaStorageException =>\n          info(s\"Failed to truncate $tp\", e)\n          partitionsWithError += tp\n      }\n    }\n\n    ResultWithPartitions(truncationPoints, partitionsWithError)\n  }\n```\n\n```\n查找当前leader_epoch的最后一个offset\noverride def endOffsetFor(requestedEpoch: Int): Long = {\n    inReadLock(lock) {\n      val offset =\n        if (requestedEpoch == UNDEFINED_EPOCH) {\n          // this may happen if a bootstrapping follower sends a request with undefined epoch or\n          // a follower is on the older message format where leader epochs are not recorded\n          UNDEFINED_EPOCH_OFFSET\n        } else if (requestedEpoch == latestEpoch) {\n          leo().messageOffset\n        } else {\n          val subsequentEpochs = epochs.filter(e => e.epoch > requestedEpoch)\n          if (subsequentEpochs.isEmpty || requestedEpoch < epochs.head.epoch)\n            UNDEFINED_EPOCH_OFFSET\n          else\n            subsequentEpochs.head.startOffset\n        }\n      debug(s\"Processed offset for epoch request for partition ${topicPartition} epoch:$requestedEpoch and returning offset $offset from epoch list of size ${epochs.size}\")\n      offset\n    }\n  }\n```\n\n### 生产的消息何时被commit\nproducer：acks=-1， broker： min.isr=2\n如果发送一条消息给leader，leader本地持久化，那需要等待至少一个除了自己之后的isr成功拉取到数据，并且给leader确认后，\nleader才会返回给producer，这条消息已经成功发送了。\n这个时候的high watermark为isr的最小LEO值，消费者最多只能看见这个值之前的消息。\n\n### num.standby.replicas\n如果本机的local state挂了，那么根据kafka的consume rebalance，会在另一台机器上恢复state，但是这个恢复时间\n可能会比较长，所以有num.standby.replicas这个参数，这个到底是什么意思？\n\n### kafka和RocketMQ设计导致得关键性差异——对多队列得支持程度\n\nhttp://blog.csdn.net/chunlongyu/article/details/54576649\n\n### 这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\n\n### 在没有Zookeeper的情况下使用Kafka吗？\n\n### 某一个(Topic, Partition)设置了3个Replica，分别在broker1, broker2, broker3上，对于每一个broker，它们的AR（assign replica）是一样的么？\nbroker1: Leader(1), AR(1, 2, 3)\nbroker2: Follower(2), AR(1, 2, 3)\nbroker3: Follower(3), AR(1, 2, 3)\n\n### Follower向Leader发送Fetch请求，HW是怎么在Follower和Leader之间传递的？\n\n### 什么叫某个(topic, partition)的Preferred Leader？\n(topic, partition)的AR中的第一个元素就是Preferred Leader。\n\n### 如果首选的副本不在ISR中会发生什么?\nBroker1: Leader(3), AR(1, 2, 3), ISR(2, 3)\n如果这样的情况是普遍情况，会导致Broker一定程度得数据倾斜。\n\n### 如果我指定了一个offset，Kafka怎么查找到对应的消息？\n\n### 如果我指定了一个timestamp，Kafka怎么查找到对应的消息？\n\n### Kafka的延时操作是怎么实现的？\n\n### Kafka中的Exactly-Once是怎么实现的？\n目前理解：每一个Producer配置一个producerId，对于同一个Producer，每一条发送的消息有一个自增的序列号，如果Broker收到同一个Producer发送了相同的两个序列号，那么就要把相同的那个序列号丢弃掉。\n\n// now that we have valid records, offsets assigned, and timestamps updated, we need to\n// validate the idempotent/transactional state of the producers and collect some metadata\nval (updatedProducers, completedTxns, maybeDuplicate) = analyzeAndValidateProducerState(validRecords, isFromClient)\nmaybeDuplicate.foreach { duplicate =>\n  appendInfo.firstOffset = duplicate.firstOffset\n  appendInfo.lastOffset = duplicate.lastOffset\n  appendInfo.logAppendTime = duplicate.timestamp\n  appendInfo.logStartOffset = logStartOffset\n  return appendInfo\n}\n\n### Kafka中的事务是怎么实现的？\n\n### Kafka如果需要拉取历史任务，怎么样解决Broker高Load问题？\nKafka本身有没有限流机制？\n\n### Kafka的consumer的心跳线程做什么事情？只是检测存活么？\n\n### Kafka vagrant搭建\nvagrant box add \\\nhttps://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/vagrant/trusty/current/trusty-server-cloudimg-amd64-vagrant-disk1.box \\\n--name ubuntu/trusty64\n\n### __consumer_offsets这个topic有什么特点？\n根据理解，说的越多越好\n1. compaction\n2. retention\n\n\n### kafka的消费者Offset是KV Map形式的，是怎么被维护在以List形式的__consumer_offsets上？\nhttps://www.jianshu.com/p/833b64e141f8\n\n### kafka在恢复kv结构的offset时，真的需要从头到尾进行遍历么？\nwhile (currOffset < highWaterMark && !shuttingDown.get()) {\n这一段是什么意思？\n\n### 消费者默认的消息事务隔离级别是什么？\n我怎么记得是 read-uncommitted\n```\n[2019-10-08 10:44:54,021] DEBUG [Consumer clientId=consumer-1, groupId=consumerGroup1] Added READ_UNCOMMITTED fetch request for partition krp-0 at offset 10 to node 172.16.115.163:9092 (id: 2 rack: null) (org.apache.kafka.clients.consumer.internals.Fetcher)\n```\n这个只针对事务消息，对一般的消息无效。\n\n### Kafka有没有类似于RocketMQ的ZeroCopy？\n是用到了，但是在哪里用到的？这里写得很清楚。\nhttps://www.jianshu.com/p/d47de3d6d8ac\n\nsendfile不是posix规范的api，要使用sendfile，在各个平台没有统一的规定，甚至连引入的头文件都没有做规范。\nFileChannelImpl.c\n\n#if defined(__linux__) || defined(__solaris__)\n#include <sys/sendfile.h>\n#elif defined(_AIX)\n#include <sys/socket.h>\n#elif defined(_ALLBSD_SOURCE)\n#include <sys/socket.h>\n#include <sys/uio.h>\n#define lseek64 lseek\n#define mmap64 mmap\n#endif\n\n### 原先的GroupCoordinator宕机了，kafka是怎么检测到并且将GroupCoordinator转移到另一台机器，然后恢复__consumer_offsets数据的？\nhttps://www.jianshu.com/p/833b64e141f8\n按照这个文章，好像说是在收到了 LeaderAndIsr的请求后？？？\n\n### 什么时候 「谁」 会调用 「谁」 的ApiKeys.LEADER_AND_ISR?\n在每个Partition(.scala)中，在每次expandIsr或者shrinkIsr时，都需要在zk(/isr_change_notification)上记录，以此来达到事件传播(propagate)的效果。\n```\ndef maybeExpandIsr(replicaId: Int, logReadResult: LogReadResult): Boolean = {\n  inWriteLock(leaderIsrUpdateLock) {\n    // check if this replica needs to be added to the ISR\n    leaderReplicaIfLocal match {\n      case Some(leaderReplica) =>\n          ...\n          // update ISR in ZK and cache\n          updateIsr(newInSyncReplicas)\n          ...\n        }\n        ...\n      case None => false // nothing to do if no longer leader\n    }\n  }\n}\n\ndef maybeShrinkIsr(replicaMaxLagTimeMs: Long) {\n  val leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) {\n    leaderReplicaIfLocal match {\n      case Some(leaderReplica) =>\n        val outOfSyncReplicas = getOutOfSyncReplicas(leaderReplica, replicaMaxLagTimeMs)\n        if(outOfSyncReplicas.nonEmpty) {\n          ...\n          // update ISR in zk and in cache\n          updateIsr(newInSyncReplicas)\n          ...\n        }\n\n      case None => false // do nothing if no longer leader\n    }\n  }\n\n  // some delayed operations may be unblocked after HW changed\n  if (leaderHWIncremented)\n    tryCompleteDelayedRequests()\n}\n\ndef recordIsrChange(topicPartition: TopicPartition) {\n  isrChangeSet synchronized {\n    isrChangeSet += topicPartition\n    lastIsrChangeMs.set(System.currentTimeMillis())\n  }\n}\n\ndef maybePropagateIsrChanges() {\n  val now = System.currentTimeMillis()\n  isrChangeSet synchronized {\n    if (isrChangeSet.nonEmpty &&\n      (lastIsrChangeMs.get() + ReplicaManager.IsrChangePropagationBlackOut < now ||\n        lastIsrPropagationMs.get() + ReplicaManager.IsrChangePropagationInterval < now)) {\n      ReplicationUtils.propagateIsrChanges(zkUtils, isrChangeSet)\n      isrChangeSet.clear()\n      lastIsrPropagationMs.set(now)\n    }\n  }\n}\n```\ncontroller在onControllerFailover的registerIsrChangeNotificationListener对上面的地址进行了监听。\n```\nprivate def registerIsrChangeNotificationListener() = {\n  debug(\"Registering IsrChangeNotificationListener\")\n  zkUtils.subscribeChildChanges(ZkUtils.IsrChangeNotificationPath, isrChangeNotificationListener)\n}\n```\n\n\n### Kafka中有哪些Coordinator?\n\n### Kafka怎么做集群迁移？\n\n### Kafka怎么做集群扩容？\n\n### Kafka怎么Topic迁移？\n\n### Kafka在数据倾斜的时候做数据平衡？\n\n### 集群中的哪一台机器会成为某一个Consumer Group的GroupCoordinator？\n// get metadata (and create the topic if necessary)\nval (partition, topicMetadata) = findCoordinatorRequest.coordinatorType match {\n  case FindCoordinatorRequest.CoordinatorType.GROUP =>\n    val partition = groupCoordinator.partitionFor(findCoordinatorRequest.coordinatorKey)\n    val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)\n    (partition, metadata)\n\n### Varint怎么能减少数据传输量？\nhttp://www.zdingke.com/2018/03/17/kafka/?falerm=x2psz2\nhttps://blog.csdn.net/u013256816/article/details/80300272\n```\n/**\n * Read an integer stored in variable-length format using zig-zag decoding from\n * <a href=\"http://code.google.com/apis/protocolbuffers/docs/encoding.html\"> Google Protocol Buffers</a>.\n *\n * @param buffer The buffer to read from\n * @return The integer read\n *\n * @throws IllegalArgumentException if variable-length value does not terminate after 5 bytes have been read\n */\npublic static int readVarint(ByteBuffer buffer) {\n    int value = 0;\n    int i = 0;\n    int b;\n    while (((b = buffer.get()) & 0x80) != 0) {\n        value |= (b & 0x7f) << i;\n        i += 7;\n        if (i > 28)\n            throw illegalVarintException(value);\n    }\n    value |= b << i;\n    return (value >>> 1) ^ -(value & 1);\n}\n\n/**\n * Write the given integer following the variable-length zig-zag encoding from\n * <a href=\"http://code.google.com/apis/protocolbuffers/docs/encoding.html\"> Google Protocol Buffers</a>\n * into the buffer.\n *\n * @param value The value to write\n * @param buffer The output to write to\n */\npublic static void writeVarint(int value, ByteBuffer buffer) {\n    int v = (value << 1) ^ (value >> 31);\n    while ((v & 0xffffff80) != 0L) {\n        byte b = (byte) ((v & 0x7f) | 0x80);\n        buffer.put(b);\n        v >>>= 7;\n    }\n    buffer.put((byte) v);\n}\n```\n\n### Kafka Rebalance 的时机是什么时候？ new KafkaConsumer() 后 还是 consumer.subscribe() 后?\n```\n在调用poll()中才开始Rebalance\n\nif (needRejoin()) {\n    // due to a race condition between the initial metadata fetch and the initial rebalance,\n    // we need to ensure that the metadata is fresh before joining initially. This ensures\n    // that we have matched the pattern against the cluster's topics at least once before joining.\n    if (subscriptions.hasPatternSubscription())\n        client.ensureFreshMetadata();\n\n    ensureActiveGroup();\n    now = time.milliseconds();\n}\n```\n\n### 如果某一ConsumerGroup的Consumer的数量发生变化，剩余的Consumer是如何检测到需要Rebalance了？\nRebalance的触发是在consumer的poll操作中\n是不是这段？\n```\n@Override\npublic boolean needRejoin() {\n    if (!subscriptions.partitionsAutoAssigned())\n        return false;\n\n    // we need to rejoin if we performed the assignment and metadata has changed\n    if (assignmentSnapshot != null && !assignmentSnapshot.equals(metadataSnapshot))\n        return true;\n\n    // we need to join if our subscription has changed since the last join\n    if (joinedSubscription != null && !joinedSubscription.equals(subscriptions.subscription()))\n        return true;\n\n    return super.needRejoin();\n}\n```\n\n### Kafka消费者Rebalance过程\n消费者查找GroupCoordinator\n消费者主动向GroupCoordinator发起JOIN\n作为GroupCoordinator的Broker接受到JOIN，选出一个Leader和epoch，给JOIN的成员发送响应\n下面应该怎么弄啊？？？？写不下去了\n\n\n这种方式的好处是，Rebalance的算法可以放在客户端，而不需要放在Broker端。\n\n\n```\n[2019-10-09 16:29:26,866] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Kafka consumer initialized (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-09 16:29:26,867] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Subscribed to topic(s): hermes.demo.pandc (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-09 16:29:26,867] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Sending FindCoordinator request to broker localhost:9091 (id: -1 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,026] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Initiating connection to node localhost:9091 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)\n...\n[2019-10-09 16:29:27,135] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Received FindCoordinator response ClientResponse(receivedTimeMs=1570609767134, latencyMs=118, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=172.16.115.163:9092 (id: 2 rack: null))) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,135] INFO [Consumer clientId=consumer-1, groupId=cg1] Discovered group coordinator 172.16.115.163:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,135] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Initiating connection to node 172.16.115.163:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.NetworkClient)\n[2019-10-09 16:29:27,137] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Heartbeat thread started (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,137] INFO [Consumer clientId=consumer-1, groupId=cg1] Revoking previously assigned partitions [] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-09 16:29:27,138] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Disabling heartbeat thread (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,138] INFO [Consumer clientId=consumer-1, groupId=cg1] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,141] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Sending JoinGroup ((type: JoinGroupRequest, groupId=cg1, sessionTimeout=10000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@23fe1d71)) to coordinator 172.16.115.163:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n...\n[2019-10-09 16:29:27,150] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@7403c468 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,150] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Performing assignment using strategy range with subscriptions {consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd=Subscription(topics=[hermes.demo.pandc])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-09 16:29:27,151] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Finished assignment for group: {consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd=Assignment(partitions=[hermes.demo.pandc-0, hermes.demo.pandc-1])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-09 16:29:27,152] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Sending leader SyncGroup to coordinator 172.16.115.163:9092 (id: 2147483645 rack: null): (type=SyncGroupRequest, groupId=cg1, generationId=13, memberId=consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd, groupAssignment=consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,156] INFO [Consumer clientId=consumer-1, groupId=cg1] Successfully joined group with generation 13 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,156] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Enabling heartbeat thread (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,157] INFO [Consumer clientId=consumer-1, groupId=cg1] Setting newly assigned partitions [hermes.demo.pandc-1, hermes.demo.pandc-0] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-09 16:29:27,157] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Fetching committed offsets for partitions: [hermes.demo.pandc-1, hermes.demo.pandc-0] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-09 16:29:27,159] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Resetting offset for partition hermes.demo.pandc-1 to the committed offset 5 (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-09 16:29:27,159] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Resetting offset for partition hermes.demo.pandc-0 to the committed offset 9 (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-09 16:29:27,160] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Added READ_UNCOMMITTED fetch request for partition hermes.demo.pandc-1 at offset 5 to node 172.16.115.163:9091 (id: 1 rack: null) (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-09 16:29:27,160] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Added READ_UNCOMMITTED fetch request for partition hermes.demo.pandc-0 at offset 9 to node 172.16.115.163:9091 (id: 1 rack: null) (org.apache.kafka.clients.consumer.internals.Fetcher)\n```\n\n\n### 异步发送后，回调是否会按照发送的真实顺序进行回调？\n我的印象是可以的\n\n\n### Kafka是否支持Long Polling\nhttps://www.jianshu.com/p/34dc83e90f98\n支持：\n/**\n * <code>fetch.max.wait.ms</code>\n */\npublic static final String FETCH_MAX_WAIT_MS_CONFIG = \"fetch.max.wait.ms\";\nprivate static final String FETCH_MAX_WAIT_MS_DOC = \"The maximum amount of time the server will block before answering the fetch request if there isn't sufficient data to immediately satisfy the requirement given by fetch.min.bytes.\";\n\n\n\n// probably unblock some follower fetch requests since log end offset has been updated\nreplicaManager.tryCompleteDelayedFetch(TopicPartitionOperationKey(this.topic, this.partitionId))\n\n从下面的代码来看，貌似是支持的。\nkafka.cluster.Partition#appendRecordsToLeader\n// some delayed operations may be unblocked after HW changed\nif (leaderHWIncremented)\n  tryCompleteDelayedRequests()\n\n/**\n   * Try to complete any pending requests. This should be called without holding the leaderIsrUpdateLock.\n   */\n  private def tryCompleteDelayedRequests() {\n    val requestKey = new TopicPartitionOperationKey(topicPartition)\n    replicaManager.tryCompleteDelayedFetch(requestKey)\n    replicaManager.tryCompleteDelayedProduce(requestKey)\n    replicaManager.tryCompleteDelayedDeleteRecords(requestKey)\n  }\n\n### 学习资料\nhttp://blog.csdn.net/chunlongyu/article/category/6638499\n\nhttp://blog.csdn.net/chunlongyu/article/details/54407633\n\nhttp://blog.csdn.net/a417930422/article/category/6086259\n\nhttp://blog.csdn.net/lizhitao\n\nhttp://www.cnblogs.com/huxi2b\n\nhttp://blog.csdn.net/u014393917/article/category/6332828\n\n阿里中间件团队博客 \nhttp://jm.taobao.org/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/\n\n\n第九课. Kafka高性能之道\n    9.1 顺序写磁盘\n    9.2 零拷贝\n    9.3 批处理\n    9.4 基于ISR的动态平衡一致性算法","source":"_posts/Kafka-FAQ.md","raw":"---\ntitle: Kafka-FAQ\ndate: 2017-11-17 15:33:16\ntags: Kafka\n---\n### 大量精品文章和面试问题\nhttps://blog.csdn.net/u013256816\n比较好的总结\nhttps://juejin.im/post/5ddf5659518825782d599641?utm_source=gold_browser_extension\n\n### Kafka发送怎么保证顺序？\n\n### Kafka异步发送能不能保证顺序？\n\n### Kafka能不能保证不丢消息（只要多数机器不挂）？\n\n### Kafka能不能保证消费顺序？\n\n### Kafka写CommitLog时用了什么锁机制?\n\nsync;lock-free;reentrant lock,用了哪一种？\n\nkafka.log.Log#append\nlock synchronized {\n}\n\n### Kafka生产者批量发送了消息，那Broker是把消息一条一存么？\n不是，是把几条连续的消息存在一起，在外层公用同一个offset\n\n### kafka消费者fetch的消息正好在某个批次中间的消息，怎么办？\n\n\n### Kafka Consumer Rebalance流程是怎么样的？\n1. Consumer查找GroupCoordinator，向它发送Join请求\n2. Broker收到Join请求后，创建一个Group，并且把创建的Consumer作为Consumer的Leader\n```\n// @ kafka.coordinator.group.GroupMetadata#add\ndef add(member: MemberMetadata) {\n  if (members.isEmpty)\n    this.protocolType = Some(member.protocolType)\n\n  assert(groupId == member.groupId)\n  assert(this.protocolType.orNull == member.protocolType)\n  assert(supportsProtocols(member.protocols))\n\n  if (leaderId.isEmpty)\n    leaderId = Some(member.memberId)\n  members.put(member.memberId, member)\n}\n```\n3. Broker并不会直接给发送Join请求的Consumer响应，而是会启动延时任务，等待一段时间，然后再给所有的Consumer响应\n```\n// @ kafka.coordinator.group.GroupCoordinator#prepareRebalance\nprivate def prepareRebalance(group: GroupMetadata) {\n  // if any members are awaiting sync, cancel their request and have them rejoin\n  if (group.is(AwaitingSync))\n    resetAndPropagateAssignmentError(group, Errors.REBALANCE_IN_PROGRESS)\n\n  val delayedRebalance = if (group.is(Empty))\n    new InitialDelayedJoin(this,\n      joinPurgatory,\n      group,\n      groupConfig.groupInitialRebalanceDelayMs,\n      groupConfig.groupInitialRebalanceDelayMs,\n      max(group.rebalanceTimeoutMs - groupConfig.groupInitialRebalanceDelayMs, 0))\n  else\n    new DelayedJoin(this, group, group.rebalanceTimeoutMs)\n\n  group.transitionTo(PreparingRebalance)\n\n  info(s\"Preparing to rebalance group ${group.groupId} with old generation ${group.generationId} \" +\n    s\"(${Topic.GROUP_METADATA_TOPIC_NAME}-${partitionFor(group.groupId)})\")\n\n  val groupKey = GroupKey(group.groupId)\n  joinPurgatory.tryCompleteElseWatch(delayedRebalance, Seq(groupKey))\n}\n```\n4. 各个Consumer收到来自Group coordinator的响应后，会查看自己是不是这个Consumer Group中的Consumer Leader\n```\n// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator.JoinGroupResponseHandler#handle\nAbstractCoordinator.this.generation = new Generation(joinResponse.generationId(),\n        joinResponse.memberId(), joinResponse.groupProtocol());\nif (joinResponse.isLeader()) {\n    onJoinLeader(joinResponse).chain(future);\n} else {\n    onJoinFollower().chain(future);\n}\n```\n5. 作为Leader的Consumer需要根据自己Rebalance算法，把rebalance的结果通过发送Sync请求反馈给Group Coordinator\n```\n// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator#onJoinLeader\nprivate RequestFuture<ByteBuffer> onJoinLeader(JoinGroupResponse joinResponse) {\n    try {\n        // perform the leader synchronization and send back the assignment for the group\n        Map<String, ByteBuffer> groupAssignment = performAssignment(joinResponse.leaderId(), joinResponse.groupProtocol(),\n                joinResponse.members());\n\n        SyncGroupRequest.Builder requestBuilder =\n                new SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId, groupAssignment);\n        log.debug(\"Sending leader SyncGroup to coordinator {}: {}\", this.coordinator, requestBuilder);\n        return sendSyncGroupRequest(requestBuilder);\n    } catch (RuntimeException e) {\n        return RequestFuture.failure(e);\n    }\n}\n```\n6. 而那些普通的Consumer也需要发送一个空的Sync请求\n```\n// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator#onJoinFollower\nprivate RequestFuture<ByteBuffer> onJoinFollower() {\n    // send follower's sync group with an empty assignment\n    SyncGroupRequest.Builder requestBuilder =\n            new SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId,\n                    Collections.<String, ByteBuffer>emptyMap());\n    log.debug(\"Sending follower SyncGroup to coordinator {}: {}\", this.coordinator, requestBuilder);\n    return sendSyncGroupRequest(requestBuilder);\n}\n```\n7. 所有的Consumer根据Sync请求的响应，更新自己的\n```\n// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator.SyncGroupResponseHandler#handle\nErrors error = syncResponse.error();\nif (error == Errors.NONE) {\n    sensors.syncLatency.record(response.requestLatencyMs());\n    future.complete(syncResponse.memberAssignment());\n}\n\n// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator#joinGroupIfNeeded\nvoid joinGroupIfNeeded() {\n    while (needRejoin() || rejoinIncomplete()) {\n        // ...\n\n        RequestFuture<ByteBuffer> future = initiateJoinGroup();\n        client.poll(future);\n\n        if (future.succeeded()) {\n            onJoinComplete(generation.generationId, generation.memberId, generation.protocol, future.value());\n\n            // We reset the join group future only after the completion callback returns. This ensures\n            // that if the callback is woken up, we will retry it on the next joinGroupIfNeeded.\n            resetJoinGroupFuture();\n            needsJoinPrepare = true;\n        } else {\n            // ...\n        }\n    }\n}\n\n// @ org.apache.kafka.clients.consumer.internals.ConsumerCoordinator#onJoinComplete\nprotected void onJoinComplete(int generation,\n                              String memberId,\n                              String assignmentStrategy,\n                              ByteBuffer assignmentBuffer) {\n    // ...\n    Assignment assignment = ConsumerProtocol.deserializeAssignment(assignmentBuffer);\n\n    // ...\n\n    // update partition assignment\n    subscriptions.assignFromSubscribed(assignment.partitions());\n\n    // ...\n}\n```\n\n### 怎么监控kafka page cache刷盘时间？\n\n\n### Kafka shallowOffset是什么意思？\n\n### Kafka的Retention是怎么工作的？不符合retention的日志什么时候会被清理掉？\n\n### Kafka发送者怎么保证是有序的？\nMAX_IN_FLIGHT_REQUESTS_PER_CONNECTION = 1， 为什么？\n不等于1的话，会有什么效果？\n\n### Consumer coordinator是什么？\n\n### Group coordinator是什么？\n\n### __consumer_offset的某一个partition挂了，kafka broker中的controller会给它选一个新的Leader，这个过程是怎么样的？\n\n### 怎么获取Kafka Consumer的Lag\n\n### Kafka是一个batch一压缩，还是一条消息一压缩？\n每一个消息都会压缩\n\n### Kafka是怎么实现幂等的？\nBroker以(producer, topic, partition)为维度，维护一份Map</*(producer, topic, partition)*/, /*sequence*/>，Producer每发送一条消息(好像是以Batch为单位的??)，都会将sequence++；如果同一个Producer对于某一个(topic, partition)发送了两个sequence一样的消息，后面发送的那个将被丢弃掉。\n实现原理：\n)Producer在初始化时，会向Broker申请一个ProducerId\n)Broker处理ProducerId申请请求，从序列段中申请一个唯一ID\n)Producer在发送消息时，会将加一的sequence发在消息体中，一起发送\n```\n// @ org.apache.kafka.clients.producer.internals.RecordAccumulator#drain\n\n// Additionally, we update the next sequence number bound for the partition,\n// and also have the transaction manager track the batch so as to ensure\n// that sequence ordering is maintained even if we receive out of order\n// responses.\nbatch.setProducerState(producerIdAndEpoch, transactionManager.sequenceNumber(batch.topicPartition), isTransactional);\n\n\n// @ org.apache.kafka.common.record.DefaultRecordBatch#incrementSequence\nstatic int incrementSequence(int baseSequence, int increment) {\n    if (baseSequence > Integer.MAX_VALUE - increment)\n        return increment - (Integer.MAX_VALUE - baseSequence) - 1;\n    return baseSequence + increment;\n}\n```\n)Broker如果收到了sequence一样的消息，丢弃后直接返回。\n```\n// @ \n// if this is a client produce request, there will be up to 5 batches which could have been duplicated.\n// If we find a duplicate, we return the metadata of the appended batch to the client.\nif (isFromClient) {\n  maybeLastEntry.flatMap(_.findDuplicateBatch(batch)).foreach { duplicate =>\n    return (updatedProducers, completedTxns.toList, Some(duplicate))\n  }\n}\n```\n\n\n### Kafka Consumer关闭后，怎么触发Rebalance？\n``` \n// @ org.apache.kafka.clients.consumer.internals.ConsumerCoordinator#needRejoin\npublic boolean needRejoin() {\n    if (!subscriptions.partitionsAutoAssigned())\n        return false;\n\n    // we need to rejoin if we performed the assignment and metadata has changed\n    if (assignmentSnapshot != null && !assignmentSnapshot.equals(metadataSnapshot))\n        return true;\n\n    // we need to join if our subscription has changed since the last join\n    if (joinedSubscription != null && !joinedSubscription.equals(subscriptions.subscription()))\n        return true;\n\n    return super.needRejoin();\n}\n```\n\n### Kafka创建Topic的过程，和我们想象中有点不一样\n1. 生成(topic, partition)replica的assignment\n```\ndef createTopic(zkUtils: ZkUtils,\n                topic: String,\n                partitions: Int,\n                replicationFactor: Int,\n                topicConfig: Properties = new Properties,\n                rackAwareMode: RackAwareMode = RackAwareMode.Enforced) {\n  val brokerMetadatas = getBrokerMetadatas(zkUtils, rackAwareMode)\n  val replicaAssignment = AdminUtils.assignReplicasToBrokers(brokerMetadatas, partitions, replicationFactor)\n  AdminUtils.createOrUpdateTopicPartitionAssignmentPathInZK(zkUtils, topic, replicaAssignment, topicConfig)\n}\n```\n2. 将生成的replica assignment写到ZK上\n```\n// create the partition assignment\nwriteTopicPartitionAssignment(zkUtils, topic, partitionReplicaAssignment, update)\n```\n3. Broker监听到这个ZK变化，然后开始调用状态机，使replica和topic上线\n```\ncase class TopicChange(topics: Set[String]) extends ControllerEvent {\n\n  def state = ControllerState.TopicChange\n\n  override def process(): Unit = {\n    if (!isActive) return\n    val newTopics = topics -- controllerContext.allTopics\n    val deletedTopics = controllerContext.allTopics -- topics\n    controllerContext.allTopics = topics\n\n    val addedPartitionReplicaAssignment = zkUtils.getReplicaAssignmentForTopics(newTopics.toSeq)\n    controllerContext.partitionReplicaAssignment = controllerContext.partitionReplicaAssignment.filter(p =>\n      !deletedTopics.contains(p._1.topic))\n    controllerContext.partitionReplicaAssignment.++=(addedPartitionReplicaAssignment)\n    info(\"New topics: [%s], deleted topics: [%s], new partition replica assignment [%s]\".format(newTopics,\n      deletedTopics, addedPartitionReplicaAssignment))\n    if (newTopics.nonEmpty)\n      onNewTopicCreation(newTopics, addedPartitionReplicaAssignment.keySet)\n  }\n}\n\n/**\n  * This callback is invoked by the topic change callback with the list of failed brokers as input.\n  * It does the following -\n  * 1. Move the newly created partitions to the NewPartition state\n  * 2. Move the newly created partitions from NewPartition->OnlinePartition state\n  */\ndef onNewPartitionCreation(newPartitions: Set[TopicAndPartition]) {\n  info(\"New partition creation callback for %s\".format(newPartitions.mkString(\",\")))\n  partitionStateMachine.handleStateChanges(newPartitions, NewPartition)\n  replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), NewReplica)\n  partitionStateMachine.handleStateChanges(newPartitions, OnlinePartition, offlinePartitionSelector)\n  replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), OnlineReplica)\n}\n```\n\n### Kafka的__consumer_offset一共有50个partition，那么我指定的某一个(topic, partition)的是被这50个__consumer_offset中的哪个管理的？\n```\ncase FindCoordinatorRequest.CoordinatorType.GROUP =>\n  val partition = groupCoordinator.partitionFor(findCoordinatorRequest.coordinatorKey)\n  val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)\n  (partition, metadata)\n```\nhttp://matt33.com/2017/10/22/consumer-join-group/\n\n### Kafka中有哪些功能是这样的模式：1. 修改ZK； 2. Broker监听到ZK变化； 3. Broker 根据ZK变化进行逻辑响应\n1. Topic创建时，replica的assignment\n2. Topic的Reassignment\n\n\n### Kafka Consumer消费流程\n1. rebalance\n2. 获取assign的(topic, partition)的消费位点\n3. \n\n### Kafka Broker在做\"Join Request\"处理时，需要等待一个timeout的时间，好让所有相关的consumer都能来得及join进来？这个是怎么实现的？\n```\nprivate def prepareRebalance(group: GroupMetadata) {\n  // if any members are awaiting sync, cancel their request and have them rejoin\n  if (group.is(AwaitingSync))\n    resetAndPropagateAssignmentError(group, Errors.REBALANCE_IN_PROGRESS)\n\n  val delayedRebalance = if (group.is(Empty))\n    new InitialDelayedJoin(this,\n      joinPurgatory,\n      group,\n      groupConfig.groupInitialRebalanceDelayMs,\n      groupConfig.groupInitialRebalanceDelayMs,\n      max(group.rebalanceTimeoutMs - groupConfig.groupInitialRebalanceDelayMs, 0))\n  else\n    new DelayedJoin(this, group, group.rebalanceTimeoutMs)\n\n  group.transitionTo(PreparingRebalance)\n\n  info(s\"Preparing to rebalance group ${group.groupId} with old generation ${group.generationId} \" +\n    s\"(${Topic.GROUP_METADATA_TOPIC_NAME}-${partitionFor(group.groupId)})\")\n\n  val groupKey = GroupKey(group.groupId)\n  joinPurgatory.tryCompleteElseWatch(delayedRebalance, Seq(groupKey))\n}\n```\n\n### 如果(topic, partiton)的leader在Broker3，Producer是怎么发送消息给Broker3的，是需要在启动的时候连接所有的Broker么？\n\n### 如果需要消费在Broker2上的（topic, partition），Consumer是怎么去连接Broker2的，Consumer会连接整个集群所有的Broker么？\n1. 先找GroupCoordinator，连接一台负载最低的机器，发送`Find Coordinator`命令\n```\nprotected synchronized RequestFuture<Void> lookupCoordinator() {\n    if (findCoordinatorFuture == null) {\n        // find a node to ask about the coordinator\n        Node node = this.client.leastLoadedNode();\n        if (node == null) {\n            log.debug(\"No broker available to send FindCoordinator request\");\n            return RequestFuture.noBrokersAvailable();\n        } else\n            findCoordinatorFuture = sendFindCoordinatorRequest(node);\n    }\n    return findCoordinatorFuture;\n}\n```\n\n### SkimpyOffsetMap 算是一个非常大的问题啊，万一消息被错误得compact怎么办呢？\n\n### 假如我手动提交消息的offset，现在我业务处理失败，那么我消费端不提交offset，那么Kafka会把这个消息怎么处理呀？后续消费端还是否能够消费到？\n\n\n### 当某一个Partition的Leader挂了，Controller会为其选出一个新的Leader，这时是ISR中随便选一个么？\n按照我的理解，应该是去选一个LEO最大的吧，完全错误\n请分析这段代码\n参考这篇：\nhttps://www.jianshu.com/p/13548893bf31\nhttp://ifeve.com/kafka-controller/\n\n真实日志\n```\nkafka1/controller.log:[2019-10-04 08:26:01,376] DEBUG [PartitionStateMachine controllerId=1] After leader election, leader cache for krp-0 is updated to (Leader:2,ISR:2,1,LeaderEpoch:1,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)\n➜  /tmp grep -R \": current leader =\" kafka*\nkafka1/controller.log:[2019-10-04 08:26:01,313] DEBUG [ControlledShutdownLeaderSelector]: Partition krp-0 : current leader = 3, new leader = 2 (kafka.controller.ControlledShutdownLeaderSelector)\n\n\nin kafka3/controller.log\n[2019-10-04 08:26:02,132] INFO [controller-event-thread]: Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)\n[2019-10-04 08:26:02,132] INFO [controller-event-thread]: Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)\n[2019-10-04 08:26:02,133] INFO [controller-event-thread]: Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)\n[2019-10-04 08:26:02,133] DEBUG [Controller id=3] Resigning (kafka.controller.KafkaController)\n[2019-10-04 08:26:02,133] DEBUG [Controller id=3] De-registering IsrChangeNotificationListener (kafka.controller.KafkaController)\n[2019-10-04 08:26:02,134] DEBUG [Controller id=3] De-registering logDirEventNotificationListener (kafka.controller.KafkaController)\n[2019-10-04 08:26:02,135] INFO [PartitionStateMachine controllerId=3] Stopped partition state machine (kafka.controller.PartitionStateMachine)\n[2019-10-04 08:26:02,136] INFO [ReplicaStateMachine controllerId=3] Stopped replica state machine (kafka.controller.ReplicaStateMachine)\n[2019-10-04 08:26:02,137] INFO [Controller id=3] Resigned (kafka.controller.KafkaController)\n\nin kafka1/controller.log\n[2019-10-04 08:26:01,300] INFO [Controller id=1] Shutting down broker 3 (kafka.controller.KafkaController)\n[2019-10-04 08:26:01,301] DEBUG [Controller id=1] All shutting down brokers: 3 (kafka.controller.KafkaController)\n[2019-10-04 08:26:01,302] DEBUG [Controller id=1] Live brokers: 1,2 (kafka.controller.KafkaController)\n[2019-10-04 08:26:01,308] INFO [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions krp-0 (kafka.controller.PartitionStateMachine)\n[2019-10-04 08:26:01,313] DEBUG [ControlledShutdownLeaderSelector]: Partition krp-0 : current leader = 3, new leader = 2 (kafka.controller.ControlledShutdownLeaderSelector)\n[2019-10-04 08:26:01,376] DEBUG [PartitionStateMachine controllerId=1] After leader election, leader cache for krp-0 is updated to (Leader:2,ISR:2,1,LeaderEpoch:1,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)\n\nin kafka1/state-change.log\nkafka1/state-change.log:[2019-10-04 08:26:01,376] TRACE [Controller id=1 epoch=1] Changed partition krp-0 from OnlinePartition to OnlinePartition with leader 2 (state.change.logger)\n```\nclass ControlledShutdownLeaderSelector(controllerContext: ControllerContext) extends PartitionLeaderSelector with Logging {\n\n  logIdent = \"[ControlledShutdownLeaderSelector]: \"\n\n  def selectLeader(topicAndPartition: TopicAndPartition,\n                   currentLeaderAndIsr: LeaderAndIsr): (LeaderAndIsr, Seq[Int]) = {\n    val currentIsr = currentLeaderAndIsr.isr\n    val assignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)\n    val liveAssignedReplicas = assignedReplicas.filter(r => controllerContext.isReplicaOnline(r, topicAndPartition, true))\n\n    val newIsr = currentIsr.filter(brokerId => !controllerContext.shuttingDownBrokerIds.contains(brokerId))\n    liveAssignedReplicas.find(newIsr.contains) match {\n      case Some(newLeader) =>\n        debug(s\"Partition $topicAndPartition : current leader = ${currentLeaderAndIsr.leader}, new leader = $newLeader\")\n        val newLeaderAndIsr = currentLeaderAndIsr.newLeaderAndIsr(newLeader, newIsr)\n        (newLeaderAndIsr, liveAssignedReplicas)\n      case None =>\n        throw new StateChangeFailedException(s\"No other replicas in ISR ${currentIsr.mkString(\",\")} for $topicAndPartition \" +\n          s\"besides shutting down brokers ${controllerContext.shuttingDownBrokerIds.mkString(\",\")}\")\n    }\n  }\n}\n\n\n### Consumer怎么去监控Rebalance事件？\n添加ConsumerRebalanceListener监听器\n\n### 为什么要引入epoch？\n这个KIP写得非常清楚。\n原先Truncate到HighWatermark处，但是这样做是有问题的，原因是Follower的HighWatermark是在消息存储后的下一轮RPC才获取到Leader的HighWatermark（Follower把消息接收后，然后发起FetchRPC告知Leader，Leader将自己的HighWatermark+1，这时Leader的返回值中含有最新的HighWatermark，但是如果这时Leader没有新的数据，这个Fetch请求就是一个长轮询请求，Follower将会延迟一段时间拿到最新的HighWatermark），这时如果Follower重启了，它将会把Leader已经确认过的HighWatermark对应的数据给Truncate掉。如果Leader这时也挂了，那么Follower将会成为新的Leader，中间的数据将会对消费者永久丢失。\n\nhttps://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation#KIP-101-AlterReplicationProtocoltouseLeaderEpochratherthanHighWatermarkforTruncation-Scenario1:HighWatermarkTruncationfollowedbyImmediateLeaderElection\n\n### 日志truncate是怎么一回事？\n\n1. ISR = {A, B, C}, HighWatermark = m1\n\nA: Leader    B: Follower  C: Follower\n|   m1  |    |   m1  |    |   m1  |\n|   m2  |    |   m2  |\n|   m3  |\n\n2. A Crashes, New Leader: B, Question:这里C有可能成为Leader么？\n\nA: Crash     B: Leader    C: Follower\n|   m1  |    |   m1  |    |   m1  |\n|   m2  |    |   m2  |  > |   m2  |\n|   m3  |\n\n3. Send More messages\n\nA: Crash     B: Leader    C: Follower\n|   m1  |    |   m1  |    |   m1  |\n|   m2  |    |   m2  |    |   m2  |\n|   m3  |    |   m4  |  > |   m4  |\n             |   m5  |  > |   m5  |\n             |   m6  |  > |   m6  |\n\n4. A back to work, 之前commit到m1,Truncate m1之后的所有数据(这一步很重要),这个逻辑需要关注\nISR = {B, C}\n\nA: Folloer   B: Leader    C: Follower\n|   m1  |    |   m1  |    |   m1  |\n             |   m2  |    |   m2  |\n             |   m4  |  > |   m4  |\n             |   m5  |  > |   m5  |\n             |   m6  |  > |   m6  |\n\n5. A逐渐追上Leader\nISR = {A, B, C}\n\nA: Folloer   B: Leader    C: Follower\n|   m1  |    |   m1  |    |   m1  |\n|   m2  |  < |   m2  |    |   m2  |\n|   m4  |  < |   m4  |  > |   m4  |\n|   m5  |  < |   m5  |  > |   m5  |\n|   m6  |  < |   m6  |  > |   m6  |\n\n\n第4步中，A恢复后，是主动要truncate日志，还是新的Leader要求它去truncate日志？看下面的实现，貌似是follower会主动根据leader的epoch进行日志切割\n\n```\n/**\n    * - Truncate the log to the leader's offset for each partition's epoch.\n    * - If the leader's offset is greater, we stick with the Log End Offset\n    *   otherwise we truncate to the leaders offset.\n    * - If the leader replied with undefined epoch offset we must use the high watermark\n    */\n  override def maybeTruncate(fetchedEpochs: Map[TopicPartition, EpochEndOffset]): ResultWithPartitions[Map[TopicPartition, Long]] = {\n    val truncationPoints = scala.collection.mutable.HashMap.empty[TopicPartition, Long]\n    val partitionsWithError = mutable.Set[TopicPartition]()\n\n    fetchedEpochs.foreach { case (tp, epochOffset) =>\n      try {\n        val replica = replicaMgr.getReplicaOrException(tp)\n\n        if (epochOffset.hasError) {\n          info(s\"Retrying leaderEpoch request for partition ${replica.topicPartition} as the leader reported an error: ${epochOffset.error}\")\n          partitionsWithError += tp\n        } else {\n          val truncationOffset =\n            if (epochOffset.endOffset == UNDEFINED_EPOCH_OFFSET)\n              highWatermark(replica, epochOffset)\n            else if (epochOffset.endOffset >= replica.logEndOffset.messageOffset)\n              logEndOffset(replica, epochOffset)\n            else\n              epochOffset.endOffset\n\n          replicaMgr.logManager.truncateTo(Map(tp -> truncationOffset))\n          truncationPoints.put(tp, truncationOffset)\n        }\n      } catch {\n        case e: KafkaStorageException =>\n          info(s\"Failed to truncate $tp\", e)\n          partitionsWithError += tp\n      }\n    }\n\n    ResultWithPartitions(truncationPoints, partitionsWithError)\n  }\n```\n\n```\n查找当前leader_epoch的最后一个offset\noverride def endOffsetFor(requestedEpoch: Int): Long = {\n    inReadLock(lock) {\n      val offset =\n        if (requestedEpoch == UNDEFINED_EPOCH) {\n          // this may happen if a bootstrapping follower sends a request with undefined epoch or\n          // a follower is on the older message format where leader epochs are not recorded\n          UNDEFINED_EPOCH_OFFSET\n        } else if (requestedEpoch == latestEpoch) {\n          leo().messageOffset\n        } else {\n          val subsequentEpochs = epochs.filter(e => e.epoch > requestedEpoch)\n          if (subsequentEpochs.isEmpty || requestedEpoch < epochs.head.epoch)\n            UNDEFINED_EPOCH_OFFSET\n          else\n            subsequentEpochs.head.startOffset\n        }\n      debug(s\"Processed offset for epoch request for partition ${topicPartition} epoch:$requestedEpoch and returning offset $offset from epoch list of size ${epochs.size}\")\n      offset\n    }\n  }\n```\n\n### 生产的消息何时被commit\nproducer：acks=-1， broker： min.isr=2\n如果发送一条消息给leader，leader本地持久化，那需要等待至少一个除了自己之后的isr成功拉取到数据，并且给leader确认后，\nleader才会返回给producer，这条消息已经成功发送了。\n这个时候的high watermark为isr的最小LEO值，消费者最多只能看见这个值之前的消息。\n\n### num.standby.replicas\n如果本机的local state挂了，那么根据kafka的consume rebalance，会在另一台机器上恢复state，但是这个恢复时间\n可能会比较长，所以有num.standby.replicas这个参数，这个到底是什么意思？\n\n### kafka和RocketMQ设计导致得关键性差异——对多队列得支持程度\n\nhttp://blog.csdn.net/chunlongyu/article/details/54576649\n\n### 这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\n\n### 在没有Zookeeper的情况下使用Kafka吗？\n\n### 某一个(Topic, Partition)设置了3个Replica，分别在broker1, broker2, broker3上，对于每一个broker，它们的AR（assign replica）是一样的么？\nbroker1: Leader(1), AR(1, 2, 3)\nbroker2: Follower(2), AR(1, 2, 3)\nbroker3: Follower(3), AR(1, 2, 3)\n\n### Follower向Leader发送Fetch请求，HW是怎么在Follower和Leader之间传递的？\n\n### 什么叫某个(topic, partition)的Preferred Leader？\n(topic, partition)的AR中的第一个元素就是Preferred Leader。\n\n### 如果首选的副本不在ISR中会发生什么?\nBroker1: Leader(3), AR(1, 2, 3), ISR(2, 3)\n如果这样的情况是普遍情况，会导致Broker一定程度得数据倾斜。\n\n### 如果我指定了一个offset，Kafka怎么查找到对应的消息？\n\n### 如果我指定了一个timestamp，Kafka怎么查找到对应的消息？\n\n### Kafka的延时操作是怎么实现的？\n\n### Kafka中的Exactly-Once是怎么实现的？\n目前理解：每一个Producer配置一个producerId，对于同一个Producer，每一条发送的消息有一个自增的序列号，如果Broker收到同一个Producer发送了相同的两个序列号，那么就要把相同的那个序列号丢弃掉。\n\n// now that we have valid records, offsets assigned, and timestamps updated, we need to\n// validate the idempotent/transactional state of the producers and collect some metadata\nval (updatedProducers, completedTxns, maybeDuplicate) = analyzeAndValidateProducerState(validRecords, isFromClient)\nmaybeDuplicate.foreach { duplicate =>\n  appendInfo.firstOffset = duplicate.firstOffset\n  appendInfo.lastOffset = duplicate.lastOffset\n  appendInfo.logAppendTime = duplicate.timestamp\n  appendInfo.logStartOffset = logStartOffset\n  return appendInfo\n}\n\n### Kafka中的事务是怎么实现的？\n\n### Kafka如果需要拉取历史任务，怎么样解决Broker高Load问题？\nKafka本身有没有限流机制？\n\n### Kafka的consumer的心跳线程做什么事情？只是检测存活么？\n\n### Kafka vagrant搭建\nvagrant box add \\\nhttps://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/vagrant/trusty/current/trusty-server-cloudimg-amd64-vagrant-disk1.box \\\n--name ubuntu/trusty64\n\n### __consumer_offsets这个topic有什么特点？\n根据理解，说的越多越好\n1. compaction\n2. retention\n\n\n### kafka的消费者Offset是KV Map形式的，是怎么被维护在以List形式的__consumer_offsets上？\nhttps://www.jianshu.com/p/833b64e141f8\n\n### kafka在恢复kv结构的offset时，真的需要从头到尾进行遍历么？\nwhile (currOffset < highWaterMark && !shuttingDown.get()) {\n这一段是什么意思？\n\n### 消费者默认的消息事务隔离级别是什么？\n我怎么记得是 read-uncommitted\n```\n[2019-10-08 10:44:54,021] DEBUG [Consumer clientId=consumer-1, groupId=consumerGroup1] Added READ_UNCOMMITTED fetch request for partition krp-0 at offset 10 to node 172.16.115.163:9092 (id: 2 rack: null) (org.apache.kafka.clients.consumer.internals.Fetcher)\n```\n这个只针对事务消息，对一般的消息无效。\n\n### Kafka有没有类似于RocketMQ的ZeroCopy？\n是用到了，但是在哪里用到的？这里写得很清楚。\nhttps://www.jianshu.com/p/d47de3d6d8ac\n\nsendfile不是posix规范的api，要使用sendfile，在各个平台没有统一的规定，甚至连引入的头文件都没有做规范。\nFileChannelImpl.c\n\n#if defined(__linux__) || defined(__solaris__)\n#include <sys/sendfile.h>\n#elif defined(_AIX)\n#include <sys/socket.h>\n#elif defined(_ALLBSD_SOURCE)\n#include <sys/socket.h>\n#include <sys/uio.h>\n#define lseek64 lseek\n#define mmap64 mmap\n#endif\n\n### 原先的GroupCoordinator宕机了，kafka是怎么检测到并且将GroupCoordinator转移到另一台机器，然后恢复__consumer_offsets数据的？\nhttps://www.jianshu.com/p/833b64e141f8\n按照这个文章，好像说是在收到了 LeaderAndIsr的请求后？？？\n\n### 什么时候 「谁」 会调用 「谁」 的ApiKeys.LEADER_AND_ISR?\n在每个Partition(.scala)中，在每次expandIsr或者shrinkIsr时，都需要在zk(/isr_change_notification)上记录，以此来达到事件传播(propagate)的效果。\n```\ndef maybeExpandIsr(replicaId: Int, logReadResult: LogReadResult): Boolean = {\n  inWriteLock(leaderIsrUpdateLock) {\n    // check if this replica needs to be added to the ISR\n    leaderReplicaIfLocal match {\n      case Some(leaderReplica) =>\n          ...\n          // update ISR in ZK and cache\n          updateIsr(newInSyncReplicas)\n          ...\n        }\n        ...\n      case None => false // nothing to do if no longer leader\n    }\n  }\n}\n\ndef maybeShrinkIsr(replicaMaxLagTimeMs: Long) {\n  val leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) {\n    leaderReplicaIfLocal match {\n      case Some(leaderReplica) =>\n        val outOfSyncReplicas = getOutOfSyncReplicas(leaderReplica, replicaMaxLagTimeMs)\n        if(outOfSyncReplicas.nonEmpty) {\n          ...\n          // update ISR in zk and in cache\n          updateIsr(newInSyncReplicas)\n          ...\n        }\n\n      case None => false // do nothing if no longer leader\n    }\n  }\n\n  // some delayed operations may be unblocked after HW changed\n  if (leaderHWIncremented)\n    tryCompleteDelayedRequests()\n}\n\ndef recordIsrChange(topicPartition: TopicPartition) {\n  isrChangeSet synchronized {\n    isrChangeSet += topicPartition\n    lastIsrChangeMs.set(System.currentTimeMillis())\n  }\n}\n\ndef maybePropagateIsrChanges() {\n  val now = System.currentTimeMillis()\n  isrChangeSet synchronized {\n    if (isrChangeSet.nonEmpty &&\n      (lastIsrChangeMs.get() + ReplicaManager.IsrChangePropagationBlackOut < now ||\n        lastIsrPropagationMs.get() + ReplicaManager.IsrChangePropagationInterval < now)) {\n      ReplicationUtils.propagateIsrChanges(zkUtils, isrChangeSet)\n      isrChangeSet.clear()\n      lastIsrPropagationMs.set(now)\n    }\n  }\n}\n```\ncontroller在onControllerFailover的registerIsrChangeNotificationListener对上面的地址进行了监听。\n```\nprivate def registerIsrChangeNotificationListener() = {\n  debug(\"Registering IsrChangeNotificationListener\")\n  zkUtils.subscribeChildChanges(ZkUtils.IsrChangeNotificationPath, isrChangeNotificationListener)\n}\n```\n\n\n### Kafka中有哪些Coordinator?\n\n### Kafka怎么做集群迁移？\n\n### Kafka怎么做集群扩容？\n\n### Kafka怎么Topic迁移？\n\n### Kafka在数据倾斜的时候做数据平衡？\n\n### 集群中的哪一台机器会成为某一个Consumer Group的GroupCoordinator？\n// get metadata (and create the topic if necessary)\nval (partition, topicMetadata) = findCoordinatorRequest.coordinatorType match {\n  case FindCoordinatorRequest.CoordinatorType.GROUP =>\n    val partition = groupCoordinator.partitionFor(findCoordinatorRequest.coordinatorKey)\n    val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)\n    (partition, metadata)\n\n### Varint怎么能减少数据传输量？\nhttp://www.zdingke.com/2018/03/17/kafka/?falerm=x2psz2\nhttps://blog.csdn.net/u013256816/article/details/80300272\n```\n/**\n * Read an integer stored in variable-length format using zig-zag decoding from\n * <a href=\"http://code.google.com/apis/protocolbuffers/docs/encoding.html\"> Google Protocol Buffers</a>.\n *\n * @param buffer The buffer to read from\n * @return The integer read\n *\n * @throws IllegalArgumentException if variable-length value does not terminate after 5 bytes have been read\n */\npublic static int readVarint(ByteBuffer buffer) {\n    int value = 0;\n    int i = 0;\n    int b;\n    while (((b = buffer.get()) & 0x80) != 0) {\n        value |= (b & 0x7f) << i;\n        i += 7;\n        if (i > 28)\n            throw illegalVarintException(value);\n    }\n    value |= b << i;\n    return (value >>> 1) ^ -(value & 1);\n}\n\n/**\n * Write the given integer following the variable-length zig-zag encoding from\n * <a href=\"http://code.google.com/apis/protocolbuffers/docs/encoding.html\"> Google Protocol Buffers</a>\n * into the buffer.\n *\n * @param value The value to write\n * @param buffer The output to write to\n */\npublic static void writeVarint(int value, ByteBuffer buffer) {\n    int v = (value << 1) ^ (value >> 31);\n    while ((v & 0xffffff80) != 0L) {\n        byte b = (byte) ((v & 0x7f) | 0x80);\n        buffer.put(b);\n        v >>>= 7;\n    }\n    buffer.put((byte) v);\n}\n```\n\n### Kafka Rebalance 的时机是什么时候？ new KafkaConsumer() 后 还是 consumer.subscribe() 后?\n```\n在调用poll()中才开始Rebalance\n\nif (needRejoin()) {\n    // due to a race condition between the initial metadata fetch and the initial rebalance,\n    // we need to ensure that the metadata is fresh before joining initially. This ensures\n    // that we have matched the pattern against the cluster's topics at least once before joining.\n    if (subscriptions.hasPatternSubscription())\n        client.ensureFreshMetadata();\n\n    ensureActiveGroup();\n    now = time.milliseconds();\n}\n```\n\n### 如果某一ConsumerGroup的Consumer的数量发生变化，剩余的Consumer是如何检测到需要Rebalance了？\nRebalance的触发是在consumer的poll操作中\n是不是这段？\n```\n@Override\npublic boolean needRejoin() {\n    if (!subscriptions.partitionsAutoAssigned())\n        return false;\n\n    // we need to rejoin if we performed the assignment and metadata has changed\n    if (assignmentSnapshot != null && !assignmentSnapshot.equals(metadataSnapshot))\n        return true;\n\n    // we need to join if our subscription has changed since the last join\n    if (joinedSubscription != null && !joinedSubscription.equals(subscriptions.subscription()))\n        return true;\n\n    return super.needRejoin();\n}\n```\n\n### Kafka消费者Rebalance过程\n消费者查找GroupCoordinator\n消费者主动向GroupCoordinator发起JOIN\n作为GroupCoordinator的Broker接受到JOIN，选出一个Leader和epoch，给JOIN的成员发送响应\n下面应该怎么弄啊？？？？写不下去了\n\n\n这种方式的好处是，Rebalance的算法可以放在客户端，而不需要放在Broker端。\n\n\n```\n[2019-10-09 16:29:26,866] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Kafka consumer initialized (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-09 16:29:26,867] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Subscribed to topic(s): hermes.demo.pandc (org.apache.kafka.clients.consumer.KafkaConsumer)\n[2019-10-09 16:29:26,867] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Sending FindCoordinator request to broker localhost:9091 (id: -1 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,026] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Initiating connection to node localhost:9091 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)\n...\n[2019-10-09 16:29:27,135] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Received FindCoordinator response ClientResponse(receivedTimeMs=1570609767134, latencyMs=118, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=172.16.115.163:9092 (id: 2 rack: null))) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,135] INFO [Consumer clientId=consumer-1, groupId=cg1] Discovered group coordinator 172.16.115.163:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,135] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Initiating connection to node 172.16.115.163:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.NetworkClient)\n[2019-10-09 16:29:27,137] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Heartbeat thread started (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,137] INFO [Consumer clientId=consumer-1, groupId=cg1] Revoking previously assigned partitions [] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-09 16:29:27,138] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Disabling heartbeat thread (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,138] INFO [Consumer clientId=consumer-1, groupId=cg1] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,141] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Sending JoinGroup ((type: JoinGroupRequest, groupId=cg1, sessionTimeout=10000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@23fe1d71)) to coordinator 172.16.115.163:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n...\n[2019-10-09 16:29:27,150] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@7403c468 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,150] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Performing assignment using strategy range with subscriptions {consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd=Subscription(topics=[hermes.demo.pandc])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-09 16:29:27,151] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Finished assignment for group: {consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd=Assignment(partitions=[hermes.demo.pandc-0, hermes.demo.pandc-1])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-09 16:29:27,152] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Sending leader SyncGroup to coordinator 172.16.115.163:9092 (id: 2147483645 rack: null): (type=SyncGroupRequest, groupId=cg1, generationId=13, memberId=consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd, groupAssignment=consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,156] INFO [Consumer clientId=consumer-1, groupId=cg1] Successfully joined group with generation 13 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,156] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Enabling heartbeat thread (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)\n[2019-10-09 16:29:27,157] INFO [Consumer clientId=consumer-1, groupId=cg1] Setting newly assigned partitions [hermes.demo.pandc-1, hermes.demo.pandc-0] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-09 16:29:27,157] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Fetching committed offsets for partitions: [hermes.demo.pandc-1, hermes.demo.pandc-0] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)\n[2019-10-09 16:29:27,159] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Resetting offset for partition hermes.demo.pandc-1 to the committed offset 5 (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-09 16:29:27,159] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Resetting offset for partition hermes.demo.pandc-0 to the committed offset 9 (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-09 16:29:27,160] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Added READ_UNCOMMITTED fetch request for partition hermes.demo.pandc-1 at offset 5 to node 172.16.115.163:9091 (id: 1 rack: null) (org.apache.kafka.clients.consumer.internals.Fetcher)\n[2019-10-09 16:29:27,160] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Added READ_UNCOMMITTED fetch request for partition hermes.demo.pandc-0 at offset 9 to node 172.16.115.163:9091 (id: 1 rack: null) (org.apache.kafka.clients.consumer.internals.Fetcher)\n```\n\n\n### 异步发送后，回调是否会按照发送的真实顺序进行回调？\n我的印象是可以的\n\n\n### Kafka是否支持Long Polling\nhttps://www.jianshu.com/p/34dc83e90f98\n支持：\n/**\n * <code>fetch.max.wait.ms</code>\n */\npublic static final String FETCH_MAX_WAIT_MS_CONFIG = \"fetch.max.wait.ms\";\nprivate static final String FETCH_MAX_WAIT_MS_DOC = \"The maximum amount of time the server will block before answering the fetch request if there isn't sufficient data to immediately satisfy the requirement given by fetch.min.bytes.\";\n\n\n\n// probably unblock some follower fetch requests since log end offset has been updated\nreplicaManager.tryCompleteDelayedFetch(TopicPartitionOperationKey(this.topic, this.partitionId))\n\n从下面的代码来看，貌似是支持的。\nkafka.cluster.Partition#appendRecordsToLeader\n// some delayed operations may be unblocked after HW changed\nif (leaderHWIncremented)\n  tryCompleteDelayedRequests()\n\n/**\n   * Try to complete any pending requests. This should be called without holding the leaderIsrUpdateLock.\n   */\n  private def tryCompleteDelayedRequests() {\n    val requestKey = new TopicPartitionOperationKey(topicPartition)\n    replicaManager.tryCompleteDelayedFetch(requestKey)\n    replicaManager.tryCompleteDelayedProduce(requestKey)\n    replicaManager.tryCompleteDelayedDeleteRecords(requestKey)\n  }\n\n### 学习资料\nhttp://blog.csdn.net/chunlongyu/article/category/6638499\n\nhttp://blog.csdn.net/chunlongyu/article/details/54407633\n\nhttp://blog.csdn.net/a417930422/article/category/6086259\n\nhttp://blog.csdn.net/lizhitao\n\nhttp://www.cnblogs.com/huxi2b\n\nhttp://blog.csdn.net/u014393917/article/category/6332828\n\n阿里中间件团队博客 \nhttp://jm.taobao.org/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/\n\n\n第九课. Kafka高性能之道\n    9.1 顺序写磁盘\n    9.2 零拷贝\n    9.3 批处理\n    9.4 基于ISR的动态平衡一致性算法","slug":"Kafka-FAQ","published":1,"updated":"2019-12-02T10:03:14.224Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83n002sv1npphr8n3jh","content":"<h3 id=\"大量精品文章和面试问题\"><a href=\"#大量精品文章和面试问题\" class=\"headerlink\" title=\"大量精品文章和面试问题\"></a>大量精品文章和面试问题</h3><p><a href=\"https://blog.csdn.net/u013256816\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u013256816</a><br>比较好的总结<br><a href=\"https://juejin.im/post/5ddf5659518825782d599641?utm_source=gold_browser_extension\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5ddf5659518825782d599641?utm_source=gold_browser_extension</a></p>\n<h3 id=\"Kafka发送怎么保证顺序？\"><a href=\"#Kafka发送怎么保证顺序？\" class=\"headerlink\" title=\"Kafka发送怎么保证顺序？\"></a>Kafka发送怎么保证顺序？</h3><h3 id=\"Kafka异步发送能不能保证顺序？\"><a href=\"#Kafka异步发送能不能保证顺序？\" class=\"headerlink\" title=\"Kafka异步发送能不能保证顺序？\"></a>Kafka异步发送能不能保证顺序？</h3><h3 id=\"Kafka能不能保证不丢消息（只要多数机器不挂）？\"><a href=\"#Kafka能不能保证不丢消息（只要多数机器不挂）？\" class=\"headerlink\" title=\"Kafka能不能保证不丢消息（只要多数机器不挂）？\"></a>Kafka能不能保证不丢消息（只要多数机器不挂）？</h3><h3 id=\"Kafka能不能保证消费顺序？\"><a href=\"#Kafka能不能保证消费顺序？\" class=\"headerlink\" title=\"Kafka能不能保证消费顺序？\"></a>Kafka能不能保证消费顺序？</h3><h3 id=\"Kafka写CommitLog时用了什么锁机制\"><a href=\"#Kafka写CommitLog时用了什么锁机制\" class=\"headerlink\" title=\"Kafka写CommitLog时用了什么锁机制?\"></a>Kafka写CommitLog时用了什么锁机制?</h3><p>sync;lock-free;reentrant lock,用了哪一种？</p>\n<p>kafka.log.Log#append<br>lock synchronized {<br>}</p>\n<h3 id=\"Kafka生产者批量发送了消息，那Broker是把消息一条一存么？\"><a href=\"#Kafka生产者批量发送了消息，那Broker是把消息一条一存么？\" class=\"headerlink\" title=\"Kafka生产者批量发送了消息，那Broker是把消息一条一存么？\"></a>Kafka生产者批量发送了消息，那Broker是把消息一条一存么？</h3><p>不是，是把几条连续的消息存在一起，在外层公用同一个offset</p>\n<h3 id=\"kafka消费者fetch的消息正好在某个批次中间的消息，怎么办？\"><a href=\"#kafka消费者fetch的消息正好在某个批次中间的消息，怎么办？\" class=\"headerlink\" title=\"kafka消费者fetch的消息正好在某个批次中间的消息，怎么办？\"></a>kafka消费者fetch的消息正好在某个批次中间的消息，怎么办？</h3><h3 id=\"Kafka-Consumer-Rebalance流程是怎么样的？\"><a href=\"#Kafka-Consumer-Rebalance流程是怎么样的？\" class=\"headerlink\" title=\"Kafka Consumer Rebalance流程是怎么样的？\"></a>Kafka Consumer Rebalance流程是怎么样的？</h3><ol>\n<li><p>Consumer查找GroupCoordinator，向它发送Join请求</p>\n</li>\n<li><p>Broker收到Join请求后，创建一个Group，并且把创建的Consumer作为Consumer的Leader</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ kafka.coordinator.group.GroupMetadata#add</span><br><span class=\"line\">def add(member: MemberMetadata) &#123;</span><br><span class=\"line\">  if (members.isEmpty)</span><br><span class=\"line\">    this.protocolType = Some(member.protocolType)</span><br><span class=\"line\"></span><br><span class=\"line\">  assert(groupId == member.groupId)</span><br><span class=\"line\">  assert(this.protocolType.orNull == member.protocolType)</span><br><span class=\"line\">  assert(supportsProtocols(member.protocols))</span><br><span class=\"line\"></span><br><span class=\"line\">  if (leaderId.isEmpty)</span><br><span class=\"line\">    leaderId = Some(member.memberId)</span><br><span class=\"line\">  members.put(member.memberId, member)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Broker并不会直接给发送Join请求的Consumer响应，而是会启动延时任务，等待一段时间，然后再给所有的Consumer响应</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ kafka.coordinator.group.GroupCoordinator#prepareRebalance</span><br><span class=\"line\">private def prepareRebalance(group: GroupMetadata) &#123;</span><br><span class=\"line\">  // if any members are awaiting sync, cancel their request and have them rejoin</span><br><span class=\"line\">  if (group.is(AwaitingSync))</span><br><span class=\"line\">    resetAndPropagateAssignmentError(group, Errors.REBALANCE_IN_PROGRESS)</span><br><span class=\"line\"></span><br><span class=\"line\">  val delayedRebalance = if (group.is(Empty))</span><br><span class=\"line\">    new InitialDelayedJoin(this,</span><br><span class=\"line\">      joinPurgatory,</span><br><span class=\"line\">      group,</span><br><span class=\"line\">      groupConfig.groupInitialRebalanceDelayMs,</span><br><span class=\"line\">      groupConfig.groupInitialRebalanceDelayMs,</span><br><span class=\"line\">      max(group.rebalanceTimeoutMs - groupConfig.groupInitialRebalanceDelayMs, 0))</span><br><span class=\"line\">  else</span><br><span class=\"line\">    new DelayedJoin(this, group, group.rebalanceTimeoutMs)</span><br><span class=\"line\"></span><br><span class=\"line\">  group.transitionTo(PreparingRebalance)</span><br><span class=\"line\"></span><br><span class=\"line\">  info(s&quot;Preparing to rebalance group $&#123;group.groupId&#125; with old generation $&#123;group.generationId&#125; &quot; +</span><br><span class=\"line\">    s&quot;($&#123;Topic.GROUP_METADATA_TOPIC_NAME&#125;-$&#123;partitionFor(group.groupId)&#125;)&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">  val groupKey = GroupKey(group.groupId)</span><br><span class=\"line\">  joinPurgatory.tryCompleteElseWatch(delayedRebalance, Seq(groupKey))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>各个Consumer收到来自Group coordinator的响应后，会查看自己是不是这个Consumer Group中的Consumer Leader</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator.JoinGroupResponseHandler#handle</span><br><span class=\"line\">AbstractCoordinator.this.generation = new Generation(joinResponse.generationId(),</span><br><span class=\"line\">        joinResponse.memberId(), joinResponse.groupProtocol());</span><br><span class=\"line\">if (joinResponse.isLeader()) &#123;</span><br><span class=\"line\">    onJoinLeader(joinResponse).chain(future);</span><br><span class=\"line\">&#125; else &#123;</span><br><span class=\"line\">    onJoinFollower().chain(future);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>作为Leader的Consumer需要根据自己Rebalance算法，把rebalance的结果通过发送Sync请求反馈给Group Coordinator</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator#onJoinLeader</span><br><span class=\"line\">private RequestFuture&lt;ByteBuffer&gt; onJoinLeader(JoinGroupResponse joinResponse) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        // perform the leader synchronization and send back the assignment for the group</span><br><span class=\"line\">        Map&lt;String, ByteBuffer&gt; groupAssignment = performAssignment(joinResponse.leaderId(), joinResponse.groupProtocol(),</span><br><span class=\"line\">                joinResponse.members());</span><br><span class=\"line\"></span><br><span class=\"line\">        SyncGroupRequest.Builder requestBuilder =</span><br><span class=\"line\">                new SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId, groupAssignment);</span><br><span class=\"line\">        log.debug(&quot;Sending leader SyncGroup to coordinator &#123;&#125;: &#123;&#125;&quot;, this.coordinator, requestBuilder);</span><br><span class=\"line\">        return sendSyncGroupRequest(requestBuilder);</span><br><span class=\"line\">    &#125; catch (RuntimeException e) &#123;</span><br><span class=\"line\">        return RequestFuture.failure(e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>而那些普通的Consumer也需要发送一个空的Sync请求</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator#onJoinFollower</span><br><span class=\"line\">private RequestFuture&lt;ByteBuffer&gt; onJoinFollower() &#123;</span><br><span class=\"line\">    // send follower&apos;s sync group with an empty assignment</span><br><span class=\"line\">    SyncGroupRequest.Builder requestBuilder =</span><br><span class=\"line\">            new SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId,</span><br><span class=\"line\">                    Collections.&lt;String, ByteBuffer&gt;emptyMap());</span><br><span class=\"line\">    log.debug(&quot;Sending follower SyncGroup to coordinator &#123;&#125;: &#123;&#125;&quot;, this.coordinator, requestBuilder);</span><br><span class=\"line\">    return sendSyncGroupRequest(requestBuilder);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>所有的Consumer根据Sync请求的响应，更新自己的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator.SyncGroupResponseHandler#handle</span><br><span class=\"line\">Errors error = syncResponse.error();</span><br><span class=\"line\">if (error == Errors.NONE) &#123;</span><br><span class=\"line\">    sensors.syncLatency.record(response.requestLatencyMs());</span><br><span class=\"line\">    future.complete(syncResponse.memberAssignment());</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator#joinGroupIfNeeded</span><br><span class=\"line\">void joinGroupIfNeeded() &#123;</span><br><span class=\"line\">    while (needRejoin() || rejoinIncomplete()) &#123;</span><br><span class=\"line\">        // ...</span><br><span class=\"line\"></span><br><span class=\"line\">        RequestFuture&lt;ByteBuffer&gt; future = initiateJoinGroup();</span><br><span class=\"line\">        client.poll(future);</span><br><span class=\"line\"></span><br><span class=\"line\">        if (future.succeeded()) &#123;</span><br><span class=\"line\">            onJoinComplete(generation.generationId, generation.memberId, generation.protocol, future.value());</span><br><span class=\"line\"></span><br><span class=\"line\">            // We reset the join group future only after the completion callback returns. This ensures</span><br><span class=\"line\">            // that if the callback is woken up, we will retry it on the next joinGroupIfNeeded.</span><br><span class=\"line\">            resetJoinGroupFuture();</span><br><span class=\"line\">            needsJoinPrepare = true;</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            // ...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.ConsumerCoordinator#onJoinComplete</span><br><span class=\"line\">protected void onJoinComplete(int generation,</span><br><span class=\"line\">                              String memberId,</span><br><span class=\"line\">                              String assignmentStrategy,</span><br><span class=\"line\">                              ByteBuffer assignmentBuffer) &#123;</span><br><span class=\"line\">    // ...</span><br><span class=\"line\">    Assignment assignment = ConsumerProtocol.deserializeAssignment(assignmentBuffer);</span><br><span class=\"line\"></span><br><span class=\"line\">    // ...</span><br><span class=\"line\"></span><br><span class=\"line\">    // update partition assignment</span><br><span class=\"line\">    subscriptions.assignFromSubscribed(assignment.partitions());</span><br><span class=\"line\"></span><br><span class=\"line\">    // ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<h3 id=\"怎么监控kafka-page-cache刷盘时间？\"><a href=\"#怎么监控kafka-page-cache刷盘时间？\" class=\"headerlink\" title=\"怎么监控kafka page cache刷盘时间？\"></a>怎么监控kafka page cache刷盘时间？</h3><h3 id=\"Kafka-shallowOffset是什么意思？\"><a href=\"#Kafka-shallowOffset是什么意思？\" class=\"headerlink\" title=\"Kafka shallowOffset是什么意思？\"></a>Kafka shallowOffset是什么意思？</h3><h3 id=\"Kafka的Retention是怎么工作的？不符合retention的日志什么时候会被清理掉？\"><a href=\"#Kafka的Retention是怎么工作的？不符合retention的日志什么时候会被清理掉？\" class=\"headerlink\" title=\"Kafka的Retention是怎么工作的？不符合retention的日志什么时候会被清理掉？\"></a>Kafka的Retention是怎么工作的？不符合retention的日志什么时候会被清理掉？</h3><h3 id=\"Kafka发送者怎么保证是有序的？\"><a href=\"#Kafka发送者怎么保证是有序的？\" class=\"headerlink\" title=\"Kafka发送者怎么保证是有序的？\"></a>Kafka发送者怎么保证是有序的？</h3><p>MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION = 1， 为什么？<br>不等于1的话，会有什么效果？</p>\n<h3 id=\"Consumer-coordinator是什么？\"><a href=\"#Consumer-coordinator是什么？\" class=\"headerlink\" title=\"Consumer coordinator是什么？\"></a>Consumer coordinator是什么？</h3><h3 id=\"Group-coordinator是什么？\"><a href=\"#Group-coordinator是什么？\" class=\"headerlink\" title=\"Group coordinator是什么？\"></a>Group coordinator是什么？</h3><h3 id=\"consumer-offset的某一个partition挂了，kafka-broker中的controller会给它选一个新的Leader，这个过程是怎么样的？\"><a href=\"#consumer-offset的某一个partition挂了，kafka-broker中的controller会给它选一个新的Leader，这个过程是怎么样的？\" class=\"headerlink\" title=\"__consumer_offset的某一个partition挂了，kafka broker中的controller会给它选一个新的Leader，这个过程是怎么样的？\"></a>__consumer_offset的某一个partition挂了，kafka broker中的controller会给它选一个新的Leader，这个过程是怎么样的？</h3><h3 id=\"怎么获取Kafka-Consumer的Lag\"><a href=\"#怎么获取Kafka-Consumer的Lag\" class=\"headerlink\" title=\"怎么获取Kafka Consumer的Lag\"></a>怎么获取Kafka Consumer的Lag</h3><h3 id=\"Kafka是一个batch一压缩，还是一条消息一压缩？\"><a href=\"#Kafka是一个batch一压缩，还是一条消息一压缩？\" class=\"headerlink\" title=\"Kafka是一个batch一压缩，还是一条消息一压缩？\"></a>Kafka是一个batch一压缩，还是一条消息一压缩？</h3><p>每一个消息都会压缩</p>\n<h3 id=\"Kafka是怎么实现幂等的？\"><a href=\"#Kafka是怎么实现幂等的？\" class=\"headerlink\" title=\"Kafka是怎么实现幂等的？\"></a>Kafka是怎么实现幂等的？</h3><p>Broker以(producer, topic, partition)为维度，维护一份Map&lt;/<em>(producer, topic, partition)</em>/, /<em>sequence</em>/&gt;，Producer每发送一条消息(好像是以Batch为单位的??)，都会将sequence++；如果同一个Producer对于某一个(topic, partition)发送了两个sequence一样的消息，后面发送的那个将被丢弃掉。<br>实现原理：<br>)Producer在初始化时，会向Broker申请一个ProducerId<br>)Broker处理ProducerId申请请求，从序列段中申请一个唯一ID<br>)Producer在发送消息时，会将加一的sequence发在消息体中，一起发送</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ org.apache.kafka.clients.producer.internals.RecordAccumulator#drain</span><br><span class=\"line\"></span><br><span class=\"line\">// Additionally, we update the next sequence number bound for the partition,</span><br><span class=\"line\">// and also have the transaction manager track the batch so as to ensure</span><br><span class=\"line\">// that sequence ordering is maintained even if we receive out of order</span><br><span class=\"line\">// responses.</span><br><span class=\"line\">batch.setProducerState(producerIdAndEpoch, transactionManager.sequenceNumber(batch.topicPartition), isTransactional);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">// @ org.apache.kafka.common.record.DefaultRecordBatch#incrementSequence</span><br><span class=\"line\">static int incrementSequence(int baseSequence, int increment) &#123;</span><br><span class=\"line\">    if (baseSequence &gt; Integer.MAX_VALUE - increment)</span><br><span class=\"line\">        return increment - (Integer.MAX_VALUE - baseSequence) - 1;</span><br><span class=\"line\">    return baseSequence + increment;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>)Broker如果收到了sequence一样的消息，丢弃后直接返回。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ </span><br><span class=\"line\">// if this is a client produce request, there will be up to 5 batches which could have been duplicated.</span><br><span class=\"line\">// If we find a duplicate, we return the metadata of the appended batch to the client.</span><br><span class=\"line\">if (isFromClient) &#123;</span><br><span class=\"line\">  maybeLastEntry.flatMap(_.findDuplicateBatch(batch)).foreach &#123; duplicate =&gt;</span><br><span class=\"line\">    return (updatedProducers, completedTxns.toList, Some(duplicate))</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Kafka-Consumer关闭后，怎么触发Rebalance？\"><a href=\"#Kafka-Consumer关闭后，怎么触发Rebalance？\" class=\"headerlink\" title=\"Kafka Consumer关闭后，怎么触发Rebalance？\"></a>Kafka Consumer关闭后，怎么触发Rebalance？</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.ConsumerCoordinator#needRejoin</span><br><span class=\"line\">public boolean needRejoin() &#123;</span><br><span class=\"line\">    if (!subscriptions.partitionsAutoAssigned())</span><br><span class=\"line\">        return false;</span><br><span class=\"line\"></span><br><span class=\"line\">    // we need to rejoin if we performed the assignment and metadata has changed</span><br><span class=\"line\">    if (assignmentSnapshot != null &amp;&amp; !assignmentSnapshot.equals(metadataSnapshot))</span><br><span class=\"line\">        return true;</span><br><span class=\"line\"></span><br><span class=\"line\">    // we need to join if our subscription has changed since the last join</span><br><span class=\"line\">    if (joinedSubscription != null &amp;&amp; !joinedSubscription.equals(subscriptions.subscription()))</span><br><span class=\"line\">        return true;</span><br><span class=\"line\"></span><br><span class=\"line\">    return super.needRejoin();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Kafka创建Topic的过程，和我们想象中有点不一样\"><a href=\"#Kafka创建Topic的过程，和我们想象中有点不一样\" class=\"headerlink\" title=\"Kafka创建Topic的过程，和我们想象中有点不一样\"></a>Kafka创建Topic的过程，和我们想象中有点不一样</h3><ol>\n<li><p>生成(topic, partition)replica的assignment</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def createTopic(zkUtils: ZkUtils,</span><br><span class=\"line\">                topic: String,</span><br><span class=\"line\">                partitions: Int,</span><br><span class=\"line\">                replicationFactor: Int,</span><br><span class=\"line\">                topicConfig: Properties = new Properties,</span><br><span class=\"line\">                rackAwareMode: RackAwareMode = RackAwareMode.Enforced) &#123;</span><br><span class=\"line\">  val brokerMetadatas = getBrokerMetadatas(zkUtils, rackAwareMode)</span><br><span class=\"line\">  val replicaAssignment = AdminUtils.assignReplicasToBrokers(brokerMetadatas, partitions, replicationFactor)</span><br><span class=\"line\">  AdminUtils.createOrUpdateTopicPartitionAssignmentPathInZK(zkUtils, topic, replicaAssignment, topicConfig)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>将生成的replica assignment写到ZK上</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// create the partition assignment</span><br><span class=\"line\">writeTopicPartitionAssignment(zkUtils, topic, partitionReplicaAssignment, update)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Broker监听到这个ZK变化，然后开始调用状态机，使replica和topic上线</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case class TopicChange(topics: Set[String]) extends ControllerEvent &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  def state = ControllerState.TopicChange</span><br><span class=\"line\"></span><br><span class=\"line\">  override def process(): Unit = &#123;</span><br><span class=\"line\">    if (!isActive) return</span><br><span class=\"line\">    val newTopics = topics -- controllerContext.allTopics</span><br><span class=\"line\">    val deletedTopics = controllerContext.allTopics -- topics</span><br><span class=\"line\">    controllerContext.allTopics = topics</span><br><span class=\"line\"></span><br><span class=\"line\">    val addedPartitionReplicaAssignment = zkUtils.getReplicaAssignmentForTopics(newTopics.toSeq)</span><br><span class=\"line\">    controllerContext.partitionReplicaAssignment = controllerContext.partitionReplicaAssignment.filter(p =&gt;</span><br><span class=\"line\">      !deletedTopics.contains(p._1.topic))</span><br><span class=\"line\">    controllerContext.partitionReplicaAssignment.++=(addedPartitionReplicaAssignment)</span><br><span class=\"line\">    info(&quot;New topics: [%s], deleted topics: [%s], new partition replica assignment [%s]&quot;.format(newTopics,</span><br><span class=\"line\">      deletedTopics, addedPartitionReplicaAssignment))</span><br><span class=\"line\">    if (newTopics.nonEmpty)</span><br><span class=\"line\">      onNewTopicCreation(newTopics, addedPartitionReplicaAssignment.keySet)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/**</span><br><span class=\"line\">  * This callback is invoked by the topic change callback with the list of failed brokers as input.</span><br><span class=\"line\">  * It does the following -</span><br><span class=\"line\">  * 1. Move the newly created partitions to the NewPartition state</span><br><span class=\"line\">  * 2. Move the newly created partitions from NewPartition-&gt;OnlinePartition state</span><br><span class=\"line\">  */</span><br><span class=\"line\">def onNewPartitionCreation(newPartitions: Set[TopicAndPartition]) &#123;</span><br><span class=\"line\">  info(&quot;New partition creation callback for %s&quot;.format(newPartitions.mkString(&quot;,&quot;)))</span><br><span class=\"line\">  partitionStateMachine.handleStateChanges(newPartitions, NewPartition)</span><br><span class=\"line\">  replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), NewReplica)</span><br><span class=\"line\">  partitionStateMachine.handleStateChanges(newPartitions, OnlinePartition, offlinePartitionSelector)</span><br><span class=\"line\">  replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), OnlineReplica)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<h3 id=\"Kafka的consumer-offset一共有50个partition，那么我指定的某一个-topic-partition-的是被这50个consumer-offset中的哪个管理的？\"><a href=\"#Kafka的consumer-offset一共有50个partition，那么我指定的某一个-topic-partition-的是被这50个consumer-offset中的哪个管理的？\" class=\"headerlink\" title=\"Kafka的consumer_offset一共有50个partition，那么我指定的某一个(topic, partition)的是被这50个consumer_offset中的哪个管理的？\"></a>Kafka的<strong>consumer_offset一共有50个partition，那么我指定的某一个(topic, partition)的是被这50个</strong>consumer_offset中的哪个管理的？</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case FindCoordinatorRequest.CoordinatorType.GROUP =&gt;</span><br><span class=\"line\">  val partition = groupCoordinator.partitionFor(findCoordinatorRequest.coordinatorKey)</span><br><span class=\"line\">  val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)</span><br><span class=\"line\">  (partition, metadata)</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"http://matt33.com/2017/10/22/consumer-join-group/\" target=\"_blank\" rel=\"noopener\">http://matt33.com/2017/10/22/consumer-join-group/</a></p>\n<h3 id=\"Kafka中有哪些功能是这样的模式：1-修改ZK；-2-Broker监听到ZK变化；-3-Broker-根据ZK变化进行逻辑响应\"><a href=\"#Kafka中有哪些功能是这样的模式：1-修改ZK；-2-Broker监听到ZK变化；-3-Broker-根据ZK变化进行逻辑响应\" class=\"headerlink\" title=\"Kafka中有哪些功能是这样的模式：1. 修改ZK； 2. Broker监听到ZK变化； 3. Broker 根据ZK变化进行逻辑响应\"></a>Kafka中有哪些功能是这样的模式：1. 修改ZK； 2. Broker监听到ZK变化； 3. Broker 根据ZK变化进行逻辑响应</h3><ol>\n<li>Topic创建时，replica的assignment</li>\n<li>Topic的Reassignment</li>\n</ol>\n<h3 id=\"Kafka-Consumer消费流程\"><a href=\"#Kafka-Consumer消费流程\" class=\"headerlink\" title=\"Kafka Consumer消费流程\"></a>Kafka Consumer消费流程</h3><ol>\n<li>rebalance</li>\n<li>获取assign的(topic, partition)的消费位点</li>\n<li></li>\n</ol>\n<h3 id=\"Kafka-Broker在做”Join-Request”处理时，需要等待一个timeout的时间，好让所有相关的consumer都能来得及join进来？这个是怎么实现的？\"><a href=\"#Kafka-Broker在做”Join-Request”处理时，需要等待一个timeout的时间，好让所有相关的consumer都能来得及join进来？这个是怎么实现的？\" class=\"headerlink\" title=\"Kafka Broker在做”Join Request”处理时，需要等待一个timeout的时间，好让所有相关的consumer都能来得及join进来？这个是怎么实现的？\"></a>Kafka Broker在做”Join Request”处理时，需要等待一个timeout的时间，好让所有相关的consumer都能来得及join进来？这个是怎么实现的？</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private def prepareRebalance(group: GroupMetadata) &#123;</span><br><span class=\"line\">  // if any members are awaiting sync, cancel their request and have them rejoin</span><br><span class=\"line\">  if (group.is(AwaitingSync))</span><br><span class=\"line\">    resetAndPropagateAssignmentError(group, Errors.REBALANCE_IN_PROGRESS)</span><br><span class=\"line\"></span><br><span class=\"line\">  val delayedRebalance = if (group.is(Empty))</span><br><span class=\"line\">    new InitialDelayedJoin(this,</span><br><span class=\"line\">      joinPurgatory,</span><br><span class=\"line\">      group,</span><br><span class=\"line\">      groupConfig.groupInitialRebalanceDelayMs,</span><br><span class=\"line\">      groupConfig.groupInitialRebalanceDelayMs,</span><br><span class=\"line\">      max(group.rebalanceTimeoutMs - groupConfig.groupInitialRebalanceDelayMs, 0))</span><br><span class=\"line\">  else</span><br><span class=\"line\">    new DelayedJoin(this, group, group.rebalanceTimeoutMs)</span><br><span class=\"line\"></span><br><span class=\"line\">  group.transitionTo(PreparingRebalance)</span><br><span class=\"line\"></span><br><span class=\"line\">  info(s&quot;Preparing to rebalance group $&#123;group.groupId&#125; with old generation $&#123;group.generationId&#125; &quot; +</span><br><span class=\"line\">    s&quot;($&#123;Topic.GROUP_METADATA_TOPIC_NAME&#125;-$&#123;partitionFor(group.groupId)&#125;)&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">  val groupKey = GroupKey(group.groupId)</span><br><span class=\"line\">  joinPurgatory.tryCompleteElseWatch(delayedRebalance, Seq(groupKey))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"如果-topic-partiton-的leader在Broker3，Producer是怎么发送消息给Broker3的，是需要在启动的时候连接所有的Broker么？\"><a href=\"#如果-topic-partiton-的leader在Broker3，Producer是怎么发送消息给Broker3的，是需要在启动的时候连接所有的Broker么？\" class=\"headerlink\" title=\"如果(topic, partiton)的leader在Broker3，Producer是怎么发送消息给Broker3的，是需要在启动的时候连接所有的Broker么？\"></a>如果(topic, partiton)的leader在Broker3，Producer是怎么发送消息给Broker3的，是需要在启动的时候连接所有的Broker么？</h3><h3 id=\"如果需要消费在Broker2上的（topic-partition），Consumer是怎么去连接Broker2的，Consumer会连接整个集群所有的Broker么？\"><a href=\"#如果需要消费在Broker2上的（topic-partition），Consumer是怎么去连接Broker2的，Consumer会连接整个集群所有的Broker么？\" class=\"headerlink\" title=\"如果需要消费在Broker2上的（topic, partition），Consumer是怎么去连接Broker2的，Consumer会连接整个集群所有的Broker么？\"></a>如果需要消费在Broker2上的（topic, partition），Consumer是怎么去连接Broker2的，Consumer会连接整个集群所有的Broker么？</h3><ol>\n<li>先找GroupCoordinator，连接一台负载最低的机器，发送<code>Find Coordinator</code>命令<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected synchronized RequestFuture&lt;Void&gt; lookupCoordinator() &#123;</span><br><span class=\"line\">    if (findCoordinatorFuture == null) &#123;</span><br><span class=\"line\">        // find a node to ask about the coordinator</span><br><span class=\"line\">        Node node = this.client.leastLoadedNode();</span><br><span class=\"line\">        if (node == null) &#123;</span><br><span class=\"line\">            log.debug(&quot;No broker available to send FindCoordinator request&quot;);</span><br><span class=\"line\">            return RequestFuture.noBrokersAvailable();</span><br><span class=\"line\">        &#125; else</span><br><span class=\"line\">            findCoordinatorFuture = sendFindCoordinatorRequest(node);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return findCoordinatorFuture;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<h3 id=\"SkimpyOffsetMap-算是一个非常大的问题啊，万一消息被错误得compact怎么办呢？\"><a href=\"#SkimpyOffsetMap-算是一个非常大的问题啊，万一消息被错误得compact怎么办呢？\" class=\"headerlink\" title=\"SkimpyOffsetMap 算是一个非常大的问题啊，万一消息被错误得compact怎么办呢？\"></a>SkimpyOffsetMap 算是一个非常大的问题啊，万一消息被错误得compact怎么办呢？</h3><h3 id=\"假如我手动提交消息的offset，现在我业务处理失败，那么我消费端不提交offset，那么Kafka会把这个消息怎么处理呀？后续消费端还是否能够消费到？\"><a href=\"#假如我手动提交消息的offset，现在我业务处理失败，那么我消费端不提交offset，那么Kafka会把这个消息怎么处理呀？后续消费端还是否能够消费到？\" class=\"headerlink\" title=\"假如我手动提交消息的offset，现在我业务处理失败，那么我消费端不提交offset，那么Kafka会把这个消息怎么处理呀？后续消费端还是否能够消费到？\"></a>假如我手动提交消息的offset，现在我业务处理失败，那么我消费端不提交offset，那么Kafka会把这个消息怎么处理呀？后续消费端还是否能够消费到？</h3><h3 id=\"当某一个Partition的Leader挂了，Controller会为其选出一个新的Leader，这时是ISR中随便选一个么？\"><a href=\"#当某一个Partition的Leader挂了，Controller会为其选出一个新的Leader，这时是ISR中随便选一个么？\" class=\"headerlink\" title=\"当某一个Partition的Leader挂了，Controller会为其选出一个新的Leader，这时是ISR中随便选一个么？\"></a>当某一个Partition的Leader挂了，Controller会为其选出一个新的Leader，这时是ISR中随便选一个么？</h3><p>按照我的理解，应该是去选一个LEO最大的吧，完全错误<br>请分析这段代码<br>参考这篇：<br><a href=\"https://www.jianshu.com/p/13548893bf31\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/13548893bf31</a><br><a href=\"http://ifeve.com/kafka-controller/\" target=\"_blank\" rel=\"noopener\">http://ifeve.com/kafka-controller/</a></p>\n<p>真实日志</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kafka1/controller.log:[2019-10-04 08:26:01,376] DEBUG [PartitionStateMachine controllerId=1] After leader election, leader cache for krp-0 is updated to (Leader:2,ISR:2,1,LeaderEpoch:1,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)</span><br><span class=\"line\">➜  /tmp grep -R &quot;: current leader =&quot; kafka*</span><br><span class=\"line\">kafka1/controller.log:[2019-10-04 08:26:01,313] DEBUG [ControlledShutdownLeaderSelector]: Partition krp-0 : current leader = 3, new leader = 2 (kafka.controller.ControlledShutdownLeaderSelector)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">in kafka3/controller.log</span><br><span class=\"line\">[2019-10-04 08:26:02,132] INFO [controller-event-thread]: Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)</span><br><span class=\"line\">[2019-10-04 08:26:02,132] INFO [controller-event-thread]: Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)</span><br><span class=\"line\">[2019-10-04 08:26:02,133] INFO [controller-event-thread]: Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)</span><br><span class=\"line\">[2019-10-04 08:26:02,133] DEBUG [Controller id=3] Resigning (kafka.controller.KafkaController)</span><br><span class=\"line\">[2019-10-04 08:26:02,133] DEBUG [Controller id=3] De-registering IsrChangeNotificationListener (kafka.controller.KafkaController)</span><br><span class=\"line\">[2019-10-04 08:26:02,134] DEBUG [Controller id=3] De-registering logDirEventNotificationListener (kafka.controller.KafkaController)</span><br><span class=\"line\">[2019-10-04 08:26:02,135] INFO [PartitionStateMachine controllerId=3] Stopped partition state machine (kafka.controller.PartitionStateMachine)</span><br><span class=\"line\">[2019-10-04 08:26:02,136] INFO [ReplicaStateMachine controllerId=3] Stopped replica state machine (kafka.controller.ReplicaStateMachine)</span><br><span class=\"line\">[2019-10-04 08:26:02,137] INFO [Controller id=3] Resigned (kafka.controller.KafkaController)</span><br><span class=\"line\"></span><br><span class=\"line\">in kafka1/controller.log</span><br><span class=\"line\">[2019-10-04 08:26:01,300] INFO [Controller id=1] Shutting down broker 3 (kafka.controller.KafkaController)</span><br><span class=\"line\">[2019-10-04 08:26:01,301] DEBUG [Controller id=1] All shutting down brokers: 3 (kafka.controller.KafkaController)</span><br><span class=\"line\">[2019-10-04 08:26:01,302] DEBUG [Controller id=1] Live brokers: 1,2 (kafka.controller.KafkaController)</span><br><span class=\"line\">[2019-10-04 08:26:01,308] INFO [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions krp-0 (kafka.controller.PartitionStateMachine)</span><br><span class=\"line\">[2019-10-04 08:26:01,313] DEBUG [ControlledShutdownLeaderSelector]: Partition krp-0 : current leader = 3, new leader = 2 (kafka.controller.ControlledShutdownLeaderSelector)</span><br><span class=\"line\">[2019-10-04 08:26:01,376] DEBUG [PartitionStateMachine controllerId=1] After leader election, leader cache for krp-0 is updated to (Leader:2,ISR:2,1,LeaderEpoch:1,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)</span><br><span class=\"line\"></span><br><span class=\"line\">in kafka1/state-change.log</span><br><span class=\"line\">kafka1/state-change.log:[2019-10-04 08:26:01,376] TRACE [Controller id=1 epoch=1] Changed partition krp-0 from OnlinePartition to OnlinePartition with leader 2 (state.change.logger)</span><br></pre></td></tr></table></figure>\n\n<p>class ControlledShutdownLeaderSelector(controllerContext: ControllerContext) extends PartitionLeaderSelector with Logging {</p>\n<p>  logIdent = “[ControlledShutdownLeaderSelector]: “</p>\n<p>  def selectLeader(topicAndPartition: TopicAndPartition,<br>                   currentLeaderAndIsr: LeaderAndIsr): (LeaderAndIsr, Seq[Int]) = {<br>    val currentIsr = currentLeaderAndIsr.isr<br>    val assignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)<br>    val liveAssignedReplicas = assignedReplicas.filter(r =&gt; controllerContext.isReplicaOnline(r, topicAndPartition, true))</p>\n<pre><code>val newIsr = currentIsr.filter(brokerId =&gt; !controllerContext.shuttingDownBrokerIds.contains(brokerId))\nliveAssignedReplicas.find(newIsr.contains) match {\n  case Some(newLeader) =&gt;\n    debug(s&quot;Partition $topicAndPartition : current leader = ${currentLeaderAndIsr.leader}, new leader = $newLeader&quot;)\n    val newLeaderAndIsr = currentLeaderAndIsr.newLeaderAndIsr(newLeader, newIsr)\n    (newLeaderAndIsr, liveAssignedReplicas)\n  case None =&gt;\n    throw new StateChangeFailedException(s&quot;No other replicas in ISR ${currentIsr.mkString(&quot;,&quot;)} for $topicAndPartition &quot; +\n      s&quot;besides shutting down brokers ${controllerContext.shuttingDownBrokerIds.mkString(&quot;,&quot;)}&quot;)\n}</code></pre><p>  }<br>}</p>\n<h3 id=\"Consumer怎么去监控Rebalance事件？\"><a href=\"#Consumer怎么去监控Rebalance事件？\" class=\"headerlink\" title=\"Consumer怎么去监控Rebalance事件？\"></a>Consumer怎么去监控Rebalance事件？</h3><p>添加ConsumerRebalanceListener监听器</p>\n<h3 id=\"为什么要引入epoch？\"><a href=\"#为什么要引入epoch？\" class=\"headerlink\" title=\"为什么要引入epoch？\"></a>为什么要引入epoch？</h3><p>这个KIP写得非常清楚。<br>原先Truncate到HighWatermark处，但是这样做是有问题的，原因是Follower的HighWatermark是在消息存储后的下一轮RPC才获取到Leader的HighWatermark（Follower把消息接收后，然后发起FetchRPC告知Leader，Leader将自己的HighWatermark+1，这时Leader的返回值中含有最新的HighWatermark，但是如果这时Leader没有新的数据，这个Fetch请求就是一个长轮询请求，Follower将会延迟一段时间拿到最新的HighWatermark），这时如果Follower重启了，它将会把Leader已经确认过的HighWatermark对应的数据给Truncate掉。如果Leader这时也挂了，那么Follower将会成为新的Leader，中间的数据将会对消费者永久丢失。</p>\n<p><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation#KIP-101-AlterReplicationProtocoltouseLeaderEpochratherthanHighWatermarkforTruncation-Scenario1:HighWatermarkTruncationfollowedbyImmediateLeaderElection\" target=\"_blank\" rel=\"noopener\">https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation#KIP-101-AlterReplicationProtocoltouseLeaderEpochratherthanHighWatermarkforTruncation-Scenario1:HighWatermarkTruncationfollowedbyImmediateLeaderElection</a></p>\n<h3 id=\"日志truncate是怎么一回事？\"><a href=\"#日志truncate是怎么一回事？\" class=\"headerlink\" title=\"日志truncate是怎么一回事？\"></a>日志truncate是怎么一回事？</h3><ol>\n<li>ISR = {A, B, C}, HighWatermark = m1</li>\n</ol>\n<p>A: Leader    B: Follower  C: Follower<br>|   m1  |    |   m1  |    |   m1  |<br>|   m2  |    |   m2  |<br>|   m3  |</p>\n<ol start=\"2\">\n<li>A Crashes, New Leader: B, Question:这里C有可能成为Leader么？</li>\n</ol>\n<p>A: Crash     B: Leader    C: Follower<br>|   m1  |    |   m1  |    |   m1  |<br>|   m2  |    |   m2  |  &gt; |   m2  |<br>|   m3  |</p>\n<ol start=\"3\">\n<li>Send More messages</li>\n</ol>\n<p>A: Crash     B: Leader    C: Follower<br>|   m1  |    |   m1  |    |   m1  |<br>|   m2  |    |   m2  |    |   m2  |<br>|   m3  |    |   m4  |  &gt; |   m4  |<br>             |   m5  |  &gt; |   m5  |<br>             |   m6  |  &gt; |   m6  |</p>\n<ol start=\"4\">\n<li>A back to work, 之前commit到m1,Truncate m1之后的所有数据(这一步很重要),这个逻辑需要关注<br>ISR = {B, C}</li>\n</ol>\n<p>A: Folloer   B: Leader    C: Follower<br>|   m1  |    |   m1  |    |   m1  |<br>             |   m2  |    |   m2  |<br>             |   m4  |  &gt; |   m4  |<br>             |   m5  |  &gt; |   m5  |<br>             |   m6  |  &gt; |   m6  |</p>\n<ol start=\"5\">\n<li>A逐渐追上Leader<br>ISR = {A, B, C}</li>\n</ol>\n<p>A: Folloer   B: Leader    C: Follower<br>|   m1  |    |   m1  |    |   m1  |<br>|   m2  |  &lt; |   m2  |    |   m2  |<br>|   m4  |  &lt; |   m4  |  &gt; |   m4  |<br>|   m5  |  &lt; |   m5  |  &gt; |   m5  |<br>|   m6  |  &lt; |   m6  |  &gt; |   m6  |</p>\n<p>第4步中，A恢复后，是主动要truncate日志，还是新的Leader要求它去truncate日志？看下面的实现，貌似是follower会主动根据leader的epoch进行日志切割</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\">    * - Truncate the log to the leader&apos;s offset for each partition&apos;s epoch.</span><br><span class=\"line\">    * - If the leader&apos;s offset is greater, we stick with the Log End Offset</span><br><span class=\"line\">    *   otherwise we truncate to the leaders offset.</span><br><span class=\"line\">    * - If the leader replied with undefined epoch offset we must use the high watermark</span><br><span class=\"line\">    */</span><br><span class=\"line\">  override def maybeTruncate(fetchedEpochs: Map[TopicPartition, EpochEndOffset]): ResultWithPartitions[Map[TopicPartition, Long]] = &#123;</span><br><span class=\"line\">    val truncationPoints = scala.collection.mutable.HashMap.empty[TopicPartition, Long]</span><br><span class=\"line\">    val partitionsWithError = mutable.Set[TopicPartition]()</span><br><span class=\"line\"></span><br><span class=\"line\">    fetchedEpochs.foreach &#123; case (tp, epochOffset) =&gt;</span><br><span class=\"line\">      try &#123;</span><br><span class=\"line\">        val replica = replicaMgr.getReplicaOrException(tp)</span><br><span class=\"line\"></span><br><span class=\"line\">        if (epochOffset.hasError) &#123;</span><br><span class=\"line\">          info(s&quot;Retrying leaderEpoch request for partition $&#123;replica.topicPartition&#125; as the leader reported an error: $&#123;epochOffset.error&#125;&quot;)</span><br><span class=\"line\">          partitionsWithError += tp</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">          val truncationOffset =</span><br><span class=\"line\">            if (epochOffset.endOffset == UNDEFINED_EPOCH_OFFSET)</span><br><span class=\"line\">              highWatermark(replica, epochOffset)</span><br><span class=\"line\">            else if (epochOffset.endOffset &gt;= replica.logEndOffset.messageOffset)</span><br><span class=\"line\">              logEndOffset(replica, epochOffset)</span><br><span class=\"line\">            else</span><br><span class=\"line\">              epochOffset.endOffset</span><br><span class=\"line\"></span><br><span class=\"line\">          replicaMgr.logManager.truncateTo(Map(tp -&gt; truncationOffset))</span><br><span class=\"line\">          truncationPoints.put(tp, truncationOffset)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125; catch &#123;</span><br><span class=\"line\">        case e: KafkaStorageException =&gt;</span><br><span class=\"line\">          info(s&quot;Failed to truncate $tp&quot;, e)</span><br><span class=\"line\">          partitionsWithError += tp</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    ResultWithPartitions(truncationPoints, partitionsWithError)</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">查找当前leader_epoch的最后一个offset</span><br><span class=\"line\">override def endOffsetFor(requestedEpoch: Int): Long = &#123;</span><br><span class=\"line\">    inReadLock(lock) &#123;</span><br><span class=\"line\">      val offset =</span><br><span class=\"line\">        if (requestedEpoch == UNDEFINED_EPOCH) &#123;</span><br><span class=\"line\">          // this may happen if a bootstrapping follower sends a request with undefined epoch or</span><br><span class=\"line\">          // a follower is on the older message format where leader epochs are not recorded</span><br><span class=\"line\">          UNDEFINED_EPOCH_OFFSET</span><br><span class=\"line\">        &#125; else if (requestedEpoch == latestEpoch) &#123;</span><br><span class=\"line\">          leo().messageOffset</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">          val subsequentEpochs = epochs.filter(e =&gt; e.epoch &gt; requestedEpoch)</span><br><span class=\"line\">          if (subsequentEpochs.isEmpty || requestedEpoch &lt; epochs.head.epoch)</span><br><span class=\"line\">            UNDEFINED_EPOCH_OFFSET</span><br><span class=\"line\">          else</span><br><span class=\"line\">            subsequentEpochs.head.startOffset</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      debug(s&quot;Processed offset for epoch request for partition $&#123;topicPartition&#125; epoch:$requestedEpoch and returning offset $offset from epoch list of size $&#123;epochs.size&#125;&quot;)</span><br><span class=\"line\">      offset</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"生产的消息何时被commit\"><a href=\"#生产的消息何时被commit\" class=\"headerlink\" title=\"生产的消息何时被commit\"></a>生产的消息何时被commit</h3><p>producer：acks=-1， broker： min.isr=2<br>如果发送一条消息给leader，leader本地持久化，那需要等待至少一个除了自己之后的isr成功拉取到数据，并且给leader确认后，<br>leader才会返回给producer，这条消息已经成功发送了。<br>这个时候的high watermark为isr的最小LEO值，消费者最多只能看见这个值之前的消息。</p>\n<h3 id=\"num-standby-replicas\"><a href=\"#num-standby-replicas\" class=\"headerlink\" title=\"num.standby.replicas\"></a>num.standby.replicas</h3><p>如果本机的local state挂了，那么根据kafka的consume rebalance，会在另一台机器上恢复state，但是这个恢复时间<br>可能会比较长，所以有num.standby.replicas这个参数，这个到底是什么意思？</p>\n<h3 id=\"kafka和RocketMQ设计导致得关键性差异——对多队列得支持程度\"><a href=\"#kafka和RocketMQ设计导致得关键性差异——对多队列得支持程度\" class=\"headerlink\" title=\"kafka和RocketMQ设计导致得关键性差异——对多队列得支持程度\"></a>kafka和RocketMQ设计导致得关键性差异——对多队列得支持程度</h3><p><a href=\"http://blog.csdn.net/chunlongyu/article/details/54576649\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/chunlongyu/article/details/54576649</a></p>\n<h3 id=\"这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\"><a href=\"#这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\" class=\"headerlink\" title=\"这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\"></a>这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？</h3><h3 id=\"在没有Zookeeper的情况下使用Kafka吗？\"><a href=\"#在没有Zookeeper的情况下使用Kafka吗？\" class=\"headerlink\" title=\"在没有Zookeeper的情况下使用Kafka吗？\"></a>在没有Zookeeper的情况下使用Kafka吗？</h3><h3 id=\"某一个-Topic-Partition-设置了3个Replica，分别在broker1-broker2-broker3上，对于每一个broker，它们的AR（assign-replica）是一样的么？\"><a href=\"#某一个-Topic-Partition-设置了3个Replica，分别在broker1-broker2-broker3上，对于每一个broker，它们的AR（assign-replica）是一样的么？\" class=\"headerlink\" title=\"某一个(Topic, Partition)设置了3个Replica，分别在broker1, broker2, broker3上，对于每一个broker，它们的AR（assign replica）是一样的么？\"></a>某一个(Topic, Partition)设置了3个Replica，分别在broker1, broker2, broker3上，对于每一个broker，它们的AR（assign replica）是一样的么？</h3><p>broker1: Leader(1), AR(1, 2, 3)<br>broker2: Follower(2), AR(1, 2, 3)<br>broker3: Follower(3), AR(1, 2, 3)</p>\n<h3 id=\"Follower向Leader发送Fetch请求，HW是怎么在Follower和Leader之间传递的？\"><a href=\"#Follower向Leader发送Fetch请求，HW是怎么在Follower和Leader之间传递的？\" class=\"headerlink\" title=\"Follower向Leader发送Fetch请求，HW是怎么在Follower和Leader之间传递的？\"></a>Follower向Leader发送Fetch请求，HW是怎么在Follower和Leader之间传递的？</h3><h3 id=\"什么叫某个-topic-partition-的Preferred-Leader？\"><a href=\"#什么叫某个-topic-partition-的Preferred-Leader？\" class=\"headerlink\" title=\"什么叫某个(topic, partition)的Preferred Leader？\"></a>什么叫某个(topic, partition)的Preferred Leader？</h3><p>(topic, partition)的AR中的第一个元素就是Preferred Leader。</p>\n<h3 id=\"如果首选的副本不在ISR中会发生什么\"><a href=\"#如果首选的副本不在ISR中会发生什么\" class=\"headerlink\" title=\"如果首选的副本不在ISR中会发生什么?\"></a>如果首选的副本不在ISR中会发生什么?</h3><p>Broker1: Leader(3), AR(1, 2, 3), ISR(2, 3)<br>如果这样的情况是普遍情况，会导致Broker一定程度得数据倾斜。</p>\n<h3 id=\"如果我指定了一个offset，Kafka怎么查找到对应的消息？\"><a href=\"#如果我指定了一个offset，Kafka怎么查找到对应的消息？\" class=\"headerlink\" title=\"如果我指定了一个offset，Kafka怎么查找到对应的消息？\"></a>如果我指定了一个offset，Kafka怎么查找到对应的消息？</h3><h3 id=\"如果我指定了一个timestamp，Kafka怎么查找到对应的消息？\"><a href=\"#如果我指定了一个timestamp，Kafka怎么查找到对应的消息？\" class=\"headerlink\" title=\"如果我指定了一个timestamp，Kafka怎么查找到对应的消息？\"></a>如果我指定了一个timestamp，Kafka怎么查找到对应的消息？</h3><h3 id=\"Kafka的延时操作是怎么实现的？\"><a href=\"#Kafka的延时操作是怎么实现的？\" class=\"headerlink\" title=\"Kafka的延时操作是怎么实现的？\"></a>Kafka的延时操作是怎么实现的？</h3><h3 id=\"Kafka中的Exactly-Once是怎么实现的？\"><a href=\"#Kafka中的Exactly-Once是怎么实现的？\" class=\"headerlink\" title=\"Kafka中的Exactly-Once是怎么实现的？\"></a>Kafka中的Exactly-Once是怎么实现的？</h3><p>目前理解：每一个Producer配置一个producerId，对于同一个Producer，每一条发送的消息有一个自增的序列号，如果Broker收到同一个Producer发送了相同的两个序列号，那么就要把相同的那个序列号丢弃掉。</p>\n<p>// now that we have valid records, offsets assigned, and timestamps updated, we need to<br>// validate the idempotent/transactional state of the producers and collect some metadata<br>val (updatedProducers, completedTxns, maybeDuplicate) = analyzeAndValidateProducerState(validRecords, isFromClient)<br>maybeDuplicate.foreach { duplicate =&gt;<br>  appendInfo.firstOffset = duplicate.firstOffset<br>  appendInfo.lastOffset = duplicate.lastOffset<br>  appendInfo.logAppendTime = duplicate.timestamp<br>  appendInfo.logStartOffset = logStartOffset<br>  return appendInfo<br>}</p>\n<h3 id=\"Kafka中的事务是怎么实现的？\"><a href=\"#Kafka中的事务是怎么实现的？\" class=\"headerlink\" title=\"Kafka中的事务是怎么实现的？\"></a>Kafka中的事务是怎么实现的？</h3><h3 id=\"Kafka如果需要拉取历史任务，怎么样解决Broker高Load问题？\"><a href=\"#Kafka如果需要拉取历史任务，怎么样解决Broker高Load问题？\" class=\"headerlink\" title=\"Kafka如果需要拉取历史任务，怎么样解决Broker高Load问题？\"></a>Kafka如果需要拉取历史任务，怎么样解决Broker高Load问题？</h3><p>Kafka本身有没有限流机制？</p>\n<h3 id=\"Kafka的consumer的心跳线程做什么事情？只是检测存活么？\"><a href=\"#Kafka的consumer的心跳线程做什么事情？只是检测存活么？\" class=\"headerlink\" title=\"Kafka的consumer的心跳线程做什么事情？只是检测存活么？\"></a>Kafka的consumer的心跳线程做什么事情？只是检测存活么？</h3><h3 id=\"Kafka-vagrant搭建\"><a href=\"#Kafka-vagrant搭建\" class=\"headerlink\" title=\"Kafka vagrant搭建\"></a>Kafka vagrant搭建</h3><p>vagrant box add <br><a href=\"https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/vagrant/trusty/current/trusty-server-cloudimg-amd64-vagrant-disk1.box\" target=\"_blank\" rel=\"noopener\">https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/vagrant/trusty/current/trusty-server-cloudimg-amd64-vagrant-disk1.box</a> <br>–name ubuntu/trusty64</p>\n<h3 id=\"consumer-offsets这个topic有什么特点？\"><a href=\"#consumer-offsets这个topic有什么特点？\" class=\"headerlink\" title=\"__consumer_offsets这个topic有什么特点？\"></a>__consumer_offsets这个topic有什么特点？</h3><p>根据理解，说的越多越好</p>\n<ol>\n<li>compaction</li>\n<li>retention</li>\n</ol>\n<h3 id=\"kafka的消费者Offset是KV-Map形式的，是怎么被维护在以List形式的-consumer-offsets上？\"><a href=\"#kafka的消费者Offset是KV-Map形式的，是怎么被维护在以List形式的-consumer-offsets上？\" class=\"headerlink\" title=\"kafka的消费者Offset是KV Map形式的，是怎么被维护在以List形式的__consumer_offsets上？\"></a>kafka的消费者Offset是KV Map形式的，是怎么被维护在以List形式的__consumer_offsets上？</h3><p><a href=\"https://www.jianshu.com/p/833b64e141f8\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/833b64e141f8</a></p>\n<h3 id=\"kafka在恢复kv结构的offset时，真的需要从头到尾进行遍历么？\"><a href=\"#kafka在恢复kv结构的offset时，真的需要从头到尾进行遍历么？\" class=\"headerlink\" title=\"kafka在恢复kv结构的offset时，真的需要从头到尾进行遍历么？\"></a>kafka在恢复kv结构的offset时，真的需要从头到尾进行遍历么？</h3><p>while (currOffset &lt; highWaterMark &amp;&amp; !shuttingDown.get()) {<br>这一段是什么意思？</p>\n<h3 id=\"消费者默认的消息事务隔离级别是什么？\"><a href=\"#消费者默认的消息事务隔离级别是什么？\" class=\"headerlink\" title=\"消费者默认的消息事务隔离级别是什么？\"></a>消费者默认的消息事务隔离级别是什么？</h3><p>我怎么记得是 read-uncommitted</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[2019-10-08 10:44:54,021] DEBUG [Consumer clientId=consumer-1, groupId=consumerGroup1] Added READ_UNCOMMITTED fetch request for partition krp-0 at offset 10 to node 172.16.115.163:9092 (id: 2 rack: null) (org.apache.kafka.clients.consumer.internals.Fetcher)</span><br></pre></td></tr></table></figure>\n\n<p>这个只针对事务消息，对一般的消息无效。</p>\n<h3 id=\"Kafka有没有类似于RocketMQ的ZeroCopy？\"><a href=\"#Kafka有没有类似于RocketMQ的ZeroCopy？\" class=\"headerlink\" title=\"Kafka有没有类似于RocketMQ的ZeroCopy？\"></a>Kafka有没有类似于RocketMQ的ZeroCopy？</h3><p>是用到了，但是在哪里用到的？这里写得很清楚。<br><a href=\"https://www.jianshu.com/p/d47de3d6d8ac\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/d47de3d6d8ac</a></p>\n<p>sendfile不是posix规范的api，要使用sendfile，在各个平台没有统一的规定，甚至连引入的头文件都没有做规范。<br>FileChannelImpl.c</p>\n<p>#if defined(<strong>linux</strong>) || defined(<strong>solaris</strong>)<br>#include &lt;sys/sendfile.h&gt;<br>#elif defined(_AIX)<br>#include &lt;sys/socket.h&gt;<br>#elif defined(_ALLBSD_SOURCE)<br>#include &lt;sys/socket.h&gt;<br>#include &lt;sys/uio.h&gt;<br>#define lseek64 lseek<br>#define mmap64 mmap<br>#endif</p>\n<h3 id=\"原先的GroupCoordinator宕机了，kafka是怎么检测到并且将GroupCoordinator转移到另一台机器，然后恢复-consumer-offsets数据的？\"><a href=\"#原先的GroupCoordinator宕机了，kafka是怎么检测到并且将GroupCoordinator转移到另一台机器，然后恢复-consumer-offsets数据的？\" class=\"headerlink\" title=\"原先的GroupCoordinator宕机了，kafka是怎么检测到并且将GroupCoordinator转移到另一台机器，然后恢复__consumer_offsets数据的？\"></a>原先的GroupCoordinator宕机了，kafka是怎么检测到并且将GroupCoordinator转移到另一台机器，然后恢复__consumer_offsets数据的？</h3><p><a href=\"https://www.jianshu.com/p/833b64e141f8\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/833b64e141f8</a><br>按照这个文章，好像说是在收到了 LeaderAndIsr的请求后？？？</p>\n<h3 id=\"什么时候-「谁」-会调用-「谁」-的ApiKeys-LEADER-AND-ISR\"><a href=\"#什么时候-「谁」-会调用-「谁」-的ApiKeys-LEADER-AND-ISR\" class=\"headerlink\" title=\"什么时候 「谁」 会调用 「谁」 的ApiKeys.LEADER_AND_ISR?\"></a>什么时候 「谁」 会调用 「谁」 的ApiKeys.LEADER_AND_ISR?</h3><p>在每个Partition(.scala)中，在每次expandIsr或者shrinkIsr时，都需要在zk(/isr_change_notification)上记录，以此来达到事件传播(propagate)的效果。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def maybeExpandIsr(replicaId: Int, logReadResult: LogReadResult): Boolean = &#123;</span><br><span class=\"line\">  inWriteLock(leaderIsrUpdateLock) &#123;</span><br><span class=\"line\">    // check if this replica needs to be added to the ISR</span><br><span class=\"line\">    leaderReplicaIfLocal match &#123;</span><br><span class=\"line\">      case Some(leaderReplica) =&gt;</span><br><span class=\"line\">          ...</span><br><span class=\"line\">          // update ISR in ZK and cache</span><br><span class=\"line\">          updateIsr(newInSyncReplicas)</span><br><span class=\"line\">          ...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">      case None =&gt; false // nothing to do if no longer leader</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">def maybeShrinkIsr(replicaMaxLagTimeMs: Long) &#123;</span><br><span class=\"line\">  val leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) &#123;</span><br><span class=\"line\">    leaderReplicaIfLocal match &#123;</span><br><span class=\"line\">      case Some(leaderReplica) =&gt;</span><br><span class=\"line\">        val outOfSyncReplicas = getOutOfSyncReplicas(leaderReplica, replicaMaxLagTimeMs)</span><br><span class=\"line\">        if(outOfSyncReplicas.nonEmpty) &#123;</span><br><span class=\"line\">          ...</span><br><span class=\"line\">          // update ISR in zk and in cache</span><br><span class=\"line\">          updateIsr(newInSyncReplicas)</span><br><span class=\"line\">          ...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      case None =&gt; false // do nothing if no longer leader</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // some delayed operations may be unblocked after HW changed</span><br><span class=\"line\">  if (leaderHWIncremented)</span><br><span class=\"line\">    tryCompleteDelayedRequests()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">def recordIsrChange(topicPartition: TopicPartition) &#123;</span><br><span class=\"line\">  isrChangeSet synchronized &#123;</span><br><span class=\"line\">    isrChangeSet += topicPartition</span><br><span class=\"line\">    lastIsrChangeMs.set(System.currentTimeMillis())</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">def maybePropagateIsrChanges() &#123;</span><br><span class=\"line\">  val now = System.currentTimeMillis()</span><br><span class=\"line\">  isrChangeSet synchronized &#123;</span><br><span class=\"line\">    if (isrChangeSet.nonEmpty &amp;&amp;</span><br><span class=\"line\">      (lastIsrChangeMs.get() + ReplicaManager.IsrChangePropagationBlackOut &lt; now ||</span><br><span class=\"line\">        lastIsrPropagationMs.get() + ReplicaManager.IsrChangePropagationInterval &lt; now)) &#123;</span><br><span class=\"line\">      ReplicationUtils.propagateIsrChanges(zkUtils, isrChangeSet)</span><br><span class=\"line\">      isrChangeSet.clear()</span><br><span class=\"line\">      lastIsrPropagationMs.set(now)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>controller在onControllerFailover的registerIsrChangeNotificationListener对上面的地址进行了监听。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private def registerIsrChangeNotificationListener() = &#123;</span><br><span class=\"line\">  debug(&quot;Registering IsrChangeNotificationListener&quot;)</span><br><span class=\"line\">  zkUtils.subscribeChildChanges(ZkUtils.IsrChangeNotificationPath, isrChangeNotificationListener)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Kafka中有哪些Coordinator\"><a href=\"#Kafka中有哪些Coordinator\" class=\"headerlink\" title=\"Kafka中有哪些Coordinator?\"></a>Kafka中有哪些Coordinator?</h3><h3 id=\"Kafka怎么做集群迁移？\"><a href=\"#Kafka怎么做集群迁移？\" class=\"headerlink\" title=\"Kafka怎么做集群迁移？\"></a>Kafka怎么做集群迁移？</h3><h3 id=\"Kafka怎么做集群扩容？\"><a href=\"#Kafka怎么做集群扩容？\" class=\"headerlink\" title=\"Kafka怎么做集群扩容？\"></a>Kafka怎么做集群扩容？</h3><h3 id=\"Kafka怎么Topic迁移？\"><a href=\"#Kafka怎么Topic迁移？\" class=\"headerlink\" title=\"Kafka怎么Topic迁移？\"></a>Kafka怎么Topic迁移？</h3><h3 id=\"Kafka在数据倾斜的时候做数据平衡？\"><a href=\"#Kafka在数据倾斜的时候做数据平衡？\" class=\"headerlink\" title=\"Kafka在数据倾斜的时候做数据平衡？\"></a>Kafka在数据倾斜的时候做数据平衡？</h3><h3 id=\"集群中的哪一台机器会成为某一个Consumer-Group的GroupCoordinator？\"><a href=\"#集群中的哪一台机器会成为某一个Consumer-Group的GroupCoordinator？\" class=\"headerlink\" title=\"集群中的哪一台机器会成为某一个Consumer Group的GroupCoordinator？\"></a>集群中的哪一台机器会成为某一个Consumer Group的GroupCoordinator？</h3><p>// get metadata (and create the topic if necessary)<br>val (partition, topicMetadata) = findCoordinatorRequest.coordinatorType match {<br>  case FindCoordinatorRequest.CoordinatorType.GROUP =&gt;<br>    val partition = groupCoordinator.partitionFor(findCoordinatorRequest.coordinatorKey)<br>    val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)<br>    (partition, metadata)</p>\n<h3 id=\"Varint怎么能减少数据传输量？\"><a href=\"#Varint怎么能减少数据传输量？\" class=\"headerlink\" title=\"Varint怎么能减少数据传输量？\"></a>Varint怎么能减少数据传输量？</h3><p><a href=\"http://www.zdingke.com/2018/03/17/kafka/?falerm=x2psz2\" target=\"_blank\" rel=\"noopener\">http://www.zdingke.com/2018/03/17/kafka/?falerm=x2psz2</a><br><a href=\"https://blog.csdn.net/u013256816/article/details/80300272\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u013256816/article/details/80300272</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Read an integer stored in variable-length format using zig-zag decoding from</span><br><span class=\"line\"> * &lt;a href=&quot;http://code.google.com/apis/protocolbuffers/docs/encoding.html&quot;&gt; Google Protocol Buffers&lt;/a&gt;.</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @param buffer The buffer to read from</span><br><span class=\"line\"> * @return The integer read</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @throws IllegalArgumentException if variable-length value does not terminate after 5 bytes have been read</span><br><span class=\"line\"> */</span><br><span class=\"line\">public static int readVarint(ByteBuffer buffer) &#123;</span><br><span class=\"line\">    int value = 0;</span><br><span class=\"line\">    int i = 0;</span><br><span class=\"line\">    int b;</span><br><span class=\"line\">    while (((b = buffer.get()) &amp; 0x80) != 0) &#123;</span><br><span class=\"line\">        value |= (b &amp; 0x7f) &lt;&lt; i;</span><br><span class=\"line\">        i += 7;</span><br><span class=\"line\">        if (i &gt; 28)</span><br><span class=\"line\">            throw illegalVarintException(value);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    value |= b &lt;&lt; i;</span><br><span class=\"line\">    return (value &gt;&gt;&gt; 1) ^ -(value &amp; 1);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/**</span><br><span class=\"line\"> * Write the given integer following the variable-length zig-zag encoding from</span><br><span class=\"line\"> * &lt;a href=&quot;http://code.google.com/apis/protocolbuffers/docs/encoding.html&quot;&gt; Google Protocol Buffers&lt;/a&gt;</span><br><span class=\"line\"> * into the buffer.</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @param value The value to write</span><br><span class=\"line\"> * @param buffer The output to write to</span><br><span class=\"line\"> */</span><br><span class=\"line\">public static void writeVarint(int value, ByteBuffer buffer) &#123;</span><br><span class=\"line\">    int v = (value &lt;&lt; 1) ^ (value &gt;&gt; 31);</span><br><span class=\"line\">    while ((v &amp; 0xffffff80) != 0L) &#123;</span><br><span class=\"line\">        byte b = (byte) ((v &amp; 0x7f) | 0x80);</span><br><span class=\"line\">        buffer.put(b);</span><br><span class=\"line\">        v &gt;&gt;&gt;= 7;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    buffer.put((byte) v);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Kafka-Rebalance-的时机是什么时候？-new-KafkaConsumer-后-还是-consumer-subscribe-后\"><a href=\"#Kafka-Rebalance-的时机是什么时候？-new-KafkaConsumer-后-还是-consumer-subscribe-后\" class=\"headerlink\" title=\"Kafka Rebalance 的时机是什么时候？ new KafkaConsumer() 后 还是 consumer.subscribe() 后?\"></a>Kafka Rebalance 的时机是什么时候？ new KafkaConsumer() 后 还是 consumer.subscribe() 后?</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">在调用poll()中才开始Rebalance</span><br><span class=\"line\"></span><br><span class=\"line\">if (needRejoin()) &#123;</span><br><span class=\"line\">    // due to a race condition between the initial metadata fetch and the initial rebalance,</span><br><span class=\"line\">    // we need to ensure that the metadata is fresh before joining initially. This ensures</span><br><span class=\"line\">    // that we have matched the pattern against the cluster&apos;s topics at least once before joining.</span><br><span class=\"line\">    if (subscriptions.hasPatternSubscription())</span><br><span class=\"line\">        client.ensureFreshMetadata();</span><br><span class=\"line\"></span><br><span class=\"line\">    ensureActiveGroup();</span><br><span class=\"line\">    now = time.milliseconds();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"如果某一ConsumerGroup的Consumer的数量发生变化，剩余的Consumer是如何检测到需要Rebalance了？\"><a href=\"#如果某一ConsumerGroup的Consumer的数量发生变化，剩余的Consumer是如何检测到需要Rebalance了？\" class=\"headerlink\" title=\"如果某一ConsumerGroup的Consumer的数量发生变化，剩余的Consumer是如何检测到需要Rebalance了？\"></a>如果某一ConsumerGroup的Consumer的数量发生变化，剩余的Consumer是如何检测到需要Rebalance了？</h3><p>Rebalance的触发是在consumer的poll操作中<br>是不是这段？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">public boolean needRejoin() &#123;</span><br><span class=\"line\">    if (!subscriptions.partitionsAutoAssigned())</span><br><span class=\"line\">        return false;</span><br><span class=\"line\"></span><br><span class=\"line\">    // we need to rejoin if we performed the assignment and metadata has changed</span><br><span class=\"line\">    if (assignmentSnapshot != null &amp;&amp; !assignmentSnapshot.equals(metadataSnapshot))</span><br><span class=\"line\">        return true;</span><br><span class=\"line\"></span><br><span class=\"line\">    // we need to join if our subscription has changed since the last join</span><br><span class=\"line\">    if (joinedSubscription != null &amp;&amp; !joinedSubscription.equals(subscriptions.subscription()))</span><br><span class=\"line\">        return true;</span><br><span class=\"line\"></span><br><span class=\"line\">    return super.needRejoin();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Kafka消费者Rebalance过程\"><a href=\"#Kafka消费者Rebalance过程\" class=\"headerlink\" title=\"Kafka消费者Rebalance过程\"></a>Kafka消费者Rebalance过程</h3><p>消费者查找GroupCoordinator<br>消费者主动向GroupCoordinator发起JOIN<br>作为GroupCoordinator的Broker接受到JOIN，选出一个Leader和epoch，给JOIN的成员发送响应<br>下面应该怎么弄啊？？？？写不下去了</p>\n<p>这种方式的好处是，Rebalance的算法可以放在客户端，而不需要放在Broker端。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[2019-10-09 16:29:26,866] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Kafka consumer initialized (org.apache.kafka.clients.consumer.KafkaConsumer)</span><br><span class=\"line\">[2019-10-09 16:29:26,867] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Subscribed to topic(s): hermes.demo.pandc (org.apache.kafka.clients.consumer.KafkaConsumer)</span><br><span class=\"line\">[2019-10-09 16:29:26,867] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Sending FindCoordinator request to broker localhost:9091 (id: -1 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,026] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Initiating connection to node localhost:9091 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)</span><br><span class=\"line\">...</span><br><span class=\"line\">[2019-10-09 16:29:27,135] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Received FindCoordinator response ClientResponse(receivedTimeMs=1570609767134, latencyMs=118, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage=&apos;null&apos;, error=NONE, node=172.16.115.163:9092 (id: 2 rack: null))) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,135] INFO [Consumer clientId=consumer-1, groupId=cg1] Discovered group coordinator 172.16.115.163:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,135] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Initiating connection to node 172.16.115.163:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.NetworkClient)</span><br><span class=\"line\">[2019-10-09 16:29:27,137] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Heartbeat thread started (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,137] INFO [Consumer clientId=consumer-1, groupId=cg1] Revoking previously assigned partitions [] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,138] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Disabling heartbeat thread (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,138] INFO [Consumer clientId=consumer-1, groupId=cg1] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,141] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Sending JoinGroup ((type: JoinGroupRequest, groupId=cg1, sessionTimeout=10000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@23fe1d71)) to coordinator 172.16.115.163:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">...</span><br><span class=\"line\">[2019-10-09 16:29:27,150] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@7403c468 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,150] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Performing assignment using strategy range with subscriptions &#123;consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd=Subscription(topics=[hermes.demo.pandc])&#125; (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,151] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Finished assignment for group: &#123;consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd=Assignment(partitions=[hermes.demo.pandc-0, hermes.demo.pandc-1])&#125; (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,152] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Sending leader SyncGroup to coordinator 172.16.115.163:9092 (id: 2147483645 rack: null): (type=SyncGroupRequest, groupId=cg1, generationId=13, memberId=consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd, groupAssignment=consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,156] INFO [Consumer clientId=consumer-1, groupId=cg1] Successfully joined group with generation 13 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,156] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Enabling heartbeat thread (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,157] INFO [Consumer clientId=consumer-1, groupId=cg1] Setting newly assigned partitions [hermes.demo.pandc-1, hermes.demo.pandc-0] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,157] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Fetching committed offsets for partitions: [hermes.demo.pandc-1, hermes.demo.pandc-0] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,159] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Resetting offset for partition hermes.demo.pandc-1 to the committed offset 5 (org.apache.kafka.clients.consumer.internals.Fetcher)</span><br><span class=\"line\">[2019-10-09 16:29:27,159] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Resetting offset for partition hermes.demo.pandc-0 to the committed offset 9 (org.apache.kafka.clients.consumer.internals.Fetcher)</span><br><span class=\"line\">[2019-10-09 16:29:27,160] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Added READ_UNCOMMITTED fetch request for partition hermes.demo.pandc-1 at offset 5 to node 172.16.115.163:9091 (id: 1 rack: null) (org.apache.kafka.clients.consumer.internals.Fetcher)</span><br><span class=\"line\">[2019-10-09 16:29:27,160] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Added READ_UNCOMMITTED fetch request for partition hermes.demo.pandc-0 at offset 9 to node 172.16.115.163:9091 (id: 1 rack: null) (org.apache.kafka.clients.consumer.internals.Fetcher)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"异步发送后，回调是否会按照发送的真实顺序进行回调？\"><a href=\"#异步发送后，回调是否会按照发送的真实顺序进行回调？\" class=\"headerlink\" title=\"异步发送后，回调是否会按照发送的真实顺序进行回调？\"></a>异步发送后，回调是否会按照发送的真实顺序进行回调？</h3><p>我的印象是可以的</p>\n<h3 id=\"Kafka是否支持Long-Polling\"><a href=\"#Kafka是否支持Long-Polling\" class=\"headerlink\" title=\"Kafka是否支持Long Polling\"></a>Kafka是否支持Long Polling</h3><p><a href=\"https://www.jianshu.com/p/34dc83e90f98\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/34dc83e90f98</a><br>支持：<br>/**</p>\n<ul>\n<li><code>fetch.max.wait.ms</code></li>\n<li>/<br>public static final String FETCH_MAX_WAIT_MS_CONFIG = “fetch.max.wait.ms”;<br>private static final String FETCH_MAX_WAIT_MS_DOC = “The maximum amount of time the server will block before answering the fetch request if there isn’t sufficient data to immediately satisfy the requirement given by fetch.min.bytes.”;</li>\n</ul>\n<p>// probably unblock some follower fetch requests since log end offset has been updated<br>replicaManager.tryCompleteDelayedFetch(TopicPartitionOperationKey(this.topic, this.partitionId))</p>\n<p>从下面的代码来看，貌似是支持的。<br>kafka.cluster.Partition#appendRecordsToLeader<br>// some delayed operations may be unblocked after HW changed<br>if (leaderHWIncremented)<br>  tryCompleteDelayedRequests()</p>\n<p>/**</p>\n<ul>\n<li>Try to complete any pending requests. This should be called without holding the leaderIsrUpdateLock.</li>\n<li>/<br>private def tryCompleteDelayedRequests() {<br>val requestKey = new TopicPartitionOperationKey(topicPartition)<br>replicaManager.tryCompleteDelayedFetch(requestKey)<br>replicaManager.tryCompleteDelayedProduce(requestKey)<br>replicaManager.tryCompleteDelayedDeleteRecords(requestKey)<br>}</li>\n</ul>\n<h3 id=\"学习资料\"><a href=\"#学习资料\" class=\"headerlink\" title=\"学习资料\"></a>学习资料</h3><p><a href=\"http://blog.csdn.net/chunlongyu/article/category/6638499\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/chunlongyu/article/category/6638499</a></p>\n<p><a href=\"http://blog.csdn.net/chunlongyu/article/details/54407633\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/chunlongyu/article/details/54407633</a></p>\n<p><a href=\"http://blog.csdn.net/a417930422/article/category/6086259\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/a417930422/article/category/6086259</a></p>\n<p><a href=\"http://blog.csdn.net/lizhitao\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/lizhitao</a></p>\n<p><a href=\"http://www.cnblogs.com/huxi2b\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/huxi2b</a></p>\n<p><a href=\"http://blog.csdn.net/u014393917/article/category/6332828\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/u014393917/article/category/6332828</a></p>\n<p>阿里中间件团队博客<br><a href=\"http://jm.taobao.org/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/\" target=\"_blank\" rel=\"noopener\">http://jm.taobao.org/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/</a></p>\n<p>第九课. Kafka高性能之道<br>    9.1 顺序写磁盘<br>    9.2 零拷贝<br>    9.3 批处理<br>    9.4 基于ISR的动态平衡一致性算法</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"大量精品文章和面试问题\"><a href=\"#大量精品文章和面试问题\" class=\"headerlink\" title=\"大量精品文章和面试问题\"></a>大量精品文章和面试问题</h3><p><a href=\"https://blog.csdn.net/u013256816\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u013256816</a><br>比较好的总结<br><a href=\"https://juejin.im/post/5ddf5659518825782d599641?utm_source=gold_browser_extension\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5ddf5659518825782d599641?utm_source=gold_browser_extension</a></p>\n<h3 id=\"Kafka发送怎么保证顺序？\"><a href=\"#Kafka发送怎么保证顺序？\" class=\"headerlink\" title=\"Kafka发送怎么保证顺序？\"></a>Kafka发送怎么保证顺序？</h3><h3 id=\"Kafka异步发送能不能保证顺序？\"><a href=\"#Kafka异步发送能不能保证顺序？\" class=\"headerlink\" title=\"Kafka异步发送能不能保证顺序？\"></a>Kafka异步发送能不能保证顺序？</h3><h3 id=\"Kafka能不能保证不丢消息（只要多数机器不挂）？\"><a href=\"#Kafka能不能保证不丢消息（只要多数机器不挂）？\" class=\"headerlink\" title=\"Kafka能不能保证不丢消息（只要多数机器不挂）？\"></a>Kafka能不能保证不丢消息（只要多数机器不挂）？</h3><h3 id=\"Kafka能不能保证消费顺序？\"><a href=\"#Kafka能不能保证消费顺序？\" class=\"headerlink\" title=\"Kafka能不能保证消费顺序？\"></a>Kafka能不能保证消费顺序？</h3><h3 id=\"Kafka写CommitLog时用了什么锁机制\"><a href=\"#Kafka写CommitLog时用了什么锁机制\" class=\"headerlink\" title=\"Kafka写CommitLog时用了什么锁机制?\"></a>Kafka写CommitLog时用了什么锁机制?</h3><p>sync;lock-free;reentrant lock,用了哪一种？</p>\n<p>kafka.log.Log#append<br>lock synchronized {<br>}</p>\n<h3 id=\"Kafka生产者批量发送了消息，那Broker是把消息一条一存么？\"><a href=\"#Kafka生产者批量发送了消息，那Broker是把消息一条一存么？\" class=\"headerlink\" title=\"Kafka生产者批量发送了消息，那Broker是把消息一条一存么？\"></a>Kafka生产者批量发送了消息，那Broker是把消息一条一存么？</h3><p>不是，是把几条连续的消息存在一起，在外层公用同一个offset</p>\n<h3 id=\"kafka消费者fetch的消息正好在某个批次中间的消息，怎么办？\"><a href=\"#kafka消费者fetch的消息正好在某个批次中间的消息，怎么办？\" class=\"headerlink\" title=\"kafka消费者fetch的消息正好在某个批次中间的消息，怎么办？\"></a>kafka消费者fetch的消息正好在某个批次中间的消息，怎么办？</h3><h3 id=\"Kafka-Consumer-Rebalance流程是怎么样的？\"><a href=\"#Kafka-Consumer-Rebalance流程是怎么样的？\" class=\"headerlink\" title=\"Kafka Consumer Rebalance流程是怎么样的？\"></a>Kafka Consumer Rebalance流程是怎么样的？</h3><ol>\n<li><p>Consumer查找GroupCoordinator，向它发送Join请求</p>\n</li>\n<li><p>Broker收到Join请求后，创建一个Group，并且把创建的Consumer作为Consumer的Leader</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ kafka.coordinator.group.GroupMetadata#add</span><br><span class=\"line\">def add(member: MemberMetadata) &#123;</span><br><span class=\"line\">  if (members.isEmpty)</span><br><span class=\"line\">    this.protocolType = Some(member.protocolType)</span><br><span class=\"line\"></span><br><span class=\"line\">  assert(groupId == member.groupId)</span><br><span class=\"line\">  assert(this.protocolType.orNull == member.protocolType)</span><br><span class=\"line\">  assert(supportsProtocols(member.protocols))</span><br><span class=\"line\"></span><br><span class=\"line\">  if (leaderId.isEmpty)</span><br><span class=\"line\">    leaderId = Some(member.memberId)</span><br><span class=\"line\">  members.put(member.memberId, member)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Broker并不会直接给发送Join请求的Consumer响应，而是会启动延时任务，等待一段时间，然后再给所有的Consumer响应</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ kafka.coordinator.group.GroupCoordinator#prepareRebalance</span><br><span class=\"line\">private def prepareRebalance(group: GroupMetadata) &#123;</span><br><span class=\"line\">  // if any members are awaiting sync, cancel their request and have them rejoin</span><br><span class=\"line\">  if (group.is(AwaitingSync))</span><br><span class=\"line\">    resetAndPropagateAssignmentError(group, Errors.REBALANCE_IN_PROGRESS)</span><br><span class=\"line\"></span><br><span class=\"line\">  val delayedRebalance = if (group.is(Empty))</span><br><span class=\"line\">    new InitialDelayedJoin(this,</span><br><span class=\"line\">      joinPurgatory,</span><br><span class=\"line\">      group,</span><br><span class=\"line\">      groupConfig.groupInitialRebalanceDelayMs,</span><br><span class=\"line\">      groupConfig.groupInitialRebalanceDelayMs,</span><br><span class=\"line\">      max(group.rebalanceTimeoutMs - groupConfig.groupInitialRebalanceDelayMs, 0))</span><br><span class=\"line\">  else</span><br><span class=\"line\">    new DelayedJoin(this, group, group.rebalanceTimeoutMs)</span><br><span class=\"line\"></span><br><span class=\"line\">  group.transitionTo(PreparingRebalance)</span><br><span class=\"line\"></span><br><span class=\"line\">  info(s&quot;Preparing to rebalance group $&#123;group.groupId&#125; with old generation $&#123;group.generationId&#125; &quot; +</span><br><span class=\"line\">    s&quot;($&#123;Topic.GROUP_METADATA_TOPIC_NAME&#125;-$&#123;partitionFor(group.groupId)&#125;)&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">  val groupKey = GroupKey(group.groupId)</span><br><span class=\"line\">  joinPurgatory.tryCompleteElseWatch(delayedRebalance, Seq(groupKey))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>各个Consumer收到来自Group coordinator的响应后，会查看自己是不是这个Consumer Group中的Consumer Leader</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator.JoinGroupResponseHandler#handle</span><br><span class=\"line\">AbstractCoordinator.this.generation = new Generation(joinResponse.generationId(),</span><br><span class=\"line\">        joinResponse.memberId(), joinResponse.groupProtocol());</span><br><span class=\"line\">if (joinResponse.isLeader()) &#123;</span><br><span class=\"line\">    onJoinLeader(joinResponse).chain(future);</span><br><span class=\"line\">&#125; else &#123;</span><br><span class=\"line\">    onJoinFollower().chain(future);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>作为Leader的Consumer需要根据自己Rebalance算法，把rebalance的结果通过发送Sync请求反馈给Group Coordinator</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator#onJoinLeader</span><br><span class=\"line\">private RequestFuture&lt;ByteBuffer&gt; onJoinLeader(JoinGroupResponse joinResponse) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        // perform the leader synchronization and send back the assignment for the group</span><br><span class=\"line\">        Map&lt;String, ByteBuffer&gt; groupAssignment = performAssignment(joinResponse.leaderId(), joinResponse.groupProtocol(),</span><br><span class=\"line\">                joinResponse.members());</span><br><span class=\"line\"></span><br><span class=\"line\">        SyncGroupRequest.Builder requestBuilder =</span><br><span class=\"line\">                new SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId, groupAssignment);</span><br><span class=\"line\">        log.debug(&quot;Sending leader SyncGroup to coordinator &#123;&#125;: &#123;&#125;&quot;, this.coordinator, requestBuilder);</span><br><span class=\"line\">        return sendSyncGroupRequest(requestBuilder);</span><br><span class=\"line\">    &#125; catch (RuntimeException e) &#123;</span><br><span class=\"line\">        return RequestFuture.failure(e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>而那些普通的Consumer也需要发送一个空的Sync请求</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator#onJoinFollower</span><br><span class=\"line\">private RequestFuture&lt;ByteBuffer&gt; onJoinFollower() &#123;</span><br><span class=\"line\">    // send follower&apos;s sync group with an empty assignment</span><br><span class=\"line\">    SyncGroupRequest.Builder requestBuilder =</span><br><span class=\"line\">            new SyncGroupRequest.Builder(groupId, generation.generationId, generation.memberId,</span><br><span class=\"line\">                    Collections.&lt;String, ByteBuffer&gt;emptyMap());</span><br><span class=\"line\">    log.debug(&quot;Sending follower SyncGroup to coordinator &#123;&#125;: &#123;&#125;&quot;, this.coordinator, requestBuilder);</span><br><span class=\"line\">    return sendSyncGroupRequest(requestBuilder);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>所有的Consumer根据Sync请求的响应，更新自己的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator.SyncGroupResponseHandler#handle</span><br><span class=\"line\">Errors error = syncResponse.error();</span><br><span class=\"line\">if (error == Errors.NONE) &#123;</span><br><span class=\"line\">    sensors.syncLatency.record(response.requestLatencyMs());</span><br><span class=\"line\">    future.complete(syncResponse.memberAssignment());</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.AbstractCoordinator#joinGroupIfNeeded</span><br><span class=\"line\">void joinGroupIfNeeded() &#123;</span><br><span class=\"line\">    while (needRejoin() || rejoinIncomplete()) &#123;</span><br><span class=\"line\">        // ...</span><br><span class=\"line\"></span><br><span class=\"line\">        RequestFuture&lt;ByteBuffer&gt; future = initiateJoinGroup();</span><br><span class=\"line\">        client.poll(future);</span><br><span class=\"line\"></span><br><span class=\"line\">        if (future.succeeded()) &#123;</span><br><span class=\"line\">            onJoinComplete(generation.generationId, generation.memberId, generation.protocol, future.value());</span><br><span class=\"line\"></span><br><span class=\"line\">            // We reset the join group future only after the completion callback returns. This ensures</span><br><span class=\"line\">            // that if the callback is woken up, we will retry it on the next joinGroupIfNeeded.</span><br><span class=\"line\">            resetJoinGroupFuture();</span><br><span class=\"line\">            needsJoinPrepare = true;</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            // ...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.ConsumerCoordinator#onJoinComplete</span><br><span class=\"line\">protected void onJoinComplete(int generation,</span><br><span class=\"line\">                              String memberId,</span><br><span class=\"line\">                              String assignmentStrategy,</span><br><span class=\"line\">                              ByteBuffer assignmentBuffer) &#123;</span><br><span class=\"line\">    // ...</span><br><span class=\"line\">    Assignment assignment = ConsumerProtocol.deserializeAssignment(assignmentBuffer);</span><br><span class=\"line\"></span><br><span class=\"line\">    // ...</span><br><span class=\"line\"></span><br><span class=\"line\">    // update partition assignment</span><br><span class=\"line\">    subscriptions.assignFromSubscribed(assignment.partitions());</span><br><span class=\"line\"></span><br><span class=\"line\">    // ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<h3 id=\"怎么监控kafka-page-cache刷盘时间？\"><a href=\"#怎么监控kafka-page-cache刷盘时间？\" class=\"headerlink\" title=\"怎么监控kafka page cache刷盘时间？\"></a>怎么监控kafka page cache刷盘时间？</h3><h3 id=\"Kafka-shallowOffset是什么意思？\"><a href=\"#Kafka-shallowOffset是什么意思？\" class=\"headerlink\" title=\"Kafka shallowOffset是什么意思？\"></a>Kafka shallowOffset是什么意思？</h3><h3 id=\"Kafka的Retention是怎么工作的？不符合retention的日志什么时候会被清理掉？\"><a href=\"#Kafka的Retention是怎么工作的？不符合retention的日志什么时候会被清理掉？\" class=\"headerlink\" title=\"Kafka的Retention是怎么工作的？不符合retention的日志什么时候会被清理掉？\"></a>Kafka的Retention是怎么工作的？不符合retention的日志什么时候会被清理掉？</h3><h3 id=\"Kafka发送者怎么保证是有序的？\"><a href=\"#Kafka发送者怎么保证是有序的？\" class=\"headerlink\" title=\"Kafka发送者怎么保证是有序的？\"></a>Kafka发送者怎么保证是有序的？</h3><p>MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION = 1， 为什么？<br>不等于1的话，会有什么效果？</p>\n<h3 id=\"Consumer-coordinator是什么？\"><a href=\"#Consumer-coordinator是什么？\" class=\"headerlink\" title=\"Consumer coordinator是什么？\"></a>Consumer coordinator是什么？</h3><h3 id=\"Group-coordinator是什么？\"><a href=\"#Group-coordinator是什么？\" class=\"headerlink\" title=\"Group coordinator是什么？\"></a>Group coordinator是什么？</h3><h3 id=\"consumer-offset的某一个partition挂了，kafka-broker中的controller会给它选一个新的Leader，这个过程是怎么样的？\"><a href=\"#consumer-offset的某一个partition挂了，kafka-broker中的controller会给它选一个新的Leader，这个过程是怎么样的？\" class=\"headerlink\" title=\"__consumer_offset的某一个partition挂了，kafka broker中的controller会给它选一个新的Leader，这个过程是怎么样的？\"></a>__consumer_offset的某一个partition挂了，kafka broker中的controller会给它选一个新的Leader，这个过程是怎么样的？</h3><h3 id=\"怎么获取Kafka-Consumer的Lag\"><a href=\"#怎么获取Kafka-Consumer的Lag\" class=\"headerlink\" title=\"怎么获取Kafka Consumer的Lag\"></a>怎么获取Kafka Consumer的Lag</h3><h3 id=\"Kafka是一个batch一压缩，还是一条消息一压缩？\"><a href=\"#Kafka是一个batch一压缩，还是一条消息一压缩？\" class=\"headerlink\" title=\"Kafka是一个batch一压缩，还是一条消息一压缩？\"></a>Kafka是一个batch一压缩，还是一条消息一压缩？</h3><p>每一个消息都会压缩</p>\n<h3 id=\"Kafka是怎么实现幂等的？\"><a href=\"#Kafka是怎么实现幂等的？\" class=\"headerlink\" title=\"Kafka是怎么实现幂等的？\"></a>Kafka是怎么实现幂等的？</h3><p>Broker以(producer, topic, partition)为维度，维护一份Map&lt;/<em>(producer, topic, partition)</em>/, /<em>sequence</em>/&gt;，Producer每发送一条消息(好像是以Batch为单位的??)，都会将sequence++；如果同一个Producer对于某一个(topic, partition)发送了两个sequence一样的消息，后面发送的那个将被丢弃掉。<br>实现原理：<br>)Producer在初始化时，会向Broker申请一个ProducerId<br>)Broker处理ProducerId申请请求，从序列段中申请一个唯一ID<br>)Producer在发送消息时，会将加一的sequence发在消息体中，一起发送</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ org.apache.kafka.clients.producer.internals.RecordAccumulator#drain</span><br><span class=\"line\"></span><br><span class=\"line\">// Additionally, we update the next sequence number bound for the partition,</span><br><span class=\"line\">// and also have the transaction manager track the batch so as to ensure</span><br><span class=\"line\">// that sequence ordering is maintained even if we receive out of order</span><br><span class=\"line\">// responses.</span><br><span class=\"line\">batch.setProducerState(producerIdAndEpoch, transactionManager.sequenceNumber(batch.topicPartition), isTransactional);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">// @ org.apache.kafka.common.record.DefaultRecordBatch#incrementSequence</span><br><span class=\"line\">static int incrementSequence(int baseSequence, int increment) &#123;</span><br><span class=\"line\">    if (baseSequence &gt; Integer.MAX_VALUE - increment)</span><br><span class=\"line\">        return increment - (Integer.MAX_VALUE - baseSequence) - 1;</span><br><span class=\"line\">    return baseSequence + increment;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>)Broker如果收到了sequence一样的消息，丢弃后直接返回。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ </span><br><span class=\"line\">// if this is a client produce request, there will be up to 5 batches which could have been duplicated.</span><br><span class=\"line\">// If we find a duplicate, we return the metadata of the appended batch to the client.</span><br><span class=\"line\">if (isFromClient) &#123;</span><br><span class=\"line\">  maybeLastEntry.flatMap(_.findDuplicateBatch(batch)).foreach &#123; duplicate =&gt;</span><br><span class=\"line\">    return (updatedProducers, completedTxns.toList, Some(duplicate))</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Kafka-Consumer关闭后，怎么触发Rebalance？\"><a href=\"#Kafka-Consumer关闭后，怎么触发Rebalance？\" class=\"headerlink\" title=\"Kafka Consumer关闭后，怎么触发Rebalance？\"></a>Kafka Consumer关闭后，怎么触发Rebalance？</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// @ org.apache.kafka.clients.consumer.internals.ConsumerCoordinator#needRejoin</span><br><span class=\"line\">public boolean needRejoin() &#123;</span><br><span class=\"line\">    if (!subscriptions.partitionsAutoAssigned())</span><br><span class=\"line\">        return false;</span><br><span class=\"line\"></span><br><span class=\"line\">    // we need to rejoin if we performed the assignment and metadata has changed</span><br><span class=\"line\">    if (assignmentSnapshot != null &amp;&amp; !assignmentSnapshot.equals(metadataSnapshot))</span><br><span class=\"line\">        return true;</span><br><span class=\"line\"></span><br><span class=\"line\">    // we need to join if our subscription has changed since the last join</span><br><span class=\"line\">    if (joinedSubscription != null &amp;&amp; !joinedSubscription.equals(subscriptions.subscription()))</span><br><span class=\"line\">        return true;</span><br><span class=\"line\"></span><br><span class=\"line\">    return super.needRejoin();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Kafka创建Topic的过程，和我们想象中有点不一样\"><a href=\"#Kafka创建Topic的过程，和我们想象中有点不一样\" class=\"headerlink\" title=\"Kafka创建Topic的过程，和我们想象中有点不一样\"></a>Kafka创建Topic的过程，和我们想象中有点不一样</h3><ol>\n<li><p>生成(topic, partition)replica的assignment</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def createTopic(zkUtils: ZkUtils,</span><br><span class=\"line\">                topic: String,</span><br><span class=\"line\">                partitions: Int,</span><br><span class=\"line\">                replicationFactor: Int,</span><br><span class=\"line\">                topicConfig: Properties = new Properties,</span><br><span class=\"line\">                rackAwareMode: RackAwareMode = RackAwareMode.Enforced) &#123;</span><br><span class=\"line\">  val brokerMetadatas = getBrokerMetadatas(zkUtils, rackAwareMode)</span><br><span class=\"line\">  val replicaAssignment = AdminUtils.assignReplicasToBrokers(brokerMetadatas, partitions, replicationFactor)</span><br><span class=\"line\">  AdminUtils.createOrUpdateTopicPartitionAssignmentPathInZK(zkUtils, topic, replicaAssignment, topicConfig)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>将生成的replica assignment写到ZK上</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// create the partition assignment</span><br><span class=\"line\">writeTopicPartitionAssignment(zkUtils, topic, partitionReplicaAssignment, update)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Broker监听到这个ZK变化，然后开始调用状态机，使replica和topic上线</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case class TopicChange(topics: Set[String]) extends ControllerEvent &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">  def state = ControllerState.TopicChange</span><br><span class=\"line\"></span><br><span class=\"line\">  override def process(): Unit = &#123;</span><br><span class=\"line\">    if (!isActive) return</span><br><span class=\"line\">    val newTopics = topics -- controllerContext.allTopics</span><br><span class=\"line\">    val deletedTopics = controllerContext.allTopics -- topics</span><br><span class=\"line\">    controllerContext.allTopics = topics</span><br><span class=\"line\"></span><br><span class=\"line\">    val addedPartitionReplicaAssignment = zkUtils.getReplicaAssignmentForTopics(newTopics.toSeq)</span><br><span class=\"line\">    controllerContext.partitionReplicaAssignment = controllerContext.partitionReplicaAssignment.filter(p =&gt;</span><br><span class=\"line\">      !deletedTopics.contains(p._1.topic))</span><br><span class=\"line\">    controllerContext.partitionReplicaAssignment.++=(addedPartitionReplicaAssignment)</span><br><span class=\"line\">    info(&quot;New topics: [%s], deleted topics: [%s], new partition replica assignment [%s]&quot;.format(newTopics,</span><br><span class=\"line\">      deletedTopics, addedPartitionReplicaAssignment))</span><br><span class=\"line\">    if (newTopics.nonEmpty)</span><br><span class=\"line\">      onNewTopicCreation(newTopics, addedPartitionReplicaAssignment.keySet)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/**</span><br><span class=\"line\">  * This callback is invoked by the topic change callback with the list of failed brokers as input.</span><br><span class=\"line\">  * It does the following -</span><br><span class=\"line\">  * 1. Move the newly created partitions to the NewPartition state</span><br><span class=\"line\">  * 2. Move the newly created partitions from NewPartition-&gt;OnlinePartition state</span><br><span class=\"line\">  */</span><br><span class=\"line\">def onNewPartitionCreation(newPartitions: Set[TopicAndPartition]) &#123;</span><br><span class=\"line\">  info(&quot;New partition creation callback for %s&quot;.format(newPartitions.mkString(&quot;,&quot;)))</span><br><span class=\"line\">  partitionStateMachine.handleStateChanges(newPartitions, NewPartition)</span><br><span class=\"line\">  replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), NewReplica)</span><br><span class=\"line\">  partitionStateMachine.handleStateChanges(newPartitions, OnlinePartition, offlinePartitionSelector)</span><br><span class=\"line\">  replicaStateMachine.handleStateChanges(controllerContext.replicasForPartition(newPartitions), OnlineReplica)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<h3 id=\"Kafka的consumer-offset一共有50个partition，那么我指定的某一个-topic-partition-的是被这50个consumer-offset中的哪个管理的？\"><a href=\"#Kafka的consumer-offset一共有50个partition，那么我指定的某一个-topic-partition-的是被这50个consumer-offset中的哪个管理的？\" class=\"headerlink\" title=\"Kafka的consumer_offset一共有50个partition，那么我指定的某一个(topic, partition)的是被这50个consumer_offset中的哪个管理的？\"></a>Kafka的<strong>consumer_offset一共有50个partition，那么我指定的某一个(topic, partition)的是被这50个</strong>consumer_offset中的哪个管理的？</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">case FindCoordinatorRequest.CoordinatorType.GROUP =&gt;</span><br><span class=\"line\">  val partition = groupCoordinator.partitionFor(findCoordinatorRequest.coordinatorKey)</span><br><span class=\"line\">  val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)</span><br><span class=\"line\">  (partition, metadata)</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"http://matt33.com/2017/10/22/consumer-join-group/\" target=\"_blank\" rel=\"noopener\">http://matt33.com/2017/10/22/consumer-join-group/</a></p>\n<h3 id=\"Kafka中有哪些功能是这样的模式：1-修改ZK；-2-Broker监听到ZK变化；-3-Broker-根据ZK变化进行逻辑响应\"><a href=\"#Kafka中有哪些功能是这样的模式：1-修改ZK；-2-Broker监听到ZK变化；-3-Broker-根据ZK变化进行逻辑响应\" class=\"headerlink\" title=\"Kafka中有哪些功能是这样的模式：1. 修改ZK； 2. Broker监听到ZK变化； 3. Broker 根据ZK变化进行逻辑响应\"></a>Kafka中有哪些功能是这样的模式：1. 修改ZK； 2. Broker监听到ZK变化； 3. Broker 根据ZK变化进行逻辑响应</h3><ol>\n<li>Topic创建时，replica的assignment</li>\n<li>Topic的Reassignment</li>\n</ol>\n<h3 id=\"Kafka-Consumer消费流程\"><a href=\"#Kafka-Consumer消费流程\" class=\"headerlink\" title=\"Kafka Consumer消费流程\"></a>Kafka Consumer消费流程</h3><ol>\n<li>rebalance</li>\n<li>获取assign的(topic, partition)的消费位点</li>\n<li></li>\n</ol>\n<h3 id=\"Kafka-Broker在做”Join-Request”处理时，需要等待一个timeout的时间，好让所有相关的consumer都能来得及join进来？这个是怎么实现的？\"><a href=\"#Kafka-Broker在做”Join-Request”处理时，需要等待一个timeout的时间，好让所有相关的consumer都能来得及join进来？这个是怎么实现的？\" class=\"headerlink\" title=\"Kafka Broker在做”Join Request”处理时，需要等待一个timeout的时间，好让所有相关的consumer都能来得及join进来？这个是怎么实现的？\"></a>Kafka Broker在做”Join Request”处理时，需要等待一个timeout的时间，好让所有相关的consumer都能来得及join进来？这个是怎么实现的？</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private def prepareRebalance(group: GroupMetadata) &#123;</span><br><span class=\"line\">  // if any members are awaiting sync, cancel their request and have them rejoin</span><br><span class=\"line\">  if (group.is(AwaitingSync))</span><br><span class=\"line\">    resetAndPropagateAssignmentError(group, Errors.REBALANCE_IN_PROGRESS)</span><br><span class=\"line\"></span><br><span class=\"line\">  val delayedRebalance = if (group.is(Empty))</span><br><span class=\"line\">    new InitialDelayedJoin(this,</span><br><span class=\"line\">      joinPurgatory,</span><br><span class=\"line\">      group,</span><br><span class=\"line\">      groupConfig.groupInitialRebalanceDelayMs,</span><br><span class=\"line\">      groupConfig.groupInitialRebalanceDelayMs,</span><br><span class=\"line\">      max(group.rebalanceTimeoutMs - groupConfig.groupInitialRebalanceDelayMs, 0))</span><br><span class=\"line\">  else</span><br><span class=\"line\">    new DelayedJoin(this, group, group.rebalanceTimeoutMs)</span><br><span class=\"line\"></span><br><span class=\"line\">  group.transitionTo(PreparingRebalance)</span><br><span class=\"line\"></span><br><span class=\"line\">  info(s&quot;Preparing to rebalance group $&#123;group.groupId&#125; with old generation $&#123;group.generationId&#125; &quot; +</span><br><span class=\"line\">    s&quot;($&#123;Topic.GROUP_METADATA_TOPIC_NAME&#125;-$&#123;partitionFor(group.groupId)&#125;)&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">  val groupKey = GroupKey(group.groupId)</span><br><span class=\"line\">  joinPurgatory.tryCompleteElseWatch(delayedRebalance, Seq(groupKey))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"如果-topic-partiton-的leader在Broker3，Producer是怎么发送消息给Broker3的，是需要在启动的时候连接所有的Broker么？\"><a href=\"#如果-topic-partiton-的leader在Broker3，Producer是怎么发送消息给Broker3的，是需要在启动的时候连接所有的Broker么？\" class=\"headerlink\" title=\"如果(topic, partiton)的leader在Broker3，Producer是怎么发送消息给Broker3的，是需要在启动的时候连接所有的Broker么？\"></a>如果(topic, partiton)的leader在Broker3，Producer是怎么发送消息给Broker3的，是需要在启动的时候连接所有的Broker么？</h3><h3 id=\"如果需要消费在Broker2上的（topic-partition），Consumer是怎么去连接Broker2的，Consumer会连接整个集群所有的Broker么？\"><a href=\"#如果需要消费在Broker2上的（topic-partition），Consumer是怎么去连接Broker2的，Consumer会连接整个集群所有的Broker么？\" class=\"headerlink\" title=\"如果需要消费在Broker2上的（topic, partition），Consumer是怎么去连接Broker2的，Consumer会连接整个集群所有的Broker么？\"></a>如果需要消费在Broker2上的（topic, partition），Consumer是怎么去连接Broker2的，Consumer会连接整个集群所有的Broker么？</h3><ol>\n<li>先找GroupCoordinator，连接一台负载最低的机器，发送<code>Find Coordinator</code>命令<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">protected synchronized RequestFuture&lt;Void&gt; lookupCoordinator() &#123;</span><br><span class=\"line\">    if (findCoordinatorFuture == null) &#123;</span><br><span class=\"line\">        // find a node to ask about the coordinator</span><br><span class=\"line\">        Node node = this.client.leastLoadedNode();</span><br><span class=\"line\">        if (node == null) &#123;</span><br><span class=\"line\">            log.debug(&quot;No broker available to send FindCoordinator request&quot;);</span><br><span class=\"line\">            return RequestFuture.noBrokersAvailable();</span><br><span class=\"line\">        &#125; else</span><br><span class=\"line\">            findCoordinatorFuture = sendFindCoordinatorRequest(node);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return findCoordinatorFuture;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<h3 id=\"SkimpyOffsetMap-算是一个非常大的问题啊，万一消息被错误得compact怎么办呢？\"><a href=\"#SkimpyOffsetMap-算是一个非常大的问题啊，万一消息被错误得compact怎么办呢？\" class=\"headerlink\" title=\"SkimpyOffsetMap 算是一个非常大的问题啊，万一消息被错误得compact怎么办呢？\"></a>SkimpyOffsetMap 算是一个非常大的问题啊，万一消息被错误得compact怎么办呢？</h3><h3 id=\"假如我手动提交消息的offset，现在我业务处理失败，那么我消费端不提交offset，那么Kafka会把这个消息怎么处理呀？后续消费端还是否能够消费到？\"><a href=\"#假如我手动提交消息的offset，现在我业务处理失败，那么我消费端不提交offset，那么Kafka会把这个消息怎么处理呀？后续消费端还是否能够消费到？\" class=\"headerlink\" title=\"假如我手动提交消息的offset，现在我业务处理失败，那么我消费端不提交offset，那么Kafka会把这个消息怎么处理呀？后续消费端还是否能够消费到？\"></a>假如我手动提交消息的offset，现在我业务处理失败，那么我消费端不提交offset，那么Kafka会把这个消息怎么处理呀？后续消费端还是否能够消费到？</h3><h3 id=\"当某一个Partition的Leader挂了，Controller会为其选出一个新的Leader，这时是ISR中随便选一个么？\"><a href=\"#当某一个Partition的Leader挂了，Controller会为其选出一个新的Leader，这时是ISR中随便选一个么？\" class=\"headerlink\" title=\"当某一个Partition的Leader挂了，Controller会为其选出一个新的Leader，这时是ISR中随便选一个么？\"></a>当某一个Partition的Leader挂了，Controller会为其选出一个新的Leader，这时是ISR中随便选一个么？</h3><p>按照我的理解，应该是去选一个LEO最大的吧，完全错误<br>请分析这段代码<br>参考这篇：<br><a href=\"https://www.jianshu.com/p/13548893bf31\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/13548893bf31</a><br><a href=\"http://ifeve.com/kafka-controller/\" target=\"_blank\" rel=\"noopener\">http://ifeve.com/kafka-controller/</a></p>\n<p>真实日志</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kafka1/controller.log:[2019-10-04 08:26:01,376] DEBUG [PartitionStateMachine controllerId=1] After leader election, leader cache for krp-0 is updated to (Leader:2,ISR:2,1,LeaderEpoch:1,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)</span><br><span class=\"line\">➜  /tmp grep -R &quot;: current leader =&quot; kafka*</span><br><span class=\"line\">kafka1/controller.log:[2019-10-04 08:26:01,313] DEBUG [ControlledShutdownLeaderSelector]: Partition krp-0 : current leader = 3, new leader = 2 (kafka.controller.ControlledShutdownLeaderSelector)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">in kafka3/controller.log</span><br><span class=\"line\">[2019-10-04 08:26:02,132] INFO [controller-event-thread]: Shutting down (kafka.controller.ControllerEventManager$ControllerEventThread)</span><br><span class=\"line\">[2019-10-04 08:26:02,132] INFO [controller-event-thread]: Shutdown completed (kafka.controller.ControllerEventManager$ControllerEventThread)</span><br><span class=\"line\">[2019-10-04 08:26:02,133] INFO [controller-event-thread]: Stopped (kafka.controller.ControllerEventManager$ControllerEventThread)</span><br><span class=\"line\">[2019-10-04 08:26:02,133] DEBUG [Controller id=3] Resigning (kafka.controller.KafkaController)</span><br><span class=\"line\">[2019-10-04 08:26:02,133] DEBUG [Controller id=3] De-registering IsrChangeNotificationListener (kafka.controller.KafkaController)</span><br><span class=\"line\">[2019-10-04 08:26:02,134] DEBUG [Controller id=3] De-registering logDirEventNotificationListener (kafka.controller.KafkaController)</span><br><span class=\"line\">[2019-10-04 08:26:02,135] INFO [PartitionStateMachine controllerId=3] Stopped partition state machine (kafka.controller.PartitionStateMachine)</span><br><span class=\"line\">[2019-10-04 08:26:02,136] INFO [ReplicaStateMachine controllerId=3] Stopped replica state machine (kafka.controller.ReplicaStateMachine)</span><br><span class=\"line\">[2019-10-04 08:26:02,137] INFO [Controller id=3] Resigned (kafka.controller.KafkaController)</span><br><span class=\"line\"></span><br><span class=\"line\">in kafka1/controller.log</span><br><span class=\"line\">[2019-10-04 08:26:01,300] INFO [Controller id=1] Shutting down broker 3 (kafka.controller.KafkaController)</span><br><span class=\"line\">[2019-10-04 08:26:01,301] DEBUG [Controller id=1] All shutting down brokers: 3 (kafka.controller.KafkaController)</span><br><span class=\"line\">[2019-10-04 08:26:01,302] DEBUG [Controller id=1] Live brokers: 1,2 (kafka.controller.KafkaController)</span><br><span class=\"line\">[2019-10-04 08:26:01,308] INFO [PartitionStateMachine controllerId=1] Invoking state change to OnlinePartition for partitions krp-0 (kafka.controller.PartitionStateMachine)</span><br><span class=\"line\">[2019-10-04 08:26:01,313] DEBUG [ControlledShutdownLeaderSelector]: Partition krp-0 : current leader = 3, new leader = 2 (kafka.controller.ControlledShutdownLeaderSelector)</span><br><span class=\"line\">[2019-10-04 08:26:01,376] DEBUG [PartitionStateMachine controllerId=1] After leader election, leader cache for krp-0 is updated to (Leader:2,ISR:2,1,LeaderEpoch:1,ControllerEpoch:1) (kafka.controller.PartitionStateMachine)</span><br><span class=\"line\"></span><br><span class=\"line\">in kafka1/state-change.log</span><br><span class=\"line\">kafka1/state-change.log:[2019-10-04 08:26:01,376] TRACE [Controller id=1 epoch=1] Changed partition krp-0 from OnlinePartition to OnlinePartition with leader 2 (state.change.logger)</span><br></pre></td></tr></table></figure>\n\n<p>class ControlledShutdownLeaderSelector(controllerContext: ControllerContext) extends PartitionLeaderSelector with Logging {</p>\n<p>  logIdent = “[ControlledShutdownLeaderSelector]: “</p>\n<p>  def selectLeader(topicAndPartition: TopicAndPartition,<br>                   currentLeaderAndIsr: LeaderAndIsr): (LeaderAndIsr, Seq[Int]) = {<br>    val currentIsr = currentLeaderAndIsr.isr<br>    val assignedReplicas = controllerContext.partitionReplicaAssignment(topicAndPartition)<br>    val liveAssignedReplicas = assignedReplicas.filter(r =&gt; controllerContext.isReplicaOnline(r, topicAndPartition, true))</p>\n<pre><code>val newIsr = currentIsr.filter(brokerId =&gt; !controllerContext.shuttingDownBrokerIds.contains(brokerId))\nliveAssignedReplicas.find(newIsr.contains) match {\n  case Some(newLeader) =&gt;\n    debug(s&quot;Partition $topicAndPartition : current leader = ${currentLeaderAndIsr.leader}, new leader = $newLeader&quot;)\n    val newLeaderAndIsr = currentLeaderAndIsr.newLeaderAndIsr(newLeader, newIsr)\n    (newLeaderAndIsr, liveAssignedReplicas)\n  case None =&gt;\n    throw new StateChangeFailedException(s&quot;No other replicas in ISR ${currentIsr.mkString(&quot;,&quot;)} for $topicAndPartition &quot; +\n      s&quot;besides shutting down brokers ${controllerContext.shuttingDownBrokerIds.mkString(&quot;,&quot;)}&quot;)\n}</code></pre><p>  }<br>}</p>\n<h3 id=\"Consumer怎么去监控Rebalance事件？\"><a href=\"#Consumer怎么去监控Rebalance事件？\" class=\"headerlink\" title=\"Consumer怎么去监控Rebalance事件？\"></a>Consumer怎么去监控Rebalance事件？</h3><p>添加ConsumerRebalanceListener监听器</p>\n<h3 id=\"为什么要引入epoch？\"><a href=\"#为什么要引入epoch？\" class=\"headerlink\" title=\"为什么要引入epoch？\"></a>为什么要引入epoch？</h3><p>这个KIP写得非常清楚。<br>原先Truncate到HighWatermark处，但是这样做是有问题的，原因是Follower的HighWatermark是在消息存储后的下一轮RPC才获取到Leader的HighWatermark（Follower把消息接收后，然后发起FetchRPC告知Leader，Leader将自己的HighWatermark+1，这时Leader的返回值中含有最新的HighWatermark，但是如果这时Leader没有新的数据，这个Fetch请求就是一个长轮询请求，Follower将会延迟一段时间拿到最新的HighWatermark），这时如果Follower重启了，它将会把Leader已经确认过的HighWatermark对应的数据给Truncate掉。如果Leader这时也挂了，那么Follower将会成为新的Leader，中间的数据将会对消费者永久丢失。</p>\n<p><a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation#KIP-101-AlterReplicationProtocoltouseLeaderEpochratherthanHighWatermarkforTruncation-Scenario1:HighWatermarkTruncationfollowedbyImmediateLeaderElection\" target=\"_blank\" rel=\"noopener\">https://cwiki.apache.org/confluence/display/KAFKA/KIP-101+-+Alter+Replication+Protocol+to+use+Leader+Epoch+rather+than+High+Watermark+for+Truncation#KIP-101-AlterReplicationProtocoltouseLeaderEpochratherthanHighWatermarkforTruncation-Scenario1:HighWatermarkTruncationfollowedbyImmediateLeaderElection</a></p>\n<h3 id=\"日志truncate是怎么一回事？\"><a href=\"#日志truncate是怎么一回事？\" class=\"headerlink\" title=\"日志truncate是怎么一回事？\"></a>日志truncate是怎么一回事？</h3><ol>\n<li>ISR = {A, B, C}, HighWatermark = m1</li>\n</ol>\n<p>A: Leader    B: Follower  C: Follower<br>|   m1  |    |   m1  |    |   m1  |<br>|   m2  |    |   m2  |<br>|   m3  |</p>\n<ol start=\"2\">\n<li>A Crashes, New Leader: B, Question:这里C有可能成为Leader么？</li>\n</ol>\n<p>A: Crash     B: Leader    C: Follower<br>|   m1  |    |   m1  |    |   m1  |<br>|   m2  |    |   m2  |  &gt; |   m2  |<br>|   m3  |</p>\n<ol start=\"3\">\n<li>Send More messages</li>\n</ol>\n<p>A: Crash     B: Leader    C: Follower<br>|   m1  |    |   m1  |    |   m1  |<br>|   m2  |    |   m2  |    |   m2  |<br>|   m3  |    |   m4  |  &gt; |   m4  |<br>             |   m5  |  &gt; |   m5  |<br>             |   m6  |  &gt; |   m6  |</p>\n<ol start=\"4\">\n<li>A back to work, 之前commit到m1,Truncate m1之后的所有数据(这一步很重要),这个逻辑需要关注<br>ISR = {B, C}</li>\n</ol>\n<p>A: Folloer   B: Leader    C: Follower<br>|   m1  |    |   m1  |    |   m1  |<br>             |   m2  |    |   m2  |<br>             |   m4  |  &gt; |   m4  |<br>             |   m5  |  &gt; |   m5  |<br>             |   m6  |  &gt; |   m6  |</p>\n<ol start=\"5\">\n<li>A逐渐追上Leader<br>ISR = {A, B, C}</li>\n</ol>\n<p>A: Folloer   B: Leader    C: Follower<br>|   m1  |    |   m1  |    |   m1  |<br>|   m2  |  &lt; |   m2  |    |   m2  |<br>|   m4  |  &lt; |   m4  |  &gt; |   m4  |<br>|   m5  |  &lt; |   m5  |  &gt; |   m5  |<br>|   m6  |  &lt; |   m6  |  &gt; |   m6  |</p>\n<p>第4步中，A恢复后，是主动要truncate日志，还是新的Leader要求它去truncate日志？看下面的实现，貌似是follower会主动根据leader的epoch进行日志切割</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\">    * - Truncate the log to the leader&apos;s offset for each partition&apos;s epoch.</span><br><span class=\"line\">    * - If the leader&apos;s offset is greater, we stick with the Log End Offset</span><br><span class=\"line\">    *   otherwise we truncate to the leaders offset.</span><br><span class=\"line\">    * - If the leader replied with undefined epoch offset we must use the high watermark</span><br><span class=\"line\">    */</span><br><span class=\"line\">  override def maybeTruncate(fetchedEpochs: Map[TopicPartition, EpochEndOffset]): ResultWithPartitions[Map[TopicPartition, Long]] = &#123;</span><br><span class=\"line\">    val truncationPoints = scala.collection.mutable.HashMap.empty[TopicPartition, Long]</span><br><span class=\"line\">    val partitionsWithError = mutable.Set[TopicPartition]()</span><br><span class=\"line\"></span><br><span class=\"line\">    fetchedEpochs.foreach &#123; case (tp, epochOffset) =&gt;</span><br><span class=\"line\">      try &#123;</span><br><span class=\"line\">        val replica = replicaMgr.getReplicaOrException(tp)</span><br><span class=\"line\"></span><br><span class=\"line\">        if (epochOffset.hasError) &#123;</span><br><span class=\"line\">          info(s&quot;Retrying leaderEpoch request for partition $&#123;replica.topicPartition&#125; as the leader reported an error: $&#123;epochOffset.error&#125;&quot;)</span><br><span class=\"line\">          partitionsWithError += tp</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">          val truncationOffset =</span><br><span class=\"line\">            if (epochOffset.endOffset == UNDEFINED_EPOCH_OFFSET)</span><br><span class=\"line\">              highWatermark(replica, epochOffset)</span><br><span class=\"line\">            else if (epochOffset.endOffset &gt;= replica.logEndOffset.messageOffset)</span><br><span class=\"line\">              logEndOffset(replica, epochOffset)</span><br><span class=\"line\">            else</span><br><span class=\"line\">              epochOffset.endOffset</span><br><span class=\"line\"></span><br><span class=\"line\">          replicaMgr.logManager.truncateTo(Map(tp -&gt; truncationOffset))</span><br><span class=\"line\">          truncationPoints.put(tp, truncationOffset)</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125; catch &#123;</span><br><span class=\"line\">        case e: KafkaStorageException =&gt;</span><br><span class=\"line\">          info(s&quot;Failed to truncate $tp&quot;, e)</span><br><span class=\"line\">          partitionsWithError += tp</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    ResultWithPartitions(truncationPoints, partitionsWithError)</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">查找当前leader_epoch的最后一个offset</span><br><span class=\"line\">override def endOffsetFor(requestedEpoch: Int): Long = &#123;</span><br><span class=\"line\">    inReadLock(lock) &#123;</span><br><span class=\"line\">      val offset =</span><br><span class=\"line\">        if (requestedEpoch == UNDEFINED_EPOCH) &#123;</span><br><span class=\"line\">          // this may happen if a bootstrapping follower sends a request with undefined epoch or</span><br><span class=\"line\">          // a follower is on the older message format where leader epochs are not recorded</span><br><span class=\"line\">          UNDEFINED_EPOCH_OFFSET</span><br><span class=\"line\">        &#125; else if (requestedEpoch == latestEpoch) &#123;</span><br><span class=\"line\">          leo().messageOffset</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">          val subsequentEpochs = epochs.filter(e =&gt; e.epoch &gt; requestedEpoch)</span><br><span class=\"line\">          if (subsequentEpochs.isEmpty || requestedEpoch &lt; epochs.head.epoch)</span><br><span class=\"line\">            UNDEFINED_EPOCH_OFFSET</span><br><span class=\"line\">          else</span><br><span class=\"line\">            subsequentEpochs.head.startOffset</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      debug(s&quot;Processed offset for epoch request for partition $&#123;topicPartition&#125; epoch:$requestedEpoch and returning offset $offset from epoch list of size $&#123;epochs.size&#125;&quot;)</span><br><span class=\"line\">      offset</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"生产的消息何时被commit\"><a href=\"#生产的消息何时被commit\" class=\"headerlink\" title=\"生产的消息何时被commit\"></a>生产的消息何时被commit</h3><p>producer：acks=-1， broker： min.isr=2<br>如果发送一条消息给leader，leader本地持久化，那需要等待至少一个除了自己之后的isr成功拉取到数据，并且给leader确认后，<br>leader才会返回给producer，这条消息已经成功发送了。<br>这个时候的high watermark为isr的最小LEO值，消费者最多只能看见这个值之前的消息。</p>\n<h3 id=\"num-standby-replicas\"><a href=\"#num-standby-replicas\" class=\"headerlink\" title=\"num.standby.replicas\"></a>num.standby.replicas</h3><p>如果本机的local state挂了，那么根据kafka的consume rebalance，会在另一台机器上恢复state，但是这个恢复时间<br>可能会比较长，所以有num.standby.replicas这个参数，这个到底是什么意思？</p>\n<h3 id=\"kafka和RocketMQ设计导致得关键性差异——对多队列得支持程度\"><a href=\"#kafka和RocketMQ设计导致得关键性差异——对多队列得支持程度\" class=\"headerlink\" title=\"kafka和RocketMQ设计导致得关键性差异——对多队列得支持程度\"></a>kafka和RocketMQ设计导致得关键性差异——对多队列得支持程度</h3><p><a href=\"http://blog.csdn.net/chunlongyu/article/details/54576649\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/chunlongyu/article/details/54576649</a></p>\n<h3 id=\"这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\"><a href=\"#这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\" class=\"headerlink\" title=\"这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？\"></a>这个过程需要验证这个批次里面的每一个消息的CRC和size，也就是说要解压么？</h3><h3 id=\"在没有Zookeeper的情况下使用Kafka吗？\"><a href=\"#在没有Zookeeper的情况下使用Kafka吗？\" class=\"headerlink\" title=\"在没有Zookeeper的情况下使用Kafka吗？\"></a>在没有Zookeeper的情况下使用Kafka吗？</h3><h3 id=\"某一个-Topic-Partition-设置了3个Replica，分别在broker1-broker2-broker3上，对于每一个broker，它们的AR（assign-replica）是一样的么？\"><a href=\"#某一个-Topic-Partition-设置了3个Replica，分别在broker1-broker2-broker3上，对于每一个broker，它们的AR（assign-replica）是一样的么？\" class=\"headerlink\" title=\"某一个(Topic, Partition)设置了3个Replica，分别在broker1, broker2, broker3上，对于每一个broker，它们的AR（assign replica）是一样的么？\"></a>某一个(Topic, Partition)设置了3个Replica，分别在broker1, broker2, broker3上，对于每一个broker，它们的AR（assign replica）是一样的么？</h3><p>broker1: Leader(1), AR(1, 2, 3)<br>broker2: Follower(2), AR(1, 2, 3)<br>broker3: Follower(3), AR(1, 2, 3)</p>\n<h3 id=\"Follower向Leader发送Fetch请求，HW是怎么在Follower和Leader之间传递的？\"><a href=\"#Follower向Leader发送Fetch请求，HW是怎么在Follower和Leader之间传递的？\" class=\"headerlink\" title=\"Follower向Leader发送Fetch请求，HW是怎么在Follower和Leader之间传递的？\"></a>Follower向Leader发送Fetch请求，HW是怎么在Follower和Leader之间传递的？</h3><h3 id=\"什么叫某个-topic-partition-的Preferred-Leader？\"><a href=\"#什么叫某个-topic-partition-的Preferred-Leader？\" class=\"headerlink\" title=\"什么叫某个(topic, partition)的Preferred Leader？\"></a>什么叫某个(topic, partition)的Preferred Leader？</h3><p>(topic, partition)的AR中的第一个元素就是Preferred Leader。</p>\n<h3 id=\"如果首选的副本不在ISR中会发生什么\"><a href=\"#如果首选的副本不在ISR中会发生什么\" class=\"headerlink\" title=\"如果首选的副本不在ISR中会发生什么?\"></a>如果首选的副本不在ISR中会发生什么?</h3><p>Broker1: Leader(3), AR(1, 2, 3), ISR(2, 3)<br>如果这样的情况是普遍情况，会导致Broker一定程度得数据倾斜。</p>\n<h3 id=\"如果我指定了一个offset，Kafka怎么查找到对应的消息？\"><a href=\"#如果我指定了一个offset，Kafka怎么查找到对应的消息？\" class=\"headerlink\" title=\"如果我指定了一个offset，Kafka怎么查找到对应的消息？\"></a>如果我指定了一个offset，Kafka怎么查找到对应的消息？</h3><h3 id=\"如果我指定了一个timestamp，Kafka怎么查找到对应的消息？\"><a href=\"#如果我指定了一个timestamp，Kafka怎么查找到对应的消息？\" class=\"headerlink\" title=\"如果我指定了一个timestamp，Kafka怎么查找到对应的消息？\"></a>如果我指定了一个timestamp，Kafka怎么查找到对应的消息？</h3><h3 id=\"Kafka的延时操作是怎么实现的？\"><a href=\"#Kafka的延时操作是怎么实现的？\" class=\"headerlink\" title=\"Kafka的延时操作是怎么实现的？\"></a>Kafka的延时操作是怎么实现的？</h3><h3 id=\"Kafka中的Exactly-Once是怎么实现的？\"><a href=\"#Kafka中的Exactly-Once是怎么实现的？\" class=\"headerlink\" title=\"Kafka中的Exactly-Once是怎么实现的？\"></a>Kafka中的Exactly-Once是怎么实现的？</h3><p>目前理解：每一个Producer配置一个producerId，对于同一个Producer，每一条发送的消息有一个自增的序列号，如果Broker收到同一个Producer发送了相同的两个序列号，那么就要把相同的那个序列号丢弃掉。</p>\n<p>// now that we have valid records, offsets assigned, and timestamps updated, we need to<br>// validate the idempotent/transactional state of the producers and collect some metadata<br>val (updatedProducers, completedTxns, maybeDuplicate) = analyzeAndValidateProducerState(validRecords, isFromClient)<br>maybeDuplicate.foreach { duplicate =&gt;<br>  appendInfo.firstOffset = duplicate.firstOffset<br>  appendInfo.lastOffset = duplicate.lastOffset<br>  appendInfo.logAppendTime = duplicate.timestamp<br>  appendInfo.logStartOffset = logStartOffset<br>  return appendInfo<br>}</p>\n<h3 id=\"Kafka中的事务是怎么实现的？\"><a href=\"#Kafka中的事务是怎么实现的？\" class=\"headerlink\" title=\"Kafka中的事务是怎么实现的？\"></a>Kafka中的事务是怎么实现的？</h3><h3 id=\"Kafka如果需要拉取历史任务，怎么样解决Broker高Load问题？\"><a href=\"#Kafka如果需要拉取历史任务，怎么样解决Broker高Load问题？\" class=\"headerlink\" title=\"Kafka如果需要拉取历史任务，怎么样解决Broker高Load问题？\"></a>Kafka如果需要拉取历史任务，怎么样解决Broker高Load问题？</h3><p>Kafka本身有没有限流机制？</p>\n<h3 id=\"Kafka的consumer的心跳线程做什么事情？只是检测存活么？\"><a href=\"#Kafka的consumer的心跳线程做什么事情？只是检测存活么？\" class=\"headerlink\" title=\"Kafka的consumer的心跳线程做什么事情？只是检测存活么？\"></a>Kafka的consumer的心跳线程做什么事情？只是检测存活么？</h3><h3 id=\"Kafka-vagrant搭建\"><a href=\"#Kafka-vagrant搭建\" class=\"headerlink\" title=\"Kafka vagrant搭建\"></a>Kafka vagrant搭建</h3><p>vagrant box add <br><a href=\"https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/vagrant/trusty/current/trusty-server-cloudimg-amd64-vagrant-disk1.box\" target=\"_blank\" rel=\"noopener\">https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/vagrant/trusty/current/trusty-server-cloudimg-amd64-vagrant-disk1.box</a> <br>–name ubuntu/trusty64</p>\n<h3 id=\"consumer-offsets这个topic有什么特点？\"><a href=\"#consumer-offsets这个topic有什么特点？\" class=\"headerlink\" title=\"__consumer_offsets这个topic有什么特点？\"></a>__consumer_offsets这个topic有什么特点？</h3><p>根据理解，说的越多越好</p>\n<ol>\n<li>compaction</li>\n<li>retention</li>\n</ol>\n<h3 id=\"kafka的消费者Offset是KV-Map形式的，是怎么被维护在以List形式的-consumer-offsets上？\"><a href=\"#kafka的消费者Offset是KV-Map形式的，是怎么被维护在以List形式的-consumer-offsets上？\" class=\"headerlink\" title=\"kafka的消费者Offset是KV Map形式的，是怎么被维护在以List形式的__consumer_offsets上？\"></a>kafka的消费者Offset是KV Map形式的，是怎么被维护在以List形式的__consumer_offsets上？</h3><p><a href=\"https://www.jianshu.com/p/833b64e141f8\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/833b64e141f8</a></p>\n<h3 id=\"kafka在恢复kv结构的offset时，真的需要从头到尾进行遍历么？\"><a href=\"#kafka在恢复kv结构的offset时，真的需要从头到尾进行遍历么？\" class=\"headerlink\" title=\"kafka在恢复kv结构的offset时，真的需要从头到尾进行遍历么？\"></a>kafka在恢复kv结构的offset时，真的需要从头到尾进行遍历么？</h3><p>while (currOffset &lt; highWaterMark &amp;&amp; !shuttingDown.get()) {<br>这一段是什么意思？</p>\n<h3 id=\"消费者默认的消息事务隔离级别是什么？\"><a href=\"#消费者默认的消息事务隔离级别是什么？\" class=\"headerlink\" title=\"消费者默认的消息事务隔离级别是什么？\"></a>消费者默认的消息事务隔离级别是什么？</h3><p>我怎么记得是 read-uncommitted</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[2019-10-08 10:44:54,021] DEBUG [Consumer clientId=consumer-1, groupId=consumerGroup1] Added READ_UNCOMMITTED fetch request for partition krp-0 at offset 10 to node 172.16.115.163:9092 (id: 2 rack: null) (org.apache.kafka.clients.consumer.internals.Fetcher)</span><br></pre></td></tr></table></figure>\n\n<p>这个只针对事务消息，对一般的消息无效。</p>\n<h3 id=\"Kafka有没有类似于RocketMQ的ZeroCopy？\"><a href=\"#Kafka有没有类似于RocketMQ的ZeroCopy？\" class=\"headerlink\" title=\"Kafka有没有类似于RocketMQ的ZeroCopy？\"></a>Kafka有没有类似于RocketMQ的ZeroCopy？</h3><p>是用到了，但是在哪里用到的？这里写得很清楚。<br><a href=\"https://www.jianshu.com/p/d47de3d6d8ac\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/d47de3d6d8ac</a></p>\n<p>sendfile不是posix规范的api，要使用sendfile，在各个平台没有统一的规定，甚至连引入的头文件都没有做规范。<br>FileChannelImpl.c</p>\n<p>#if defined(<strong>linux</strong>) || defined(<strong>solaris</strong>)<br>#include &lt;sys/sendfile.h&gt;<br>#elif defined(_AIX)<br>#include &lt;sys/socket.h&gt;<br>#elif defined(_ALLBSD_SOURCE)<br>#include &lt;sys/socket.h&gt;<br>#include &lt;sys/uio.h&gt;<br>#define lseek64 lseek<br>#define mmap64 mmap<br>#endif</p>\n<h3 id=\"原先的GroupCoordinator宕机了，kafka是怎么检测到并且将GroupCoordinator转移到另一台机器，然后恢复-consumer-offsets数据的？\"><a href=\"#原先的GroupCoordinator宕机了，kafka是怎么检测到并且将GroupCoordinator转移到另一台机器，然后恢复-consumer-offsets数据的？\" class=\"headerlink\" title=\"原先的GroupCoordinator宕机了，kafka是怎么检测到并且将GroupCoordinator转移到另一台机器，然后恢复__consumer_offsets数据的？\"></a>原先的GroupCoordinator宕机了，kafka是怎么检测到并且将GroupCoordinator转移到另一台机器，然后恢复__consumer_offsets数据的？</h3><p><a href=\"https://www.jianshu.com/p/833b64e141f8\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/833b64e141f8</a><br>按照这个文章，好像说是在收到了 LeaderAndIsr的请求后？？？</p>\n<h3 id=\"什么时候-「谁」-会调用-「谁」-的ApiKeys-LEADER-AND-ISR\"><a href=\"#什么时候-「谁」-会调用-「谁」-的ApiKeys-LEADER-AND-ISR\" class=\"headerlink\" title=\"什么时候 「谁」 会调用 「谁」 的ApiKeys.LEADER_AND_ISR?\"></a>什么时候 「谁」 会调用 「谁」 的ApiKeys.LEADER_AND_ISR?</h3><p>在每个Partition(.scala)中，在每次expandIsr或者shrinkIsr时，都需要在zk(/isr_change_notification)上记录，以此来达到事件传播(propagate)的效果。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def maybeExpandIsr(replicaId: Int, logReadResult: LogReadResult): Boolean = &#123;</span><br><span class=\"line\">  inWriteLock(leaderIsrUpdateLock) &#123;</span><br><span class=\"line\">    // check if this replica needs to be added to the ISR</span><br><span class=\"line\">    leaderReplicaIfLocal match &#123;</span><br><span class=\"line\">      case Some(leaderReplica) =&gt;</span><br><span class=\"line\">          ...</span><br><span class=\"line\">          // update ISR in ZK and cache</span><br><span class=\"line\">          updateIsr(newInSyncReplicas)</span><br><span class=\"line\">          ...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">      case None =&gt; false // nothing to do if no longer leader</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">def maybeShrinkIsr(replicaMaxLagTimeMs: Long) &#123;</span><br><span class=\"line\">  val leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) &#123;</span><br><span class=\"line\">    leaderReplicaIfLocal match &#123;</span><br><span class=\"line\">      case Some(leaderReplica) =&gt;</span><br><span class=\"line\">        val outOfSyncReplicas = getOutOfSyncReplicas(leaderReplica, replicaMaxLagTimeMs)</span><br><span class=\"line\">        if(outOfSyncReplicas.nonEmpty) &#123;</span><br><span class=\"line\">          ...</span><br><span class=\"line\">          // update ISR in zk and in cache</span><br><span class=\"line\">          updateIsr(newInSyncReplicas)</span><br><span class=\"line\">          ...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      case None =&gt; false // do nothing if no longer leader</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  // some delayed operations may be unblocked after HW changed</span><br><span class=\"line\">  if (leaderHWIncremented)</span><br><span class=\"line\">    tryCompleteDelayedRequests()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">def recordIsrChange(topicPartition: TopicPartition) &#123;</span><br><span class=\"line\">  isrChangeSet synchronized &#123;</span><br><span class=\"line\">    isrChangeSet += topicPartition</span><br><span class=\"line\">    lastIsrChangeMs.set(System.currentTimeMillis())</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">def maybePropagateIsrChanges() &#123;</span><br><span class=\"line\">  val now = System.currentTimeMillis()</span><br><span class=\"line\">  isrChangeSet synchronized &#123;</span><br><span class=\"line\">    if (isrChangeSet.nonEmpty &amp;&amp;</span><br><span class=\"line\">      (lastIsrChangeMs.get() + ReplicaManager.IsrChangePropagationBlackOut &lt; now ||</span><br><span class=\"line\">        lastIsrPropagationMs.get() + ReplicaManager.IsrChangePropagationInterval &lt; now)) &#123;</span><br><span class=\"line\">      ReplicationUtils.propagateIsrChanges(zkUtils, isrChangeSet)</span><br><span class=\"line\">      isrChangeSet.clear()</span><br><span class=\"line\">      lastIsrPropagationMs.set(now)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>controller在onControllerFailover的registerIsrChangeNotificationListener对上面的地址进行了监听。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private def registerIsrChangeNotificationListener() = &#123;</span><br><span class=\"line\">  debug(&quot;Registering IsrChangeNotificationListener&quot;)</span><br><span class=\"line\">  zkUtils.subscribeChildChanges(ZkUtils.IsrChangeNotificationPath, isrChangeNotificationListener)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Kafka中有哪些Coordinator\"><a href=\"#Kafka中有哪些Coordinator\" class=\"headerlink\" title=\"Kafka中有哪些Coordinator?\"></a>Kafka中有哪些Coordinator?</h3><h3 id=\"Kafka怎么做集群迁移？\"><a href=\"#Kafka怎么做集群迁移？\" class=\"headerlink\" title=\"Kafka怎么做集群迁移？\"></a>Kafka怎么做集群迁移？</h3><h3 id=\"Kafka怎么做集群扩容？\"><a href=\"#Kafka怎么做集群扩容？\" class=\"headerlink\" title=\"Kafka怎么做集群扩容？\"></a>Kafka怎么做集群扩容？</h3><h3 id=\"Kafka怎么Topic迁移？\"><a href=\"#Kafka怎么Topic迁移？\" class=\"headerlink\" title=\"Kafka怎么Topic迁移？\"></a>Kafka怎么Topic迁移？</h3><h3 id=\"Kafka在数据倾斜的时候做数据平衡？\"><a href=\"#Kafka在数据倾斜的时候做数据平衡？\" class=\"headerlink\" title=\"Kafka在数据倾斜的时候做数据平衡？\"></a>Kafka在数据倾斜的时候做数据平衡？</h3><h3 id=\"集群中的哪一台机器会成为某一个Consumer-Group的GroupCoordinator？\"><a href=\"#集群中的哪一台机器会成为某一个Consumer-Group的GroupCoordinator？\" class=\"headerlink\" title=\"集群中的哪一台机器会成为某一个Consumer Group的GroupCoordinator？\"></a>集群中的哪一台机器会成为某一个Consumer Group的GroupCoordinator？</h3><p>// get metadata (and create the topic if necessary)<br>val (partition, topicMetadata) = findCoordinatorRequest.coordinatorType match {<br>  case FindCoordinatorRequest.CoordinatorType.GROUP =&gt;<br>    val partition = groupCoordinator.partitionFor(findCoordinatorRequest.coordinatorKey)<br>    val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)<br>    (partition, metadata)</p>\n<h3 id=\"Varint怎么能减少数据传输量？\"><a href=\"#Varint怎么能减少数据传输量？\" class=\"headerlink\" title=\"Varint怎么能减少数据传输量？\"></a>Varint怎么能减少数据传输量？</h3><p><a href=\"http://www.zdingke.com/2018/03/17/kafka/?falerm=x2psz2\" target=\"_blank\" rel=\"noopener\">http://www.zdingke.com/2018/03/17/kafka/?falerm=x2psz2</a><br><a href=\"https://blog.csdn.net/u013256816/article/details/80300272\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u013256816/article/details/80300272</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Read an integer stored in variable-length format using zig-zag decoding from</span><br><span class=\"line\"> * &lt;a href=&quot;http://code.google.com/apis/protocolbuffers/docs/encoding.html&quot;&gt; Google Protocol Buffers&lt;/a&gt;.</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @param buffer The buffer to read from</span><br><span class=\"line\"> * @return The integer read</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @throws IllegalArgumentException if variable-length value does not terminate after 5 bytes have been read</span><br><span class=\"line\"> */</span><br><span class=\"line\">public static int readVarint(ByteBuffer buffer) &#123;</span><br><span class=\"line\">    int value = 0;</span><br><span class=\"line\">    int i = 0;</span><br><span class=\"line\">    int b;</span><br><span class=\"line\">    while (((b = buffer.get()) &amp; 0x80) != 0) &#123;</span><br><span class=\"line\">        value |= (b &amp; 0x7f) &lt;&lt; i;</span><br><span class=\"line\">        i += 7;</span><br><span class=\"line\">        if (i &gt; 28)</span><br><span class=\"line\">            throw illegalVarintException(value);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    value |= b &lt;&lt; i;</span><br><span class=\"line\">    return (value &gt;&gt;&gt; 1) ^ -(value &amp; 1);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/**</span><br><span class=\"line\"> * Write the given integer following the variable-length zig-zag encoding from</span><br><span class=\"line\"> * &lt;a href=&quot;http://code.google.com/apis/protocolbuffers/docs/encoding.html&quot;&gt; Google Protocol Buffers&lt;/a&gt;</span><br><span class=\"line\"> * into the buffer.</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @param value The value to write</span><br><span class=\"line\"> * @param buffer The output to write to</span><br><span class=\"line\"> */</span><br><span class=\"line\">public static void writeVarint(int value, ByteBuffer buffer) &#123;</span><br><span class=\"line\">    int v = (value &lt;&lt; 1) ^ (value &gt;&gt; 31);</span><br><span class=\"line\">    while ((v &amp; 0xffffff80) != 0L) &#123;</span><br><span class=\"line\">        byte b = (byte) ((v &amp; 0x7f) | 0x80);</span><br><span class=\"line\">        buffer.put(b);</span><br><span class=\"line\">        v &gt;&gt;&gt;= 7;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    buffer.put((byte) v);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Kafka-Rebalance-的时机是什么时候？-new-KafkaConsumer-后-还是-consumer-subscribe-后\"><a href=\"#Kafka-Rebalance-的时机是什么时候？-new-KafkaConsumer-后-还是-consumer-subscribe-后\" class=\"headerlink\" title=\"Kafka Rebalance 的时机是什么时候？ new KafkaConsumer() 后 还是 consumer.subscribe() 后?\"></a>Kafka Rebalance 的时机是什么时候？ new KafkaConsumer() 后 还是 consumer.subscribe() 后?</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">在调用poll()中才开始Rebalance</span><br><span class=\"line\"></span><br><span class=\"line\">if (needRejoin()) &#123;</span><br><span class=\"line\">    // due to a race condition between the initial metadata fetch and the initial rebalance,</span><br><span class=\"line\">    // we need to ensure that the metadata is fresh before joining initially. This ensures</span><br><span class=\"line\">    // that we have matched the pattern against the cluster&apos;s topics at least once before joining.</span><br><span class=\"line\">    if (subscriptions.hasPatternSubscription())</span><br><span class=\"line\">        client.ensureFreshMetadata();</span><br><span class=\"line\"></span><br><span class=\"line\">    ensureActiveGroup();</span><br><span class=\"line\">    now = time.milliseconds();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"如果某一ConsumerGroup的Consumer的数量发生变化，剩余的Consumer是如何检测到需要Rebalance了？\"><a href=\"#如果某一ConsumerGroup的Consumer的数量发生变化，剩余的Consumer是如何检测到需要Rebalance了？\" class=\"headerlink\" title=\"如果某一ConsumerGroup的Consumer的数量发生变化，剩余的Consumer是如何检测到需要Rebalance了？\"></a>如果某一ConsumerGroup的Consumer的数量发生变化，剩余的Consumer是如何检测到需要Rebalance了？</h3><p>Rebalance的触发是在consumer的poll操作中<br>是不是这段？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">public boolean needRejoin() &#123;</span><br><span class=\"line\">    if (!subscriptions.partitionsAutoAssigned())</span><br><span class=\"line\">        return false;</span><br><span class=\"line\"></span><br><span class=\"line\">    // we need to rejoin if we performed the assignment and metadata has changed</span><br><span class=\"line\">    if (assignmentSnapshot != null &amp;&amp; !assignmentSnapshot.equals(metadataSnapshot))</span><br><span class=\"line\">        return true;</span><br><span class=\"line\"></span><br><span class=\"line\">    // we need to join if our subscription has changed since the last join</span><br><span class=\"line\">    if (joinedSubscription != null &amp;&amp; !joinedSubscription.equals(subscriptions.subscription()))</span><br><span class=\"line\">        return true;</span><br><span class=\"line\"></span><br><span class=\"line\">    return super.needRejoin();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Kafka消费者Rebalance过程\"><a href=\"#Kafka消费者Rebalance过程\" class=\"headerlink\" title=\"Kafka消费者Rebalance过程\"></a>Kafka消费者Rebalance过程</h3><p>消费者查找GroupCoordinator<br>消费者主动向GroupCoordinator发起JOIN<br>作为GroupCoordinator的Broker接受到JOIN，选出一个Leader和epoch，给JOIN的成员发送响应<br>下面应该怎么弄啊？？？？写不下去了</p>\n<p>这种方式的好处是，Rebalance的算法可以放在客户端，而不需要放在Broker端。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[2019-10-09 16:29:26,866] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Kafka consumer initialized (org.apache.kafka.clients.consumer.KafkaConsumer)</span><br><span class=\"line\">[2019-10-09 16:29:26,867] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Subscribed to topic(s): hermes.demo.pandc (org.apache.kafka.clients.consumer.KafkaConsumer)</span><br><span class=\"line\">[2019-10-09 16:29:26,867] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Sending FindCoordinator request to broker localhost:9091 (id: -1 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,026] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Initiating connection to node localhost:9091 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient)</span><br><span class=\"line\">...</span><br><span class=\"line\">[2019-10-09 16:29:27,135] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Received FindCoordinator response ClientResponse(receivedTimeMs=1570609767134, latencyMs=118, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=1, clientId=consumer-1, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage=&apos;null&apos;, error=NONE, node=172.16.115.163:9092 (id: 2 rack: null))) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,135] INFO [Consumer clientId=consumer-1, groupId=cg1] Discovered group coordinator 172.16.115.163:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,135] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Initiating connection to node 172.16.115.163:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.NetworkClient)</span><br><span class=\"line\">[2019-10-09 16:29:27,137] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Heartbeat thread started (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,137] INFO [Consumer clientId=consumer-1, groupId=cg1] Revoking previously assigned partitions [] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,138] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Disabling heartbeat thread (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,138] INFO [Consumer clientId=consumer-1, groupId=cg1] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,141] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Sending JoinGroup ((type: JoinGroupRequest, groupId=cg1, sessionTimeout=10000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@23fe1d71)) to coordinator 172.16.115.163:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">...</span><br><span class=\"line\">[2019-10-09 16:29:27,150] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Received successful JoinGroup response: org.apache.kafka.common.requests.JoinGroupResponse@7403c468 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,150] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Performing assignment using strategy range with subscriptions &#123;consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd=Subscription(topics=[hermes.demo.pandc])&#125; (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,151] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Finished assignment for group: &#123;consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd=Assignment(partitions=[hermes.demo.pandc-0, hermes.demo.pandc-1])&#125; (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,152] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Sending leader SyncGroup to coordinator 172.16.115.163:9092 (id: 2147483645 rack: null): (type=SyncGroupRequest, groupId=cg1, generationId=13, memberId=consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd, groupAssignment=consumer-1-cce37b28-bff5-471b-84b8-c0d8f2316bdd) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,156] INFO [Consumer clientId=consumer-1, groupId=cg1] Successfully joined group with generation 13 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,156] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Enabling heartbeat thread (org.apache.kafka.clients.consumer.internals.AbstractCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,157] INFO [Consumer clientId=consumer-1, groupId=cg1] Setting newly assigned partitions [hermes.demo.pandc-1, hermes.demo.pandc-0] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,157] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Fetching committed offsets for partitions: [hermes.demo.pandc-1, hermes.demo.pandc-0] (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)</span><br><span class=\"line\">[2019-10-09 16:29:27,159] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Resetting offset for partition hermes.demo.pandc-1 to the committed offset 5 (org.apache.kafka.clients.consumer.internals.Fetcher)</span><br><span class=\"line\">[2019-10-09 16:29:27,159] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Resetting offset for partition hermes.demo.pandc-0 to the committed offset 9 (org.apache.kafka.clients.consumer.internals.Fetcher)</span><br><span class=\"line\">[2019-10-09 16:29:27,160] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Added READ_UNCOMMITTED fetch request for partition hermes.demo.pandc-1 at offset 5 to node 172.16.115.163:9091 (id: 1 rack: null) (org.apache.kafka.clients.consumer.internals.Fetcher)</span><br><span class=\"line\">[2019-10-09 16:29:27,160] DEBUG [Consumer clientId=consumer-1, groupId=cg1] Added READ_UNCOMMITTED fetch request for partition hermes.demo.pandc-0 at offset 9 to node 172.16.115.163:9091 (id: 1 rack: null) (org.apache.kafka.clients.consumer.internals.Fetcher)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"异步发送后，回调是否会按照发送的真实顺序进行回调？\"><a href=\"#异步发送后，回调是否会按照发送的真实顺序进行回调？\" class=\"headerlink\" title=\"异步发送后，回调是否会按照发送的真实顺序进行回调？\"></a>异步发送后，回调是否会按照发送的真实顺序进行回调？</h3><p>我的印象是可以的</p>\n<h3 id=\"Kafka是否支持Long-Polling\"><a href=\"#Kafka是否支持Long-Polling\" class=\"headerlink\" title=\"Kafka是否支持Long Polling\"></a>Kafka是否支持Long Polling</h3><p><a href=\"https://www.jianshu.com/p/34dc83e90f98\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/34dc83e90f98</a><br>支持：<br>/**</p>\n<ul>\n<li><code>fetch.max.wait.ms</code></li>\n<li>/<br>public static final String FETCH_MAX_WAIT_MS_CONFIG = “fetch.max.wait.ms”;<br>private static final String FETCH_MAX_WAIT_MS_DOC = “The maximum amount of time the server will block before answering the fetch request if there isn’t sufficient data to immediately satisfy the requirement given by fetch.min.bytes.”;</li>\n</ul>\n<p>// probably unblock some follower fetch requests since log end offset has been updated<br>replicaManager.tryCompleteDelayedFetch(TopicPartitionOperationKey(this.topic, this.partitionId))</p>\n<p>从下面的代码来看，貌似是支持的。<br>kafka.cluster.Partition#appendRecordsToLeader<br>// some delayed operations may be unblocked after HW changed<br>if (leaderHWIncremented)<br>  tryCompleteDelayedRequests()</p>\n<p>/**</p>\n<ul>\n<li>Try to complete any pending requests. This should be called without holding the leaderIsrUpdateLock.</li>\n<li>/<br>private def tryCompleteDelayedRequests() {<br>val requestKey = new TopicPartitionOperationKey(topicPartition)<br>replicaManager.tryCompleteDelayedFetch(requestKey)<br>replicaManager.tryCompleteDelayedProduce(requestKey)<br>replicaManager.tryCompleteDelayedDeleteRecords(requestKey)<br>}</li>\n</ul>\n<h3 id=\"学习资料\"><a href=\"#学习资料\" class=\"headerlink\" title=\"学习资料\"></a>学习资料</h3><p><a href=\"http://blog.csdn.net/chunlongyu/article/category/6638499\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/chunlongyu/article/category/6638499</a></p>\n<p><a href=\"http://blog.csdn.net/chunlongyu/article/details/54407633\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/chunlongyu/article/details/54407633</a></p>\n<p><a href=\"http://blog.csdn.net/a417930422/article/category/6086259\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/a417930422/article/category/6086259</a></p>\n<p><a href=\"http://blog.csdn.net/lizhitao\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/lizhitao</a></p>\n<p><a href=\"http://www.cnblogs.com/huxi2b\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/huxi2b</a></p>\n<p><a href=\"http://blog.csdn.net/u014393917/article/category/6332828\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/u014393917/article/category/6332828</a></p>\n<p>阿里中间件团队博客<br><a href=\"http://jm.taobao.org/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/\" target=\"_blank\" rel=\"noopener\">http://jm.taobao.org/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/</a></p>\n<p>第九课. Kafka高性能之道<br>    9.1 顺序写磁盘<br>    9.2 零拷贝<br>    9.3 批处理<br>    9.4 基于ISR的动态平衡一致性算法</p>\n"},{"title":"LevelDB","date":"2019-03-17T13:14:04.000Z","_content":"\n\n\n### 这篇文章很好的说明了Compaction\nhttps://www.cnblogs.com/KevinT/p/3819134.html\n\n### LevelDB compact 过程. 画图\nhttps://blog.csdn.net/baijiwei/article/details/83240078\n\nhttps://www.zhihu.com/question/19887265\n\n\n### LevelDB某一个值的多版本是怎么做的？\n\n\n### LevelDB参数调优\n\n\n### LevelDB: Read the Fucking Source Code\nhttp://www.grakra.com/2017/06/17/Leveldb-RTFSC/\n\n### 架构性\nhttps://zhuanlan.zhihu.com/p/54510835\n\n### LevelDB Cache —— Table Cache and Block Cache\nhttps://www.cnblogs.com/liuhao/archive/2012/11/29/2795455.html\n\n### LSM优化在SSD\nhttp://catkang.github.io/2017/04/30/lsm-upon-ssd.html\n\n### 牛逼啊\nhttps://www.bookstack.cn/read/system-design/cn-key-value-store.md\n\n### LSM理解\n所有的方法都可以有效的提高了读操作的性能（最少提供了O(log(n)) )，但是，却丢失了日志文件超好的写性能。上面这些方法，都强加了总体的结构信息在数据上，数据被按照特定的方式放置，所以可以很快的找到特定的数据，但是却对写操作不友善，让写操作性能下降。\n他们通过顺序的在文件末尾重复写对结构来实现写操作，之前的树结构的相关部分，包括最顶层结点都会变成孤结点。尽管通过这种方法避免了本地更新，但是因为每个写操作都要重写树结构，放大了写操作，降低了写性能。\n\n# LSM-tree以及基于其实现的存储引擎有以下特点：\n## 小的随机写IO被顺序化为大的连续IO；\n## 磁盘上的物理文件（sstable）被分层为多个level，且随着系统的运行，层级低的数据会向层级高的数据合并。\n\n因为LSM-tree将大量的随机IO变成了顺序IO，因此对HDD此类存储介质有着比较明显的性能提升。但同时，此架构也会带来如下一些问题，最主要的便是IO放大以及IO放大带来的副作用。\n\nLSM-tree结构之所以带来IO放大，是因为：\n## 写入时，除了将数据顺序写入日志外，还考虑将memtable写入level 0 的sstable以及由此带来的sstable合并问题，根据论文作者的计算，在极端情况下，可能带来的放大系数为10*Level；\n## 读取时，首先需要查找文件所在的sstable，由于sstable分层，因此该过程要由低向高level逐渐查找，在极端情况下，需要遍历所有sstable的元数据块，也带来了相当程度的读放大。\n\n而这种IO放大会带来怎样的副作用呢？\n## 显而易见的是IO效率的降低；\n## 对于SSD存储器件，这种放大还会导致存储硬件的寿命缩减。\n\n### 在SSD中，如何尽可能避免LSM读/写放大带来的影响？\nhttps://zhuanlan.zhihu.com/p/30773636\n```\n回顾上面的问题，当LSM中数据的长度很大时，这个问题变得尤为突出，这是因为：\n\n1. 数据长度越大，越容易触发Compaction，从而造成写放大；\n2. 如果把上层文件看做下层文件的cache，大数据长度会造成这个cache能cache的数据个数变少，从而读请求更大概率的需要访问下层数据，从而造成读放大；\n3. 每条数据每次Merge需要更多的写入量\n```\n但是，进一步分析，LSM需要的其实是key的有序，而跟value无关。所以自然而然的思路是\nKey Value 分离存储\n\n\n### 为什么会有归并排序\nhttps://www.codedump.info/post/20190215-leveldb/\nMergingIterator\n用于合并流程的迭代器。在合并过程中，需要操作memtable、immutable memtable、level 0 sstable以及非level 0的sstable，该迭代器将这些存储数据结构体的迭代器，统一进行归并排序\n\n\nEncodeVarint\n为什么要把整型（int）编码成变长整型（varint）呢？是为了尽可能的节约存储空间。\nvarint是一种紧凑的表示数字的方法，它用一个或多个字节来表示一个数字，值越小的数字使用越少的字节数。比如int32类型的数字，一般需要4个字节。但是采用Varint，对于很小的int32类型的数字，则可以用1个字节来表示。当然凡事都有好的也有不好的一面，采用varint表示法，大的数字则可能需要5个字节来表示。从统计的角度来说，一般不会所有消息中的数字都是大数，因此大多数情况下，采用varint后，可以用更小的字节数来表示数字信息。\nvarint中的每个字节的最高位（bit）有特殊含义，如果该位为1，表示后续的字节也是这个数字的一部分，如果该位为0，则结束。其他的7位（bit）都表示数字。7位能表示的最大数是127，因此小于128的数字都可以用一个字节表示。大于等于128的数字，比如说300，会用两个字节在内存中表示为：\n低               高\n1010 1100 0000 0010\n正常情况下，int需要32位，varint用一个字节的最高位作为标识位，所以，一个字节只能存储7位，如果整数特别大，可能需要5个字节才能存放（5*8-5（标志位）>32），下面if语句的第五个分支就是处理这种情况。\n---------------------\n作者：灿哥哥\n来源：CSDN\n原文：https://blog.csdn.net/caoshangpa/article/details/78815940\n版权声明：本文为博主原创文章，转载请附上博文链接！","source":"_posts/LevelDB.md","raw":"---\ntitle: LevelDB\ndate: 2019-03-17 21:14:04\ntags:\n---\n\n\n\n### 这篇文章很好的说明了Compaction\nhttps://www.cnblogs.com/KevinT/p/3819134.html\n\n### LevelDB compact 过程. 画图\nhttps://blog.csdn.net/baijiwei/article/details/83240078\n\nhttps://www.zhihu.com/question/19887265\n\n\n### LevelDB某一个值的多版本是怎么做的？\n\n\n### LevelDB参数调优\n\n\n### LevelDB: Read the Fucking Source Code\nhttp://www.grakra.com/2017/06/17/Leveldb-RTFSC/\n\n### 架构性\nhttps://zhuanlan.zhihu.com/p/54510835\n\n### LevelDB Cache —— Table Cache and Block Cache\nhttps://www.cnblogs.com/liuhao/archive/2012/11/29/2795455.html\n\n### LSM优化在SSD\nhttp://catkang.github.io/2017/04/30/lsm-upon-ssd.html\n\n### 牛逼啊\nhttps://www.bookstack.cn/read/system-design/cn-key-value-store.md\n\n### LSM理解\n所有的方法都可以有效的提高了读操作的性能（最少提供了O(log(n)) )，但是，却丢失了日志文件超好的写性能。上面这些方法，都强加了总体的结构信息在数据上，数据被按照特定的方式放置，所以可以很快的找到特定的数据，但是却对写操作不友善，让写操作性能下降。\n他们通过顺序的在文件末尾重复写对结构来实现写操作，之前的树结构的相关部分，包括最顶层结点都会变成孤结点。尽管通过这种方法避免了本地更新，但是因为每个写操作都要重写树结构，放大了写操作，降低了写性能。\n\n# LSM-tree以及基于其实现的存储引擎有以下特点：\n## 小的随机写IO被顺序化为大的连续IO；\n## 磁盘上的物理文件（sstable）被分层为多个level，且随着系统的运行，层级低的数据会向层级高的数据合并。\n\n因为LSM-tree将大量的随机IO变成了顺序IO，因此对HDD此类存储介质有着比较明显的性能提升。但同时，此架构也会带来如下一些问题，最主要的便是IO放大以及IO放大带来的副作用。\n\nLSM-tree结构之所以带来IO放大，是因为：\n## 写入时，除了将数据顺序写入日志外，还考虑将memtable写入level 0 的sstable以及由此带来的sstable合并问题，根据论文作者的计算，在极端情况下，可能带来的放大系数为10*Level；\n## 读取时，首先需要查找文件所在的sstable，由于sstable分层，因此该过程要由低向高level逐渐查找，在极端情况下，需要遍历所有sstable的元数据块，也带来了相当程度的读放大。\n\n而这种IO放大会带来怎样的副作用呢？\n## 显而易见的是IO效率的降低；\n## 对于SSD存储器件，这种放大还会导致存储硬件的寿命缩减。\n\n### 在SSD中，如何尽可能避免LSM读/写放大带来的影响？\nhttps://zhuanlan.zhihu.com/p/30773636\n```\n回顾上面的问题，当LSM中数据的长度很大时，这个问题变得尤为突出，这是因为：\n\n1. 数据长度越大，越容易触发Compaction，从而造成写放大；\n2. 如果把上层文件看做下层文件的cache，大数据长度会造成这个cache能cache的数据个数变少，从而读请求更大概率的需要访问下层数据，从而造成读放大；\n3. 每条数据每次Merge需要更多的写入量\n```\n但是，进一步分析，LSM需要的其实是key的有序，而跟value无关。所以自然而然的思路是\nKey Value 分离存储\n\n\n### 为什么会有归并排序\nhttps://www.codedump.info/post/20190215-leveldb/\nMergingIterator\n用于合并流程的迭代器。在合并过程中，需要操作memtable、immutable memtable、level 0 sstable以及非level 0的sstable，该迭代器将这些存储数据结构体的迭代器，统一进行归并排序\n\n\nEncodeVarint\n为什么要把整型（int）编码成变长整型（varint）呢？是为了尽可能的节约存储空间。\nvarint是一种紧凑的表示数字的方法，它用一个或多个字节来表示一个数字，值越小的数字使用越少的字节数。比如int32类型的数字，一般需要4个字节。但是采用Varint，对于很小的int32类型的数字，则可以用1个字节来表示。当然凡事都有好的也有不好的一面，采用varint表示法，大的数字则可能需要5个字节来表示。从统计的角度来说，一般不会所有消息中的数字都是大数，因此大多数情况下，采用varint后，可以用更小的字节数来表示数字信息。\nvarint中的每个字节的最高位（bit）有特殊含义，如果该位为1，表示后续的字节也是这个数字的一部分，如果该位为0，则结束。其他的7位（bit）都表示数字。7位能表示的最大数是127，因此小于128的数字都可以用一个字节表示。大于等于128的数字，比如说300，会用两个字节在内存中表示为：\n低               高\n1010 1100 0000 0010\n正常情况下，int需要32位，varint用一个字节的最高位作为标识位，所以，一个字节只能存储7位，如果整数特别大，可能需要5个字节才能存放（5*8-5（标志位）>32），下面if语句的第五个分支就是处理这种情况。\n---------------------\n作者：灿哥哥\n来源：CSDN\n原文：https://blog.csdn.net/caoshangpa/article/details/78815940\n版权声明：本文为博主原创文章，转载请附上博文链接！","slug":"LevelDB","published":1,"updated":"2019-10-11T12:36:41.875Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83n002tv1npk69h56m6","content":"<h3 id=\"这篇文章很好的说明了Compaction\"><a href=\"#这篇文章很好的说明了Compaction\" class=\"headerlink\" title=\"这篇文章很好的说明了Compaction\"></a>这篇文章很好的说明了Compaction</h3><p><a href=\"https://www.cnblogs.com/KevinT/p/3819134.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/KevinT/p/3819134.html</a></p>\n<h3 id=\"LevelDB-compact-过程-画图\"><a href=\"#LevelDB-compact-过程-画图\" class=\"headerlink\" title=\"LevelDB compact 过程. 画图\"></a>LevelDB compact 过程. 画图</h3><p><a href=\"https://blog.csdn.net/baijiwei/article/details/83240078\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/baijiwei/article/details/83240078</a></p>\n<p><a href=\"https://www.zhihu.com/question/19887265\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/19887265</a></p>\n<h3 id=\"LevelDB某一个值的多版本是怎么做的？\"><a href=\"#LevelDB某一个值的多版本是怎么做的？\" class=\"headerlink\" title=\"LevelDB某一个值的多版本是怎么做的？\"></a>LevelDB某一个值的多版本是怎么做的？</h3><h3 id=\"LevelDB参数调优\"><a href=\"#LevelDB参数调优\" class=\"headerlink\" title=\"LevelDB参数调优\"></a>LevelDB参数调优</h3><h3 id=\"LevelDB-Read-the-Fucking-Source-Code\"><a href=\"#LevelDB-Read-the-Fucking-Source-Code\" class=\"headerlink\" title=\"LevelDB: Read the Fucking Source Code\"></a>LevelDB: Read the Fucking Source Code</h3><p><a href=\"http://www.grakra.com/2017/06/17/Leveldb-RTFSC/\" target=\"_blank\" rel=\"noopener\">http://www.grakra.com/2017/06/17/Leveldb-RTFSC/</a></p>\n<h3 id=\"架构性\"><a href=\"#架构性\" class=\"headerlink\" title=\"架构性\"></a>架构性</h3><p><a href=\"https://zhuanlan.zhihu.com/p/54510835\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/54510835</a></p>\n<h3 id=\"LevelDB-Cache-——-Table-Cache-and-Block-Cache\"><a href=\"#LevelDB-Cache-——-Table-Cache-and-Block-Cache\" class=\"headerlink\" title=\"LevelDB Cache —— Table Cache and Block Cache\"></a>LevelDB Cache —— Table Cache and Block Cache</h3><p><a href=\"https://www.cnblogs.com/liuhao/archive/2012/11/29/2795455.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/liuhao/archive/2012/11/29/2795455.html</a></p>\n<h3 id=\"LSM优化在SSD\"><a href=\"#LSM优化在SSD\" class=\"headerlink\" title=\"LSM优化在SSD\"></a>LSM优化在SSD</h3><p><a href=\"http://catkang.github.io/2017/04/30/lsm-upon-ssd.html\" target=\"_blank\" rel=\"noopener\">http://catkang.github.io/2017/04/30/lsm-upon-ssd.html</a></p>\n<h3 id=\"牛逼啊\"><a href=\"#牛逼啊\" class=\"headerlink\" title=\"牛逼啊\"></a>牛逼啊</h3><p><a href=\"https://www.bookstack.cn/read/system-design/cn-key-value-store.md\" target=\"_blank\" rel=\"noopener\">https://www.bookstack.cn/read/system-design/cn-key-value-store.md</a></p>\n<h3 id=\"LSM理解\"><a href=\"#LSM理解\" class=\"headerlink\" title=\"LSM理解\"></a>LSM理解</h3><p>所有的方法都可以有效的提高了读操作的性能（最少提供了O(log(n)) )，但是，却丢失了日志文件超好的写性能。上面这些方法，都强加了总体的结构信息在数据上，数据被按照特定的方式放置，所以可以很快的找到特定的数据，但是却对写操作不友善，让写操作性能下降。<br>他们通过顺序的在文件末尾重复写对结构来实现写操作，之前的树结构的相关部分，包括最顶层结点都会变成孤结点。尽管通过这种方法避免了本地更新，但是因为每个写操作都要重写树结构，放大了写操作，降低了写性能。</p>\n<h1 id=\"LSM-tree以及基于其实现的存储引擎有以下特点：\"><a href=\"#LSM-tree以及基于其实现的存储引擎有以下特点：\" class=\"headerlink\" title=\"LSM-tree以及基于其实现的存储引擎有以下特点：\"></a>LSM-tree以及基于其实现的存储引擎有以下特点：</h1><h2 id=\"小的随机写IO被顺序化为大的连续IO；\"><a href=\"#小的随机写IO被顺序化为大的连续IO；\" class=\"headerlink\" title=\"小的随机写IO被顺序化为大的连续IO；\"></a>小的随机写IO被顺序化为大的连续IO；</h2><h2 id=\"磁盘上的物理文件（sstable）被分层为多个level，且随着系统的运行，层级低的数据会向层级高的数据合并。\"><a href=\"#磁盘上的物理文件（sstable）被分层为多个level，且随着系统的运行，层级低的数据会向层级高的数据合并。\" class=\"headerlink\" title=\"磁盘上的物理文件（sstable）被分层为多个level，且随着系统的运行，层级低的数据会向层级高的数据合并。\"></a>磁盘上的物理文件（sstable）被分层为多个level，且随着系统的运行，层级低的数据会向层级高的数据合并。</h2><p>因为LSM-tree将大量的随机IO变成了顺序IO，因此对HDD此类存储介质有着比较明显的性能提升。但同时，此架构也会带来如下一些问题，最主要的便是IO放大以及IO放大带来的副作用。</p>\n<p>LSM-tree结构之所以带来IO放大，是因为：</p>\n<h2 id=\"写入时，除了将数据顺序写入日志外，还考虑将memtable写入level-0-的sstable以及由此带来的sstable合并问题，根据论文作者的计算，在极端情况下，可能带来的放大系数为10-Level；\"><a href=\"#写入时，除了将数据顺序写入日志外，还考虑将memtable写入level-0-的sstable以及由此带来的sstable合并问题，根据论文作者的计算，在极端情况下，可能带来的放大系数为10-Level；\" class=\"headerlink\" title=\"写入时，除了将数据顺序写入日志外，还考虑将memtable写入level 0 的sstable以及由此带来的sstable合并问题，根据论文作者的计算，在极端情况下，可能带来的放大系数为10*Level；\"></a>写入时，除了将数据顺序写入日志外，还考虑将memtable写入level 0 的sstable以及由此带来的sstable合并问题，根据论文作者的计算，在极端情况下，可能带来的放大系数为10*Level；</h2><h2 id=\"读取时，首先需要查找文件所在的sstable，由于sstable分层，因此该过程要由低向高level逐渐查找，在极端情况下，需要遍历所有sstable的元数据块，也带来了相当程度的读放大。\"><a href=\"#读取时，首先需要查找文件所在的sstable，由于sstable分层，因此该过程要由低向高level逐渐查找，在极端情况下，需要遍历所有sstable的元数据块，也带来了相当程度的读放大。\" class=\"headerlink\" title=\"读取时，首先需要查找文件所在的sstable，由于sstable分层，因此该过程要由低向高level逐渐查找，在极端情况下，需要遍历所有sstable的元数据块，也带来了相当程度的读放大。\"></a>读取时，首先需要查找文件所在的sstable，由于sstable分层，因此该过程要由低向高level逐渐查找，在极端情况下，需要遍历所有sstable的元数据块，也带来了相当程度的读放大。</h2><p>而这种IO放大会带来怎样的副作用呢？</p>\n<h2 id=\"显而易见的是IO效率的降低；\"><a href=\"#显而易见的是IO效率的降低；\" class=\"headerlink\" title=\"显而易见的是IO效率的降低；\"></a>显而易见的是IO效率的降低；</h2><h2 id=\"对于SSD存储器件，这种放大还会导致存储硬件的寿命缩减。\"><a href=\"#对于SSD存储器件，这种放大还会导致存储硬件的寿命缩减。\" class=\"headerlink\" title=\"对于SSD存储器件，这种放大还会导致存储硬件的寿命缩减。\"></a>对于SSD存储器件，这种放大还会导致存储硬件的寿命缩减。</h2><h3 id=\"在SSD中，如何尽可能避免LSM读-写放大带来的影响？\"><a href=\"#在SSD中，如何尽可能避免LSM读-写放大带来的影响？\" class=\"headerlink\" title=\"在SSD中，如何尽可能避免LSM读/写放大带来的影响？\"></a>在SSD中，如何尽可能避免LSM读/写放大带来的影响？</h3><p><a href=\"https://zhuanlan.zhihu.com/p/30773636\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/30773636</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">回顾上面的问题，当LSM中数据的长度很大时，这个问题变得尤为突出，这是因为：</span><br><span class=\"line\"></span><br><span class=\"line\">1. 数据长度越大，越容易触发Compaction，从而造成写放大；</span><br><span class=\"line\">2. 如果把上层文件看做下层文件的cache，大数据长度会造成这个cache能cache的数据个数变少，从而读请求更大概率的需要访问下层数据，从而造成读放大；</span><br><span class=\"line\">3. 每条数据每次Merge需要更多的写入量</span><br></pre></td></tr></table></figure>\n\n<p>但是，进一步分析，LSM需要的其实是key的有序，而跟value无关。所以自然而然的思路是<br>Key Value 分离存储</p>\n<h3 id=\"为什么会有归并排序\"><a href=\"#为什么会有归并排序\" class=\"headerlink\" title=\"为什么会有归并排序\"></a>为什么会有归并排序</h3><p><a href=\"https://www.codedump.info/post/20190215-leveldb/\" target=\"_blank\" rel=\"noopener\">https://www.codedump.info/post/20190215-leveldb/</a><br>MergingIterator<br>用于合并流程的迭代器。在合并过程中，需要操作memtable、immutable memtable、level 0 sstable以及非level 0的sstable，该迭代器将这些存储数据结构体的迭代器，统一进行归并排序</p>\n<p>EncodeVarint<br>为什么要把整型（int）编码成变长整型（varint）呢？是为了尽可能的节约存储空间。<br>varint是一种紧凑的表示数字的方法，它用一个或多个字节来表示一个数字，值越小的数字使用越少的字节数。比如int32类型的数字，一般需要4个字节。但是采用Varint，对于很小的int32类型的数字，则可以用1个字节来表示。当然凡事都有好的也有不好的一面，采用varint表示法，大的数字则可能需要5个字节来表示。从统计的角度来说，一般不会所有消息中的数字都是大数，因此大多数情况下，采用varint后，可以用更小的字节数来表示数字信息。<br>varint中的每个字节的最高位（bit）有特殊含义，如果该位为1，表示后续的字节也是这个数字的一部分，如果该位为0，则结束。其他的7位（bit）都表示数字。7位能表示的最大数是127，因此小于128的数字都可以用一个字节表示。大于等于128的数字，比如说300，会用两个字节在内存中表示为：<br>低               高<br>1010 1100 0000 0010<br>正常情况下，int需要32位，varint用一个字节的最高位作为标识位，所以，一个字节只能存储7位，如果整数特别大，可能需要5个字节才能存放（5*8-5（标志位）&gt;32），下面if语句的第五个分支就是处理这种情况。</p>\n<hr>\n<p>作者：灿哥哥<br>来源：CSDN<br>原文：<a href=\"https://blog.csdn.net/caoshangpa/article/details/78815940\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/caoshangpa/article/details/78815940</a><br>版权声明：本文为博主原创文章，转载请附上博文链接！</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"这篇文章很好的说明了Compaction\"><a href=\"#这篇文章很好的说明了Compaction\" class=\"headerlink\" title=\"这篇文章很好的说明了Compaction\"></a>这篇文章很好的说明了Compaction</h3><p><a href=\"https://www.cnblogs.com/KevinT/p/3819134.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/KevinT/p/3819134.html</a></p>\n<h3 id=\"LevelDB-compact-过程-画图\"><a href=\"#LevelDB-compact-过程-画图\" class=\"headerlink\" title=\"LevelDB compact 过程. 画图\"></a>LevelDB compact 过程. 画图</h3><p><a href=\"https://blog.csdn.net/baijiwei/article/details/83240078\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/baijiwei/article/details/83240078</a></p>\n<p><a href=\"https://www.zhihu.com/question/19887265\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/19887265</a></p>\n<h3 id=\"LevelDB某一个值的多版本是怎么做的？\"><a href=\"#LevelDB某一个值的多版本是怎么做的？\" class=\"headerlink\" title=\"LevelDB某一个值的多版本是怎么做的？\"></a>LevelDB某一个值的多版本是怎么做的？</h3><h3 id=\"LevelDB参数调优\"><a href=\"#LevelDB参数调优\" class=\"headerlink\" title=\"LevelDB参数调优\"></a>LevelDB参数调优</h3><h3 id=\"LevelDB-Read-the-Fucking-Source-Code\"><a href=\"#LevelDB-Read-the-Fucking-Source-Code\" class=\"headerlink\" title=\"LevelDB: Read the Fucking Source Code\"></a>LevelDB: Read the Fucking Source Code</h3><p><a href=\"http://www.grakra.com/2017/06/17/Leveldb-RTFSC/\" target=\"_blank\" rel=\"noopener\">http://www.grakra.com/2017/06/17/Leveldb-RTFSC/</a></p>\n<h3 id=\"架构性\"><a href=\"#架构性\" class=\"headerlink\" title=\"架构性\"></a>架构性</h3><p><a href=\"https://zhuanlan.zhihu.com/p/54510835\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/54510835</a></p>\n<h3 id=\"LevelDB-Cache-——-Table-Cache-and-Block-Cache\"><a href=\"#LevelDB-Cache-——-Table-Cache-and-Block-Cache\" class=\"headerlink\" title=\"LevelDB Cache —— Table Cache and Block Cache\"></a>LevelDB Cache —— Table Cache and Block Cache</h3><p><a href=\"https://www.cnblogs.com/liuhao/archive/2012/11/29/2795455.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/liuhao/archive/2012/11/29/2795455.html</a></p>\n<h3 id=\"LSM优化在SSD\"><a href=\"#LSM优化在SSD\" class=\"headerlink\" title=\"LSM优化在SSD\"></a>LSM优化在SSD</h3><p><a href=\"http://catkang.github.io/2017/04/30/lsm-upon-ssd.html\" target=\"_blank\" rel=\"noopener\">http://catkang.github.io/2017/04/30/lsm-upon-ssd.html</a></p>\n<h3 id=\"牛逼啊\"><a href=\"#牛逼啊\" class=\"headerlink\" title=\"牛逼啊\"></a>牛逼啊</h3><p><a href=\"https://www.bookstack.cn/read/system-design/cn-key-value-store.md\" target=\"_blank\" rel=\"noopener\">https://www.bookstack.cn/read/system-design/cn-key-value-store.md</a></p>\n<h3 id=\"LSM理解\"><a href=\"#LSM理解\" class=\"headerlink\" title=\"LSM理解\"></a>LSM理解</h3><p>所有的方法都可以有效的提高了读操作的性能（最少提供了O(log(n)) )，但是，却丢失了日志文件超好的写性能。上面这些方法，都强加了总体的结构信息在数据上，数据被按照特定的方式放置，所以可以很快的找到特定的数据，但是却对写操作不友善，让写操作性能下降。<br>他们通过顺序的在文件末尾重复写对结构来实现写操作，之前的树结构的相关部分，包括最顶层结点都会变成孤结点。尽管通过这种方法避免了本地更新，但是因为每个写操作都要重写树结构，放大了写操作，降低了写性能。</p>\n<h1 id=\"LSM-tree以及基于其实现的存储引擎有以下特点：\"><a href=\"#LSM-tree以及基于其实现的存储引擎有以下特点：\" class=\"headerlink\" title=\"LSM-tree以及基于其实现的存储引擎有以下特点：\"></a>LSM-tree以及基于其实现的存储引擎有以下特点：</h1><h2 id=\"小的随机写IO被顺序化为大的连续IO；\"><a href=\"#小的随机写IO被顺序化为大的连续IO；\" class=\"headerlink\" title=\"小的随机写IO被顺序化为大的连续IO；\"></a>小的随机写IO被顺序化为大的连续IO；</h2><h2 id=\"磁盘上的物理文件（sstable）被分层为多个level，且随着系统的运行，层级低的数据会向层级高的数据合并。\"><a href=\"#磁盘上的物理文件（sstable）被分层为多个level，且随着系统的运行，层级低的数据会向层级高的数据合并。\" class=\"headerlink\" title=\"磁盘上的物理文件（sstable）被分层为多个level，且随着系统的运行，层级低的数据会向层级高的数据合并。\"></a>磁盘上的物理文件（sstable）被分层为多个level，且随着系统的运行，层级低的数据会向层级高的数据合并。</h2><p>因为LSM-tree将大量的随机IO变成了顺序IO，因此对HDD此类存储介质有着比较明显的性能提升。但同时，此架构也会带来如下一些问题，最主要的便是IO放大以及IO放大带来的副作用。</p>\n<p>LSM-tree结构之所以带来IO放大，是因为：</p>\n<h2 id=\"写入时，除了将数据顺序写入日志外，还考虑将memtable写入level-0-的sstable以及由此带来的sstable合并问题，根据论文作者的计算，在极端情况下，可能带来的放大系数为10-Level；\"><a href=\"#写入时，除了将数据顺序写入日志外，还考虑将memtable写入level-0-的sstable以及由此带来的sstable合并问题，根据论文作者的计算，在极端情况下，可能带来的放大系数为10-Level；\" class=\"headerlink\" title=\"写入时，除了将数据顺序写入日志外，还考虑将memtable写入level 0 的sstable以及由此带来的sstable合并问题，根据论文作者的计算，在极端情况下，可能带来的放大系数为10*Level；\"></a>写入时，除了将数据顺序写入日志外，还考虑将memtable写入level 0 的sstable以及由此带来的sstable合并问题，根据论文作者的计算，在极端情况下，可能带来的放大系数为10*Level；</h2><h2 id=\"读取时，首先需要查找文件所在的sstable，由于sstable分层，因此该过程要由低向高level逐渐查找，在极端情况下，需要遍历所有sstable的元数据块，也带来了相当程度的读放大。\"><a href=\"#读取时，首先需要查找文件所在的sstable，由于sstable分层，因此该过程要由低向高level逐渐查找，在极端情况下，需要遍历所有sstable的元数据块，也带来了相当程度的读放大。\" class=\"headerlink\" title=\"读取时，首先需要查找文件所在的sstable，由于sstable分层，因此该过程要由低向高level逐渐查找，在极端情况下，需要遍历所有sstable的元数据块，也带来了相当程度的读放大。\"></a>读取时，首先需要查找文件所在的sstable，由于sstable分层，因此该过程要由低向高level逐渐查找，在极端情况下，需要遍历所有sstable的元数据块，也带来了相当程度的读放大。</h2><p>而这种IO放大会带来怎样的副作用呢？</p>\n<h2 id=\"显而易见的是IO效率的降低；\"><a href=\"#显而易见的是IO效率的降低；\" class=\"headerlink\" title=\"显而易见的是IO效率的降低；\"></a>显而易见的是IO效率的降低；</h2><h2 id=\"对于SSD存储器件，这种放大还会导致存储硬件的寿命缩减。\"><a href=\"#对于SSD存储器件，这种放大还会导致存储硬件的寿命缩减。\" class=\"headerlink\" title=\"对于SSD存储器件，这种放大还会导致存储硬件的寿命缩减。\"></a>对于SSD存储器件，这种放大还会导致存储硬件的寿命缩减。</h2><h3 id=\"在SSD中，如何尽可能避免LSM读-写放大带来的影响？\"><a href=\"#在SSD中，如何尽可能避免LSM读-写放大带来的影响？\" class=\"headerlink\" title=\"在SSD中，如何尽可能避免LSM读/写放大带来的影响？\"></a>在SSD中，如何尽可能避免LSM读/写放大带来的影响？</h3><p><a href=\"https://zhuanlan.zhihu.com/p/30773636\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/30773636</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">回顾上面的问题，当LSM中数据的长度很大时，这个问题变得尤为突出，这是因为：</span><br><span class=\"line\"></span><br><span class=\"line\">1. 数据长度越大，越容易触发Compaction，从而造成写放大；</span><br><span class=\"line\">2. 如果把上层文件看做下层文件的cache，大数据长度会造成这个cache能cache的数据个数变少，从而读请求更大概率的需要访问下层数据，从而造成读放大；</span><br><span class=\"line\">3. 每条数据每次Merge需要更多的写入量</span><br></pre></td></tr></table></figure>\n\n<p>但是，进一步分析，LSM需要的其实是key的有序，而跟value无关。所以自然而然的思路是<br>Key Value 分离存储</p>\n<h3 id=\"为什么会有归并排序\"><a href=\"#为什么会有归并排序\" class=\"headerlink\" title=\"为什么会有归并排序\"></a>为什么会有归并排序</h3><p><a href=\"https://www.codedump.info/post/20190215-leveldb/\" target=\"_blank\" rel=\"noopener\">https://www.codedump.info/post/20190215-leveldb/</a><br>MergingIterator<br>用于合并流程的迭代器。在合并过程中，需要操作memtable、immutable memtable、level 0 sstable以及非level 0的sstable，该迭代器将这些存储数据结构体的迭代器，统一进行归并排序</p>\n<p>EncodeVarint<br>为什么要把整型（int）编码成变长整型（varint）呢？是为了尽可能的节约存储空间。<br>varint是一种紧凑的表示数字的方法，它用一个或多个字节来表示一个数字，值越小的数字使用越少的字节数。比如int32类型的数字，一般需要4个字节。但是采用Varint，对于很小的int32类型的数字，则可以用1个字节来表示。当然凡事都有好的也有不好的一面，采用varint表示法，大的数字则可能需要5个字节来表示。从统计的角度来说，一般不会所有消息中的数字都是大数，因此大多数情况下，采用varint后，可以用更小的字节数来表示数字信息。<br>varint中的每个字节的最高位（bit）有特殊含义，如果该位为1，表示后续的字节也是这个数字的一部分，如果该位为0，则结束。其他的7位（bit）都表示数字。7位能表示的最大数是127，因此小于128的数字都可以用一个字节表示。大于等于128的数字，比如说300，会用两个字节在内存中表示为：<br>低               高<br>1010 1100 0000 0010<br>正常情况下，int需要32位，varint用一个字节的最高位作为标识位，所以，一个字节只能存储7位，如果整数特别大，可能需要5个字节才能存放（5*8-5（标志位）&gt;32），下面if语句的第五个分支就是处理这种情况。</p>\n<hr>\n<p>作者：灿哥哥<br>来源：CSDN<br>原文：<a href=\"https://blog.csdn.net/caoshangpa/article/details/78815940\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/caoshangpa/article/details/78815940</a><br>版权声明：本文为博主原创文章，转载请附上博文链接！</p>\n"},{"title":"Kafka-Useful-Metrics","date":"2019-08-26T05:02:31.000Z","_content":"\n\n### consumer\nkafka.consumer\n    app-info:\n        consumer-1: [consumer]级别\n            commit-id\n            start-time-ms 启动时间\n            version 消费者版本\n\n    consumer-coordinator-metrics:\n        consumer-1: [consumer]级别\n\n            assigned-partitions 分配到的partition数量\n\n            commit-latency-avg 「commit请求」响应平均值\n            commit-latency-max 「commit请求」响应最大值\n            commit-rate 发送「commit请求」的频率\n            commit-total 发送「commit请求」的总数\n\n            heartbeat-rate 发送「heartbeat请求」的频率\n            heartbeat-response-time-max 「heartbeat请求」的响应最大值\n            heartbeat-total 发送「heartbeat请求」的数量\n            last-heartbeat-seconds-ago 距离上一次「heartbeat请求」的发送的时间\n\n            join-rate 发送「join请求」的频率\n            join-time-avg\n            join-time-max\n            join-total\n\n            sync-rate\n            sync-time-avg\n            sync-time-max\n            sync-total\n\n    consumer-fetch-manager-metrics:\n        consumer-1: [consumer]级别\n\n            fetch-total 发送「fetch请求」的数量\n\n            bytes-consumed-rate 接收消息byte的速率\n            bytes-consumed-total 接收消息byte数\n\n            records-consumed-total 接收消息数量\n            records-lag-max\n\n            hello-topic: [topic]级别\n                bytes-consumed-total\n                records-consumed-total\n\n    consumer-metrics:\n        consumer-1: [consumer]级别\n            connection-close-total\n            connection-count\n            connection-creation-rate\n            connection-creation-total\n\n            io-ratio\n            io-time-ns-avg\n            io-wait-ratio\n            io-wait-time-ns-avg\n            io-waittime-total\n            iotime-total\n\n            incoming-byte-rate\n            incoming-byte-total\n\n            outgoing-byte-rate\n            outgoing-byte-total\n\n            select-rate\n            select-total\n\n    consumer-node-metrics:\n        consumer-1:\n\n\n\n\n### producer\n\n### broker","source":"_posts/Kafka-Useful-Metrics.md","raw":"---\ntitle: Kafka-Useful-Metrics\ndate: 2019-08-26 13:02:31\ntags:\n---\n\n\n### consumer\nkafka.consumer\n    app-info:\n        consumer-1: [consumer]级别\n            commit-id\n            start-time-ms 启动时间\n            version 消费者版本\n\n    consumer-coordinator-metrics:\n        consumer-1: [consumer]级别\n\n            assigned-partitions 分配到的partition数量\n\n            commit-latency-avg 「commit请求」响应平均值\n            commit-latency-max 「commit请求」响应最大值\n            commit-rate 发送「commit请求」的频率\n            commit-total 发送「commit请求」的总数\n\n            heartbeat-rate 发送「heartbeat请求」的频率\n            heartbeat-response-time-max 「heartbeat请求」的响应最大值\n            heartbeat-total 发送「heartbeat请求」的数量\n            last-heartbeat-seconds-ago 距离上一次「heartbeat请求」的发送的时间\n\n            join-rate 发送「join请求」的频率\n            join-time-avg\n            join-time-max\n            join-total\n\n            sync-rate\n            sync-time-avg\n            sync-time-max\n            sync-total\n\n    consumer-fetch-manager-metrics:\n        consumer-1: [consumer]级别\n\n            fetch-total 发送「fetch请求」的数量\n\n            bytes-consumed-rate 接收消息byte的速率\n            bytes-consumed-total 接收消息byte数\n\n            records-consumed-total 接收消息数量\n            records-lag-max\n\n            hello-topic: [topic]级别\n                bytes-consumed-total\n                records-consumed-total\n\n    consumer-metrics:\n        consumer-1: [consumer]级别\n            connection-close-total\n            connection-count\n            connection-creation-rate\n            connection-creation-total\n\n            io-ratio\n            io-time-ns-avg\n            io-wait-ratio\n            io-wait-time-ns-avg\n            io-waittime-total\n            iotime-total\n\n            incoming-byte-rate\n            incoming-byte-total\n\n            outgoing-byte-rate\n            outgoing-byte-total\n\n            select-rate\n            select-total\n\n    consumer-node-metrics:\n        consumer-1:\n\n\n\n\n### producer\n\n### broker","slug":"Kafka-Useful-Metrics","published":1,"updated":"2019-09-28T08:51:00.881Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83o002uv1npq7tpj9lm","content":"<h3 id=\"consumer\"><a href=\"#consumer\" class=\"headerlink\" title=\"consumer\"></a>consumer</h3><p>kafka.consumer<br>    app-info:<br>        consumer-1: [consumer]级别<br>            commit-id<br>            start-time-ms 启动时间<br>            version 消费者版本</p>\n<pre><code>consumer-coordinator-metrics:\n    consumer-1: [consumer]级别\n\n        assigned-partitions 分配到的partition数量\n\n        commit-latency-avg 「commit请求」响应平均值\n        commit-latency-max 「commit请求」响应最大值\n        commit-rate 发送「commit请求」的频率\n        commit-total 发送「commit请求」的总数\n\n        heartbeat-rate 发送「heartbeat请求」的频率\n        heartbeat-response-time-max 「heartbeat请求」的响应最大值\n        heartbeat-total 发送「heartbeat请求」的数量\n        last-heartbeat-seconds-ago 距离上一次「heartbeat请求」的发送的时间\n\n        join-rate 发送「join请求」的频率\n        join-time-avg\n        join-time-max\n        join-total\n\n        sync-rate\n        sync-time-avg\n        sync-time-max\n        sync-total\n\nconsumer-fetch-manager-metrics:\n    consumer-1: [consumer]级别\n\n        fetch-total 发送「fetch请求」的数量\n\n        bytes-consumed-rate 接收消息byte的速率\n        bytes-consumed-total 接收消息byte数\n\n        records-consumed-total 接收消息数量\n        records-lag-max\n\n        hello-topic: [topic]级别\n            bytes-consumed-total\n            records-consumed-total\n\nconsumer-metrics:\n    consumer-1: [consumer]级别\n        connection-close-total\n        connection-count\n        connection-creation-rate\n        connection-creation-total\n\n        io-ratio\n        io-time-ns-avg\n        io-wait-ratio\n        io-wait-time-ns-avg\n        io-waittime-total\n        iotime-total\n\n        incoming-byte-rate\n        incoming-byte-total\n\n        outgoing-byte-rate\n        outgoing-byte-total\n\n        select-rate\n        select-total\n\nconsumer-node-metrics:\n    consumer-1:</code></pre><h3 id=\"producer\"><a href=\"#producer\" class=\"headerlink\" title=\"producer\"></a>producer</h3><h3 id=\"broker\"><a href=\"#broker\" class=\"headerlink\" title=\"broker\"></a>broker</h3>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"consumer\"><a href=\"#consumer\" class=\"headerlink\" title=\"consumer\"></a>consumer</h3><p>kafka.consumer<br>    app-info:<br>        consumer-1: [consumer]级别<br>            commit-id<br>            start-time-ms 启动时间<br>            version 消费者版本</p>\n<pre><code>consumer-coordinator-metrics:\n    consumer-1: [consumer]级别\n\n        assigned-partitions 分配到的partition数量\n\n        commit-latency-avg 「commit请求」响应平均值\n        commit-latency-max 「commit请求」响应最大值\n        commit-rate 发送「commit请求」的频率\n        commit-total 发送「commit请求」的总数\n\n        heartbeat-rate 发送「heartbeat请求」的频率\n        heartbeat-response-time-max 「heartbeat请求」的响应最大值\n        heartbeat-total 发送「heartbeat请求」的数量\n        last-heartbeat-seconds-ago 距离上一次「heartbeat请求」的发送的时间\n\n        join-rate 发送「join请求」的频率\n        join-time-avg\n        join-time-max\n        join-total\n\n        sync-rate\n        sync-time-avg\n        sync-time-max\n        sync-total\n\nconsumer-fetch-manager-metrics:\n    consumer-1: [consumer]级别\n\n        fetch-total 发送「fetch请求」的数量\n\n        bytes-consumed-rate 接收消息byte的速率\n        bytes-consumed-total 接收消息byte数\n\n        records-consumed-total 接收消息数量\n        records-lag-max\n\n        hello-topic: [topic]级别\n            bytes-consumed-total\n            records-consumed-total\n\nconsumer-metrics:\n    consumer-1: [consumer]级别\n        connection-close-total\n        connection-count\n        connection-creation-rate\n        connection-creation-total\n\n        io-ratio\n        io-time-ns-avg\n        io-wait-ratio\n        io-wait-time-ns-avg\n        io-waittime-total\n        iotime-total\n\n        incoming-byte-rate\n        incoming-byte-total\n\n        outgoing-byte-rate\n        outgoing-byte-total\n\n        select-rate\n        select-total\n\nconsumer-node-metrics:\n    consumer-1:</code></pre><h3 id=\"producer\"><a href=\"#producer\" class=\"headerlink\" title=\"producer\"></a>producer</h3><h3 id=\"broker\"><a href=\"#broker\" class=\"headerlink\" title=\"broker\"></a>broker</h3>"},{"title":"LevelDB-Options-Tuning","date":"2019-04-11T03:00:23.000Z","_content":"\n### 常用语调优的参数\n// memtable 的最大 size\nsize_t write_buffer_size;\n// db 中打开的文件最大个数\n// db 中需要打开的文件包括基本的 CURRENT/LOG/MANIFEST/LOCK, 以及打开的 sstable 文件。 // sstable 一旦打开，就会将 index 信息加入 TableCache，所以把\n// (max_open_files - 10)作为 table cache 的最大数量.\nint max_open_files;\n// 传入的 block 数据的 cache 管理\nCache* block_cache;\n// sstable 中 block 的 size\nsize_t block_size;\n// block 中对 key 做前缀压缩的区间长度\nint block_restart_interval;\n// 压缩数据使用的压缩类型(默认支持 snappy，其他类型需要使用者实现)\nCompressionType compression;\n\nnamespace config {\n// level 的最大值\nstatic const int kNumLevels = 7;\n// level-0 中 sstable 的数量超过这个阈值，触发 compact\nstatic const int kL0_CompactionTrigger = 4;\n// level-0 中 sstable 的数量超过这个阈值, 慢处理此次写(sleep1ms) static const int kL0_SlowdownWritesTrigger = 8;\n// level-0 中 sstable 的数量超过这个阈值, 阻塞至 compact memtable 完成。 static const int kL0_StopWritesTrigger = 12;\n// memtable dump 成的 sstable，允许推向的最高 level\n// (参见 Compact 流程的 VersionSet::PickLevelForMemTableOutput()) static const int kMaxMemCompactLevel = 2;\n}\n\n\n### leveldb中的写放大\n\n一条记录写到leveldb，则会写一次到log，写一次到level 0，随着后面更多数据的写入，level n里面的记录会与level n+1的记录合并排序，按照level n+1的数据量是level n的10倍，预计每提升一级，需要11个写，因此如果是7级的话，大约为68个写，即写放大为68。leveldb存放在内存中的数据大小write_buffer_size默认为4M，level 1的大小默认为10M。因此一个1TB的数据库会有7层。通过加大内存中的数据以及level 1的大小，例如设置write_buffer_size=1G，level1大小为4G，那么总共的层级只有5级，写放大大约为46，性能可以提升大约30%\n\n\n### leveldb中的读放大\n\n前一篇提到一次记录的读取需要多次文件读取，通过bloomfilter可以讲实际读取数据降到到接近1。我们来看看bloomfilter降低读取的原理。假设filter的bits为10，一个文件有1000个key，那么filter一共有1w个bit，对每个key计算hash值，把hash值模1w后对应的bit置为1，多计算几种hash值，都设置相应的bit为1。获取一个指定的key1时，按照前面的算法计算hash值检查bit值，如果这些bit值不是全1，那么可以肯定这个key1不在文件中。这样就可以通过不读取文件就判断key1是否在文件中。当然可能会出现全1但是key1又不在文件中，这样的情况就相当于是hash冲突了。通过查阅bloomfilter的资料，可以看到hash冲突的概率的情况为：\n10 bits     0.0081\n15 bits     0.0007\n19 bits      0.0001\n假设每次读取需要查找10个文件，那么10bits的hash冲突导致的多余读取为10 * 0.0081 = 0.081大约是8%\n我在实际使用tair中，当写入较多时，导致level0的数据可能达到32，这种情况下10bits的多余夺取为35 * 0.0081 = 0.2835大约是28%，此时应当增加bits，例如15bits则额外读为2.45%\n\n\n这两点是是实际使用中碰到的，可以提升实际的应用性能\n---------------------\n作者：dongfuye\n来源：CSDN\n原文：https://blog.csdn.net/dongfuye/article/details/46818023\n版权声明：本文为博主原创文章，转载请附上博文链接！","source":"_posts/LevelDB-Options-Tuning.md","raw":"---\ntitle: LevelDB-Options-Tuning\ndate: 2019-04-11 11:00:23\ntags:\n---\n\n### 常用语调优的参数\n// memtable 的最大 size\nsize_t write_buffer_size;\n// db 中打开的文件最大个数\n// db 中需要打开的文件包括基本的 CURRENT/LOG/MANIFEST/LOCK, 以及打开的 sstable 文件。 // sstable 一旦打开，就会将 index 信息加入 TableCache，所以把\n// (max_open_files - 10)作为 table cache 的最大数量.\nint max_open_files;\n// 传入的 block 数据的 cache 管理\nCache* block_cache;\n// sstable 中 block 的 size\nsize_t block_size;\n// block 中对 key 做前缀压缩的区间长度\nint block_restart_interval;\n// 压缩数据使用的压缩类型(默认支持 snappy，其他类型需要使用者实现)\nCompressionType compression;\n\nnamespace config {\n// level 的最大值\nstatic const int kNumLevels = 7;\n// level-0 中 sstable 的数量超过这个阈值，触发 compact\nstatic const int kL0_CompactionTrigger = 4;\n// level-0 中 sstable 的数量超过这个阈值, 慢处理此次写(sleep1ms) static const int kL0_SlowdownWritesTrigger = 8;\n// level-0 中 sstable 的数量超过这个阈值, 阻塞至 compact memtable 完成。 static const int kL0_StopWritesTrigger = 12;\n// memtable dump 成的 sstable，允许推向的最高 level\n// (参见 Compact 流程的 VersionSet::PickLevelForMemTableOutput()) static const int kMaxMemCompactLevel = 2;\n}\n\n\n### leveldb中的写放大\n\n一条记录写到leveldb，则会写一次到log，写一次到level 0，随着后面更多数据的写入，level n里面的记录会与level n+1的记录合并排序，按照level n+1的数据量是level n的10倍，预计每提升一级，需要11个写，因此如果是7级的话，大约为68个写，即写放大为68。leveldb存放在内存中的数据大小write_buffer_size默认为4M，level 1的大小默认为10M。因此一个1TB的数据库会有7层。通过加大内存中的数据以及level 1的大小，例如设置write_buffer_size=1G，level1大小为4G，那么总共的层级只有5级，写放大大约为46，性能可以提升大约30%\n\n\n### leveldb中的读放大\n\n前一篇提到一次记录的读取需要多次文件读取，通过bloomfilter可以讲实际读取数据降到到接近1。我们来看看bloomfilter降低读取的原理。假设filter的bits为10，一个文件有1000个key，那么filter一共有1w个bit，对每个key计算hash值，把hash值模1w后对应的bit置为1，多计算几种hash值，都设置相应的bit为1。获取一个指定的key1时，按照前面的算法计算hash值检查bit值，如果这些bit值不是全1，那么可以肯定这个key1不在文件中。这样就可以通过不读取文件就判断key1是否在文件中。当然可能会出现全1但是key1又不在文件中，这样的情况就相当于是hash冲突了。通过查阅bloomfilter的资料，可以看到hash冲突的概率的情况为：\n10 bits     0.0081\n15 bits     0.0007\n19 bits      0.0001\n假设每次读取需要查找10个文件，那么10bits的hash冲突导致的多余读取为10 * 0.0081 = 0.081大约是8%\n我在实际使用tair中，当写入较多时，导致level0的数据可能达到32，这种情况下10bits的多余夺取为35 * 0.0081 = 0.2835大约是28%，此时应当增加bits，例如15bits则额外读为2.45%\n\n\n这两点是是实际使用中碰到的，可以提升实际的应用性能\n---------------------\n作者：dongfuye\n来源：CSDN\n原文：https://blog.csdn.net/dongfuye/article/details/46818023\n版权声明：本文为博主原创文章，转载请附上博文链接！","slug":"LevelDB-Options-Tuning","published":1,"updated":"2019-09-28T08:51:00.882Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83o002vv1np48m6y29q","content":"<h3 id=\"常用语调优的参数\"><a href=\"#常用语调优的参数\" class=\"headerlink\" title=\"常用语调优的参数\"></a>常用语调优的参数</h3><p>// memtable 的最大 size<br>size_t write_buffer_size;<br>// db 中打开的文件最大个数<br>// db 中需要打开的文件包括基本的 CURRENT/LOG/MANIFEST/LOCK, 以及打开的 sstable 文件。 // sstable 一旦打开，就会将 index 信息加入 TableCache，所以把<br>// (max_open_files - 10)作为 table cache 的最大数量.<br>int max_open_files;<br>// 传入的 block 数据的 cache 管理<br>Cache* block_cache;<br>// sstable 中 block 的 size<br>size_t block_size;<br>// block 中对 key 做前缀压缩的区间长度<br>int block_restart_interval;<br>// 压缩数据使用的压缩类型(默认支持 snappy，其他类型需要使用者实现)<br>CompressionType compression;</p>\n<p>namespace config {<br>// level 的最大值<br>static const int kNumLevels = 7;<br>// level-0 中 sstable 的数量超过这个阈值，触发 compact<br>static const int kL0_CompactionTrigger = 4;<br>// level-0 中 sstable 的数量超过这个阈值, 慢处理此次写(sleep1ms) static const int kL0_SlowdownWritesTrigger = 8;<br>// level-0 中 sstable 的数量超过这个阈值, 阻塞至 compact memtable 完成。 static const int kL0_StopWritesTrigger = 12;<br>// memtable dump 成的 sstable，允许推向的最高 level<br>// (参见 Compact 流程的 VersionSet::PickLevelForMemTableOutput()) static const int kMaxMemCompactLevel = 2;<br>}</p>\n<h3 id=\"leveldb中的写放大\"><a href=\"#leveldb中的写放大\" class=\"headerlink\" title=\"leveldb中的写放大\"></a>leveldb中的写放大</h3><p>一条记录写到leveldb，则会写一次到log，写一次到level 0，随着后面更多数据的写入，level n里面的记录会与level n+1的记录合并排序，按照level n+1的数据量是level n的10倍，预计每提升一级，需要11个写，因此如果是7级的话，大约为68个写，即写放大为68。leveldb存放在内存中的数据大小write_buffer_size默认为4M，level 1的大小默认为10M。因此一个1TB的数据库会有7层。通过加大内存中的数据以及level 1的大小，例如设置write_buffer_size=1G，level1大小为4G，那么总共的层级只有5级，写放大大约为46，性能可以提升大约30%</p>\n<h3 id=\"leveldb中的读放大\"><a href=\"#leveldb中的读放大\" class=\"headerlink\" title=\"leveldb中的读放大\"></a>leveldb中的读放大</h3><p>前一篇提到一次记录的读取需要多次文件读取，通过bloomfilter可以讲实际读取数据降到到接近1。我们来看看bloomfilter降低读取的原理。假设filter的bits为10，一个文件有1000个key，那么filter一共有1w个bit，对每个key计算hash值，把hash值模1w后对应的bit置为1，多计算几种hash值，都设置相应的bit为1。获取一个指定的key1时，按照前面的算法计算hash值检查bit值，如果这些bit值不是全1，那么可以肯定这个key1不在文件中。这样就可以通过不读取文件就判断key1是否在文件中。当然可能会出现全1但是key1又不在文件中，这样的情况就相当于是hash冲突了。通过查阅bloomfilter的资料，可以看到hash冲突的概率的情况为：<br>10 bits     0.0081<br>15 bits     0.0007<br>19 bits      0.0001<br>假设每次读取需要查找10个文件，那么10bits的hash冲突导致的多余读取为10 * 0.0081 = 0.081大约是8%<br>我在实际使用tair中，当写入较多时，导致level0的数据可能达到32，这种情况下10bits的多余夺取为35 * 0.0081 = 0.2835大约是28%，此时应当增加bits，例如15bits则额外读为2.45%</p>\n<h2 id=\"这两点是是实际使用中碰到的，可以提升实际的应用性能\"><a href=\"#这两点是是实际使用中碰到的，可以提升实际的应用性能\" class=\"headerlink\" title=\"这两点是是实际使用中碰到的，可以提升实际的应用性能\"></a>这两点是是实际使用中碰到的，可以提升实际的应用性能</h2><p>作者：dongfuye<br>来源：CSDN<br>原文：<a href=\"https://blog.csdn.net/dongfuye/article/details/46818023\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/dongfuye/article/details/46818023</a><br>版权声明：本文为博主原创文章，转载请附上博文链接！</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"常用语调优的参数\"><a href=\"#常用语调优的参数\" class=\"headerlink\" title=\"常用语调优的参数\"></a>常用语调优的参数</h3><p>// memtable 的最大 size<br>size_t write_buffer_size;<br>// db 中打开的文件最大个数<br>// db 中需要打开的文件包括基本的 CURRENT/LOG/MANIFEST/LOCK, 以及打开的 sstable 文件。 // sstable 一旦打开，就会将 index 信息加入 TableCache，所以把<br>// (max_open_files - 10)作为 table cache 的最大数量.<br>int max_open_files;<br>// 传入的 block 数据的 cache 管理<br>Cache* block_cache;<br>// sstable 中 block 的 size<br>size_t block_size;<br>// block 中对 key 做前缀压缩的区间长度<br>int block_restart_interval;<br>// 压缩数据使用的压缩类型(默认支持 snappy，其他类型需要使用者实现)<br>CompressionType compression;</p>\n<p>namespace config {<br>// level 的最大值<br>static const int kNumLevels = 7;<br>// level-0 中 sstable 的数量超过这个阈值，触发 compact<br>static const int kL0_CompactionTrigger = 4;<br>// level-0 中 sstable 的数量超过这个阈值, 慢处理此次写(sleep1ms) static const int kL0_SlowdownWritesTrigger = 8;<br>// level-0 中 sstable 的数量超过这个阈值, 阻塞至 compact memtable 完成。 static const int kL0_StopWritesTrigger = 12;<br>// memtable dump 成的 sstable，允许推向的最高 level<br>// (参见 Compact 流程的 VersionSet::PickLevelForMemTableOutput()) static const int kMaxMemCompactLevel = 2;<br>}</p>\n<h3 id=\"leveldb中的写放大\"><a href=\"#leveldb中的写放大\" class=\"headerlink\" title=\"leveldb中的写放大\"></a>leveldb中的写放大</h3><p>一条记录写到leveldb，则会写一次到log，写一次到level 0，随着后面更多数据的写入，level n里面的记录会与level n+1的记录合并排序，按照level n+1的数据量是level n的10倍，预计每提升一级，需要11个写，因此如果是7级的话，大约为68个写，即写放大为68。leveldb存放在内存中的数据大小write_buffer_size默认为4M，level 1的大小默认为10M。因此一个1TB的数据库会有7层。通过加大内存中的数据以及level 1的大小，例如设置write_buffer_size=1G，level1大小为4G，那么总共的层级只有5级，写放大大约为46，性能可以提升大约30%</p>\n<h3 id=\"leveldb中的读放大\"><a href=\"#leveldb中的读放大\" class=\"headerlink\" title=\"leveldb中的读放大\"></a>leveldb中的读放大</h3><p>前一篇提到一次记录的读取需要多次文件读取，通过bloomfilter可以讲实际读取数据降到到接近1。我们来看看bloomfilter降低读取的原理。假设filter的bits为10，一个文件有1000个key，那么filter一共有1w个bit，对每个key计算hash值，把hash值模1w后对应的bit置为1，多计算几种hash值，都设置相应的bit为1。获取一个指定的key1时，按照前面的算法计算hash值检查bit值，如果这些bit值不是全1，那么可以肯定这个key1不在文件中。这样就可以通过不读取文件就判断key1是否在文件中。当然可能会出现全1但是key1又不在文件中，这样的情况就相当于是hash冲突了。通过查阅bloomfilter的资料，可以看到hash冲突的概率的情况为：<br>10 bits     0.0081<br>15 bits     0.0007<br>19 bits      0.0001<br>假设每次读取需要查找10个文件，那么10bits的hash冲突导致的多余读取为10 * 0.0081 = 0.081大约是8%<br>我在实际使用tair中，当写入较多时，导致level0的数据可能达到32，这种情况下10bits的多余夺取为35 * 0.0081 = 0.2835大约是28%，此时应当增加bits，例如15bits则额外读为2.45%</p>\n<h2 id=\"这两点是是实际使用中碰到的，可以提升实际的应用性能\"><a href=\"#这两点是是实际使用中碰到的，可以提升实际的应用性能\" class=\"headerlink\" title=\"这两点是是实际使用中碰到的，可以提升实际的应用性能\"></a>这两点是是实际使用中碰到的，可以提升实际的应用性能</h2><p>作者：dongfuye<br>来源：CSDN<br>原文：<a href=\"https://blog.csdn.net/dongfuye/article/details/46818023\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/dongfuye/article/details/46818023</a><br>版权声明：本文为博主原创文章，转载请附上博文链接！</p>\n"},{"title":"Linux-Context-Switch","date":"2018-07-30T11:32:58.000Z","_content":"\nhttp://www.361way.com/linux-context-switch/5131.html\n\nhttp://colobu.com/2016/04/12/context-switching-monitor/\n\nhttp://www.361way.com/linux-context-switch/5131.html\n\nhttp://www.cnblogs.com/pheye/p/4830058.html\n\n### 写得太好了\nhttps://blog.csdn.net/longerzone/article/details/8631183\n\n### 中断\nhttps://blog.csdn.net/zhouziyu2011/article/details/69817707","source":"_posts/Linux-Context-Switch.md","raw":"---\ntitle: Linux-Context-Switch\ndate: 2018-07-30 19:32:58\ntags:\n---\n\nhttp://www.361way.com/linux-context-switch/5131.html\n\nhttp://colobu.com/2016/04/12/context-switching-monitor/\n\nhttp://www.361way.com/linux-context-switch/5131.html\n\nhttp://www.cnblogs.com/pheye/p/4830058.html\n\n### 写得太好了\nhttps://blog.csdn.net/longerzone/article/details/8631183\n\n### 中断\nhttps://blog.csdn.net/zhouziyu2011/article/details/69817707","slug":"Linux-Context-Switch","published":1,"updated":"2019-09-28T08:51:00.882Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83p002wv1npk3hkxxxc","content":"<p><a href=\"http://www.361way.com/linux-context-switch/5131.html\" target=\"_blank\" rel=\"noopener\">http://www.361way.com/linux-context-switch/5131.html</a></p>\n<p><a href=\"http://colobu.com/2016/04/12/context-switching-monitor/\" target=\"_blank\" rel=\"noopener\">http://colobu.com/2016/04/12/context-switching-monitor/</a></p>\n<p><a href=\"http://www.361way.com/linux-context-switch/5131.html\" target=\"_blank\" rel=\"noopener\">http://www.361way.com/linux-context-switch/5131.html</a></p>\n<p><a href=\"http://www.cnblogs.com/pheye/p/4830058.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/pheye/p/4830058.html</a></p>\n<h3 id=\"写得太好了\"><a href=\"#写得太好了\" class=\"headerlink\" title=\"写得太好了\"></a>写得太好了</h3><p><a href=\"https://blog.csdn.net/longerzone/article/details/8631183\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/longerzone/article/details/8631183</a></p>\n<h3 id=\"中断\"><a href=\"#中断\" class=\"headerlink\" title=\"中断\"></a>中断</h3><p><a href=\"https://blog.csdn.net/zhouziyu2011/article/details/69817707\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zhouziyu2011/article/details/69817707</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://www.361way.com/linux-context-switch/5131.html\" target=\"_blank\" rel=\"noopener\">http://www.361way.com/linux-context-switch/5131.html</a></p>\n<p><a href=\"http://colobu.com/2016/04/12/context-switching-monitor/\" target=\"_blank\" rel=\"noopener\">http://colobu.com/2016/04/12/context-switching-monitor/</a></p>\n<p><a href=\"http://www.361way.com/linux-context-switch/5131.html\" target=\"_blank\" rel=\"noopener\">http://www.361way.com/linux-context-switch/5131.html</a></p>\n<p><a href=\"http://www.cnblogs.com/pheye/p/4830058.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/pheye/p/4830058.html</a></p>\n<h3 id=\"写得太好了\"><a href=\"#写得太好了\" class=\"headerlink\" title=\"写得太好了\"></a>写得太好了</h3><p><a href=\"https://blog.csdn.net/longerzone/article/details/8631183\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/longerzone/article/details/8631183</a></p>\n<h3 id=\"中断\"><a href=\"#中断\" class=\"headerlink\" title=\"中断\"></a>中断</h3><p><a href=\"https://blog.csdn.net/zhouziyu2011/article/details/69817707\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zhouziyu2011/article/details/69817707</a></p>\n"},{"title":"Linux-Ansible-Operation","date":"2018-07-25T11:34:47.000Z","_content":"\n\nsudo ansible -i ./zerodb-ansible/hosts proxy_public  -m \"shell\" -a \"free -h\" --private-key=~/.ssh/id_rsa -u nanxing\n\n### hosts\n[proxy_public]\n10.12.0.241\n10.12.1.[61:62]","source":"_posts/Linux-Ansible-Operation.md","raw":"---\ntitle: Linux-Ansible-Operation\ndate: 2018-07-25 19:34:47\ntags:\n---\n\n\nsudo ansible -i ./zerodb-ansible/hosts proxy_public  -m \"shell\" -a \"free -h\" --private-key=~/.ssh/id_rsa -u nanxing\n\n### hosts\n[proxy_public]\n10.12.0.241\n10.12.1.[61:62]","slug":"Linux-Ansible-Operation","published":1,"updated":"2019-09-28T08:51:00.882Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83p002xv1npfhww1cvm","content":"<p>sudo ansible -i ./zerodb-ansible/hosts proxy_public  -m “shell” -a “free -h” –private-key=~/.ssh/id_rsa -u nanxing</p>\n<h3 id=\"hosts\"><a href=\"#hosts\" class=\"headerlink\" title=\"hosts\"></a>hosts</h3><p>[proxy_public]<br>10.12.0.241<br>10.12.1.[61:62]</p>\n","site":{"data":{}},"excerpt":"","more":"<p>sudo ansible -i ./zerodb-ansible/hosts proxy_public  -m “shell” -a “free -h” –private-key=~/.ssh/id_rsa -u nanxing</p>\n<h3 id=\"hosts\"><a href=\"#hosts\" class=\"headerlink\" title=\"hosts\"></a>hosts</h3><p>[proxy_public]<br>10.12.0.241<br>10.12.1.[61:62]</p>\n"},{"title":"Linux-Cacheline","date":"2018-08-29T01:31:23.000Z","_content":"\n在一个高级语言中编程，理论上你只要把两个变量A和B定义在相邻的位置，就有可能公用同一个Cacheline。\n如果变量A的值被修改，OS会将整块Cacheline都置为失效，变量B在Cache中的值自然也失效了。\n如果要告诉JVM，定义在相邻位置的变量不要放在一个Cacheline中，那么需要使用Padding方式将变量相隔开。\n\n\n### linux cacheline\ncat /sys/devices/system/cpu/cpu1/cache/index0/coherency_line_size \n\n\n### 怎么写一个程序证明Cacheline在起作用\nhttp://processon.com/chart_image/5b85fd4ce4b06fc64ad9ebf5.png\n\nhttps://mp.weixin.qq.com/s?__biz=MzU0MzQ5MDA0Mw==&mid=2247484179&idx=1&sn=4251523d0fa59a53b4a4261818978f30&chksm=fb0be987cc7c6091a58fa0bc5278b99ff79c4054bebee4dabd34a62993e0f72c7703d0354f64&mpshare=1&scene=1&srcid=08295eOSDzz41jjz3kt8l2q6&key=ef1a4b05b697803cb8f54afe4edc2443783e0e02110f86a4ef8eb30b96b36f3e256cfba9721a9cca57fca60ca6d3b571c4555f2d5da6bf98f233876799e65900cdb847bee4f39152f77db07280bc0948&ascene=0&uin=MjcyMjMxNTA0Mg%3D%3D&devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12.6+build(16G1212)&version=12010210&nettype=WIFI&lang=zh_CN&fontScale=100&pass_ticket=9bTk3VRopZ%2FeeIIwYm7T5ZB9ac0zDWCk4nquX%2BTk%2B4982wcuo%2FydTBHDBJyIR2t2\n\n这篇文章从一个非常好的角度切入\n\n","source":"_posts/Linux-Cacheline.md","raw":"---\ntitle: Linux-Cacheline\ndate: 2018-08-29 09:31:23\ntags:\n---\n\n在一个高级语言中编程，理论上你只要把两个变量A和B定义在相邻的位置，就有可能公用同一个Cacheline。\n如果变量A的值被修改，OS会将整块Cacheline都置为失效，变量B在Cache中的值自然也失效了。\n如果要告诉JVM，定义在相邻位置的变量不要放在一个Cacheline中，那么需要使用Padding方式将变量相隔开。\n\n\n### linux cacheline\ncat /sys/devices/system/cpu/cpu1/cache/index0/coherency_line_size \n\n\n### 怎么写一个程序证明Cacheline在起作用\nhttp://processon.com/chart_image/5b85fd4ce4b06fc64ad9ebf5.png\n\nhttps://mp.weixin.qq.com/s?__biz=MzU0MzQ5MDA0Mw==&mid=2247484179&idx=1&sn=4251523d0fa59a53b4a4261818978f30&chksm=fb0be987cc7c6091a58fa0bc5278b99ff79c4054bebee4dabd34a62993e0f72c7703d0354f64&mpshare=1&scene=1&srcid=08295eOSDzz41jjz3kt8l2q6&key=ef1a4b05b697803cb8f54afe4edc2443783e0e02110f86a4ef8eb30b96b36f3e256cfba9721a9cca57fca60ca6d3b571c4555f2d5da6bf98f233876799e65900cdb847bee4f39152f77db07280bc0948&ascene=0&uin=MjcyMjMxNTA0Mg%3D%3D&devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12.6+build(16G1212)&version=12010210&nettype=WIFI&lang=zh_CN&fontScale=100&pass_ticket=9bTk3VRopZ%2FeeIIwYm7T5ZB9ac0zDWCk4nquX%2BTk%2B4982wcuo%2FydTBHDBJyIR2t2\n\n这篇文章从一个非常好的角度切入\n\n","slug":"Linux-Cacheline","published":1,"updated":"2019-09-28T08:51:00.882Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83p002yv1npetb3obyh","content":"<p>在一个高级语言中编程，理论上你只要把两个变量A和B定义在相邻的位置，就有可能公用同一个Cacheline。<br>如果变量A的值被修改，OS会将整块Cacheline都置为失效，变量B在Cache中的值自然也失效了。<br>如果要告诉JVM，定义在相邻位置的变量不要放在一个Cacheline中，那么需要使用Padding方式将变量相隔开。</p>\n<h3 id=\"linux-cacheline\"><a href=\"#linux-cacheline\" class=\"headerlink\" title=\"linux cacheline\"></a>linux cacheline</h3><p>cat /sys/devices/system/cpu/cpu1/cache/index0/coherency_line_size </p>\n<h3 id=\"怎么写一个程序证明Cacheline在起作用\"><a href=\"#怎么写一个程序证明Cacheline在起作用\" class=\"headerlink\" title=\"怎么写一个程序证明Cacheline在起作用\"></a>怎么写一个程序证明Cacheline在起作用</h3><p><a href=\"http://processon.com/chart_image/5b85fd4ce4b06fc64ad9ebf5.png\" target=\"_blank\" rel=\"noopener\">http://processon.com/chart_image/5b85fd4ce4b06fc64ad9ebf5.png</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU0MzQ5MDA0Mw==&amp;mid=2247484179&amp;idx=1&amp;sn=4251523d0fa59a53b4a4261818978f30&amp;chksm=fb0be987cc7c6091a58fa0bc5278b99ff79c4054bebee4dabd34a62993e0f72c7703d0354f64&amp;mpshare=1&amp;scene=1&amp;srcid=08295eOSDzz41jjz3kt8l2q6&amp;key=ef1a4b05b697803cb8f54afe4edc2443783e0e02110f86a4ef8eb30b96b36f3e256cfba9721a9cca57fca60ca6d3b571c4555f2d5da6bf98f233876799e65900cdb847bee4f39152f77db07280bc0948&amp;ascene=0&amp;uin=MjcyMjMxNTA0Mg%3D%3D&amp;devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12.6+build(16G1212)&amp;version=12010210&amp;nettype=WIFI&amp;lang=zh_CN&amp;fontScale=100&amp;pass_ticket=9bTk3VRopZ%2FeeIIwYm7T5ZB9ac0zDWCk4nquX%2BTk%2B4982wcuo%2FydTBHDBJyIR2t2\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s?__biz=MzU0MzQ5MDA0Mw==&amp;mid=2247484179&amp;idx=1&amp;sn=4251523d0fa59a53b4a4261818978f30&amp;chksm=fb0be987cc7c6091a58fa0bc5278b99ff79c4054bebee4dabd34a62993e0f72c7703d0354f64&amp;mpshare=1&amp;scene=1&amp;srcid=08295eOSDzz41jjz3kt8l2q6&amp;key=ef1a4b05b697803cb8f54afe4edc2443783e0e02110f86a4ef8eb30b96b36f3e256cfba9721a9cca57fca60ca6d3b571c4555f2d5da6bf98f233876799e65900cdb847bee4f39152f77db07280bc0948&amp;ascene=0&amp;uin=MjcyMjMxNTA0Mg%3D%3D&amp;devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12.6+build(16G1212)&amp;version=12010210&amp;nettype=WIFI&amp;lang=zh_CN&amp;fontScale=100&amp;pass_ticket=9bTk3VRopZ%2FeeIIwYm7T5ZB9ac0zDWCk4nquX%2BTk%2B4982wcuo%2FydTBHDBJyIR2t2</a></p>\n<p>这篇文章从一个非常好的角度切入</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在一个高级语言中编程，理论上你只要把两个变量A和B定义在相邻的位置，就有可能公用同一个Cacheline。<br>如果变量A的值被修改，OS会将整块Cacheline都置为失效，变量B在Cache中的值自然也失效了。<br>如果要告诉JVM，定义在相邻位置的变量不要放在一个Cacheline中，那么需要使用Padding方式将变量相隔开。</p>\n<h3 id=\"linux-cacheline\"><a href=\"#linux-cacheline\" class=\"headerlink\" title=\"linux cacheline\"></a>linux cacheline</h3><p>cat /sys/devices/system/cpu/cpu1/cache/index0/coherency_line_size </p>\n<h3 id=\"怎么写一个程序证明Cacheline在起作用\"><a href=\"#怎么写一个程序证明Cacheline在起作用\" class=\"headerlink\" title=\"怎么写一个程序证明Cacheline在起作用\"></a>怎么写一个程序证明Cacheline在起作用</h3><p><a href=\"http://processon.com/chart_image/5b85fd4ce4b06fc64ad9ebf5.png\" target=\"_blank\" rel=\"noopener\">http://processon.com/chart_image/5b85fd4ce4b06fc64ad9ebf5.png</a></p>\n<p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU0MzQ5MDA0Mw==&amp;mid=2247484179&amp;idx=1&amp;sn=4251523d0fa59a53b4a4261818978f30&amp;chksm=fb0be987cc7c6091a58fa0bc5278b99ff79c4054bebee4dabd34a62993e0f72c7703d0354f64&amp;mpshare=1&amp;scene=1&amp;srcid=08295eOSDzz41jjz3kt8l2q6&amp;key=ef1a4b05b697803cb8f54afe4edc2443783e0e02110f86a4ef8eb30b96b36f3e256cfba9721a9cca57fca60ca6d3b571c4555f2d5da6bf98f233876799e65900cdb847bee4f39152f77db07280bc0948&amp;ascene=0&amp;uin=MjcyMjMxNTA0Mg%3D%3D&amp;devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12.6+build(16G1212)&amp;version=12010210&amp;nettype=WIFI&amp;lang=zh_CN&amp;fontScale=100&amp;pass_ticket=9bTk3VRopZ%2FeeIIwYm7T5ZB9ac0zDWCk4nquX%2BTk%2B4982wcuo%2FydTBHDBJyIR2t2\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s?__biz=MzU0MzQ5MDA0Mw==&amp;mid=2247484179&amp;idx=1&amp;sn=4251523d0fa59a53b4a4261818978f30&amp;chksm=fb0be987cc7c6091a58fa0bc5278b99ff79c4054bebee4dabd34a62993e0f72c7703d0354f64&amp;mpshare=1&amp;scene=1&amp;srcid=08295eOSDzz41jjz3kt8l2q6&amp;key=ef1a4b05b697803cb8f54afe4edc2443783e0e02110f86a4ef8eb30b96b36f3e256cfba9721a9cca57fca60ca6d3b571c4555f2d5da6bf98f233876799e65900cdb847bee4f39152f77db07280bc0948&amp;ascene=0&amp;uin=MjcyMjMxNTA0Mg%3D%3D&amp;devicetype=iMac+MacBookPro11%2C4+OSX+OSX+10.12.6+build(16G1212)&amp;version=12010210&amp;nettype=WIFI&amp;lang=zh_CN&amp;fontScale=100&amp;pass_ticket=9bTk3VRopZ%2FeeIIwYm7T5ZB9ac0zDWCk4nquX%2BTk%2B4982wcuo%2FydTBHDBJyIR2t2</a></p>\n<p>这篇文章从一个非常好的角度切入</p>\n"},{"title":"Linux-DirectIO","date":"2019-03-18T10:38:35.000Z","_content":"\n\n### 为什么需要DirectIO?\nWhy do we need it?\nWith buffered I/O, the data is copied twice between storage and memory because of the page cache as the proxy between the two. In most cases, the introduction of page cache could achieve better performance. But for self-caching applications such as RocksDB, the application itself should have a better knowledge of the logical semantics of the data than OS, which provides a chance that the applications could implements more efficient replacement algorithm for cache with any application-defined data block as a unit by leveraging their knowledge of data semantics. On the other hand, in some situations, we want some data to opt-out of system cache. At this time, direct I/O would be a better choice.\n当我们的系统自己有设计Cache时","source":"_posts/Linux-DirectIO.md","raw":"---\ntitle: Linux-DirectIO\ndate: 2019-03-18 18:38:35\ntags:\n---\n\n\n### 为什么需要DirectIO?\nWhy do we need it?\nWith buffered I/O, the data is copied twice between storage and memory because of the page cache as the proxy between the two. In most cases, the introduction of page cache could achieve better performance. But for self-caching applications such as RocksDB, the application itself should have a better knowledge of the logical semantics of the data than OS, which provides a chance that the applications could implements more efficient replacement algorithm for cache with any application-defined data block as a unit by leveraging their knowledge of data semantics. On the other hand, in some situations, we want some data to opt-out of system cache. At this time, direct I/O would be a better choice.\n当我们的系统自己有设计Cache时","slug":"Linux-DirectIO","published":1,"updated":"2019-09-28T08:51:00.882Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83q002zv1npw6bez0sd","content":"<h3 id=\"为什么需要DirectIO\"><a href=\"#为什么需要DirectIO\" class=\"headerlink\" title=\"为什么需要DirectIO?\"></a>为什么需要DirectIO?</h3><p>Why do we need it?<br>With buffered I/O, the data is copied twice between storage and memory because of the page cache as the proxy between the two. In most cases, the introduction of page cache could achieve better performance. But for self-caching applications such as RocksDB, the application itself should have a better knowledge of the logical semantics of the data than OS, which provides a chance that the applications could implements more efficient replacement algorithm for cache with any application-defined data block as a unit by leveraging their knowledge of data semantics. On the other hand, in some situations, we want some data to opt-out of system cache. At this time, direct I/O would be a better choice.<br>当我们的系统自己有设计Cache时</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"为什么需要DirectIO\"><a href=\"#为什么需要DirectIO\" class=\"headerlink\" title=\"为什么需要DirectIO?\"></a>为什么需要DirectIO?</h3><p>Why do we need it?<br>With buffered I/O, the data is copied twice between storage and memory because of the page cache as the proxy between the two. In most cases, the introduction of page cache could achieve better performance. But for self-caching applications such as RocksDB, the application itself should have a better knowledge of the logical semantics of the data than OS, which provides a chance that the applications could implements more efficient replacement algorithm for cache with any application-defined data block as a unit by leveraging their knowledge of data semantics. On the other hand, in some situations, we want some data to opt-out of system cache. At this time, direct I/O would be a better choice.<br>当我们的系统自己有设计Cache时</p>\n"},{"title":"Linux-Disk-io-scheduler","date":"2019-02-26T14:13:09.000Z","_content":"\n\nhttps://www.cnblogs.com/bamanzi/p/linux-disk-io-scheduler.html\n```\nOn GNU/Linux, the queue scheduler determines the order in which requests to a block\ndevice are actually sent to the underlying device.\n\nThe default is Completely Fair Queueing, or cfq. It’s okay for casual use on laptops and desktops, where it helps prevent\nI/O starvation, but it’s terrible for servers. It causes very poor response times under the types of workload that MySQL generates, because it stalls some requests in the queue\nneedlessly.\n\nYou can see which schedulers are available, and which one is active, with the following\ncommand:\n\n$ cat /sys/block/sda/queue/scheduler\nnoop deadline [cfq]\nYou should replace sda with the device name of the disk you’re interested in. In our\nexample, the square brackets indicate which scheduler is in use for this device.\n\nThe\nother two choices are suitable for server-class hardware, and in most cases they work\nabout equally well. The noop scheduler is appropriate for devices that do their own\nscheduling behind the scenes, such as hardware RAID controllers and SANs, and deadline is fine both for RAID controllers and disks that are directly attached. Our benchmarks show very little difference between these two. The main thing is to use anything\nbut cfq, which can cause severe performance problems.\n\nTake this advice with a grain of salt, though, because the disk schedulers actually come\nin many variations in different kernels, and there is no indication of that in their names.\n```","source":"_posts/Linux-Disk-io-scheduler.md","raw":"---\ntitle: Linux-Disk-io-scheduler\ndate: 2019-02-26 22:13:09\ntags:\n---\n\n\nhttps://www.cnblogs.com/bamanzi/p/linux-disk-io-scheduler.html\n```\nOn GNU/Linux, the queue scheduler determines the order in which requests to a block\ndevice are actually sent to the underlying device.\n\nThe default is Completely Fair Queueing, or cfq. It’s okay for casual use on laptops and desktops, where it helps prevent\nI/O starvation, but it’s terrible for servers. It causes very poor response times under the types of workload that MySQL generates, because it stalls some requests in the queue\nneedlessly.\n\nYou can see which schedulers are available, and which one is active, with the following\ncommand:\n\n$ cat /sys/block/sda/queue/scheduler\nnoop deadline [cfq]\nYou should replace sda with the device name of the disk you’re interested in. In our\nexample, the square brackets indicate which scheduler is in use for this device.\n\nThe\nother two choices are suitable for server-class hardware, and in most cases they work\nabout equally well. The noop scheduler is appropriate for devices that do their own\nscheduling behind the scenes, such as hardware RAID controllers and SANs, and deadline is fine both for RAID controllers and disks that are directly attached. Our benchmarks show very little difference between these two. The main thing is to use anything\nbut cfq, which can cause severe performance problems.\n\nTake this advice with a grain of salt, though, because the disk schedulers actually come\nin many variations in different kernels, and there is no indication of that in their names.\n```","slug":"Linux-Disk-io-scheduler","published":1,"updated":"2019-09-28T08:51:00.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83q0030v1np3cpvqd0o","content":"<p><a href=\"https://www.cnblogs.com/bamanzi/p/linux-disk-io-scheduler.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/bamanzi/p/linux-disk-io-scheduler.html</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">On GNU/Linux, the queue scheduler determines the order in which requests to a block</span><br><span class=\"line\">device are actually sent to the underlying device.</span><br><span class=\"line\"></span><br><span class=\"line\">The default is Completely Fair Queueing, or cfq. It’s okay for casual use on laptops and desktops, where it helps prevent</span><br><span class=\"line\">I/O starvation, but it’s terrible for servers. It causes very poor response times under the types of workload that MySQL generates, because it stalls some requests in the queue</span><br><span class=\"line\">needlessly.</span><br><span class=\"line\"></span><br><span class=\"line\">You can see which schedulers are available, and which one is active, with the following</span><br><span class=\"line\">command:</span><br><span class=\"line\"></span><br><span class=\"line\">$ cat /sys/block/sda/queue/scheduler</span><br><span class=\"line\">noop deadline [cfq]</span><br><span class=\"line\">You should replace sda with the device name of the disk you’re interested in. In our</span><br><span class=\"line\">example, the square brackets indicate which scheduler is in use for this device.</span><br><span class=\"line\"></span><br><span class=\"line\">The</span><br><span class=\"line\">other two choices are suitable for server-class hardware, and in most cases they work</span><br><span class=\"line\">about equally well. The noop scheduler is appropriate for devices that do their own</span><br><span class=\"line\">scheduling behind the scenes, such as hardware RAID controllers and SANs, and deadline is fine both for RAID controllers and disks that are directly attached. Our benchmarks show very little difference between these two. The main thing is to use anything</span><br><span class=\"line\">but cfq, which can cause severe performance problems.</span><br><span class=\"line\"></span><br><span class=\"line\">Take this advice with a grain of salt, though, because the disk schedulers actually come</span><br><span class=\"line\">in many variations in different kernels, and there is no indication of that in their names.</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.cnblogs.com/bamanzi/p/linux-disk-io-scheduler.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/bamanzi/p/linux-disk-io-scheduler.html</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">On GNU/Linux, the queue scheduler determines the order in which requests to a block</span><br><span class=\"line\">device are actually sent to the underlying device.</span><br><span class=\"line\"></span><br><span class=\"line\">The default is Completely Fair Queueing, or cfq. It’s okay for casual use on laptops and desktops, where it helps prevent</span><br><span class=\"line\">I/O starvation, but it’s terrible for servers. It causes very poor response times under the types of workload that MySQL generates, because it stalls some requests in the queue</span><br><span class=\"line\">needlessly.</span><br><span class=\"line\"></span><br><span class=\"line\">You can see which schedulers are available, and which one is active, with the following</span><br><span class=\"line\">command:</span><br><span class=\"line\"></span><br><span class=\"line\">$ cat /sys/block/sda/queue/scheduler</span><br><span class=\"line\">noop deadline [cfq]</span><br><span class=\"line\">You should replace sda with the device name of the disk you’re interested in. In our</span><br><span class=\"line\">example, the square brackets indicate which scheduler is in use for this device.</span><br><span class=\"line\"></span><br><span class=\"line\">The</span><br><span class=\"line\">other two choices are suitable for server-class hardware, and in most cases they work</span><br><span class=\"line\">about equally well. The noop scheduler is appropriate for devices that do their own</span><br><span class=\"line\">scheduling behind the scenes, such as hardware RAID controllers and SANs, and deadline is fine both for RAID controllers and disks that are directly attached. Our benchmarks show very little difference between these two. The main thing is to use anything</span><br><span class=\"line\">but cfq, which can cause severe performance problems.</span><br><span class=\"line\"></span><br><span class=\"line\">Take this advice with a grain of salt, though, because the disk schedulers actually come</span><br><span class=\"line\">in many variations in different kernels, and there is no indication of that in their names.</span><br></pre></td></tr></table></figure>"},{"title":"Linux-Disk-io-test","date":"2018-09-22T06:20:03.000Z","_content":"\n\n### 测试写\ntime dd if=/dev/zero of=test.dbf bs=8k count=300000\n\n### 测试读\ntime dd if=/dev/sda1 of=/dev/null bs=8k count=300000\n","source":"_posts/Linux-Disk-io-test.md","raw":"---\ntitle: Linux-Disk-io-test\ndate: 2018-09-22 14:20:03\ntags:\n---\n\n\n### 测试写\ntime dd if=/dev/zero of=test.dbf bs=8k count=300000\n\n### 测试读\ntime dd if=/dev/sda1 of=/dev/null bs=8k count=300000\n","slug":"Linux-Disk-io-test","published":1,"updated":"2019-09-28T08:51:00.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83r0031v1npvo5rhord","content":"<h3 id=\"测试写\"><a href=\"#测试写\" class=\"headerlink\" title=\"测试写\"></a>测试写</h3><p>time dd if=/dev/zero of=test.dbf bs=8k count=300000</p>\n<h3 id=\"测试读\"><a href=\"#测试读\" class=\"headerlink\" title=\"测试读\"></a>测试读</h3><p>time dd if=/dev/sda1 of=/dev/null bs=8k count=300000</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"测试写\"><a href=\"#测试写\" class=\"headerlink\" title=\"测试写\"></a>测试写</h3><p>time dd if=/dev/zero of=test.dbf bs=8k count=300000</p>\n<h3 id=\"测试读\"><a href=\"#测试读\" class=\"headerlink\" title=\"测试读\"></a>测试读</h3><p>time dd if=/dev/sda1 of=/dev/null bs=8k count=300000</p>\n"},{"title":"Linux-Dmesg","date":"2018-09-22T14:13:13.000Z","_content":"\n\n","source":"_posts/Linux-Dmesg.md","raw":"---\ntitle: Linux-Dmesg\ndate: 2018-09-22 22:13:13\ntags:\n---\n\n\n","slug":"Linux-Dmesg","published":1,"updated":"2019-09-28T08:51:00.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83s0032v1npcypzcw21","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Linux-IO","date":"2019-03-16T06:12:07.000Z","_content":"\n\n### DirectIO方式读写文件\nhttps://blog.csdn.net/zhangxinrun/article/details/6874143","source":"_posts/Linux-IO.md","raw":"---\ntitle: Linux-IO\ndate: 2019-03-16 14:12:07\ntags:\n---\n\n\n### DirectIO方式读写文件\nhttps://blog.csdn.net/zhangxinrun/article/details/6874143","slug":"Linux-IO","published":1,"updated":"2019-09-28T08:51:00.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83s0033v1np04a8jykt","content":"<h3 id=\"DirectIO方式读写文件\"><a href=\"#DirectIO方式读写文件\" class=\"headerlink\" title=\"DirectIO方式读写文件\"></a>DirectIO方式读写文件</h3><p><a href=\"https://blog.csdn.net/zhangxinrun/article/details/6874143\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zhangxinrun/article/details/6874143</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"DirectIO方式读写文件\"><a href=\"#DirectIO方式读写文件\" class=\"headerlink\" title=\"DirectIO方式读写文件\"></a>DirectIO方式读写文件</h3><p><a href=\"https://blog.csdn.net/zhangxinrun/article/details/6874143\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zhangxinrun/article/details/6874143</a></p>\n"},{"title":"OS-Kernel-space-and-User-space","date":"2017-11-14T03:17:59.000Z","_content":"\nhttp://www.cnblogs.com/Anker/p/3269106.html\n","source":"_posts/Linux-Kernel-space-and-User-space.md","raw":"---\ntitle: OS-Kernel-space-and-User-space\ndate: 2017-11-14 11:17:59\ntags: Linux\n---\n\nhttp://www.cnblogs.com/Anker/p/3269106.html\n","slug":"Linux-Kernel-space-and-User-space","published":1,"updated":"2019-09-28T08:51:00.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83t0034v1nplwjsml4n","content":"<p><a href=\"http://www.cnblogs.com/Anker/p/3269106.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/Anker/p/3269106.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://www.cnblogs.com/Anker/p/3269106.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/Anker/p/3269106.html</a></p>\n"},{"title":"Linux-Madvise","date":"2018-09-26T02:05:09.000Z","_content":"\n\nmadvise, posix_madvise -- give advice about use of memory\n\n```\nDESCRIPTION\n     The madvise() system call allows a process that has knowledge of its memory behavior to describe it to the system.  The advice passed in\n     may be used by the system to alter its virtual memory paging strategy.  This advice may improve application and system performance.  The\n     behavior specified in advice can only be one of the following values:\n\n     MADV_NORMAL      Indicates that the application has no advice to give on its behavior in the specified address range.  This is the sys-\n                      tem default behavior.  This is used with madvise() system call.\n\n     POSIX_MADV_NORMAL\n                      Same as MADV_NORMAL but used with posix_madvise() system call.\n\n     MADV_SEQUENTIAL  Indicates that the application expects to access this address range in a sequential manner.  This is used with\n                      madvise() system call.\n\n     POSIX_MADV_SEQUENTIAL\n                      Same as MADV_SEQUENTIAL but used with posix_madvise() system call.\n\n     MADV_RANDOM      Indicates that the application expects to access this address range in a random manner.  This is used with madvise()\n                      system call.\n\n     POSIX_MADV_RANDOM\n                      Same as MADV_RANDOM but used with posix_madvise() system call.\n\n     MADV_WILLNEED    Indicates that the application expects to access this address range soon.  This is used with madvise() system call.\n\n     POSIX_MADV_WILLNEED\n                      Same as MADV_WILLNEED but used with posix_madvise() system call.\n\n     MADV_DONTNEED    Indicates that the application is not expecting to access this address range soon.  This is used with madvise() system\n                      call.\n\n     POSIX_MADV_DONTNEED\n                      Same as MADV_DONTNEED but used with posix_madvise() system call.\n\n     MADV_FREE        Indicates that the application will not need the information contained in this address range, so the pages may be\n                      reused right away.  The address range will remain valid.  This is used with madvise() system call.\n\n     MADV_ZERO_WIRED_PAGES\n                      Indicates that the application would like the wired pages in this address range to be zeroed out if the address range\n                      is deallocated without first unwiring the pages (i.e. a munmap(2) without a preceding munlock(2) or the application\n                      quits).  This is used with madvise() system call.\n\n```","source":"_posts/Linux-Madvise.md","raw":"---\ntitle: Linux-Madvise\ndate: 2018-09-26 10:05:09\ntags:\n---\n\n\nmadvise, posix_madvise -- give advice about use of memory\n\n```\nDESCRIPTION\n     The madvise() system call allows a process that has knowledge of its memory behavior to describe it to the system.  The advice passed in\n     may be used by the system to alter its virtual memory paging strategy.  This advice may improve application and system performance.  The\n     behavior specified in advice can only be one of the following values:\n\n     MADV_NORMAL      Indicates that the application has no advice to give on its behavior in the specified address range.  This is the sys-\n                      tem default behavior.  This is used with madvise() system call.\n\n     POSIX_MADV_NORMAL\n                      Same as MADV_NORMAL but used with posix_madvise() system call.\n\n     MADV_SEQUENTIAL  Indicates that the application expects to access this address range in a sequential manner.  This is used with\n                      madvise() system call.\n\n     POSIX_MADV_SEQUENTIAL\n                      Same as MADV_SEQUENTIAL but used with posix_madvise() system call.\n\n     MADV_RANDOM      Indicates that the application expects to access this address range in a random manner.  This is used with madvise()\n                      system call.\n\n     POSIX_MADV_RANDOM\n                      Same as MADV_RANDOM but used with posix_madvise() system call.\n\n     MADV_WILLNEED    Indicates that the application expects to access this address range soon.  This is used with madvise() system call.\n\n     POSIX_MADV_WILLNEED\n                      Same as MADV_WILLNEED but used with posix_madvise() system call.\n\n     MADV_DONTNEED    Indicates that the application is not expecting to access this address range soon.  This is used with madvise() system\n                      call.\n\n     POSIX_MADV_DONTNEED\n                      Same as MADV_DONTNEED but used with posix_madvise() system call.\n\n     MADV_FREE        Indicates that the application will not need the information contained in this address range, so the pages may be\n                      reused right away.  The address range will remain valid.  This is used with madvise() system call.\n\n     MADV_ZERO_WIRED_PAGES\n                      Indicates that the application would like the wired pages in this address range to be zeroed out if the address range\n                      is deallocated without first unwiring the pages (i.e. a munmap(2) without a preceding munlock(2) or the application\n                      quits).  This is used with madvise() system call.\n\n```","slug":"Linux-Madvise","published":1,"updated":"2019-09-28T08:51:00.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83t0035v1npcgbmgbij","content":"<p>madvise, posix_madvise – give advice about use of memory</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DESCRIPTION</span><br><span class=\"line\">     The madvise() system call allows a process that has knowledge of its memory behavior to describe it to the system.  The advice passed in</span><br><span class=\"line\">     may be used by the system to alter its virtual memory paging strategy.  This advice may improve application and system performance.  The</span><br><span class=\"line\">     behavior specified in advice can only be one of the following values:</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_NORMAL      Indicates that the application has no advice to give on its behavior in the specified address range.  This is the sys-</span><br><span class=\"line\">                      tem default behavior.  This is used with madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     POSIX_MADV_NORMAL</span><br><span class=\"line\">                      Same as MADV_NORMAL but used with posix_madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_SEQUENTIAL  Indicates that the application expects to access this address range in a sequential manner.  This is used with</span><br><span class=\"line\">                      madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     POSIX_MADV_SEQUENTIAL</span><br><span class=\"line\">                      Same as MADV_SEQUENTIAL but used with posix_madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_RANDOM      Indicates that the application expects to access this address range in a random manner.  This is used with madvise()</span><br><span class=\"line\">                      system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     POSIX_MADV_RANDOM</span><br><span class=\"line\">                      Same as MADV_RANDOM but used with posix_madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_WILLNEED    Indicates that the application expects to access this address range soon.  This is used with madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     POSIX_MADV_WILLNEED</span><br><span class=\"line\">                      Same as MADV_WILLNEED but used with posix_madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_DONTNEED    Indicates that the application is not expecting to access this address range soon.  This is used with madvise() system</span><br><span class=\"line\">                      call.</span><br><span class=\"line\"></span><br><span class=\"line\">     POSIX_MADV_DONTNEED</span><br><span class=\"line\">                      Same as MADV_DONTNEED but used with posix_madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_FREE        Indicates that the application will not need the information contained in this address range, so the pages may be</span><br><span class=\"line\">                      reused right away.  The address range will remain valid.  This is used with madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_ZERO_WIRED_PAGES</span><br><span class=\"line\">                      Indicates that the application would like the wired pages in this address range to be zeroed out if the address range</span><br><span class=\"line\">                      is deallocated without first unwiring the pages (i.e. a munmap(2) without a preceding munlock(2) or the application</span><br><span class=\"line\">                      quits).  This is used with madvise() system call.</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p>madvise, posix_madvise – give advice about use of memory</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DESCRIPTION</span><br><span class=\"line\">     The madvise() system call allows a process that has knowledge of its memory behavior to describe it to the system.  The advice passed in</span><br><span class=\"line\">     may be used by the system to alter its virtual memory paging strategy.  This advice may improve application and system performance.  The</span><br><span class=\"line\">     behavior specified in advice can only be one of the following values:</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_NORMAL      Indicates that the application has no advice to give on its behavior in the specified address range.  This is the sys-</span><br><span class=\"line\">                      tem default behavior.  This is used with madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     POSIX_MADV_NORMAL</span><br><span class=\"line\">                      Same as MADV_NORMAL but used with posix_madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_SEQUENTIAL  Indicates that the application expects to access this address range in a sequential manner.  This is used with</span><br><span class=\"line\">                      madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     POSIX_MADV_SEQUENTIAL</span><br><span class=\"line\">                      Same as MADV_SEQUENTIAL but used with posix_madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_RANDOM      Indicates that the application expects to access this address range in a random manner.  This is used with madvise()</span><br><span class=\"line\">                      system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     POSIX_MADV_RANDOM</span><br><span class=\"line\">                      Same as MADV_RANDOM but used with posix_madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_WILLNEED    Indicates that the application expects to access this address range soon.  This is used with madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     POSIX_MADV_WILLNEED</span><br><span class=\"line\">                      Same as MADV_WILLNEED but used with posix_madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_DONTNEED    Indicates that the application is not expecting to access this address range soon.  This is used with madvise() system</span><br><span class=\"line\">                      call.</span><br><span class=\"line\"></span><br><span class=\"line\">     POSIX_MADV_DONTNEED</span><br><span class=\"line\">                      Same as MADV_DONTNEED but used with posix_madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_FREE        Indicates that the application will not need the information contained in this address range, so the pages may be</span><br><span class=\"line\">                      reused right away.  The address range will remain valid.  This is used with madvise() system call.</span><br><span class=\"line\"></span><br><span class=\"line\">     MADV_ZERO_WIRED_PAGES</span><br><span class=\"line\">                      Indicates that the application would like the wired pages in this address range to be zeroed out if the address range</span><br><span class=\"line\">                      is deallocated without first unwiring the pages (i.e. a munmap(2) without a preceding munlock(2) or the application</span><br><span class=\"line\">                      quits).  This is used with madvise() system call.</span><br></pre></td></tr></table></figure>"},{"title":"Linux-Memory-allocation","date":"2018-11-23T02:52:16.000Z","_content":"\nhttps://blog.csdn.net/dc_neo/article/details/28427335","source":"_posts/Linux-Memory-allocation.md","raw":"---\ntitle: Linux-Memory-allocation\ndate: 2018-11-23 10:52:16\ntags:\n---\n\nhttps://blog.csdn.net/dc_neo/article/details/28427335","slug":"Linux-Memory-allocation","published":1,"updated":"2019-09-28T08:51:00.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83t0036v1npmwsnj7mi","content":"<p><a href=\"https://blog.csdn.net/dc_neo/article/details/28427335\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/dc_neo/article/details/28427335</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/dc_neo/article/details/28427335\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/dc_neo/article/details/28427335</a></p>\n"},{"title":"Linux-Memory-management","date":"2018-09-25T13:14:18.000Z","_content":"\nhttps://blog.csdn.net/adaptiver/article/details/7084364\n\n\nTerms\n\nVSS- Virtual Set Size 虚拟耗用内存（包含共享库占用的内存）\nRSS- Resident Set Size 实际使用物理内存（包含共享库占用的内存）\nPSS- Proportional Set Size 实际使用的物理内存（比例分配共享库占用的内存）\nUSS- Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存）\n一般来说内存占用大小有如下规律：VSS >= RSS >= PSS >= USS\n\n","source":"_posts/Linux-Memory-management.md","raw":"---\ntitle: Linux-Memory-management\ndate: 2018-09-25 21:14:18\ntags:\n---\n\nhttps://blog.csdn.net/adaptiver/article/details/7084364\n\n\nTerms\n\nVSS- Virtual Set Size 虚拟耗用内存（包含共享库占用的内存）\nRSS- Resident Set Size 实际使用物理内存（包含共享库占用的内存）\nPSS- Proportional Set Size 实际使用的物理内存（比例分配共享库占用的内存）\nUSS- Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存）\n一般来说内存占用大小有如下规律：VSS >= RSS >= PSS >= USS\n\n","slug":"Linux-Memory-management","published":1,"updated":"2019-09-28T08:51:00.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83u0037v1npdr6teccu","content":"<p><a href=\"https://blog.csdn.net/adaptiver/article/details/7084364\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/adaptiver/article/details/7084364</a></p>\n<p>Terms</p>\n<p>VSS- Virtual Set Size 虚拟耗用内存（包含共享库占用的内存）<br>RSS- Resident Set Size 实际使用物理内存（包含共享库占用的内存）<br>PSS- Proportional Set Size 实际使用的物理内存（比例分配共享库占用的内存）<br>USS- Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存）<br>一般来说内存占用大小有如下规律：VSS &gt;= RSS &gt;= PSS &gt;= USS</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/adaptiver/article/details/7084364\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/adaptiver/article/details/7084364</a></p>\n<p>Terms</p>\n<p>VSS- Virtual Set Size 虚拟耗用内存（包含共享库占用的内存）<br>RSS- Resident Set Size 实际使用物理内存（包含共享库占用的内存）<br>PSS- Proportional Set Size 实际使用的物理内存（比例分配共享库占用的内存）<br>USS- Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存）<br>一般来说内存占用大小有如下规律：VSS &gt;= RSS &gt;= PSS &gt;= USS</p>\n"},{"title":"Linux-Mlock","date":"2018-09-26T02:05:01.000Z","_content":"\n\n### 笨叔叔\nmlock(), mlock2(), and mlockall() lock part or all of the calling\nprocess's virtual address space into RAM, preventing that memory from\nbeing paged to the swap area.\n\n这个是mlock的man。说是将某段虚拟内存锁进Ram，防止对应的物理内存swap out。是不是也可以理解为，锁住 vma和pm的 mapping关系，不被删除？\n\n不完全正确\n内存 不加入 LRU链表，所以也不会 被 swap out","source":"_posts/Linux-Mlock.md","raw":"---\ntitle: Linux-Mlock\ndate: 2018-09-26 10:05:01\ntags:\n---\n\n\n### 笨叔叔\nmlock(), mlock2(), and mlockall() lock part or all of the calling\nprocess's virtual address space into RAM, preventing that memory from\nbeing paged to the swap area.\n\n这个是mlock的man。说是将某段虚拟内存锁进Ram，防止对应的物理内存swap out。是不是也可以理解为，锁住 vma和pm的 mapping关系，不被删除？\n\n不完全正确\n内存 不加入 LRU链表，所以也不会 被 swap out","slug":"Linux-Mlock","published":1,"updated":"2019-09-28T08:51:00.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83u0038v1np74h774lj","content":"<h3 id=\"笨叔叔\"><a href=\"#笨叔叔\" class=\"headerlink\" title=\"笨叔叔\"></a>笨叔叔</h3><p>mlock(), mlock2(), and mlockall() lock part or all of the calling<br>process’s virtual address space into RAM, preventing that memory from<br>being paged to the swap area.</p>\n<p>这个是mlock的man。说是将某段虚拟内存锁进Ram，防止对应的物理内存swap out。是不是也可以理解为，锁住 vma和pm的 mapping关系，不被删除？</p>\n<p>不完全正确<br>内存 不加入 LRU链表，所以也不会 被 swap out</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"笨叔叔\"><a href=\"#笨叔叔\" class=\"headerlink\" title=\"笨叔叔\"></a>笨叔叔</h3><p>mlock(), mlock2(), and mlockall() lock part or all of the calling<br>process’s virtual address space into RAM, preventing that memory from<br>being paged to the swap area.</p>\n<p>这个是mlock的man。说是将某段虚拟内存锁进Ram，防止对应的物理内存swap out。是不是也可以理解为，锁住 vma和pm的 mapping关系，不被删除？</p>\n<p>不完全正确<br>内存 不加入 LRU链表，所以也不会 被 swap out</p>\n"},{"title":"Linux-Core-dump","date":"2018-10-10T03:15:10.000Z","_content":"\nulimint -a 用来显示当前的各种用户进程限制\n\n```\n$ ulimit -a\n-t: cpu time (seconds)              unlimited\n-f: file size (blocks)              unlimited\n-d: data seg size (kbytes)          unlimited\n-s: stack size (kbytes)             8192\n-c: core file size (blocks)         0\n-v: address space (kbytes)          unlimited\n-l: locked-in-memory size (kbytes)  unlimited\n-u: processes                       709\n-n: file descriptors                256\n```\n\n","source":"_posts/Linux-Core-dump.md","raw":"---\ntitle: Linux-Core-dump\ndate: 2018-10-10 11:15:10\ntags:\n---\n\nulimint -a 用来显示当前的各种用户进程限制\n\n```\n$ ulimit -a\n-t: cpu time (seconds)              unlimited\n-f: file size (blocks)              unlimited\n-d: data seg size (kbytes)          unlimited\n-s: stack size (kbytes)             8192\n-c: core file size (blocks)         0\n-v: address space (kbytes)          unlimited\n-l: locked-in-memory size (kbytes)  unlimited\n-u: processes                       709\n-n: file descriptors                256\n```\n\n","slug":"Linux-Core-dump","published":1,"updated":"2019-09-28T08:51:00.882Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83v0039v1nplxxvbk0m","content":"<p>ulimint -a 用来显示当前的各种用户进程限制</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ulimit -a</span><br><span class=\"line\">-t: cpu time (seconds)              unlimited</span><br><span class=\"line\">-f: file size (blocks)              unlimited</span><br><span class=\"line\">-d: data seg size (kbytes)          unlimited</span><br><span class=\"line\">-s: stack size (kbytes)             8192</span><br><span class=\"line\">-c: core file size (blocks)         0</span><br><span class=\"line\">-v: address space (kbytes)          unlimited</span><br><span class=\"line\">-l: locked-in-memory size (kbytes)  unlimited</span><br><span class=\"line\">-u: processes                       709</span><br><span class=\"line\">-n: file descriptors                256</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<p>ulimint -a 用来显示当前的各种用户进程限制</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ulimit -a</span><br><span class=\"line\">-t: cpu time (seconds)              unlimited</span><br><span class=\"line\">-f: file size (blocks)              unlimited</span><br><span class=\"line\">-d: data seg size (kbytes)          unlimited</span><br><span class=\"line\">-s: stack size (kbytes)             8192</span><br><span class=\"line\">-c: core file size (blocks)         0</span><br><span class=\"line\">-v: address space (kbytes)          unlimited</span><br><span class=\"line\">-l: locked-in-memory size (kbytes)  unlimited</span><br><span class=\"line\">-u: processes                       709</span><br><span class=\"line\">-n: file descriptors                256</span><br></pre></td></tr></table></figure>\n\n"},{"title":"Linux-Memory-Alignment","date":"2019-04-01T08:44:15.000Z","_content":"\n\n\n### 为什么需要进行内存对齐\nhttps://www.jianshu.com/p/730c23e57249\n\n很多 CPU（如基于 Alpha，IA-64，MIPS，和 SuperH 体系的）拒绝读取未对齐数据。当一个程序要求这些 CPU 读取未对齐数据时，这时 CPU 会进入异常处理状态并且通知程序不能继续执行。举个例子，在 ARM，MIPS，和 SH 硬件平台上，当操作系统被要求存取一个未对齐数据时会默认给应用程序抛出硬件异常。所以，如果编译器不进行内存对齐，那在很多平台的上的开发将难以进行。\n那么，为什么这些 CPU 会拒绝读取未对齐数据？是因为未对齐的数据，会大大降低 CPU 的性能。\n\n作者：xuyafei86\n链接：https://www.jianshu.com/p/a371e2613ec8\n来源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n\n\nhttps://www.jianshu.com/p/a371e2613ec8","source":"_posts/Linux-Memory-Alignment.md","raw":"---\ntitle: Linux-Memory-Alignment\ndate: 2019-04-01 16:44:15\ntags:\n---\n\n\n\n### 为什么需要进行内存对齐\nhttps://www.jianshu.com/p/730c23e57249\n\n很多 CPU（如基于 Alpha，IA-64，MIPS，和 SuperH 体系的）拒绝读取未对齐数据。当一个程序要求这些 CPU 读取未对齐数据时，这时 CPU 会进入异常处理状态并且通知程序不能继续执行。举个例子，在 ARM，MIPS，和 SH 硬件平台上，当操作系统被要求存取一个未对齐数据时会默认给应用程序抛出硬件异常。所以，如果编译器不进行内存对齐，那在很多平台的上的开发将难以进行。\n那么，为什么这些 CPU 会拒绝读取未对齐数据？是因为未对齐的数据，会大大降低 CPU 的性能。\n\n作者：xuyafei86\n链接：https://www.jianshu.com/p/a371e2613ec8\n来源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n\n\nhttps://www.jianshu.com/p/a371e2613ec8","slug":"Linux-Memory-Alignment","published":1,"updated":"2019-09-28T08:51:00.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83v003av1npynfqhr02","content":"<h3 id=\"为什么需要进行内存对齐\"><a href=\"#为什么需要进行内存对齐\" class=\"headerlink\" title=\"为什么需要进行内存对齐\"></a>为什么需要进行内存对齐</h3><p><a href=\"https://www.jianshu.com/p/730c23e57249\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/730c23e57249</a></p>\n<p>很多 CPU（如基于 Alpha，IA-64，MIPS，和 SuperH 体系的）拒绝读取未对齐数据。当一个程序要求这些 CPU 读取未对齐数据时，这时 CPU 会进入异常处理状态并且通知程序不能继续执行。举个例子，在 ARM，MIPS，和 SH 硬件平台上，当操作系统被要求存取一个未对齐数据时会默认给应用程序抛出硬件异常。所以，如果编译器不进行内存对齐，那在很多平台的上的开发将难以进行。<br>那么，为什么这些 CPU 会拒绝读取未对齐数据？是因为未对齐的数据，会大大降低 CPU 的性能。</p>\n<p>作者：xuyafei86<br>链接：<a href=\"https://www.jianshu.com/p/a371e2613ec8\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/a371e2613ec8</a><br>来源：简书<br>简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p>\n<p><a href=\"https://www.jianshu.com/p/a371e2613ec8\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/a371e2613ec8</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"为什么需要进行内存对齐\"><a href=\"#为什么需要进行内存对齐\" class=\"headerlink\" title=\"为什么需要进行内存对齐\"></a>为什么需要进行内存对齐</h3><p><a href=\"https://www.jianshu.com/p/730c23e57249\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/730c23e57249</a></p>\n<p>很多 CPU（如基于 Alpha，IA-64，MIPS，和 SuperH 体系的）拒绝读取未对齐数据。当一个程序要求这些 CPU 读取未对齐数据时，这时 CPU 会进入异常处理状态并且通知程序不能继续执行。举个例子，在 ARM，MIPS，和 SH 硬件平台上，当操作系统被要求存取一个未对齐数据时会默认给应用程序抛出硬件异常。所以，如果编译器不进行内存对齐，那在很多平台的上的开发将难以进行。<br>那么，为什么这些 CPU 会拒绝读取未对齐数据？是因为未对齐的数据，会大大降低 CPU 的性能。</p>\n<p>作者：xuyafei86<br>链接：<a href=\"https://www.jianshu.com/p/a371e2613ec8\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/a371e2613ec8</a><br>来源：简书<br>简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p>\n<p><a href=\"https://www.jianshu.com/p/a371e2613ec8\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/a371e2613ec8</a></p>\n"},{"title":"Linux-NUMA","date":"2019-02-18T09:33:32.000Z","_content":"\n### 极佳\nhttps://blog.csdn.net/liguangxianbin/article/details/80797400\n\n### 为什么要有NUMA\n在NUMA架构出现前，CPU欢快的朝着频率越来越高的方向发展。受到物理极限的挑战，又转为核数越来越多的方向发展。如果每个core的工作性质 都是share-nothing（类似于map-reduce的node节点的作业属性），那么也许就不会有NUMA。由于所有CPU Core都是通过共享一个北桥来读取内存，随着核数如何的发展，北桥在响应时间上的性能瓶颈越来越明显。于是，聪明的硬件设计师们，先到了把内存控制器 （原本北桥中读取内存的部分）也做个拆分，平分到了每个die上。于是NUMA就出现了！\n\n### NUMA是什么\nNUMA中，虽然内存直接attach在CPU上，但是由于内存被平均分配在了各个die上。只有当CPU访问自身直接attach内存对应的物理地址时，才会有较短的响应时间（后称Local Access）。而如果需要访问其他CPU attach的内存的数据时，就需要通过inter-connect通道访问，响应时间就相比之前变慢了（后称Remote Access）。所以NUMA（Non-Uniform Memory Access）就此得名。","source":"_posts/Linux-NUMA.md","raw":"---\ntitle: Linux-NUMA\ndate: 2019-02-18 17:33:32\ntags: Linux\n---\n\n### 极佳\nhttps://blog.csdn.net/liguangxianbin/article/details/80797400\n\n### 为什么要有NUMA\n在NUMA架构出现前，CPU欢快的朝着频率越来越高的方向发展。受到物理极限的挑战，又转为核数越来越多的方向发展。如果每个core的工作性质 都是share-nothing（类似于map-reduce的node节点的作业属性），那么也许就不会有NUMA。由于所有CPU Core都是通过共享一个北桥来读取内存，随着核数如何的发展，北桥在响应时间上的性能瓶颈越来越明显。于是，聪明的硬件设计师们，先到了把内存控制器 （原本北桥中读取内存的部分）也做个拆分，平分到了每个die上。于是NUMA就出现了！\n\n### NUMA是什么\nNUMA中，虽然内存直接attach在CPU上，但是由于内存被平均分配在了各个die上。只有当CPU访问自身直接attach内存对应的物理地址时，才会有较短的响应时间（后称Local Access）。而如果需要访问其他CPU attach的内存的数据时，就需要通过inter-connect通道访问，响应时间就相比之前变慢了（后称Remote Access）。所以NUMA（Non-Uniform Memory Access）就此得名。","slug":"Linux-NUMA","published":1,"updated":"2019-09-28T08:51:00.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83w003bv1npp2wwypvq","content":"<h3 id=\"极佳\"><a href=\"#极佳\" class=\"headerlink\" title=\"极佳\"></a>极佳</h3><p><a href=\"https://blog.csdn.net/liguangxianbin/article/details/80797400\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/liguangxianbin/article/details/80797400</a></p>\n<h3 id=\"为什么要有NUMA\"><a href=\"#为什么要有NUMA\" class=\"headerlink\" title=\"为什么要有NUMA\"></a>为什么要有NUMA</h3><p>在NUMA架构出现前，CPU欢快的朝着频率越来越高的方向发展。受到物理极限的挑战，又转为核数越来越多的方向发展。如果每个core的工作性质 都是share-nothing（类似于map-reduce的node节点的作业属性），那么也许就不会有NUMA。由于所有CPU Core都是通过共享一个北桥来读取内存，随着核数如何的发展，北桥在响应时间上的性能瓶颈越来越明显。于是，聪明的硬件设计师们，先到了把内存控制器 （原本北桥中读取内存的部分）也做个拆分，平分到了每个die上。于是NUMA就出现了！</p>\n<h3 id=\"NUMA是什么\"><a href=\"#NUMA是什么\" class=\"headerlink\" title=\"NUMA是什么\"></a>NUMA是什么</h3><p>NUMA中，虽然内存直接attach在CPU上，但是由于内存被平均分配在了各个die上。只有当CPU访问自身直接attach内存对应的物理地址时，才会有较短的响应时间（后称Local Access）。而如果需要访问其他CPU attach的内存的数据时，就需要通过inter-connect通道访问，响应时间就相比之前变慢了（后称Remote Access）。所以NUMA（Non-Uniform Memory Access）就此得名。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"极佳\"><a href=\"#极佳\" class=\"headerlink\" title=\"极佳\"></a>极佳</h3><p><a href=\"https://blog.csdn.net/liguangxianbin/article/details/80797400\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/liguangxianbin/article/details/80797400</a></p>\n<h3 id=\"为什么要有NUMA\"><a href=\"#为什么要有NUMA\" class=\"headerlink\" title=\"为什么要有NUMA\"></a>为什么要有NUMA</h3><p>在NUMA架构出现前，CPU欢快的朝着频率越来越高的方向发展。受到物理极限的挑战，又转为核数越来越多的方向发展。如果每个core的工作性质 都是share-nothing（类似于map-reduce的node节点的作业属性），那么也许就不会有NUMA。由于所有CPU Core都是通过共享一个北桥来读取内存，随着核数如何的发展，北桥在响应时间上的性能瓶颈越来越明显。于是，聪明的硬件设计师们，先到了把内存控制器 （原本北桥中读取内存的部分）也做个拆分，平分到了每个die上。于是NUMA就出现了！</p>\n<h3 id=\"NUMA是什么\"><a href=\"#NUMA是什么\" class=\"headerlink\" title=\"NUMA是什么\"></a>NUMA是什么</h3><p>NUMA中，虽然内存直接attach在CPU上，但是由于内存被平均分配在了各个die上。只有当CPU访问自身直接attach内存对应的物理地址时，才会有较短的响应时间（后称Local Access）。而如果需要访问其他CPU attach的内存的数据时，就需要通过inter-connect通道访问，响应时间就相比之前变慢了（后称Remote Access）。所以NUMA（Non-Uniform Memory Access）就此得名。</p>\n"},{"title":"Linux-OOM-killer","date":"2018-09-22T14:12:32.000Z","_content":"\n\nhttps://blog.csdn.net/zgrjkflmkyc/article/details/77645570\nhttps://blog.csdn.net/liukuan73/article/details/43238623\n\n\n# 立即重新启动计算机    （Reboots the kernel without first unmounting file systems or syncing disks attached to the system）\necho \"b\" > /proc/sysrq-trigger     \n# 立即关闭计算机（shuts off the system）\necho \"o\" > /proc/sysrq-trigger\n# 导出内存分配的信息 （可以用/var/log/message 查看）（Outputs memory statistics to the console）   \n\necho \"m\" > /proc/sysrq-trigger     \n# 导出当前CPU寄存器信息和标志位的信息（Outputs all flags and registers to the console）\necho \"p\" > /proc/sysrq-trigger     \n# 导出线程状态信息    （Outputs a list of processes to the console）\necho \"t\" > /proc/sysrq-trigger\n# 故意让系统崩溃    （ Crashes the system without first unmounting file systems or syncing disks attached to the system）\necho \"c\" > /proc/sysrq-trigger\n\n# 立即重新挂载所有的文件系统 （Attempts to sync disks attached to the system）\necho \"s\" > /proc/sysrq-trigger     \n# 立即重新挂载所有的文件系统为只读 （Attempts to unmount and remount all file systems as read-only）\necho \"u\" > /proc/sysrq-trigger\n# 手动触发oom-killer\necho \"f\" > /proc/sysrq-trigger\n\n---------------------\n\n本文来自 njuitjf 的CSDN 博客 ，全文地址请点击：https://blog.csdn.net/njuitjf/article/details/12045527?utm_source=copy ","source":"_posts/Linux-OOM-killer.md","raw":"---\ntitle: Linux-OOM-killer\ndate: 2018-09-22 22:12:32\ntags:\n---\n\n\nhttps://blog.csdn.net/zgrjkflmkyc/article/details/77645570\nhttps://blog.csdn.net/liukuan73/article/details/43238623\n\n\n# 立即重新启动计算机    （Reboots the kernel without first unmounting file systems or syncing disks attached to the system）\necho \"b\" > /proc/sysrq-trigger     \n# 立即关闭计算机（shuts off the system）\necho \"o\" > /proc/sysrq-trigger\n# 导出内存分配的信息 （可以用/var/log/message 查看）（Outputs memory statistics to the console）   \n\necho \"m\" > /proc/sysrq-trigger     \n# 导出当前CPU寄存器信息和标志位的信息（Outputs all flags and registers to the console）\necho \"p\" > /proc/sysrq-trigger     \n# 导出线程状态信息    （Outputs a list of processes to the console）\necho \"t\" > /proc/sysrq-trigger\n# 故意让系统崩溃    （ Crashes the system without first unmounting file systems or syncing disks attached to the system）\necho \"c\" > /proc/sysrq-trigger\n\n# 立即重新挂载所有的文件系统 （Attempts to sync disks attached to the system）\necho \"s\" > /proc/sysrq-trigger     \n# 立即重新挂载所有的文件系统为只读 （Attempts to unmount and remount all file systems as read-only）\necho \"u\" > /proc/sysrq-trigger\n# 手动触发oom-killer\necho \"f\" > /proc/sysrq-trigger\n\n---------------------\n\n本文来自 njuitjf 的CSDN 博客 ，全文地址请点击：https://blog.csdn.net/njuitjf/article/details/12045527?utm_source=copy ","slug":"Linux-OOM-killer","published":1,"updated":"2019-09-28T08:51:00.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83w003cv1npag63kwti","content":"<p><a href=\"https://blog.csdn.net/zgrjkflmkyc/article/details/77645570\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zgrjkflmkyc/article/details/77645570</a><br><a href=\"https://blog.csdn.net/liukuan73/article/details/43238623\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/liukuan73/article/details/43238623</a></p>\n<h1 id=\"立即重新启动计算机-（Reboots-the-kernel-without-first-unmounting-file-systems-or-syncing-disks-attached-to-the-system）\"><a href=\"#立即重新启动计算机-（Reboots-the-kernel-without-first-unmounting-file-systems-or-syncing-disks-attached-to-the-system）\" class=\"headerlink\" title=\"立即重新启动计算机    （Reboots the kernel without first unmounting file systems or syncing disks attached to the system）\"></a>立即重新启动计算机    （Reboots the kernel without first unmounting file systems or syncing disks attached to the system）</h1><p>echo “b” &gt; /proc/sysrq-trigger     </p>\n<h1 id=\"立即关闭计算机（shuts-off-the-system）\"><a href=\"#立即关闭计算机（shuts-off-the-system）\" class=\"headerlink\" title=\"立即关闭计算机（shuts off the system）\"></a>立即关闭计算机（shuts off the system）</h1><p>echo “o” &gt; /proc/sysrq-trigger</p>\n<h1 id=\"导出内存分配的信息-（可以用-var-log-message-查看）（Outputs-memory-statistics-to-the-console）\"><a href=\"#导出内存分配的信息-（可以用-var-log-message-查看）（Outputs-memory-statistics-to-the-console）\" class=\"headerlink\" title=\"导出内存分配的信息 （可以用/var/log/message 查看）（Outputs memory statistics to the console）\"></a>导出内存分配的信息 （可以用/var/log/message 查看）（Outputs memory statistics to the console）</h1><p>echo “m” &gt; /proc/sysrq-trigger     </p>\n<h1 id=\"导出当前CPU寄存器信息和标志位的信息（Outputs-all-flags-and-registers-to-the-console）\"><a href=\"#导出当前CPU寄存器信息和标志位的信息（Outputs-all-flags-and-registers-to-the-console）\" class=\"headerlink\" title=\"导出当前CPU寄存器信息和标志位的信息（Outputs all flags and registers to the console）\"></a>导出当前CPU寄存器信息和标志位的信息（Outputs all flags and registers to the console）</h1><p>echo “p” &gt; /proc/sysrq-trigger     </p>\n<h1 id=\"导出线程状态信息-（Outputs-a-list-of-processes-to-the-console）\"><a href=\"#导出线程状态信息-（Outputs-a-list-of-processes-to-the-console）\" class=\"headerlink\" title=\"导出线程状态信息    （Outputs a list of processes to the console）\"></a>导出线程状态信息    （Outputs a list of processes to the console）</h1><p>echo “t” &gt; /proc/sysrq-trigger</p>\n<h1 id=\"故意让系统崩溃-（-Crashes-the-system-without-first-unmounting-file-systems-or-syncing-disks-attached-to-the-system）\"><a href=\"#故意让系统崩溃-（-Crashes-the-system-without-first-unmounting-file-systems-or-syncing-disks-attached-to-the-system）\" class=\"headerlink\" title=\"故意让系统崩溃    （ Crashes the system without first unmounting file systems or syncing disks attached to the system）\"></a>故意让系统崩溃    （ Crashes the system without first unmounting file systems or syncing disks attached to the system）</h1><p>echo “c” &gt; /proc/sysrq-trigger</p>\n<h1 id=\"立即重新挂载所有的文件系统-（Attempts-to-sync-disks-attached-to-the-system）\"><a href=\"#立即重新挂载所有的文件系统-（Attempts-to-sync-disks-attached-to-the-system）\" class=\"headerlink\" title=\"立即重新挂载所有的文件系统 （Attempts to sync disks attached to the system）\"></a>立即重新挂载所有的文件系统 （Attempts to sync disks attached to the system）</h1><p>echo “s” &gt; /proc/sysrq-trigger     </p>\n<h1 id=\"立即重新挂载所有的文件系统为只读-（Attempts-to-unmount-and-remount-all-file-systems-as-read-only）\"><a href=\"#立即重新挂载所有的文件系统为只读-（Attempts-to-unmount-and-remount-all-file-systems-as-read-only）\" class=\"headerlink\" title=\"立即重新挂载所有的文件系统为只读 （Attempts to unmount and remount all file systems as read-only）\"></a>立即重新挂载所有的文件系统为只读 （Attempts to unmount and remount all file systems as read-only）</h1><p>echo “u” &gt; /proc/sysrq-trigger</p>\n<h1 id=\"手动触发oom-killer\"><a href=\"#手动触发oom-killer\" class=\"headerlink\" title=\"手动触发oom-killer\"></a>手动触发oom-killer</h1><p>echo “f” &gt; /proc/sysrq-trigger</p>\n<hr>\n<p>本文来自 njuitjf 的CSDN 博客 ，全文地址请点击：<a href=\"https://blog.csdn.net/njuitjf/article/details/12045527?utm_source=copy\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/njuitjf/article/details/12045527?utm_source=copy</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/zgrjkflmkyc/article/details/77645570\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zgrjkflmkyc/article/details/77645570</a><br><a href=\"https://blog.csdn.net/liukuan73/article/details/43238623\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/liukuan73/article/details/43238623</a></p>\n<h1 id=\"立即重新启动计算机-（Reboots-the-kernel-without-first-unmounting-file-systems-or-syncing-disks-attached-to-the-system）\"><a href=\"#立即重新启动计算机-（Reboots-the-kernel-without-first-unmounting-file-systems-or-syncing-disks-attached-to-the-system）\" class=\"headerlink\" title=\"立即重新启动计算机    （Reboots the kernel without first unmounting file systems or syncing disks attached to the system）\"></a>立即重新启动计算机    （Reboots the kernel without first unmounting file systems or syncing disks attached to the system）</h1><p>echo “b” &gt; /proc/sysrq-trigger     </p>\n<h1 id=\"立即关闭计算机（shuts-off-the-system）\"><a href=\"#立即关闭计算机（shuts-off-the-system）\" class=\"headerlink\" title=\"立即关闭计算机（shuts off the system）\"></a>立即关闭计算机（shuts off the system）</h1><p>echo “o” &gt; /proc/sysrq-trigger</p>\n<h1 id=\"导出内存分配的信息-（可以用-var-log-message-查看）（Outputs-memory-statistics-to-the-console）\"><a href=\"#导出内存分配的信息-（可以用-var-log-message-查看）（Outputs-memory-statistics-to-the-console）\" class=\"headerlink\" title=\"导出内存分配的信息 （可以用/var/log/message 查看）（Outputs memory statistics to the console）\"></a>导出内存分配的信息 （可以用/var/log/message 查看）（Outputs memory statistics to the console）</h1><p>echo “m” &gt; /proc/sysrq-trigger     </p>\n<h1 id=\"导出当前CPU寄存器信息和标志位的信息（Outputs-all-flags-and-registers-to-the-console）\"><a href=\"#导出当前CPU寄存器信息和标志位的信息（Outputs-all-flags-and-registers-to-the-console）\" class=\"headerlink\" title=\"导出当前CPU寄存器信息和标志位的信息（Outputs all flags and registers to the console）\"></a>导出当前CPU寄存器信息和标志位的信息（Outputs all flags and registers to the console）</h1><p>echo “p” &gt; /proc/sysrq-trigger     </p>\n<h1 id=\"导出线程状态信息-（Outputs-a-list-of-processes-to-the-console）\"><a href=\"#导出线程状态信息-（Outputs-a-list-of-processes-to-the-console）\" class=\"headerlink\" title=\"导出线程状态信息    （Outputs a list of processes to the console）\"></a>导出线程状态信息    （Outputs a list of processes to the console）</h1><p>echo “t” &gt; /proc/sysrq-trigger</p>\n<h1 id=\"故意让系统崩溃-（-Crashes-the-system-without-first-unmounting-file-systems-or-syncing-disks-attached-to-the-system）\"><a href=\"#故意让系统崩溃-（-Crashes-the-system-without-first-unmounting-file-systems-or-syncing-disks-attached-to-the-system）\" class=\"headerlink\" title=\"故意让系统崩溃    （ Crashes the system without first unmounting file systems or syncing disks attached to the system）\"></a>故意让系统崩溃    （ Crashes the system without first unmounting file systems or syncing disks attached to the system）</h1><p>echo “c” &gt; /proc/sysrq-trigger</p>\n<h1 id=\"立即重新挂载所有的文件系统-（Attempts-to-sync-disks-attached-to-the-system）\"><a href=\"#立即重新挂载所有的文件系统-（Attempts-to-sync-disks-attached-to-the-system）\" class=\"headerlink\" title=\"立即重新挂载所有的文件系统 （Attempts to sync disks attached to the system）\"></a>立即重新挂载所有的文件系统 （Attempts to sync disks attached to the system）</h1><p>echo “s” &gt; /proc/sysrq-trigger     </p>\n<h1 id=\"立即重新挂载所有的文件系统为只读-（Attempts-to-unmount-and-remount-all-file-systems-as-read-only）\"><a href=\"#立即重新挂载所有的文件系统为只读-（Attempts-to-unmount-and-remount-all-file-systems-as-read-only）\" class=\"headerlink\" title=\"立即重新挂载所有的文件系统为只读 （Attempts to unmount and remount all file systems as read-only）\"></a>立即重新挂载所有的文件系统为只读 （Attempts to unmount and remount all file systems as read-only）</h1><p>echo “u” &gt; /proc/sysrq-trigger</p>\n<h1 id=\"手动触发oom-killer\"><a href=\"#手动触发oom-killer\" class=\"headerlink\" title=\"手动触发oom-killer\"></a>手动触发oom-killer</h1><p>echo “f” &gt; /proc/sysrq-trigger</p>\n<hr>\n<p>本文来自 njuitjf 的CSDN 博客 ，全文地址请点击：<a href=\"https://blog.csdn.net/njuitjf/article/details/12045527?utm_source=copy\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/njuitjf/article/details/12045527?utm_source=copy</a> </p>\n"},{"title":"Linux-Mmap","date":"2017-11-20T09:22:52.000Z","_content":"\n从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：brk和mmap。\n1、brk是将数据段(.data)的最高地址指针_edata往高地址推；\n2、mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。\n\n这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。\n\n\nhttp://xiaoz5919.iteye.com/blog/2093323\n\n### 问题\nmmap中map和unmap的细节是什么样的？\n\n```\npublic static void main(String[] args) throws Exception {\n    int len = 1024 * 1024 * 1024;\n    File file = new File(\"/Users/eric/Code/kick-off/MappedByteBuffer-kick-off/src/main/resources/bigFile.cc\");\n\n    RandomAccessFile accessFile = new RandomAccessFile(file, \"rw\");\n\n    MappedByteBuffer mappedByteBuffer = accessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, len);\n\n    for (int i = 0; i < len; i++) {\n        mappedByteBuffer.put((byte) (i % 128));\n    }\n    System.out.println(mappedByteBuffer.limit());\n    System.out.println(\"done\");\n\n    Thread.sleep(10000000);\n\n//        file.delete();\n}\n```\n\neric@ubuntu:~/Software/pcstat$ pmap -X 4690\n4690:   /home/eric/Software/jdk1.7.0_79/bin/java -Didea.launcher.port=7532 -Didea.launcher.bin.path=/home/eric/Software/idea-IU-162.1121.32/bin -Dfile.encoding=UTF-8 -classpath /home/eric/Software/jdk1.7.0_79/jre/lib/charsets.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/deploy.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/dnsns.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/localedata.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunec.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunjce_provider.jar:/home/\n         Address Perm   Offset Device   Inode    Size    Rss    Pss Referenced Anonymous Shared_Hugetlb Private_Hugetlb Swap SwapPss Locked Mapping\n        00400000 r-xp 00000000  08:01  801959       4      4      2          4         0              0               0    0       0      0 java\n        00600000 rw-p 00000000  08:01  801959       4      4      4          4         4              0               0    0       0      0 java\n        0122b000 rw-p 00000000  00:00       0     132     12     12         12        12              0               0    0       0      0 [heap]\n        dbe00000 rw-p 00000000  00:00       0   10560   2048   2048       2048      2048              0               0    0       0      0 \n        dc850000 rw-p 00000000  00:00       0  158720      0      0          0         0              0               0    0       0      0 \n        e6350000 rw-p 00000000  00:00       0   21184      0      0          0         0              0               0    0       0      0 \n        e7800000 rw-p 00000000  00:00       0  317440      0      0          0         0              0               0    0       0      0 \n        fae00000 rw-p 00000000  00:00       0   21248   4096   4096       4096      4096              0               0    0       0      0 \n        fc2c0000 rw-p 00000000  00:00       0   62720      0      0          0         0              0               0    0       0      0 \n    7f55bcfff000 rw-s 00000000  08:01 1053783 1048576 140544 140544     140544         0              0               0    0       0      0 bigFile.cc\n    7f55fcfff000 rw-p 00000000  00:00       0   49156      4      4          4         4              0               0    0       0      0 \n    7f5600000000 rw-p 00000000  00:00       0     168    168    168        168       168              0               0    0       0      0 \n\npmap Rss PageCache: 140544\n","source":"_posts/Linux-Mmap.md","raw":"---\ntitle: Linux-Mmap\ndate: 2017-11-20 17:22:52\ntags: Linux\n---\n\n从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：brk和mmap。\n1、brk是将数据段(.data)的最高地址指针_edata往高地址推；\n2、mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。\n\n这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。\n\n\nhttp://xiaoz5919.iteye.com/blog/2093323\n\n### 问题\nmmap中map和unmap的细节是什么样的？\n\n```\npublic static void main(String[] args) throws Exception {\n    int len = 1024 * 1024 * 1024;\n    File file = new File(\"/Users/eric/Code/kick-off/MappedByteBuffer-kick-off/src/main/resources/bigFile.cc\");\n\n    RandomAccessFile accessFile = new RandomAccessFile(file, \"rw\");\n\n    MappedByteBuffer mappedByteBuffer = accessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, len);\n\n    for (int i = 0; i < len; i++) {\n        mappedByteBuffer.put((byte) (i % 128));\n    }\n    System.out.println(mappedByteBuffer.limit());\n    System.out.println(\"done\");\n\n    Thread.sleep(10000000);\n\n//        file.delete();\n}\n```\n\neric@ubuntu:~/Software/pcstat$ pmap -X 4690\n4690:   /home/eric/Software/jdk1.7.0_79/bin/java -Didea.launcher.port=7532 -Didea.launcher.bin.path=/home/eric/Software/idea-IU-162.1121.32/bin -Dfile.encoding=UTF-8 -classpath /home/eric/Software/jdk1.7.0_79/jre/lib/charsets.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/deploy.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/dnsns.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/localedata.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunec.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunjce_provider.jar:/home/\n         Address Perm   Offset Device   Inode    Size    Rss    Pss Referenced Anonymous Shared_Hugetlb Private_Hugetlb Swap SwapPss Locked Mapping\n        00400000 r-xp 00000000  08:01  801959       4      4      2          4         0              0               0    0       0      0 java\n        00600000 rw-p 00000000  08:01  801959       4      4      4          4         4              0               0    0       0      0 java\n        0122b000 rw-p 00000000  00:00       0     132     12     12         12        12              0               0    0       0      0 [heap]\n        dbe00000 rw-p 00000000  00:00       0   10560   2048   2048       2048      2048              0               0    0       0      0 \n        dc850000 rw-p 00000000  00:00       0  158720      0      0          0         0              0               0    0       0      0 \n        e6350000 rw-p 00000000  00:00       0   21184      0      0          0         0              0               0    0       0      0 \n        e7800000 rw-p 00000000  00:00       0  317440      0      0          0         0              0               0    0       0      0 \n        fae00000 rw-p 00000000  00:00       0   21248   4096   4096       4096      4096              0               0    0       0      0 \n        fc2c0000 rw-p 00000000  00:00       0   62720      0      0          0         0              0               0    0       0      0 \n    7f55bcfff000 rw-s 00000000  08:01 1053783 1048576 140544 140544     140544         0              0               0    0       0      0 bigFile.cc\n    7f55fcfff000 rw-p 00000000  00:00       0   49156      4      4          4         4              0               0    0       0      0 \n    7f5600000000 rw-p 00000000  00:00       0     168    168    168        168       168              0               0    0       0      0 \n\npmap Rss PageCache: 140544\n","slug":"Linux-Mmap","published":1,"updated":"2019-09-28T08:51:00.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83x003dv1npi231cu2n","content":"<p>从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：brk和mmap。<br>1、brk是将数据段(.data)的最高地址指针_edata往高地址推；<br>2、mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。</p>\n<p>这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。</p>\n<p><a href=\"http://xiaoz5919.iteye.com/blog/2093323\" target=\"_blank\" rel=\"noopener\">http://xiaoz5919.iteye.com/blog/2093323</a></p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><p>mmap中map和unmap的细节是什么样的？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static void main(String[] args) throws Exception &#123;</span><br><span class=\"line\">    int len = 1024 * 1024 * 1024;</span><br><span class=\"line\">    File file = new File(&quot;/Users/eric/Code/kick-off/MappedByteBuffer-kick-off/src/main/resources/bigFile.cc&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    RandomAccessFile accessFile = new RandomAccessFile(file, &quot;rw&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    MappedByteBuffer mappedByteBuffer = accessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, len);</span><br><span class=\"line\"></span><br><span class=\"line\">    for (int i = 0; i &lt; len; i++) &#123;</span><br><span class=\"line\">        mappedByteBuffer.put((byte) (i % 128));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    System.out.println(mappedByteBuffer.limit());</span><br><span class=\"line\">    System.out.println(&quot;done&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    Thread.sleep(10000000);</span><br><span class=\"line\"></span><br><span class=\"line\">//        file.delete();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>eric@ubuntu:~/Software/pcstat$ pmap -X 4690<br>4690:   /home/eric/Software/jdk1.7.0_79/bin/java -Didea.launcher.port=7532 -Didea.launcher.bin.path=/home/eric/Software/idea-IU-162.1121.32/bin -Dfile.encoding=UTF-8 -classpath /home/eric/Software/jdk1.7.0_79/jre/lib/charsets.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/deploy.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/dnsns.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/localedata.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunec.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunjce_provider.jar:/home/<br>         Address Perm   Offset Device   Inode    Size    Rss    Pss Referenced Anonymous Shared_Hugetlb Private_Hugetlb Swap SwapPss Locked Mapping<br>        00400000 r-xp 00000000  08:01  801959       4      4      2          4         0              0               0    0       0      0 java<br>        00600000 rw-p 00000000  08:01  801959       4      4      4          4         4              0               0    0       0      0 java<br>        0122b000 rw-p 00000000  00:00       0     132     12     12         12        12              0               0    0       0      0 [heap]<br>        dbe00000 rw-p 00000000  00:00       0   10560   2048   2048       2048      2048              0               0    0       0      0<br>        dc850000 rw-p 00000000  00:00       0  158720      0      0          0         0              0               0    0       0      0<br>        e6350000 rw-p 00000000  00:00       0   21184      0      0          0         0              0               0    0       0      0<br>        e7800000 rw-p 00000000  00:00       0  317440      0      0          0         0              0               0    0       0      0<br>        fae00000 rw-p 00000000  00:00       0   21248   4096   4096       4096      4096              0               0    0       0      0<br>        fc2c0000 rw-p 00000000  00:00       0   62720      0      0          0         0              0               0    0       0      0<br>    7f55bcfff000 rw-s 00000000  08:01 1053783 1048576 140544 140544     140544         0              0               0    0       0      0 bigFile.cc<br>    7f55fcfff000 rw-p 00000000  00:00       0   49156      4      4          4         4              0               0    0       0      0<br>    7f5600000000 rw-p 00000000  00:00       0     168    168    168        168       168              0               0    0       0      0 </p>\n<p>pmap Rss PageCache: 140544</p>\n","site":{"data":{}},"excerpt":"","more":"<p>从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：brk和mmap。<br>1、brk是将数据段(.data)的最高地址指针_edata往高地址推；<br>2、mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。</p>\n<p>这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。</p>\n<p><a href=\"http://xiaoz5919.iteye.com/blog/2093323\" target=\"_blank\" rel=\"noopener\">http://xiaoz5919.iteye.com/blog/2093323</a></p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><p>mmap中map和unmap的细节是什么样的？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static void main(String[] args) throws Exception &#123;</span><br><span class=\"line\">    int len = 1024 * 1024 * 1024;</span><br><span class=\"line\">    File file = new File(&quot;/Users/eric/Code/kick-off/MappedByteBuffer-kick-off/src/main/resources/bigFile.cc&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    RandomAccessFile accessFile = new RandomAccessFile(file, &quot;rw&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    MappedByteBuffer mappedByteBuffer = accessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, len);</span><br><span class=\"line\"></span><br><span class=\"line\">    for (int i = 0; i &lt; len; i++) &#123;</span><br><span class=\"line\">        mappedByteBuffer.put((byte) (i % 128));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    System.out.println(mappedByteBuffer.limit());</span><br><span class=\"line\">    System.out.println(&quot;done&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    Thread.sleep(10000000);</span><br><span class=\"line\"></span><br><span class=\"line\">//        file.delete();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>eric@ubuntu:~/Software/pcstat$ pmap -X 4690<br>4690:   /home/eric/Software/jdk1.7.0_79/bin/java -Didea.launcher.port=7532 -Didea.launcher.bin.path=/home/eric/Software/idea-IU-162.1121.32/bin -Dfile.encoding=UTF-8 -classpath /home/eric/Software/jdk1.7.0_79/jre/lib/charsets.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/deploy.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/dnsns.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/localedata.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunec.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunjce_provider.jar:/home/<br>         Address Perm   Offset Device   Inode    Size    Rss    Pss Referenced Anonymous Shared_Hugetlb Private_Hugetlb Swap SwapPss Locked Mapping<br>        00400000 r-xp 00000000  08:01  801959       4      4      2          4         0              0               0    0       0      0 java<br>        00600000 rw-p 00000000  08:01  801959       4      4      4          4         4              0               0    0       0      0 java<br>        0122b000 rw-p 00000000  00:00       0     132     12     12         12        12              0               0    0       0      0 [heap]<br>        dbe00000 rw-p 00000000  00:00       0   10560   2048   2048       2048      2048              0               0    0       0      0<br>        dc850000 rw-p 00000000  00:00       0  158720      0      0          0         0              0               0    0       0      0<br>        e6350000 rw-p 00000000  00:00       0   21184      0      0          0         0              0               0    0       0      0<br>        e7800000 rw-p 00000000  00:00       0  317440      0      0          0         0              0               0    0       0      0<br>        fae00000 rw-p 00000000  00:00       0   21248   4096   4096       4096      4096              0               0    0       0      0<br>        fc2c0000 rw-p 00000000  00:00       0   62720      0      0          0         0              0               0    0       0      0<br>    7f55bcfff000 rw-s 00000000  08:01 1053783 1048576 140544 140544     140544         0              0               0    0       0      0 bigFile.cc<br>    7f55fcfff000 rw-p 00000000  00:00       0   49156      4      4          4         4              0               0    0       0      0<br>    7f5600000000 rw-p 00000000  00:00       0     168    168    168        168       168              0               0    0       0      0 </p>\n<p>pmap Rss PageCache: 140544</p>\n"},{"title":"Linux-Pmap","date":"2018-09-25T05:04:31.000Z","_content":"\n\nhttp://man.linuxde.net/pmap\n\n\n### 还有这种东西啊。。。\nhttp://makelinux.net/kernel_map/\n\n用pmap来查看mmap堆外内存\n\n```\npublic static void main(String[] args) throws Exception {\n        int len = 1024 * 1024 * 1024;\n        File file = new File(\"/Users/eric/Code/kick-off/MappedByteBuffer-kick-off/src/main/resources/bigFile.cc\");\n\n        RandomAccessFile accessFile = new RandomAccessFile(file, \"rw\");\n\n        MappedByteBuffer mappedByteBuffer = accessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, len);\n\n        for (int i = 0; i < len; i++) {\n            mappedByteBuffer.put((byte) (i % 128));\n        }\n        System.out.println(mappedByteBuffer.limit());\n        System.out.println(\"done\");\n\n        Thread.sleep(10000000);\n\n//        file.delete();\n    }\n```\n\n运行程序前，\neric@ubuntu:~/Software/pcstat$ free -m\n              total        used        free      shared  buff/cache   available\nMem:           1982        1551         213           8         217         238\nSwap:          1021         437         584\n\n运行sleep后:\neric@ubuntu:~/Software/pcstat$ free -m\n              total        used        free      shared  buff/cache   available\nMem:           1982        1566          81           8         335         221\nSwap:          1021         437         584\n\n\neric@ubuntu:~/Software/pcstat$ ./pcstat /home/eric/IdeaProjects/memmap/src/main/resources/bigFile.cc\n|--------------------------------------------------------------+----------------+------------+-----------+---------|\n| Name                                                         | Size           | Pages      | Cached    | Percent |\n|--------------------------------------------------------------+----------------+------------+-----------+---------|\n| /home/eric/IdeaProjects/memmap/src/main/resources/bigFile.cc | 1073741824     | 262144     | 35136     | 013.403 |\n|--------------------------------------------------------------+----------------+------------+-----------+---------|\n\n\neric@ubuntu:~/Software/pcstat$ pmap -X 4690\n4690:   /home/eric/Software/jdk1.7.0_79/bin/java -Didea.launcher.port=7532 -Didea.launcher.bin.path=/home/eric/Software/idea-IU-162.1121.32/bin -Dfile.encoding=UTF-8 -classpath /home/eric/Software/jdk1.7.0_79/jre/lib/charsets.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/deploy.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/dnsns.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/localedata.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunec.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunjce_provider.jar:/home/\n         Address Perm   Offset Device   Inode    Size    Rss    Pss Referenced Anonymous Shared_Hugetlb Private_Hugetlb Swap SwapPss Locked Mapping\n        00400000 r-xp 00000000  08:01  801959       4      4      2          4         0              0               0    0       0      0 java\n        00600000 rw-p 00000000  08:01  801959       4      4      4          4         4              0               0    0       0      0 java\n        0122b000 rw-p 00000000  00:00       0     132     12     12         12        12              0               0    0       0      0 [heap]\n        dbe00000 rw-p 00000000  00:00       0   10560   2048   2048       2048      2048              0               0    0       0      0 \n        dc850000 rw-p 00000000  00:00       0  158720      0      0          0         0              0               0    0       0      0 \n        e6350000 rw-p 00000000  00:00       0   21184      0      0          0         0              0               0    0       0      0 \n        e7800000 rw-p 00000000  00:00       0  317440      0      0          0         0              0               0    0       0      0 \n        fae00000 rw-p 00000000  00:00       0   21248   4096   4096       4096      4096              0               0    0       0      0 \n        fc2c0000 rw-p 00000000  00:00       0   62720      0      0          0         0              0               0    0       0      0 \n    7f55bcfff000 rw-s 00000000  08:01 1053783 1048576 140544 140544     140544         0              0               0    0       0      0 bigFile.cc\n    7f55fcfff000 rw-p 00000000  00:00       0   49156      4      4          4         4              0               0    0       0      0 \n    7f5600000000 rw-p 00000000  00:00       0     168    168    168        168       168              0               0    0       0      0 \n\npcstat PageCache: 35136 * 4 = 140544\npmap Rss PageCache: 140544\n\n\n作者：in nek\n链接：https://www.zhihu.com/question/48161206/answer/110418693\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n你的脑子是晕的，被听到的信息搞晕了头脑，我帮你洗一次脑吧。1. 请放弃虚拟内存这个概念，那个是广告性的概念，在开发中没有意义。开发中只有虚拟空间的概念，进程看到的所有地址组成的空间，就是虚拟空间。虚拟空间是某个进程对分配给它的所有物理地址（已经分配的和将会分配的）的重新映射。2. mmap的作用，在应用这一层，是让你把文件的某一段，当作内存一样来访问。内核和驱动如何实现的，性能高不高这些问题，这层语义上没有承诺。你基于功能决定怎么用它就好了，少胡思乱想。有了以上两个，你就可以写好程序了。下面介绍一下Linux的实现细节，权当好玩，如果你搞不清楚前面两条，后面的就不要看，否则你又乱掉了。3. mmap的工作原理，当你发起这个调用的时候，它只是在你的虚拟空间中分配了一段空间，连真实的物理地址都不会分配的，当你访问这段空间，CPU陷入OS内核执行异常处理，然后异常处理会在这个时间分配物理内存，并用文件的内容填充这片内存，然后才返回你进程的上下文，这时你的程序才会感知到这片内存里有数据4. 驱动每次读入多少页面，页面的分配算法等等，都不是系统的承诺，不能作为你编程的依赖。这就是前面说的：不要胡思乱想5. 至于swap分区的作用，参考这里：Linux 是怎样使用内存的？ - in nek 的回答基于题主继续的问题，我们接着来解释一下为什么我建议你放弃虚拟内存而使用虚拟空间的概念。","source":"_posts/Linux-Pmap.md","raw":"---\ntitle: Linux-Pmap\ndate: 2018-09-25 13:04:31\ntags:\n---\n\n\nhttp://man.linuxde.net/pmap\n\n\n### 还有这种东西啊。。。\nhttp://makelinux.net/kernel_map/\n\n用pmap来查看mmap堆外内存\n\n```\npublic static void main(String[] args) throws Exception {\n        int len = 1024 * 1024 * 1024;\n        File file = new File(\"/Users/eric/Code/kick-off/MappedByteBuffer-kick-off/src/main/resources/bigFile.cc\");\n\n        RandomAccessFile accessFile = new RandomAccessFile(file, \"rw\");\n\n        MappedByteBuffer mappedByteBuffer = accessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, len);\n\n        for (int i = 0; i < len; i++) {\n            mappedByteBuffer.put((byte) (i % 128));\n        }\n        System.out.println(mappedByteBuffer.limit());\n        System.out.println(\"done\");\n\n        Thread.sleep(10000000);\n\n//        file.delete();\n    }\n```\n\n运行程序前，\neric@ubuntu:~/Software/pcstat$ free -m\n              total        used        free      shared  buff/cache   available\nMem:           1982        1551         213           8         217         238\nSwap:          1021         437         584\n\n运行sleep后:\neric@ubuntu:~/Software/pcstat$ free -m\n              total        used        free      shared  buff/cache   available\nMem:           1982        1566          81           8         335         221\nSwap:          1021         437         584\n\n\neric@ubuntu:~/Software/pcstat$ ./pcstat /home/eric/IdeaProjects/memmap/src/main/resources/bigFile.cc\n|--------------------------------------------------------------+----------------+------------+-----------+---------|\n| Name                                                         | Size           | Pages      | Cached    | Percent |\n|--------------------------------------------------------------+----------------+------------+-----------+---------|\n| /home/eric/IdeaProjects/memmap/src/main/resources/bigFile.cc | 1073741824     | 262144     | 35136     | 013.403 |\n|--------------------------------------------------------------+----------------+------------+-----------+---------|\n\n\neric@ubuntu:~/Software/pcstat$ pmap -X 4690\n4690:   /home/eric/Software/jdk1.7.0_79/bin/java -Didea.launcher.port=7532 -Didea.launcher.bin.path=/home/eric/Software/idea-IU-162.1121.32/bin -Dfile.encoding=UTF-8 -classpath /home/eric/Software/jdk1.7.0_79/jre/lib/charsets.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/deploy.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/dnsns.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/localedata.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunec.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunjce_provider.jar:/home/\n         Address Perm   Offset Device   Inode    Size    Rss    Pss Referenced Anonymous Shared_Hugetlb Private_Hugetlb Swap SwapPss Locked Mapping\n        00400000 r-xp 00000000  08:01  801959       4      4      2          4         0              0               0    0       0      0 java\n        00600000 rw-p 00000000  08:01  801959       4      4      4          4         4              0               0    0       0      0 java\n        0122b000 rw-p 00000000  00:00       0     132     12     12         12        12              0               0    0       0      0 [heap]\n        dbe00000 rw-p 00000000  00:00       0   10560   2048   2048       2048      2048              0               0    0       0      0 \n        dc850000 rw-p 00000000  00:00       0  158720      0      0          0         0              0               0    0       0      0 \n        e6350000 rw-p 00000000  00:00       0   21184      0      0          0         0              0               0    0       0      0 \n        e7800000 rw-p 00000000  00:00       0  317440      0      0          0         0              0               0    0       0      0 \n        fae00000 rw-p 00000000  00:00       0   21248   4096   4096       4096      4096              0               0    0       0      0 \n        fc2c0000 rw-p 00000000  00:00       0   62720      0      0          0         0              0               0    0       0      0 \n    7f55bcfff000 rw-s 00000000  08:01 1053783 1048576 140544 140544     140544         0              0               0    0       0      0 bigFile.cc\n    7f55fcfff000 rw-p 00000000  00:00       0   49156      4      4          4         4              0               0    0       0      0 \n    7f5600000000 rw-p 00000000  00:00       0     168    168    168        168       168              0               0    0       0      0 \n\npcstat PageCache: 35136 * 4 = 140544\npmap Rss PageCache: 140544\n\n\n作者：in nek\n链接：https://www.zhihu.com/question/48161206/answer/110418693\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n你的脑子是晕的，被听到的信息搞晕了头脑，我帮你洗一次脑吧。1. 请放弃虚拟内存这个概念，那个是广告性的概念，在开发中没有意义。开发中只有虚拟空间的概念，进程看到的所有地址组成的空间，就是虚拟空间。虚拟空间是某个进程对分配给它的所有物理地址（已经分配的和将会分配的）的重新映射。2. mmap的作用，在应用这一层，是让你把文件的某一段，当作内存一样来访问。内核和驱动如何实现的，性能高不高这些问题，这层语义上没有承诺。你基于功能决定怎么用它就好了，少胡思乱想。有了以上两个，你就可以写好程序了。下面介绍一下Linux的实现细节，权当好玩，如果你搞不清楚前面两条，后面的就不要看，否则你又乱掉了。3. mmap的工作原理，当你发起这个调用的时候，它只是在你的虚拟空间中分配了一段空间，连真实的物理地址都不会分配的，当你访问这段空间，CPU陷入OS内核执行异常处理，然后异常处理会在这个时间分配物理内存，并用文件的内容填充这片内存，然后才返回你进程的上下文，这时你的程序才会感知到这片内存里有数据4. 驱动每次读入多少页面，页面的分配算法等等，都不是系统的承诺，不能作为你编程的依赖。这就是前面说的：不要胡思乱想5. 至于swap分区的作用，参考这里：Linux 是怎样使用内存的？ - in nek 的回答基于题主继续的问题，我们接着来解释一下为什么我建议你放弃虚拟内存而使用虚拟空间的概念。","slug":"Linux-Pmap","published":1,"updated":"2019-09-28T08:51:00.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83y003ev1np03222je9","content":"<p><a href=\"http://man.linuxde.net/pmap\" target=\"_blank\" rel=\"noopener\">http://man.linuxde.net/pmap</a></p>\n<h3 id=\"还有这种东西啊。。。\"><a href=\"#还有这种东西啊。。。\" class=\"headerlink\" title=\"还有这种东西啊。。。\"></a>还有这种东西啊。。。</h3><p><a href=\"http://makelinux.net/kernel_map/\" target=\"_blank\" rel=\"noopener\">http://makelinux.net/kernel_map/</a></p>\n<p>用pmap来查看mmap堆外内存</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static void main(String[] args) throws Exception &#123;</span><br><span class=\"line\">        int len = 1024 * 1024 * 1024;</span><br><span class=\"line\">        File file = new File(&quot;/Users/eric/Code/kick-off/MappedByteBuffer-kick-off/src/main/resources/bigFile.cc&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">        RandomAccessFile accessFile = new RandomAccessFile(file, &quot;rw&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">        MappedByteBuffer mappedByteBuffer = accessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, len);</span><br><span class=\"line\"></span><br><span class=\"line\">        for (int i = 0; i &lt; len; i++) &#123;</span><br><span class=\"line\">            mappedByteBuffer.put((byte) (i % 128));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        System.out.println(mappedByteBuffer.limit());</span><br><span class=\"line\">        System.out.println(&quot;done&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">        Thread.sleep(10000000);</span><br><span class=\"line\"></span><br><span class=\"line\">//        file.delete();</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>运行程序前，<br>eric@ubuntu:~/Software/pcstat$ free -m<br>              total        used        free      shared  buff/cache   available<br>Mem:           1982        1551         213           8         217         238<br>Swap:          1021         437         584</p>\n<p>运行sleep后:<br>eric@ubuntu:~/Software/pcstat$ free -m<br>              total        used        free      shared  buff/cache   available<br>Mem:           1982        1566          81           8         335         221<br>Swap:          1021         437         584</p>\n<p>eric@ubuntu:~/Software/pcstat$ ./pcstat /home/eric/IdeaProjects/memmap/src/main/resources/bigFile.cc<br>|————————————————————–+—————-+————+———–+———|<br>| Name                                                         | Size           | Pages      | Cached    | Percent |<br>|————————————————————–+—————-+————+———–+———|<br>| /home/eric/IdeaProjects/memmap/src/main/resources/bigFile.cc | 1073741824     | 262144     | 35136     | 013.403 |<br>|————————————————————–+—————-+————+———–+———|</p>\n<p>eric@ubuntu:~/Software/pcstat$ pmap -X 4690<br>4690:   /home/eric/Software/jdk1.7.0_79/bin/java -Didea.launcher.port=7532 -Didea.launcher.bin.path=/home/eric/Software/idea-IU-162.1121.32/bin -Dfile.encoding=UTF-8 -classpath /home/eric/Software/jdk1.7.0_79/jre/lib/charsets.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/deploy.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/dnsns.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/localedata.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunec.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunjce_provider.jar:/home/<br>         Address Perm   Offset Device   Inode    Size    Rss    Pss Referenced Anonymous Shared_Hugetlb Private_Hugetlb Swap SwapPss Locked Mapping<br>        00400000 r-xp 00000000  08:01  801959       4      4      2          4         0              0               0    0       0      0 java<br>        00600000 rw-p 00000000  08:01  801959       4      4      4          4         4              0               0    0       0      0 java<br>        0122b000 rw-p 00000000  00:00       0     132     12     12         12        12              0               0    0       0      0 [heap]<br>        dbe00000 rw-p 00000000  00:00       0   10560   2048   2048       2048      2048              0               0    0       0      0<br>        dc850000 rw-p 00000000  00:00       0  158720      0      0          0         0              0               0    0       0      0<br>        e6350000 rw-p 00000000  00:00       0   21184      0      0          0         0              0               0    0       0      0<br>        e7800000 rw-p 00000000  00:00       0  317440      0      0          0         0              0               0    0       0      0<br>        fae00000 rw-p 00000000  00:00       0   21248   4096   4096       4096      4096              0               0    0       0      0<br>        fc2c0000 rw-p 00000000  00:00       0   62720      0      0          0         0              0               0    0       0      0<br>    7f55bcfff000 rw-s 00000000  08:01 1053783 1048576 140544 140544     140544         0              0               0    0       0      0 bigFile.cc<br>    7f55fcfff000 rw-p 00000000  00:00       0   49156      4      4          4         4              0               0    0       0      0<br>    7f5600000000 rw-p 00000000  00:00       0     168    168    168        168       168              0               0    0       0      0 </p>\n<p>pcstat PageCache: 35136 * 4 = 140544<br>pmap Rss PageCache: 140544</p>\n<p>作者：in nek<br>链接：<a href=\"https://www.zhihu.com/question/48161206/answer/110418693\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/48161206/answer/110418693</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>\n<p>你的脑子是晕的，被听到的信息搞晕了头脑，我帮你洗一次脑吧。1. 请放弃虚拟内存这个概念，那个是广告性的概念，在开发中没有意义。开发中只有虚拟空间的概念，进程看到的所有地址组成的空间，就是虚拟空间。虚拟空间是某个进程对分配给它的所有物理地址（已经分配的和将会分配的）的重新映射。2. mmap的作用，在应用这一层，是让你把文件的某一段，当作内存一样来访问。内核和驱动如何实现的，性能高不高这些问题，这层语义上没有承诺。你基于功能决定怎么用它就好了，少胡思乱想。有了以上两个，你就可以写好程序了。下面介绍一下Linux的实现细节，权当好玩，如果你搞不清楚前面两条，后面的就不要看，否则你又乱掉了。3. mmap的工作原理，当你发起这个调用的时候，它只是在你的虚拟空间中分配了一段空间，连真实的物理地址都不会分配的，当你访问这段空间，CPU陷入OS内核执行异常处理，然后异常处理会在这个时间分配物理内存，并用文件的内容填充这片内存，然后才返回你进程的上下文，这时你的程序才会感知到这片内存里有数据4. 驱动每次读入多少页面，页面的分配算法等等，都不是系统的承诺，不能作为你编程的依赖。这就是前面说的：不要胡思乱想5. 至于swap分区的作用，参考这里：Linux 是怎样使用内存的？ - in nek 的回答基于题主继续的问题，我们接着来解释一下为什么我建议你放弃虚拟内存而使用虚拟空间的概念。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://man.linuxde.net/pmap\" target=\"_blank\" rel=\"noopener\">http://man.linuxde.net/pmap</a></p>\n<h3 id=\"还有这种东西啊。。。\"><a href=\"#还有这种东西啊。。。\" class=\"headerlink\" title=\"还有这种东西啊。。。\"></a>还有这种东西啊。。。</h3><p><a href=\"http://makelinux.net/kernel_map/\" target=\"_blank\" rel=\"noopener\">http://makelinux.net/kernel_map/</a></p>\n<p>用pmap来查看mmap堆外内存</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public static void main(String[] args) throws Exception &#123;</span><br><span class=\"line\">        int len = 1024 * 1024 * 1024;</span><br><span class=\"line\">        File file = new File(&quot;/Users/eric/Code/kick-off/MappedByteBuffer-kick-off/src/main/resources/bigFile.cc&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">        RandomAccessFile accessFile = new RandomAccessFile(file, &quot;rw&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">        MappedByteBuffer mappedByteBuffer = accessFile.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, len);</span><br><span class=\"line\"></span><br><span class=\"line\">        for (int i = 0; i &lt; len; i++) &#123;</span><br><span class=\"line\">            mappedByteBuffer.put((byte) (i % 128));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        System.out.println(mappedByteBuffer.limit());</span><br><span class=\"line\">        System.out.println(&quot;done&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">        Thread.sleep(10000000);</span><br><span class=\"line\"></span><br><span class=\"line\">//        file.delete();</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>运行程序前，<br>eric@ubuntu:~/Software/pcstat$ free -m<br>              total        used        free      shared  buff/cache   available<br>Mem:           1982        1551         213           8         217         238<br>Swap:          1021         437         584</p>\n<p>运行sleep后:<br>eric@ubuntu:~/Software/pcstat$ free -m<br>              total        used        free      shared  buff/cache   available<br>Mem:           1982        1566          81           8         335         221<br>Swap:          1021         437         584</p>\n<p>eric@ubuntu:~/Software/pcstat$ ./pcstat /home/eric/IdeaProjects/memmap/src/main/resources/bigFile.cc<br>|————————————————————–+—————-+————+———–+———|<br>| Name                                                         | Size           | Pages      | Cached    | Percent |<br>|————————————————————–+—————-+————+———–+———|<br>| /home/eric/IdeaProjects/memmap/src/main/resources/bigFile.cc | 1073741824     | 262144     | 35136     | 013.403 |<br>|————————————————————–+—————-+————+———–+———|</p>\n<p>eric@ubuntu:~/Software/pcstat$ pmap -X 4690<br>4690:   /home/eric/Software/jdk1.7.0_79/bin/java -Didea.launcher.port=7532 -Didea.launcher.bin.path=/home/eric/Software/idea-IU-162.1121.32/bin -Dfile.encoding=UTF-8 -classpath /home/eric/Software/jdk1.7.0_79/jre/lib/charsets.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/deploy.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/dnsns.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/localedata.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunec.jar:/home/eric/Software/jdk1.7.0_79/jre/lib/ext/sunjce_provider.jar:/home/<br>         Address Perm   Offset Device   Inode    Size    Rss    Pss Referenced Anonymous Shared_Hugetlb Private_Hugetlb Swap SwapPss Locked Mapping<br>        00400000 r-xp 00000000  08:01  801959       4      4      2          4         0              0               0    0       0      0 java<br>        00600000 rw-p 00000000  08:01  801959       4      4      4          4         4              0               0    0       0      0 java<br>        0122b000 rw-p 00000000  00:00       0     132     12     12         12        12              0               0    0       0      0 [heap]<br>        dbe00000 rw-p 00000000  00:00       0   10560   2048   2048       2048      2048              0               0    0       0      0<br>        dc850000 rw-p 00000000  00:00       0  158720      0      0          0         0              0               0    0       0      0<br>        e6350000 rw-p 00000000  00:00       0   21184      0      0          0         0              0               0    0       0      0<br>        e7800000 rw-p 00000000  00:00       0  317440      0      0          0         0              0               0    0       0      0<br>        fae00000 rw-p 00000000  00:00       0   21248   4096   4096       4096      4096              0               0    0       0      0<br>        fc2c0000 rw-p 00000000  00:00       0   62720      0      0          0         0              0               0    0       0      0<br>    7f55bcfff000 rw-s 00000000  08:01 1053783 1048576 140544 140544     140544         0              0               0    0       0      0 bigFile.cc<br>    7f55fcfff000 rw-p 00000000  00:00       0   49156      4      4          4         4              0               0    0       0      0<br>    7f5600000000 rw-p 00000000  00:00       0     168    168    168        168       168              0               0    0       0      0 </p>\n<p>pcstat PageCache: 35136 * 4 = 140544<br>pmap Rss PageCache: 140544</p>\n<p>作者：in nek<br>链接：<a href=\"https://www.zhihu.com/question/48161206/answer/110418693\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/48161206/answer/110418693</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>\n<p>你的脑子是晕的，被听到的信息搞晕了头脑，我帮你洗一次脑吧。1. 请放弃虚拟内存这个概念，那个是广告性的概念，在开发中没有意义。开发中只有虚拟空间的概念，进程看到的所有地址组成的空间，就是虚拟空间。虚拟空间是某个进程对分配给它的所有物理地址（已经分配的和将会分配的）的重新映射。2. mmap的作用，在应用这一层，是让你把文件的某一段，当作内存一样来访问。内核和驱动如何实现的，性能高不高这些问题，这层语义上没有承诺。你基于功能决定怎么用它就好了，少胡思乱想。有了以上两个，你就可以写好程序了。下面介绍一下Linux的实现细节，权当好玩，如果你搞不清楚前面两条，后面的就不要看，否则你又乱掉了。3. mmap的工作原理，当你发起这个调用的时候，它只是在你的虚拟空间中分配了一段空间，连真实的物理地址都不会分配的，当你访问这段空间，CPU陷入OS内核执行异常处理，然后异常处理会在这个时间分配物理内存，并用文件的内容填充这片内存，然后才返回你进程的上下文，这时你的程序才会感知到这片内存里有数据4. 驱动每次读入多少页面，页面的分配算法等等，都不是系统的承诺，不能作为你编程的依赖。这就是前面说的：不要胡思乱想5. 至于swap分区的作用，参考这里：Linux 是怎样使用内存的？ - in nek 的回答基于题主继续的问题，我们接着来解释一下为什么我建议你放弃虚拟内存而使用虚拟空间的概念。</p>\n"},{"title":"Linux-Pagecache","date":"2018-08-14T09:17:43.000Z","_content":"\n\n### Linux文件读写机制及优化方式\nhttps://blog.csdn.net/littlewhite1989/article/details/52583879\n\n### 什么是pagecache\n```\nIn computing, a page cache, sometimes also called disk cache,[2] is a transparent cache for the pages originating from a secondary storage device such as a hard disk drive (HDD). The operating system keeps a page cache in otherwise unused portions of the main memory (RAM), resulting in quicker access to the contents of cached pages and overall performance improvements. A page cache is implemented in kernels with the paging memory management, and is mostly transparent to applications.\n```\n\n### pagecache查看\nfree -h\n\n推荐一款工具pcstat(https://github.com/tobert/pcstat)，它可以直观得显示出指定文件是否被cache，甚至可以知道cache的比例是多少。\n\n### pagecache清理\n```\n释放缓存区内存的方法\n1）清理pagecache（页面缓存）\n[root@backup ~]# echo 1 > /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=1\n \n2）清理dentries（目录缓存）和inodes\n[root@backup ~]# echo 2 > /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=2\n \n3）清理pagecache、dentries和inodes\n[root@backup ~]# echo 3 > /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=3\n```\n\n### pagecache中脏页调优\nhttps://blog.csdn.net/csCrazybing/article/details/78127308\n\n### pagecache应用\nRocketMQ和Kafka的应用\n\n### pagecache参考文章\nhttps://www.cnblogs.com/kevingrace/p/5991604.html\n\n### page cache与脏页\nhttps://blog.csdn.net/yunsongice/article/details/5850855\n\n```\n页面类型 \n\nLinux 中内存页面有三种类型： \n\n·    Read pages，只读页（或代码页），那些通过主缺页中断从硬盘读取的页面，包括不能修改的静态文件、可执行文件、库文件等。当内核需要它们的时候把它们读到 内存中，当内存不足的时候，内核就释放它们到空闲列表，当程序再次需要它们的时候需要通过缺页中断再次读到内存。 \n\n·    Dirty pages，脏页，指那些在内存中被修改过的数据页，比如文本文件等。这些文件由 pdflush 负责同步到硬盘，内存不足的时候由 kswapd 和 pdflush 把数据写回硬盘并释放内存。 \n\n·    Anonymous pages，匿名页，那些属于某个进程但是又和任何文件无关联，不能被同步到硬盘上，内存不足的时候由 kswapd 负责将它们写到交换分区并释放内存。 \n```\n\n### 怎么查看脏页的大小\n```\ncat /proc/meminfo |grep Dirty\nDirty:              1184 kB\n```\n\n### 怎么查看关于脏页刷新的配置\n```\n[root@kafka1003 ~]# sysctl -a |grep dirty\nvm.dirty_background_bytes = 0\nvm.dirty_background_ratio = 10\nvm.dirty_bytes = 0\nvm.dirty_expire_centisecs = 3000\nvm.dirty_ratio = 30\nvm.dirty_writeback_centisecs = 500\n```\n\n### 脏页刷盘的几种情况\n1. 局部脏页过期dirty_expire_centisecs\n2. 全部脏页定时dirty_writeback_centisecs\n3. 全部脏页数量达到阈值dirty_background_bytes/dirty_bytes\n4. 全部脏页比例达到阈值dirty_background_ratio/dirty_ratio\n5. 手动执行fsync/sync\n\n### sync\n```\nSYNC(1)                          User Commands                         SYNC(1)\n\nNAME\n       sync - flush file system buffers\n\nSYNOPSIS\n       sync [OPTION]\n\nDESCRIPTION\n       Force changed blocks to disk, update the super block.\n\n       --help display this help and exit\n\n       --version\n              output version information and exit\n```\n","source":"_posts/Linux-Pagecache.md","raw":"---\ntitle: Linux-Pagecache\ndate: 2018-08-14 17:17:43\ntags:\n---\n\n\n### Linux文件读写机制及优化方式\nhttps://blog.csdn.net/littlewhite1989/article/details/52583879\n\n### 什么是pagecache\n```\nIn computing, a page cache, sometimes also called disk cache,[2] is a transparent cache for the pages originating from a secondary storage device such as a hard disk drive (HDD). The operating system keeps a page cache in otherwise unused portions of the main memory (RAM), resulting in quicker access to the contents of cached pages and overall performance improvements. A page cache is implemented in kernels with the paging memory management, and is mostly transparent to applications.\n```\n\n### pagecache查看\nfree -h\n\n推荐一款工具pcstat(https://github.com/tobert/pcstat)，它可以直观得显示出指定文件是否被cache，甚至可以知道cache的比例是多少。\n\n### pagecache清理\n```\n释放缓存区内存的方法\n1）清理pagecache（页面缓存）\n[root@backup ~]# echo 1 > /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=1\n \n2）清理dentries（目录缓存）和inodes\n[root@backup ~]# echo 2 > /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=2\n \n3）清理pagecache、dentries和inodes\n[root@backup ~]# echo 3 > /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=3\n```\n\n### pagecache中脏页调优\nhttps://blog.csdn.net/csCrazybing/article/details/78127308\n\n### pagecache应用\nRocketMQ和Kafka的应用\n\n### pagecache参考文章\nhttps://www.cnblogs.com/kevingrace/p/5991604.html\n\n### page cache与脏页\nhttps://blog.csdn.net/yunsongice/article/details/5850855\n\n```\n页面类型 \n\nLinux 中内存页面有三种类型： \n\n·    Read pages，只读页（或代码页），那些通过主缺页中断从硬盘读取的页面，包括不能修改的静态文件、可执行文件、库文件等。当内核需要它们的时候把它们读到 内存中，当内存不足的时候，内核就释放它们到空闲列表，当程序再次需要它们的时候需要通过缺页中断再次读到内存。 \n\n·    Dirty pages，脏页，指那些在内存中被修改过的数据页，比如文本文件等。这些文件由 pdflush 负责同步到硬盘，内存不足的时候由 kswapd 和 pdflush 把数据写回硬盘并释放内存。 \n\n·    Anonymous pages，匿名页，那些属于某个进程但是又和任何文件无关联，不能被同步到硬盘上，内存不足的时候由 kswapd 负责将它们写到交换分区并释放内存。 \n```\n\n### 怎么查看脏页的大小\n```\ncat /proc/meminfo |grep Dirty\nDirty:              1184 kB\n```\n\n### 怎么查看关于脏页刷新的配置\n```\n[root@kafka1003 ~]# sysctl -a |grep dirty\nvm.dirty_background_bytes = 0\nvm.dirty_background_ratio = 10\nvm.dirty_bytes = 0\nvm.dirty_expire_centisecs = 3000\nvm.dirty_ratio = 30\nvm.dirty_writeback_centisecs = 500\n```\n\n### 脏页刷盘的几种情况\n1. 局部脏页过期dirty_expire_centisecs\n2. 全部脏页定时dirty_writeback_centisecs\n3. 全部脏页数量达到阈值dirty_background_bytes/dirty_bytes\n4. 全部脏页比例达到阈值dirty_background_ratio/dirty_ratio\n5. 手动执行fsync/sync\n\n### sync\n```\nSYNC(1)                          User Commands                         SYNC(1)\n\nNAME\n       sync - flush file system buffers\n\nSYNOPSIS\n       sync [OPTION]\n\nDESCRIPTION\n       Force changed blocks to disk, update the super block.\n\n       --help display this help and exit\n\n       --version\n              output version information and exit\n```\n","slug":"Linux-Pagecache","published":1,"updated":"2019-09-28T08:51:00.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83y003fv1np7l81xwxg","content":"<h3 id=\"Linux文件读写机制及优化方式\"><a href=\"#Linux文件读写机制及优化方式\" class=\"headerlink\" title=\"Linux文件读写机制及优化方式\"></a>Linux文件读写机制及优化方式</h3><p><a href=\"https://blog.csdn.net/littlewhite1989/article/details/52583879\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/littlewhite1989/article/details/52583879</a></p>\n<h3 id=\"什么是pagecache\"><a href=\"#什么是pagecache\" class=\"headerlink\" title=\"什么是pagecache\"></a>什么是pagecache</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In computing, a page cache, sometimes also called disk cache,[2] is a transparent cache for the pages originating from a secondary storage device such as a hard disk drive (HDD). The operating system keeps a page cache in otherwise unused portions of the main memory (RAM), resulting in quicker access to the contents of cached pages and overall performance improvements. A page cache is implemented in kernels with the paging memory management, and is mostly transparent to applications.</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"pagecache查看\"><a href=\"#pagecache查看\" class=\"headerlink\" title=\"pagecache查看\"></a>pagecache查看</h3><p>free -h</p>\n<p>推荐一款工具pcstat(<a href=\"https://github.com/tobert/pcstat)，它可以直观得显示出指定文件是否被cache，甚至可以知道cache的比例是多少。\" target=\"_blank\" rel=\"noopener\">https://github.com/tobert/pcstat)，它可以直观得显示出指定文件是否被cache，甚至可以知道cache的比例是多少。</a></p>\n<h3 id=\"pagecache清理\"><a href=\"#pagecache清理\" class=\"headerlink\" title=\"pagecache清理\"></a>pagecache清理</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">释放缓存区内存的方法</span><br><span class=\"line\">1）清理pagecache（页面缓存）</span><br><span class=\"line\">[root@backup ~]# echo 1 &gt; /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=1</span><br><span class=\"line\"> </span><br><span class=\"line\">2）清理dentries（目录缓存）和inodes</span><br><span class=\"line\">[root@backup ~]# echo 2 &gt; /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=2</span><br><span class=\"line\"> </span><br><span class=\"line\">3）清理pagecache、dentries和inodes</span><br><span class=\"line\">[root@backup ~]# echo 3 &gt; /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=3</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"pagecache中脏页调优\"><a href=\"#pagecache中脏页调优\" class=\"headerlink\" title=\"pagecache中脏页调优\"></a>pagecache中脏页调优</h3><p><a href=\"https://blog.csdn.net/csCrazybing/article/details/78127308\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/csCrazybing/article/details/78127308</a></p>\n<h3 id=\"pagecache应用\"><a href=\"#pagecache应用\" class=\"headerlink\" title=\"pagecache应用\"></a>pagecache应用</h3><p>RocketMQ和Kafka的应用</p>\n<h3 id=\"pagecache参考文章\"><a href=\"#pagecache参考文章\" class=\"headerlink\" title=\"pagecache参考文章\"></a>pagecache参考文章</h3><p><a href=\"https://www.cnblogs.com/kevingrace/p/5991604.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/kevingrace/p/5991604.html</a></p>\n<h3 id=\"page-cache与脏页\"><a href=\"#page-cache与脏页\" class=\"headerlink\" title=\"page cache与脏页\"></a>page cache与脏页</h3><p><a href=\"https://blog.csdn.net/yunsongice/article/details/5850855\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yunsongice/article/details/5850855</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">页面类型 </span><br><span class=\"line\"></span><br><span class=\"line\">Linux 中内存页面有三种类型： </span><br><span class=\"line\"></span><br><span class=\"line\">·    Read pages，只读页（或代码页），那些通过主缺页中断从硬盘读取的页面，包括不能修改的静态文件、可执行文件、库文件等。当内核需要它们的时候把它们读到 内存中，当内存不足的时候，内核就释放它们到空闲列表，当程序再次需要它们的时候需要通过缺页中断再次读到内存。 </span><br><span class=\"line\"></span><br><span class=\"line\">·    Dirty pages，脏页，指那些在内存中被修改过的数据页，比如文本文件等。这些文件由 pdflush 负责同步到硬盘，内存不足的时候由 kswapd 和 pdflush 把数据写回硬盘并释放内存。 </span><br><span class=\"line\"></span><br><span class=\"line\">·    Anonymous pages，匿名页，那些属于某个进程但是又和任何文件无关联，不能被同步到硬盘上，内存不足的时候由 kswapd 负责将它们写到交换分区并释放内存。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"怎么查看脏页的大小\"><a href=\"#怎么查看脏页的大小\" class=\"headerlink\" title=\"怎么查看脏页的大小\"></a>怎么查看脏页的大小</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/meminfo |grep Dirty</span><br><span class=\"line\">Dirty:              1184 kB</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"怎么查看关于脏页刷新的配置\"><a href=\"#怎么查看关于脏页刷新的配置\" class=\"headerlink\" title=\"怎么查看关于脏页刷新的配置\"></a>怎么查看关于脏页刷新的配置</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kafka1003 ~]# sysctl -a |grep dirty</span><br><span class=\"line\">vm.dirty_background_bytes = 0</span><br><span class=\"line\">vm.dirty_background_ratio = 10</span><br><span class=\"line\">vm.dirty_bytes = 0</span><br><span class=\"line\">vm.dirty_expire_centisecs = 3000</span><br><span class=\"line\">vm.dirty_ratio = 30</span><br><span class=\"line\">vm.dirty_writeback_centisecs = 500</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"脏页刷盘的几种情况\"><a href=\"#脏页刷盘的几种情况\" class=\"headerlink\" title=\"脏页刷盘的几种情况\"></a>脏页刷盘的几种情况</h3><ol>\n<li>局部脏页过期dirty_expire_centisecs</li>\n<li>全部脏页定时dirty_writeback_centisecs</li>\n<li>全部脏页数量达到阈值dirty_background_bytes/dirty_bytes</li>\n<li>全部脏页比例达到阈值dirty_background_ratio/dirty_ratio</li>\n<li>手动执行fsync/sync</li>\n</ol>\n<h3 id=\"sync\"><a href=\"#sync\" class=\"headerlink\" title=\"sync\"></a>sync</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SYNC(1)                          User Commands                         SYNC(1)</span><br><span class=\"line\"></span><br><span class=\"line\">NAME</span><br><span class=\"line\">       sync - flush file system buffers</span><br><span class=\"line\"></span><br><span class=\"line\">SYNOPSIS</span><br><span class=\"line\">       sync [OPTION]</span><br><span class=\"line\"></span><br><span class=\"line\">DESCRIPTION</span><br><span class=\"line\">       Force changed blocks to disk, update the super block.</span><br><span class=\"line\"></span><br><span class=\"line\">       --help display this help and exit</span><br><span class=\"line\"></span><br><span class=\"line\">       --version</span><br><span class=\"line\">              output version information and exit</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Linux文件读写机制及优化方式\"><a href=\"#Linux文件读写机制及优化方式\" class=\"headerlink\" title=\"Linux文件读写机制及优化方式\"></a>Linux文件读写机制及优化方式</h3><p><a href=\"https://blog.csdn.net/littlewhite1989/article/details/52583879\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/littlewhite1989/article/details/52583879</a></p>\n<h3 id=\"什么是pagecache\"><a href=\"#什么是pagecache\" class=\"headerlink\" title=\"什么是pagecache\"></a>什么是pagecache</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In computing, a page cache, sometimes also called disk cache,[2] is a transparent cache for the pages originating from a secondary storage device such as a hard disk drive (HDD). The operating system keeps a page cache in otherwise unused portions of the main memory (RAM), resulting in quicker access to the contents of cached pages and overall performance improvements. A page cache is implemented in kernels with the paging memory management, and is mostly transparent to applications.</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"pagecache查看\"><a href=\"#pagecache查看\" class=\"headerlink\" title=\"pagecache查看\"></a>pagecache查看</h3><p>free -h</p>\n<p>推荐一款工具pcstat(<a href=\"https://github.com/tobert/pcstat)，它可以直观得显示出指定文件是否被cache，甚至可以知道cache的比例是多少。\" target=\"_blank\" rel=\"noopener\">https://github.com/tobert/pcstat)，它可以直观得显示出指定文件是否被cache，甚至可以知道cache的比例是多少。</a></p>\n<h3 id=\"pagecache清理\"><a href=\"#pagecache清理\" class=\"headerlink\" title=\"pagecache清理\"></a>pagecache清理</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">释放缓存区内存的方法</span><br><span class=\"line\">1）清理pagecache（页面缓存）</span><br><span class=\"line\">[root@backup ~]# echo 1 &gt; /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=1</span><br><span class=\"line\"> </span><br><span class=\"line\">2）清理dentries（目录缓存）和inodes</span><br><span class=\"line\">[root@backup ~]# echo 2 &gt; /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=2</span><br><span class=\"line\"> </span><br><span class=\"line\">3）清理pagecache、dentries和inodes</span><br><span class=\"line\">[root@backup ~]# echo 3 &gt; /proc/sys/vm/drop_caches     或者 # sysctl -w vm.drop_caches=3</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"pagecache中脏页调优\"><a href=\"#pagecache中脏页调优\" class=\"headerlink\" title=\"pagecache中脏页调优\"></a>pagecache中脏页调优</h3><p><a href=\"https://blog.csdn.net/csCrazybing/article/details/78127308\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/csCrazybing/article/details/78127308</a></p>\n<h3 id=\"pagecache应用\"><a href=\"#pagecache应用\" class=\"headerlink\" title=\"pagecache应用\"></a>pagecache应用</h3><p>RocketMQ和Kafka的应用</p>\n<h3 id=\"pagecache参考文章\"><a href=\"#pagecache参考文章\" class=\"headerlink\" title=\"pagecache参考文章\"></a>pagecache参考文章</h3><p><a href=\"https://www.cnblogs.com/kevingrace/p/5991604.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/kevingrace/p/5991604.html</a></p>\n<h3 id=\"page-cache与脏页\"><a href=\"#page-cache与脏页\" class=\"headerlink\" title=\"page cache与脏页\"></a>page cache与脏页</h3><p><a href=\"https://blog.csdn.net/yunsongice/article/details/5850855\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yunsongice/article/details/5850855</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">页面类型 </span><br><span class=\"line\"></span><br><span class=\"line\">Linux 中内存页面有三种类型： </span><br><span class=\"line\"></span><br><span class=\"line\">·    Read pages，只读页（或代码页），那些通过主缺页中断从硬盘读取的页面，包括不能修改的静态文件、可执行文件、库文件等。当内核需要它们的时候把它们读到 内存中，当内存不足的时候，内核就释放它们到空闲列表，当程序再次需要它们的时候需要通过缺页中断再次读到内存。 </span><br><span class=\"line\"></span><br><span class=\"line\">·    Dirty pages，脏页，指那些在内存中被修改过的数据页，比如文本文件等。这些文件由 pdflush 负责同步到硬盘，内存不足的时候由 kswapd 和 pdflush 把数据写回硬盘并释放内存。 </span><br><span class=\"line\"></span><br><span class=\"line\">·    Anonymous pages，匿名页，那些属于某个进程但是又和任何文件无关联，不能被同步到硬盘上，内存不足的时候由 kswapd 负责将它们写到交换分区并释放内存。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"怎么查看脏页的大小\"><a href=\"#怎么查看脏页的大小\" class=\"headerlink\" title=\"怎么查看脏页的大小\"></a>怎么查看脏页的大小</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /proc/meminfo |grep Dirty</span><br><span class=\"line\">Dirty:              1184 kB</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"怎么查看关于脏页刷新的配置\"><a href=\"#怎么查看关于脏页刷新的配置\" class=\"headerlink\" title=\"怎么查看关于脏页刷新的配置\"></a>怎么查看关于脏页刷新的配置</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@kafka1003 ~]# sysctl -a |grep dirty</span><br><span class=\"line\">vm.dirty_background_bytes = 0</span><br><span class=\"line\">vm.dirty_background_ratio = 10</span><br><span class=\"line\">vm.dirty_bytes = 0</span><br><span class=\"line\">vm.dirty_expire_centisecs = 3000</span><br><span class=\"line\">vm.dirty_ratio = 30</span><br><span class=\"line\">vm.dirty_writeback_centisecs = 500</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"脏页刷盘的几种情况\"><a href=\"#脏页刷盘的几种情况\" class=\"headerlink\" title=\"脏页刷盘的几种情况\"></a>脏页刷盘的几种情况</h3><ol>\n<li>局部脏页过期dirty_expire_centisecs</li>\n<li>全部脏页定时dirty_writeback_centisecs</li>\n<li>全部脏页数量达到阈值dirty_background_bytes/dirty_bytes</li>\n<li>全部脏页比例达到阈值dirty_background_ratio/dirty_ratio</li>\n<li>手动执行fsync/sync</li>\n</ol>\n<h3 id=\"sync\"><a href=\"#sync\" class=\"headerlink\" title=\"sync\"></a>sync</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SYNC(1)                          User Commands                         SYNC(1)</span><br><span class=\"line\"></span><br><span class=\"line\">NAME</span><br><span class=\"line\">       sync - flush file system buffers</span><br><span class=\"line\"></span><br><span class=\"line\">SYNOPSIS</span><br><span class=\"line\">       sync [OPTION]</span><br><span class=\"line\"></span><br><span class=\"line\">DESCRIPTION</span><br><span class=\"line\">       Force changed blocks to disk, update the super block.</span><br><span class=\"line\"></span><br><span class=\"line\">       --help display this help and exit</span><br><span class=\"line\"></span><br><span class=\"line\">       --version</span><br><span class=\"line\">              output version information and exit</span><br></pre></td></tr></table></figure>\n\n"},{"title":"Linux-Page-fault","date":"2018-09-21T15:36:36.000Z","_content":"\n\nhttps://liam0205.me/2017/09/01/page-fault/\n\n\n当进程在进行一些计算时，CPU 会请求内存中存储的数据。在这个请求过程中，CPU 发出的地址是逻辑地址（虚拟地址），然后交由 CPU 当中的 MMU 单元进行内存寻址，找到实际物理内存上的内容。若是目标虚存空间中的内存页（因为某种原因），在物理内存中没有对应的页帧，那么 CPU 就无法获取数据。这种情况下，CPU 是无法进行计算的，于是它就会报告一个缺页错误（Page Fault）。\n\n因为 CPU 无法继续进行进程请求的计算，并报告了缺页错误，用户进程必然就中断了。这样的中断称之为缺页中断。在报告 Page Fault 之后，进程会从用户态切换到系统态，交由操作系统内核的 Page Fault Handler 处理缺页错误。\n\n\n### minor 和 major page fault\nhttps://www.quora.com/What-is-the-difference-between-minor-and-major-page-fault-in-Linux\n\n\n\nhttps://processon.com/diagraming/5bfb6518e4b018141e80aecd\n\nJVM启动参数-XX:+AlwaysPreTouch\n```\nvirtualspace.cpp\nstatic bool commit_expanded(char* start, size_t size, size_t alignment, bool pre_touch, bool executable) {\n  if (os::commit_memory(start, size, alignment, executable)) {\n    if (pre_touch || AlwaysPreTouch) {\n      pretouch_expanded_memory(start, start + size);\n    }\n    return true;\n  }\n\n  debug_only(warning(\n      \"INFO: os::commit_memory(\" PTR_FORMAT \", \" PTR_FORMAT\n      \" size=\" SIZE_FORMAT \", executable=%d) failed\",\n      p2i(start), p2i(start + size), size, executable);)\n\n  return false;\n}\n\nstatic void pretouch_expanded_memory(void* start, void* end) {\n  assert(is_ptr_aligned(start, os::vm_page_size()), \"Unexpected alignment\");\n  assert(is_ptr_aligned(end,   os::vm_page_size()), \"Unexpected alignment\");\n\n  os::pretouch_memory(start, end);\n}\n\nos.cpp\nvoid os::pretouch_memory(void* start, void* end, size_t page_size) {\n  for (volatile char *p = (char*)start; p < (char*)end; p += page_size) {\n    *p = 0;\n  }\n}\n```","source":"_posts/Linux-Page-fault.md","raw":"---\ntitle: Linux-Page-fault\ndate: 2018-09-21 23:36:36\ntags:\n---\n\n\nhttps://liam0205.me/2017/09/01/page-fault/\n\n\n当进程在进行一些计算时，CPU 会请求内存中存储的数据。在这个请求过程中，CPU 发出的地址是逻辑地址（虚拟地址），然后交由 CPU 当中的 MMU 单元进行内存寻址，找到实际物理内存上的内容。若是目标虚存空间中的内存页（因为某种原因），在物理内存中没有对应的页帧，那么 CPU 就无法获取数据。这种情况下，CPU 是无法进行计算的，于是它就会报告一个缺页错误（Page Fault）。\n\n因为 CPU 无法继续进行进程请求的计算，并报告了缺页错误，用户进程必然就中断了。这样的中断称之为缺页中断。在报告 Page Fault 之后，进程会从用户态切换到系统态，交由操作系统内核的 Page Fault Handler 处理缺页错误。\n\n\n### minor 和 major page fault\nhttps://www.quora.com/What-is-the-difference-between-minor-and-major-page-fault-in-Linux\n\n\n\nhttps://processon.com/diagraming/5bfb6518e4b018141e80aecd\n\nJVM启动参数-XX:+AlwaysPreTouch\n```\nvirtualspace.cpp\nstatic bool commit_expanded(char* start, size_t size, size_t alignment, bool pre_touch, bool executable) {\n  if (os::commit_memory(start, size, alignment, executable)) {\n    if (pre_touch || AlwaysPreTouch) {\n      pretouch_expanded_memory(start, start + size);\n    }\n    return true;\n  }\n\n  debug_only(warning(\n      \"INFO: os::commit_memory(\" PTR_FORMAT \", \" PTR_FORMAT\n      \" size=\" SIZE_FORMAT \", executable=%d) failed\",\n      p2i(start), p2i(start + size), size, executable);)\n\n  return false;\n}\n\nstatic void pretouch_expanded_memory(void* start, void* end) {\n  assert(is_ptr_aligned(start, os::vm_page_size()), \"Unexpected alignment\");\n  assert(is_ptr_aligned(end,   os::vm_page_size()), \"Unexpected alignment\");\n\n  os::pretouch_memory(start, end);\n}\n\nos.cpp\nvoid os::pretouch_memory(void* start, void* end, size_t page_size) {\n  for (volatile char *p = (char*)start; p < (char*)end; p += page_size) {\n    *p = 0;\n  }\n}\n```","slug":"Linux-Page-fault","published":1,"updated":"2019-09-28T08:51:00.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83y003gv1np284rrzye","content":"<p><a href=\"https://liam0205.me/2017/09/01/page-fault/\" target=\"_blank\" rel=\"noopener\">https://liam0205.me/2017/09/01/page-fault/</a></p>\n<p>当进程在进行一些计算时，CPU 会请求内存中存储的数据。在这个请求过程中，CPU 发出的地址是逻辑地址（虚拟地址），然后交由 CPU 当中的 MMU 单元进行内存寻址，找到实际物理内存上的内容。若是目标虚存空间中的内存页（因为某种原因），在物理内存中没有对应的页帧，那么 CPU 就无法获取数据。这种情况下，CPU 是无法进行计算的，于是它就会报告一个缺页错误（Page Fault）。</p>\n<p>因为 CPU 无法继续进行进程请求的计算，并报告了缺页错误，用户进程必然就中断了。这样的中断称之为缺页中断。在报告 Page Fault 之后，进程会从用户态切换到系统态，交由操作系统内核的 Page Fault Handler 处理缺页错误。</p>\n<h3 id=\"minor-和-major-page-fault\"><a href=\"#minor-和-major-page-fault\" class=\"headerlink\" title=\"minor 和 major page fault\"></a>minor 和 major page fault</h3><p><a href=\"https://www.quora.com/What-is-the-difference-between-minor-and-major-page-fault-in-Linux\" target=\"_blank\" rel=\"noopener\">https://www.quora.com/What-is-the-difference-between-minor-and-major-page-fault-in-Linux</a></p>\n<p><a href=\"https://processon.com/diagraming/5bfb6518e4b018141e80aecd\" target=\"_blank\" rel=\"noopener\">https://processon.com/diagraming/5bfb6518e4b018141e80aecd</a></p>\n<p>JVM启动参数-XX:+AlwaysPreTouch</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">virtualspace.cpp</span><br><span class=\"line\">static bool commit_expanded(char* start, size_t size, size_t alignment, bool pre_touch, bool executable) &#123;</span><br><span class=\"line\">  if (os::commit_memory(start, size, alignment, executable)) &#123;</span><br><span class=\"line\">    if (pre_touch || AlwaysPreTouch) &#123;</span><br><span class=\"line\">      pretouch_expanded_memory(start, start + size);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  debug_only(warning(</span><br><span class=\"line\">      &quot;INFO: os::commit_memory(&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT</span><br><span class=\"line\">      &quot; size=&quot; SIZE_FORMAT &quot;, executable=%d) failed&quot;,</span><br><span class=\"line\">      p2i(start), p2i(start + size), size, executable);)</span><br><span class=\"line\"></span><br><span class=\"line\">  return false;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">static void pretouch_expanded_memory(void* start, void* end) &#123;</span><br><span class=\"line\">  assert(is_ptr_aligned(start, os::vm_page_size()), &quot;Unexpected alignment&quot;);</span><br><span class=\"line\">  assert(is_ptr_aligned(end,   os::vm_page_size()), &quot;Unexpected alignment&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">  os::pretouch_memory(start, end);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">os.cpp</span><br><span class=\"line\">void os::pretouch_memory(void* start, void* end, size_t page_size) &#123;</span><br><span class=\"line\">  for (volatile char *p = (char*)start; p &lt; (char*)end; p += page_size) &#123;</span><br><span class=\"line\">    *p = 0;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://liam0205.me/2017/09/01/page-fault/\" target=\"_blank\" rel=\"noopener\">https://liam0205.me/2017/09/01/page-fault/</a></p>\n<p>当进程在进行一些计算时，CPU 会请求内存中存储的数据。在这个请求过程中，CPU 发出的地址是逻辑地址（虚拟地址），然后交由 CPU 当中的 MMU 单元进行内存寻址，找到实际物理内存上的内容。若是目标虚存空间中的内存页（因为某种原因），在物理内存中没有对应的页帧，那么 CPU 就无法获取数据。这种情况下，CPU 是无法进行计算的，于是它就会报告一个缺页错误（Page Fault）。</p>\n<p>因为 CPU 无法继续进行进程请求的计算，并报告了缺页错误，用户进程必然就中断了。这样的中断称之为缺页中断。在报告 Page Fault 之后，进程会从用户态切换到系统态，交由操作系统内核的 Page Fault Handler 处理缺页错误。</p>\n<h3 id=\"minor-和-major-page-fault\"><a href=\"#minor-和-major-page-fault\" class=\"headerlink\" title=\"minor 和 major page fault\"></a>minor 和 major page fault</h3><p><a href=\"https://www.quora.com/What-is-the-difference-between-minor-and-major-page-fault-in-Linux\" target=\"_blank\" rel=\"noopener\">https://www.quora.com/What-is-the-difference-between-minor-and-major-page-fault-in-Linux</a></p>\n<p><a href=\"https://processon.com/diagraming/5bfb6518e4b018141e80aecd\" target=\"_blank\" rel=\"noopener\">https://processon.com/diagraming/5bfb6518e4b018141e80aecd</a></p>\n<p>JVM启动参数-XX:+AlwaysPreTouch</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">virtualspace.cpp</span><br><span class=\"line\">static bool commit_expanded(char* start, size_t size, size_t alignment, bool pre_touch, bool executable) &#123;</span><br><span class=\"line\">  if (os::commit_memory(start, size, alignment, executable)) &#123;</span><br><span class=\"line\">    if (pre_touch || AlwaysPreTouch) &#123;</span><br><span class=\"line\">      pretouch_expanded_memory(start, start + size);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return true;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  debug_only(warning(</span><br><span class=\"line\">      &quot;INFO: os::commit_memory(&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT</span><br><span class=\"line\">      &quot; size=&quot; SIZE_FORMAT &quot;, executable=%d) failed&quot;,</span><br><span class=\"line\">      p2i(start), p2i(start + size), size, executable);)</span><br><span class=\"line\"></span><br><span class=\"line\">  return false;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">static void pretouch_expanded_memory(void* start, void* end) &#123;</span><br><span class=\"line\">  assert(is_ptr_aligned(start, os::vm_page_size()), &quot;Unexpected alignment&quot;);</span><br><span class=\"line\">  assert(is_ptr_aligned(end,   os::vm_page_size()), &quot;Unexpected alignment&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">  os::pretouch_memory(start, end);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">os.cpp</span><br><span class=\"line\">void os::pretouch_memory(void* start, void* end, size_t page_size) &#123;</span><br><span class=\"line\">  for (volatile char *p = (char*)start; p &lt; (char*)end; p += page_size) &#123;</span><br><span class=\"line\">    *p = 0;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Linux-Swap","date":"2018-09-22T14:12:43.000Z","_content":"\n\nhttps://www.cnblogs.com/tolimit/p/5447448.html\n\n\n对于整个内存回收来说，lru链表是关键中的关键，实际上整个内存回收，做的事情就是处理lru链表的收缩，所以这篇文章就先说说系统的lru链表。\n内存回收的核心思想，就是如果一些数据能够保存到磁盘，在内存不足时就把这些数据写到磁盘中，这样这些数据占用的内存页就可以作为空闲内存页给予系统使用了。\n当内存不足时，系统就必须要将一些页框回收，而哪些页框可以回收呢，之前我们有说过，属于内核的大部分页框是不能够进行回收的，比如内核栈、内核代码段、内核数据段以及大部分内核使用的页框，它们都是不能够进行回收的；而相反，主要由进程使用的页框，比如进程代码段、进程数据段、进程堆栈、进程访问文件时映射的文件页、进程间共享内存使用的页，这些页框都是可以进行回收的。\n当明确哪些页框可以回收，哪些页框不能够回收时，针对那些可以回收的页框，从中选择更应该进行回收的页框就变成一件很有必要的事情了，因为选择得好，能够减轻系统的负担，选择得不好，反而拖累了系统，让系统运行起来更艰难。比如：一个非常频繁地被访问的页，这个页可以进行回收，当内存不足时，系统选择对这个页进行回收，将这个页写入磁盘，而由于此页在写入磁盘之后立即又被访问了，系统又要将这个页从磁盘读到内存中，相当于系统进行了一次读写，而页又没有能够进行释放，一个页是这样可以接受，如果是1000个页是这种情况，可想而知，这样会大大拖累的系统，让系统做了非常多无用功。\nlru链表在这时候就起到了这个重要作用，它能够让系统在那些可以回收的页框当中，选择到理想的回收页框。lru链表的核心思想就是做假设，如果一个页很久没有被访问到了，那么就假设在下一段时间中，这个页也可能不会被访问到。但是对于系统来说，它永远无法知道哪个页即将被访问，它认定一个页接下来的一段时间不会被访问到，但是有可能此页在下一刻就立刻被访问到了，也就是说，即使使用了lru链表，也不能保证不会发生上述的情况。\n\n### 笨叔叔\nmlock(), mlock2(), and mlockall() lock part or all of the calling\nprocess's virtual address space into RAM, preventing that memory from\nbeing paged to the swap area.\n\n这个是mlock的man。说是将某段虚拟内存锁进Ram，防止对应的物理内存swap out。是不是也可以理解为，锁住 vma和pm的 mapping关系，不被删除？\n\n不完全正确\n内存 不加入 LRU链表，所以也不会 被 swap out","source":"_posts/Linux-Swap.md","raw":"---\ntitle: Linux-Swap\ndate: 2018-09-22 22:12:43\ntags:\n---\n\n\nhttps://www.cnblogs.com/tolimit/p/5447448.html\n\n\n对于整个内存回收来说，lru链表是关键中的关键，实际上整个内存回收，做的事情就是处理lru链表的收缩，所以这篇文章就先说说系统的lru链表。\n内存回收的核心思想，就是如果一些数据能够保存到磁盘，在内存不足时就把这些数据写到磁盘中，这样这些数据占用的内存页就可以作为空闲内存页给予系统使用了。\n当内存不足时，系统就必须要将一些页框回收，而哪些页框可以回收呢，之前我们有说过，属于内核的大部分页框是不能够进行回收的，比如内核栈、内核代码段、内核数据段以及大部分内核使用的页框，它们都是不能够进行回收的；而相反，主要由进程使用的页框，比如进程代码段、进程数据段、进程堆栈、进程访问文件时映射的文件页、进程间共享内存使用的页，这些页框都是可以进行回收的。\n当明确哪些页框可以回收，哪些页框不能够回收时，针对那些可以回收的页框，从中选择更应该进行回收的页框就变成一件很有必要的事情了，因为选择得好，能够减轻系统的负担，选择得不好，反而拖累了系统，让系统运行起来更艰难。比如：一个非常频繁地被访问的页，这个页可以进行回收，当内存不足时，系统选择对这个页进行回收，将这个页写入磁盘，而由于此页在写入磁盘之后立即又被访问了，系统又要将这个页从磁盘读到内存中，相当于系统进行了一次读写，而页又没有能够进行释放，一个页是这样可以接受，如果是1000个页是这种情况，可想而知，这样会大大拖累的系统，让系统做了非常多无用功。\nlru链表在这时候就起到了这个重要作用，它能够让系统在那些可以回收的页框当中，选择到理想的回收页框。lru链表的核心思想就是做假设，如果一个页很久没有被访问到了，那么就假设在下一段时间中，这个页也可能不会被访问到。但是对于系统来说，它永远无法知道哪个页即将被访问，它认定一个页接下来的一段时间不会被访问到，但是有可能此页在下一刻就立刻被访问到了，也就是说，即使使用了lru链表，也不能保证不会发生上述的情况。\n\n### 笨叔叔\nmlock(), mlock2(), and mlockall() lock part or all of the calling\nprocess's virtual address space into RAM, preventing that memory from\nbeing paged to the swap area.\n\n这个是mlock的man。说是将某段虚拟内存锁进Ram，防止对应的物理内存swap out。是不是也可以理解为，锁住 vma和pm的 mapping关系，不被删除？\n\n不完全正确\n内存 不加入 LRU链表，所以也不会 被 swap out","slug":"Linux-Swap","published":1,"updated":"2019-09-28T08:51:00.885Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83z003hv1nplv0bqwof","content":"<p><a href=\"https://www.cnblogs.com/tolimit/p/5447448.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/tolimit/p/5447448.html</a></p>\n<p>对于整个内存回收来说，lru链表是关键中的关键，实际上整个内存回收，做的事情就是处理lru链表的收缩，所以这篇文章就先说说系统的lru链表。<br>内存回收的核心思想，就是如果一些数据能够保存到磁盘，在内存不足时就把这些数据写到磁盘中，这样这些数据占用的内存页就可以作为空闲内存页给予系统使用了。<br>当内存不足时，系统就必须要将一些页框回收，而哪些页框可以回收呢，之前我们有说过，属于内核的大部分页框是不能够进行回收的，比如内核栈、内核代码段、内核数据段以及大部分内核使用的页框，它们都是不能够进行回收的；而相反，主要由进程使用的页框，比如进程代码段、进程数据段、进程堆栈、进程访问文件时映射的文件页、进程间共享内存使用的页，这些页框都是可以进行回收的。<br>当明确哪些页框可以回收，哪些页框不能够回收时，针对那些可以回收的页框，从中选择更应该进行回收的页框就变成一件很有必要的事情了，因为选择得好，能够减轻系统的负担，选择得不好，反而拖累了系统，让系统运行起来更艰难。比如：一个非常频繁地被访问的页，这个页可以进行回收，当内存不足时，系统选择对这个页进行回收，将这个页写入磁盘，而由于此页在写入磁盘之后立即又被访问了，系统又要将这个页从磁盘读到内存中，相当于系统进行了一次读写，而页又没有能够进行释放，一个页是这样可以接受，如果是1000个页是这种情况，可想而知，这样会大大拖累的系统，让系统做了非常多无用功。<br>lru链表在这时候就起到了这个重要作用，它能够让系统在那些可以回收的页框当中，选择到理想的回收页框。lru链表的核心思想就是做假设，如果一个页很久没有被访问到了，那么就假设在下一段时间中，这个页也可能不会被访问到。但是对于系统来说，它永远无法知道哪个页即将被访问，它认定一个页接下来的一段时间不会被访问到，但是有可能此页在下一刻就立刻被访问到了，也就是说，即使使用了lru链表，也不能保证不会发生上述的情况。</p>\n<h3 id=\"笨叔叔\"><a href=\"#笨叔叔\" class=\"headerlink\" title=\"笨叔叔\"></a>笨叔叔</h3><p>mlock(), mlock2(), and mlockall() lock part or all of the calling<br>process’s virtual address space into RAM, preventing that memory from<br>being paged to the swap area.</p>\n<p>这个是mlock的man。说是将某段虚拟内存锁进Ram，防止对应的物理内存swap out。是不是也可以理解为，锁住 vma和pm的 mapping关系，不被删除？</p>\n<p>不完全正确<br>内存 不加入 LRU链表，所以也不会 被 swap out</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.cnblogs.com/tolimit/p/5447448.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/tolimit/p/5447448.html</a></p>\n<p>对于整个内存回收来说，lru链表是关键中的关键，实际上整个内存回收，做的事情就是处理lru链表的收缩，所以这篇文章就先说说系统的lru链表。<br>内存回收的核心思想，就是如果一些数据能够保存到磁盘，在内存不足时就把这些数据写到磁盘中，这样这些数据占用的内存页就可以作为空闲内存页给予系统使用了。<br>当内存不足时，系统就必须要将一些页框回收，而哪些页框可以回收呢，之前我们有说过，属于内核的大部分页框是不能够进行回收的，比如内核栈、内核代码段、内核数据段以及大部分内核使用的页框，它们都是不能够进行回收的；而相反，主要由进程使用的页框，比如进程代码段、进程数据段、进程堆栈、进程访问文件时映射的文件页、进程间共享内存使用的页，这些页框都是可以进行回收的。<br>当明确哪些页框可以回收，哪些页框不能够回收时，针对那些可以回收的页框，从中选择更应该进行回收的页框就变成一件很有必要的事情了，因为选择得好，能够减轻系统的负担，选择得不好，反而拖累了系统，让系统运行起来更艰难。比如：一个非常频繁地被访问的页，这个页可以进行回收，当内存不足时，系统选择对这个页进行回收，将这个页写入磁盘，而由于此页在写入磁盘之后立即又被访问了，系统又要将这个页从磁盘读到内存中，相当于系统进行了一次读写，而页又没有能够进行释放，一个页是这样可以接受，如果是1000个页是这种情况，可想而知，这样会大大拖累的系统，让系统做了非常多无用功。<br>lru链表在这时候就起到了这个重要作用，它能够让系统在那些可以回收的页框当中，选择到理想的回收页框。lru链表的核心思想就是做假设，如果一个页很久没有被访问到了，那么就假设在下一段时间中，这个页也可能不会被访问到。但是对于系统来说，它永远无法知道哪个页即将被访问，它认定一个页接下来的一段时间不会被访问到，但是有可能此页在下一刻就立刻被访问到了，也就是说，即使使用了lru链表，也不能保证不会发生上述的情况。</p>\n<h3 id=\"笨叔叔\"><a href=\"#笨叔叔\" class=\"headerlink\" title=\"笨叔叔\"></a>笨叔叔</h3><p>mlock(), mlock2(), and mlockall() lock part or all of the calling<br>process’s virtual address space into RAM, preventing that memory from<br>being paged to the swap area.</p>\n<p>这个是mlock的man。说是将某段虚拟内存锁进Ram，防止对应的物理内存swap out。是不是也可以理解为，锁住 vma和pm的 mapping关系，不被删除？</p>\n<p>不完全正确<br>内存 不加入 LRU链表，所以也不会 被 swap out</p>\n"},{"title":"Linux-TCP-dump","date":"2018-10-16T08:07:36.000Z","_content":"\n### 问题描述\n在数据库中间件中，下面的SQL执行了3010ms，但是在MySQL中，没有看到慢日志。最终定位到\n`socket.connect(new InetSocketAddress(dbHostConfig.getIp(), dbHostConfig.getPort()), SOCKET_CONNECT_TIMEOUT);`\n这行语句执行了3秒左右。\n\n```\nSELECT id\n        FROM item\n        WHERE op_time < 1539672074878\n        AND platform_id = 1\n        limit 0,1000\n```\n\n### dump指定网卡3306端口的所有TCP请求\ntcpdump -i eth0 port 3306 -w /tmp/a.out\n\n### 将a.out导入到wireshark\n\n### \n点击`find a packet`，将`Display filter`修改成为`String`，将最前面的`Packet list`修改成`Packet bytes`，从而可以匹配TCP包内部的字符串。\n查看上面的SQL，发现可以用时间作为关键字来进行查询。\n\n### 列出所有stream\n但是从包stream上来看，TCP的3次握手就是从14:41:17开始的，所以排除了网络抖动的可能性，那分析下来就只能是`new InetSocketAddress(dbHostConfig.getIp()`非常慢，该语句就是用于DNS解析。\n\n","source":"_posts/Linux-TCP-dump.md","raw":"---\ntitle: Linux-TCP-dump\ndate: 2018-10-16 16:07:36\ntags:\n---\n\n### 问题描述\n在数据库中间件中，下面的SQL执行了3010ms，但是在MySQL中，没有看到慢日志。最终定位到\n`socket.connect(new InetSocketAddress(dbHostConfig.getIp(), dbHostConfig.getPort()), SOCKET_CONNECT_TIMEOUT);`\n这行语句执行了3秒左右。\n\n```\nSELECT id\n        FROM item\n        WHERE op_time < 1539672074878\n        AND platform_id = 1\n        limit 0,1000\n```\n\n### dump指定网卡3306端口的所有TCP请求\ntcpdump -i eth0 port 3306 -w /tmp/a.out\n\n### 将a.out导入到wireshark\n\n### \n点击`find a packet`，将`Display filter`修改成为`String`，将最前面的`Packet list`修改成`Packet bytes`，从而可以匹配TCP包内部的字符串。\n查看上面的SQL，发现可以用时间作为关键字来进行查询。\n\n### 列出所有stream\n但是从包stream上来看，TCP的3次握手就是从14:41:17开始的，所以排除了网络抖动的可能性，那分析下来就只能是`new InetSocketAddress(dbHostConfig.getIp()`非常慢，该语句就是用于DNS解析。\n\n","slug":"Linux-TCP-dump","published":1,"updated":"2019-09-28T08:51:00.885Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o83z003iv1npxwpfgs1i","content":"<h3 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a>问题描述</h3><p>在数据库中间件中，下面的SQL执行了3010ms，但是在MySQL中，没有看到慢日志。最终定位到<br><code>socket.connect(new InetSocketAddress(dbHostConfig.getIp(), dbHostConfig.getPort()), SOCKET_CONNECT_TIMEOUT);</code><br>这行语句执行了3秒左右。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT id</span><br><span class=\"line\">        FROM item</span><br><span class=\"line\">        WHERE op_time &lt; 1539672074878</span><br><span class=\"line\">        AND platform_id = 1</span><br><span class=\"line\">        limit 0,1000</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"dump指定网卡3306端口的所有TCP请求\"><a href=\"#dump指定网卡3306端口的所有TCP请求\" class=\"headerlink\" title=\"dump指定网卡3306端口的所有TCP请求\"></a>dump指定网卡3306端口的所有TCP请求</h3><p>tcpdump -i eth0 port 3306 -w /tmp/a.out</p>\n<h3 id=\"将a-out导入到wireshark\"><a href=\"#将a-out导入到wireshark\" class=\"headerlink\" title=\"将a.out导入到wireshark\"></a>将a.out导入到wireshark</h3><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>点击<code>find a packet</code>，将<code>Display filter</code>修改成为<code>String</code>，将最前面的<code>Packet list</code>修改成<code>Packet bytes</code>，从而可以匹配TCP包内部的字符串。<br>查看上面的SQL，发现可以用时间作为关键字来进行查询。</p>\n<h3 id=\"列出所有stream\"><a href=\"#列出所有stream\" class=\"headerlink\" title=\"列出所有stream\"></a>列出所有stream</h3><p>但是从包stream上来看，TCP的3次握手就是从14:41:17开始的，所以排除了网络抖动的可能性，那分析下来就只能是<code>new InetSocketAddress(dbHostConfig.getIp()</code>非常慢，该语句就是用于DNS解析。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a>问题描述</h3><p>在数据库中间件中，下面的SQL执行了3010ms，但是在MySQL中，没有看到慢日志。最终定位到<br><code>socket.connect(new InetSocketAddress(dbHostConfig.getIp(), dbHostConfig.getPort()), SOCKET_CONNECT_TIMEOUT);</code><br>这行语句执行了3秒左右。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT id</span><br><span class=\"line\">        FROM item</span><br><span class=\"line\">        WHERE op_time &lt; 1539672074878</span><br><span class=\"line\">        AND platform_id = 1</span><br><span class=\"line\">        limit 0,1000</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"dump指定网卡3306端口的所有TCP请求\"><a href=\"#dump指定网卡3306端口的所有TCP请求\" class=\"headerlink\" title=\"dump指定网卡3306端口的所有TCP请求\"></a>dump指定网卡3306端口的所有TCP请求</h3><p>tcpdump -i eth0 port 3306 -w /tmp/a.out</p>\n<h3 id=\"将a-out导入到wireshark\"><a href=\"#将a-out导入到wireshark\" class=\"headerlink\" title=\"将a.out导入到wireshark\"></a>将a.out导入到wireshark</h3><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>点击<code>find a packet</code>，将<code>Display filter</code>修改成为<code>String</code>，将最前面的<code>Packet list</code>修改成<code>Packet bytes</code>，从而可以匹配TCP包内部的字符串。<br>查看上面的SQL，发现可以用时间作为关键字来进行查询。</p>\n<h3 id=\"列出所有stream\"><a href=\"#列出所有stream\" class=\"headerlink\" title=\"列出所有stream\"></a>列出所有stream</h3><p>但是从包stream上来看，TCP的3次握手就是从14:41:17开始的，所以排除了网络抖动的可能性，那分析下来就只能是<code>new InetSocketAddress(dbHostConfig.getIp()</code>非常慢，该语句就是用于DNS解析。</p>\n"},{"title":"Linux-TCP","date":"2018-12-25T04:36:44.000Z","_content":"\n### TCP动画\nhttps://blog.csdn.net/bntX2jSQfEHy7/article/details/80837422","source":"_posts/Linux-TCP.md","raw":"---\ntitle: Linux-TCP\ndate: 2018-12-25 12:36:44\ntags:\n---\n\n### TCP动画\nhttps://blog.csdn.net/bntX2jSQfEHy7/article/details/80837422","slug":"Linux-TCP","published":1,"updated":"2019-09-28T08:51:00.906Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o840003jv1npn5485vqm","content":"<h3 id=\"TCP动画\"><a href=\"#TCP动画\" class=\"headerlink\" title=\"TCP动画\"></a>TCP动画</h3><p><a href=\"https://blog.csdn.net/bntX2jSQfEHy7/article/details/80837422\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/bntX2jSQfEHy7/article/details/80837422</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"TCP动画\"><a href=\"#TCP动画\" class=\"headerlink\" title=\"TCP动画\"></a>TCP动画</h3><p><a href=\"https://blog.csdn.net/bntX2jSQfEHy7/article/details/80837422\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/bntX2jSQfEHy7/article/details/80837422</a></p>\n"},{"title":"实用Linux命令整理","date":"2017-09-09T09:16:00.000Z","_content":"\n#### 文件内容替换\n\n``` bash\nsudo sed -i 's/aaa/bbb/g' `grep -Rl aaa order_migrate_conf/`\n```\n真实案例\n```\nsudo sed -i '/canal.instance.master.position/d' `grep -Rl cluster1611 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.position/d' `grep -Rl cluster1612 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.position/d' `grep -Rl cluster1613 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.position/d' `grep -Rl cluster1614 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.journal.name/d' `grep -Rl cluster1611 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.journal.name/d' `grep -Rl cluster1612 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.journal.name/d' `grep -Rl cluster1613 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.journal.name/d' `grep -Rl cluster1614 /opt/app/canal/conf/*`\n\nsudo sed -i 'N;8icanal.instance.master.journal.name = mysql-bin.000017' `grep -Rl cluster1611 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.journal.name = mysql-bin.000015' `grep -Rl cluster1612 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.journal.name = mysql-bin.000014' `grep -Rl cluster1613 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.journal.name = mysql-bin.000015' `grep -Rl cluster1614 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.position = 4' `grep -Rl cluster1611 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.position = 4' `grep -Rl cluster1612 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.position = 4' `grep -Rl cluster1613 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.position = 4' `grep -Rl cluster1614 /opt/app/canal/conf/*`\n```\n\n#### 查找目录下的所有文件中是否含有某个字符串,并且只打印出文件名\n\n``` bash\ngrep -Rl 1496628000000 order_migrate_conf/\n```\n\n#### 查看超大文件，vim 慎用\n\n``` bash\nless file.log\n```\n```\nsudo vim perf-payload-5.log \n# vim讲文件全部加载到pagecache中去了\n[jump@zerodb-agent009 app]$ sudo ./pcstat perf-payload-5.log \n|--------------------+----------------+------------+-----------+---------|\n| Name               | Size           | Pages      | Cached    | Percent |\n|--------------------+----------------+------------+-----------+---------|\n| perf-payload-5.log | 31792791       | 7762       | 7762      | 100.000 |\n|--------------------+----------------+------------+-----------+---------|\n```\n\n#### 超大文件从后往前查找关键词kind_pay\n\n``` bash\ntac file_path | grep kind_pay\n```\n\nless file_path, G(go to file end), /kind_pay + enter, N(search key word reversely)\n\n#### 分类查看各种状态的TCP连接\n\n``` bash\nss  -tan|awk 'NR>1{++S[$1]}END{for (a in S) print a,S[a]}'\n```\n\n#### 查看logs目录下所有文件夹及其内容的大小\n\n``` bash\ndu -sh logs/*\n```\n```\n$ du -sh Movies/* | sort -nr\n 28G\tMovies/Pan's.Labyrinth.潘神的迷宫.2006.1080p.BluRay.REMUX.MPEG-4.AVC.PCM-WARHD\n 19G\tMovies/The.Lord.Of.The.Rings.The.Return.Of.The.King.2003.1080p.BluRay.x264-SiNNERS\n 16G\tMovies/The.Lord.Of.The.Rings.The.Fellowship.Of.The.Ring.2001.1080p.BluRay.x264-SiNNERS\n 15G\tMovies/Interstellar.星际穿越.2014.1080p.BluRay.x264.DTS-RARBG\n 14G\tMovies/Witness.for.the.Prosecution.控方证人.1957.1080p.BluRay.x264.DTS-WiKi\n 14G\tMovies/Se7en.七宗罪.1995.REMASTERED.1080p.BluRay.x264.DTS-ES-FGT\n 14G\tMovies/In.Bruges.杀手没有假期.2008.1080p.BluRay.x264.DTS-FGT\n 13G\tMovies/Saving.Private.Ryan.拯救大兵瑞恩.1998.1080p.BluRay.x264-LEVERAGE\n 13G\tMovies/Braveheart.勇敢的心.1995.1080p.BluRay.x264-CiNEFiLE\n 12G\tMovies/The.Hunt.狩猎.2012.DANISH.1080p.BluRay.x264.DTS-FGT\n 12G\tMovies/The.Dark.Knight.Rises.蝙蝠侠.黑暗骑士崛起.2012.1080p.BluRay.x264-ALLiANCE\n 12G\tMovies/Life.of.Pi.少年派的奇幻漂流.2012.1080p.BluRay.x264.DTS-FGT\n 11G\tMovies/The.Lost.City.of.Z.迷失Z城.2016.1080p.BluRay.x264-GECKOS[rarbg]\n 11G\tMovies/Manhattan.Murder.Mystery.曼哈顿谋杀疑案.1993.1080p.BluRay.X264-AMIABLE[rarbg]\n 11G\tMovies/Like.Father.Like.Son.如父如子.2013.1080p.BluRay.DTS.x264-PublicHD\n```\n\n#### 将需要交互的命令的结果重定向到文件中\n\n``` bash\ntelnet zk_ip 2181 | tee -a  -i someFile\n\nenvi\n```\n\n#### 查看上下文切换\n\n``` bash\nnmon\n```\n\n#### 查看某个端口的应用程序PID\n``` bash\n$ lsof -i:9696\nCOMMAND    PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME\nkingshard 4994 eric   24u  IPv6 0x2dd5bc594d052b1f      0t0  TCP *:9696 (LISTEN)\n\n```\n\n#### 模拟网络抖动\nhttp://blog.csdn.net/weiweicao0429/article/details/17578011\n``` bash\n# tc qdisc add dev eth0 root netem delay 100ms\n# tc qdisc del dev eth0 root netem delay 100ms\n# tc qdisc del dev eth0 root\n```\n\n#### 进程死亡查询\nhttps://blog.csdn.net/green1893/article/details/78192017\n```\ndmesg | egrep -i -B100 'killed process'\n\n## 或:\negrep -i 'killed process' /var/log/messages\negrep -i -r 'killed process' /var/log\n\n## 或:\njournalctl -xb | egrep -i 'killed process'\n```\n\n#### 显示进程中线程\n```\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     ├─{zeroProxy.out}(25095)\n                     ├─{zeroProxy.out}(25120)\n                     ├─{zeroProxy.out}(25121)\n                     └─{zeroProxy.out}(25123)\n```\n\n#### 显示system call\n```\nstrace - trace system calls and signals\n\n$strace -f java -cp . ContextSwitchTest\nhttps://www.cnblogs.com/softidea/p/5873305.html\n```\n\n\n#### iostat 查询磁盘整体问题（比如iops）\nhttp://coolnull.com/4444.html\n```\n[root@binlog-msg001 zerokeeper]# iostat -x 1 10\nLinux 2.6.32-754.el6.x86_64 (binlog-msg001.dev.2dfire.info) \t08/02/2018 \t_x86_64_\t(1 CPU)\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           3.16    0.00    1.51    5.03    0.17   90.14\n\nDevice:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nscd0              0.00     0.00    0.00    0.00     0.01     0.00     7.00     0.00    0.35    0.35    0.00   0.35   0.00\nvda               4.11    10.08  137.57    1.97  2882.02    96.38    21.34     0.23    1.67    1.66    2.48   0.41   5.79\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           1.02    0.00    2.04   96.94    0.00    0.00\n\nDevice:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nscd0              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nvda              73.47     0.00   75.51    1.02 49616.33     8.16   648.43     6.91   94.92   96.19    1.00  13.33 102.04\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           1.03    0.00    1.03   97.94    0.00    0.00\n\nDevice:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nscd0              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nvda               2.06     0.00   94.85    0.00 50969.07     0.00   537.39     9.49   97.23   97.23    0.00  10.87 103.09\n```\n\n### iotop 查看那些进程(线程)正在读写磁盘。\n```\n\n```\n\n### ps -eo pid,lstart|grep 26251\n查看进程的启动时间\n\n### dstat -cldny 性能观察综合神器\n```\n[nanxing@zerodb-proxy003 ~]$ dstat -cldny\n----total-cpu-usage---- ---load-avg--- -dsk/total- -net/total- ---system--\nusr sys idl wai hiq siq| 1m   5m  15m | read  writ| recv  send| int   csw \n  8   2  89   0   0   1|2.91 1.00 0.95|5423B   94k|   0     0 |2065  2245 \n 71  17   3   0   0  10|2.91 1.00 0.95|   0     0 |  23M   23M|  56k 1746 \n 69  17   2   0   0  11|2.91 1.00 0.95|   0   716k|  23M   23M|  56k 1597 \n 70  17   3   0   0  10|3.00 1.05 0.97|   0    32k|  23M   23M|  55k 1848 \n 69  18   3   0   0  11|3.00 1.05 0.97|   0     0 |  23M   23M|  56k 1758 \n 71  17   2   0   0  11|3.00 1.05 0.97|   0     0 |  23M   23M|  56k 1509 \n 70  16   3   0   0  11|3.00 1.05 0.97|   0     0 |  23M   23M|  56k 1531 \n 71  16   2   0   0  11|3.00 1.05 0.97|   0    72k|  23M   23M|  57k 1403 \n 70  17   2   0   0  11|3.08 1.10 0.99|   0     0 |  23M   23M|  56k 1455 \n```\n\n### iftop\n```\n                               204Mb                          407Mb                           611Mb                          814Mb                     0.99Gb\n└──────────────────────────────┴──────────────────────────────┴───────────────────────────────┴──────────────────────────────┴───────────────────────────────\n10.12.1.62                                                       => 10.12.1.74                                                         103Mb   102Mb  96.3Mb\n                                                                 <=                                                                   37.6Mb  37.5Mb  35.2Mb\n10.12.1.62                                                       => 10.12.1.69                                                        10.4Mb  10.4Mb  9.77Mb\n                                                                 <=                                                                   25.8Mb  25.9Mb  24.3Mb\n10.12.1.62                                                       => 10.12.1.68                                                        10.3Mb  10.3Mb  9.71Mb\n                                                                 <=                                                                   25.5Mb  25.6Mb  24.1Mb\n10.12.1.62                                                       => 10.12.1.66                                                        10.4Mb  10.3Mb  9.69Mb\n                                                                 <=                                                                   25.8Mb  25.5Mb  24.0Mb\n10.12.1.62                                                       => 10.12.1.67                                                        10.3Mb  10.3Mb  9.68Mb\n                                                                 <=                                                                   25.6Mb  25.5Mb  24.0Mb\n10.12.1.62                                                       => 10.6.0.11                                                            0b   13.5Kb  8.42Kb\n                                                                 <=                                                                      0b    376b    235b\n10.12.1.62                                                       => 10.1.133.201                                                      3.44Kb  4.43Kb  5.10Kb\n                                                                 <=                                                                    832b    499b    546b\n10.12.1.62                                                       => 10.12.0.243                                                       1.69Kb   691b    648b\n                                                                 <=                                                                   1.14Kb   424b    410b\n10.12.1.62                                                       => 10.12.1.70                                                        2.23Kb   458b    572b\n                                                                 <=                                                                   2.23Kb   458b    572b\n10.12.1.62                                                       => 10.12.1.71                                                        2.23Kb   458b    572b\n                                                                 <=                                                                   2.23Kb   458b    572b\n10.12.1.62                                                       => 10.12.1.72                                                        2.23Kb   458b    572b\n                                                                 <=                                                                   2.23Kb   458b    572b\n10.12.1.62                                                       => 10.12.1.73                                                        2.23Kb   458b    572b\n                                                                 <=                                                                   2.23Kb   458b    572b\n10.12.1.62                                                       => 100.116.166.131                                                    240b    240b    240b\n                                                                 <=                                                                    656b    656b    656b\n10.12.1.62                                                       => 100.116.202.130                                                    240b    240b    240b\n                                                                 <=                                                                    656b    656b    656b\n10.12.1.62                                                       => 100.116.203.1                                                      240b    240b    240b\n                                                                 <=                                                                    656b    656b    656b\n10.12.1.62                                                       => 100.116.165.130                                                    240b    240b    210b\n                                                                 <=                                                                    656b    656b    574b\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\nTX:             cum:    270MB   peak:\t 145Mb                                                                               rates:    144Mb   144Mb   135Mb\nRX:                     263MB            141Mb                                                                                         140Mb   140Mb   132Mb\nTOTAL:                  533MB            287Mb                                                                                         284Mb   284Mb   267Mb\n\n```","source":"_posts/Linux-Useful-command.md","raw":"---\ntitle: 实用Linux命令整理\ndate: 2017-09-09 17:16:00\ntags: Linux\n---\n\n#### 文件内容替换\n\n``` bash\nsudo sed -i 's/aaa/bbb/g' `grep -Rl aaa order_migrate_conf/`\n```\n真实案例\n```\nsudo sed -i '/canal.instance.master.position/d' `grep -Rl cluster1611 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.position/d' `grep -Rl cluster1612 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.position/d' `grep -Rl cluster1613 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.position/d' `grep -Rl cluster1614 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.journal.name/d' `grep -Rl cluster1611 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.journal.name/d' `grep -Rl cluster1612 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.journal.name/d' `grep -Rl cluster1613 /opt/app/canal/conf/*`\nsudo sed -i '/canal.instance.master.journal.name/d' `grep -Rl cluster1614 /opt/app/canal/conf/*`\n\nsudo sed -i 'N;8icanal.instance.master.journal.name = mysql-bin.000017' `grep -Rl cluster1611 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.journal.name = mysql-bin.000015' `grep -Rl cluster1612 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.journal.name = mysql-bin.000014' `grep -Rl cluster1613 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.journal.name = mysql-bin.000015' `grep -Rl cluster1614 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.position = 4' `grep -Rl cluster1611 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.position = 4' `grep -Rl cluster1612 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.position = 4' `grep -Rl cluster1613 /opt/app/canal/conf/*`\nsudo sed -i 'N;8icanal.instance.master.position = 4' `grep -Rl cluster1614 /opt/app/canal/conf/*`\n```\n\n#### 查找目录下的所有文件中是否含有某个字符串,并且只打印出文件名\n\n``` bash\ngrep -Rl 1496628000000 order_migrate_conf/\n```\n\n#### 查看超大文件，vim 慎用\n\n``` bash\nless file.log\n```\n```\nsudo vim perf-payload-5.log \n# vim讲文件全部加载到pagecache中去了\n[jump@zerodb-agent009 app]$ sudo ./pcstat perf-payload-5.log \n|--------------------+----------------+------------+-----------+---------|\n| Name               | Size           | Pages      | Cached    | Percent |\n|--------------------+----------------+------------+-----------+---------|\n| perf-payload-5.log | 31792791       | 7762       | 7762      | 100.000 |\n|--------------------+----------------+------------+-----------+---------|\n```\n\n#### 超大文件从后往前查找关键词kind_pay\n\n``` bash\ntac file_path | grep kind_pay\n```\n\nless file_path, G(go to file end), /kind_pay + enter, N(search key word reversely)\n\n#### 分类查看各种状态的TCP连接\n\n``` bash\nss  -tan|awk 'NR>1{++S[$1]}END{for (a in S) print a,S[a]}'\n```\n\n#### 查看logs目录下所有文件夹及其内容的大小\n\n``` bash\ndu -sh logs/*\n```\n```\n$ du -sh Movies/* | sort -nr\n 28G\tMovies/Pan's.Labyrinth.潘神的迷宫.2006.1080p.BluRay.REMUX.MPEG-4.AVC.PCM-WARHD\n 19G\tMovies/The.Lord.Of.The.Rings.The.Return.Of.The.King.2003.1080p.BluRay.x264-SiNNERS\n 16G\tMovies/The.Lord.Of.The.Rings.The.Fellowship.Of.The.Ring.2001.1080p.BluRay.x264-SiNNERS\n 15G\tMovies/Interstellar.星际穿越.2014.1080p.BluRay.x264.DTS-RARBG\n 14G\tMovies/Witness.for.the.Prosecution.控方证人.1957.1080p.BluRay.x264.DTS-WiKi\n 14G\tMovies/Se7en.七宗罪.1995.REMASTERED.1080p.BluRay.x264.DTS-ES-FGT\n 14G\tMovies/In.Bruges.杀手没有假期.2008.1080p.BluRay.x264.DTS-FGT\n 13G\tMovies/Saving.Private.Ryan.拯救大兵瑞恩.1998.1080p.BluRay.x264-LEVERAGE\n 13G\tMovies/Braveheart.勇敢的心.1995.1080p.BluRay.x264-CiNEFiLE\n 12G\tMovies/The.Hunt.狩猎.2012.DANISH.1080p.BluRay.x264.DTS-FGT\n 12G\tMovies/The.Dark.Knight.Rises.蝙蝠侠.黑暗骑士崛起.2012.1080p.BluRay.x264-ALLiANCE\n 12G\tMovies/Life.of.Pi.少年派的奇幻漂流.2012.1080p.BluRay.x264.DTS-FGT\n 11G\tMovies/The.Lost.City.of.Z.迷失Z城.2016.1080p.BluRay.x264-GECKOS[rarbg]\n 11G\tMovies/Manhattan.Murder.Mystery.曼哈顿谋杀疑案.1993.1080p.BluRay.X264-AMIABLE[rarbg]\n 11G\tMovies/Like.Father.Like.Son.如父如子.2013.1080p.BluRay.DTS.x264-PublicHD\n```\n\n#### 将需要交互的命令的结果重定向到文件中\n\n``` bash\ntelnet zk_ip 2181 | tee -a  -i someFile\n\nenvi\n```\n\n#### 查看上下文切换\n\n``` bash\nnmon\n```\n\n#### 查看某个端口的应用程序PID\n``` bash\n$ lsof -i:9696\nCOMMAND    PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME\nkingshard 4994 eric   24u  IPv6 0x2dd5bc594d052b1f      0t0  TCP *:9696 (LISTEN)\n\n```\n\n#### 模拟网络抖动\nhttp://blog.csdn.net/weiweicao0429/article/details/17578011\n``` bash\n# tc qdisc add dev eth0 root netem delay 100ms\n# tc qdisc del dev eth0 root netem delay 100ms\n# tc qdisc del dev eth0 root\n```\n\n#### 进程死亡查询\nhttps://blog.csdn.net/green1893/article/details/78192017\n```\ndmesg | egrep -i -B100 'killed process'\n\n## 或:\negrep -i 'killed process' /var/log/messages\negrep -i -r 'killed process' /var/log\n\n## 或:\njournalctl -xb | egrep -i 'killed process'\n```\n\n#### 显示进程中线程\n```\n[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086\nzeroProxy.out(25086)─┬─{zeroProxy.out}(25087)\n                     ├─{zeroProxy.out}(25088)\n                     ├─{zeroProxy.out}(25089)\n                     ├─{zeroProxy.out}(25090)\n                     ├─{zeroProxy.out}(25091)\n                     ├─{zeroProxy.out}(25092)\n                     ├─{zeroProxy.out}(25093)\n                     ├─{zeroProxy.out}(25094)\n                     ├─{zeroProxy.out}(25095)\n                     ├─{zeroProxy.out}(25120)\n                     ├─{zeroProxy.out}(25121)\n                     └─{zeroProxy.out}(25123)\n```\n\n#### 显示system call\n```\nstrace - trace system calls and signals\n\n$strace -f java -cp . ContextSwitchTest\nhttps://www.cnblogs.com/softidea/p/5873305.html\n```\n\n\n#### iostat 查询磁盘整体问题（比如iops）\nhttp://coolnull.com/4444.html\n```\n[root@binlog-msg001 zerokeeper]# iostat -x 1 10\nLinux 2.6.32-754.el6.x86_64 (binlog-msg001.dev.2dfire.info) \t08/02/2018 \t_x86_64_\t(1 CPU)\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           3.16    0.00    1.51    5.03    0.17   90.14\n\nDevice:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nscd0              0.00     0.00    0.00    0.00     0.01     0.00     7.00     0.00    0.35    0.35    0.00   0.35   0.00\nvda               4.11    10.08  137.57    1.97  2882.02    96.38    21.34     0.23    1.67    1.66    2.48   0.41   5.79\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           1.02    0.00    2.04   96.94    0.00    0.00\n\nDevice:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nscd0              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nvda              73.47     0.00   75.51    1.02 49616.33     8.16   648.43     6.91   94.92   96.19    1.00  13.33 102.04\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           1.03    0.00    1.03   97.94    0.00    0.00\n\nDevice:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nscd0              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nvda               2.06     0.00   94.85    0.00 50969.07     0.00   537.39     9.49   97.23   97.23    0.00  10.87 103.09\n```\n\n### iotop 查看那些进程(线程)正在读写磁盘。\n```\n\n```\n\n### ps -eo pid,lstart|grep 26251\n查看进程的启动时间\n\n### dstat -cldny 性能观察综合神器\n```\n[nanxing@zerodb-proxy003 ~]$ dstat -cldny\n----total-cpu-usage---- ---load-avg--- -dsk/total- -net/total- ---system--\nusr sys idl wai hiq siq| 1m   5m  15m | read  writ| recv  send| int   csw \n  8   2  89   0   0   1|2.91 1.00 0.95|5423B   94k|   0     0 |2065  2245 \n 71  17   3   0   0  10|2.91 1.00 0.95|   0     0 |  23M   23M|  56k 1746 \n 69  17   2   0   0  11|2.91 1.00 0.95|   0   716k|  23M   23M|  56k 1597 \n 70  17   3   0   0  10|3.00 1.05 0.97|   0    32k|  23M   23M|  55k 1848 \n 69  18   3   0   0  11|3.00 1.05 0.97|   0     0 |  23M   23M|  56k 1758 \n 71  17   2   0   0  11|3.00 1.05 0.97|   0     0 |  23M   23M|  56k 1509 \n 70  16   3   0   0  11|3.00 1.05 0.97|   0     0 |  23M   23M|  56k 1531 \n 71  16   2   0   0  11|3.00 1.05 0.97|   0    72k|  23M   23M|  57k 1403 \n 70  17   2   0   0  11|3.08 1.10 0.99|   0     0 |  23M   23M|  56k 1455 \n```\n\n### iftop\n```\n                               204Mb                          407Mb                           611Mb                          814Mb                     0.99Gb\n└──────────────────────────────┴──────────────────────────────┴───────────────────────────────┴──────────────────────────────┴───────────────────────────────\n10.12.1.62                                                       => 10.12.1.74                                                         103Mb   102Mb  96.3Mb\n                                                                 <=                                                                   37.6Mb  37.5Mb  35.2Mb\n10.12.1.62                                                       => 10.12.1.69                                                        10.4Mb  10.4Mb  9.77Mb\n                                                                 <=                                                                   25.8Mb  25.9Mb  24.3Mb\n10.12.1.62                                                       => 10.12.1.68                                                        10.3Mb  10.3Mb  9.71Mb\n                                                                 <=                                                                   25.5Mb  25.6Mb  24.1Mb\n10.12.1.62                                                       => 10.12.1.66                                                        10.4Mb  10.3Mb  9.69Mb\n                                                                 <=                                                                   25.8Mb  25.5Mb  24.0Mb\n10.12.1.62                                                       => 10.12.1.67                                                        10.3Mb  10.3Mb  9.68Mb\n                                                                 <=                                                                   25.6Mb  25.5Mb  24.0Mb\n10.12.1.62                                                       => 10.6.0.11                                                            0b   13.5Kb  8.42Kb\n                                                                 <=                                                                      0b    376b    235b\n10.12.1.62                                                       => 10.1.133.201                                                      3.44Kb  4.43Kb  5.10Kb\n                                                                 <=                                                                    832b    499b    546b\n10.12.1.62                                                       => 10.12.0.243                                                       1.69Kb   691b    648b\n                                                                 <=                                                                   1.14Kb   424b    410b\n10.12.1.62                                                       => 10.12.1.70                                                        2.23Kb   458b    572b\n                                                                 <=                                                                   2.23Kb   458b    572b\n10.12.1.62                                                       => 10.12.1.71                                                        2.23Kb   458b    572b\n                                                                 <=                                                                   2.23Kb   458b    572b\n10.12.1.62                                                       => 10.12.1.72                                                        2.23Kb   458b    572b\n                                                                 <=                                                                   2.23Kb   458b    572b\n10.12.1.62                                                       => 10.12.1.73                                                        2.23Kb   458b    572b\n                                                                 <=                                                                   2.23Kb   458b    572b\n10.12.1.62                                                       => 100.116.166.131                                                    240b    240b    240b\n                                                                 <=                                                                    656b    656b    656b\n10.12.1.62                                                       => 100.116.202.130                                                    240b    240b    240b\n                                                                 <=                                                                    656b    656b    656b\n10.12.1.62                                                       => 100.116.203.1                                                      240b    240b    240b\n                                                                 <=                                                                    656b    656b    656b\n10.12.1.62                                                       => 100.116.165.130                                                    240b    240b    210b\n                                                                 <=                                                                    656b    656b    574b\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\nTX:             cum:    270MB   peak:\t 145Mb                                                                               rates:    144Mb   144Mb   135Mb\nRX:                     263MB            141Mb                                                                                         140Mb   140Mb   132Mb\nTOTAL:                  533MB            287Mb                                                                                         284Mb   284Mb   267Mb\n\n```","slug":"Linux-Useful-command","published":1,"updated":"2019-09-28T08:51:00.907Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o840003kv1npbomyd7o2","content":"<h4 id=\"文件内容替换\"><a href=\"#文件内容替换\" class=\"headerlink\" title=\"文件内容替换\"></a>文件内容替换</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sed -i <span class=\"string\">'s/aaa/bbb/g'</span> `grep -Rl aaa order_migrate_conf/`</span><br></pre></td></tr></table></figure>\n\n<p>真实案例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sed -i &apos;/canal.instance.master.position/d&apos; `grep -Rl cluster1611 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.position/d&apos; `grep -Rl cluster1612 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.position/d&apos; `grep -Rl cluster1613 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.position/d&apos; `grep -Rl cluster1614 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.journal.name/d&apos; `grep -Rl cluster1611 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.journal.name/d&apos; `grep -Rl cluster1612 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.journal.name/d&apos; `grep -Rl cluster1613 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.journal.name/d&apos; `grep -Rl cluster1614 /opt/app/canal/conf/*`</span><br><span class=\"line\"></span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.journal.name = mysql-bin.000017&apos; `grep -Rl cluster1611 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.journal.name = mysql-bin.000015&apos; `grep -Rl cluster1612 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.journal.name = mysql-bin.000014&apos; `grep -Rl cluster1613 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.journal.name = mysql-bin.000015&apos; `grep -Rl cluster1614 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.position = 4&apos; `grep -Rl cluster1611 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.position = 4&apos; `grep -Rl cluster1612 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.position = 4&apos; `grep -Rl cluster1613 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.position = 4&apos; `grep -Rl cluster1614 /opt/app/canal/conf/*`</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"查找目录下的所有文件中是否含有某个字符串-并且只打印出文件名\"><a href=\"#查找目录下的所有文件中是否含有某个字符串-并且只打印出文件名\" class=\"headerlink\" title=\"查找目录下的所有文件中是否含有某个字符串,并且只打印出文件名\"></a>查找目录下的所有文件中是否含有某个字符串,并且只打印出文件名</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grep -Rl 1496628000000 order_migrate_conf/</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"查看超大文件，vim-慎用\"><a href=\"#查看超大文件，vim-慎用\" class=\"headerlink\" title=\"查看超大文件，vim 慎用\"></a>查看超大文件，vim 慎用</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">less file.log</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo vim perf-payload-5.log </span><br><span class=\"line\"># vim讲文件全部加载到pagecache中去了</span><br><span class=\"line\">[jump@zerodb-agent009 app]$ sudo ./pcstat perf-payload-5.log </span><br><span class=\"line\">|--------------------+----------------+------------+-----------+---------|</span><br><span class=\"line\">| Name               | Size           | Pages      | Cached    | Percent |</span><br><span class=\"line\">|--------------------+----------------+------------+-----------+---------|</span><br><span class=\"line\">| perf-payload-5.log | 31792791       | 7762       | 7762      | 100.000 |</span><br><span class=\"line\">|--------------------+----------------+------------+-----------+---------|</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"超大文件从后往前查找关键词kind-pay\"><a href=\"#超大文件从后往前查找关键词kind-pay\" class=\"headerlink\" title=\"超大文件从后往前查找关键词kind_pay\"></a>超大文件从后往前查找关键词kind_pay</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tac file_path | grep kind_pay</span><br></pre></td></tr></table></figure>\n\n<p>less file_path, G(go to file end), /kind_pay + enter, N(search key word reversely)</p>\n<h4 id=\"分类查看各种状态的TCP连接\"><a href=\"#分类查看各种状态的TCP连接\" class=\"headerlink\" title=\"分类查看各种状态的TCP连接\"></a>分类查看各种状态的TCP连接</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ss  -tan|awk <span class=\"string\">'NR&gt;1&#123;++S[$1]&#125;END&#123;for (a in S) print a,S[a]&#125;'</span></span><br></pre></td></tr></table></figure>\n\n<h4 id=\"查看logs目录下所有文件夹及其内容的大小\"><a href=\"#查看logs目录下所有文件夹及其内容的大小\" class=\"headerlink\" title=\"查看logs目录下所有文件夹及其内容的大小\"></a>查看logs目录下所有文件夹及其内容的大小</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">du -sh logs/*</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ du -sh Movies/* | sort -nr</span><br><span class=\"line\"> 28G\tMovies/Pan&apos;s.Labyrinth.潘神的迷宫.2006.1080p.BluRay.REMUX.MPEG-4.AVC.PCM-WARHD</span><br><span class=\"line\"> 19G\tMovies/The.Lord.Of.The.Rings.The.Return.Of.The.King.2003.1080p.BluRay.x264-SiNNERS</span><br><span class=\"line\"> 16G\tMovies/The.Lord.Of.The.Rings.The.Fellowship.Of.The.Ring.2001.1080p.BluRay.x264-SiNNERS</span><br><span class=\"line\"> 15G\tMovies/Interstellar.星际穿越.2014.1080p.BluRay.x264.DTS-RARBG</span><br><span class=\"line\"> 14G\tMovies/Witness.for.the.Prosecution.控方证人.1957.1080p.BluRay.x264.DTS-WiKi</span><br><span class=\"line\"> 14G\tMovies/Se7en.七宗罪.1995.REMASTERED.1080p.BluRay.x264.DTS-ES-FGT</span><br><span class=\"line\"> 14G\tMovies/In.Bruges.杀手没有假期.2008.1080p.BluRay.x264.DTS-FGT</span><br><span class=\"line\"> 13G\tMovies/Saving.Private.Ryan.拯救大兵瑞恩.1998.1080p.BluRay.x264-LEVERAGE</span><br><span class=\"line\"> 13G\tMovies/Braveheart.勇敢的心.1995.1080p.BluRay.x264-CiNEFiLE</span><br><span class=\"line\"> 12G\tMovies/The.Hunt.狩猎.2012.DANISH.1080p.BluRay.x264.DTS-FGT</span><br><span class=\"line\"> 12G\tMovies/The.Dark.Knight.Rises.蝙蝠侠.黑暗骑士崛起.2012.1080p.BluRay.x264-ALLiANCE</span><br><span class=\"line\"> 12G\tMovies/Life.of.Pi.少年派的奇幻漂流.2012.1080p.BluRay.x264.DTS-FGT</span><br><span class=\"line\"> 11G\tMovies/The.Lost.City.of.Z.迷失Z城.2016.1080p.BluRay.x264-GECKOS[rarbg]</span><br><span class=\"line\"> 11G\tMovies/Manhattan.Murder.Mystery.曼哈顿谋杀疑案.1993.1080p.BluRay.X264-AMIABLE[rarbg]</span><br><span class=\"line\"> 11G\tMovies/Like.Father.Like.Son.如父如子.2013.1080p.BluRay.DTS.x264-PublicHD</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"将需要交互的命令的结果重定向到文件中\"><a href=\"#将需要交互的命令的结果重定向到文件中\" class=\"headerlink\" title=\"将需要交互的命令的结果重定向到文件中\"></a>将需要交互的命令的结果重定向到文件中</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">telnet zk_ip 2181 | tee -a  -i someFile</span><br><span class=\"line\"></span><br><span class=\"line\">envi</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"查看上下文切换\"><a href=\"#查看上下文切换\" class=\"headerlink\" title=\"查看上下文切换\"></a>查看上下文切换</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nmon</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"查看某个端口的应用程序PID\"><a href=\"#查看某个端口的应用程序PID\" class=\"headerlink\" title=\"查看某个端口的应用程序PID\"></a>查看某个端口的应用程序PID</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ lsof -i:9696</span><br><span class=\"line\">COMMAND    PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME</span><br><span class=\"line\">kingshard 4994 eric   24u  IPv6 0x2dd5bc594d052b1f      0t0  TCP *:9696 (LISTEN)</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"模拟网络抖动\"><a href=\"#模拟网络抖动\" class=\"headerlink\" title=\"模拟网络抖动\"></a>模拟网络抖动</h4><p><a href=\"http://blog.csdn.net/weiweicao0429/article/details/17578011\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/weiweicao0429/article/details/17578011</a></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># tc qdisc add dev eth0 root netem delay 100ms</span></span><br><span class=\"line\"><span class=\"comment\"># tc qdisc del dev eth0 root netem delay 100ms</span></span><br><span class=\"line\"><span class=\"comment\"># tc qdisc del dev eth0 root</span></span><br></pre></td></tr></table></figure>\n\n<h4 id=\"进程死亡查询\"><a href=\"#进程死亡查询\" class=\"headerlink\" title=\"进程死亡查询\"></a>进程死亡查询</h4><p><a href=\"https://blog.csdn.net/green1893/article/details/78192017\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/green1893/article/details/78192017</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dmesg | egrep -i -B100 &apos;killed process&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">## 或:</span><br><span class=\"line\">egrep -i &apos;killed process&apos; /var/log/messages</span><br><span class=\"line\">egrep -i -r &apos;killed process&apos; /var/log</span><br><span class=\"line\"></span><br><span class=\"line\">## 或:</span><br><span class=\"line\">journalctl -xb | egrep -i &apos;killed process&apos;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"显示进程中线程\"><a href=\"#显示进程中线程\" class=\"headerlink\" title=\"显示进程中线程\"></a>显示进程中线程</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25120)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25121)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25123)</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"显示system-call\"><a href=\"#显示system-call\" class=\"headerlink\" title=\"显示system call\"></a>显示system call</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">strace - trace system calls and signals</span><br><span class=\"line\"></span><br><span class=\"line\">$strace -f java -cp . ContextSwitchTest</span><br><span class=\"line\">https://www.cnblogs.com/softidea/p/5873305.html</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"iostat-查询磁盘整体问题（比如iops）\"><a href=\"#iostat-查询磁盘整体问题（比如iops）\" class=\"headerlink\" title=\"iostat 查询磁盘整体问题（比如iops）\"></a>iostat 查询磁盘整体问题（比如iops）</h4><p><a href=\"http://coolnull.com/4444.html\" target=\"_blank\" rel=\"noopener\">http://coolnull.com/4444.html</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@binlog-msg001 zerokeeper]# iostat -x 1 10</span><br><span class=\"line\">Linux 2.6.32-754.el6.x86_64 (binlog-msg001.dev.2dfire.info) \t08/02/2018 \t_x86_64_\t(1 CPU)</span><br><span class=\"line\"></span><br><span class=\"line\">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class=\"line\">           3.16    0.00    1.51    5.03    0.17   90.14</span><br><span class=\"line\"></span><br><span class=\"line\">Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class=\"line\">scd0              0.00     0.00    0.00    0.00     0.01     0.00     7.00     0.00    0.35    0.35    0.00   0.35   0.00</span><br><span class=\"line\">vda               4.11    10.08  137.57    1.97  2882.02    96.38    21.34     0.23    1.67    1.66    2.48   0.41   5.79</span><br><span class=\"line\"></span><br><span class=\"line\">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class=\"line\">           1.02    0.00    2.04   96.94    0.00    0.00</span><br><span class=\"line\"></span><br><span class=\"line\">Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class=\"line\">scd0              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class=\"line\">vda              73.47     0.00   75.51    1.02 49616.33     8.16   648.43     6.91   94.92   96.19    1.00  13.33 102.04</span><br><span class=\"line\"></span><br><span class=\"line\">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class=\"line\">           1.03    0.00    1.03   97.94    0.00    0.00</span><br><span class=\"line\"></span><br><span class=\"line\">Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class=\"line\">scd0              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class=\"line\">vda               2.06     0.00   94.85    0.00 50969.07     0.00   537.39     9.49   97.23   97.23    0.00  10.87 103.09</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"iotop-查看那些进程-线程-正在读写磁盘。\"><a href=\"#iotop-查看那些进程-线程-正在读写磁盘。\" class=\"headerlink\" title=\"iotop 查看那些进程(线程)正在读写磁盘。\"></a>iotop 查看那些进程(线程)正在读写磁盘。</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"ps-eo-pid-lstart-grep-26251\"><a href=\"#ps-eo-pid-lstart-grep-26251\" class=\"headerlink\" title=\"ps -eo pid,lstart|grep 26251\"></a>ps -eo pid,lstart|grep 26251</h3><p>查看进程的启动时间</p>\n<h3 id=\"dstat-cldny-性能观察综合神器\"><a href=\"#dstat-cldny-性能观察综合神器\" class=\"headerlink\" title=\"dstat -cldny 性能观察综合神器\"></a>dstat -cldny 性能观察综合神器</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[nanxing@zerodb-proxy003 ~]$ dstat -cldny</span><br><span class=\"line\">----total-cpu-usage---- ---load-avg--- -dsk/total- -net/total- ---system--</span><br><span class=\"line\">usr sys idl wai hiq siq| 1m   5m  15m | read  writ| recv  send| int   csw </span><br><span class=\"line\">  8   2  89   0   0   1|2.91 1.00 0.95|5423B   94k|   0     0 |2065  2245 </span><br><span class=\"line\"> 71  17   3   0   0  10|2.91 1.00 0.95|   0     0 |  23M   23M|  56k 1746 </span><br><span class=\"line\"> 69  17   2   0   0  11|2.91 1.00 0.95|   0   716k|  23M   23M|  56k 1597 </span><br><span class=\"line\"> 70  17   3   0   0  10|3.00 1.05 0.97|   0    32k|  23M   23M|  55k 1848 </span><br><span class=\"line\"> 69  18   3   0   0  11|3.00 1.05 0.97|   0     0 |  23M   23M|  56k 1758 </span><br><span class=\"line\"> 71  17   2   0   0  11|3.00 1.05 0.97|   0     0 |  23M   23M|  56k 1509 </span><br><span class=\"line\"> 70  16   3   0   0  11|3.00 1.05 0.97|   0     0 |  23M   23M|  56k 1531 </span><br><span class=\"line\"> 71  16   2   0   0  11|3.00 1.05 0.97|   0    72k|  23M   23M|  57k 1403 </span><br><span class=\"line\"> 70  17   2   0   0  11|3.08 1.10 0.99|   0     0 |  23M   23M|  56k 1455</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"iftop\"><a href=\"#iftop\" class=\"headerlink\" title=\"iftop\"></a>iftop</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">                               204Mb                          407Mb                           611Mb                          814Mb                     0.99Gb</span><br><span class=\"line\">└──────────────────────────────┴──────────────────────────────┴───────────────────────────────┴──────────────────────────────┴───────────────────────────────</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.74                                                         103Mb   102Mb  96.3Mb</span><br><span class=\"line\">                                                                 &lt;=                                                                   37.6Mb  37.5Mb  35.2Mb</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.69                                                        10.4Mb  10.4Mb  9.77Mb</span><br><span class=\"line\">                                                                 &lt;=                                                                   25.8Mb  25.9Mb  24.3Mb</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.68                                                        10.3Mb  10.3Mb  9.71Mb</span><br><span class=\"line\">                                                                 &lt;=                                                                   25.5Mb  25.6Mb  24.1Mb</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.66                                                        10.4Mb  10.3Mb  9.69Mb</span><br><span class=\"line\">                                                                 &lt;=                                                                   25.8Mb  25.5Mb  24.0Mb</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.67                                                        10.3Mb  10.3Mb  9.68Mb</span><br><span class=\"line\">                                                                 &lt;=                                                                   25.6Mb  25.5Mb  24.0Mb</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.6.0.11                                                            0b   13.5Kb  8.42Kb</span><br><span class=\"line\">                                                                 &lt;=                                                                      0b    376b    235b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.1.133.201                                                      3.44Kb  4.43Kb  5.10Kb</span><br><span class=\"line\">                                                                 &lt;=                                                                    832b    499b    546b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.0.243                                                       1.69Kb   691b    648b</span><br><span class=\"line\">                                                                 &lt;=                                                                   1.14Kb   424b    410b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.70                                                        2.23Kb   458b    572b</span><br><span class=\"line\">                                                                 &lt;=                                                                   2.23Kb   458b    572b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.71                                                        2.23Kb   458b    572b</span><br><span class=\"line\">                                                                 &lt;=                                                                   2.23Kb   458b    572b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.72                                                        2.23Kb   458b    572b</span><br><span class=\"line\">                                                                 &lt;=                                                                   2.23Kb   458b    572b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.73                                                        2.23Kb   458b    572b</span><br><span class=\"line\">                                                                 &lt;=                                                                   2.23Kb   458b    572b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 100.116.166.131                                                    240b    240b    240b</span><br><span class=\"line\">                                                                 &lt;=                                                                    656b    656b    656b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 100.116.202.130                                                    240b    240b    240b</span><br><span class=\"line\">                                                                 &lt;=                                                                    656b    656b    656b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 100.116.203.1                                                      240b    240b    240b</span><br><span class=\"line\">                                                                 &lt;=                                                                    656b    656b    656b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 100.116.165.130                                                    240b    240b    210b</span><br><span class=\"line\">                                                                 &lt;=                                                                    656b    656b    574b</span><br><span class=\"line\">─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span><br><span class=\"line\">TX:             cum:    270MB   peak:\t 145Mb                                                                               rates:    144Mb   144Mb   135Mb</span><br><span class=\"line\">RX:                     263MB            141Mb                                                                                         140Mb   140Mb   132Mb</span><br><span class=\"line\">TOTAL:                  533MB            287Mb                                                                                         284Mb   284Mb   267Mb</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h4 id=\"文件内容替换\"><a href=\"#文件内容替换\" class=\"headerlink\" title=\"文件内容替换\"></a>文件内容替换</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sed -i <span class=\"string\">'s/aaa/bbb/g'</span> `grep -Rl aaa order_migrate_conf/`</span><br></pre></td></tr></table></figure>\n\n<p>真实案例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sed -i &apos;/canal.instance.master.position/d&apos; `grep -Rl cluster1611 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.position/d&apos; `grep -Rl cluster1612 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.position/d&apos; `grep -Rl cluster1613 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.position/d&apos; `grep -Rl cluster1614 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.journal.name/d&apos; `grep -Rl cluster1611 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.journal.name/d&apos; `grep -Rl cluster1612 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.journal.name/d&apos; `grep -Rl cluster1613 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;/canal.instance.master.journal.name/d&apos; `grep -Rl cluster1614 /opt/app/canal/conf/*`</span><br><span class=\"line\"></span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.journal.name = mysql-bin.000017&apos; `grep -Rl cluster1611 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.journal.name = mysql-bin.000015&apos; `grep -Rl cluster1612 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.journal.name = mysql-bin.000014&apos; `grep -Rl cluster1613 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.journal.name = mysql-bin.000015&apos; `grep -Rl cluster1614 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.position = 4&apos; `grep -Rl cluster1611 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.position = 4&apos; `grep -Rl cluster1612 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.position = 4&apos; `grep -Rl cluster1613 /opt/app/canal/conf/*`</span><br><span class=\"line\">sudo sed -i &apos;N;8icanal.instance.master.position = 4&apos; `grep -Rl cluster1614 /opt/app/canal/conf/*`</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"查找目录下的所有文件中是否含有某个字符串-并且只打印出文件名\"><a href=\"#查找目录下的所有文件中是否含有某个字符串-并且只打印出文件名\" class=\"headerlink\" title=\"查找目录下的所有文件中是否含有某个字符串,并且只打印出文件名\"></a>查找目录下的所有文件中是否含有某个字符串,并且只打印出文件名</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grep -Rl 1496628000000 order_migrate_conf/</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"查看超大文件，vim-慎用\"><a href=\"#查看超大文件，vim-慎用\" class=\"headerlink\" title=\"查看超大文件，vim 慎用\"></a>查看超大文件，vim 慎用</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">less file.log</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo vim perf-payload-5.log </span><br><span class=\"line\"># vim讲文件全部加载到pagecache中去了</span><br><span class=\"line\">[jump@zerodb-agent009 app]$ sudo ./pcstat perf-payload-5.log </span><br><span class=\"line\">|--------------------+----------------+------------+-----------+---------|</span><br><span class=\"line\">| Name               | Size           | Pages      | Cached    | Percent |</span><br><span class=\"line\">|--------------------+----------------+------------+-----------+---------|</span><br><span class=\"line\">| perf-payload-5.log | 31792791       | 7762       | 7762      | 100.000 |</span><br><span class=\"line\">|--------------------+----------------+------------+-----------+---------|</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"超大文件从后往前查找关键词kind-pay\"><a href=\"#超大文件从后往前查找关键词kind-pay\" class=\"headerlink\" title=\"超大文件从后往前查找关键词kind_pay\"></a>超大文件从后往前查找关键词kind_pay</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tac file_path | grep kind_pay</span><br></pre></td></tr></table></figure>\n\n<p>less file_path, G(go to file end), /kind_pay + enter, N(search key word reversely)</p>\n<h4 id=\"分类查看各种状态的TCP连接\"><a href=\"#分类查看各种状态的TCP连接\" class=\"headerlink\" title=\"分类查看各种状态的TCP连接\"></a>分类查看各种状态的TCP连接</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ss  -tan|awk <span class=\"string\">'NR&gt;1&#123;++S[$1]&#125;END&#123;for (a in S) print a,S[a]&#125;'</span></span><br></pre></td></tr></table></figure>\n\n<h4 id=\"查看logs目录下所有文件夹及其内容的大小\"><a href=\"#查看logs目录下所有文件夹及其内容的大小\" class=\"headerlink\" title=\"查看logs目录下所有文件夹及其内容的大小\"></a>查看logs目录下所有文件夹及其内容的大小</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">du -sh logs/*</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ du -sh Movies/* | sort -nr</span><br><span class=\"line\"> 28G\tMovies/Pan&apos;s.Labyrinth.潘神的迷宫.2006.1080p.BluRay.REMUX.MPEG-4.AVC.PCM-WARHD</span><br><span class=\"line\"> 19G\tMovies/The.Lord.Of.The.Rings.The.Return.Of.The.King.2003.1080p.BluRay.x264-SiNNERS</span><br><span class=\"line\"> 16G\tMovies/The.Lord.Of.The.Rings.The.Fellowship.Of.The.Ring.2001.1080p.BluRay.x264-SiNNERS</span><br><span class=\"line\"> 15G\tMovies/Interstellar.星际穿越.2014.1080p.BluRay.x264.DTS-RARBG</span><br><span class=\"line\"> 14G\tMovies/Witness.for.the.Prosecution.控方证人.1957.1080p.BluRay.x264.DTS-WiKi</span><br><span class=\"line\"> 14G\tMovies/Se7en.七宗罪.1995.REMASTERED.1080p.BluRay.x264.DTS-ES-FGT</span><br><span class=\"line\"> 14G\tMovies/In.Bruges.杀手没有假期.2008.1080p.BluRay.x264.DTS-FGT</span><br><span class=\"line\"> 13G\tMovies/Saving.Private.Ryan.拯救大兵瑞恩.1998.1080p.BluRay.x264-LEVERAGE</span><br><span class=\"line\"> 13G\tMovies/Braveheart.勇敢的心.1995.1080p.BluRay.x264-CiNEFiLE</span><br><span class=\"line\"> 12G\tMovies/The.Hunt.狩猎.2012.DANISH.1080p.BluRay.x264.DTS-FGT</span><br><span class=\"line\"> 12G\tMovies/The.Dark.Knight.Rises.蝙蝠侠.黑暗骑士崛起.2012.1080p.BluRay.x264-ALLiANCE</span><br><span class=\"line\"> 12G\tMovies/Life.of.Pi.少年派的奇幻漂流.2012.1080p.BluRay.x264.DTS-FGT</span><br><span class=\"line\"> 11G\tMovies/The.Lost.City.of.Z.迷失Z城.2016.1080p.BluRay.x264-GECKOS[rarbg]</span><br><span class=\"line\"> 11G\tMovies/Manhattan.Murder.Mystery.曼哈顿谋杀疑案.1993.1080p.BluRay.X264-AMIABLE[rarbg]</span><br><span class=\"line\"> 11G\tMovies/Like.Father.Like.Son.如父如子.2013.1080p.BluRay.DTS.x264-PublicHD</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"将需要交互的命令的结果重定向到文件中\"><a href=\"#将需要交互的命令的结果重定向到文件中\" class=\"headerlink\" title=\"将需要交互的命令的结果重定向到文件中\"></a>将需要交互的命令的结果重定向到文件中</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">telnet zk_ip 2181 | tee -a  -i someFile</span><br><span class=\"line\"></span><br><span class=\"line\">envi</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"查看上下文切换\"><a href=\"#查看上下文切换\" class=\"headerlink\" title=\"查看上下文切换\"></a>查看上下文切换</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nmon</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"查看某个端口的应用程序PID\"><a href=\"#查看某个端口的应用程序PID\" class=\"headerlink\" title=\"查看某个端口的应用程序PID\"></a>查看某个端口的应用程序PID</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ lsof -i:9696</span><br><span class=\"line\">COMMAND    PID USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME</span><br><span class=\"line\">kingshard 4994 eric   24u  IPv6 0x2dd5bc594d052b1f      0t0  TCP *:9696 (LISTEN)</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"模拟网络抖动\"><a href=\"#模拟网络抖动\" class=\"headerlink\" title=\"模拟网络抖动\"></a>模拟网络抖动</h4><p><a href=\"http://blog.csdn.net/weiweicao0429/article/details/17578011\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/weiweicao0429/article/details/17578011</a></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># tc qdisc add dev eth0 root netem delay 100ms</span></span><br><span class=\"line\"><span class=\"comment\"># tc qdisc del dev eth0 root netem delay 100ms</span></span><br><span class=\"line\"><span class=\"comment\"># tc qdisc del dev eth0 root</span></span><br></pre></td></tr></table></figure>\n\n<h4 id=\"进程死亡查询\"><a href=\"#进程死亡查询\" class=\"headerlink\" title=\"进程死亡查询\"></a>进程死亡查询</h4><p><a href=\"https://blog.csdn.net/green1893/article/details/78192017\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/green1893/article/details/78192017</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dmesg | egrep -i -B100 &apos;killed process&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">## 或:</span><br><span class=\"line\">egrep -i &apos;killed process&apos; /var/log/messages</span><br><span class=\"line\">egrep -i -r &apos;killed process&apos; /var/log</span><br><span class=\"line\"></span><br><span class=\"line\">## 或:</span><br><span class=\"line\">journalctl -xb | egrep -i &apos;killed process&apos;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"显示进程中线程\"><a href=\"#显示进程中线程\" class=\"headerlink\" title=\"显示进程中线程\"></a>显示进程中线程</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[nanxing@zerodb-proxy001 zeroproxy]$ pstree -p 25086</span><br><span class=\"line\">zeroProxy.out(25086)─┬─&#123;zeroProxy.out&#125;(25087)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25088)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25089)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25090)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25091)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25092)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25093)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25094)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25095)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25120)</span><br><span class=\"line\">                     ├─&#123;zeroProxy.out&#125;(25121)</span><br><span class=\"line\">                     └─&#123;zeroProxy.out&#125;(25123)</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"显示system-call\"><a href=\"#显示system-call\" class=\"headerlink\" title=\"显示system call\"></a>显示system call</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">strace - trace system calls and signals</span><br><span class=\"line\"></span><br><span class=\"line\">$strace -f java -cp . ContextSwitchTest</span><br><span class=\"line\">https://www.cnblogs.com/softidea/p/5873305.html</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"iostat-查询磁盘整体问题（比如iops）\"><a href=\"#iostat-查询磁盘整体问题（比如iops）\" class=\"headerlink\" title=\"iostat 查询磁盘整体问题（比如iops）\"></a>iostat 查询磁盘整体问题（比如iops）</h4><p><a href=\"http://coolnull.com/4444.html\" target=\"_blank\" rel=\"noopener\">http://coolnull.com/4444.html</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@binlog-msg001 zerokeeper]# iostat -x 1 10</span><br><span class=\"line\">Linux 2.6.32-754.el6.x86_64 (binlog-msg001.dev.2dfire.info) \t08/02/2018 \t_x86_64_\t(1 CPU)</span><br><span class=\"line\"></span><br><span class=\"line\">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class=\"line\">           3.16    0.00    1.51    5.03    0.17   90.14</span><br><span class=\"line\"></span><br><span class=\"line\">Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class=\"line\">scd0              0.00     0.00    0.00    0.00     0.01     0.00     7.00     0.00    0.35    0.35    0.00   0.35   0.00</span><br><span class=\"line\">vda               4.11    10.08  137.57    1.97  2882.02    96.38    21.34     0.23    1.67    1.66    2.48   0.41   5.79</span><br><span class=\"line\"></span><br><span class=\"line\">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class=\"line\">           1.02    0.00    2.04   96.94    0.00    0.00</span><br><span class=\"line\"></span><br><span class=\"line\">Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class=\"line\">scd0              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class=\"line\">vda              73.47     0.00   75.51    1.02 49616.33     8.16   648.43     6.91   94.92   96.19    1.00  13.33 102.04</span><br><span class=\"line\"></span><br><span class=\"line\">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class=\"line\">           1.03    0.00    1.03   97.94    0.00    0.00</span><br><span class=\"line\"></span><br><span class=\"line\">Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class=\"line\">scd0              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class=\"line\">vda               2.06     0.00   94.85    0.00 50969.07     0.00   537.39     9.49   97.23   97.23    0.00  10.87 103.09</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"iotop-查看那些进程-线程-正在读写磁盘。\"><a href=\"#iotop-查看那些进程-线程-正在读写磁盘。\" class=\"headerlink\" title=\"iotop 查看那些进程(线程)正在读写磁盘。\"></a>iotop 查看那些进程(线程)正在读写磁盘。</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"ps-eo-pid-lstart-grep-26251\"><a href=\"#ps-eo-pid-lstart-grep-26251\" class=\"headerlink\" title=\"ps -eo pid,lstart|grep 26251\"></a>ps -eo pid,lstart|grep 26251</h3><p>查看进程的启动时间</p>\n<h3 id=\"dstat-cldny-性能观察综合神器\"><a href=\"#dstat-cldny-性能观察综合神器\" class=\"headerlink\" title=\"dstat -cldny 性能观察综合神器\"></a>dstat -cldny 性能观察综合神器</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[nanxing@zerodb-proxy003 ~]$ dstat -cldny</span><br><span class=\"line\">----total-cpu-usage---- ---load-avg--- -dsk/total- -net/total- ---system--</span><br><span class=\"line\">usr sys idl wai hiq siq| 1m   5m  15m | read  writ| recv  send| int   csw </span><br><span class=\"line\">  8   2  89   0   0   1|2.91 1.00 0.95|5423B   94k|   0     0 |2065  2245 </span><br><span class=\"line\"> 71  17   3   0   0  10|2.91 1.00 0.95|   0     0 |  23M   23M|  56k 1746 </span><br><span class=\"line\"> 69  17   2   0   0  11|2.91 1.00 0.95|   0   716k|  23M   23M|  56k 1597 </span><br><span class=\"line\"> 70  17   3   0   0  10|3.00 1.05 0.97|   0    32k|  23M   23M|  55k 1848 </span><br><span class=\"line\"> 69  18   3   0   0  11|3.00 1.05 0.97|   0     0 |  23M   23M|  56k 1758 </span><br><span class=\"line\"> 71  17   2   0   0  11|3.00 1.05 0.97|   0     0 |  23M   23M|  56k 1509 </span><br><span class=\"line\"> 70  16   3   0   0  11|3.00 1.05 0.97|   0     0 |  23M   23M|  56k 1531 </span><br><span class=\"line\"> 71  16   2   0   0  11|3.00 1.05 0.97|   0    72k|  23M   23M|  57k 1403 </span><br><span class=\"line\"> 70  17   2   0   0  11|3.08 1.10 0.99|   0     0 |  23M   23M|  56k 1455</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"iftop\"><a href=\"#iftop\" class=\"headerlink\" title=\"iftop\"></a>iftop</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">                               204Mb                          407Mb                           611Mb                          814Mb                     0.99Gb</span><br><span class=\"line\">└──────────────────────────────┴──────────────────────────────┴───────────────────────────────┴──────────────────────────────┴───────────────────────────────</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.74                                                         103Mb   102Mb  96.3Mb</span><br><span class=\"line\">                                                                 &lt;=                                                                   37.6Mb  37.5Mb  35.2Mb</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.69                                                        10.4Mb  10.4Mb  9.77Mb</span><br><span class=\"line\">                                                                 &lt;=                                                                   25.8Mb  25.9Mb  24.3Mb</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.68                                                        10.3Mb  10.3Mb  9.71Mb</span><br><span class=\"line\">                                                                 &lt;=                                                                   25.5Mb  25.6Mb  24.1Mb</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.66                                                        10.4Mb  10.3Mb  9.69Mb</span><br><span class=\"line\">                                                                 &lt;=                                                                   25.8Mb  25.5Mb  24.0Mb</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.67                                                        10.3Mb  10.3Mb  9.68Mb</span><br><span class=\"line\">                                                                 &lt;=                                                                   25.6Mb  25.5Mb  24.0Mb</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.6.0.11                                                            0b   13.5Kb  8.42Kb</span><br><span class=\"line\">                                                                 &lt;=                                                                      0b    376b    235b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.1.133.201                                                      3.44Kb  4.43Kb  5.10Kb</span><br><span class=\"line\">                                                                 &lt;=                                                                    832b    499b    546b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.0.243                                                       1.69Kb   691b    648b</span><br><span class=\"line\">                                                                 &lt;=                                                                   1.14Kb   424b    410b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.70                                                        2.23Kb   458b    572b</span><br><span class=\"line\">                                                                 &lt;=                                                                   2.23Kb   458b    572b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.71                                                        2.23Kb   458b    572b</span><br><span class=\"line\">                                                                 &lt;=                                                                   2.23Kb   458b    572b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.72                                                        2.23Kb   458b    572b</span><br><span class=\"line\">                                                                 &lt;=                                                                   2.23Kb   458b    572b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 10.12.1.73                                                        2.23Kb   458b    572b</span><br><span class=\"line\">                                                                 &lt;=                                                                   2.23Kb   458b    572b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 100.116.166.131                                                    240b    240b    240b</span><br><span class=\"line\">                                                                 &lt;=                                                                    656b    656b    656b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 100.116.202.130                                                    240b    240b    240b</span><br><span class=\"line\">                                                                 &lt;=                                                                    656b    656b    656b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 100.116.203.1                                                      240b    240b    240b</span><br><span class=\"line\">                                                                 &lt;=                                                                    656b    656b    656b</span><br><span class=\"line\">10.12.1.62                                                       =&gt; 100.116.165.130                                                    240b    240b    210b</span><br><span class=\"line\">                                                                 &lt;=                                                                    656b    656b    574b</span><br><span class=\"line\">─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span><br><span class=\"line\">TX:             cum:    270MB   peak:\t 145Mb                                                                               rates:    144Mb   144Mb   135Mb</span><br><span class=\"line\">RX:                     263MB            141Mb                                                                                         140Mb   140Mb   132Mb</span><br><span class=\"line\">TOTAL:                  533MB            287Mb                                                                                         284Mb   284Mb   267Mb</span><br></pre></td></tr></table></figure>"},{"title":"Linux-Top","date":"2018-09-26T04:42:06.000Z","_content":"\n用`top -H + jstack`定位RocketMQ最耗CPU的线程在做什么事情\n```\ntop -H\n\n按住shift+p，让线程按照CPU从大到小排列\n\ntop - 12:44:35 up 14 days, 19:56,  3 users,  load average: 0.22, 0.25, 0.31\nThreads: 386 total,   3 running, 383 sleeping,   0 stopped,   0 zombie\n%Cpu(s): 12.4 us,  6.7 sy,  0.0 ni, 77.4 id,  2.0 wa,  0.0 hi,  1.1 si,  0.4 st\nKiB Mem : 90.6/3881920  [||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||          ]\nKiB Swap: 11.2/1048572  [|||||||||||                                                                                         ]\n\n  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                                                                                                            \n28690 root      20   0 14.263g 2.862g 207296 S 10.0 77.3   0:12.49 java                                                                                                                               \n28598 root      20   0 14.263g 2.862g 207296 S  7.3 77.3   0:26.65 java                                                                                                                               \n28589 root      20   0 14.263g 2.862g 207296 S  7.0 77.3   0:58.14 java                                                                                                                               \n27914 root      20   0 14.263g 2.862g 207296 S  5.0 77.3   1:18.72 java                                                                                                                               \n27874 root      20   0 14.263g 2.862g 207296 R  4.7 77.3   2:04.93 java                                                                                                                               \n27887 root      20   0 14.263g 2.862g 207296 S  4.7 77.3   2:27.30 java                                                                                                                               \n27872 root      20   0 14.263g 2.862g 207296 S  1.7 77.3   0:13.04 java                                                                                                                               \n  259 root      20   0       0      0      0 S  1.0  0.0   2:09.55 jbd2/vda1-8                                                                                                                        \n27896 root      20   0 14.263g 2.862g 207296 S  0.7 77.3   1:48.26 java                                                                                                                               \n27924 root      20   0 14.263g 2.862g 207296 S  0.7 77.3   0:03.36 java                                                                                                                               \n28940 root      20   0 2846000 216716   6820 S  0.7  5.6   0:16.50 java                                                                                                                               \n28951 root      20   0 2846000 216716   6820 S  0.7  5.6   0:44.03 java                                                                                                                               \n    6 root      20   0       0      0      0 S  0.3  0.0   1:04.50 kworker/u4:0                                                                                                                       \n  391 root       0 -20       0      0      0 S  0.3  0.0   0:24.38 kworker/0:1H  \n  \n\n线程号为28690线程占用了最多的CPU\n\nprintf \"%x\\n\" 28690\n7012\n\n用该线程号去java栈中找，\n\n[root@mq004 rocketmqlogs]# jstack 27782 | grep -A29 7012\n\"NettyServerCodecThread_4\" #62 prio=5 os_prio=0 tid=0x00007f13cc019510 nid=0x7012 waiting on condition [0x00007f11c9c0d000]\n   java.lang.Thread.State: TIMED_WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x00000007274f1b30> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n\tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)\n\tat java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.takeTask(SingleThreadEventExecutor.java:269)\n\tat io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:39)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\"ClientManageThread_15\" #165 prio=5 os_prio=0 tid=0x00007f139c802840 nid=0x6ff6 waiting on condition [0x00007f11c9d0e000]\n   java.lang.Thread.State: WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x00000007260004c0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n\tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\n\tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\n\tat java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\"NettyServerCodecThread_3\" #61 prio=5 os_prio=0 tid=0x00007f13b802fa50 nid=0x6fd1 waiting on condition [0x00007f11c9e0f000]\n   java.lang.Thread.State: TIMED_WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x00000007274f1c08> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n\tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)\n\t\n\t\n发现NettyServerCodecThread_4占用的CPU比较多，从名字上也能看出，这个线程是用来codec的。\n```\n\n","source":"_posts/Linux-Top.md","raw":"---\ntitle: Linux-Top\ndate: 2018-09-26 12:42:06\ntags:\n---\n\n用`top -H + jstack`定位RocketMQ最耗CPU的线程在做什么事情\n```\ntop -H\n\n按住shift+p，让线程按照CPU从大到小排列\n\ntop - 12:44:35 up 14 days, 19:56,  3 users,  load average: 0.22, 0.25, 0.31\nThreads: 386 total,   3 running, 383 sleeping,   0 stopped,   0 zombie\n%Cpu(s): 12.4 us,  6.7 sy,  0.0 ni, 77.4 id,  2.0 wa,  0.0 hi,  1.1 si,  0.4 st\nKiB Mem : 90.6/3881920  [||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||          ]\nKiB Swap: 11.2/1048572  [|||||||||||                                                                                         ]\n\n  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                                                                                                            \n28690 root      20   0 14.263g 2.862g 207296 S 10.0 77.3   0:12.49 java                                                                                                                               \n28598 root      20   0 14.263g 2.862g 207296 S  7.3 77.3   0:26.65 java                                                                                                                               \n28589 root      20   0 14.263g 2.862g 207296 S  7.0 77.3   0:58.14 java                                                                                                                               \n27914 root      20   0 14.263g 2.862g 207296 S  5.0 77.3   1:18.72 java                                                                                                                               \n27874 root      20   0 14.263g 2.862g 207296 R  4.7 77.3   2:04.93 java                                                                                                                               \n27887 root      20   0 14.263g 2.862g 207296 S  4.7 77.3   2:27.30 java                                                                                                                               \n27872 root      20   0 14.263g 2.862g 207296 S  1.7 77.3   0:13.04 java                                                                                                                               \n  259 root      20   0       0      0      0 S  1.0  0.0   2:09.55 jbd2/vda1-8                                                                                                                        \n27896 root      20   0 14.263g 2.862g 207296 S  0.7 77.3   1:48.26 java                                                                                                                               \n27924 root      20   0 14.263g 2.862g 207296 S  0.7 77.3   0:03.36 java                                                                                                                               \n28940 root      20   0 2846000 216716   6820 S  0.7  5.6   0:16.50 java                                                                                                                               \n28951 root      20   0 2846000 216716   6820 S  0.7  5.6   0:44.03 java                                                                                                                               \n    6 root      20   0       0      0      0 S  0.3  0.0   1:04.50 kworker/u4:0                                                                                                                       \n  391 root       0 -20       0      0      0 S  0.3  0.0   0:24.38 kworker/0:1H  \n  \n\n线程号为28690线程占用了最多的CPU\n\nprintf \"%x\\n\" 28690\n7012\n\n用该线程号去java栈中找，\n\n[root@mq004 rocketmqlogs]# jstack 27782 | grep -A29 7012\n\"NettyServerCodecThread_4\" #62 prio=5 os_prio=0 tid=0x00007f13cc019510 nid=0x7012 waiting on condition [0x00007f11c9c0d000]\n   java.lang.Thread.State: TIMED_WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x00000007274f1b30> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n\tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)\n\tat java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.takeTask(SingleThreadEventExecutor.java:269)\n\tat io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:39)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\"ClientManageThread_15\" #165 prio=5 os_prio=0 tid=0x00007f139c802840 nid=0x6ff6 waiting on condition [0x00007f11c9d0e000]\n   java.lang.Thread.State: WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x00000007260004c0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n\tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\n\tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\n\tat java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\"NettyServerCodecThread_3\" #61 prio=5 os_prio=0 tid=0x00007f13b802fa50 nid=0x6fd1 waiting on condition [0x00007f11c9e0f000]\n   java.lang.Thread.State: TIMED_WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x00000007274f1c08> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n\tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)\n\t\n\t\n发现NettyServerCodecThread_4占用的CPU比较多，从名字上也能看出，这个线程是用来codec的。\n```\n\n","slug":"Linux-Top","published":1,"updated":"2019-09-28T08:51:00.906Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o840003lv1np5q1j0tlo","content":"<p>用<code>top -H + jstack</code>定位RocketMQ最耗CPU的线程在做什么事情</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">top -H</span><br><span class=\"line\"></span><br><span class=\"line\">按住shift+p，让线程按照CPU从大到小排列</span><br><span class=\"line\"></span><br><span class=\"line\">top - 12:44:35 up 14 days, 19:56,  3 users,  load average: 0.22, 0.25, 0.31</span><br><span class=\"line\">Threads: 386 total,   3 running, 383 sleeping,   0 stopped,   0 zombie</span><br><span class=\"line\">%Cpu(s): 12.4 us,  6.7 sy,  0.0 ni, 77.4 id,  2.0 wa,  0.0 hi,  1.1 si,  0.4 st</span><br><span class=\"line\">KiB Mem : 90.6/3881920  [||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||          ]</span><br><span class=\"line\">KiB Swap: 11.2/1048572  [|||||||||||                                                                                         ]</span><br><span class=\"line\"></span><br><span class=\"line\">  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                                                                                                            </span><br><span class=\"line\">28690 root      20   0 14.263g 2.862g 207296 S 10.0 77.3   0:12.49 java                                                                                                                               </span><br><span class=\"line\">28598 root      20   0 14.263g 2.862g 207296 S  7.3 77.3   0:26.65 java                                                                                                                               </span><br><span class=\"line\">28589 root      20   0 14.263g 2.862g 207296 S  7.0 77.3   0:58.14 java                                                                                                                               </span><br><span class=\"line\">27914 root      20   0 14.263g 2.862g 207296 S  5.0 77.3   1:18.72 java                                                                                                                               </span><br><span class=\"line\">27874 root      20   0 14.263g 2.862g 207296 R  4.7 77.3   2:04.93 java                                                                                                                               </span><br><span class=\"line\">27887 root      20   0 14.263g 2.862g 207296 S  4.7 77.3   2:27.30 java                                                                                                                               </span><br><span class=\"line\">27872 root      20   0 14.263g 2.862g 207296 S  1.7 77.3   0:13.04 java                                                                                                                               </span><br><span class=\"line\">  259 root      20   0       0      0      0 S  1.0  0.0   2:09.55 jbd2/vda1-8                                                                                                                        </span><br><span class=\"line\">27896 root      20   0 14.263g 2.862g 207296 S  0.7 77.3   1:48.26 java                                                                                                                               </span><br><span class=\"line\">27924 root      20   0 14.263g 2.862g 207296 S  0.7 77.3   0:03.36 java                                                                                                                               </span><br><span class=\"line\">28940 root      20   0 2846000 216716   6820 S  0.7  5.6   0:16.50 java                                                                                                                               </span><br><span class=\"line\">28951 root      20   0 2846000 216716   6820 S  0.7  5.6   0:44.03 java                                                                                                                               </span><br><span class=\"line\">    6 root      20   0       0      0      0 S  0.3  0.0   1:04.50 kworker/u4:0                                                                                                                       </span><br><span class=\"line\">  391 root       0 -20       0      0      0 S  0.3  0.0   0:24.38 kworker/0:1H  </span><br><span class=\"line\">  </span><br><span class=\"line\"></span><br><span class=\"line\">线程号为28690线程占用了最多的CPU</span><br><span class=\"line\"></span><br><span class=\"line\">printf &quot;%x\\n&quot; 28690</span><br><span class=\"line\">7012</span><br><span class=\"line\"></span><br><span class=\"line\">用该线程号去java栈中找，</span><br><span class=\"line\"></span><br><span class=\"line\">[root@mq004 rocketmqlogs]# jstack 27782 | grep -A29 7012</span><br><span class=\"line\">&quot;NettyServerCodecThread_4&quot; #62 prio=5 os_prio=0 tid=0x00007f13cc019510 nid=0x7012 waiting on condition [0x00007f11c9c0d000]</span><br><span class=\"line\">   java.lang.Thread.State: TIMED_WAITING (parking)</span><br><span class=\"line\">\tat sun.misc.Unsafe.park(Native Method)</span><br><span class=\"line\">\t- parking to wait for  &lt;0x00000007274f1b30&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)</span><br><span class=\"line\">\tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)</span><br><span class=\"line\">\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)</span><br><span class=\"line\">\tat java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)</span><br><span class=\"line\">\tat io.netty.util.concurrent.SingleThreadEventExecutor.takeTask(SingleThreadEventExecutor.java:269)</span><br><span class=\"line\">\tat io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:39)</span><br><span class=\"line\">\tat io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)</span><br><span class=\"line\">\tat java.lang.Thread.run(Thread.java:748)</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;ClientManageThread_15&quot; #165 prio=5 os_prio=0 tid=0x00007f139c802840 nid=0x6ff6 waiting on condition [0x00007f11c9d0e000]</span><br><span class=\"line\">   java.lang.Thread.State: WAITING (parking)</span><br><span class=\"line\">\tat sun.misc.Unsafe.park(Native Method)</span><br><span class=\"line\">\t- parking to wait for  &lt;0x00000007260004c0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)</span><br><span class=\"line\">\tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)</span><br><span class=\"line\">\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)</span><br><span class=\"line\">\tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)</span><br><span class=\"line\">\tat java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)</span><br><span class=\"line\">\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)</span><br><span class=\"line\">\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class=\"line\">\tat java.lang.Thread.run(Thread.java:748)</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;NettyServerCodecThread_3&quot; #61 prio=5 os_prio=0 tid=0x00007f13b802fa50 nid=0x6fd1 waiting on condition [0x00007f11c9e0f000]</span><br><span class=\"line\">   java.lang.Thread.State: TIMED_WAITING (parking)</span><br><span class=\"line\">\tat sun.misc.Unsafe.park(Native Method)</span><br><span class=\"line\">\t- parking to wait for  &lt;0x00000007274f1c08&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)</span><br><span class=\"line\">\tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)</span><br><span class=\"line\">\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">发现NettyServerCodecThread_4占用的CPU比较多，从名字上也能看出，这个线程是用来codec的。</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<p>用<code>top -H + jstack</code>定位RocketMQ最耗CPU的线程在做什么事情</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">top -H</span><br><span class=\"line\"></span><br><span class=\"line\">按住shift+p，让线程按照CPU从大到小排列</span><br><span class=\"line\"></span><br><span class=\"line\">top - 12:44:35 up 14 days, 19:56,  3 users,  load average: 0.22, 0.25, 0.31</span><br><span class=\"line\">Threads: 386 total,   3 running, 383 sleeping,   0 stopped,   0 zombie</span><br><span class=\"line\">%Cpu(s): 12.4 us,  6.7 sy,  0.0 ni, 77.4 id,  2.0 wa,  0.0 hi,  1.1 si,  0.4 st</span><br><span class=\"line\">KiB Mem : 90.6/3881920  [||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||          ]</span><br><span class=\"line\">KiB Swap: 11.2/1048572  [|||||||||||                                                                                         ]</span><br><span class=\"line\"></span><br><span class=\"line\">  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                                                                                                            </span><br><span class=\"line\">28690 root      20   0 14.263g 2.862g 207296 S 10.0 77.3   0:12.49 java                                                                                                                               </span><br><span class=\"line\">28598 root      20   0 14.263g 2.862g 207296 S  7.3 77.3   0:26.65 java                                                                                                                               </span><br><span class=\"line\">28589 root      20   0 14.263g 2.862g 207296 S  7.0 77.3   0:58.14 java                                                                                                                               </span><br><span class=\"line\">27914 root      20   0 14.263g 2.862g 207296 S  5.0 77.3   1:18.72 java                                                                                                                               </span><br><span class=\"line\">27874 root      20   0 14.263g 2.862g 207296 R  4.7 77.3   2:04.93 java                                                                                                                               </span><br><span class=\"line\">27887 root      20   0 14.263g 2.862g 207296 S  4.7 77.3   2:27.30 java                                                                                                                               </span><br><span class=\"line\">27872 root      20   0 14.263g 2.862g 207296 S  1.7 77.3   0:13.04 java                                                                                                                               </span><br><span class=\"line\">  259 root      20   0       0      0      0 S  1.0  0.0   2:09.55 jbd2/vda1-8                                                                                                                        </span><br><span class=\"line\">27896 root      20   0 14.263g 2.862g 207296 S  0.7 77.3   1:48.26 java                                                                                                                               </span><br><span class=\"line\">27924 root      20   0 14.263g 2.862g 207296 S  0.7 77.3   0:03.36 java                                                                                                                               </span><br><span class=\"line\">28940 root      20   0 2846000 216716   6820 S  0.7  5.6   0:16.50 java                                                                                                                               </span><br><span class=\"line\">28951 root      20   0 2846000 216716   6820 S  0.7  5.6   0:44.03 java                                                                                                                               </span><br><span class=\"line\">    6 root      20   0       0      0      0 S  0.3  0.0   1:04.50 kworker/u4:0                                                                                                                       </span><br><span class=\"line\">  391 root       0 -20       0      0      0 S  0.3  0.0   0:24.38 kworker/0:1H  </span><br><span class=\"line\">  </span><br><span class=\"line\"></span><br><span class=\"line\">线程号为28690线程占用了最多的CPU</span><br><span class=\"line\"></span><br><span class=\"line\">printf &quot;%x\\n&quot; 28690</span><br><span class=\"line\">7012</span><br><span class=\"line\"></span><br><span class=\"line\">用该线程号去java栈中找，</span><br><span class=\"line\"></span><br><span class=\"line\">[root@mq004 rocketmqlogs]# jstack 27782 | grep -A29 7012</span><br><span class=\"line\">&quot;NettyServerCodecThread_4&quot; #62 prio=5 os_prio=0 tid=0x00007f13cc019510 nid=0x7012 waiting on condition [0x00007f11c9c0d000]</span><br><span class=\"line\">   java.lang.Thread.State: TIMED_WAITING (parking)</span><br><span class=\"line\">\tat sun.misc.Unsafe.park(Native Method)</span><br><span class=\"line\">\t- parking to wait for  &lt;0x00000007274f1b30&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)</span><br><span class=\"line\">\tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)</span><br><span class=\"line\">\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)</span><br><span class=\"line\">\tat java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)</span><br><span class=\"line\">\tat io.netty.util.concurrent.SingleThreadEventExecutor.takeTask(SingleThreadEventExecutor.java:269)</span><br><span class=\"line\">\tat io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:39)</span><br><span class=\"line\">\tat io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)</span><br><span class=\"line\">\tat java.lang.Thread.run(Thread.java:748)</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;ClientManageThread_15&quot; #165 prio=5 os_prio=0 tid=0x00007f139c802840 nid=0x6ff6 waiting on condition [0x00007f11c9d0e000]</span><br><span class=\"line\">   java.lang.Thread.State: WAITING (parking)</span><br><span class=\"line\">\tat sun.misc.Unsafe.park(Native Method)</span><br><span class=\"line\">\t- parking to wait for  &lt;0x00000007260004c0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)</span><br><span class=\"line\">\tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)</span><br><span class=\"line\">\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)</span><br><span class=\"line\">\tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)</span><br><span class=\"line\">\tat java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)</span><br><span class=\"line\">\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)</span><br><span class=\"line\">\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class=\"line\">\tat java.lang.Thread.run(Thread.java:748)</span><br><span class=\"line\"></span><br><span class=\"line\">&quot;NettyServerCodecThread_3&quot; #61 prio=5 os_prio=0 tid=0x00007f13b802fa50 nid=0x6fd1 waiting on condition [0x00007f11c9e0f000]</span><br><span class=\"line\">   java.lang.Thread.State: TIMED_WAITING (parking)</span><br><span class=\"line\">\tat sun.misc.Unsafe.park(Native Method)</span><br><span class=\"line\">\t- parking to wait for  &lt;0x00000007274f1c08&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)</span><br><span class=\"line\">\tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)</span><br><span class=\"line\">\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">发现NettyServerCodecThread_4占用的CPU比较多，从名字上也能看出，这个线程是用来codec的。</span><br></pre></td></tr></table></figure>\n\n"},{"title":"Linux-SAR","date":"2019-06-04T10:57:09.000Z","_content":"\n\n### 网络\nsar -n SOCK\n06:08:01 PM    totsck    tcpsck    udpsck    rawsck   ip-frag    tcp-tw\n06:09:01 PM      3871      3757         7         0         0       221\n06:10:01 PM      3874      3762         7         0         0       224\n06:11:01 PM      3878      3764         7         0         0       167\n06:12:01 PM      3878      3766         7         0         0       161\n06:13:01 PM      3884      3770         7         0         0       196\n06:14:01 PM      3894      3780         7         0         0       210\n06:15:01 PM      3888      3774         7         0         0       209\n06:16:01 PM      3889      3775         7         0         0       204\n06:17:01 PM      3883      3769         7         0         0       159\n06:18:01 PM      3886      3772         7         0         0       137\n06:19:01 PM      3868      3754         7         0         0       164\n\n### 网卡\nsar -n DEV\n04:39:01 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s\n04:40:01 PM        lo      9.69      9.69      1.46      1.46      0.00      0.00      0.00\n04:40:01 PM      eth0   4359.96   3684.55   2903.17   2860.18      0.00      0.00      0.00\n04:41:01 PM        lo     10.14     10.14      1.70      1.70      0.00      0.00      0.00\n04:41:01 PM      eth0   6758.43   5968.06   4236.71   4187.10      0.00      0.00      0.00\n04:42:01 PM        lo      9.80      9.80      1.48      1.48      0.00      0.00      0.00\n04:42:01 PM      eth0   6793.83   6054.64   4280.76   4233.98      0.00      0.00      0.00\n04:43:01 PM        lo      9.72      9.72      1.47      1.47      0.00      0.00      0.00\n04:43:01 PM      eth0   5421.57   4548.74   3735.40   3683.44      0.00      0.00      0.00\n04:44:01 PM        lo      9.73      9.73      1.47      1.47      0.00      0.00      0.00\n04:44:01 PM      eth0   5311.06   4402.71   3718.44   3662.39      0.00      0.00      0.00\n\n### CPU\nsar -w\n04:26:01 PM    proc/s   cswch/s\n04:27:01 PM      3.99   7822.70\n04:28:01 PM      3.88   9660.06\n04:29:01 PM      4.32   8863.08\n04:30:01 PM      3.89   8613.99\n04:31:01 PM      4.02   9019.60\n04:32:01 PM      4.04   9476.70\n04:33:01 PM      3.94   9747.35\n04:34:01 PM      4.32   9579.99\n04:35:01 PM      3.94   9611.87\n04:36:01 PM      4.09  10145.43\n04:37:01 PM      4.04   9741.25\n04:38:01 PM      3.93   8964.98\n\n### 磁盘\nsar -b\n06:08:01 PM       tps      rtps      wtps   bread/s   bwrtn/s\n06:09:01 PM      3.84      0.00      3.84      0.00    458.83\n06:10:01 PM      2.53      0.00      2.53      0.00     40.97\n06:11:01 PM      1.81      0.00      1.81      0.00     37.48\n06:12:01 PM      2.44      0.00      2.44      0.00     42.19\n06:13:01 PM      1.85      0.00      1.85      0.00     36.34\n06:14:01 PM      4.09      0.00      4.09      0.00    465.35\n06:15:01 PM      3.31      0.32      2.99      6.09     50.66\n06:16:01 PM      1.80      0.00      1.80      0.00     35.49\n06:17:01 PM      2.44      0.00      2.44      0.00     43.24\n06:18:01 PM      2.27      0.00      2.27      0.00     41.68\n\n\n### 内存\nsar -r\n06:42:01 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit\n06:43:01 PM    252992  16080648     98.45    165136   2553056  14508648     88.83\n06:44:01 PM    252264  16081376     98.46    165136   2553164  14508656     88.83\n06:45:01 PM    252628  16081012     98.45    165136   2553276  14508656     88.83\n06:46:01 PM    252660  16080980     98.45    165136   2553388  14508656     88.83\n06:47:01 PM    252728  16080912     98.45    165136   2553488  14508652     88.83\n06:48:02 PM    252752  16080888     98.45    165136   2553592  14508604     88.83\n06:49:01 PM    253460  16080180     98.45    165136   2553696  14507040     88.82\n06:50:01 PM    253144  16080496     98.45    165144   2553796  14505000     88.80\n06:51:01 PM    254632  16079008     98.44    165144   2553904  14504924     88.80\n","source":"_posts/Linux-SAR.md","raw":"---\ntitle: Linux-SAR\ndate: 2019-06-04 18:57:09\ntags:\n---\n\n\n### 网络\nsar -n SOCK\n06:08:01 PM    totsck    tcpsck    udpsck    rawsck   ip-frag    tcp-tw\n06:09:01 PM      3871      3757         7         0         0       221\n06:10:01 PM      3874      3762         7         0         0       224\n06:11:01 PM      3878      3764         7         0         0       167\n06:12:01 PM      3878      3766         7         0         0       161\n06:13:01 PM      3884      3770         7         0         0       196\n06:14:01 PM      3894      3780         7         0         0       210\n06:15:01 PM      3888      3774         7         0         0       209\n06:16:01 PM      3889      3775         7         0         0       204\n06:17:01 PM      3883      3769         7         0         0       159\n06:18:01 PM      3886      3772         7         0         0       137\n06:19:01 PM      3868      3754         7         0         0       164\n\n### 网卡\nsar -n DEV\n04:39:01 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s\n04:40:01 PM        lo      9.69      9.69      1.46      1.46      0.00      0.00      0.00\n04:40:01 PM      eth0   4359.96   3684.55   2903.17   2860.18      0.00      0.00      0.00\n04:41:01 PM        lo     10.14     10.14      1.70      1.70      0.00      0.00      0.00\n04:41:01 PM      eth0   6758.43   5968.06   4236.71   4187.10      0.00      0.00      0.00\n04:42:01 PM        lo      9.80      9.80      1.48      1.48      0.00      0.00      0.00\n04:42:01 PM      eth0   6793.83   6054.64   4280.76   4233.98      0.00      0.00      0.00\n04:43:01 PM        lo      9.72      9.72      1.47      1.47      0.00      0.00      0.00\n04:43:01 PM      eth0   5421.57   4548.74   3735.40   3683.44      0.00      0.00      0.00\n04:44:01 PM        lo      9.73      9.73      1.47      1.47      0.00      0.00      0.00\n04:44:01 PM      eth0   5311.06   4402.71   3718.44   3662.39      0.00      0.00      0.00\n\n### CPU\nsar -w\n04:26:01 PM    proc/s   cswch/s\n04:27:01 PM      3.99   7822.70\n04:28:01 PM      3.88   9660.06\n04:29:01 PM      4.32   8863.08\n04:30:01 PM      3.89   8613.99\n04:31:01 PM      4.02   9019.60\n04:32:01 PM      4.04   9476.70\n04:33:01 PM      3.94   9747.35\n04:34:01 PM      4.32   9579.99\n04:35:01 PM      3.94   9611.87\n04:36:01 PM      4.09  10145.43\n04:37:01 PM      4.04   9741.25\n04:38:01 PM      3.93   8964.98\n\n### 磁盘\nsar -b\n06:08:01 PM       tps      rtps      wtps   bread/s   bwrtn/s\n06:09:01 PM      3.84      0.00      3.84      0.00    458.83\n06:10:01 PM      2.53      0.00      2.53      0.00     40.97\n06:11:01 PM      1.81      0.00      1.81      0.00     37.48\n06:12:01 PM      2.44      0.00      2.44      0.00     42.19\n06:13:01 PM      1.85      0.00      1.85      0.00     36.34\n06:14:01 PM      4.09      0.00      4.09      0.00    465.35\n06:15:01 PM      3.31      0.32      2.99      6.09     50.66\n06:16:01 PM      1.80      0.00      1.80      0.00     35.49\n06:17:01 PM      2.44      0.00      2.44      0.00     43.24\n06:18:01 PM      2.27      0.00      2.27      0.00     41.68\n\n\n### 内存\nsar -r\n06:42:01 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit\n06:43:01 PM    252992  16080648     98.45    165136   2553056  14508648     88.83\n06:44:01 PM    252264  16081376     98.46    165136   2553164  14508656     88.83\n06:45:01 PM    252628  16081012     98.45    165136   2553276  14508656     88.83\n06:46:01 PM    252660  16080980     98.45    165136   2553388  14508656     88.83\n06:47:01 PM    252728  16080912     98.45    165136   2553488  14508652     88.83\n06:48:02 PM    252752  16080888     98.45    165136   2553592  14508604     88.83\n06:49:01 PM    253460  16080180     98.45    165136   2553696  14507040     88.82\n06:50:01 PM    253144  16080496     98.45    165144   2553796  14505000     88.80\n06:51:01 PM    254632  16079008     98.44    165144   2553904  14504924     88.80\n","slug":"Linux-SAR","published":1,"updated":"2019-09-28T08:51:00.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o841003mv1npwh1rfqjp","content":"<h3 id=\"网络\"><a href=\"#网络\" class=\"headerlink\" title=\"网络\"></a>网络</h3><p>sar -n SOCK<br>06:08:01 PM    totsck    tcpsck    udpsck    rawsck   ip-frag    tcp-tw<br>06:09:01 PM      3871      3757         7         0         0       221<br>06:10:01 PM      3874      3762         7         0         0       224<br>06:11:01 PM      3878      3764         7         0         0       167<br>06:12:01 PM      3878      3766         7         0         0       161<br>06:13:01 PM      3884      3770         7         0         0       196<br>06:14:01 PM      3894      3780         7         0         0       210<br>06:15:01 PM      3888      3774         7         0         0       209<br>06:16:01 PM      3889      3775         7         0         0       204<br>06:17:01 PM      3883      3769         7         0         0       159<br>06:18:01 PM      3886      3772         7         0         0       137<br>06:19:01 PM      3868      3754         7         0         0       164</p>\n<h3 id=\"网卡\"><a href=\"#网卡\" class=\"headerlink\" title=\"网卡\"></a>网卡</h3><p>sar -n DEV<br>04:39:01 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s<br>04:40:01 PM        lo      9.69      9.69      1.46      1.46      0.00      0.00      0.00<br>04:40:01 PM      eth0   4359.96   3684.55   2903.17   2860.18      0.00      0.00      0.00<br>04:41:01 PM        lo     10.14     10.14      1.70      1.70      0.00      0.00      0.00<br>04:41:01 PM      eth0   6758.43   5968.06   4236.71   4187.10      0.00      0.00      0.00<br>04:42:01 PM        lo      9.80      9.80      1.48      1.48      0.00      0.00      0.00<br>04:42:01 PM      eth0   6793.83   6054.64   4280.76   4233.98      0.00      0.00      0.00<br>04:43:01 PM        lo      9.72      9.72      1.47      1.47      0.00      0.00      0.00<br>04:43:01 PM      eth0   5421.57   4548.74   3735.40   3683.44      0.00      0.00      0.00<br>04:44:01 PM        lo      9.73      9.73      1.47      1.47      0.00      0.00      0.00<br>04:44:01 PM      eth0   5311.06   4402.71   3718.44   3662.39      0.00      0.00      0.00</p>\n<h3 id=\"CPU\"><a href=\"#CPU\" class=\"headerlink\" title=\"CPU\"></a>CPU</h3><p>sar -w<br>04:26:01 PM    proc/s   cswch/s<br>04:27:01 PM      3.99   7822.70<br>04:28:01 PM      3.88   9660.06<br>04:29:01 PM      4.32   8863.08<br>04:30:01 PM      3.89   8613.99<br>04:31:01 PM      4.02   9019.60<br>04:32:01 PM      4.04   9476.70<br>04:33:01 PM      3.94   9747.35<br>04:34:01 PM      4.32   9579.99<br>04:35:01 PM      3.94   9611.87<br>04:36:01 PM      4.09  10145.43<br>04:37:01 PM      4.04   9741.25<br>04:38:01 PM      3.93   8964.98</p>\n<h3 id=\"磁盘\"><a href=\"#磁盘\" class=\"headerlink\" title=\"磁盘\"></a>磁盘</h3><p>sar -b<br>06:08:01 PM       tps      rtps      wtps   bread/s   bwrtn/s<br>06:09:01 PM      3.84      0.00      3.84      0.00    458.83<br>06:10:01 PM      2.53      0.00      2.53      0.00     40.97<br>06:11:01 PM      1.81      0.00      1.81      0.00     37.48<br>06:12:01 PM      2.44      0.00      2.44      0.00     42.19<br>06:13:01 PM      1.85      0.00      1.85      0.00     36.34<br>06:14:01 PM      4.09      0.00      4.09      0.00    465.35<br>06:15:01 PM      3.31      0.32      2.99      6.09     50.66<br>06:16:01 PM      1.80      0.00      1.80      0.00     35.49<br>06:17:01 PM      2.44      0.00      2.44      0.00     43.24<br>06:18:01 PM      2.27      0.00      2.27      0.00     41.68</p>\n<h3 id=\"内存\"><a href=\"#内存\" class=\"headerlink\" title=\"内存\"></a>内存</h3><p>sar -r<br>06:42:01 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit<br>06:43:01 PM    252992  16080648     98.45    165136   2553056  14508648     88.83<br>06:44:01 PM    252264  16081376     98.46    165136   2553164  14508656     88.83<br>06:45:01 PM    252628  16081012     98.45    165136   2553276  14508656     88.83<br>06:46:01 PM    252660  16080980     98.45    165136   2553388  14508656     88.83<br>06:47:01 PM    252728  16080912     98.45    165136   2553488  14508652     88.83<br>06:48:02 PM    252752  16080888     98.45    165136   2553592  14508604     88.83<br>06:49:01 PM    253460  16080180     98.45    165136   2553696  14507040     88.82<br>06:50:01 PM    253144  16080496     98.45    165144   2553796  14505000     88.80<br>06:51:01 PM    254632  16079008     98.44    165144   2553904  14504924     88.80</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"网络\"><a href=\"#网络\" class=\"headerlink\" title=\"网络\"></a>网络</h3><p>sar -n SOCK<br>06:08:01 PM    totsck    tcpsck    udpsck    rawsck   ip-frag    tcp-tw<br>06:09:01 PM      3871      3757         7         0         0       221<br>06:10:01 PM      3874      3762         7         0         0       224<br>06:11:01 PM      3878      3764         7         0         0       167<br>06:12:01 PM      3878      3766         7         0         0       161<br>06:13:01 PM      3884      3770         7         0         0       196<br>06:14:01 PM      3894      3780         7         0         0       210<br>06:15:01 PM      3888      3774         7         0         0       209<br>06:16:01 PM      3889      3775         7         0         0       204<br>06:17:01 PM      3883      3769         7         0         0       159<br>06:18:01 PM      3886      3772         7         0         0       137<br>06:19:01 PM      3868      3754         7         0         0       164</p>\n<h3 id=\"网卡\"><a href=\"#网卡\" class=\"headerlink\" title=\"网卡\"></a>网卡</h3><p>sar -n DEV<br>04:39:01 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s<br>04:40:01 PM        lo      9.69      9.69      1.46      1.46      0.00      0.00      0.00<br>04:40:01 PM      eth0   4359.96   3684.55   2903.17   2860.18      0.00      0.00      0.00<br>04:41:01 PM        lo     10.14     10.14      1.70      1.70      0.00      0.00      0.00<br>04:41:01 PM      eth0   6758.43   5968.06   4236.71   4187.10      0.00      0.00      0.00<br>04:42:01 PM        lo      9.80      9.80      1.48      1.48      0.00      0.00      0.00<br>04:42:01 PM      eth0   6793.83   6054.64   4280.76   4233.98      0.00      0.00      0.00<br>04:43:01 PM        lo      9.72      9.72      1.47      1.47      0.00      0.00      0.00<br>04:43:01 PM      eth0   5421.57   4548.74   3735.40   3683.44      0.00      0.00      0.00<br>04:44:01 PM        lo      9.73      9.73      1.47      1.47      0.00      0.00      0.00<br>04:44:01 PM      eth0   5311.06   4402.71   3718.44   3662.39      0.00      0.00      0.00</p>\n<h3 id=\"CPU\"><a href=\"#CPU\" class=\"headerlink\" title=\"CPU\"></a>CPU</h3><p>sar -w<br>04:26:01 PM    proc/s   cswch/s<br>04:27:01 PM      3.99   7822.70<br>04:28:01 PM      3.88   9660.06<br>04:29:01 PM      4.32   8863.08<br>04:30:01 PM      3.89   8613.99<br>04:31:01 PM      4.02   9019.60<br>04:32:01 PM      4.04   9476.70<br>04:33:01 PM      3.94   9747.35<br>04:34:01 PM      4.32   9579.99<br>04:35:01 PM      3.94   9611.87<br>04:36:01 PM      4.09  10145.43<br>04:37:01 PM      4.04   9741.25<br>04:38:01 PM      3.93   8964.98</p>\n<h3 id=\"磁盘\"><a href=\"#磁盘\" class=\"headerlink\" title=\"磁盘\"></a>磁盘</h3><p>sar -b<br>06:08:01 PM       tps      rtps      wtps   bread/s   bwrtn/s<br>06:09:01 PM      3.84      0.00      3.84      0.00    458.83<br>06:10:01 PM      2.53      0.00      2.53      0.00     40.97<br>06:11:01 PM      1.81      0.00      1.81      0.00     37.48<br>06:12:01 PM      2.44      0.00      2.44      0.00     42.19<br>06:13:01 PM      1.85      0.00      1.85      0.00     36.34<br>06:14:01 PM      4.09      0.00      4.09      0.00    465.35<br>06:15:01 PM      3.31      0.32      2.99      6.09     50.66<br>06:16:01 PM      1.80      0.00      1.80      0.00     35.49<br>06:17:01 PM      2.44      0.00      2.44      0.00     43.24<br>06:18:01 PM      2.27      0.00      2.27      0.00     41.68</p>\n<h3 id=\"内存\"><a href=\"#内存\" class=\"headerlink\" title=\"内存\"></a>内存</h3><p>sar -r<br>06:42:01 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit<br>06:43:01 PM    252992  16080648     98.45    165136   2553056  14508648     88.83<br>06:44:01 PM    252264  16081376     98.46    165136   2553164  14508656     88.83<br>06:45:01 PM    252628  16081012     98.45    165136   2553276  14508656     88.83<br>06:46:01 PM    252660  16080980     98.45    165136   2553388  14508656     88.83<br>06:47:01 PM    252728  16080912     98.45    165136   2553488  14508652     88.83<br>06:48:02 PM    252752  16080888     98.45    165136   2553592  14508604     88.83<br>06:49:01 PM    253460  16080180     98.45    165136   2553696  14507040     88.82<br>06:50:01 PM    253144  16080496     98.45    165144   2553796  14505000     88.80<br>06:51:01 PM    254632  16079008     98.44    165144   2553904  14504924     88.80</p>\n"},{"title":"Linux-Virtual-memory","date":"2018-09-14T11:27:23.000Z","_content":"\n\n\nhttps://blog.csdn.net/tenfyguo/article/details/8575473\n```\n一，不是 malloc 后就马上占用实际内存，而是第一次使用时（如对内存赋值，memset等操作）发现虚存对应的物理页面未分配，产生缺页中断，才真正分配物理页面，\n同时更新进程页面的映射关系。但由于每个物理内存页面大小是 4k ，不管 memset其中的1k还是5k 、7k ，实际占用物理内存总是 4k 的倍数。所以 RSS 的增量总是 4k 的倍数。\n```","source":"_posts/Linux-Virtual-memory.md","raw":"---\ntitle: Linux-Virtual-memory\ndate: 2018-09-14 19:27:23\ntags:\n---\n\n\n\nhttps://blog.csdn.net/tenfyguo/article/details/8575473\n```\n一，不是 malloc 后就马上占用实际内存，而是第一次使用时（如对内存赋值，memset等操作）发现虚存对应的物理页面未分配，产生缺页中断，才真正分配物理页面，\n同时更新进程页面的映射关系。但由于每个物理内存页面大小是 4k ，不管 memset其中的1k还是5k 、7k ，实际占用物理内存总是 4k 的倍数。所以 RSS 的增量总是 4k 的倍数。\n```","slug":"Linux-Virtual-memory","published":1,"updated":"2019-09-28T08:51:00.907Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o841003nv1npsobobxmn","content":"<p><a href=\"https://blog.csdn.net/tenfyguo/article/details/8575473\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/tenfyguo/article/details/8575473</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">一，不是 malloc 后就马上占用实际内存，而是第一次使用时（如对内存赋值，memset等操作）发现虚存对应的物理页面未分配，产生缺页中断，才真正分配物理页面，</span><br><span class=\"line\">同时更新进程页面的映射关系。但由于每个物理内存页面大小是 4k ，不管 memset其中的1k还是5k 、7k ，实际占用物理内存总是 4k 的倍数。所以 RSS 的增量总是 4k 的倍数。</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/tenfyguo/article/details/8575473\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/tenfyguo/article/details/8575473</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">一，不是 malloc 后就马上占用实际内存，而是第一次使用时（如对内存赋值，memset等操作）发现虚存对应的物理页面未分配，产生缺页中断，才真正分配物理页面，</span><br><span class=\"line\">同时更新进程页面的映射关系。但由于每个物理内存页面大小是 4k ，不管 memset其中的1k还是5k 、7k ，实际占用物理内存总是 4k 的倍数。所以 RSS 的增量总是 4k 的倍数。</span><br></pre></td></tr></table></figure>"},{"title":"Linux-Zero-Copy","date":"2017-11-16T07:26:51.000Z","_content":"\n如今的系统，感觉没有用到 Zero copy 都不好意思拿出手\n\n\n### 参考资料\nhttps://www.ibm.com/developerworks/library/j-zerocopy/\nhttp://www.cnblogs.com/zemliu/p/3695549.html","source":"_posts/Linux-Zero-Copy.md","raw":"---\ntitle: Linux-Zero-Copy\ndate: 2017-11-16 15:26:51\ntags: Linux\n---\n\n如今的系统，感觉没有用到 Zero copy 都不好意思拿出手\n\n\n### 参考资料\nhttps://www.ibm.com/developerworks/library/j-zerocopy/\nhttp://www.cnblogs.com/zemliu/p/3695549.html","slug":"Linux-Zero-Copy","published":1,"updated":"2019-09-28T08:51:00.907Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o842003ov1nprl2gj5qw","content":"<p>如今的系统，感觉没有用到 Zero copy 都不好意思拿出手</p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><p><a href=\"https://www.ibm.com/developerworks/library/j-zerocopy/\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/library/j-zerocopy/</a><br><a href=\"http://www.cnblogs.com/zemliu/p/3695549.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/zemliu/p/3695549.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>如今的系统，感觉没有用到 Zero copy 都不好意思拿出手</p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><p><a href=\"https://www.ibm.com/developerworks/library/j-zerocopy/\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/library/j-zerocopy/</a><br><a href=\"http://www.cnblogs.com/zemliu/p/3695549.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/zemliu/p/3695549.html</a></p>\n"},{"title":"Mac-Multi-JDK","date":"2019-10-08T06:58:44.000Z","_content":"\n\n```\n# 设置 JDK 8\nexport JAVA_8_HOME=`/usr/libexec/java_home -v 1.8`\n# 设置 JDK 12\nexport JAVA_12_HOME=`/usr/libexec/java_home -v 12`\n\nexport JAVA_HOME=$JAVA_8_HOME\n#alias命令动态切换JDK版本\nalias jdk8=\"export JAVA_HOME=$JAVA_8_HOME\"\nalias jdk12=\"export JAVA_HOME=$JAVA_12_HOME\"\n```","source":"_posts/Mac-Multi-JDK.md","raw":"---\ntitle: Mac-Multi-JDK\ndate: 2019-10-08 14:58:44\ntags:\n---\n\n\n```\n# 设置 JDK 8\nexport JAVA_8_HOME=`/usr/libexec/java_home -v 1.8`\n# 设置 JDK 12\nexport JAVA_12_HOME=`/usr/libexec/java_home -v 12`\n\nexport JAVA_HOME=$JAVA_8_HOME\n#alias命令动态切换JDK版本\nalias jdk8=\"export JAVA_HOME=$JAVA_8_HOME\"\nalias jdk12=\"export JAVA_HOME=$JAVA_12_HOME\"\n```","slug":"Mac-Multi-JDK","published":1,"updated":"2019-10-08T07:00:05.140Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o842003pv1np2emw4zsg","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置 JDK 8</span><br><span class=\"line\">export JAVA_8_HOME=`/usr/libexec/java_home -v 1.8`</span><br><span class=\"line\"># 设置 JDK 12</span><br><span class=\"line\">export JAVA_12_HOME=`/usr/libexec/java_home -v 12`</span><br><span class=\"line\"></span><br><span class=\"line\">export JAVA_HOME=$JAVA_8_HOME</span><br><span class=\"line\">#alias命令动态切换JDK版本</span><br><span class=\"line\">alias jdk8=&quot;export JAVA_HOME=$JAVA_8_HOME&quot;</span><br><span class=\"line\">alias jdk12=&quot;export JAVA_HOME=$JAVA_12_HOME&quot;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置 JDK 8</span><br><span class=\"line\">export JAVA_8_HOME=`/usr/libexec/java_home -v 1.8`</span><br><span class=\"line\"># 设置 JDK 12</span><br><span class=\"line\">export JAVA_12_HOME=`/usr/libexec/java_home -v 12`</span><br><span class=\"line\"></span><br><span class=\"line\">export JAVA_HOME=$JAVA_8_HOME</span><br><span class=\"line\">#alias命令动态切换JDK版本</span><br><span class=\"line\">alias jdk8=&quot;export JAVA_HOME=$JAVA_8_HOME&quot;</span><br><span class=\"line\">alias jdk12=&quot;export JAVA_HOME=$JAVA_12_HOME&quot;</span><br></pre></td></tr></table></figure>"},{"title":"Linux-dstat","date":"2019-02-27T10:45:51.000Z","_content":"\n\nhttp://wangyapu.com/2018/03/15/sysetem_optimize/","source":"_posts/Linux-dstat.md","raw":"---\ntitle: Linux-dstat\ndate: 2019-02-27 18:45:51\ntags:\n---\n\n\nhttp://wangyapu.com/2018/03/15/sysetem_optimize/","slug":"Linux-dstat","published":1,"updated":"2019-09-28T08:51:00.907Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o842003qv1np4e3104pj","content":"<p><a href=\"http://wangyapu.com/2018/03/15/sysetem_optimize/\" target=\"_blank\" rel=\"noopener\">http://wangyapu.com/2018/03/15/sysetem_optimize/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://wangyapu.com/2018/03/15/sysetem_optimize/\" target=\"_blank\" rel=\"noopener\">http://wangyapu.com/2018/03/15/sysetem_optimize/</a></p>\n"},{"title":"OS-sync-async-blocking-noblocking","date":"2017-11-01T07:01:02.000Z","_content":"\nhttps://github.com/calidion/calidion.github.io/issues/40","source":"_posts/Linux-sync-async-blocking-noblocking.md","raw":"---\ntitle: OS-sync-async-blocking-noblocking\ndate: 2017-11-01 15:01:02\ntags: Linux\n---\n\nhttps://github.com/calidion/calidion.github.io/issues/40","slug":"Linux-sync-async-blocking-noblocking","published":1,"updated":"2019-09-28T08:51:00.907Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o843003rv1np7gqqe1sy","content":"<p><a href=\"https://github.com/calidion/calidion.github.io/issues/40\" target=\"_blank\" rel=\"noopener\">https://github.com/calidion/calidion.github.io/issues/40</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://github.com/calidion/calidion.github.io/issues/40\" target=\"_blank\" rel=\"noopener\">https://github.com/calidion/calidion.github.io/issues/40</a></p>\n"},{"title":"MySQL-Redo-Log-Flush","date":"2018-08-31T11:05:49.000Z","_content":"\n\nhttps://www.cnblogs.com/xinysu/p/6555082.html","source":"_posts/MySQL-Redo-Log-Flush.md","raw":"---\ntitle: MySQL-Redo-Log-Flush\ndate: 2018-08-31 19:05:49\ntags:\n---\n\n\nhttps://www.cnblogs.com/xinysu/p/6555082.html","slug":"MySQL-Redo-Log-Flush","published":1,"updated":"2019-09-28T08:51:00.908Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o843003sv1npr4fz7sx7","content":"<p><a href=\"https://www.cnblogs.com/xinysu/p/6555082.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/xinysu/p/6555082.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.cnblogs.com/xinysu/p/6555082.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/xinysu/p/6555082.html</a></p>\n"},{"title":"Netty-AdaptiveRecvByteBufAllocator","date":"2019-02-25T10:21:32.000Z","_content":"\n\nThe RecvByteBufAllocator that automatically increases and decreases the predicted buffer size on feed back.\nIt gradually increases the expected number of readable bytes if the previous read fully filled the allocated buffer. It gradually decreases the expected number of readable bytes if the read operation was not able to fill a certain amount of the allocated buffer two times consecutively. Otherwise, it keeps returning the same prediction.\n\n\n避免扩容: ByteBuf的大小预估与AdaptiveRecvByteBufAllocator\nByteBuf如果一开始申请的不足，到极限时会智能的扩容，但也和Java一样，需要重新申请两倍的内存，然后把旧的内容复制过去，一听就是个很消耗的动作，因此，反正是堆外内存池，一开始还是给多一点吧。\n\n另一个有趣的思路是Netty的自适应算法。Netty收到一个请求时，什么都不知道啊，那会申请多大的内存来接收它呢？在Bootstrap里可以配置，默认是 AdaptiveRecvByteBufAllocator，根据每一次收到的请求动态变化。\n\n但如果一个应用有几个不同接口，请求的大小变来变去，会不会玩死它呢？好像会的。不过服务化体系里的特征都是请求小，返回大，请求包的大小变化不会太剧烈。","source":"_posts/Netty-AdaptiveRecvByteBufAllocator.md","raw":"---\ntitle: Netty-AdaptiveRecvByteBufAllocator\ndate: 2019-02-25 18:21:32\ntags:\n---\n\n\nThe RecvByteBufAllocator that automatically increases and decreases the predicted buffer size on feed back.\nIt gradually increases the expected number of readable bytes if the previous read fully filled the allocated buffer. It gradually decreases the expected number of readable bytes if the read operation was not able to fill a certain amount of the allocated buffer two times consecutively. Otherwise, it keeps returning the same prediction.\n\n\n避免扩容: ByteBuf的大小预估与AdaptiveRecvByteBufAllocator\nByteBuf如果一开始申请的不足，到极限时会智能的扩容，但也和Java一样，需要重新申请两倍的内存，然后把旧的内容复制过去，一听就是个很消耗的动作，因此，反正是堆外内存池，一开始还是给多一点吧。\n\n另一个有趣的思路是Netty的自适应算法。Netty收到一个请求时，什么都不知道啊，那会申请多大的内存来接收它呢？在Bootstrap里可以配置，默认是 AdaptiveRecvByteBufAllocator，根据每一次收到的请求动态变化。\n\n但如果一个应用有几个不同接口，请求的大小变来变去，会不会玩死它呢？好像会的。不过服务化体系里的特征都是请求小，返回大，请求包的大小变化不会太剧烈。","slug":"Netty-AdaptiveRecvByteBufAllocator","published":1,"updated":"2019-09-28T08:51:00.908Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o843003tv1npwfsctlff","content":"<p>The RecvByteBufAllocator that automatically increases and decreases the predicted buffer size on feed back.<br>It gradually increases the expected number of readable bytes if the previous read fully filled the allocated buffer. It gradually decreases the expected number of readable bytes if the read operation was not able to fill a certain amount of the allocated buffer two times consecutively. Otherwise, it keeps returning the same prediction.</p>\n<p>避免扩容: ByteBuf的大小预估与AdaptiveRecvByteBufAllocator<br>ByteBuf如果一开始申请的不足，到极限时会智能的扩容，但也和Java一样，需要重新申请两倍的内存，然后把旧的内容复制过去，一听就是个很消耗的动作，因此，反正是堆外内存池，一开始还是给多一点吧。</p>\n<p>另一个有趣的思路是Netty的自适应算法。Netty收到一个请求时，什么都不知道啊，那会申请多大的内存来接收它呢？在Bootstrap里可以配置，默认是 AdaptiveRecvByteBufAllocator，根据每一次收到的请求动态变化。</p>\n<p>但如果一个应用有几个不同接口，请求的大小变来变去，会不会玩死它呢？好像会的。不过服务化体系里的特征都是请求小，返回大，请求包的大小变化不会太剧烈。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>The RecvByteBufAllocator that automatically increases and decreases the predicted buffer size on feed back.<br>It gradually increases the expected number of readable bytes if the previous read fully filled the allocated buffer. It gradually decreases the expected number of readable bytes if the read operation was not able to fill a certain amount of the allocated buffer two times consecutively. Otherwise, it keeps returning the same prediction.</p>\n<p>避免扩容: ByteBuf的大小预估与AdaptiveRecvByteBufAllocator<br>ByteBuf如果一开始申请的不足，到极限时会智能的扩容，但也和Java一样，需要重新申请两倍的内存，然后把旧的内容复制过去，一听就是个很消耗的动作，因此，反正是堆外内存池，一开始还是给多一点吧。</p>\n<p>另一个有趣的思路是Netty的自适应算法。Netty收到一个请求时，什么都不知道啊，那会申请多大的内存来接收它呢？在Bootstrap里可以配置，默认是 AdaptiveRecvByteBufAllocator，根据每一次收到的请求动态变化。</p>\n<p>但如果一个应用有几个不同接口，请求的大小变来变去，会不会玩死它呢？好像会的。不过服务化体系里的特征都是请求小，返回大，请求包的大小变化不会太剧烈。</p>\n"},{"title":"MySQL-MVCC","date":"2018-08-31T11:04:03.000Z","_content":"\n### MVCC实现原理——undo log\nhttps://www.cnblogs.com/chenpingzhao/p/5065316.html","source":"_posts/MySQL-MVCC.md","raw":"---\ntitle: MySQL-MVCC\ndate: 2018-08-31 19:04:03\ntags:\n---\n\n### MVCC实现原理——undo log\nhttps://www.cnblogs.com/chenpingzhao/p/5065316.html","slug":"MySQL-MVCC","published":1,"updated":"2019-09-28T08:51:00.907Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o844003uv1npfl56drxd","content":"<h3 id=\"MVCC实现原理——undo-log\"><a href=\"#MVCC实现原理——undo-log\" class=\"headerlink\" title=\"MVCC实现原理——undo log\"></a>MVCC实现原理——undo log</h3><p><a href=\"https://www.cnblogs.com/chenpingzhao/p/5065316.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/chenpingzhao/p/5065316.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"MVCC实现原理——undo-log\"><a href=\"#MVCC实现原理——undo-log\" class=\"headerlink\" title=\"MVCC实现原理——undo log\"></a>MVCC实现原理——undo log</h3><p><a href=\"https://www.cnblogs.com/chenpingzhao/p/5065316.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/chenpingzhao/p/5065316.html</a></p>\n"},{"title":"Netty-Bind-Port","date":"2017-12-04T02:05:04.000Z","_content":"\n``` java\n@Override\npublic void execute(Runnable task) {\n    if (task == null) {\n        throw new NullPointerException(\"task\");\n    }\n\n    boolean inEventLoop = inEventLoop();\n    if (inEventLoop) {\n        addTask(task);\n    } else {\n        // 启动 eventLoop\n        startThread();\n        addTask(task);\n        if (isShutdown() && removeTask(task)) {\n            reject();\n        }\n    }\n\n    if (!addTaskWakesUp && wakesUpForTask(task)) {\n        wakeup(inEventLoop);\n    }\n}\n\nprivate void doStartThread() {\n    assert thread == null;\n    executor.execute(new Runnable() {\n        @Override\n        public void run() {\n            thread = Thread.currentThread();\n            if (interrupted) {\n                thread.interrupt();\n            }\n\n            boolean success = false;\n            updateLastExecutionTime();\n            try {\n                SingleThreadEventExecutor.this.run();\n                success = true;\n            } catch (Throwable t) {\n                logger.warn(\"Unexpected exception from an event executor: \", t);\n            } finally {\n                for (;;) {\n                    int oldState = STATE_UPDATER.get(SingleThreadEventExecutor.this);\n                    if (oldState >= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet(\n                            SingleThreadEventExecutor.this, oldState, ST_SHUTTING_DOWN)) {\n                        break;\n                    }\n                }\n\n                // Check if confirmShutdown() was called at the end of the loop.\n                if (success && gracefulShutdownStartTime == 0) {\n                    logger.error(\"Buggy \" + EventExecutor.class.getSimpleName() + \" implementation; \" +\n                            SingleThreadEventExecutor.class.getSimpleName() + \".confirmShutdown() must be called \" +\n                            \"before run() implementation terminates.\");\n                }\n\n                try {\n                    // Run all remaining tasks and shutdown hooks.\n                    for (;;) {\n                        if (confirmShutdown()) {\n                            break;\n                        }\n                    }\n                } finally {\n                    try {\n                        cleanup();\n                    } finally {\n                        STATE_UPDATER.set(SingleThreadEventExecutor.this, ST_TERMINATED);\n                        threadLock.release();\n                        if (!taskQueue.isEmpty()) {\n                            logger.warn(\n                                    \"An event executor terminated with \" +\n                                            \"non-empty task queue (\" + taskQueue.size() + ')');\n                        }\n\n                        terminationFuture.setSuccess(null);\n                    }\n                }\n            }\n        }\n    });\n}\n\n\n@Override\nprotected void run() {\n    for (;;) {\n        try {\n            switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) {\n                case SelectStrategy.CONTINUE:\n                    continue;\n                case SelectStrategy.SELECT:\n                    select(wakenUp.getAndSet(false));\n\n                    // 'wakenUp.compareAndSet(false, true)' is always evaluated\n                    // before calling 'selector.wakeup()' to reduce the wake-up\n                    // overhead. (Selector.wakeup() is an expensive operation.)\n                    //\n                    // However, there is a race condition in this approach.\n                    // The race condition is triggered when 'wakenUp' is set to\n                    // true too early.\n                    //\n                    // 'wakenUp' is set to true too early if:\n                    // 1) Selector is waken up between 'wakenUp.set(false)' and\n                    //    'selector.select(...)'. (BAD)\n                    // 2) Selector is waken up between 'selector.select(...)' and\n                    //    'if (wakenUp.get()) { ... }'. (OK)\n                    //\n                    // In the first case, 'wakenUp' is set to true and the\n                    // following 'selector.select(...)' will wake up immediately.\n                    // Until 'wakenUp' is set to false again in the next round,\n                    // 'wakenUp.compareAndSet(false, true)' will fail, and therefore\n                    // any attempt to wake up the Selector will fail, too, causing\n                    // the following 'selector.select(...)' call to block\n                    // unnecessarily.\n                    //\n                    // To fix this problem, we wake up the selector again if wakenUp\n                    // is true immediately after selector.select(...).\n                    // It is inefficient in that it wakes up the selector for both\n                    // the first case (BAD - wake-up required) and the second case\n                    // (OK - no wake-up required).\n\n                    if (wakenUp.get()) {\n                        selector.wakeup();\n                    }\n                default:\n                    // fallthrough\n            }\n\n            cancelledKeys = 0;\n            needsToSelectAgain = false;\n            final int ioRatio = this.ioRatio;\n            if (ioRatio == 100) {\n                try {\n                    processSelectedKeys();\n                } finally {\n                    // Ensure we always run tasks.\n                    runAllTasks();\n                }\n            } else {\n                final long ioStartTime = System.nanoTime();\n                try {\n                    processSelectedKeys();\n                } finally {\n                    // Ensure we always run tasks.\n                    final long ioTime = System.nanoTime() - ioStartTime;\n                    runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n                }\n            }\n        } catch (Throwable t) {\n            handleLoopException(t);\n        }\n        // Always handle shutdown even if the loop processing threw an exception.\n        try {\n            if (isShuttingDown()) {\n                closeAll();\n                if (confirmShutdown()) {\n                    return;\n                }\n            }\n        } catch (Throwable t) {\n            handleLoopException(t);\n        }\n    }\n}\n```\n\n``` java\nfinal long ioStartTime = System.nanoTime();\ntry {\n    processSelectedKeys();\n} finally {\n    // Ensure we always run tasks.\n    final long ioTime = System.nanoTime() - ioStartTime;\n    runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n}\n```\n\nhttps://github.com/netty/netty/issues/6058\nprocessSelectedKeys();指的是IO任务\nrunAllTasks();指的是除了IO的任务\n\nioTime / (n + ioTime) = ioRatio / (100)\n=> n = ioTime * (100 - ioRatio) / ioRatio\n\nhttp://budairenqin.iteye.com/blog/2215896","source":"_posts/Netty-Bind-Port.md","raw":"---\ntitle: Netty-Bind-Port\ndate: 2017-12-04 10:05:04\ntags: Netty\n---\n\n``` java\n@Override\npublic void execute(Runnable task) {\n    if (task == null) {\n        throw new NullPointerException(\"task\");\n    }\n\n    boolean inEventLoop = inEventLoop();\n    if (inEventLoop) {\n        addTask(task);\n    } else {\n        // 启动 eventLoop\n        startThread();\n        addTask(task);\n        if (isShutdown() && removeTask(task)) {\n            reject();\n        }\n    }\n\n    if (!addTaskWakesUp && wakesUpForTask(task)) {\n        wakeup(inEventLoop);\n    }\n}\n\nprivate void doStartThread() {\n    assert thread == null;\n    executor.execute(new Runnable() {\n        @Override\n        public void run() {\n            thread = Thread.currentThread();\n            if (interrupted) {\n                thread.interrupt();\n            }\n\n            boolean success = false;\n            updateLastExecutionTime();\n            try {\n                SingleThreadEventExecutor.this.run();\n                success = true;\n            } catch (Throwable t) {\n                logger.warn(\"Unexpected exception from an event executor: \", t);\n            } finally {\n                for (;;) {\n                    int oldState = STATE_UPDATER.get(SingleThreadEventExecutor.this);\n                    if (oldState >= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet(\n                            SingleThreadEventExecutor.this, oldState, ST_SHUTTING_DOWN)) {\n                        break;\n                    }\n                }\n\n                // Check if confirmShutdown() was called at the end of the loop.\n                if (success && gracefulShutdownStartTime == 0) {\n                    logger.error(\"Buggy \" + EventExecutor.class.getSimpleName() + \" implementation; \" +\n                            SingleThreadEventExecutor.class.getSimpleName() + \".confirmShutdown() must be called \" +\n                            \"before run() implementation terminates.\");\n                }\n\n                try {\n                    // Run all remaining tasks and shutdown hooks.\n                    for (;;) {\n                        if (confirmShutdown()) {\n                            break;\n                        }\n                    }\n                } finally {\n                    try {\n                        cleanup();\n                    } finally {\n                        STATE_UPDATER.set(SingleThreadEventExecutor.this, ST_TERMINATED);\n                        threadLock.release();\n                        if (!taskQueue.isEmpty()) {\n                            logger.warn(\n                                    \"An event executor terminated with \" +\n                                            \"non-empty task queue (\" + taskQueue.size() + ')');\n                        }\n\n                        terminationFuture.setSuccess(null);\n                    }\n                }\n            }\n        }\n    });\n}\n\n\n@Override\nprotected void run() {\n    for (;;) {\n        try {\n            switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) {\n                case SelectStrategy.CONTINUE:\n                    continue;\n                case SelectStrategy.SELECT:\n                    select(wakenUp.getAndSet(false));\n\n                    // 'wakenUp.compareAndSet(false, true)' is always evaluated\n                    // before calling 'selector.wakeup()' to reduce the wake-up\n                    // overhead. (Selector.wakeup() is an expensive operation.)\n                    //\n                    // However, there is a race condition in this approach.\n                    // The race condition is triggered when 'wakenUp' is set to\n                    // true too early.\n                    //\n                    // 'wakenUp' is set to true too early if:\n                    // 1) Selector is waken up between 'wakenUp.set(false)' and\n                    //    'selector.select(...)'. (BAD)\n                    // 2) Selector is waken up between 'selector.select(...)' and\n                    //    'if (wakenUp.get()) { ... }'. (OK)\n                    //\n                    // In the first case, 'wakenUp' is set to true and the\n                    // following 'selector.select(...)' will wake up immediately.\n                    // Until 'wakenUp' is set to false again in the next round,\n                    // 'wakenUp.compareAndSet(false, true)' will fail, and therefore\n                    // any attempt to wake up the Selector will fail, too, causing\n                    // the following 'selector.select(...)' call to block\n                    // unnecessarily.\n                    //\n                    // To fix this problem, we wake up the selector again if wakenUp\n                    // is true immediately after selector.select(...).\n                    // It is inefficient in that it wakes up the selector for both\n                    // the first case (BAD - wake-up required) and the second case\n                    // (OK - no wake-up required).\n\n                    if (wakenUp.get()) {\n                        selector.wakeup();\n                    }\n                default:\n                    // fallthrough\n            }\n\n            cancelledKeys = 0;\n            needsToSelectAgain = false;\n            final int ioRatio = this.ioRatio;\n            if (ioRatio == 100) {\n                try {\n                    processSelectedKeys();\n                } finally {\n                    // Ensure we always run tasks.\n                    runAllTasks();\n                }\n            } else {\n                final long ioStartTime = System.nanoTime();\n                try {\n                    processSelectedKeys();\n                } finally {\n                    // Ensure we always run tasks.\n                    final long ioTime = System.nanoTime() - ioStartTime;\n                    runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n                }\n            }\n        } catch (Throwable t) {\n            handleLoopException(t);\n        }\n        // Always handle shutdown even if the loop processing threw an exception.\n        try {\n            if (isShuttingDown()) {\n                closeAll();\n                if (confirmShutdown()) {\n                    return;\n                }\n            }\n        } catch (Throwable t) {\n            handleLoopException(t);\n        }\n    }\n}\n```\n\n``` java\nfinal long ioStartTime = System.nanoTime();\ntry {\n    processSelectedKeys();\n} finally {\n    // Ensure we always run tasks.\n    final long ioTime = System.nanoTime() - ioStartTime;\n    runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n}\n```\n\nhttps://github.com/netty/netty/issues/6058\nprocessSelectedKeys();指的是IO任务\nrunAllTasks();指的是除了IO的任务\n\nioTime / (n + ioTime) = ioRatio / (100)\n=> n = ioTime * (100 - ioRatio) / ioRatio\n\nhttp://budairenqin.iteye.com/blog/2215896","slug":"Netty-Bind-Port","published":1,"updated":"2019-09-28T08:51:00.908Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o844003vv1npjfsapseo","content":"<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">execute</span><span class=\"params\">(Runnable task)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (task == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> NullPointerException(<span class=\"string\">\"task\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> inEventLoop = inEventLoop();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (inEventLoop) &#123;</span><br><span class=\"line\">        addTask(task);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 启动 eventLoop</span></span><br><span class=\"line\">        startThread();</span><br><span class=\"line\">        addTask(task);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (isShutdown() &amp;&amp; removeTask(task)) &#123;</span><br><span class=\"line\">            reject();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123;</span><br><span class=\"line\">        wakeup(inEventLoop);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">doStartThread</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> thread == <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    executor.execute(<span class=\"keyword\">new</span> Runnable() &#123;</span><br><span class=\"line\">        <span class=\"meta\">@Override</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">            thread = Thread.currentThread();</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (interrupted) &#123;</span><br><span class=\"line\">                thread.interrupt();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">boolean</span> success = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">            updateLastExecutionTime();</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                SingleThreadEventExecutor.<span class=\"keyword\">this</span>.run();</span><br><span class=\"line\">                success = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (Throwable t) &#123;</span><br><span class=\"line\">                logger.warn(<span class=\"string\">\"Unexpected exception from an event executor: \"</span>, t);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">int</span> oldState = STATE_UPDATER.get(SingleThreadEventExecutor.<span class=\"keyword\">this</span>);</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (oldState &gt;= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet(</span><br><span class=\"line\">                            SingleThreadEventExecutor.<span class=\"keyword\">this</span>, oldState, ST_SHUTTING_DOWN)) &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"comment\">// Check if confirmShutdown() was called at the end of the loop.</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (success &amp;&amp; gracefulShutdownStartTime == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                    logger.error(<span class=\"string\">\"Buggy \"</span> + EventExecutor.class.getSimpleName() + <span class=\"string\">\" implementation; \"</span> +</span><br><span class=\"line\">                            SingleThreadEventExecutor.class.getSimpleName() + <span class=\"string\">\".confirmShutdown() must be called \"</span> +</span><br><span class=\"line\">                            <span class=\"string\">\"before run() implementation terminates.\"</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// Run all remaining tasks and shutdown hooks.</span></span><br><span class=\"line\">                    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (confirmShutdown()) &#123;</span><br><span class=\"line\">                            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                        cleanup();</span><br><span class=\"line\">                    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                        STATE_UPDATER.set(SingleThreadEventExecutor.<span class=\"keyword\">this</span>, ST_TERMINATED);</span><br><span class=\"line\">                        threadLock.release();</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (!taskQueue.isEmpty()) &#123;</span><br><span class=\"line\">                            logger.warn(</span><br><span class=\"line\">                                    <span class=\"string\">\"An event executor terminated with \"</span> +</span><br><span class=\"line\">                                            <span class=\"string\">\"non-empty task queue (\"</span> + taskQueue.size() + <span class=\"string\">')'</span>);</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                        terminationFuture.setSuccess(<span class=\"keyword\">null</span>);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">switch</span> (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">case</span> SelectStrategy.CONTINUE:</span><br><span class=\"line\">                    <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">                <span class=\"keyword\">case</span> SelectStrategy.SELECT:</span><br><span class=\"line\">                    select(wakenUp.getAndSet(<span class=\"keyword\">false</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">                    <span class=\"comment\">// 'wakenUp.compareAndSet(false, true)' is always evaluated</span></span><br><span class=\"line\">                    <span class=\"comment\">// before calling 'selector.wakeup()' to reduce the wake-up</span></span><br><span class=\"line\">                    <span class=\"comment\">// overhead. (Selector.wakeup() is an expensive operation.)</span></span><br><span class=\"line\">                    <span class=\"comment\">//</span></span><br><span class=\"line\">                    <span class=\"comment\">// However, there is a race condition in this approach.</span></span><br><span class=\"line\">                    <span class=\"comment\">// The race condition is triggered when 'wakenUp' is set to</span></span><br><span class=\"line\">                    <span class=\"comment\">// true too early.</span></span><br><span class=\"line\">                    <span class=\"comment\">//</span></span><br><span class=\"line\">                    <span class=\"comment\">// 'wakenUp' is set to true too early if:</span></span><br><span class=\"line\">                    <span class=\"comment\">// 1) Selector is waken up between 'wakenUp.set(false)' and</span></span><br><span class=\"line\">                    <span class=\"comment\">//    'selector.select(...)'. (BAD)</span></span><br><span class=\"line\">                    <span class=\"comment\">// 2) Selector is waken up between 'selector.select(...)' and</span></span><br><span class=\"line\">                    <span class=\"comment\">//    'if (wakenUp.get()) &#123; ... &#125;'. (OK)</span></span><br><span class=\"line\">                    <span class=\"comment\">//</span></span><br><span class=\"line\">                    <span class=\"comment\">// In the first case, 'wakenUp' is set to true and the</span></span><br><span class=\"line\">                    <span class=\"comment\">// following 'selector.select(...)' will wake up immediately.</span></span><br><span class=\"line\">                    <span class=\"comment\">// Until 'wakenUp' is set to false again in the next round,</span></span><br><span class=\"line\">                    <span class=\"comment\">// 'wakenUp.compareAndSet(false, true)' will fail, and therefore</span></span><br><span class=\"line\">                    <span class=\"comment\">// any attempt to wake up the Selector will fail, too, causing</span></span><br><span class=\"line\">                    <span class=\"comment\">// the following 'selector.select(...)' call to block</span></span><br><span class=\"line\">                    <span class=\"comment\">// unnecessarily.</span></span><br><span class=\"line\">                    <span class=\"comment\">//</span></span><br><span class=\"line\">                    <span class=\"comment\">// To fix this problem, we wake up the selector again if wakenUp</span></span><br><span class=\"line\">                    <span class=\"comment\">// is true immediately after selector.select(...).</span></span><br><span class=\"line\">                    <span class=\"comment\">// It is inefficient in that it wakes up the selector for both</span></span><br><span class=\"line\">                    <span class=\"comment\">// the first case (BAD - wake-up required) and the second case</span></span><br><span class=\"line\">                    <span class=\"comment\">// (OK - no wake-up required).</span></span><br><span class=\"line\"></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (wakenUp.get()) &#123;</span><br><span class=\"line\">                        selector.wakeup();</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                <span class=\"keyword\">default</span>:</span><br><span class=\"line\">                    <span class=\"comment\">// fallthrough</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            cancelledKeys = <span class=\"number\">0</span>;</span><br><span class=\"line\">            needsToSelectAgain = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">            <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ioRatio = <span class=\"keyword\">this</span>.ioRatio;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (ioRatio == <span class=\"number\">100</span>) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    processSelectedKeys();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// Ensure we always run tasks.</span></span><br><span class=\"line\">                    runAllTasks();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioStartTime = System.nanoTime();</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    processSelectedKeys();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// Ensure we always run tasks.</span></span><br><span class=\"line\">                    <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioTime = System.nanoTime() - ioStartTime;</span><br><span class=\"line\">                    runAllTasks(ioTime * (<span class=\"number\">100</span> - ioRatio) / ioRatio);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (Throwable t) &#123;</span><br><span class=\"line\">            handleLoopException(t);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// Always handle shutdown even if the loop processing threw an exception.</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (isShuttingDown()) &#123;</span><br><span class=\"line\">                closeAll();</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (confirmShutdown()) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">return</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (Throwable t) &#123;</span><br><span class=\"line\">            handleLoopException(t);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioStartTime = System.nanoTime();</span><br><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">    processSelectedKeys();</span><br><span class=\"line\">&#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// Ensure we always run tasks.</span></span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioTime = System.nanoTime() - ioStartTime;</span><br><span class=\"line\">    runAllTasks(ioTime * (<span class=\"number\">100</span> - ioRatio) / ioRatio);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://github.com/netty/netty/issues/6058\" target=\"_blank\" rel=\"noopener\">https://github.com/netty/netty/issues/6058</a><br>processSelectedKeys();指的是IO任务<br>runAllTasks();指的是除了IO的任务</p>\n<p>ioTime / (n + ioTime) = ioRatio / (100)<br>=&gt; n = ioTime * (100 - ioRatio) / ioRatio</p>\n<p><a href=\"http://budairenqin.iteye.com/blog/2215896\" target=\"_blank\" rel=\"noopener\">http://budairenqin.iteye.com/blog/2215896</a></p>\n","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">execute</span><span class=\"params\">(Runnable task)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (task == <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> NullPointerException(<span class=\"string\">\"task\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> inEventLoop = inEventLoop();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (inEventLoop) &#123;</span><br><span class=\"line\">        addTask(task);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 启动 eventLoop</span></span><br><span class=\"line\">        startThread();</span><br><span class=\"line\">        addTask(task);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (isShutdown() &amp;&amp; removeTask(task)) &#123;</span><br><span class=\"line\">            reject();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123;</span><br><span class=\"line\">        wakeup(inEventLoop);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">doStartThread</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> thread == <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    executor.execute(<span class=\"keyword\">new</span> Runnable() &#123;</span><br><span class=\"line\">        <span class=\"meta\">@Override</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">            thread = Thread.currentThread();</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (interrupted) &#123;</span><br><span class=\"line\">                thread.interrupt();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">boolean</span> success = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">            updateLastExecutionTime();</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                SingleThreadEventExecutor.<span class=\"keyword\">this</span>.run();</span><br><span class=\"line\">                success = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (Throwable t) &#123;</span><br><span class=\"line\">                logger.warn(<span class=\"string\">\"Unexpected exception from an event executor: \"</span>, t);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">int</span> oldState = STATE_UPDATER.get(SingleThreadEventExecutor.<span class=\"keyword\">this</span>);</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (oldState &gt;= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet(</span><br><span class=\"line\">                            SingleThreadEventExecutor.<span class=\"keyword\">this</span>, oldState, ST_SHUTTING_DOWN)) &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"comment\">// Check if confirmShutdown() was called at the end of the loop.</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (success &amp;&amp; gracefulShutdownStartTime == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                    logger.error(<span class=\"string\">\"Buggy \"</span> + EventExecutor.class.getSimpleName() + <span class=\"string\">\" implementation; \"</span> +</span><br><span class=\"line\">                            SingleThreadEventExecutor.class.getSimpleName() + <span class=\"string\">\".confirmShutdown() must be called \"</span> +</span><br><span class=\"line\">                            <span class=\"string\">\"before run() implementation terminates.\"</span>);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// Run all remaining tasks and shutdown hooks.</span></span><br><span class=\"line\">                    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (confirmShutdown()) &#123;</span><br><span class=\"line\">                            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                        cleanup();</span><br><span class=\"line\">                    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                        STATE_UPDATER.set(SingleThreadEventExecutor.<span class=\"keyword\">this</span>, ST_TERMINATED);</span><br><span class=\"line\">                        threadLock.release();</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (!taskQueue.isEmpty()) &#123;</span><br><span class=\"line\">                            logger.warn(</span><br><span class=\"line\">                                    <span class=\"string\">\"An event executor terminated with \"</span> +</span><br><span class=\"line\">                                            <span class=\"string\">\"non-empty task queue (\"</span> + taskQueue.size() + <span class=\"string\">')'</span>);</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                        terminationFuture.setSuccess(<span class=\"keyword\">null</span>);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">switch</span> (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">case</span> SelectStrategy.CONTINUE:</span><br><span class=\"line\">                    <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">                <span class=\"keyword\">case</span> SelectStrategy.SELECT:</span><br><span class=\"line\">                    select(wakenUp.getAndSet(<span class=\"keyword\">false</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">                    <span class=\"comment\">// 'wakenUp.compareAndSet(false, true)' is always evaluated</span></span><br><span class=\"line\">                    <span class=\"comment\">// before calling 'selector.wakeup()' to reduce the wake-up</span></span><br><span class=\"line\">                    <span class=\"comment\">// overhead. (Selector.wakeup() is an expensive operation.)</span></span><br><span class=\"line\">                    <span class=\"comment\">//</span></span><br><span class=\"line\">                    <span class=\"comment\">// However, there is a race condition in this approach.</span></span><br><span class=\"line\">                    <span class=\"comment\">// The race condition is triggered when 'wakenUp' is set to</span></span><br><span class=\"line\">                    <span class=\"comment\">// true too early.</span></span><br><span class=\"line\">                    <span class=\"comment\">//</span></span><br><span class=\"line\">                    <span class=\"comment\">// 'wakenUp' is set to true too early if:</span></span><br><span class=\"line\">                    <span class=\"comment\">// 1) Selector is waken up between 'wakenUp.set(false)' and</span></span><br><span class=\"line\">                    <span class=\"comment\">//    'selector.select(...)'. (BAD)</span></span><br><span class=\"line\">                    <span class=\"comment\">// 2) Selector is waken up between 'selector.select(...)' and</span></span><br><span class=\"line\">                    <span class=\"comment\">//    'if (wakenUp.get()) &#123; ... &#125;'. (OK)</span></span><br><span class=\"line\">                    <span class=\"comment\">//</span></span><br><span class=\"line\">                    <span class=\"comment\">// In the first case, 'wakenUp' is set to true and the</span></span><br><span class=\"line\">                    <span class=\"comment\">// following 'selector.select(...)' will wake up immediately.</span></span><br><span class=\"line\">                    <span class=\"comment\">// Until 'wakenUp' is set to false again in the next round,</span></span><br><span class=\"line\">                    <span class=\"comment\">// 'wakenUp.compareAndSet(false, true)' will fail, and therefore</span></span><br><span class=\"line\">                    <span class=\"comment\">// any attempt to wake up the Selector will fail, too, causing</span></span><br><span class=\"line\">                    <span class=\"comment\">// the following 'selector.select(...)' call to block</span></span><br><span class=\"line\">                    <span class=\"comment\">// unnecessarily.</span></span><br><span class=\"line\">                    <span class=\"comment\">//</span></span><br><span class=\"line\">                    <span class=\"comment\">// To fix this problem, we wake up the selector again if wakenUp</span></span><br><span class=\"line\">                    <span class=\"comment\">// is true immediately after selector.select(...).</span></span><br><span class=\"line\">                    <span class=\"comment\">// It is inefficient in that it wakes up the selector for both</span></span><br><span class=\"line\">                    <span class=\"comment\">// the first case (BAD - wake-up required) and the second case</span></span><br><span class=\"line\">                    <span class=\"comment\">// (OK - no wake-up required).</span></span><br><span class=\"line\"></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (wakenUp.get()) &#123;</span><br><span class=\"line\">                        selector.wakeup();</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                <span class=\"keyword\">default</span>:</span><br><span class=\"line\">                    <span class=\"comment\">// fallthrough</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            cancelledKeys = <span class=\"number\">0</span>;</span><br><span class=\"line\">            needsToSelectAgain = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">            <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ioRatio = <span class=\"keyword\">this</span>.ioRatio;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (ioRatio == <span class=\"number\">100</span>) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    processSelectedKeys();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// Ensure we always run tasks.</span></span><br><span class=\"line\">                    runAllTasks();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioStartTime = System.nanoTime();</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    processSelectedKeys();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// Ensure we always run tasks.</span></span><br><span class=\"line\">                    <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioTime = System.nanoTime() - ioStartTime;</span><br><span class=\"line\">                    runAllTasks(ioTime * (<span class=\"number\">100</span> - ioRatio) / ioRatio);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (Throwable t) &#123;</span><br><span class=\"line\">            handleLoopException(t);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// Always handle shutdown even if the loop processing threw an exception.</span></span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (isShuttingDown()) &#123;</span><br><span class=\"line\">                closeAll();</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (confirmShutdown()) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">return</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (Throwable t) &#123;</span><br><span class=\"line\">            handleLoopException(t);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioStartTime = System.nanoTime();</span><br><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">    processSelectedKeys();</span><br><span class=\"line\">&#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// Ensure we always run tasks.</span></span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> ioTime = System.nanoTime() - ioStartTime;</span><br><span class=\"line\">    runAllTasks(ioTime * (<span class=\"number\">100</span> - ioRatio) / ioRatio);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://github.com/netty/netty/issues/6058\" target=\"_blank\" rel=\"noopener\">https://github.com/netty/netty/issues/6058</a><br>processSelectedKeys();指的是IO任务<br>runAllTasks();指的是除了IO的任务</p>\n<p>ioTime / (n + ioTime) = ioRatio / (100)<br>=&gt; n = ioTime * (100 - ioRatio) / ioRatio</p>\n<p><a href=\"http://budairenqin.iteye.com/blog/2215896\" target=\"_blank\" rel=\"noopener\">http://budairenqin.iteye.com/blog/2215896</a></p>\n"},{"title":"MySQL-Transaction-isolation","date":"2018-09-07T02:17:32.000Z","_content":"\n### 也可以看看这篇文章\nhttps://www.cnblogs.com/JohnABC/p/3521061.html\n\n### 什么是标准的事务隔离级别\n事务隔离级别是来界定事务与事务之间数据可见性的程度。\n在ANIS SQL标准中一共4种，按照可见性程度的从大到小，分别是：\nREAD UNCOMMITTED「可读未提交」\nREAD COMMITTED「读已提交」\nREPEATABLE READ「重复一致读」\nSERIALIZABLE「串行读」\n不是所有的数据库都完整实现了这四种隔离级别，至于其它数据库具体的情况不在本文讨论范围内，但是MySQL中的InnoDB存储引擎很好的实现了这4种级别。\n举个栗子，我们有一张balance（余额）表，\n\n```\nCREATE TABLE `mysql_learn`.`balance` (\n  `id` INT NOT NULL AUTO_INCREMENT,\n  `user_id` BIGINT(20) NULL,\n  `count` DECIMAL(2) NULL,\n  `version` BIGINT(20) NULL,\n  PRIMARY KEY (`id`),\n  INDEX `user_id_idx` (`user_id` ASC)\n);\n```\n\nid | user_id | count | version \n----|------|---|--|\n1 | 1  | 1000.00 | 1\n\n*READ UNCOMMITTED\n\n```\nSET TX_ISOLATION = 'READ UNCOMMITTED';\n```\n\nTX A | TX B \n---|---\nBegin |\nselect count from balance where user_id = 1; // 返回1000.00 |\n| Begin\n| update balance set count = 2000 where user_id = 1;\nselect count from balance where user_id = 1; // 返回2000.00 |\n| Rollback\nselect count from balance where user_id = 1; // 返回1000.00 |\nCommit |\n\n所有命令执行的顺序是从上往下的（下同），特别注意下A事务，在该事务中执行了3次「select count from balance where user_id = 1」，但每次与上一次的结果都不一样，原因是两个事务之间，隔离得「不够彻底」，当B事务还没有「Commit」或者「Rollback」的时候，A事务就能「偷窥」到它内部的数据，显然，这个数据是「脏」的（dirty），我们称这种现象为「脏读」。\n\n*READ COMMITTED\n\n        SET GLOBAL_TX = 'READ COMMITTED';\n\nTX A | TX B \n---|---\nBegin |\nselect count from balance where user_id = 1; // 返回1000.00 |\n| Begin\n| update balance set count = 2000 where user_id = 1;\nselect count from balance where user_id = 1; // 返回1000.00 |\n| Commit\nselect count from balance where user_id = 1; // 返回2000.00 |\n加一个update语句 |\nCommit |\n\n这一次，我们再次关注A事务，在B事务没有提交的时候，A事务读取到的值始终是1000，而当B事务提交了数据更新时，即使A事务还没有提交，也可以「Read」到B事务「Commited」的数据变化，符合该级别的名称，这种现象也叫幻读「Phantom Problem」，专业的解释是指在同一事务下，连续执行两次同样的SQL语句可能会导致不同的结果。所以这种隔离级别可以去实现乐观锁。但是，熟悉MySQL的人都知道它的默认级别「REPEATABLE READ」，与上面的例子一样的情况下，会有不一样的表现，下个例子说明。\n\nTX A | TX B \n---|---\nBegin |\nselect count from balance where user_id = 1; // 返回1000.00 |\nupdate balance set count = 2000 where user_id = 1; |\n| Begin\n| update balance set count = 3000 where user_id = 1;\nselect count from balance where user_id = 1; // 返回2000.00 |\n| Commit\nselect count from balance where user_id = 1; // 返回3000.00 |\nCommit |\n\n*REPEATABLE READ\n\n        SET @@TX_ISOLATION = 'REPEATABLE READ';\n\nTX A | TX B | TX C\n---|---|---\nBegin || \nselect count from balance where user_id = 1; // 返回1000.00 ||\n| Begin |\n| update balance set count = 2000 where user_id = 1; |\nselect count from balance where user_id = 1; // 返回1000.00 ||\n| Commit\n||Begin\n|| select count from balance where user_id = 1; // 返回2000.00\nselect count from balance where user_id = 1; // 返回1000.00 ||\nCommit ||Commit\n\n当要说明这个隔离级别的时候，我们又加了一个C事务，先从A和B事务入手，与「READ COMMITTED」唯一的区别是，在B事务提交了「update balance set count = 2000 where user_id = 1」之后，A事务提交之前，A事务「Repetitive」得「Read」，得到的结果却总是一致的，同样在这个时候，C事务进来，但C事务却能读到B事务已经提交的数据更新。总结下，该级别的特点就是在同一个事务中，同一条SELECT语句读到的数据总是一致的，即使其它的事务已经对SELECT的记录修改并且提交了，这样就解决了幻读的问题。\n*问题来了，为什么设计者需要把默认隔离级别设置成「REPEATABLE READ」，事务A和B中对于同一条记录有两个不同版本，又是怎么实现的，且听后文分解「TBD」。\n\nTX A | TX B \n---|---\nBegin |\nselect count from balance where user_id = 1; // 返回1000.00 |\nupdate balance set count = 2000 where user_id = 1; |\n| Begin\n| update balance set count = 3000 where user_id = 1; //阻塞\nselect count from balance where user_id = 1; // 返回2000.00 |\nselect count from balance where user_id = 1; // 返回3000.00 |\nCommit |\n| Commit\n\n*SERIALIZABLE\n由于是串行的，所以高并发下性能有很大问题。","source":"_posts/MySQL-Transaction-isolation.md","raw":"---\ntitle: MySQL-Transaction-isolation\ndate: 2018-09-07 10:17:32\ntags:\n---\n\n### 也可以看看这篇文章\nhttps://www.cnblogs.com/JohnABC/p/3521061.html\n\n### 什么是标准的事务隔离级别\n事务隔离级别是来界定事务与事务之间数据可见性的程度。\n在ANIS SQL标准中一共4种，按照可见性程度的从大到小，分别是：\nREAD UNCOMMITTED「可读未提交」\nREAD COMMITTED「读已提交」\nREPEATABLE READ「重复一致读」\nSERIALIZABLE「串行读」\n不是所有的数据库都完整实现了这四种隔离级别，至于其它数据库具体的情况不在本文讨论范围内，但是MySQL中的InnoDB存储引擎很好的实现了这4种级别。\n举个栗子，我们有一张balance（余额）表，\n\n```\nCREATE TABLE `mysql_learn`.`balance` (\n  `id` INT NOT NULL AUTO_INCREMENT,\n  `user_id` BIGINT(20) NULL,\n  `count` DECIMAL(2) NULL,\n  `version` BIGINT(20) NULL,\n  PRIMARY KEY (`id`),\n  INDEX `user_id_idx` (`user_id` ASC)\n);\n```\n\nid | user_id | count | version \n----|------|---|--|\n1 | 1  | 1000.00 | 1\n\n*READ UNCOMMITTED\n\n```\nSET TX_ISOLATION = 'READ UNCOMMITTED';\n```\n\nTX A | TX B \n---|---\nBegin |\nselect count from balance where user_id = 1; // 返回1000.00 |\n| Begin\n| update balance set count = 2000 where user_id = 1;\nselect count from balance where user_id = 1; // 返回2000.00 |\n| Rollback\nselect count from balance where user_id = 1; // 返回1000.00 |\nCommit |\n\n所有命令执行的顺序是从上往下的（下同），特别注意下A事务，在该事务中执行了3次「select count from balance where user_id = 1」，但每次与上一次的结果都不一样，原因是两个事务之间，隔离得「不够彻底」，当B事务还没有「Commit」或者「Rollback」的时候，A事务就能「偷窥」到它内部的数据，显然，这个数据是「脏」的（dirty），我们称这种现象为「脏读」。\n\n*READ COMMITTED\n\n        SET GLOBAL_TX = 'READ COMMITTED';\n\nTX A | TX B \n---|---\nBegin |\nselect count from balance where user_id = 1; // 返回1000.00 |\n| Begin\n| update balance set count = 2000 where user_id = 1;\nselect count from balance where user_id = 1; // 返回1000.00 |\n| Commit\nselect count from balance where user_id = 1; // 返回2000.00 |\n加一个update语句 |\nCommit |\n\n这一次，我们再次关注A事务，在B事务没有提交的时候，A事务读取到的值始终是1000，而当B事务提交了数据更新时，即使A事务还没有提交，也可以「Read」到B事务「Commited」的数据变化，符合该级别的名称，这种现象也叫幻读「Phantom Problem」，专业的解释是指在同一事务下，连续执行两次同样的SQL语句可能会导致不同的结果。所以这种隔离级别可以去实现乐观锁。但是，熟悉MySQL的人都知道它的默认级别「REPEATABLE READ」，与上面的例子一样的情况下，会有不一样的表现，下个例子说明。\n\nTX A | TX B \n---|---\nBegin |\nselect count from balance where user_id = 1; // 返回1000.00 |\nupdate balance set count = 2000 where user_id = 1; |\n| Begin\n| update balance set count = 3000 where user_id = 1;\nselect count from balance where user_id = 1; // 返回2000.00 |\n| Commit\nselect count from balance where user_id = 1; // 返回3000.00 |\nCommit |\n\n*REPEATABLE READ\n\n        SET @@TX_ISOLATION = 'REPEATABLE READ';\n\nTX A | TX B | TX C\n---|---|---\nBegin || \nselect count from balance where user_id = 1; // 返回1000.00 ||\n| Begin |\n| update balance set count = 2000 where user_id = 1; |\nselect count from balance where user_id = 1; // 返回1000.00 ||\n| Commit\n||Begin\n|| select count from balance where user_id = 1; // 返回2000.00\nselect count from balance where user_id = 1; // 返回1000.00 ||\nCommit ||Commit\n\n当要说明这个隔离级别的时候，我们又加了一个C事务，先从A和B事务入手，与「READ COMMITTED」唯一的区别是，在B事务提交了「update balance set count = 2000 where user_id = 1」之后，A事务提交之前，A事务「Repetitive」得「Read」，得到的结果却总是一致的，同样在这个时候，C事务进来，但C事务却能读到B事务已经提交的数据更新。总结下，该级别的特点就是在同一个事务中，同一条SELECT语句读到的数据总是一致的，即使其它的事务已经对SELECT的记录修改并且提交了，这样就解决了幻读的问题。\n*问题来了，为什么设计者需要把默认隔离级别设置成「REPEATABLE READ」，事务A和B中对于同一条记录有两个不同版本，又是怎么实现的，且听后文分解「TBD」。\n\nTX A | TX B \n---|---\nBegin |\nselect count from balance where user_id = 1; // 返回1000.00 |\nupdate balance set count = 2000 where user_id = 1; |\n| Begin\n| update balance set count = 3000 where user_id = 1; //阻塞\nselect count from balance where user_id = 1; // 返回2000.00 |\nselect count from balance where user_id = 1; // 返回3000.00 |\nCommit |\n| Commit\n\n*SERIALIZABLE\n由于是串行的，所以高并发下性能有很大问题。","slug":"MySQL-Transaction-isolation","published":1,"updated":"2019-09-28T08:51:00.908Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o845003wv1npjdhxur0v","content":"<h3 id=\"也可以看看这篇文章\"><a href=\"#也可以看看这篇文章\" class=\"headerlink\" title=\"也可以看看这篇文章\"></a>也可以看看这篇文章</h3><p><a href=\"https://www.cnblogs.com/JohnABC/p/3521061.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/JohnABC/p/3521061.html</a></p>\n<h3 id=\"什么是标准的事务隔离级别\"><a href=\"#什么是标准的事务隔离级别\" class=\"headerlink\" title=\"什么是标准的事务隔离级别\"></a>什么是标准的事务隔离级别</h3><p>事务隔离级别是来界定事务与事务之间数据可见性的程度。<br>在ANIS SQL标准中一共4种，按照可见性程度的从大到小，分别是：<br>READ UNCOMMITTED「可读未提交」<br>READ COMMITTED「读已提交」<br>REPEATABLE READ「重复一致读」<br>SERIALIZABLE「串行读」<br>不是所有的数据库都完整实现了这四种隔离级别，至于其它数据库具体的情况不在本文讨论范围内，但是MySQL中的InnoDB存储引擎很好的实现了这4种级别。<br>举个栗子，我们有一张balance（余额）表，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE TABLE `mysql_learn`.`balance` (</span><br><span class=\"line\">  `id` INT NOT NULL AUTO_INCREMENT,</span><br><span class=\"line\">  `user_id` BIGINT(20) NULL,</span><br><span class=\"line\">  `count` DECIMAL(2) NULL,</span><br><span class=\"line\">  `version` BIGINT(20) NULL,</span><br><span class=\"line\">  PRIMARY KEY (`id`),</span><br><span class=\"line\">  INDEX `user_id_idx` (`user_id` ASC)</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n\n<table>\n<thead>\n<tr>\n<th>id</th>\n<th>user_id</th>\n<th>count</th>\n<th>version</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>1</td>\n<td>1000.00</td>\n<td>1</td>\n</tr>\n</tbody></table>\n<p>*READ UNCOMMITTED</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SET TX_ISOLATION = &apos;READ UNCOMMITTED&apos;;</span><br></pre></td></tr></table></figure>\n\n<table>\n<thead>\n<tr>\n<th>TX A</th>\n<th>TX B</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Begin</td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Begin</td>\n</tr>\n<tr>\n<td></td>\n<td>update balance set count = 2000 where user_id = 1;</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回2000.00</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Rollback</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>Commit</td>\n<td></td>\n</tr>\n</tbody></table>\n<p>所有命令执行的顺序是从上往下的（下同），特别注意下A事务，在该事务中执行了3次「select count from balance where user_id = 1」，但每次与上一次的结果都不一样，原因是两个事务之间，隔离得「不够彻底」，当B事务还没有「Commit」或者「Rollback」的时候，A事务就能「偷窥」到它内部的数据，显然，这个数据是「脏」的（dirty），我们称这种现象为「脏读」。</p>\n<p>*READ COMMITTED</p>\n<pre><code>SET GLOBAL_TX = &apos;READ COMMITTED&apos;;</code></pre><table>\n<thead>\n<tr>\n<th>TX A</th>\n<th>TX B</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Begin</td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Begin</td>\n</tr>\n<tr>\n<td></td>\n<td>update balance set count = 2000 where user_id = 1;</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Commit</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回2000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>加一个update语句</td>\n<td></td>\n</tr>\n<tr>\n<td>Commit</td>\n<td></td>\n</tr>\n</tbody></table>\n<p>这一次，我们再次关注A事务，在B事务没有提交的时候，A事务读取到的值始终是1000，而当B事务提交了数据更新时，即使A事务还没有提交，也可以「Read」到B事务「Commited」的数据变化，符合该级别的名称，这种现象也叫幻读「Phantom Problem」，专业的解释是指在同一事务下，连续执行两次同样的SQL语句可能会导致不同的结果。所以这种隔离级别可以去实现乐观锁。但是，熟悉MySQL的人都知道它的默认级别「REPEATABLE READ」，与上面的例子一样的情况下，会有不一样的表现，下个例子说明。</p>\n<table>\n<thead>\n<tr>\n<th>TX A</th>\n<th>TX B</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Begin</td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>update balance set count = 2000 where user_id = 1;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Begin</td>\n</tr>\n<tr>\n<td></td>\n<td>update balance set count = 3000 where user_id = 1;</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回2000.00</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Commit</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回3000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>Commit</td>\n<td></td>\n</tr>\n</tbody></table>\n<p>*REPEATABLE READ</p>\n<pre><code>SET @@TX_ISOLATION = &apos;REPEATABLE READ&apos;;</code></pre><table>\n<thead>\n<tr>\n<th>TX A</th>\n<th>TX B</th>\n<th>TX C</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Begin</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Begin</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>update balance set count = 2000 where user_id = 1;</td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Commit</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td>Begin</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td>select count from balance where user_id = 1; // 返回2000.00</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Commit</td>\n<td></td>\n<td>Commit</td>\n</tr>\n</tbody></table>\n<p>当要说明这个隔离级别的时候，我们又加了一个C事务，先从A和B事务入手，与「READ COMMITTED」唯一的区别是，在B事务提交了「update balance set count = 2000 where user_id = 1」之后，A事务提交之前，A事务「Repetitive」得「Read」，得到的结果却总是一致的，同样在这个时候，C事务进来，但C事务却能读到B事务已经提交的数据更新。总结下，该级别的特点就是在同一个事务中，同一条SELECT语句读到的数据总是一致的，即使其它的事务已经对SELECT的记录修改并且提交了，这样就解决了幻读的问题。<br>*问题来了，为什么设计者需要把默认隔离级别设置成「REPEATABLE READ」，事务A和B中对于同一条记录有两个不同版本，又是怎么实现的，且听后文分解「TBD」。</p>\n<table>\n<thead>\n<tr>\n<th>TX A</th>\n<th>TX B</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Begin</td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>update balance set count = 2000 where user_id = 1;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Begin</td>\n</tr>\n<tr>\n<td></td>\n<td>update balance set count = 3000 where user_id = 1; //阻塞</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回2000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回3000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>Commit</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Commit</td>\n</tr>\n</tbody></table>\n<p>*SERIALIZABLE<br>由于是串行的，所以高并发下性能有很大问题。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"也可以看看这篇文章\"><a href=\"#也可以看看这篇文章\" class=\"headerlink\" title=\"也可以看看这篇文章\"></a>也可以看看这篇文章</h3><p><a href=\"https://www.cnblogs.com/JohnABC/p/3521061.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/JohnABC/p/3521061.html</a></p>\n<h3 id=\"什么是标准的事务隔离级别\"><a href=\"#什么是标准的事务隔离级别\" class=\"headerlink\" title=\"什么是标准的事务隔离级别\"></a>什么是标准的事务隔离级别</h3><p>事务隔离级别是来界定事务与事务之间数据可见性的程度。<br>在ANIS SQL标准中一共4种，按照可见性程度的从大到小，分别是：<br>READ UNCOMMITTED「可读未提交」<br>READ COMMITTED「读已提交」<br>REPEATABLE READ「重复一致读」<br>SERIALIZABLE「串行读」<br>不是所有的数据库都完整实现了这四种隔离级别，至于其它数据库具体的情况不在本文讨论范围内，但是MySQL中的InnoDB存储引擎很好的实现了这4种级别。<br>举个栗子，我们有一张balance（余额）表，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CREATE TABLE `mysql_learn`.`balance` (</span><br><span class=\"line\">  `id` INT NOT NULL AUTO_INCREMENT,</span><br><span class=\"line\">  `user_id` BIGINT(20) NULL,</span><br><span class=\"line\">  `count` DECIMAL(2) NULL,</span><br><span class=\"line\">  `version` BIGINT(20) NULL,</span><br><span class=\"line\">  PRIMARY KEY (`id`),</span><br><span class=\"line\">  INDEX `user_id_idx` (`user_id` ASC)</span><br><span class=\"line\">);</span><br></pre></td></tr></table></figure>\n\n<table>\n<thead>\n<tr>\n<th>id</th>\n<th>user_id</th>\n<th>count</th>\n<th>version</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>1</td>\n<td>1000.00</td>\n<td>1</td>\n</tr>\n</tbody></table>\n<p>*READ UNCOMMITTED</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SET TX_ISOLATION = &apos;READ UNCOMMITTED&apos;;</span><br></pre></td></tr></table></figure>\n\n<table>\n<thead>\n<tr>\n<th>TX A</th>\n<th>TX B</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Begin</td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Begin</td>\n</tr>\n<tr>\n<td></td>\n<td>update balance set count = 2000 where user_id = 1;</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回2000.00</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Rollback</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>Commit</td>\n<td></td>\n</tr>\n</tbody></table>\n<p>所有命令执行的顺序是从上往下的（下同），特别注意下A事务，在该事务中执行了3次「select count from balance where user_id = 1」，但每次与上一次的结果都不一样，原因是两个事务之间，隔离得「不够彻底」，当B事务还没有「Commit」或者「Rollback」的时候，A事务就能「偷窥」到它内部的数据，显然，这个数据是「脏」的（dirty），我们称这种现象为「脏读」。</p>\n<p>*READ COMMITTED</p>\n<pre><code>SET GLOBAL_TX = &apos;READ COMMITTED&apos;;</code></pre><table>\n<thead>\n<tr>\n<th>TX A</th>\n<th>TX B</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Begin</td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Begin</td>\n</tr>\n<tr>\n<td></td>\n<td>update balance set count = 2000 where user_id = 1;</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Commit</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回2000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>加一个update语句</td>\n<td></td>\n</tr>\n<tr>\n<td>Commit</td>\n<td></td>\n</tr>\n</tbody></table>\n<p>这一次，我们再次关注A事务，在B事务没有提交的时候，A事务读取到的值始终是1000，而当B事务提交了数据更新时，即使A事务还没有提交，也可以「Read」到B事务「Commited」的数据变化，符合该级别的名称，这种现象也叫幻读「Phantom Problem」，专业的解释是指在同一事务下，连续执行两次同样的SQL语句可能会导致不同的结果。所以这种隔离级别可以去实现乐观锁。但是，熟悉MySQL的人都知道它的默认级别「REPEATABLE READ」，与上面的例子一样的情况下，会有不一样的表现，下个例子说明。</p>\n<table>\n<thead>\n<tr>\n<th>TX A</th>\n<th>TX B</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Begin</td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>update balance set count = 2000 where user_id = 1;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Begin</td>\n</tr>\n<tr>\n<td></td>\n<td>update balance set count = 3000 where user_id = 1;</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回2000.00</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Commit</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回3000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>Commit</td>\n<td></td>\n</tr>\n</tbody></table>\n<p>*REPEATABLE READ</p>\n<pre><code>SET @@TX_ISOLATION = &apos;REPEATABLE READ&apos;;</code></pre><table>\n<thead>\n<tr>\n<th>TX A</th>\n<th>TX B</th>\n<th>TX C</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Begin</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Begin</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>update balance set count = 2000 where user_id = 1;</td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Commit</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td>Begin</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td>select count from balance where user_id = 1; // 返回2000.00</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Commit</td>\n<td></td>\n<td>Commit</td>\n</tr>\n</tbody></table>\n<p>当要说明这个隔离级别的时候，我们又加了一个C事务，先从A和B事务入手，与「READ COMMITTED」唯一的区别是，在B事务提交了「update balance set count = 2000 where user_id = 1」之后，A事务提交之前，A事务「Repetitive」得「Read」，得到的结果却总是一致的，同样在这个时候，C事务进来，但C事务却能读到B事务已经提交的数据更新。总结下，该级别的特点就是在同一个事务中，同一条SELECT语句读到的数据总是一致的，即使其它的事务已经对SELECT的记录修改并且提交了，这样就解决了幻读的问题。<br>*问题来了，为什么设计者需要把默认隔离级别设置成「REPEATABLE READ」，事务A和B中对于同一条记录有两个不同版本，又是怎么实现的，且听后文分解「TBD」。</p>\n<table>\n<thead>\n<tr>\n<th>TX A</th>\n<th>TX B</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Begin</td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回1000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>update balance set count = 2000 where user_id = 1;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Begin</td>\n</tr>\n<tr>\n<td></td>\n<td>update balance set count = 3000 where user_id = 1; //阻塞</td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回2000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>select count from balance where user_id = 1; // 返回3000.00</td>\n<td></td>\n</tr>\n<tr>\n<td>Commit</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td>Commit</td>\n</tr>\n</tbody></table>\n<p>*SERIALIZABLE<br>由于是串行的，所以高并发下性能有很大问题。</p>\n"},{"title":"Netty-Async-write","date":"2019-01-14T14:34:47.000Z","_content":"\nNetty中调用``，其实可以分为两个部分--`write` and `flush`，仅仅调用write是不会触发nio底层channel的write操作，而是将数据先放入\n`ChannelOutboundBuffer`中，调用了flush之后，才会真实调用channel的write。\n关于ChannelOutboundBuffer的部分，查看\nhttps://www.jianshu.com/p/311425d1c72f\n\n```\nch.pipeline().addLast(handlerExecutorGroup, \"in1\", new ChannelInboundHandlerAdapter() {\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n        System.out.println(\"handler(in1) write buffer in thread:\" + Thread.currentThread().getName());\n        ChannelFuture channelFuture = ctx.writeAndFlush(msg);\n\n        System.out.println(channelFuture.isDone());\n\n        channelFuture.addListener(new GenericFutureListener<Future<? super Void>>() {\n            @Override\n            public void operationComplete(Future<? super Void> future) throws Exception {\n                // 既然是回调，一定要明确，这个回调是哪个线程执行的。\n\n                // 这里有两种情况会触发调用`operationComplete`\n\n                // 1 在addListener时，会主动尝试调用notifyListeners，只要future.idDone()是true的，那执行这段代码的线程就是执行\n                // `channelRead`的线程，也就是当前Pipeline节点(AbstractChannelHandlerContext)的Executor。\n\n                // 2 在addListener时，future.idDone()返回的是false，所以不会在第一种情况下触发。当nioEventLoop底层的线程在调用了\n                // flush0()之后，也会调用notifyListeners，触发`operationComplete`。调用栈如下所示。但会去判断下是不是在Promise的\n                // EventExecutor执行的，如果不是，会把`notifyListenersNow`作为任务给Promise的EventExecutor执行。Promise的\n                // EventExecutor其实就是当前Pipeline节点(AbstractChannelHandlerContext)的Executor。\n\n                System.out.println(\"write complete in thread:\" + Thread.currentThread().getName());\n            }\n        });\n    }\n});\n\nnotifyListeners():417, DefaultPromise (io.netty.util.concurrent), DefaultPromise.java\ntrySuccess(Object):103, DefaultPromise (io.netty.util.concurrent), DefaultPromise.java\ntrySuccess(Promise, Object, InternalLogger):48, PromiseNotificationUtil (io.netty.util.internal), PromiseNotificationUtil.java\nsafeSuccess(ChannelPromise):703, ChannelOutboundBuffer (io.netty.channel), ChannelOutboundBuffer.java\nremove():258, ChannelOutboundBuffer (io.netty.channel), ChannelOutboundBuffer.java\nremoveBytes(long):338, ChannelOutboundBuffer (io.netty.channel), ChannelOutboundBuffer.java\ndoWrite(ChannelOutboundBuffer):411, NioSocketChannel (io.netty.channel.socket.nio), NioSocketChannel.java\nflush0():938, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java\nflush0():360, AbstractNioChannel$AbstractNioUnsafe (io.netty.channel.nio), AbstractNioChannel.java\nflush():905, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java\nflush(ChannelHandlerContext):1370, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java\ninvokeFlush0():776, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeFlush():768, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\naccess$1500(AbstractChannelHandlerContext):38, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nwrite(AbstractChannelHandlerContext, Object, ChannelPromise):1175, AbstractChannelHandlerContext$WriteAndFlushTask (io.netty.channel), AbstractChannelHandlerContext.java\nrun():1098, AbstractChannelHandlerContext$AbstractWriteTask (io.netty.channel), AbstractChannelHandlerContext.java\nsafeExecute$$$capture(Runnable):163, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java\nsafeExecute(Runnable):-1, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java\n - Async stack trace\naddTask:-1, SingleThreadEventExecutor (io.netty.util.concurrent)\nexecute:756, SingleThreadEventExecutor (io.netty.util.concurrent)\nsafeExecute:1036, AbstractChannelHandlerContext (io.netty.channel)\nwrite:825, AbstractChannelHandlerContext (io.netty.channel)\nwriteAndFlush:794, AbstractChannelHandlerContext (io.netty.channel)\nwriteAndFlush:837, AbstractChannelHandlerContext (io.netty.channel)\nchannelRead:41, HandlerExecutor$1$1 (com.eric)\ninvokeChannelRead:362, AbstractChannelHandlerContext (io.netty.channel)\naccess$600:38, AbstractChannelHandlerContext (io.netty.channel)\nrun:353, AbstractChannelHandlerContext$7 (io.netty.channel)\nrun:54, DefaultEventLoop (io.netty.channel)\nrun:905, SingleThreadEventExecutor$5 (io.netty.util.concurrent)\nrun:30, FastThreadLocalRunnable (io.netty.util.concurrent)\nrun:748, Thread (java.lang)\n```","source":"_posts/Netty-Async-write.md","raw":"---\ntitle: Netty-Async-write\ndate: 2019-01-14 22:34:47\ntags:\n---\n\nNetty中调用``，其实可以分为两个部分--`write` and `flush`，仅仅调用write是不会触发nio底层channel的write操作，而是将数据先放入\n`ChannelOutboundBuffer`中，调用了flush之后，才会真实调用channel的write。\n关于ChannelOutboundBuffer的部分，查看\nhttps://www.jianshu.com/p/311425d1c72f\n\n```\nch.pipeline().addLast(handlerExecutorGroup, \"in1\", new ChannelInboundHandlerAdapter() {\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n        System.out.println(\"handler(in1) write buffer in thread:\" + Thread.currentThread().getName());\n        ChannelFuture channelFuture = ctx.writeAndFlush(msg);\n\n        System.out.println(channelFuture.isDone());\n\n        channelFuture.addListener(new GenericFutureListener<Future<? super Void>>() {\n            @Override\n            public void operationComplete(Future<? super Void> future) throws Exception {\n                // 既然是回调，一定要明确，这个回调是哪个线程执行的。\n\n                // 这里有两种情况会触发调用`operationComplete`\n\n                // 1 在addListener时，会主动尝试调用notifyListeners，只要future.idDone()是true的，那执行这段代码的线程就是执行\n                // `channelRead`的线程，也就是当前Pipeline节点(AbstractChannelHandlerContext)的Executor。\n\n                // 2 在addListener时，future.idDone()返回的是false，所以不会在第一种情况下触发。当nioEventLoop底层的线程在调用了\n                // flush0()之后，也会调用notifyListeners，触发`operationComplete`。调用栈如下所示。但会去判断下是不是在Promise的\n                // EventExecutor执行的，如果不是，会把`notifyListenersNow`作为任务给Promise的EventExecutor执行。Promise的\n                // EventExecutor其实就是当前Pipeline节点(AbstractChannelHandlerContext)的Executor。\n\n                System.out.println(\"write complete in thread:\" + Thread.currentThread().getName());\n            }\n        });\n    }\n});\n\nnotifyListeners():417, DefaultPromise (io.netty.util.concurrent), DefaultPromise.java\ntrySuccess(Object):103, DefaultPromise (io.netty.util.concurrent), DefaultPromise.java\ntrySuccess(Promise, Object, InternalLogger):48, PromiseNotificationUtil (io.netty.util.internal), PromiseNotificationUtil.java\nsafeSuccess(ChannelPromise):703, ChannelOutboundBuffer (io.netty.channel), ChannelOutboundBuffer.java\nremove():258, ChannelOutboundBuffer (io.netty.channel), ChannelOutboundBuffer.java\nremoveBytes(long):338, ChannelOutboundBuffer (io.netty.channel), ChannelOutboundBuffer.java\ndoWrite(ChannelOutboundBuffer):411, NioSocketChannel (io.netty.channel.socket.nio), NioSocketChannel.java\nflush0():938, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java\nflush0():360, AbstractNioChannel$AbstractNioUnsafe (io.netty.channel.nio), AbstractNioChannel.java\nflush():905, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java\nflush(ChannelHandlerContext):1370, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java\ninvokeFlush0():776, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeFlush():768, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\naccess$1500(AbstractChannelHandlerContext):38, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nwrite(AbstractChannelHandlerContext, Object, ChannelPromise):1175, AbstractChannelHandlerContext$WriteAndFlushTask (io.netty.channel), AbstractChannelHandlerContext.java\nrun():1098, AbstractChannelHandlerContext$AbstractWriteTask (io.netty.channel), AbstractChannelHandlerContext.java\nsafeExecute$$$capture(Runnable):163, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java\nsafeExecute(Runnable):-1, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java\n - Async stack trace\naddTask:-1, SingleThreadEventExecutor (io.netty.util.concurrent)\nexecute:756, SingleThreadEventExecutor (io.netty.util.concurrent)\nsafeExecute:1036, AbstractChannelHandlerContext (io.netty.channel)\nwrite:825, AbstractChannelHandlerContext (io.netty.channel)\nwriteAndFlush:794, AbstractChannelHandlerContext (io.netty.channel)\nwriteAndFlush:837, AbstractChannelHandlerContext (io.netty.channel)\nchannelRead:41, HandlerExecutor$1$1 (com.eric)\ninvokeChannelRead:362, AbstractChannelHandlerContext (io.netty.channel)\naccess$600:38, AbstractChannelHandlerContext (io.netty.channel)\nrun:353, AbstractChannelHandlerContext$7 (io.netty.channel)\nrun:54, DefaultEventLoop (io.netty.channel)\nrun:905, SingleThreadEventExecutor$5 (io.netty.util.concurrent)\nrun:30, FastThreadLocalRunnable (io.netty.util.concurrent)\nrun:748, Thread (java.lang)\n```","slug":"Netty-Async-write","published":1,"updated":"2019-09-28T08:51:00.908Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o845003xv1np3tkwai29","content":"<p>Netty中调用``，其实可以分为两个部分–<code>write</code> and <code>flush</code>，仅仅调用write是不会触发nio底层channel的write操作，而是将数据先放入<br><code>ChannelOutboundBuffer</code>中，调用了flush之后，才会真实调用channel的write。<br>关于ChannelOutboundBuffer的部分，查看<br><a href=\"https://www.jianshu.com/p/311425d1c72f\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/311425d1c72f</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ch.pipeline().addLast(handlerExecutorGroup, &quot;in1&quot;, new ChannelInboundHandlerAdapter() &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;</span><br><span class=\"line\">        System.out.println(&quot;handler(in1) write buffer in thread:&quot; + Thread.currentThread().getName());</span><br><span class=\"line\">        ChannelFuture channelFuture = ctx.writeAndFlush(msg);</span><br><span class=\"line\"></span><br><span class=\"line\">        System.out.println(channelFuture.isDone());</span><br><span class=\"line\"></span><br><span class=\"line\">        channelFuture.addListener(new GenericFutureListener&lt;Future&lt;? super Void&gt;&gt;() &#123;</span><br><span class=\"line\">            @Override</span><br><span class=\"line\">            public void operationComplete(Future&lt;? super Void&gt; future) throws Exception &#123;</span><br><span class=\"line\">                // 既然是回调，一定要明确，这个回调是哪个线程执行的。</span><br><span class=\"line\"></span><br><span class=\"line\">                // 这里有两种情况会触发调用`operationComplete`</span><br><span class=\"line\"></span><br><span class=\"line\">                // 1 在addListener时，会主动尝试调用notifyListeners，只要future.idDone()是true的，那执行这段代码的线程就是执行</span><br><span class=\"line\">                // `channelRead`的线程，也就是当前Pipeline节点(AbstractChannelHandlerContext)的Executor。</span><br><span class=\"line\"></span><br><span class=\"line\">                // 2 在addListener时，future.idDone()返回的是false，所以不会在第一种情况下触发。当nioEventLoop底层的线程在调用了</span><br><span class=\"line\">                // flush0()之后，也会调用notifyListeners，触发`operationComplete`。调用栈如下所示。但会去判断下是不是在Promise的</span><br><span class=\"line\">                // EventExecutor执行的，如果不是，会把`notifyListenersNow`作为任务给Promise的EventExecutor执行。Promise的</span><br><span class=\"line\">                // EventExecutor其实就是当前Pipeline节点(AbstractChannelHandlerContext)的Executor。</span><br><span class=\"line\"></span><br><span class=\"line\">                System.out.println(&quot;write complete in thread:&quot; + Thread.currentThread().getName());</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">notifyListeners():417, DefaultPromise (io.netty.util.concurrent), DefaultPromise.java</span><br><span class=\"line\">trySuccess(Object):103, DefaultPromise (io.netty.util.concurrent), DefaultPromise.java</span><br><span class=\"line\">trySuccess(Promise, Object, InternalLogger):48, PromiseNotificationUtil (io.netty.util.internal), PromiseNotificationUtil.java</span><br><span class=\"line\">safeSuccess(ChannelPromise):703, ChannelOutboundBuffer (io.netty.channel), ChannelOutboundBuffer.java</span><br><span class=\"line\">remove():258, ChannelOutboundBuffer (io.netty.channel), ChannelOutboundBuffer.java</span><br><span class=\"line\">removeBytes(long):338, ChannelOutboundBuffer (io.netty.channel), ChannelOutboundBuffer.java</span><br><span class=\"line\">doWrite(ChannelOutboundBuffer):411, NioSocketChannel (io.netty.channel.socket.nio), NioSocketChannel.java</span><br><span class=\"line\">flush0():938, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java</span><br><span class=\"line\">flush0():360, AbstractNioChannel$AbstractNioUnsafe (io.netty.channel.nio), AbstractNioChannel.java</span><br><span class=\"line\">flush():905, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java</span><br><span class=\"line\">flush(ChannelHandlerContext):1370, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java</span><br><span class=\"line\">invokeFlush0():776, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">invokeFlush():768, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">access$1500(AbstractChannelHandlerContext):38, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">write(AbstractChannelHandlerContext, Object, ChannelPromise):1175, AbstractChannelHandlerContext$WriteAndFlushTask (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">run():1098, AbstractChannelHandlerContext$AbstractWriteTask (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">safeExecute$$$capture(Runnable):163, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java</span><br><span class=\"line\">safeExecute(Runnable):-1, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java</span><br><span class=\"line\"> - Async stack trace</span><br><span class=\"line\">addTask:-1, SingleThreadEventExecutor (io.netty.util.concurrent)</span><br><span class=\"line\">execute:756, SingleThreadEventExecutor (io.netty.util.concurrent)</span><br><span class=\"line\">safeExecute:1036, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">write:825, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">writeAndFlush:794, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">writeAndFlush:837, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">channelRead:41, HandlerExecutor$1$1 (com.eric)</span><br><span class=\"line\">invokeChannelRead:362, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">access$600:38, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">run:353, AbstractChannelHandlerContext$7 (io.netty.channel)</span><br><span class=\"line\">run:54, DefaultEventLoop (io.netty.channel)</span><br><span class=\"line\">run:905, SingleThreadEventExecutor$5 (io.netty.util.concurrent)</span><br><span class=\"line\">run:30, FastThreadLocalRunnable (io.netty.util.concurrent)</span><br><span class=\"line\">run:748, Thread (java.lang)</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p>Netty中调用``，其实可以分为两个部分–<code>write</code> and <code>flush</code>，仅仅调用write是不会触发nio底层channel的write操作，而是将数据先放入<br><code>ChannelOutboundBuffer</code>中，调用了flush之后，才会真实调用channel的write。<br>关于ChannelOutboundBuffer的部分，查看<br><a href=\"https://www.jianshu.com/p/311425d1c72f\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/311425d1c72f</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ch.pipeline().addLast(handlerExecutorGroup, &quot;in1&quot;, new ChannelInboundHandlerAdapter() &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;</span><br><span class=\"line\">        System.out.println(&quot;handler(in1) write buffer in thread:&quot; + Thread.currentThread().getName());</span><br><span class=\"line\">        ChannelFuture channelFuture = ctx.writeAndFlush(msg);</span><br><span class=\"line\"></span><br><span class=\"line\">        System.out.println(channelFuture.isDone());</span><br><span class=\"line\"></span><br><span class=\"line\">        channelFuture.addListener(new GenericFutureListener&lt;Future&lt;? super Void&gt;&gt;() &#123;</span><br><span class=\"line\">            @Override</span><br><span class=\"line\">            public void operationComplete(Future&lt;? super Void&gt; future) throws Exception &#123;</span><br><span class=\"line\">                // 既然是回调，一定要明确，这个回调是哪个线程执行的。</span><br><span class=\"line\"></span><br><span class=\"line\">                // 这里有两种情况会触发调用`operationComplete`</span><br><span class=\"line\"></span><br><span class=\"line\">                // 1 在addListener时，会主动尝试调用notifyListeners，只要future.idDone()是true的，那执行这段代码的线程就是执行</span><br><span class=\"line\">                // `channelRead`的线程，也就是当前Pipeline节点(AbstractChannelHandlerContext)的Executor。</span><br><span class=\"line\"></span><br><span class=\"line\">                // 2 在addListener时，future.idDone()返回的是false，所以不会在第一种情况下触发。当nioEventLoop底层的线程在调用了</span><br><span class=\"line\">                // flush0()之后，也会调用notifyListeners，触发`operationComplete`。调用栈如下所示。但会去判断下是不是在Promise的</span><br><span class=\"line\">                // EventExecutor执行的，如果不是，会把`notifyListenersNow`作为任务给Promise的EventExecutor执行。Promise的</span><br><span class=\"line\">                // EventExecutor其实就是当前Pipeline节点(AbstractChannelHandlerContext)的Executor。</span><br><span class=\"line\"></span><br><span class=\"line\">                System.out.println(&quot;write complete in thread:&quot; + Thread.currentThread().getName());</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">notifyListeners():417, DefaultPromise (io.netty.util.concurrent), DefaultPromise.java</span><br><span class=\"line\">trySuccess(Object):103, DefaultPromise (io.netty.util.concurrent), DefaultPromise.java</span><br><span class=\"line\">trySuccess(Promise, Object, InternalLogger):48, PromiseNotificationUtil (io.netty.util.internal), PromiseNotificationUtil.java</span><br><span class=\"line\">safeSuccess(ChannelPromise):703, ChannelOutboundBuffer (io.netty.channel), ChannelOutboundBuffer.java</span><br><span class=\"line\">remove():258, ChannelOutboundBuffer (io.netty.channel), ChannelOutboundBuffer.java</span><br><span class=\"line\">removeBytes(long):338, ChannelOutboundBuffer (io.netty.channel), ChannelOutboundBuffer.java</span><br><span class=\"line\">doWrite(ChannelOutboundBuffer):411, NioSocketChannel (io.netty.channel.socket.nio), NioSocketChannel.java</span><br><span class=\"line\">flush0():938, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java</span><br><span class=\"line\">flush0():360, AbstractNioChannel$AbstractNioUnsafe (io.netty.channel.nio), AbstractNioChannel.java</span><br><span class=\"line\">flush():905, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java</span><br><span class=\"line\">flush(ChannelHandlerContext):1370, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java</span><br><span class=\"line\">invokeFlush0():776, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">invokeFlush():768, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">access$1500(AbstractChannelHandlerContext):38, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">write(AbstractChannelHandlerContext, Object, ChannelPromise):1175, AbstractChannelHandlerContext$WriteAndFlushTask (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">run():1098, AbstractChannelHandlerContext$AbstractWriteTask (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">safeExecute$$$capture(Runnable):163, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java</span><br><span class=\"line\">safeExecute(Runnable):-1, AbstractEventExecutor (io.netty.util.concurrent), AbstractEventExecutor.java</span><br><span class=\"line\"> - Async stack trace</span><br><span class=\"line\">addTask:-1, SingleThreadEventExecutor (io.netty.util.concurrent)</span><br><span class=\"line\">execute:756, SingleThreadEventExecutor (io.netty.util.concurrent)</span><br><span class=\"line\">safeExecute:1036, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">write:825, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">writeAndFlush:794, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">writeAndFlush:837, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">channelRead:41, HandlerExecutor$1$1 (com.eric)</span><br><span class=\"line\">invokeChannelRead:362, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">access$600:38, AbstractChannelHandlerContext (io.netty.channel)</span><br><span class=\"line\">run:353, AbstractChannelHandlerContext$7 (io.netty.channel)</span><br><span class=\"line\">run:54, DefaultEventLoop (io.netty.channel)</span><br><span class=\"line\">run:905, SingleThreadEventExecutor$5 (io.netty.util.concurrent)</span><br><span class=\"line\">run:30, FastThreadLocalRunnable (io.netty.util.concurrent)</span><br><span class=\"line\">run:748, Thread (java.lang)</span><br></pre></td></tr></table></figure>"},{"title":"Netty-Buffer-Allocator","date":"2017-11-15T02:05:55.000Z","_content":"\npage  - a page is the smallest unit of memory chunk that can be allocated\n\n一般操作系统的内存page都是4kb    既然这么讲，不是可以     byte a = 1; 这样不就是分配了一个byte么???\n\nhttp://www.jianshu.com/p/cec977b28079\n\nhttp://www.jianshu.com/u/dbcfb30ec5e4","source":"_posts/Netty-Buffer-Allocator.md","raw":"---\ntitle: Netty-Buffer-Allocator\ndate: 2017-11-15 10:05:55\ntags: Netty\n---\n\npage  - a page is the smallest unit of memory chunk that can be allocated\n\n一般操作系统的内存page都是4kb    既然这么讲，不是可以     byte a = 1; 这样不就是分配了一个byte么???\n\nhttp://www.jianshu.com/p/cec977b28079\n\nhttp://www.jianshu.com/u/dbcfb30ec5e4","slug":"Netty-Buffer-Allocator","published":1,"updated":"2019-09-28T08:51:00.908Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o845003yv1npkzve6n6o","content":"<p>page  - a page is the smallest unit of memory chunk that can be allocated</p>\n<p>一般操作系统的内存page都是4kb    既然这么讲，不是可以     byte a = 1; 这样不就是分配了一个byte么???</p>\n<p><a href=\"http://www.jianshu.com/p/cec977b28079\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/cec977b28079</a></p>\n<p><a href=\"http://www.jianshu.com/u/dbcfb30ec5e4\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/u/dbcfb30ec5e4</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>page  - a page is the smallest unit of memory chunk that can be allocated</p>\n<p>一般操作系统的内存page都是4kb    既然这么讲，不是可以     byte a = 1; 这样不就是分配了一个byte么???</p>\n<p><a href=\"http://www.jianshu.com/p/cec977b28079\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/cec977b28079</a></p>\n<p><a href=\"http://www.jianshu.com/u/dbcfb30ec5e4\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/u/dbcfb30ec5e4</a></p>\n"},{"title":"Netty-ChannelOption-Backlog","date":"2017-12-07T09:34:59.000Z","_content":"\nhttp://www.jianshu.com/p/e6f2036621f4","source":"_posts/Netty-ChannelOption-Backlog.md","raw":"---\ntitle: Netty-ChannelOption-Backlog\ndate: 2017-12-07 17:34:59\ntags:\n---\n\nhttp://www.jianshu.com/p/e6f2036621f4","slug":"Netty-ChannelOption-Backlog","published":1,"updated":"2019-09-28T08:51:00.908Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o846003zv1nptznyzdle","content":"<p><a href=\"http://www.jianshu.com/p/e6f2036621f4\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/e6f2036621f4</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://www.jianshu.com/p/e6f2036621f4\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/e6f2036621f4</a></p>\n"},{"title":"Netty-ChannelOption","date":"2017-11-20T07:53:52.000Z","_content":"\n\n在用netty作为底层网络通信的时候关于ChannelOption的参数让我一直模糊不清楚，于是去看一下linux网络编程，发现ChannelOption的各种属性在套接字选项中都有对应\n\n下面简单的总结一下ChannelOption的含义已及使用的场景\n\n1、ChannelOption.SO_BACKLOG\n\nhttp://budairenqin.iteye.com/blog/2215899\n\nChannelOption.SO_BACKLOG对应的是tcp/ip协议listen函数中的backlog参数，函数listen(int socketfd,int backlog)用来初始化服务端可连接队列，\n\n服务端处理客户端连接请求是顺序处理的，所以同一时间只能处理一个客户端连接，多个客户端来的时候，服务端将不能处理的客户端连接请求放在队列中等待处理，backlog参数指定了队列的大小\n\n2、ChannelOption.SO_REUSEADDR\n\nChanneOption.SO_REUSEADDR对应于套接字选项中的SO_REUSEADDR，这个参数表示允许重复使用本地地址和端口，\n\n比如，某个服务器进程占用了TCP的80端口进行监听，此时再次监听该端口就会返回错误，使用该参数就可以解决问题，该参数允许共用该端口，这个在服务器程序中比较常使用，\n\n比如某个进程非正常退出，该程序占用的端口可能要被占用一段时间才能允许其他进程使用，而且程序死掉以后，内核一需要一定的时间才能够释放此端口，不设置SO_REUSEADDR\n\n就无法正常使用该端口。\n\n3、ChannelOption.SO_KEEPALIVE\n\nChanneloption.SO_KEEPALIVE参数对应于套接字选项中的SO_KEEPALIVE，该参数用于设置TCP连接，当设置该选项以后，连接会测试链接的状态，这个选项用于可能长时间没有数据交流的\n\n连接。当设置该选项以后，如果在两小时内没有数据的通信时，TCP会自动发送一个活动探测数据报文。\n\n4、ChannelOption.SO_SNDBUF和ChannelOpSNDBUF和ChannelOptiontion.SO_RCVBUF\n\nChannelOption.SO_SNDBUF参数对应于套接字选项中的SO_SNDBUF，ChannelOption.SO_RCVBUF参数对应于套接字选项中的SO_RCVBUF这两个参数用于操作接收缓冲区和发送缓冲区\n\n的大小，接收缓冲区用于保存网络协议站内收到的数据，直到应用程序读取成功，发送缓冲区用于保存发送数据，直到发送成功。\n\n5、ChannelOption.SO_LINGER\n\nChannelOption.SO_LINGER参数对应于套接字选项中的SO_LINGER,Linux内核默认的处理方式是当用户调用close（）方法的时候，函数返回，在可能的情况下，尽量发送数据，不一定保证\n\n会发生剩余的数据，造成了数据的不确定性，使用SO_LINGER可以阻塞close()的调用时间，直到数据完全发送\n\n6、ChannelOption.TCP_NODELAY\n\nChannelOption.TCP_NODELAY参数对应于套接字选项中的TCP_NODELAY,该参数的使用与Nagle算法有关\n\nNagle算法是将小的数据包组装为更大的帧然后进行发送，而不是输入一次发送一次,因此在数据包不足的时候会等待其他数据的到了，组装成大的数据包进行发送，虽然该方式有效提高网络的有效\n\n负载，但是却造成了延时，而该参数的作用就是禁止使用Nagle算法，使用于小数据即时传输，于TCP_NODELAY相对应的是TCP_CORK，该选项是需要等到发送的数据量最大的时候，一次性发送\n\n数据，适用于文件传输。\n\n","source":"_posts/Netty-ChannelOption.md","raw":"---\ntitle: Netty-ChannelOption\ndate: 2017-11-20 15:53:52\ntags: Netty\n---\n\n\n在用netty作为底层网络通信的时候关于ChannelOption的参数让我一直模糊不清楚，于是去看一下linux网络编程，发现ChannelOption的各种属性在套接字选项中都有对应\n\n下面简单的总结一下ChannelOption的含义已及使用的场景\n\n1、ChannelOption.SO_BACKLOG\n\nhttp://budairenqin.iteye.com/blog/2215899\n\nChannelOption.SO_BACKLOG对应的是tcp/ip协议listen函数中的backlog参数，函数listen(int socketfd,int backlog)用来初始化服务端可连接队列，\n\n服务端处理客户端连接请求是顺序处理的，所以同一时间只能处理一个客户端连接，多个客户端来的时候，服务端将不能处理的客户端连接请求放在队列中等待处理，backlog参数指定了队列的大小\n\n2、ChannelOption.SO_REUSEADDR\n\nChanneOption.SO_REUSEADDR对应于套接字选项中的SO_REUSEADDR，这个参数表示允许重复使用本地地址和端口，\n\n比如，某个服务器进程占用了TCP的80端口进行监听，此时再次监听该端口就会返回错误，使用该参数就可以解决问题，该参数允许共用该端口，这个在服务器程序中比较常使用，\n\n比如某个进程非正常退出，该程序占用的端口可能要被占用一段时间才能允许其他进程使用，而且程序死掉以后，内核一需要一定的时间才能够释放此端口，不设置SO_REUSEADDR\n\n就无法正常使用该端口。\n\n3、ChannelOption.SO_KEEPALIVE\n\nChanneloption.SO_KEEPALIVE参数对应于套接字选项中的SO_KEEPALIVE，该参数用于设置TCP连接，当设置该选项以后，连接会测试链接的状态，这个选项用于可能长时间没有数据交流的\n\n连接。当设置该选项以后，如果在两小时内没有数据的通信时，TCP会自动发送一个活动探测数据报文。\n\n4、ChannelOption.SO_SNDBUF和ChannelOpSNDBUF和ChannelOptiontion.SO_RCVBUF\n\nChannelOption.SO_SNDBUF参数对应于套接字选项中的SO_SNDBUF，ChannelOption.SO_RCVBUF参数对应于套接字选项中的SO_RCVBUF这两个参数用于操作接收缓冲区和发送缓冲区\n\n的大小，接收缓冲区用于保存网络协议站内收到的数据，直到应用程序读取成功，发送缓冲区用于保存发送数据，直到发送成功。\n\n5、ChannelOption.SO_LINGER\n\nChannelOption.SO_LINGER参数对应于套接字选项中的SO_LINGER,Linux内核默认的处理方式是当用户调用close（）方法的时候，函数返回，在可能的情况下，尽量发送数据，不一定保证\n\n会发生剩余的数据，造成了数据的不确定性，使用SO_LINGER可以阻塞close()的调用时间，直到数据完全发送\n\n6、ChannelOption.TCP_NODELAY\n\nChannelOption.TCP_NODELAY参数对应于套接字选项中的TCP_NODELAY,该参数的使用与Nagle算法有关\n\nNagle算法是将小的数据包组装为更大的帧然后进行发送，而不是输入一次发送一次,因此在数据包不足的时候会等待其他数据的到了，组装成大的数据包进行发送，虽然该方式有效提高网络的有效\n\n负载，但是却造成了延时，而该参数的作用就是禁止使用Nagle算法，使用于小数据即时传输，于TCP_NODELAY相对应的是TCP_CORK，该选项是需要等到发送的数据量最大的时候，一次性发送\n\n数据，适用于文件传输。\n\n","slug":"Netty-ChannelOption","published":1,"updated":"2019-09-28T08:51:00.909Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8460040v1np6k8huhnv","content":"<p>在用netty作为底层网络通信的时候关于ChannelOption的参数让我一直模糊不清楚，于是去看一下linux网络编程，发现ChannelOption的各种属性在套接字选项中都有对应</p>\n<p>下面简单的总结一下ChannelOption的含义已及使用的场景</p>\n<p>1、ChannelOption.SO_BACKLOG</p>\n<p><a href=\"http://budairenqin.iteye.com/blog/2215899\" target=\"_blank\" rel=\"noopener\">http://budairenqin.iteye.com/blog/2215899</a></p>\n<p>ChannelOption.SO_BACKLOG对应的是tcp/ip协议listen函数中的backlog参数，函数listen(int socketfd,int backlog)用来初始化服务端可连接队列，</p>\n<p>服务端处理客户端连接请求是顺序处理的，所以同一时间只能处理一个客户端连接，多个客户端来的时候，服务端将不能处理的客户端连接请求放在队列中等待处理，backlog参数指定了队列的大小</p>\n<p>2、ChannelOption.SO_REUSEADDR</p>\n<p>ChanneOption.SO_REUSEADDR对应于套接字选项中的SO_REUSEADDR，这个参数表示允许重复使用本地地址和端口，</p>\n<p>比如，某个服务器进程占用了TCP的80端口进行监听，此时再次监听该端口就会返回错误，使用该参数就可以解决问题，该参数允许共用该端口，这个在服务器程序中比较常使用，</p>\n<p>比如某个进程非正常退出，该程序占用的端口可能要被占用一段时间才能允许其他进程使用，而且程序死掉以后，内核一需要一定的时间才能够释放此端口，不设置SO_REUSEADDR</p>\n<p>就无法正常使用该端口。</p>\n<p>3、ChannelOption.SO_KEEPALIVE</p>\n<p>Channeloption.SO_KEEPALIVE参数对应于套接字选项中的SO_KEEPALIVE，该参数用于设置TCP连接，当设置该选项以后，连接会测试链接的状态，这个选项用于可能长时间没有数据交流的</p>\n<p>连接。当设置该选项以后，如果在两小时内没有数据的通信时，TCP会自动发送一个活动探测数据报文。</p>\n<p>4、ChannelOption.SO_SNDBUF和ChannelOpSNDBUF和ChannelOptiontion.SO_RCVBUF</p>\n<p>ChannelOption.SO_SNDBUF参数对应于套接字选项中的SO_SNDBUF，ChannelOption.SO_RCVBUF参数对应于套接字选项中的SO_RCVBUF这两个参数用于操作接收缓冲区和发送缓冲区</p>\n<p>的大小，接收缓冲区用于保存网络协议站内收到的数据，直到应用程序读取成功，发送缓冲区用于保存发送数据，直到发送成功。</p>\n<p>5、ChannelOption.SO_LINGER</p>\n<p>ChannelOption.SO_LINGER参数对应于套接字选项中的SO_LINGER,Linux内核默认的处理方式是当用户调用close（）方法的时候，函数返回，在可能的情况下，尽量发送数据，不一定保证</p>\n<p>会发生剩余的数据，造成了数据的不确定性，使用SO_LINGER可以阻塞close()的调用时间，直到数据完全发送</p>\n<p>6、ChannelOption.TCP_NODELAY</p>\n<p>ChannelOption.TCP_NODELAY参数对应于套接字选项中的TCP_NODELAY,该参数的使用与Nagle算法有关</p>\n<p>Nagle算法是将小的数据包组装为更大的帧然后进行发送，而不是输入一次发送一次,因此在数据包不足的时候会等待其他数据的到了，组装成大的数据包进行发送，虽然该方式有效提高网络的有效</p>\n<p>负载，但是却造成了延时，而该参数的作用就是禁止使用Nagle算法，使用于小数据即时传输，于TCP_NODELAY相对应的是TCP_CORK，该选项是需要等到发送的数据量最大的时候，一次性发送</p>\n<p>数据，适用于文件传输。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在用netty作为底层网络通信的时候关于ChannelOption的参数让我一直模糊不清楚，于是去看一下linux网络编程，发现ChannelOption的各种属性在套接字选项中都有对应</p>\n<p>下面简单的总结一下ChannelOption的含义已及使用的场景</p>\n<p>1、ChannelOption.SO_BACKLOG</p>\n<p><a href=\"http://budairenqin.iteye.com/blog/2215899\" target=\"_blank\" rel=\"noopener\">http://budairenqin.iteye.com/blog/2215899</a></p>\n<p>ChannelOption.SO_BACKLOG对应的是tcp/ip协议listen函数中的backlog参数，函数listen(int socketfd,int backlog)用来初始化服务端可连接队列，</p>\n<p>服务端处理客户端连接请求是顺序处理的，所以同一时间只能处理一个客户端连接，多个客户端来的时候，服务端将不能处理的客户端连接请求放在队列中等待处理，backlog参数指定了队列的大小</p>\n<p>2、ChannelOption.SO_REUSEADDR</p>\n<p>ChanneOption.SO_REUSEADDR对应于套接字选项中的SO_REUSEADDR，这个参数表示允许重复使用本地地址和端口，</p>\n<p>比如，某个服务器进程占用了TCP的80端口进行监听，此时再次监听该端口就会返回错误，使用该参数就可以解决问题，该参数允许共用该端口，这个在服务器程序中比较常使用，</p>\n<p>比如某个进程非正常退出，该程序占用的端口可能要被占用一段时间才能允许其他进程使用，而且程序死掉以后，内核一需要一定的时间才能够释放此端口，不设置SO_REUSEADDR</p>\n<p>就无法正常使用该端口。</p>\n<p>3、ChannelOption.SO_KEEPALIVE</p>\n<p>Channeloption.SO_KEEPALIVE参数对应于套接字选项中的SO_KEEPALIVE，该参数用于设置TCP连接，当设置该选项以后，连接会测试链接的状态，这个选项用于可能长时间没有数据交流的</p>\n<p>连接。当设置该选项以后，如果在两小时内没有数据的通信时，TCP会自动发送一个活动探测数据报文。</p>\n<p>4、ChannelOption.SO_SNDBUF和ChannelOpSNDBUF和ChannelOptiontion.SO_RCVBUF</p>\n<p>ChannelOption.SO_SNDBUF参数对应于套接字选项中的SO_SNDBUF，ChannelOption.SO_RCVBUF参数对应于套接字选项中的SO_RCVBUF这两个参数用于操作接收缓冲区和发送缓冲区</p>\n<p>的大小，接收缓冲区用于保存网络协议站内收到的数据，直到应用程序读取成功，发送缓冲区用于保存发送数据，直到发送成功。</p>\n<p>5、ChannelOption.SO_LINGER</p>\n<p>ChannelOption.SO_LINGER参数对应于套接字选项中的SO_LINGER,Linux内核默认的处理方式是当用户调用close（）方法的时候，函数返回，在可能的情况下，尽量发送数据，不一定保证</p>\n<p>会发生剩余的数据，造成了数据的不确定性，使用SO_LINGER可以阻塞close()的调用时间，直到数据完全发送</p>\n<p>6、ChannelOption.TCP_NODELAY</p>\n<p>ChannelOption.TCP_NODELAY参数对应于套接字选项中的TCP_NODELAY,该参数的使用与Nagle算法有关</p>\n<p>Nagle算法是将小的数据包组装为更大的帧然后进行发送，而不是输入一次发送一次,因此在数据包不足的时候会等待其他数据的到了，组装成大的数据包进行发送，虽然该方式有效提高网络的有效</p>\n<p>负载，但是却造成了延时，而该参数的作用就是禁止使用Nagle算法，使用于小数据即时传输，于TCP_NODELAY相对应的是TCP_CORK，该选项是需要等到发送的数据量最大的时候，一次性发送</p>\n<p>数据，适用于文件传输。</p>\n"},{"title":"Netty-DirectMemory-leak","date":"2019-02-20T11:22:54.000Z","_content":"\n\nhttp://calvin1978.blogcn.com/articles/netty-leak.html\n江南白衣的文章\n\nhttps://www.jianshu.com/p/4e96beb37935\n\nnetty 堆外内存泄露排查盛宴\n\n\n所谓内存泄漏，主要是针对池化的ByteBuf。ByteBuf对象被JVM GC掉之前，没有调用release()去把底下的DirectByteBuffer或byte[]归还到池里，会导致池越来越大。而非池化的ByteBuf，即使像DirectByteBuf那样可能会用到System.gc()，但终归会被release掉的，不会出大事。\n\n如果ByteBuf调用了Release，是不会被GC清理掉的。\n\n\n### 会自动释放ByteBuf\nByteToMessageDecoder\nSimpleChannelInboundHandler","source":"_posts/Netty-DirectMemory-leak.md","raw":"---\ntitle: Netty-DirectMemory-leak\ndate: 2019-02-20 19:22:54\ntags:\n---\n\n\nhttp://calvin1978.blogcn.com/articles/netty-leak.html\n江南白衣的文章\n\nhttps://www.jianshu.com/p/4e96beb37935\n\nnetty 堆外内存泄露排查盛宴\n\n\n所谓内存泄漏，主要是针对池化的ByteBuf。ByteBuf对象被JVM GC掉之前，没有调用release()去把底下的DirectByteBuffer或byte[]归还到池里，会导致池越来越大。而非池化的ByteBuf，即使像DirectByteBuf那样可能会用到System.gc()，但终归会被release掉的，不会出大事。\n\n如果ByteBuf调用了Release，是不会被GC清理掉的。\n\n\n### 会自动释放ByteBuf\nByteToMessageDecoder\nSimpleChannelInboundHandler","slug":"Netty-DirectMemory-leak","published":1,"updated":"2019-09-28T08:51:00.909Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8460041v1npt45ykqne","content":"<p><a href=\"http://calvin1978.blogcn.com/articles/netty-leak.html\" target=\"_blank\" rel=\"noopener\">http://calvin1978.blogcn.com/articles/netty-leak.html</a><br>江南白衣的文章</p>\n<p><a href=\"https://www.jianshu.com/p/4e96beb37935\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/4e96beb37935</a></p>\n<p>netty 堆外内存泄露排查盛宴</p>\n<p>所谓内存泄漏，主要是针对池化的ByteBuf。ByteBuf对象被JVM GC掉之前，没有调用release()去把底下的DirectByteBuffer或byte[]归还到池里，会导致池越来越大。而非池化的ByteBuf，即使像DirectByteBuf那样可能会用到System.gc()，但终归会被release掉的，不会出大事。</p>\n<p>如果ByteBuf调用了Release，是不会被GC清理掉的。</p>\n<h3 id=\"会自动释放ByteBuf\"><a href=\"#会自动释放ByteBuf\" class=\"headerlink\" title=\"会自动释放ByteBuf\"></a>会自动释放ByteBuf</h3><p>ByteToMessageDecoder<br>SimpleChannelInboundHandler</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://calvin1978.blogcn.com/articles/netty-leak.html\" target=\"_blank\" rel=\"noopener\">http://calvin1978.blogcn.com/articles/netty-leak.html</a><br>江南白衣的文章</p>\n<p><a href=\"https://www.jianshu.com/p/4e96beb37935\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/4e96beb37935</a></p>\n<p>netty 堆外内存泄露排查盛宴</p>\n<p>所谓内存泄漏，主要是针对池化的ByteBuf。ByteBuf对象被JVM GC掉之前，没有调用release()去把底下的DirectByteBuffer或byte[]归还到池里，会导致池越来越大。而非池化的ByteBuf，即使像DirectByteBuf那样可能会用到System.gc()，但终归会被release掉的，不会出大事。</p>\n<p>如果ByteBuf调用了Release，是不会被GC清理掉的。</p>\n<h3 id=\"会自动释放ByteBuf\"><a href=\"#会自动释放ByteBuf\" class=\"headerlink\" title=\"会自动释放ByteBuf\"></a>会自动释放ByteBuf</h3><p>ByteToMessageDecoder<br>SimpleChannelInboundHandler</p>\n"},{"title":"Netty-FastThreadLocal","date":"2019-02-27T03:36:57.000Z","_content":"\n\nhttps://www.jianshu.com/p/80284438bb97\nhttps://my.oschina.net/andylucc/blog/614359","source":"_posts/Netty-FastThreadLocal.md","raw":"---\ntitle: Netty-FastThreadLocal\ndate: 2019-02-27 11:36:57\ntags:\n---\n\n\nhttps://www.jianshu.com/p/80284438bb97\nhttps://my.oschina.net/andylucc/blog/614359","slug":"Netty-FastThreadLocal","published":1,"updated":"2019-09-28T08:51:00.910Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8470042v1npsq16bdjc","content":"<p><a href=\"https://www.jianshu.com/p/80284438bb97\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/80284438bb97</a><br><a href=\"https://my.oschina.net/andylucc/blog/614359\" target=\"_blank\" rel=\"noopener\">https://my.oschina.net/andylucc/blog/614359</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.jianshu.com/p/80284438bb97\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/80284438bb97</a><br><a href=\"https://my.oschina.net/andylucc/blog/614359\" target=\"_blank\" rel=\"noopener\">https://my.oschina.net/andylucc/blog/614359</a></p>\n"},{"title":"Netty-FileRegion","date":"2019-01-28T01:56:21.000Z","_content":"\n\ndoWrite(ChannelOutboundBuffer):226, AbstractNioByteChannel (io.netty.channel.nio), AbstractNioByteChannel.java\ndoWrite(ChannelOutboundBuffer):314, NioSocketChannel (io.netty.channel.socket.nio), NioSocketChannel.java\nflush0():802, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java\nflush0():313, AbstractNioChannel$AbstractNioUnsafe (io.netty.channel.nio), AbstractNioChannel.java\nflush():770, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java\nflush(ChannelHandlerContext):1256, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java\ninvokeFlush0():781, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeFlush():773, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\naccess$1500(AbstractChannelHandlerContext):36, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nrun():761, AbstractChannelHandlerContext$16 (io.netty.channel), AbstractChannelHandlerContext.java\nrunAllTasks(long):408, SingleThreadEventExecutor (io.netty.util.concurrent), SingleThreadEventExecutor.java\nrun():455, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nrun():140, SingleThreadEventExecutor$2 (io.netty.util.concurrent), SingleThreadEventExecutor.java\nrun():748, Thread (java.lang), Thread.java\n```\nif (msg instanceof FileRegion) {\n    FileRegion region = (FileRegion) msg;\n    boolean done = region.transfered() >= region.count();\n\n    if (!done) {\n        long flushedAmount = 0;\n        if (writeSpinCount == -1) {\n            writeSpinCount = config().getWriteSpinCount();\n        }\n\n        for (int i = writeSpinCount - 1; i >= 0; i--) {\n            long localFlushedAmount = doWriteFileRegion(region);\n            if (localFlushedAmount == 0) {\n                setOpWrite = true;\n                break;\n            }\n\n            flushedAmount += localFlushedAmount;\n            if (region.transfered() >= region.count()) {\n                done = true;\n                break;\n            }\n        }\n\n        in.progress(flushedAmount);\n    }\n\n    if (done) {\n        in.remove();\n    } else {\n        // Break the loop and so incompleteWrite(...) is called.\n        break;\n    }\n}\n```","source":"_posts/Netty-FileRegion.md","raw":"---\ntitle: Netty-FileRegion\ndate: 2019-01-28 09:56:21\ntags:\n---\n\n\ndoWrite(ChannelOutboundBuffer):226, AbstractNioByteChannel (io.netty.channel.nio), AbstractNioByteChannel.java\ndoWrite(ChannelOutboundBuffer):314, NioSocketChannel (io.netty.channel.socket.nio), NioSocketChannel.java\nflush0():802, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java\nflush0():313, AbstractNioChannel$AbstractNioUnsafe (io.netty.channel.nio), AbstractNioChannel.java\nflush():770, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java\nflush(ChannelHandlerContext):1256, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java\ninvokeFlush0():781, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeFlush():773, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\naccess$1500(AbstractChannelHandlerContext):36, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nrun():761, AbstractChannelHandlerContext$16 (io.netty.channel), AbstractChannelHandlerContext.java\nrunAllTasks(long):408, SingleThreadEventExecutor (io.netty.util.concurrent), SingleThreadEventExecutor.java\nrun():455, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nrun():140, SingleThreadEventExecutor$2 (io.netty.util.concurrent), SingleThreadEventExecutor.java\nrun():748, Thread (java.lang), Thread.java\n```\nif (msg instanceof FileRegion) {\n    FileRegion region = (FileRegion) msg;\n    boolean done = region.transfered() >= region.count();\n\n    if (!done) {\n        long flushedAmount = 0;\n        if (writeSpinCount == -1) {\n            writeSpinCount = config().getWriteSpinCount();\n        }\n\n        for (int i = writeSpinCount - 1; i >= 0; i--) {\n            long localFlushedAmount = doWriteFileRegion(region);\n            if (localFlushedAmount == 0) {\n                setOpWrite = true;\n                break;\n            }\n\n            flushedAmount += localFlushedAmount;\n            if (region.transfered() >= region.count()) {\n                done = true;\n                break;\n            }\n        }\n\n        in.progress(flushedAmount);\n    }\n\n    if (done) {\n        in.remove();\n    } else {\n        // Break the loop and so incompleteWrite(...) is called.\n        break;\n    }\n}\n```","slug":"Netty-FileRegion","published":1,"updated":"2019-09-28T08:51:00.910Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8470043v1npxm728h9d","content":"<p>doWrite(ChannelOutboundBuffer):226, AbstractNioByteChannel (io.netty.channel.nio), AbstractNioByteChannel.java<br>doWrite(ChannelOutboundBuffer):314, NioSocketChannel (io.netty.channel.socket.nio), NioSocketChannel.java<br>flush0():802, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java<br>flush0():313, AbstractNioChannel$AbstractNioUnsafe (io.netty.channel.nio), AbstractNioChannel.java<br>flush():770, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java<br>flush(ChannelHandlerContext):1256, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java<br>invokeFlush0():781, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>invokeFlush():773, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>access$1500(AbstractChannelHandlerContext):36, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>run():761, AbstractChannelHandlerContext$16 (io.netty.channel), AbstractChannelHandlerContext.java<br>runAllTasks(long):408, SingleThreadEventExecutor (io.netty.util.concurrent), SingleThreadEventExecutor.java<br>run():455, NioEventLoop (io.netty.channel.nio), NioEventLoop.java<br>run():140, SingleThreadEventExecutor$2 (io.netty.util.concurrent), SingleThreadEventExecutor.java<br>run():748, Thread (java.lang), Thread.java</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (msg instanceof FileRegion) &#123;</span><br><span class=\"line\">    FileRegion region = (FileRegion) msg;</span><br><span class=\"line\">    boolean done = region.transfered() &gt;= region.count();</span><br><span class=\"line\"></span><br><span class=\"line\">    if (!done) &#123;</span><br><span class=\"line\">        long flushedAmount = 0;</span><br><span class=\"line\">        if (writeSpinCount == -1) &#123;</span><br><span class=\"line\">            writeSpinCount = config().getWriteSpinCount();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        for (int i = writeSpinCount - 1; i &gt;= 0; i--) &#123;</span><br><span class=\"line\">            long localFlushedAmount = doWriteFileRegion(region);</span><br><span class=\"line\">            if (localFlushedAmount == 0) &#123;</span><br><span class=\"line\">                setOpWrite = true;</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            flushedAmount += localFlushedAmount;</span><br><span class=\"line\">            if (region.transfered() &gt;= region.count()) &#123;</span><br><span class=\"line\">                done = true;</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        in.progress(flushedAmount);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (done) &#123;</span><br><span class=\"line\">        in.remove();</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        // Break the loop and so incompleteWrite(...) is called.</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p>doWrite(ChannelOutboundBuffer):226, AbstractNioByteChannel (io.netty.channel.nio), AbstractNioByteChannel.java<br>doWrite(ChannelOutboundBuffer):314, NioSocketChannel (io.netty.channel.socket.nio), NioSocketChannel.java<br>flush0():802, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java<br>flush0():313, AbstractNioChannel$AbstractNioUnsafe (io.netty.channel.nio), AbstractNioChannel.java<br>flush():770, AbstractChannel$AbstractUnsafe (io.netty.channel), AbstractChannel.java<br>flush(ChannelHandlerContext):1256, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java<br>invokeFlush0():781, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>invokeFlush():773, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>access$1500(AbstractChannelHandlerContext):36, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>run():761, AbstractChannelHandlerContext$16 (io.netty.channel), AbstractChannelHandlerContext.java<br>runAllTasks(long):408, SingleThreadEventExecutor (io.netty.util.concurrent), SingleThreadEventExecutor.java<br>run():455, NioEventLoop (io.netty.channel.nio), NioEventLoop.java<br>run():140, SingleThreadEventExecutor$2 (io.netty.util.concurrent), SingleThreadEventExecutor.java<br>run():748, Thread (java.lang), Thread.java</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (msg instanceof FileRegion) &#123;</span><br><span class=\"line\">    FileRegion region = (FileRegion) msg;</span><br><span class=\"line\">    boolean done = region.transfered() &gt;= region.count();</span><br><span class=\"line\"></span><br><span class=\"line\">    if (!done) &#123;</span><br><span class=\"line\">        long flushedAmount = 0;</span><br><span class=\"line\">        if (writeSpinCount == -1) &#123;</span><br><span class=\"line\">            writeSpinCount = config().getWriteSpinCount();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        for (int i = writeSpinCount - 1; i &gt;= 0; i--) &#123;</span><br><span class=\"line\">            long localFlushedAmount = doWriteFileRegion(region);</span><br><span class=\"line\">            if (localFlushedAmount == 0) &#123;</span><br><span class=\"line\">                setOpWrite = true;</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            flushedAmount += localFlushedAmount;</span><br><span class=\"line\">            if (region.transfered() &gt;= region.count()) &#123;</span><br><span class=\"line\">                done = true;</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        in.progress(flushedAmount);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (done) &#123;</span><br><span class=\"line\">        in.remove();</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        // Break the loop and so incompleteWrite(...) is called.</span><br><span class=\"line\">        break;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Netty-Child-EventLoopGroup","date":"2019-01-28T12:21:48.000Z","_content":"\n\n","source":"_posts/Netty-Child-EventLoopGroup.md","raw":"---\ntitle: Netty-Child-EventLoopGroup\ndate: 2019-01-28 20:21:48\ntags: Netty\n---\n\n\n","slug":"Netty-Child-EventLoopGroup","published":1,"updated":"2019-09-28T08:51:00.909Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8480044v1npcfpu6apj","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Netty-原理整理","date":"2017-10-16T06:25:04.000Z","_content":"\n\n\n### 这篇文章好好研究下\nhttps://github.com/fengjiachun/Jupiter/blob/master/docs/static_files/high_performance_rpc_with_netty.md\n\nhttps://www.infoq.cn/article/netty-million-level-push-service-design-points\n\n### 怎么样的情况下，netty会发生内存泄露，应该怎么样去检测内存泄露，应该要怎么样处理？\nhttps://www.jianshu.com/p/73fff8e09fed\n如果我们的Handler对消息进行了处理，但是没有把消息往Pipeline的tail节点传递，那么就没有办法调用到Tail中`ReferenceCountUtil.release(msg);`导致内存泄露。\n但是使用SimpleChannelInboundHandler就会帮助我们避免这个问题\n\n### Netty PooledByteBufAllocator会创建多大的堆外内存？\n\n\n\n\n### 重要概念 Future and Promise\n\n### Netty处理的对象\n\nbytes and messages.\n\n\n### Netty采坑之： ctx.channel().writeAndFlush 和 ctx.writeAndFlush 的区别\nhttps://blog.csdn.net/FishSeeker/article/details/78447684\n\n### 如何调试事件循环线程（自己总结的，精彩）\n当我们用debug启动netty server时，我们不知道boss线程运行的代码，那怎么样才能发现boss线程当前的执行轨迹呢。如果能找到轨迹，对我们研究boss线程有非常大的帮助。\n\n给boss时间循环线程池起个名字\n``` java\n NioEventLoopGroup boss = new NioEventLoopGroup(0, new ThreadFactory() {\n    @Override\n    public Thread newThread(Runnable r) {\n        return new Thread(r, \"boss-event-loop\");\n    }\n});\n```\n如果用的Intellij，就能实现这个效果，首先用debug模式启动netty server。在debug tag下，我们进入Threads，展开**Thread Group \"main\"**，发现**boss-event-loop**正在处于Running状态。选中**boss-event-loop**，右键点击**suspend**，之后就能看到代码停了下来，去**Frames**tab中选择某一行进行断点调试。\n\n### 聊天程序，推送技术\nWeb Socket技术\nLong Pooling技术\n\n### 原生NIO可能会被问到的问题\n\n### Netty线程管理，高低水位线(watermark)控制，高低水位指的是线程\nhttps://stackoverflow.com/questions/25281124/netty-4-high-and-low-write-watermarks\nhttp://adolgarev.blogspot.ru/2013/12/pipelining-and-flow-control.html?view=flipcard\n\n看下这个文章，是不是可以用Netty的限流来完成这个事情\n\n### Netty线程模型，Netty异常对Inbound(入站)和Outbound(出站) Handler的影响\n\n### Netty内存管理，怎么防止内存过度使用\n\nio模型，上面图里的问题，内存池怎么管理，怎么防止泄露。\nmq主从切换，但是网络原因master假死， 这时候slave升级为主，怎么办？\n和mysql主从切换一个道理，我不知道怎么办。或者怎么屏蔽。\n\n\n### Netty bind()方法\n\n``` java\n@Override\nprotected void doRegister() throws Exception {\n    boolean selected = false;\n    for (;;) {\n        try {\n            selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this);\n            return;\n        } catch (CancelledKeyException e) {\n            if (!selected) {\n                // Force the Selector to select now as the \"canceled\" SelectionKey may still be\n                // cached and not removed because no Select.select(..) operation was called yet.\n                eventLoop().selectNow();\n                selected = true;\n            } else {\n                // We forced a select operation on the selector before but the SelectionKey is still cached\n                // for whatever reason. JDK bug ?\n                throw e;\n            }\n        }\n    }\n}\n```\n注意到，register的第二个参数为0，也就是说，selector和serverSocketChannel之间仅仅有了注册关系，但没有指定selector到底interest什么事件，那问题是，selector和serverSocketChannel之间的OP_ACCEPT是什么时候完成的？\n\n### 用sendBuf和RecBuf做系统之间的限流，这好像是一个天然的事情\n\n### Netty高性能开发备忘录\nhttp://blog.csdn.net/asdfayw/article/details/71730543\n\n### Netty中的那些坑\nhttp://www.jianshu.com/p/890525ff73cb\nhttp://www.jianshu.com/p/8f22675d71ac\n\n### 用Netty开发中间件：高并发性能优化\nhttp://blog.csdn.net/dc_726/article/details/48978891\n\n### handler和childHandler的区别\n\n### 问题\n\n``` java\nprivate static ServerSocketChannel newSocket(SelectorProvider provider) {\n    try {\n        /**\n         *  Use the {@link SelectorProvider} to open {@link SocketChannel} and so remove condition in\n         *  {@link SelectorProvider#provider()} which is called by each ServerSocketChannel.open() otherwise.\n         *\n         *  See <a href=\"https://github.com/netty/netty/issues/2308\">#2308</a>.\n         */\n        return provider.openServerSocketChannel();\n    } catch (IOException e) {\n        throw new ChannelException(\n                \"Failed to open a server socket.\", e);\n    }\n}\n```\n\n### Netty怎么维护着所有的长连接？\n\n### Netty ByteBuf release怎么用？\n\n### 什么样的Handler可以用单例？\n\n### Netty性能极致优化指南\n1. 用@ChannelHandler.Sharable注解标识单例Handler\n2. EpollEventLoop","source":"_posts/Netty-FAQ.md","raw":"---\ntitle: Netty-原理整理\ndate: 2017-10-16 14:25:04\ntags: Netty\n---\n\n\n\n### 这篇文章好好研究下\nhttps://github.com/fengjiachun/Jupiter/blob/master/docs/static_files/high_performance_rpc_with_netty.md\n\nhttps://www.infoq.cn/article/netty-million-level-push-service-design-points\n\n### 怎么样的情况下，netty会发生内存泄露，应该怎么样去检测内存泄露，应该要怎么样处理？\nhttps://www.jianshu.com/p/73fff8e09fed\n如果我们的Handler对消息进行了处理，但是没有把消息往Pipeline的tail节点传递，那么就没有办法调用到Tail中`ReferenceCountUtil.release(msg);`导致内存泄露。\n但是使用SimpleChannelInboundHandler就会帮助我们避免这个问题\n\n### Netty PooledByteBufAllocator会创建多大的堆外内存？\n\n\n\n\n### 重要概念 Future and Promise\n\n### Netty处理的对象\n\nbytes and messages.\n\n\n### Netty采坑之： ctx.channel().writeAndFlush 和 ctx.writeAndFlush 的区别\nhttps://blog.csdn.net/FishSeeker/article/details/78447684\n\n### 如何调试事件循环线程（自己总结的，精彩）\n当我们用debug启动netty server时，我们不知道boss线程运行的代码，那怎么样才能发现boss线程当前的执行轨迹呢。如果能找到轨迹，对我们研究boss线程有非常大的帮助。\n\n给boss时间循环线程池起个名字\n``` java\n NioEventLoopGroup boss = new NioEventLoopGroup(0, new ThreadFactory() {\n    @Override\n    public Thread newThread(Runnable r) {\n        return new Thread(r, \"boss-event-loop\");\n    }\n});\n```\n如果用的Intellij，就能实现这个效果，首先用debug模式启动netty server。在debug tag下，我们进入Threads，展开**Thread Group \"main\"**，发现**boss-event-loop**正在处于Running状态。选中**boss-event-loop**，右键点击**suspend**，之后就能看到代码停了下来，去**Frames**tab中选择某一行进行断点调试。\n\n### 聊天程序，推送技术\nWeb Socket技术\nLong Pooling技术\n\n### 原生NIO可能会被问到的问题\n\n### Netty线程管理，高低水位线(watermark)控制，高低水位指的是线程\nhttps://stackoverflow.com/questions/25281124/netty-4-high-and-low-write-watermarks\nhttp://adolgarev.blogspot.ru/2013/12/pipelining-and-flow-control.html?view=flipcard\n\n看下这个文章，是不是可以用Netty的限流来完成这个事情\n\n### Netty线程模型，Netty异常对Inbound(入站)和Outbound(出站) Handler的影响\n\n### Netty内存管理，怎么防止内存过度使用\n\nio模型，上面图里的问题，内存池怎么管理，怎么防止泄露。\nmq主从切换，但是网络原因master假死， 这时候slave升级为主，怎么办？\n和mysql主从切换一个道理，我不知道怎么办。或者怎么屏蔽。\n\n\n### Netty bind()方法\n\n``` java\n@Override\nprotected void doRegister() throws Exception {\n    boolean selected = false;\n    for (;;) {\n        try {\n            selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this);\n            return;\n        } catch (CancelledKeyException e) {\n            if (!selected) {\n                // Force the Selector to select now as the \"canceled\" SelectionKey may still be\n                // cached and not removed because no Select.select(..) operation was called yet.\n                eventLoop().selectNow();\n                selected = true;\n            } else {\n                // We forced a select operation on the selector before but the SelectionKey is still cached\n                // for whatever reason. JDK bug ?\n                throw e;\n            }\n        }\n    }\n}\n```\n注意到，register的第二个参数为0，也就是说，selector和serverSocketChannel之间仅仅有了注册关系，但没有指定selector到底interest什么事件，那问题是，selector和serverSocketChannel之间的OP_ACCEPT是什么时候完成的？\n\n### 用sendBuf和RecBuf做系统之间的限流，这好像是一个天然的事情\n\n### Netty高性能开发备忘录\nhttp://blog.csdn.net/asdfayw/article/details/71730543\n\n### Netty中的那些坑\nhttp://www.jianshu.com/p/890525ff73cb\nhttp://www.jianshu.com/p/8f22675d71ac\n\n### 用Netty开发中间件：高并发性能优化\nhttp://blog.csdn.net/dc_726/article/details/48978891\n\n### handler和childHandler的区别\n\n### 问题\n\n``` java\nprivate static ServerSocketChannel newSocket(SelectorProvider provider) {\n    try {\n        /**\n         *  Use the {@link SelectorProvider} to open {@link SocketChannel} and so remove condition in\n         *  {@link SelectorProvider#provider()} which is called by each ServerSocketChannel.open() otherwise.\n         *\n         *  See <a href=\"https://github.com/netty/netty/issues/2308\">#2308</a>.\n         */\n        return provider.openServerSocketChannel();\n    } catch (IOException e) {\n        throw new ChannelException(\n                \"Failed to open a server socket.\", e);\n    }\n}\n```\n\n### Netty怎么维护着所有的长连接？\n\n### Netty ByteBuf release怎么用？\n\n### 什么样的Handler可以用单例？\n\n### Netty性能极致优化指南\n1. 用@ChannelHandler.Sharable注解标识单例Handler\n2. EpollEventLoop","slug":"Netty-FAQ","published":1,"updated":"2019-09-28T08:51:00.909Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8480045v1npu09gwdzn","content":"<h3 id=\"这篇文章好好研究下\"><a href=\"#这篇文章好好研究下\" class=\"headerlink\" title=\"这篇文章好好研究下\"></a>这篇文章好好研究下</h3><p><a href=\"https://github.com/fengjiachun/Jupiter/blob/master/docs/static_files/high_performance_rpc_with_netty.md\" target=\"_blank\" rel=\"noopener\">https://github.com/fengjiachun/Jupiter/blob/master/docs/static_files/high_performance_rpc_with_netty.md</a></p>\n<p><a href=\"https://www.infoq.cn/article/netty-million-level-push-service-design-points\" target=\"_blank\" rel=\"noopener\">https://www.infoq.cn/article/netty-million-level-push-service-design-points</a></p>\n<h3 id=\"怎么样的情况下，netty会发生内存泄露，应该怎么样去检测内存泄露，应该要怎么样处理？\"><a href=\"#怎么样的情况下，netty会发生内存泄露，应该怎么样去检测内存泄露，应该要怎么样处理？\" class=\"headerlink\" title=\"怎么样的情况下，netty会发生内存泄露，应该怎么样去检测内存泄露，应该要怎么样处理？\"></a>怎么样的情况下，netty会发生内存泄露，应该怎么样去检测内存泄露，应该要怎么样处理？</h3><p><a href=\"https://www.jianshu.com/p/73fff8e09fed\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/73fff8e09fed</a><br>如果我们的Handler对消息进行了处理，但是没有把消息往Pipeline的tail节点传递，那么就没有办法调用到Tail中<code>ReferenceCountUtil.release(msg);</code>导致内存泄露。<br>但是使用SimpleChannelInboundHandler就会帮助我们避免这个问题</p>\n<h3 id=\"Netty-PooledByteBufAllocator会创建多大的堆外内存？\"><a href=\"#Netty-PooledByteBufAllocator会创建多大的堆外内存？\" class=\"headerlink\" title=\"Netty PooledByteBufAllocator会创建多大的堆外内存？\"></a>Netty PooledByteBufAllocator会创建多大的堆外内存？</h3><h3 id=\"重要概念-Future-and-Promise\"><a href=\"#重要概念-Future-and-Promise\" class=\"headerlink\" title=\"重要概念 Future and Promise\"></a>重要概念 Future and Promise</h3><h3 id=\"Netty处理的对象\"><a href=\"#Netty处理的对象\" class=\"headerlink\" title=\"Netty处理的对象\"></a>Netty处理的对象</h3><p>bytes and messages.</p>\n<h3 id=\"Netty采坑之：-ctx-channel-writeAndFlush-和-ctx-writeAndFlush-的区别\"><a href=\"#Netty采坑之：-ctx-channel-writeAndFlush-和-ctx-writeAndFlush-的区别\" class=\"headerlink\" title=\"Netty采坑之： ctx.channel().writeAndFlush 和 ctx.writeAndFlush 的区别\"></a>Netty采坑之： ctx.channel().writeAndFlush 和 ctx.writeAndFlush 的区别</h3><p><a href=\"https://blog.csdn.net/FishSeeker/article/details/78447684\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/FishSeeker/article/details/78447684</a></p>\n<h3 id=\"如何调试事件循环线程（自己总结的，精彩）\"><a href=\"#如何调试事件循环线程（自己总结的，精彩）\" class=\"headerlink\" title=\"如何调试事件循环线程（自己总结的，精彩）\"></a>如何调试事件循环线程（自己总结的，精彩）</h3><p>当我们用debug启动netty server时，我们不知道boss线程运行的代码，那怎么样才能发现boss线程当前的执行轨迹呢。如果能找到轨迹，对我们研究boss线程有非常大的帮助。</p>\n<p>给boss时间循环线程池起个名字</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> NioEventLoopGroup boss = <span class=\"keyword\">new</span> NioEventLoopGroup(<span class=\"number\">0</span>, <span class=\"keyword\">new</span> ThreadFactory() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Thread <span class=\"title\">newThread</span><span class=\"params\">(Runnable r)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> Thread(r, <span class=\"string\">\"boss-event-loop\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n\n<p>如果用的Intellij，就能实现这个效果，首先用debug模式启动netty server。在debug tag下，我们进入Threads，展开<strong>Thread Group “main”</strong>，发现<strong>boss-event-loop</strong>正在处于Running状态。选中<strong>boss-event-loop</strong>，右键点击<strong>suspend</strong>，之后就能看到代码停了下来，去<strong>Frames</strong>tab中选择某一行进行断点调试。</p>\n<h3 id=\"聊天程序，推送技术\"><a href=\"#聊天程序，推送技术\" class=\"headerlink\" title=\"聊天程序，推送技术\"></a>聊天程序，推送技术</h3><p>Web Socket技术<br>Long Pooling技术</p>\n<h3 id=\"原生NIO可能会被问到的问题\"><a href=\"#原生NIO可能会被问到的问题\" class=\"headerlink\" title=\"原生NIO可能会被问到的问题\"></a>原生NIO可能会被问到的问题</h3><h3 id=\"Netty线程管理，高低水位线-watermark-控制，高低水位指的是线程\"><a href=\"#Netty线程管理，高低水位线-watermark-控制，高低水位指的是线程\" class=\"headerlink\" title=\"Netty线程管理，高低水位线(watermark)控制，高低水位指的是线程\"></a>Netty线程管理，高低水位线(watermark)控制，高低水位指的是线程</h3><p><a href=\"https://stackoverflow.com/questions/25281124/netty-4-high-and-low-write-watermarks\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/25281124/netty-4-high-and-low-write-watermarks</a><br><a href=\"http://adolgarev.blogspot.ru/2013/12/pipelining-and-flow-control.html?view=flipcard\" target=\"_blank\" rel=\"noopener\">http://adolgarev.blogspot.ru/2013/12/pipelining-and-flow-control.html?view=flipcard</a></p>\n<p>看下这个文章，是不是可以用Netty的限流来完成这个事情</p>\n<h3 id=\"Netty线程模型，Netty异常对Inbound-入站-和Outbound-出站-Handler的影响\"><a href=\"#Netty线程模型，Netty异常对Inbound-入站-和Outbound-出站-Handler的影响\" class=\"headerlink\" title=\"Netty线程模型，Netty异常对Inbound(入站)和Outbound(出站) Handler的影响\"></a>Netty线程模型，Netty异常对Inbound(入站)和Outbound(出站) Handler的影响</h3><h3 id=\"Netty内存管理，怎么防止内存过度使用\"><a href=\"#Netty内存管理，怎么防止内存过度使用\" class=\"headerlink\" title=\"Netty内存管理，怎么防止内存过度使用\"></a>Netty内存管理，怎么防止内存过度使用</h3><p>io模型，上面图里的问题，内存池怎么管理，怎么防止泄露。<br>mq主从切换，但是网络原因master假死， 这时候slave升级为主，怎么办？<br>和mysql主从切换一个道理，我不知道怎么办。或者怎么屏蔽。</p>\n<h3 id=\"Netty-bind-方法\"><a href=\"#Netty-bind-方法\" class=\"headerlink\" title=\"Netty bind()方法\"></a>Netty bind()方法</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">doRegister</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> selected = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), <span class=\"number\">0</span>, <span class=\"keyword\">this</span>);</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (CancelledKeyException e) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!selected) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// Force the Selector to select now as the \"canceled\" SelectionKey may still be</span></span><br><span class=\"line\">                <span class=\"comment\">// cached and not removed because no Select.select(..) operation was called yet.</span></span><br><span class=\"line\">                eventLoop().selectNow();</span><br><span class=\"line\">                selected = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"comment\">// We forced a select operation on the selector before but the SelectionKey is still cached</span></span><br><span class=\"line\">                <span class=\"comment\">// for whatever reason. JDK bug ?</span></span><br><span class=\"line\">                <span class=\"keyword\">throw</span> e;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>注意到，register的第二个参数为0，也就是说，selector和serverSocketChannel之间仅仅有了注册关系，但没有指定selector到底interest什么事件，那问题是，selector和serverSocketChannel之间的OP_ACCEPT是什么时候完成的？</p>\n<h3 id=\"用sendBuf和RecBuf做系统之间的限流，这好像是一个天然的事情\"><a href=\"#用sendBuf和RecBuf做系统之间的限流，这好像是一个天然的事情\" class=\"headerlink\" title=\"用sendBuf和RecBuf做系统之间的限流，这好像是一个天然的事情\"></a>用sendBuf和RecBuf做系统之间的限流，这好像是一个天然的事情</h3><h3 id=\"Netty高性能开发备忘录\"><a href=\"#Netty高性能开发备忘录\" class=\"headerlink\" title=\"Netty高性能开发备忘录\"></a>Netty高性能开发备忘录</h3><p><a href=\"http://blog.csdn.net/asdfayw/article/details/71730543\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/asdfayw/article/details/71730543</a></p>\n<h3 id=\"Netty中的那些坑\"><a href=\"#Netty中的那些坑\" class=\"headerlink\" title=\"Netty中的那些坑\"></a>Netty中的那些坑</h3><p><a href=\"http://www.jianshu.com/p/890525ff73cb\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/890525ff73cb</a><br><a href=\"http://www.jianshu.com/p/8f22675d71ac\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/8f22675d71ac</a></p>\n<h3 id=\"用Netty开发中间件：高并发性能优化\"><a href=\"#用Netty开发中间件：高并发性能优化\" class=\"headerlink\" title=\"用Netty开发中间件：高并发性能优化\"></a>用Netty开发中间件：高并发性能优化</h3><p><a href=\"http://blog.csdn.net/dc_726/article/details/48978891\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/dc_726/article/details/48978891</a></p>\n<h3 id=\"handler和childHandler的区别\"><a href=\"#handler和childHandler的区别\" class=\"headerlink\" title=\"handler和childHandler的区别\"></a>handler和childHandler的区别</h3><h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> ServerSocketChannel <span class=\"title\">newSocket</span><span class=\"params\">(SelectorProvider provider)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">         *  Use the &#123;<span class=\"doctag\">@link</span> SelectorProvider&#125; to open &#123;<span class=\"doctag\">@link</span> SocketChannel&#125; and so remove condition in</span></span><br><span class=\"line\"><span class=\"comment\">         *  &#123;<span class=\"doctag\">@link</span> SelectorProvider#provider()&#125; which is called by each ServerSocketChannel.open() otherwise.</span></span><br><span class=\"line\"><span class=\"comment\">         *</span></span><br><span class=\"line\"><span class=\"comment\">         *  See &lt;a href=\"https://github.com/netty/netty/issues/2308\"&gt;#2308&lt;/a&gt;.</span></span><br><span class=\"line\"><span class=\"comment\">         */</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> provider.openServerSocketChannel();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ChannelException(</span><br><span class=\"line\">                <span class=\"string\">\"Failed to open a server socket.\"</span>, e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Netty怎么维护着所有的长连接？\"><a href=\"#Netty怎么维护着所有的长连接？\" class=\"headerlink\" title=\"Netty怎么维护着所有的长连接？\"></a>Netty怎么维护着所有的长连接？</h3><h3 id=\"Netty-ByteBuf-release怎么用？\"><a href=\"#Netty-ByteBuf-release怎么用？\" class=\"headerlink\" title=\"Netty ByteBuf release怎么用？\"></a>Netty ByteBuf release怎么用？</h3><h3 id=\"什么样的Handler可以用单例？\"><a href=\"#什么样的Handler可以用单例？\" class=\"headerlink\" title=\"什么样的Handler可以用单例？\"></a>什么样的Handler可以用单例？</h3><h3 id=\"Netty性能极致优化指南\"><a href=\"#Netty性能极致优化指南\" class=\"headerlink\" title=\"Netty性能极致优化指南\"></a>Netty性能极致优化指南</h3><ol>\n<li>用@ChannelHandler.Sharable注解标识单例Handler</li>\n<li>EpollEventLoop</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"这篇文章好好研究下\"><a href=\"#这篇文章好好研究下\" class=\"headerlink\" title=\"这篇文章好好研究下\"></a>这篇文章好好研究下</h3><p><a href=\"https://github.com/fengjiachun/Jupiter/blob/master/docs/static_files/high_performance_rpc_with_netty.md\" target=\"_blank\" rel=\"noopener\">https://github.com/fengjiachun/Jupiter/blob/master/docs/static_files/high_performance_rpc_with_netty.md</a></p>\n<p><a href=\"https://www.infoq.cn/article/netty-million-level-push-service-design-points\" target=\"_blank\" rel=\"noopener\">https://www.infoq.cn/article/netty-million-level-push-service-design-points</a></p>\n<h3 id=\"怎么样的情况下，netty会发生内存泄露，应该怎么样去检测内存泄露，应该要怎么样处理？\"><a href=\"#怎么样的情况下，netty会发生内存泄露，应该怎么样去检测内存泄露，应该要怎么样处理？\" class=\"headerlink\" title=\"怎么样的情况下，netty会发生内存泄露，应该怎么样去检测内存泄露，应该要怎么样处理？\"></a>怎么样的情况下，netty会发生内存泄露，应该怎么样去检测内存泄露，应该要怎么样处理？</h3><p><a href=\"https://www.jianshu.com/p/73fff8e09fed\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/73fff8e09fed</a><br>如果我们的Handler对消息进行了处理，但是没有把消息往Pipeline的tail节点传递，那么就没有办法调用到Tail中<code>ReferenceCountUtil.release(msg);</code>导致内存泄露。<br>但是使用SimpleChannelInboundHandler就会帮助我们避免这个问题</p>\n<h3 id=\"Netty-PooledByteBufAllocator会创建多大的堆外内存？\"><a href=\"#Netty-PooledByteBufAllocator会创建多大的堆外内存？\" class=\"headerlink\" title=\"Netty PooledByteBufAllocator会创建多大的堆外内存？\"></a>Netty PooledByteBufAllocator会创建多大的堆外内存？</h3><h3 id=\"重要概念-Future-and-Promise\"><a href=\"#重要概念-Future-and-Promise\" class=\"headerlink\" title=\"重要概念 Future and Promise\"></a>重要概念 Future and Promise</h3><h3 id=\"Netty处理的对象\"><a href=\"#Netty处理的对象\" class=\"headerlink\" title=\"Netty处理的对象\"></a>Netty处理的对象</h3><p>bytes and messages.</p>\n<h3 id=\"Netty采坑之：-ctx-channel-writeAndFlush-和-ctx-writeAndFlush-的区别\"><a href=\"#Netty采坑之：-ctx-channel-writeAndFlush-和-ctx-writeAndFlush-的区别\" class=\"headerlink\" title=\"Netty采坑之： ctx.channel().writeAndFlush 和 ctx.writeAndFlush 的区别\"></a>Netty采坑之： ctx.channel().writeAndFlush 和 ctx.writeAndFlush 的区别</h3><p><a href=\"https://blog.csdn.net/FishSeeker/article/details/78447684\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/FishSeeker/article/details/78447684</a></p>\n<h3 id=\"如何调试事件循环线程（自己总结的，精彩）\"><a href=\"#如何调试事件循环线程（自己总结的，精彩）\" class=\"headerlink\" title=\"如何调试事件循环线程（自己总结的，精彩）\"></a>如何调试事件循环线程（自己总结的，精彩）</h3><p>当我们用debug启动netty server时，我们不知道boss线程运行的代码，那怎么样才能发现boss线程当前的执行轨迹呢。如果能找到轨迹，对我们研究boss线程有非常大的帮助。</p>\n<p>给boss时间循环线程池起个名字</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> NioEventLoopGroup boss = <span class=\"keyword\">new</span> NioEventLoopGroup(<span class=\"number\">0</span>, <span class=\"keyword\">new</span> ThreadFactory() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Thread <span class=\"title\">newThread</span><span class=\"params\">(Runnable r)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> Thread(r, <span class=\"string\">\"boss-event-loop\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n\n<p>如果用的Intellij，就能实现这个效果，首先用debug模式启动netty server。在debug tag下，我们进入Threads，展开<strong>Thread Group “main”</strong>，发现<strong>boss-event-loop</strong>正在处于Running状态。选中<strong>boss-event-loop</strong>，右键点击<strong>suspend</strong>，之后就能看到代码停了下来，去<strong>Frames</strong>tab中选择某一行进行断点调试。</p>\n<h3 id=\"聊天程序，推送技术\"><a href=\"#聊天程序，推送技术\" class=\"headerlink\" title=\"聊天程序，推送技术\"></a>聊天程序，推送技术</h3><p>Web Socket技术<br>Long Pooling技术</p>\n<h3 id=\"原生NIO可能会被问到的问题\"><a href=\"#原生NIO可能会被问到的问题\" class=\"headerlink\" title=\"原生NIO可能会被问到的问题\"></a>原生NIO可能会被问到的问题</h3><h3 id=\"Netty线程管理，高低水位线-watermark-控制，高低水位指的是线程\"><a href=\"#Netty线程管理，高低水位线-watermark-控制，高低水位指的是线程\" class=\"headerlink\" title=\"Netty线程管理，高低水位线(watermark)控制，高低水位指的是线程\"></a>Netty线程管理，高低水位线(watermark)控制，高低水位指的是线程</h3><p><a href=\"https://stackoverflow.com/questions/25281124/netty-4-high-and-low-write-watermarks\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/25281124/netty-4-high-and-low-write-watermarks</a><br><a href=\"http://adolgarev.blogspot.ru/2013/12/pipelining-and-flow-control.html?view=flipcard\" target=\"_blank\" rel=\"noopener\">http://adolgarev.blogspot.ru/2013/12/pipelining-and-flow-control.html?view=flipcard</a></p>\n<p>看下这个文章，是不是可以用Netty的限流来完成这个事情</p>\n<h3 id=\"Netty线程模型，Netty异常对Inbound-入站-和Outbound-出站-Handler的影响\"><a href=\"#Netty线程模型，Netty异常对Inbound-入站-和Outbound-出站-Handler的影响\" class=\"headerlink\" title=\"Netty线程模型，Netty异常对Inbound(入站)和Outbound(出站) Handler的影响\"></a>Netty线程模型，Netty异常对Inbound(入站)和Outbound(出站) Handler的影响</h3><h3 id=\"Netty内存管理，怎么防止内存过度使用\"><a href=\"#Netty内存管理，怎么防止内存过度使用\" class=\"headerlink\" title=\"Netty内存管理，怎么防止内存过度使用\"></a>Netty内存管理，怎么防止内存过度使用</h3><p>io模型，上面图里的问题，内存池怎么管理，怎么防止泄露。<br>mq主从切换，但是网络原因master假死， 这时候slave升级为主，怎么办？<br>和mysql主从切换一个道理，我不知道怎么办。或者怎么屏蔽。</p>\n<h3 id=\"Netty-bind-方法\"><a href=\"#Netty-bind-方法\" class=\"headerlink\" title=\"Netty bind()方法\"></a>Netty bind()方法</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">protected</span> <span class=\"keyword\">void</span> <span class=\"title\">doRegister</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> selected = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (;;) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), <span class=\"number\">0</span>, <span class=\"keyword\">this</span>);</span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (CancelledKeyException e) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!selected) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// Force the Selector to select now as the \"canceled\" SelectionKey may still be</span></span><br><span class=\"line\">                <span class=\"comment\">// cached and not removed because no Select.select(..) operation was called yet.</span></span><br><span class=\"line\">                eventLoop().selectNow();</span><br><span class=\"line\">                selected = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"comment\">// We forced a select operation on the selector before but the SelectionKey is still cached</span></span><br><span class=\"line\">                <span class=\"comment\">// for whatever reason. JDK bug ?</span></span><br><span class=\"line\">                <span class=\"keyword\">throw</span> e;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>注意到，register的第二个参数为0，也就是说，selector和serverSocketChannel之间仅仅有了注册关系，但没有指定selector到底interest什么事件，那问题是，selector和serverSocketChannel之间的OP_ACCEPT是什么时候完成的？</p>\n<h3 id=\"用sendBuf和RecBuf做系统之间的限流，这好像是一个天然的事情\"><a href=\"#用sendBuf和RecBuf做系统之间的限流，这好像是一个天然的事情\" class=\"headerlink\" title=\"用sendBuf和RecBuf做系统之间的限流，这好像是一个天然的事情\"></a>用sendBuf和RecBuf做系统之间的限流，这好像是一个天然的事情</h3><h3 id=\"Netty高性能开发备忘录\"><a href=\"#Netty高性能开发备忘录\" class=\"headerlink\" title=\"Netty高性能开发备忘录\"></a>Netty高性能开发备忘录</h3><p><a href=\"http://blog.csdn.net/asdfayw/article/details/71730543\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/asdfayw/article/details/71730543</a></p>\n<h3 id=\"Netty中的那些坑\"><a href=\"#Netty中的那些坑\" class=\"headerlink\" title=\"Netty中的那些坑\"></a>Netty中的那些坑</h3><p><a href=\"http://www.jianshu.com/p/890525ff73cb\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/890525ff73cb</a><br><a href=\"http://www.jianshu.com/p/8f22675d71ac\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/8f22675d71ac</a></p>\n<h3 id=\"用Netty开发中间件：高并发性能优化\"><a href=\"#用Netty开发中间件：高并发性能优化\" class=\"headerlink\" title=\"用Netty开发中间件：高并发性能优化\"></a>用Netty开发中间件：高并发性能优化</h3><p><a href=\"http://blog.csdn.net/dc_726/article/details/48978891\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/dc_726/article/details/48978891</a></p>\n<h3 id=\"handler和childHandler的区别\"><a href=\"#handler和childHandler的区别\" class=\"headerlink\" title=\"handler和childHandler的区别\"></a>handler和childHandler的区别</h3><h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> ServerSocketChannel <span class=\"title\">newSocket</span><span class=\"params\">(SelectorProvider provider)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">         *  Use the &#123;<span class=\"doctag\">@link</span> SelectorProvider&#125; to open &#123;<span class=\"doctag\">@link</span> SocketChannel&#125; and so remove condition in</span></span><br><span class=\"line\"><span class=\"comment\">         *  &#123;<span class=\"doctag\">@link</span> SelectorProvider#provider()&#125; which is called by each ServerSocketChannel.open() otherwise.</span></span><br><span class=\"line\"><span class=\"comment\">         *</span></span><br><span class=\"line\"><span class=\"comment\">         *  See &lt;a href=\"https://github.com/netty/netty/issues/2308\"&gt;#2308&lt;/a&gt;.</span></span><br><span class=\"line\"><span class=\"comment\">         */</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> provider.openServerSocketChannel();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> ChannelException(</span><br><span class=\"line\">                <span class=\"string\">\"Failed to open a server socket.\"</span>, e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Netty怎么维护着所有的长连接？\"><a href=\"#Netty怎么维护着所有的长连接？\" class=\"headerlink\" title=\"Netty怎么维护着所有的长连接？\"></a>Netty怎么维护着所有的长连接？</h3><h3 id=\"Netty-ByteBuf-release怎么用？\"><a href=\"#Netty-ByteBuf-release怎么用？\" class=\"headerlink\" title=\"Netty ByteBuf release怎么用？\"></a>Netty ByteBuf release怎么用？</h3><h3 id=\"什么样的Handler可以用单例？\"><a href=\"#什么样的Handler可以用单例？\" class=\"headerlink\" title=\"什么样的Handler可以用单例？\"></a>什么样的Handler可以用单例？</h3><h3 id=\"Netty性能极致优化指南\"><a href=\"#Netty性能极致优化指南\" class=\"headerlink\" title=\"Netty性能极致优化指南\"></a>Netty性能极致优化指南</h3><ol>\n<li>用@ChannelHandler.Sharable注解标识单例Handler</li>\n<li>EpollEventLoop</li>\n</ol>\n"},{"title":"Netty-High-Performance","date":"2019-01-12T03:49:47.000Z","_content":"\n\nhttps://blog.csdn.net/baiye_xing/article/details/76735113","source":"_posts/Netty-High-Performance.md","raw":"---\ntitle: Netty-High-Performance\ndate: 2019-01-12 11:49:47\ntags:\n---\n\n\nhttps://blog.csdn.net/baiye_xing/article/details/76735113","slug":"Netty-High-Performance","published":1,"updated":"2019-09-28T08:51:00.910Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8490046v1np1rs6tbkw","content":"<p><a href=\"https://blog.csdn.net/baiye_xing/article/details/76735113\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/baiye_xing/article/details/76735113</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/baiye_xing/article/details/76735113\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/baiye_xing/article/details/76735113</a></p>\n"},{"title":"Netty-Jemalloc-PoolArena","date":"2018-11-28T03:03:13.000Z","_content":"\nArena本身是指一块区域，在内存管理中，Memory Arena是指内存中的一大块连续的区域，PoolArena就是Netty的内存池实现类。","source":"_posts/Netty-Jemalloc-PoolArena.md","raw":"---\ntitle: Netty-Jemalloc-PoolArena\ndate: 2018-11-28 11:03:13\ntags:\n---\n\nArena本身是指一块区域，在内存管理中，Memory Arena是指内存中的一大块连续的区域，PoolArena就是Netty的内存池实现类。","slug":"Netty-Jemalloc-PoolArena","published":1,"updated":"2019-09-28T08:51:00.910Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o8490047v1npknkncqur","content":"<p>Arena本身是指一块区域，在内存管理中，Memory Arena是指内存中的一大块连续的区域，PoolArena就是Netty的内存池实现类。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Arena本身是指一块区域，在内存管理中，Memory Arena是指内存中的一大块连续的区域，PoolArena就是Netty的内存池实现类。</p>\n"},{"title":"Netty-Jemalloc-PoolThreadLocalCache","date":"2018-11-27T09:35:26.000Z","_content":"\n``` PooledByteBufAllocator.java\n@Override\nprotected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) {\n    PoolThreadCache cache = threadCache.get();\n    PoolArena<ByteBuffer> directArena = cache.directArena;\n\n    final ByteBuf buf;\n    if (directArena != null) {\n        buf = directArena.allocate(cache, initialCapacity, maxCapacity);\n    } else {\n        buf = PlatformDependent.hasUnsafe() ?\n                UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity) :\n                new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity);\n    }\n\n    return toLeakAwareBuffer(buf);\n}\n```\n\n\n``` FastThreadLocal.java\n/**\n * Returns the current value for the current thread\n */\n@SuppressWarnings(\"unchecked\")\npublic final V get() {\n    InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get();\n    Object v = threadLocalMap.indexedVariable(index);\n    if (v != InternalThreadLocalMap.UNSET) {\n        return (V) v;\n    }\n\n    V value = initialize(threadLocalMap);\n    registerCleaner(threadLocalMap);\n    return value;\n}\n```\n\n\n``` InternalThreadLocalMap.java\nprivate static Object[] newIndexedVariableTable() {\n    Object[] array = new Object[32];\n    Arrays.fill(array, UNSET);\n    return array;\n}\n```","source":"_posts/Netty-Jemalloc-PoolThreadLocalCache.md","raw":"---\ntitle: Netty-Jemalloc-PoolThreadLocalCache\ndate: 2018-11-27 17:35:26\ntags:\n---\n\n``` PooledByteBufAllocator.java\n@Override\nprotected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) {\n    PoolThreadCache cache = threadCache.get();\n    PoolArena<ByteBuffer> directArena = cache.directArena;\n\n    final ByteBuf buf;\n    if (directArena != null) {\n        buf = directArena.allocate(cache, initialCapacity, maxCapacity);\n    } else {\n        buf = PlatformDependent.hasUnsafe() ?\n                UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity) :\n                new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity);\n    }\n\n    return toLeakAwareBuffer(buf);\n}\n```\n\n\n``` FastThreadLocal.java\n/**\n * Returns the current value for the current thread\n */\n@SuppressWarnings(\"unchecked\")\npublic final V get() {\n    InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get();\n    Object v = threadLocalMap.indexedVariable(index);\n    if (v != InternalThreadLocalMap.UNSET) {\n        return (V) v;\n    }\n\n    V value = initialize(threadLocalMap);\n    registerCleaner(threadLocalMap);\n    return value;\n}\n```\n\n\n``` InternalThreadLocalMap.java\nprivate static Object[] newIndexedVariableTable() {\n    Object[] array = new Object[32];\n    Arrays.fill(array, UNSET);\n    return array;\n}\n```","slug":"Netty-Jemalloc-PoolThreadLocalCache","published":1,"updated":"2019-09-28T08:51:00.910Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84a0048v1npbd9shb2q","content":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) &#123;</span><br><span class=\"line\">    PoolThreadCache cache = threadCache.get();</span><br><span class=\"line\">    PoolArena&lt;ByteBuffer&gt; directArena = cache.directArena;</span><br><span class=\"line\"></span><br><span class=\"line\">    final ByteBuf buf;</span><br><span class=\"line\">    if (directArena != null) &#123;</span><br><span class=\"line\">        buf = directArena.allocate(cache, initialCapacity, maxCapacity);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        buf = PlatformDependent.hasUnsafe() ?</span><br><span class=\"line\">                UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity) :</span><br><span class=\"line\">                new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    return toLeakAwareBuffer(buf);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Returns the current value for the current thread</span><br><span class=\"line\"> */</span><br><span class=\"line\">@SuppressWarnings(&quot;unchecked&quot;)</span><br><span class=\"line\">public final V get() &#123;</span><br><span class=\"line\">    InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get();</span><br><span class=\"line\">    Object v = threadLocalMap.indexedVariable(index);</span><br><span class=\"line\">    if (v != InternalThreadLocalMap.UNSET) &#123;</span><br><span class=\"line\">        return (V) v;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    V value = initialize(threadLocalMap);</span><br><span class=\"line\">    registerCleaner(threadLocalMap);</span><br><span class=\"line\">    return value;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private static Object[] newIndexedVariableTable() &#123;</span><br><span class=\"line\">    Object[] array = new Object[32];</span><br><span class=\"line\">    Arrays.fill(array, UNSET);</span><br><span class=\"line\">    return array;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) &#123;</span><br><span class=\"line\">    PoolThreadCache cache = threadCache.get();</span><br><span class=\"line\">    PoolArena&lt;ByteBuffer&gt; directArena = cache.directArena;</span><br><span class=\"line\"></span><br><span class=\"line\">    final ByteBuf buf;</span><br><span class=\"line\">    if (directArena != null) &#123;</span><br><span class=\"line\">        buf = directArena.allocate(cache, initialCapacity, maxCapacity);</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        buf = PlatformDependent.hasUnsafe() ?</span><br><span class=\"line\">                UnsafeByteBufUtil.newUnsafeDirectByteBuf(this, initialCapacity, maxCapacity) :</span><br><span class=\"line\">                new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    return toLeakAwareBuffer(buf);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Returns the current value for the current thread</span><br><span class=\"line\"> */</span><br><span class=\"line\">@SuppressWarnings(&quot;unchecked&quot;)</span><br><span class=\"line\">public final V get() &#123;</span><br><span class=\"line\">    InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get();</span><br><span class=\"line\">    Object v = threadLocalMap.indexedVariable(index);</span><br><span class=\"line\">    if (v != InternalThreadLocalMap.UNSET) &#123;</span><br><span class=\"line\">        return (V) v;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    V value = initialize(threadLocalMap);</span><br><span class=\"line\">    registerCleaner(threadLocalMap);</span><br><span class=\"line\">    return value;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private static Object[] newIndexedVariableTable() &#123;</span><br><span class=\"line\">    Object[] array = new Object[32];</span><br><span class=\"line\">    Arrays.fill(array, UNSET);</span><br><span class=\"line\">    return array;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Netty-Jemalloc","date":"2017-12-06T06:07:49.000Z","_content":"\nhttp://wangkaisino.blog.163.com/blog/static/1870444202011431112323846\n\n转载:\n\n在Netty4中引入了新的内存管理机制极大地提升其性能，本文将对该内在管理机制进行剖析。\n\n这里[有篇文章](http://www.infoq.com/news/2013/11/netty4-twitter)讲述了在推特(Twitter)内部\n使用Netty的状况以及Netty4所带来的性能收益。\n\n<!--more-->\n\n在分析Netty4的`PooledByteBufAllocator`之前，我们最好先认识一下[jemalloc](http://www.canonware.com/jemalloc/)。\nNetty在4.0之前的版本已经尝试过通过优化内存管理的方式来提高性能（如果我没有记错的话），但4.0中的改进则特别\n显著。在这个版本中，其内存管理实现主要是参考了`jemalloc`。\n\n# jemalloc\n\n**jemalloc** 是由Jason Evans在FreeBSD项目中引入的，其主旨是为了提升在并发环境下内存的分配效率。说白了就是替代\n`malloc`。malloc之所以没有照顾到并发环境，那是由于在那个时代并发还只在理论，未曾普及。而现在则是多核的天下，连\n手机都动则2、4核，甚至于8核了。与jemalloc齐名的还有Google的[tcmalloc](https://code.google.com/p/gperftools/)，其\n实现与jemalloc多少也有点相似，这里不做介绍。\n\n## jemalloc的理念\n\n我们以买火车票为例，来简单地说明一下jemalloc与malloc的区别。原来的malloc，相当于只有一个售票窗口的售票大厅，\n而jemalloc则在同一个售票大厅里面适量地增加的窗口。当然，火车票的总量(即内存大小)是不变的，买票的人相当于线程了。\n说起来这也是很自然的事情的。\n\n> 在这里，一个售票窗口就是相当于一个**Arena**。\n\nArena则按页(Page)来的管理内存，也就是说，一张车票就相当于一页。（后面就不太适合用火车票的例子了）。\n\n同时，jemalloc还根据所请求的内存大小，对其进行分类。如下图：\n\n![jemalloc allocation size category](http://farm4.staticflickr.com/3749/12402575993_30e006725c_o.png)\n\n默认情况下，Page的大小为4KB。如图，有三类，small、large和huge。small类的内存请求都属于一个内存页之内\n（没有半张车票出售:(）。另外，在small类里面，又分了三个子类，分别是Tiny、Quantum-Spaced和Sub-page。\n这几个概念都在Netty中得到应用。\n\n每个线程都与某个Arena绑定在一起，线程采用round-robin算法来绑定到某个Arena。\n\n> 这里有个问题，就是与某个Arena相关的一批线程使用内存资源过快，导致该Arena的内存资源全部消耗殆尽，\n> 而其它的Arena又有盈余，这时怎么处理？能否借用。\n> \n> 目前还没有对jemalloc本身的实现做过多的研究。\n\n通过对jemalloc有个简单的了解后，我们再来看看，Netty4是如何借鉴jemalloc的经验的。需要注意的是，\njemalloc的实现，要远比Netty4复杂，一个是系统层的，一个则是应用层的。但两者的思想是相通的。\n\n# Netty4中的内存管理\n\n以下内容所参考的代码是`netty-4.0.15.Final`。\n\nArena其实就是预先分配好的一个区域的内存。\n\nNetty4中，内存池管理的入口点是`PooledByteBufAllocator`。在该实现中，除了Arena和Page之外，\n还一个Chunk的概念。一个Arena由多个Chunk组成，而Chunk则由N个Page组成。\n\n默认配置中，\n\n\n``` java\n// 默认页面大小为8KB\nint defaultPageSize = SystemPropertyUtil.getInt(\"io.netty.allocator.pageSize\", 8192); \n\n// 默认的Chunk大小为16MB，即由2048个页面组成\nint defaultMaxOrder = SystemPropertyUtil.getInt(\"io.netty.allocator.maxOrder\", 11);\nfinal int defaultChunkSize = DEFAULT_PAGE_SIZE << DEFAULT_MAX_ORDER;\n\n// 默认情况下，一个Arena由3个Chunk组成，且所有Arena（就同一类而言）所占用的内存总数，\n// 不能超过可用内存的一半(50%)。\n\nDEFAULT_NUM_HEAP_ARENA = Math.max(0,\n        SystemPropertyUtil.getInt(\n                \"io.netty.allocator.numHeapArenas\",\n                (int) Math.min(\n                        runtime.availableProcessors(),\n                        Runtime.getRuntime().maxMemory() / defaultChunkSize / 2 / 3)));\nDEFAULT_NUM_DIRECT_ARENA = Math.max(0,\n        SystemPropertyUtil.getInt(\n                \"io.netty.allocator.numDirectArenas\",\n                (int) Math.min(\n                        runtime.availableProcessors(),\n                        PlatformDependent.maxDirectMemory() / defaultChunkSize / 2 / 3)));\n```\n\n\n根据以上代码，我们发现，Arena是分为两类的，一类是基于堆；另一类则是Direct内存（直接向操作系统请求的）。\n具体使用哪一类，默认是根据所使用的虚拟机而定，优先使用Direct类型（如果可用的话）。判断的条件是，\n看能否访问JVM的`Unsafe`类。具体可以参考`PlatformDependent.hasUnsafe()`方法。\n\n> 这里提到的两类不会被同时使用的！\n\n\n另外，对于内存请求大小的分类，这里也有一些变动。对于所请求内存的大小N\n\n``` java\nif N < PAGE_SIZE:\n\tif N < 512:\n\t\treturn TINY;\n\telse\n\t\treturn SMALL;\nelif N > CHUNK_SIZE:\n\treturn HUGE;\nelse\n\treturn LARGE;\n```\n\n## 内存管理\n\n现在，我们来仔细地看看内存分配的过程。\n\n\n``` java\nPooledByteBufAllocator alloc = new PooledByteBufAllocator(PlatformDependent.directBufferPreferred());\nByteBuf buff = alloc.ioBuffer(N);\n```\n\n\n假设在当前的JVM环境中，Direct内存可用的。那当我们尝试去申请N字节的内存时，其实现流程如下：\n\n1.  获取一个ByteBuf对象，但是该对象未与任何可用内存空间关联。\n2.  检查N的大小，并对N进行修正。。\n3.  分配内存。\n\n\n对N的修正：\n\n``` java\nprivate int normalizeCapacity(int reqCapacity) {\n    if (reqCapacity < 0) {\n        throw new IllegalArgumentException(\"capacity: \" + reqCapacity + \" (expected: 0+)\");\n    }\n    if (reqCapacity >= chunkSize) {\n        return reqCapacity;\n    }\n\n    if ((reqCapacity & 0xFFFFFE00) != 0) { // >= 512\n        // Doubled\n\n        int normalizedCapacity = reqCapacity;\n        normalizedCapacity |= normalizedCapacity >>>  1;\n        normalizedCapacity |= normalizedCapacity >>>  2;\n        normalizedCapacity |= normalizedCapacity >>>  4;\n        normalizedCapacity |= normalizedCapacity >>>  8;\n        normalizedCapacity |= normalizedCapacity >>> 16;\n        normalizedCapacity ++;\n\n        if (normalizedCapacity < 0) {\n            normalizedCapacity >>>= 1;\n        }\n\n        return normalizedCapacity;\n    }\n\n    // Quantum-spaced\n    if ((reqCapacity & 15) == 0) {\n        return reqCapacity;\n    }\n\n    return (reqCapacity & ~15) + 16;\n}\n```\n\n说到内存的分配，则需要对页的管理有一定的了解。\n\n### 内存页的管理模型\n\nNetty4使用了二叉树来管理每一个内存页。假设一个Chunk是由连续的N块内存页组成，\n则Netty4使用一个长度为`2N`的整型数组来记录和管理每一个内存页的使用情况。\n\n``` java\nint[] memoryMap = new int[N << 1]\n```\n\n假设N=4，则下图，基于`memoryMap`的二叉树的结构。每个结点的序号为数组的索引值。其中4、5、6、7是这四个叶子节点，\n分别用来记录4个内存页的使用状态。而2、3是用来表示其管辖的内存页的使用状态。节点1则管理整个Chunk的状态。\n\n![基于一维数组的二叉树](http://farm3.staticflickr.com/2805/12403894375_2ee7cf93a4_o.png)\n\n内存页的状态有四种：\n\n``` java\nprivate static final int ST_UNUSED = 0;  // 初始状态，未使用\n\nprivate static final int ST_BRANCH = 1;  // 只对非叶子节点有效，表明该节点下某一部分叶子节点被使用\n\n// 被使用，如果是叶子节点，则表明对应的内存页已经分配出去了\n// 如果是非叶子节点，则表明该节点所管辖的内存页已经全部分配出去了\nprivate static final int ST_ALLOCATED = 2; \n\n// 只对叶子节点有效，表示内存页里面的一部分被分配出去了。这种情况属于Tiny类型的内存请求。\nprivate static final int ST_ALLOCATED_SUBPAGE = ST_ALLOCATED | 1;\n```\n\n### 内存页的分配\n\n内存页的分配有两种情况，有多页分配和页内分配。这里我们先说多页（1个内存页以上）的分配。\n当请求的内存大小大于一个内存页时，`PooledByteBufAllocator`会通过遍历`memoryMap`来，来找出合适内存页。\n\n1. 首先，它要判断根节点1是否已经被分配，如果是，则表示当前的个Chunk已经没有可用的空间，它需要去其的Chunk找了。\n2. 接着，随机选择当前节点的某一个子节点（2或者3），判断是否有可用空间\n3. 重复步骤2，直到找到可用的内存页\n\n> 先写到这里，以下剩余内容的目录。另外，对`memoryMap`中的值，也需要进一步的说明,\n> 因为关系具体的内存位置。\n> \n> 写博客果然比较费事！\n\n### 页内分配\n\n# 内存的释放\n\n## 内存页的释放\n\n## 页内释放\n\n# 其它\n\n## ByteBuf实例缓存\n\n\n\n\n``` PoolChunk.java\n * For simplicity all sizes are normalized according to PoolArena#normalizeCapacity method\n * This ensures that when we request for memory segments of size >= pageSize the normalizedCapacity\n * equals the next nearest power of 2\n *\n * To search for the first offset in chunk that has at least requested size available we construct a\n * complete balanced binary tree and store it in an array (just like heaps) - memoryMap\n *\n * The tree looks like this (the size of each node being mentioned in the parenthesis)\n *\n * depth=0        1 node (chunkSize)\n * depth=1        2 nodes (chunkSize/2)\n * ..\n * ..\n * depth=d        2^d nodes (chunkSize/2^d)\n * ..\n * depth=maxOrder 2^maxOrder nodes (chunkSize/2^{maxOrder} = pageSize)\n *\n * depth=maxOrder is the last level and the leafs consist of pages\n```\n\n\n###\nNetty 内存分配\n- ByteBuf 分类\n- 内存规格是什么样的\n- 缓存数据结构\n- directArena 分配 direct 内存的流程\n- 从对象池里面拿到 PooledByteBuf 进行复用\n- 从缓存上进行内存分配\n- 从内存堆里面进行分配\n- arena、chunk、page、subpage之间的关系是什么？Netty 是如何维护他们之间的关系\n- page 是如何进行内存划分的\n- subpage 又是如何进行内存划分的\n- ByteBuf 的回收","source":"_posts/Netty-Jemalloc.md","raw":"---\ntitle: Netty-Jemalloc\ndate: 2017-12-06 14:07:49\ntags: Netty\n---\n\nhttp://wangkaisino.blog.163.com/blog/static/1870444202011431112323846\n\n转载:\n\n在Netty4中引入了新的内存管理机制极大地提升其性能，本文将对该内在管理机制进行剖析。\n\n这里[有篇文章](http://www.infoq.com/news/2013/11/netty4-twitter)讲述了在推特(Twitter)内部\n使用Netty的状况以及Netty4所带来的性能收益。\n\n<!--more-->\n\n在分析Netty4的`PooledByteBufAllocator`之前，我们最好先认识一下[jemalloc](http://www.canonware.com/jemalloc/)。\nNetty在4.0之前的版本已经尝试过通过优化内存管理的方式来提高性能（如果我没有记错的话），但4.0中的改进则特别\n显著。在这个版本中，其内存管理实现主要是参考了`jemalloc`。\n\n# jemalloc\n\n**jemalloc** 是由Jason Evans在FreeBSD项目中引入的，其主旨是为了提升在并发环境下内存的分配效率。说白了就是替代\n`malloc`。malloc之所以没有照顾到并发环境，那是由于在那个时代并发还只在理论，未曾普及。而现在则是多核的天下，连\n手机都动则2、4核，甚至于8核了。与jemalloc齐名的还有Google的[tcmalloc](https://code.google.com/p/gperftools/)，其\n实现与jemalloc多少也有点相似，这里不做介绍。\n\n## jemalloc的理念\n\n我们以买火车票为例，来简单地说明一下jemalloc与malloc的区别。原来的malloc，相当于只有一个售票窗口的售票大厅，\n而jemalloc则在同一个售票大厅里面适量地增加的窗口。当然，火车票的总量(即内存大小)是不变的，买票的人相当于线程了。\n说起来这也是很自然的事情的。\n\n> 在这里，一个售票窗口就是相当于一个**Arena**。\n\nArena则按页(Page)来的管理内存，也就是说，一张车票就相当于一页。（后面就不太适合用火车票的例子了）。\n\n同时，jemalloc还根据所请求的内存大小，对其进行分类。如下图：\n\n![jemalloc allocation size category](http://farm4.staticflickr.com/3749/12402575993_30e006725c_o.png)\n\n默认情况下，Page的大小为4KB。如图，有三类，small、large和huge。small类的内存请求都属于一个内存页之内\n（没有半张车票出售:(）。另外，在small类里面，又分了三个子类，分别是Tiny、Quantum-Spaced和Sub-page。\n这几个概念都在Netty中得到应用。\n\n每个线程都与某个Arena绑定在一起，线程采用round-robin算法来绑定到某个Arena。\n\n> 这里有个问题，就是与某个Arena相关的一批线程使用内存资源过快，导致该Arena的内存资源全部消耗殆尽，\n> 而其它的Arena又有盈余，这时怎么处理？能否借用。\n> \n> 目前还没有对jemalloc本身的实现做过多的研究。\n\n通过对jemalloc有个简单的了解后，我们再来看看，Netty4是如何借鉴jemalloc的经验的。需要注意的是，\njemalloc的实现，要远比Netty4复杂，一个是系统层的，一个则是应用层的。但两者的思想是相通的。\n\n# Netty4中的内存管理\n\n以下内容所参考的代码是`netty-4.0.15.Final`。\n\nArena其实就是预先分配好的一个区域的内存。\n\nNetty4中，内存池管理的入口点是`PooledByteBufAllocator`。在该实现中，除了Arena和Page之外，\n还一个Chunk的概念。一个Arena由多个Chunk组成，而Chunk则由N个Page组成。\n\n默认配置中，\n\n\n``` java\n// 默认页面大小为8KB\nint defaultPageSize = SystemPropertyUtil.getInt(\"io.netty.allocator.pageSize\", 8192); \n\n// 默认的Chunk大小为16MB，即由2048个页面组成\nint defaultMaxOrder = SystemPropertyUtil.getInt(\"io.netty.allocator.maxOrder\", 11);\nfinal int defaultChunkSize = DEFAULT_PAGE_SIZE << DEFAULT_MAX_ORDER;\n\n// 默认情况下，一个Arena由3个Chunk组成，且所有Arena（就同一类而言）所占用的内存总数，\n// 不能超过可用内存的一半(50%)。\n\nDEFAULT_NUM_HEAP_ARENA = Math.max(0,\n        SystemPropertyUtil.getInt(\n                \"io.netty.allocator.numHeapArenas\",\n                (int) Math.min(\n                        runtime.availableProcessors(),\n                        Runtime.getRuntime().maxMemory() / defaultChunkSize / 2 / 3)));\nDEFAULT_NUM_DIRECT_ARENA = Math.max(0,\n        SystemPropertyUtil.getInt(\n                \"io.netty.allocator.numDirectArenas\",\n                (int) Math.min(\n                        runtime.availableProcessors(),\n                        PlatformDependent.maxDirectMemory() / defaultChunkSize / 2 / 3)));\n```\n\n\n根据以上代码，我们发现，Arena是分为两类的，一类是基于堆；另一类则是Direct内存（直接向操作系统请求的）。\n具体使用哪一类，默认是根据所使用的虚拟机而定，优先使用Direct类型（如果可用的话）。判断的条件是，\n看能否访问JVM的`Unsafe`类。具体可以参考`PlatformDependent.hasUnsafe()`方法。\n\n> 这里提到的两类不会被同时使用的！\n\n\n另外，对于内存请求大小的分类，这里也有一些变动。对于所请求内存的大小N\n\n``` java\nif N < PAGE_SIZE:\n\tif N < 512:\n\t\treturn TINY;\n\telse\n\t\treturn SMALL;\nelif N > CHUNK_SIZE:\n\treturn HUGE;\nelse\n\treturn LARGE;\n```\n\n## 内存管理\n\n现在，我们来仔细地看看内存分配的过程。\n\n\n``` java\nPooledByteBufAllocator alloc = new PooledByteBufAllocator(PlatformDependent.directBufferPreferred());\nByteBuf buff = alloc.ioBuffer(N);\n```\n\n\n假设在当前的JVM环境中，Direct内存可用的。那当我们尝试去申请N字节的内存时，其实现流程如下：\n\n1.  获取一个ByteBuf对象，但是该对象未与任何可用内存空间关联。\n2.  检查N的大小，并对N进行修正。。\n3.  分配内存。\n\n\n对N的修正：\n\n``` java\nprivate int normalizeCapacity(int reqCapacity) {\n    if (reqCapacity < 0) {\n        throw new IllegalArgumentException(\"capacity: \" + reqCapacity + \" (expected: 0+)\");\n    }\n    if (reqCapacity >= chunkSize) {\n        return reqCapacity;\n    }\n\n    if ((reqCapacity & 0xFFFFFE00) != 0) { // >= 512\n        // Doubled\n\n        int normalizedCapacity = reqCapacity;\n        normalizedCapacity |= normalizedCapacity >>>  1;\n        normalizedCapacity |= normalizedCapacity >>>  2;\n        normalizedCapacity |= normalizedCapacity >>>  4;\n        normalizedCapacity |= normalizedCapacity >>>  8;\n        normalizedCapacity |= normalizedCapacity >>> 16;\n        normalizedCapacity ++;\n\n        if (normalizedCapacity < 0) {\n            normalizedCapacity >>>= 1;\n        }\n\n        return normalizedCapacity;\n    }\n\n    // Quantum-spaced\n    if ((reqCapacity & 15) == 0) {\n        return reqCapacity;\n    }\n\n    return (reqCapacity & ~15) + 16;\n}\n```\n\n说到内存的分配，则需要对页的管理有一定的了解。\n\n### 内存页的管理模型\n\nNetty4使用了二叉树来管理每一个内存页。假设一个Chunk是由连续的N块内存页组成，\n则Netty4使用一个长度为`2N`的整型数组来记录和管理每一个内存页的使用情况。\n\n``` java\nint[] memoryMap = new int[N << 1]\n```\n\n假设N=4，则下图，基于`memoryMap`的二叉树的结构。每个结点的序号为数组的索引值。其中4、5、6、7是这四个叶子节点，\n分别用来记录4个内存页的使用状态。而2、3是用来表示其管辖的内存页的使用状态。节点1则管理整个Chunk的状态。\n\n![基于一维数组的二叉树](http://farm3.staticflickr.com/2805/12403894375_2ee7cf93a4_o.png)\n\n内存页的状态有四种：\n\n``` java\nprivate static final int ST_UNUSED = 0;  // 初始状态，未使用\n\nprivate static final int ST_BRANCH = 1;  // 只对非叶子节点有效，表明该节点下某一部分叶子节点被使用\n\n// 被使用，如果是叶子节点，则表明对应的内存页已经分配出去了\n// 如果是非叶子节点，则表明该节点所管辖的内存页已经全部分配出去了\nprivate static final int ST_ALLOCATED = 2; \n\n// 只对叶子节点有效，表示内存页里面的一部分被分配出去了。这种情况属于Tiny类型的内存请求。\nprivate static final int ST_ALLOCATED_SUBPAGE = ST_ALLOCATED | 1;\n```\n\n### 内存页的分配\n\n内存页的分配有两种情况，有多页分配和页内分配。这里我们先说多页（1个内存页以上）的分配。\n当请求的内存大小大于一个内存页时，`PooledByteBufAllocator`会通过遍历`memoryMap`来，来找出合适内存页。\n\n1. 首先，它要判断根节点1是否已经被分配，如果是，则表示当前的个Chunk已经没有可用的空间，它需要去其的Chunk找了。\n2. 接着，随机选择当前节点的某一个子节点（2或者3），判断是否有可用空间\n3. 重复步骤2，直到找到可用的内存页\n\n> 先写到这里，以下剩余内容的目录。另外，对`memoryMap`中的值，也需要进一步的说明,\n> 因为关系具体的内存位置。\n> \n> 写博客果然比较费事！\n\n### 页内分配\n\n# 内存的释放\n\n## 内存页的释放\n\n## 页内释放\n\n# 其它\n\n## ByteBuf实例缓存\n\n\n\n\n``` PoolChunk.java\n * For simplicity all sizes are normalized according to PoolArena#normalizeCapacity method\n * This ensures that when we request for memory segments of size >= pageSize the normalizedCapacity\n * equals the next nearest power of 2\n *\n * To search for the first offset in chunk that has at least requested size available we construct a\n * complete balanced binary tree and store it in an array (just like heaps) - memoryMap\n *\n * The tree looks like this (the size of each node being mentioned in the parenthesis)\n *\n * depth=0        1 node (chunkSize)\n * depth=1        2 nodes (chunkSize/2)\n * ..\n * ..\n * depth=d        2^d nodes (chunkSize/2^d)\n * ..\n * depth=maxOrder 2^maxOrder nodes (chunkSize/2^{maxOrder} = pageSize)\n *\n * depth=maxOrder is the last level and the leafs consist of pages\n```\n\n\n###\nNetty 内存分配\n- ByteBuf 分类\n- 内存规格是什么样的\n- 缓存数据结构\n- directArena 分配 direct 内存的流程\n- 从对象池里面拿到 PooledByteBuf 进行复用\n- 从缓存上进行内存分配\n- 从内存堆里面进行分配\n- arena、chunk、page、subpage之间的关系是什么？Netty 是如何维护他们之间的关系\n- page 是如何进行内存划分的\n- subpage 又是如何进行内存划分的\n- ByteBuf 的回收","slug":"Netty-Jemalloc","published":1,"updated":"2019-09-28T08:51:00.910Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84a0049v1npv9hbbkow","content":"<p><a href=\"http://wangkaisino.blog.163.com/blog/static/1870444202011431112323846\" target=\"_blank\" rel=\"noopener\">http://wangkaisino.blog.163.com/blog/static/1870444202011431112323846</a></p>\n<p>转载:</p>\n<p>在Netty4中引入了新的内存管理机制极大地提升其性能，本文将对该内在管理机制进行剖析。</p>\n<p>这里<a href=\"http://www.infoq.com/news/2013/11/netty4-twitter\" target=\"_blank\" rel=\"noopener\">有篇文章</a>讲述了在推特(Twitter)内部<br>使用Netty的状况以及Netty4所带来的性能收益。</p>\n<a id=\"more\"></a>\n\n<p>在分析Netty4的<code>PooledByteBufAllocator</code>之前，我们最好先认识一下<a href=\"http://www.canonware.com/jemalloc/\" target=\"_blank\" rel=\"noopener\">jemalloc</a>。<br>Netty在4.0之前的版本已经尝试过通过优化内存管理的方式来提高性能（如果我没有记错的话），但4.0中的改进则特别<br>显著。在这个版本中，其内存管理实现主要是参考了<code>jemalloc</code>。</p>\n<h1 id=\"jemalloc\"><a href=\"#jemalloc\" class=\"headerlink\" title=\"jemalloc\"></a>jemalloc</h1><p><strong>jemalloc</strong> 是由Jason Evans在FreeBSD项目中引入的，其主旨是为了提升在并发环境下内存的分配效率。说白了就是替代<br><code>malloc</code>。malloc之所以没有照顾到并发环境，那是由于在那个时代并发还只在理论，未曾普及。而现在则是多核的天下，连<br>手机都动则2、4核，甚至于8核了。与jemalloc齐名的还有Google的<a href=\"https://code.google.com/p/gperftools/\" target=\"_blank\" rel=\"noopener\">tcmalloc</a>，其<br>实现与jemalloc多少也有点相似，这里不做介绍。</p>\n<h2 id=\"jemalloc的理念\"><a href=\"#jemalloc的理念\" class=\"headerlink\" title=\"jemalloc的理念\"></a>jemalloc的理念</h2><p>我们以买火车票为例，来简单地说明一下jemalloc与malloc的区别。原来的malloc，相当于只有一个售票窗口的售票大厅，<br>而jemalloc则在同一个售票大厅里面适量地增加的窗口。当然，火车票的总量(即内存大小)是不变的，买票的人相当于线程了。<br>说起来这也是很自然的事情的。</p>\n<blockquote>\n<p>在这里，一个售票窗口就是相当于一个<strong>Arena</strong>。</p>\n</blockquote>\n<p>Arena则按页(Page)来的管理内存，也就是说，一张车票就相当于一页。（后面就不太适合用火车票的例子了）。</p>\n<p>同时，jemalloc还根据所请求的内存大小，对其进行分类。如下图：</p>\n<p><img src=\"http://farm4.staticflickr.com/3749/12402575993_30e006725c_o.png\" alt=\"jemalloc allocation size category\"></p>\n<p>默认情况下，Page的大小为4KB。如图，有三类，small、large和huge。small类的内存请求都属于一个内存页之内<br>（没有半张车票出售:(）。另外，在small类里面，又分了三个子类，分别是Tiny、Quantum-Spaced和Sub-page。<br>这几个概念都在Netty中得到应用。</p>\n<p>每个线程都与某个Arena绑定在一起，线程采用round-robin算法来绑定到某个Arena。</p>\n<blockquote>\n<p>这里有个问题，就是与某个Arena相关的一批线程使用内存资源过快，导致该Arena的内存资源全部消耗殆尽，<br>而其它的Arena又有盈余，这时怎么处理？能否借用。</p>\n<p>目前还没有对jemalloc本身的实现做过多的研究。</p>\n</blockquote>\n<p>通过对jemalloc有个简单的了解后，我们再来看看，Netty4是如何借鉴jemalloc的经验的。需要注意的是，<br>jemalloc的实现，要远比Netty4复杂，一个是系统层的，一个则是应用层的。但两者的思想是相通的。</p>\n<h1 id=\"Netty4中的内存管理\"><a href=\"#Netty4中的内存管理\" class=\"headerlink\" title=\"Netty4中的内存管理\"></a>Netty4中的内存管理</h1><p>以下内容所参考的代码是<code>netty-4.0.15.Final</code>。</p>\n<p>Arena其实就是预先分配好的一个区域的内存。</p>\n<p>Netty4中，内存池管理的入口点是<code>PooledByteBufAllocator</code>。在该实现中，除了Arena和Page之外，<br>还一个Chunk的概念。一个Arena由多个Chunk组成，而Chunk则由N个Page组成。</p>\n<p>默认配置中，</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 默认页面大小为8KB</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> defaultPageSize = SystemPropertyUtil.getInt(<span class=\"string\">\"io.netty.allocator.pageSize\"</span>, <span class=\"number\">8192</span>); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 默认的Chunk大小为16MB，即由2048个页面组成</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> defaultMaxOrder = SystemPropertyUtil.getInt(<span class=\"string\">\"io.netty.allocator.maxOrder\"</span>, <span class=\"number\">11</span>);</span><br><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"keyword\">int</span> defaultChunkSize = DEFAULT_PAGE_SIZE &lt;&lt; DEFAULT_MAX_ORDER;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 默认情况下，一个Arena由3个Chunk组成，且所有Arena（就同一类而言）所占用的内存总数，</span></span><br><span class=\"line\"><span class=\"comment\">// 不能超过可用内存的一半(50%)。</span></span><br><span class=\"line\"></span><br><span class=\"line\">DEFAULT_NUM_HEAP_ARENA = Math.max(<span class=\"number\">0</span>,</span><br><span class=\"line\">        SystemPropertyUtil.getInt(</span><br><span class=\"line\">                <span class=\"string\">\"io.netty.allocator.numHeapArenas\"</span>,</span><br><span class=\"line\">                (<span class=\"keyword\">int</span>) Math.min(</span><br><span class=\"line\">                        runtime.availableProcessors(),</span><br><span class=\"line\">                        Runtime.getRuntime().maxMemory() / defaultChunkSize / <span class=\"number\">2</span> / <span class=\"number\">3</span>)));</span><br><span class=\"line\">DEFAULT_NUM_DIRECT_ARENA = Math.max(<span class=\"number\">0</span>,</span><br><span class=\"line\">        SystemPropertyUtil.getInt(</span><br><span class=\"line\">                <span class=\"string\">\"io.netty.allocator.numDirectArenas\"</span>,</span><br><span class=\"line\">                (<span class=\"keyword\">int</span>) Math.min(</span><br><span class=\"line\">                        runtime.availableProcessors(),</span><br><span class=\"line\">                        PlatformDependent.maxDirectMemory() / defaultChunkSize / <span class=\"number\">2</span> / <span class=\"number\">3</span>)));</span><br></pre></td></tr></table></figure>\n\n<p>根据以上代码，我们发现，Arena是分为两类的，一类是基于堆；另一类则是Direct内存（直接向操作系统请求的）。<br>具体使用哪一类，默认是根据所使用的虚拟机而定，优先使用Direct类型（如果可用的话）。判断的条件是，<br>看能否访问JVM的<code>Unsafe</code>类。具体可以参考<code>PlatformDependent.hasUnsafe()</code>方法。</p>\n<blockquote>\n<p>这里提到的两类不会被同时使用的！</p>\n</blockquote>\n<p>另外，对于内存请求大小的分类，这里也有一些变动。对于所请求内存的大小N</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> N &lt; PAGE_SIZE:</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> N &lt; <span class=\"number\">512</span>:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> TINY;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> SMALL;</span><br><span class=\"line\">elif N &gt; CHUNK_SIZE:</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> HUGE;</span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">\t<span class=\"keyword\">return</span> LARGE;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"内存管理\"><a href=\"#内存管理\" class=\"headerlink\" title=\"内存管理\"></a>内存管理</h2><p>现在，我们来仔细地看看内存分配的过程。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PooledByteBufAllocator alloc = <span class=\"keyword\">new</span> PooledByteBufAllocator(PlatformDependent.directBufferPreferred());</span><br><span class=\"line\">ByteBuf buff = alloc.ioBuffer(N);</span><br></pre></td></tr></table></figure>\n\n<p>假设在当前的JVM环境中，Direct内存可用的。那当我们尝试去申请N字节的内存时，其实现流程如下：</p>\n<ol>\n<li>获取一个ByteBuf对象，但是该对象未与任何可用内存空间关联。</li>\n<li>检查N的大小，并对N进行修正。。</li>\n<li>分配内存。</li>\n</ol>\n<p>对N的修正：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">int</span> <span class=\"title\">normalizeCapacity</span><span class=\"params\">(<span class=\"keyword\">int</span> reqCapacity)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (reqCapacity &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(<span class=\"string\">\"capacity: \"</span> + reqCapacity + <span class=\"string\">\" (expected: 0+)\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (reqCapacity &gt;= chunkSize) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> reqCapacity;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((reqCapacity &amp; <span class=\"number\">0xFFFFFE00</span>) != <span class=\"number\">0</span>) &#123; <span class=\"comment\">// &gt;= 512</span></span><br><span class=\"line\">        <span class=\"comment\">// Doubled</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">int</span> normalizedCapacity = reqCapacity;</span><br><span class=\"line\">        normalizedCapacity |= normalizedCapacity &gt;&gt;&gt;  <span class=\"number\">1</span>;</span><br><span class=\"line\">        normalizedCapacity |= normalizedCapacity &gt;&gt;&gt;  <span class=\"number\">2</span>;</span><br><span class=\"line\">        normalizedCapacity |= normalizedCapacity &gt;&gt;&gt;  <span class=\"number\">4</span>;</span><br><span class=\"line\">        normalizedCapacity |= normalizedCapacity &gt;&gt;&gt;  <span class=\"number\">8</span>;</span><br><span class=\"line\">        normalizedCapacity |= normalizedCapacity &gt;&gt;&gt; <span class=\"number\">16</span>;</span><br><span class=\"line\">        normalizedCapacity ++;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (normalizedCapacity &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            normalizedCapacity &gt;&gt;&gt;= <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> normalizedCapacity;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// Quantum-spaced</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((reqCapacity &amp; <span class=\"number\">15</span>) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> reqCapacity;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (reqCapacity &amp; ~<span class=\"number\">15</span>) + <span class=\"number\">16</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>说到内存的分配，则需要对页的管理有一定的了解。</p>\n<h3 id=\"内存页的管理模型\"><a href=\"#内存页的管理模型\" class=\"headerlink\" title=\"内存页的管理模型\"></a>内存页的管理模型</h3><p>Netty4使用了二叉树来管理每一个内存页。假设一个Chunk是由连续的N块内存页组成，<br>则Netty4使用一个长度为<code>2N</code>的整型数组来记录和管理每一个内存页的使用情况。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span>[] memoryMap = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[N &lt;&lt; <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure>\n\n<p>假设N=4，则下图，基于<code>memoryMap</code>的二叉树的结构。每个结点的序号为数组的索引值。其中4、5、6、7是这四个叶子节点，<br>分别用来记录4个内存页的使用状态。而2、3是用来表示其管辖的内存页的使用状态。节点1则管理整个Chunk的状态。</p>\n<p><img src=\"http://farm3.staticflickr.com/2805/12403894375_2ee7cf93a4_o.png\" alt=\"基于一维数组的二叉树\"></p>\n<p>内存页的状态有四种：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ST_UNUSED = <span class=\"number\">0</span>;  <span class=\"comment\">// 初始状态，未使用</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ST_BRANCH = <span class=\"number\">1</span>;  <span class=\"comment\">// 只对非叶子节点有效，表明该节点下某一部分叶子节点被使用</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 被使用，如果是叶子节点，则表明对应的内存页已经分配出去了</span></span><br><span class=\"line\"><span class=\"comment\">// 如果是非叶子节点，则表明该节点所管辖的内存页已经全部分配出去了</span></span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ST_ALLOCATED = <span class=\"number\">2</span>; </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 只对叶子节点有效，表示内存页里面的一部分被分配出去了。这种情况属于Tiny类型的内存请求。</span></span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ST_ALLOCATED_SUBPAGE = ST_ALLOCATED | <span class=\"number\">1</span>;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"内存页的分配\"><a href=\"#内存页的分配\" class=\"headerlink\" title=\"内存页的分配\"></a>内存页的分配</h3><p>内存页的分配有两种情况，有多页分配和页内分配。这里我们先说多页（1个内存页以上）的分配。<br>当请求的内存大小大于一个内存页时，<code>PooledByteBufAllocator</code>会通过遍历<code>memoryMap</code>来，来找出合适内存页。</p>\n<ol>\n<li>首先，它要判断根节点1是否已经被分配，如果是，则表示当前的个Chunk已经没有可用的空间，它需要去其的Chunk找了。</li>\n<li>接着，随机选择当前节点的某一个子节点（2或者3），判断是否有可用空间</li>\n<li>重复步骤2，直到找到可用的内存页</li>\n</ol>\n<blockquote>\n<p>先写到这里，以下剩余内容的目录。另外，对<code>memoryMap</code>中的值，也需要进一步的说明,<br>因为关系具体的内存位置。</p>\n<p>写博客果然比较费事！</p>\n</blockquote>\n<h3 id=\"页内分配\"><a href=\"#页内分配\" class=\"headerlink\" title=\"页内分配\"></a>页内分配</h3><h1 id=\"内存的释放\"><a href=\"#内存的释放\" class=\"headerlink\" title=\"内存的释放\"></a>内存的释放</h1><h2 id=\"内存页的释放\"><a href=\"#内存页的释放\" class=\"headerlink\" title=\"内存页的释放\"></a>内存页的释放</h2><h2 id=\"页内释放\"><a href=\"#页内释放\" class=\"headerlink\" title=\"页内释放\"></a>页内释放</h2><h1 id=\"其它\"><a href=\"#其它\" class=\"headerlink\" title=\"其它\"></a>其它</h1><h2 id=\"ByteBuf实例缓存\"><a href=\"#ByteBuf实例缓存\" class=\"headerlink\" title=\"ByteBuf实例缓存\"></a>ByteBuf实例缓存</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">* For simplicity all sizes are normalized according to PoolArena#normalizeCapacity method</span><br><span class=\"line\">* This ensures that when we request for memory segments of size &gt;= pageSize the normalizedCapacity</span><br><span class=\"line\">* equals the next nearest power of 2</span><br><span class=\"line\">*</span><br><span class=\"line\">* To search for the first offset in chunk that has at least requested size available we construct a</span><br><span class=\"line\">* complete balanced binary tree and store it in an array (just like heaps) - memoryMap</span><br><span class=\"line\">*</span><br><span class=\"line\">* The tree looks like this (the size of each node being mentioned in the parenthesis)</span><br><span class=\"line\">*</span><br><span class=\"line\">* depth=0        1 node (chunkSize)</span><br><span class=\"line\">* depth=1        2 nodes (chunkSize/2)</span><br><span class=\"line\">* ..</span><br><span class=\"line\">* ..</span><br><span class=\"line\">* depth=d        2^d nodes (chunkSize/2^d)</span><br><span class=\"line\">* ..</span><br><span class=\"line\">* depth=maxOrder 2^maxOrder nodes (chunkSize/2^&#123;maxOrder&#125; = pageSize)</span><br><span class=\"line\">*</span><br><span class=\"line\">* depth=maxOrder is the last level and the leafs consist of pages</span><br></pre></td></tr></table></figure>\n\n<p>###<br>Netty 内存分配</p>\n<ul>\n<li>ByteBuf 分类</li>\n<li>内存规格是什么样的</li>\n<li>缓存数据结构</li>\n<li>directArena 分配 direct 内存的流程</li>\n<li>从对象池里面拿到 PooledByteBuf 进行复用</li>\n<li>从缓存上进行内存分配</li>\n<li>从内存堆里面进行分配</li>\n<li>arena、chunk、page、subpage之间的关系是什么？Netty 是如何维护他们之间的关系</li>\n<li>page 是如何进行内存划分的</li>\n<li>subpage 又是如何进行内存划分的</li>\n<li>ByteBuf 的回收</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p><a href=\"http://wangkaisino.blog.163.com/blog/static/1870444202011431112323846\" target=\"_blank\" rel=\"noopener\">http://wangkaisino.blog.163.com/blog/static/1870444202011431112323846</a></p>\n<p>转载:</p>\n<p>在Netty4中引入了新的内存管理机制极大地提升其性能，本文将对该内在管理机制进行剖析。</p>\n<p>这里<a href=\"http://www.infoq.com/news/2013/11/netty4-twitter\" target=\"_blank\" rel=\"noopener\">有篇文章</a>讲述了在推特(Twitter)内部<br>使用Netty的状况以及Netty4所带来的性能收益。</p>","more":"<p>在分析Netty4的<code>PooledByteBufAllocator</code>之前，我们最好先认识一下<a href=\"http://www.canonware.com/jemalloc/\" target=\"_blank\" rel=\"noopener\">jemalloc</a>。<br>Netty在4.0之前的版本已经尝试过通过优化内存管理的方式来提高性能（如果我没有记错的话），但4.0中的改进则特别<br>显著。在这个版本中，其内存管理实现主要是参考了<code>jemalloc</code>。</p>\n<h1 id=\"jemalloc\"><a href=\"#jemalloc\" class=\"headerlink\" title=\"jemalloc\"></a>jemalloc</h1><p><strong>jemalloc</strong> 是由Jason Evans在FreeBSD项目中引入的，其主旨是为了提升在并发环境下内存的分配效率。说白了就是替代<br><code>malloc</code>。malloc之所以没有照顾到并发环境，那是由于在那个时代并发还只在理论，未曾普及。而现在则是多核的天下，连<br>手机都动则2、4核，甚至于8核了。与jemalloc齐名的还有Google的<a href=\"https://code.google.com/p/gperftools/\" target=\"_blank\" rel=\"noopener\">tcmalloc</a>，其<br>实现与jemalloc多少也有点相似，这里不做介绍。</p>\n<h2 id=\"jemalloc的理念\"><a href=\"#jemalloc的理念\" class=\"headerlink\" title=\"jemalloc的理念\"></a>jemalloc的理念</h2><p>我们以买火车票为例，来简单地说明一下jemalloc与malloc的区别。原来的malloc，相当于只有一个售票窗口的售票大厅，<br>而jemalloc则在同一个售票大厅里面适量地增加的窗口。当然，火车票的总量(即内存大小)是不变的，买票的人相当于线程了。<br>说起来这也是很自然的事情的。</p>\n<blockquote>\n<p>在这里，一个售票窗口就是相当于一个<strong>Arena</strong>。</p>\n</blockquote>\n<p>Arena则按页(Page)来的管理内存，也就是说，一张车票就相当于一页。（后面就不太适合用火车票的例子了）。</p>\n<p>同时，jemalloc还根据所请求的内存大小，对其进行分类。如下图：</p>\n<p><img src=\"http://farm4.staticflickr.com/3749/12402575993_30e006725c_o.png\" alt=\"jemalloc allocation size category\"></p>\n<p>默认情况下，Page的大小为4KB。如图，有三类，small、large和huge。small类的内存请求都属于一个内存页之内<br>（没有半张车票出售:(）。另外，在small类里面，又分了三个子类，分别是Tiny、Quantum-Spaced和Sub-page。<br>这几个概念都在Netty中得到应用。</p>\n<p>每个线程都与某个Arena绑定在一起，线程采用round-robin算法来绑定到某个Arena。</p>\n<blockquote>\n<p>这里有个问题，就是与某个Arena相关的一批线程使用内存资源过快，导致该Arena的内存资源全部消耗殆尽，<br>而其它的Arena又有盈余，这时怎么处理？能否借用。</p>\n<p>目前还没有对jemalloc本身的实现做过多的研究。</p>\n</blockquote>\n<p>通过对jemalloc有个简单的了解后，我们再来看看，Netty4是如何借鉴jemalloc的经验的。需要注意的是，<br>jemalloc的实现，要远比Netty4复杂，一个是系统层的，一个则是应用层的。但两者的思想是相通的。</p>\n<h1 id=\"Netty4中的内存管理\"><a href=\"#Netty4中的内存管理\" class=\"headerlink\" title=\"Netty4中的内存管理\"></a>Netty4中的内存管理</h1><p>以下内容所参考的代码是<code>netty-4.0.15.Final</code>。</p>\n<p>Arena其实就是预先分配好的一个区域的内存。</p>\n<p>Netty4中，内存池管理的入口点是<code>PooledByteBufAllocator</code>。在该实现中，除了Arena和Page之外，<br>还一个Chunk的概念。一个Arena由多个Chunk组成，而Chunk则由N个Page组成。</p>\n<p>默认配置中，</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 默认页面大小为8KB</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> defaultPageSize = SystemPropertyUtil.getInt(<span class=\"string\">\"io.netty.allocator.pageSize\"</span>, <span class=\"number\">8192</span>); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 默认的Chunk大小为16MB，即由2048个页面组成</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> defaultMaxOrder = SystemPropertyUtil.getInt(<span class=\"string\">\"io.netty.allocator.maxOrder\"</span>, <span class=\"number\">11</span>);</span><br><span class=\"line\"><span class=\"keyword\">final</span> <span class=\"keyword\">int</span> defaultChunkSize = DEFAULT_PAGE_SIZE &lt;&lt; DEFAULT_MAX_ORDER;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 默认情况下，一个Arena由3个Chunk组成，且所有Arena（就同一类而言）所占用的内存总数，</span></span><br><span class=\"line\"><span class=\"comment\">// 不能超过可用内存的一半(50%)。</span></span><br><span class=\"line\"></span><br><span class=\"line\">DEFAULT_NUM_HEAP_ARENA = Math.max(<span class=\"number\">0</span>,</span><br><span class=\"line\">        SystemPropertyUtil.getInt(</span><br><span class=\"line\">                <span class=\"string\">\"io.netty.allocator.numHeapArenas\"</span>,</span><br><span class=\"line\">                (<span class=\"keyword\">int</span>) Math.min(</span><br><span class=\"line\">                        runtime.availableProcessors(),</span><br><span class=\"line\">                        Runtime.getRuntime().maxMemory() / defaultChunkSize / <span class=\"number\">2</span> / <span class=\"number\">3</span>)));</span><br><span class=\"line\">DEFAULT_NUM_DIRECT_ARENA = Math.max(<span class=\"number\">0</span>,</span><br><span class=\"line\">        SystemPropertyUtil.getInt(</span><br><span class=\"line\">                <span class=\"string\">\"io.netty.allocator.numDirectArenas\"</span>,</span><br><span class=\"line\">                (<span class=\"keyword\">int</span>) Math.min(</span><br><span class=\"line\">                        runtime.availableProcessors(),</span><br><span class=\"line\">                        PlatformDependent.maxDirectMemory() / defaultChunkSize / <span class=\"number\">2</span> / <span class=\"number\">3</span>)));</span><br></pre></td></tr></table></figure>\n\n<p>根据以上代码，我们发现，Arena是分为两类的，一类是基于堆；另一类则是Direct内存（直接向操作系统请求的）。<br>具体使用哪一类，默认是根据所使用的虚拟机而定，优先使用Direct类型（如果可用的话）。判断的条件是，<br>看能否访问JVM的<code>Unsafe</code>类。具体可以参考<code>PlatformDependent.hasUnsafe()</code>方法。</p>\n<blockquote>\n<p>这里提到的两类不会被同时使用的！</p>\n</blockquote>\n<p>另外，对于内存请求大小的分类，这里也有一些变动。对于所请求内存的大小N</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> N &lt; PAGE_SIZE:</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> N &lt; <span class=\"number\">512</span>:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> TINY;</span><br><span class=\"line\">\t<span class=\"keyword\">else</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> SMALL;</span><br><span class=\"line\">elif N &gt; CHUNK_SIZE:</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> HUGE;</span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">\t<span class=\"keyword\">return</span> LARGE;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"内存管理\"><a href=\"#内存管理\" class=\"headerlink\" title=\"内存管理\"></a>内存管理</h2><p>现在，我们来仔细地看看内存分配的过程。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PooledByteBufAllocator alloc = <span class=\"keyword\">new</span> PooledByteBufAllocator(PlatformDependent.directBufferPreferred());</span><br><span class=\"line\">ByteBuf buff = alloc.ioBuffer(N);</span><br></pre></td></tr></table></figure>\n\n<p>假设在当前的JVM环境中，Direct内存可用的。那当我们尝试去申请N字节的内存时，其实现流程如下：</p>\n<ol>\n<li>获取一个ByteBuf对象，但是该对象未与任何可用内存空间关联。</li>\n<li>检查N的大小，并对N进行修正。。</li>\n<li>分配内存。</li>\n</ol>\n<p>对N的修正：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">int</span> <span class=\"title\">normalizeCapacity</span><span class=\"params\">(<span class=\"keyword\">int</span> reqCapacity)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (reqCapacity &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(<span class=\"string\">\"capacity: \"</span> + reqCapacity + <span class=\"string\">\" (expected: 0+)\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (reqCapacity &gt;= chunkSize) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> reqCapacity;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((reqCapacity &amp; <span class=\"number\">0xFFFFFE00</span>) != <span class=\"number\">0</span>) &#123; <span class=\"comment\">// &gt;= 512</span></span><br><span class=\"line\">        <span class=\"comment\">// Doubled</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">int</span> normalizedCapacity = reqCapacity;</span><br><span class=\"line\">        normalizedCapacity |= normalizedCapacity &gt;&gt;&gt;  <span class=\"number\">1</span>;</span><br><span class=\"line\">        normalizedCapacity |= normalizedCapacity &gt;&gt;&gt;  <span class=\"number\">2</span>;</span><br><span class=\"line\">        normalizedCapacity |= normalizedCapacity &gt;&gt;&gt;  <span class=\"number\">4</span>;</span><br><span class=\"line\">        normalizedCapacity |= normalizedCapacity &gt;&gt;&gt;  <span class=\"number\">8</span>;</span><br><span class=\"line\">        normalizedCapacity |= normalizedCapacity &gt;&gt;&gt; <span class=\"number\">16</span>;</span><br><span class=\"line\">        normalizedCapacity ++;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (normalizedCapacity &lt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            normalizedCapacity &gt;&gt;&gt;= <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> normalizedCapacity;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// Quantum-spaced</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> ((reqCapacity &amp; <span class=\"number\">15</span>) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> reqCapacity;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (reqCapacity &amp; ~<span class=\"number\">15</span>) + <span class=\"number\">16</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>说到内存的分配，则需要对页的管理有一定的了解。</p>\n<h3 id=\"内存页的管理模型\"><a href=\"#内存页的管理模型\" class=\"headerlink\" title=\"内存页的管理模型\"></a>内存页的管理模型</h3><p>Netty4使用了二叉树来管理每一个内存页。假设一个Chunk是由连续的N块内存页组成，<br>则Netty4使用一个长度为<code>2N</code>的整型数组来记录和管理每一个内存页的使用情况。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span>[] memoryMap = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[N &lt;&lt; <span class=\"number\">1</span>]</span><br></pre></td></tr></table></figure>\n\n<p>假设N=4，则下图，基于<code>memoryMap</code>的二叉树的结构。每个结点的序号为数组的索引值。其中4、5、6、7是这四个叶子节点，<br>分别用来记录4个内存页的使用状态。而2、3是用来表示其管辖的内存页的使用状态。节点1则管理整个Chunk的状态。</p>\n<p><img src=\"http://farm3.staticflickr.com/2805/12403894375_2ee7cf93a4_o.png\" alt=\"基于一维数组的二叉树\"></p>\n<p>内存页的状态有四种：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ST_UNUSED = <span class=\"number\">0</span>;  <span class=\"comment\">// 初始状态，未使用</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ST_BRANCH = <span class=\"number\">1</span>;  <span class=\"comment\">// 只对非叶子节点有效，表明该节点下某一部分叶子节点被使用</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 被使用，如果是叶子节点，则表明对应的内存页已经分配出去了</span></span><br><span class=\"line\"><span class=\"comment\">// 如果是非叶子节点，则表明该节点所管辖的内存页已经全部分配出去了</span></span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ST_ALLOCATED = <span class=\"number\">2</span>; </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 只对叶子节点有效，表示内存页里面的一部分被分配出去了。这种情况属于Tiny类型的内存请求。</span></span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> ST_ALLOCATED_SUBPAGE = ST_ALLOCATED | <span class=\"number\">1</span>;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"内存页的分配\"><a href=\"#内存页的分配\" class=\"headerlink\" title=\"内存页的分配\"></a>内存页的分配</h3><p>内存页的分配有两种情况，有多页分配和页内分配。这里我们先说多页（1个内存页以上）的分配。<br>当请求的内存大小大于一个内存页时，<code>PooledByteBufAllocator</code>会通过遍历<code>memoryMap</code>来，来找出合适内存页。</p>\n<ol>\n<li>首先，它要判断根节点1是否已经被分配，如果是，则表示当前的个Chunk已经没有可用的空间，它需要去其的Chunk找了。</li>\n<li>接着，随机选择当前节点的某一个子节点（2或者3），判断是否有可用空间</li>\n<li>重复步骤2，直到找到可用的内存页</li>\n</ol>\n<blockquote>\n<p>先写到这里，以下剩余内容的目录。另外，对<code>memoryMap</code>中的值，也需要进一步的说明,<br>因为关系具体的内存位置。</p>\n<p>写博客果然比较费事！</p>\n</blockquote>\n<h3 id=\"页内分配\"><a href=\"#页内分配\" class=\"headerlink\" title=\"页内分配\"></a>页内分配</h3><h1 id=\"内存的释放\"><a href=\"#内存的释放\" class=\"headerlink\" title=\"内存的释放\"></a>内存的释放</h1><h2 id=\"内存页的释放\"><a href=\"#内存页的释放\" class=\"headerlink\" title=\"内存页的释放\"></a>内存页的释放</h2><h2 id=\"页内释放\"><a href=\"#页内释放\" class=\"headerlink\" title=\"页内释放\"></a>页内释放</h2><h1 id=\"其它\"><a href=\"#其它\" class=\"headerlink\" title=\"其它\"></a>其它</h1><h2 id=\"ByteBuf实例缓存\"><a href=\"#ByteBuf实例缓存\" class=\"headerlink\" title=\"ByteBuf实例缓存\"></a>ByteBuf实例缓存</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">* For simplicity all sizes are normalized according to PoolArena#normalizeCapacity method</span><br><span class=\"line\">* This ensures that when we request for memory segments of size &gt;= pageSize the normalizedCapacity</span><br><span class=\"line\">* equals the next nearest power of 2</span><br><span class=\"line\">*</span><br><span class=\"line\">* To search for the first offset in chunk that has at least requested size available we construct a</span><br><span class=\"line\">* complete balanced binary tree and store it in an array (just like heaps) - memoryMap</span><br><span class=\"line\">*</span><br><span class=\"line\">* The tree looks like this (the size of each node being mentioned in the parenthesis)</span><br><span class=\"line\">*</span><br><span class=\"line\">* depth=0        1 node (chunkSize)</span><br><span class=\"line\">* depth=1        2 nodes (chunkSize/2)</span><br><span class=\"line\">* ..</span><br><span class=\"line\">* ..</span><br><span class=\"line\">* depth=d        2^d nodes (chunkSize/2^d)</span><br><span class=\"line\">* ..</span><br><span class=\"line\">* depth=maxOrder 2^maxOrder nodes (chunkSize/2^&#123;maxOrder&#125; = pageSize)</span><br><span class=\"line\">*</span><br><span class=\"line\">* depth=maxOrder is the last level and the leafs consist of pages</span><br></pre></td></tr></table></figure>\n\n<p>###<br>Netty 内存分配</p>\n<ul>\n<li>ByteBuf 分类</li>\n<li>内存规格是什么样的</li>\n<li>缓存数据结构</li>\n<li>directArena 分配 direct 内存的流程</li>\n<li>从对象池里面拿到 PooledByteBuf 进行复用</li>\n<li>从缓存上进行内存分配</li>\n<li>从内存堆里面进行分配</li>\n<li>arena、chunk、page、subpage之间的关系是什么？Netty 是如何维护他们之间的关系</li>\n<li>page 是如何进行内存划分的</li>\n<li>subpage 又是如何进行内存划分的</li>\n<li>ByteBuf 的回收</li>\n</ul>"},{"title":"Netty-Performance-Test","date":"2017-12-07T04:52:29.000Z","_content":"\nhttps://www.infoq.com/news/2013/11/netty4-twitter","source":"_posts/Netty-Performance-Test.md","raw":"---\ntitle: Netty-Performance-Test\ndate: 2017-12-07 12:52:29\ntags: Netty\n---\n\nhttps://www.infoq.com/news/2013/11/netty4-twitter","slug":"Netty-Performance-Test","published":1,"updated":"2019-09-28T08:51:00.912Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84b004av1npyris4r01","content":"<p><a href=\"https://www.infoq.com/news/2013/11/netty4-twitter\" target=\"_blank\" rel=\"noopener\">https://www.infoq.com/news/2013/11/netty4-twitter</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.infoq.com/news/2013/11/netty4-twitter\" target=\"_blank\" rel=\"noopener\">https://www.infoq.com/news/2013/11/netty4-twitter</a></p>\n"},{"title":"Netty-Mpsc-queue","date":"2019-01-14T02:22:12.000Z","_content":"\n\nNetty中MpscQueue的实现\nhttps://www.jianshu.com/p/c7ef93e65832","source":"_posts/Netty-Mpsc-queue.md","raw":"---\ntitle: Netty-Mpsc-queue\ndate: 2019-01-14 10:22:12\ntags:\n---\n\n\nNetty中MpscQueue的实现\nhttps://www.jianshu.com/p/c7ef93e65832","slug":"Netty-Mpsc-queue","published":1,"updated":"2019-09-28T08:51:00.912Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84c004bv1npt60ezr6k","content":"<p>Netty中MpscQueue的实现<br><a href=\"https://www.jianshu.com/p/c7ef93e65832\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/c7ef93e65832</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Netty中MpscQueue的实现<br><a href=\"https://www.jianshu.com/p/c7ef93e65832\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/c7ef93e65832</a></p>\n"},{"title":"Netty-Source","date":"2019-02-24T13:16:25.000Z","_content":"\n\n\n\nhttps://blog.csdn.net/RobertoHuang/column/info/24824\n","source":"_posts/Netty-Source.md","raw":"---\ntitle: Netty-Source\ndate: 2019-02-24 21:16:25\ntags:\n---\n\n\n\n\nhttps://blog.csdn.net/RobertoHuang/column/info/24824\n","slug":"Netty-Source","published":1,"updated":"2019-09-28T08:51:00.912Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84c004cv1npspicr5dg","content":"<p><a href=\"https://blog.csdn.net/RobertoHuang/column/info/24824\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/RobertoHuang/column/info/24824</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/RobertoHuang/column/info/24824\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/RobertoHuang/column/info/24824</a></p>\n"},{"title":"Netty-TrafficShaping","date":"2019-03-01T03:10:02.000Z","_content":"","source":"_posts/Netty-TrafficShaping.md","raw":"---\ntitle: Netty-TrafficShaping\ndate: 2019-03-01 11:10:02\ntags:\n---\n","slug":"Netty-TrafficShaping","published":1,"updated":"2019-09-28T08:51:00.912Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84d004dv1npzhvt83gc","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Netty-Transport-Native","date":"2019-01-12T01:47:39.000Z","_content":"\n### 查看glibc版本\n\n\nhttps://www.cnblogs.com/lemontea-t/p/4919091.html\n```\nLT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表．\n\n优点：当进行socket通信的时候，保证了数据的完整输出，进行IO操作的时候，如果还有数据，就会一直的通知你。\n\n缺点：由于只要还有数据，内核就会不停的从内核空间转到用户空间，所有占用了大量内核资源，试想一下当有大量数据到来的时候，每次读取一个字节，这样就会不停的进行切换。内核资源的浪费严重。效率来讲也是很低的。\n\nET:\n\nET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知。请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once).\n\n优点：每次内核只会通知一次，大大减少了内核资源的浪费，提高效率。\n\n缺点：不能保证数据的完整。不能及时的取出所有的数据。\n\n应用场景： 处理大数据。使用non-block模式的socket。\n```\n","source":"_posts/Netty-Transport-Native.md","raw":"---\ntitle: Netty-Transport-Native\ndate: 2019-01-12 09:47:39\ntags:\n---\n\n### 查看glibc版本\n\n\nhttps://www.cnblogs.com/lemontea-t/p/4919091.html\n```\nLT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表．\n\n优点：当进行socket通信的时候，保证了数据的完整输出，进行IO操作的时候，如果还有数据，就会一直的通知你。\n\n缺点：由于只要还有数据，内核就会不停的从内核空间转到用户空间，所有占用了大量内核资源，试想一下当有大量数据到来的时候，每次读取一个字节，这样就会不停的进行切换。内核资源的浪费严重。效率来讲也是很低的。\n\nET:\n\nET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知。请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once).\n\n优点：每次内核只会通知一次，大大减少了内核资源的浪费，提高效率。\n\n缺点：不能保证数据的完整。不能及时的取出所有的数据。\n\n应用场景： 处理大数据。使用non-block模式的socket。\n```\n","slug":"Netty-Transport-Native","published":1,"updated":"2019-09-28T08:51:00.913Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84d004ev1np8umcheea","content":"<h3 id=\"查看glibc版本\"><a href=\"#查看glibc版本\" class=\"headerlink\" title=\"查看glibc版本\"></a>查看glibc版本</h3><p><a href=\"https://www.cnblogs.com/lemontea-t/p/4919091.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/lemontea-t/p/4919091.html</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表．</span><br><span class=\"line\"></span><br><span class=\"line\">优点：当进行socket通信的时候，保证了数据的完整输出，进行IO操作的时候，如果还有数据，就会一直的通知你。</span><br><span class=\"line\"></span><br><span class=\"line\">缺点：由于只要还有数据，内核就会不停的从内核空间转到用户空间，所有占用了大量内核资源，试想一下当有大量数据到来的时候，每次读取一个字节，这样就会不停的进行切换。内核资源的浪费严重。效率来讲也是很低的。</span><br><span class=\"line\"></span><br><span class=\"line\">ET:</span><br><span class=\"line\"></span><br><span class=\"line\">ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知。请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once).</span><br><span class=\"line\"></span><br><span class=\"line\">优点：每次内核只会通知一次，大大减少了内核资源的浪费，提高效率。</span><br><span class=\"line\"></span><br><span class=\"line\">缺点：不能保证数据的完整。不能及时的取出所有的数据。</span><br><span class=\"line\"></span><br><span class=\"line\">应用场景： 处理大数据。使用non-block模式的socket。</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"查看glibc版本\"><a href=\"#查看glibc版本\" class=\"headerlink\" title=\"查看glibc版本\"></a>查看glibc版本</h3><p><a href=\"https://www.cnblogs.com/lemontea-t/p/4919091.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/lemontea-t/p/4919091.html</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表．</span><br><span class=\"line\"></span><br><span class=\"line\">优点：当进行socket通信的时候，保证了数据的完整输出，进行IO操作的时候，如果还有数据，就会一直的通知你。</span><br><span class=\"line\"></span><br><span class=\"line\">缺点：由于只要还有数据，内核就会不停的从内核空间转到用户空间，所有占用了大量内核资源，试想一下当有大量数据到来的时候，每次读取一个字节，这样就会不停的进行切换。内核资源的浪费严重。效率来讲也是很低的。</span><br><span class=\"line\"></span><br><span class=\"line\">ET:</span><br><span class=\"line\"></span><br><span class=\"line\">ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知。请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once).</span><br><span class=\"line\"></span><br><span class=\"line\">优点：每次内核只会通知一次，大大减少了内核资源的浪费，提高效率。</span><br><span class=\"line\"></span><br><span class=\"line\">缺点：不能保证数据的完整。不能及时的取出所有的数据。</span><br><span class=\"line\"></span><br><span class=\"line\">应用场景： 处理大数据。使用non-block模式的socket。</span><br></pre></td></tr></table></figure>\n\n"},{"title":"Netty-NioEventLoop","date":"2019-02-27T03:06:40.000Z","_content":"\n\nNetty的线程池理念有点像ForkJoinPool，都不是一个线程大池子并发等待一条任务队列，而是每条线程自己一个任务队列，怎么做的？建了N个只有一条线程的线程池。\n\n而且Netty的线程，并不只是简单的阻塞地拉取任务，而是非常辛苦命的在每个循环做三件事情：\n\n先SelectKeys()处理NIO的事件\n\n然后获取2.3里提到的本线程的定时任务，放到本线程的任务队列里\n\n再然后混合2.2里提到的其他线程提交给本线程的任务，一起执行\n\n每个循环里处理NIO事件与其他任务的时间消耗比例，还能通过ioRatio变量来控制，默认是各占50%。\n\n可见，Netty的线程根本没有阻塞等待任务的清闲日子，所以也不使用有锁的BlockingQueue如ArrayBlockingQueue来做任务队列了，而是使用后面提到的无锁的MpscLinkedQueue(Mpsc 是Multiple Producer, Single Consumer的缩写)。","source":"_posts/Netty-NioEventLoop.md","raw":"---\ntitle: Netty-NioEventLoop\ndate: 2019-02-27 11:06:40\ntags:\n---\n\n\nNetty的线程池理念有点像ForkJoinPool，都不是一个线程大池子并发等待一条任务队列，而是每条线程自己一个任务队列，怎么做的？建了N个只有一条线程的线程池。\n\n而且Netty的线程，并不只是简单的阻塞地拉取任务，而是非常辛苦命的在每个循环做三件事情：\n\n先SelectKeys()处理NIO的事件\n\n然后获取2.3里提到的本线程的定时任务，放到本线程的任务队列里\n\n再然后混合2.2里提到的其他线程提交给本线程的任务，一起执行\n\n每个循环里处理NIO事件与其他任务的时间消耗比例，还能通过ioRatio变量来控制，默认是各占50%。\n\n可见，Netty的线程根本没有阻塞等待任务的清闲日子，所以也不使用有锁的BlockingQueue如ArrayBlockingQueue来做任务队列了，而是使用后面提到的无锁的MpscLinkedQueue(Mpsc 是Multiple Producer, Single Consumer的缩写)。","slug":"Netty-NioEventLoop","published":1,"updated":"2019-09-28T08:51:00.912Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84e004fv1npu4y351k0","content":"<p>Netty的线程池理念有点像ForkJoinPool，都不是一个线程大池子并发等待一条任务队列，而是每条线程自己一个任务队列，怎么做的？建了N个只有一条线程的线程池。</p>\n<p>而且Netty的线程，并不只是简单的阻塞地拉取任务，而是非常辛苦命的在每个循环做三件事情：</p>\n<p>先SelectKeys()处理NIO的事件</p>\n<p>然后获取2.3里提到的本线程的定时任务，放到本线程的任务队列里</p>\n<p>再然后混合2.2里提到的其他线程提交给本线程的任务，一起执行</p>\n<p>每个循环里处理NIO事件与其他任务的时间消耗比例，还能通过ioRatio变量来控制，默认是各占50%。</p>\n<p>可见，Netty的线程根本没有阻塞等待任务的清闲日子，所以也不使用有锁的BlockingQueue如ArrayBlockingQueue来做任务队列了，而是使用后面提到的无锁的MpscLinkedQueue(Mpsc 是Multiple Producer, Single Consumer的缩写)。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Netty的线程池理念有点像ForkJoinPool，都不是一个线程大池子并发等待一条任务队列，而是每条线程自己一个任务队列，怎么做的？建了N个只有一条线程的线程池。</p>\n<p>而且Netty的线程，并不只是简单的阻塞地拉取任务，而是非常辛苦命的在每个循环做三件事情：</p>\n<p>先SelectKeys()处理NIO的事件</p>\n<p>然后获取2.3里提到的本线程的定时任务，放到本线程的任务队列里</p>\n<p>再然后混合2.2里提到的其他线程提交给本线程的任务，一起执行</p>\n<p>每个循环里处理NIO事件与其他任务的时间消耗比例，还能通过ioRatio变量来控制，默认是各占50%。</p>\n<p>可见，Netty的线程根本没有阻塞等待任务的清闲日子，所以也不使用有锁的BlockingQueue如ArrayBlockingQueue来做任务队列了，而是使用后面提到的无锁的MpscLinkedQueue(Mpsc 是Multiple Producer, Single Consumer的缩写)。</p>\n"},{"title":"Netty-Watermark","date":"2019-01-05T11:15:15.000Z","_content":"\n\nChannelOutboundBuffer\n\n```\n@Override\npublic final void write(Object msg, ChannelPromise promise) {\n    assertEventLoop();\n\n    ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;\n    if (outboundBuffer == null) {\n        // If the outboundBuffer is null we know the channel was closed and so\n        // need to fail the future right away. If it is not null the handling of the rest\n        // will be done in flush0()\n        // See https://github.com/netty/netty/issues/2362\n        safeSetFailure(promise, WRITE_CLOSED_CHANNEL_EXCEPTION);\n        // release message now to prevent resource-leak\n        ReferenceCountUtil.release(msg);\n        return;\n    }\n\n    int size;\n    try {\n        msg = filterOutboundMessage(msg);\n        size = pipeline.estimatorHandle().size(msg);\n        if (size < 0) {\n            size = 0;\n        }\n    } catch (Throwable t) {\n        safeSetFailure(promise, t);\n        ReferenceCountUtil.release(msg);\n        return;\n    }\n\n    outboundBuffer.addMessage(msg, size, promise);\n}\n\n\n/**\n * Add given message to this {@link ChannelOutboundBuffer}. The given {@link ChannelPromise} will be notified once\n * the message was written.\n */\npublic void addMessage(Object msg, int size, ChannelPromise promise) {\n    Entry entry = Entry.newInstance(msg, size, total(msg), promise);\n    if (tailEntry == null) {\n        flushedEntry = null;\n        tailEntry = entry;\n    } else {\n        Entry tail = tailEntry;\n        tail.next = entry;\n        tailEntry = entry;\n    }\n    if (unflushedEntry == null) {\n        unflushedEntry = entry;\n    }\n\n    // increment pending bytes after adding message to the unflushed arrays.\n    // See https://github.com/netty/netty/issues/1619\n    incrementPendingOutboundBytes(size, false);\n}\n\nprivate void incrementPendingOutboundBytes(long size, boolean invokeLater) {\n    if (size == 0) {\n        return;\n    }\n\n    long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size);\n    // int writeBufferHighWaterMark = 64 * 1024;\n    if (newWriteBufferSize > channel.config().getWriteBufferHighWaterMark()) {\n        setUnwritable(invokeLater);\n    }\n}\n\nprivate void setUnwritable(boolean invokeLater) {\n    for (;;) {\n        final int oldValue = unwritable;\n        final int newValue = oldValue | 1;\n        if (UNWRITABLE_UPDATER.compareAndSet(this, oldValue, newValue)) {\n            if (oldValue == 0 && newValue != 0) {\n                fireChannelWritabilityChanged(invokeLater);\n            }\n            break;\n        }\n    }\n}\n\nprivate void decrementPendingOutboundBytes(long size, boolean invokeLater, boolean notifyWritability) {\n    if (size == 0) {\n        return;\n    }\n\n    long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, -size);\n    // int writeBufferLowWaterMark = 32 * 1024;\n    if (notifyWritability && newWriteBufferSize < channel.config().getWriteBufferLowWaterMark()) {\n        setWritable(invokeLater);\n    }\n}\n\n```\n","source":"_posts/Netty-Watermark.md","raw":"---\ntitle: Netty-Watermark\ndate: 2019-01-05 19:15:15\ntags:\n---\n\n\nChannelOutboundBuffer\n\n```\n@Override\npublic final void write(Object msg, ChannelPromise promise) {\n    assertEventLoop();\n\n    ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;\n    if (outboundBuffer == null) {\n        // If the outboundBuffer is null we know the channel was closed and so\n        // need to fail the future right away. If it is not null the handling of the rest\n        // will be done in flush0()\n        // See https://github.com/netty/netty/issues/2362\n        safeSetFailure(promise, WRITE_CLOSED_CHANNEL_EXCEPTION);\n        // release message now to prevent resource-leak\n        ReferenceCountUtil.release(msg);\n        return;\n    }\n\n    int size;\n    try {\n        msg = filterOutboundMessage(msg);\n        size = pipeline.estimatorHandle().size(msg);\n        if (size < 0) {\n            size = 0;\n        }\n    } catch (Throwable t) {\n        safeSetFailure(promise, t);\n        ReferenceCountUtil.release(msg);\n        return;\n    }\n\n    outboundBuffer.addMessage(msg, size, promise);\n}\n\n\n/**\n * Add given message to this {@link ChannelOutboundBuffer}. The given {@link ChannelPromise} will be notified once\n * the message was written.\n */\npublic void addMessage(Object msg, int size, ChannelPromise promise) {\n    Entry entry = Entry.newInstance(msg, size, total(msg), promise);\n    if (tailEntry == null) {\n        flushedEntry = null;\n        tailEntry = entry;\n    } else {\n        Entry tail = tailEntry;\n        tail.next = entry;\n        tailEntry = entry;\n    }\n    if (unflushedEntry == null) {\n        unflushedEntry = entry;\n    }\n\n    // increment pending bytes after adding message to the unflushed arrays.\n    // See https://github.com/netty/netty/issues/1619\n    incrementPendingOutboundBytes(size, false);\n}\n\nprivate void incrementPendingOutboundBytes(long size, boolean invokeLater) {\n    if (size == 0) {\n        return;\n    }\n\n    long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size);\n    // int writeBufferHighWaterMark = 64 * 1024;\n    if (newWriteBufferSize > channel.config().getWriteBufferHighWaterMark()) {\n        setUnwritable(invokeLater);\n    }\n}\n\nprivate void setUnwritable(boolean invokeLater) {\n    for (;;) {\n        final int oldValue = unwritable;\n        final int newValue = oldValue | 1;\n        if (UNWRITABLE_UPDATER.compareAndSet(this, oldValue, newValue)) {\n            if (oldValue == 0 && newValue != 0) {\n                fireChannelWritabilityChanged(invokeLater);\n            }\n            break;\n        }\n    }\n}\n\nprivate void decrementPendingOutboundBytes(long size, boolean invokeLater, boolean notifyWritability) {\n    if (size == 0) {\n        return;\n    }\n\n    long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, -size);\n    // int writeBufferLowWaterMark = 32 * 1024;\n    if (notifyWritability && newWriteBufferSize < channel.config().getWriteBufferLowWaterMark()) {\n        setWritable(invokeLater);\n    }\n}\n\n```\n","slug":"Netty-Watermark","published":1,"updated":"2019-09-28T08:51:00.913Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84e004gv1np72kcbkxc","content":"<p>ChannelOutboundBuffer</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">public final void write(Object msg, ChannelPromise promise) &#123;</span><br><span class=\"line\">    assertEventLoop();</span><br><span class=\"line\"></span><br><span class=\"line\">    ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;</span><br><span class=\"line\">    if (outboundBuffer == null) &#123;</span><br><span class=\"line\">        // If the outboundBuffer is null we know the channel was closed and so</span><br><span class=\"line\">        // need to fail the future right away. If it is not null the handling of the rest</span><br><span class=\"line\">        // will be done in flush0()</span><br><span class=\"line\">        // See https://github.com/netty/netty/issues/2362</span><br><span class=\"line\">        safeSetFailure(promise, WRITE_CLOSED_CHANNEL_EXCEPTION);</span><br><span class=\"line\">        // release message now to prevent resource-leak</span><br><span class=\"line\">        ReferenceCountUtil.release(msg);</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    int size;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        msg = filterOutboundMessage(msg);</span><br><span class=\"line\">        size = pipeline.estimatorHandle().size(msg);</span><br><span class=\"line\">        if (size &lt; 0) &#123;</span><br><span class=\"line\">            size = 0;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">        safeSetFailure(promise, t);</span><br><span class=\"line\">        ReferenceCountUtil.release(msg);</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    outboundBuffer.addMessage(msg, size, promise);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">/**</span><br><span class=\"line\"> * Add given message to this &#123;@link ChannelOutboundBuffer&#125;. The given &#123;@link ChannelPromise&#125; will be notified once</span><br><span class=\"line\"> * the message was written.</span><br><span class=\"line\"> */</span><br><span class=\"line\">public void addMessage(Object msg, int size, ChannelPromise promise) &#123;</span><br><span class=\"line\">    Entry entry = Entry.newInstance(msg, size, total(msg), promise);</span><br><span class=\"line\">    if (tailEntry == null) &#123;</span><br><span class=\"line\">        flushedEntry = null;</span><br><span class=\"line\">        tailEntry = entry;</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        Entry tail = tailEntry;</span><br><span class=\"line\">        tail.next = entry;</span><br><span class=\"line\">        tailEntry = entry;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if (unflushedEntry == null) &#123;</span><br><span class=\"line\">        unflushedEntry = entry;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // increment pending bytes after adding message to the unflushed arrays.</span><br><span class=\"line\">    // See https://github.com/netty/netty/issues/1619</span><br><span class=\"line\">    incrementPendingOutboundBytes(size, false);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private void incrementPendingOutboundBytes(long size, boolean invokeLater) &#123;</span><br><span class=\"line\">    if (size == 0) &#123;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size);</span><br><span class=\"line\">    // int writeBufferHighWaterMark = 64 * 1024;</span><br><span class=\"line\">    if (newWriteBufferSize &gt; channel.config().getWriteBufferHighWaterMark()) &#123;</span><br><span class=\"line\">        setUnwritable(invokeLater);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private void setUnwritable(boolean invokeLater) &#123;</span><br><span class=\"line\">    for (;;) &#123;</span><br><span class=\"line\">        final int oldValue = unwritable;</span><br><span class=\"line\">        final int newValue = oldValue | 1;</span><br><span class=\"line\">        if (UNWRITABLE_UPDATER.compareAndSet(this, oldValue, newValue)) &#123;</span><br><span class=\"line\">            if (oldValue == 0 &amp;&amp; newValue != 0) &#123;</span><br><span class=\"line\">                fireChannelWritabilityChanged(invokeLater);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private void decrementPendingOutboundBytes(long size, boolean invokeLater, boolean notifyWritability) &#123;</span><br><span class=\"line\">    if (size == 0) &#123;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, -size);</span><br><span class=\"line\">    // int writeBufferLowWaterMark = 32 * 1024;</span><br><span class=\"line\">    if (notifyWritability &amp;&amp; newWriteBufferSize &lt; channel.config().getWriteBufferLowWaterMark()) &#123;</span><br><span class=\"line\">        setWritable(invokeLater);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<p>ChannelOutboundBuffer</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">public final void write(Object msg, ChannelPromise promise) &#123;</span><br><span class=\"line\">    assertEventLoop();</span><br><span class=\"line\"></span><br><span class=\"line\">    ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;</span><br><span class=\"line\">    if (outboundBuffer == null) &#123;</span><br><span class=\"line\">        // If the outboundBuffer is null we know the channel was closed and so</span><br><span class=\"line\">        // need to fail the future right away. If it is not null the handling of the rest</span><br><span class=\"line\">        // will be done in flush0()</span><br><span class=\"line\">        // See https://github.com/netty/netty/issues/2362</span><br><span class=\"line\">        safeSetFailure(promise, WRITE_CLOSED_CHANNEL_EXCEPTION);</span><br><span class=\"line\">        // release message now to prevent resource-leak</span><br><span class=\"line\">        ReferenceCountUtil.release(msg);</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    int size;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        msg = filterOutboundMessage(msg);</span><br><span class=\"line\">        size = pipeline.estimatorHandle().size(msg);</span><br><span class=\"line\">        if (size &lt; 0) &#123;</span><br><span class=\"line\">            size = 0;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">        safeSetFailure(promise, t);</span><br><span class=\"line\">        ReferenceCountUtil.release(msg);</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    outboundBuffer.addMessage(msg, size, promise);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">/**</span><br><span class=\"line\"> * Add given message to this &#123;@link ChannelOutboundBuffer&#125;. The given &#123;@link ChannelPromise&#125; will be notified once</span><br><span class=\"line\"> * the message was written.</span><br><span class=\"line\"> */</span><br><span class=\"line\">public void addMessage(Object msg, int size, ChannelPromise promise) &#123;</span><br><span class=\"line\">    Entry entry = Entry.newInstance(msg, size, total(msg), promise);</span><br><span class=\"line\">    if (tailEntry == null) &#123;</span><br><span class=\"line\">        flushedEntry = null;</span><br><span class=\"line\">        tailEntry = entry;</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        Entry tail = tailEntry;</span><br><span class=\"line\">        tail.next = entry;</span><br><span class=\"line\">        tailEntry = entry;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if (unflushedEntry == null) &#123;</span><br><span class=\"line\">        unflushedEntry = entry;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // increment pending bytes after adding message to the unflushed arrays.</span><br><span class=\"line\">    // See https://github.com/netty/netty/issues/1619</span><br><span class=\"line\">    incrementPendingOutboundBytes(size, false);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private void incrementPendingOutboundBytes(long size, boolean invokeLater) &#123;</span><br><span class=\"line\">    if (size == 0) &#123;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size);</span><br><span class=\"line\">    // int writeBufferHighWaterMark = 64 * 1024;</span><br><span class=\"line\">    if (newWriteBufferSize &gt; channel.config().getWriteBufferHighWaterMark()) &#123;</span><br><span class=\"line\">        setUnwritable(invokeLater);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private void setUnwritable(boolean invokeLater) &#123;</span><br><span class=\"line\">    for (;;) &#123;</span><br><span class=\"line\">        final int oldValue = unwritable;</span><br><span class=\"line\">        final int newValue = oldValue | 1;</span><br><span class=\"line\">        if (UNWRITABLE_UPDATER.compareAndSet(this, oldValue, newValue)) &#123;</span><br><span class=\"line\">            if (oldValue == 0 &amp;&amp; newValue != 0) &#123;</span><br><span class=\"line\">                fireChannelWritabilityChanged(invokeLater);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">private void decrementPendingOutboundBytes(long size, boolean invokeLater, boolean notifyWritability) &#123;</span><br><span class=\"line\">    if (size == 0) &#123;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, -size);</span><br><span class=\"line\">    // int writeBufferLowWaterMark = 32 * 1024;</span><br><span class=\"line\">    if (notifyWritability &amp;&amp; newWriteBufferSize &lt; channel.config().getWriteBufferLowWaterMark()) &#123;</span><br><span class=\"line\">        setWritable(invokeLater);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"Netty-Pipeline","date":"2019-02-19T06:32:27.000Z","_content":"\n\nhttps://segmentfault.com/a/1190000007308934","source":"_posts/Netty-Pipeline.md","raw":"---\ntitle: Netty-Pipeline\ndate: 2019-02-19 14:32:27\ntags:\n---\n\n\nhttps://segmentfault.com/a/1190000007308934","slug":"Netty-Pipeline","published":1,"updated":"2019-09-28T08:51:00.912Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84g004hv1npq29m3ivj","content":"<p><a href=\"https://segmentfault.com/a/1190000007308934\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000007308934</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://segmentfault.com/a/1190000007308934\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000007308934</a></p>\n"},{"title":"OSAHS手术回忆","date":"2018-07-02T02:32:32.000Z","_content":"\n### OSAHS——「阻塞性睡眠呼吸暂停综合征」手术回忆\nOSAHS，最大的风险就是睡眠时上气道塌陷阻塞引起的呼吸暂停和低通气，导致血氧饱和度非常低，引起白天嗜睡，注意力不集中，记忆力下降等病症，更严重的可能导致窒息。我其实从高中开始就每天睡不好，白天没有精神，可能跟那个时候吃胖得有关。\n\n## 2018-06-25，周一\n请假来到「浙江大学医学院附属邵逸夫医院」办理住院手续，心情愉悦，一脸微笑，病床靠窗，窗外是钱江新城的高楼，着实有种度假的感觉，同病房的两位老爷爷还在奇怪我好像没有病啊。由于没有去查阅过任何治疗经历，所以也其实自己也不知道是怎么回事，只知道可能要切除下扁桃体。术前手续其实不多，作为医生的女朋友给我安排得妥妥当当的。\n\n下午被手术助手之一的金医生叫到办公室，简单得描述了下手术的原理还有流程，我只注意到，这哥们说，手术做完后，会很痛苦，我呢是被安排在周二早上第2台手术，10点左右开始，大概会持续一个小时，全程麻醉，由于要动刀，所以也有可能会痛，要忍，由于手术有窒息风险，插在呼吸道的管子必须到我意识恢复后才能拔出来，那时会非常不舒服，术后要大量饮水，把血冲到肚子里面，保证喉咙湿润。这时我算对这个手术有了一定的认识，还是有点紧张的，毕竟从小到大没有做过手术，还全麻，以上就是我在手术前所需要知道的所有东西。晚上在病床休息，临时被通知被换到明早第一台手术，心里有点慌。\n\n## 2018-06-26，周二\n早上6点左右就被工作人员拖出了病房，带到了一个「护士流动站」的地方，不知道有没有记错名字，我是最初几个被拉进来的，然后看着房间里面越来越多的病人被工作人员推进来。做肝肾，胆手术的都有，心情确实不好受，感觉是待宰的羔羊。最最难受的是，在这个房间里面，意识非常清醒的状态下，等了近两个小时，非常煎药，还不如直接来个痛快的。还好女朋友是本院医生，走关系进来陪我说说话，不然是心慌慌。大概8点半，我被推进了看上去挺豪华的手术室，主刀医生和各位助理医生早已在那里等我，随后就是在我身上贴了各种不知道干嘛的小片，还给我开了个玩笑，具体内容真忘记了，然后护士小姐给我带了个氧气罩，让我深呼吸，同时我知道输液的液体已经被换成了麻醉药，一小会儿，我就失去了意识，慢慢睡着了。。。\n\n当我醒来的时候，还好不是在动刀子的时候，不然想想挺奔溃的。只记得那时我口中插了管子，靠着呼吸机在呼吸，口中感觉不时冒出一点血，量不大，吸一吸就行，身边是女朋友和一个带着口罩面向着显示器的医院，不停得和我说话。我虽然有点头痛，但好像也不是特别难受，不时还能用动作回他们的话，我知道最危险的时候度过了。医生觉得我状态还行，就说可以把管子了，期间要忍一忍，可能有点恶心，其实我觉得也就这样。随后就被拉回了病房，我爸也在病房等我。\n\n接下去噩梦开始到来，由于从深度麻醉中醒来，头痛得不行，喉咙也非常痛，连舌头也不敢乱动，讲话几乎是不可能的，只能像小孩子一样发出点声音，右边的鼻子中被严严实实得塞了棉条，防止鼻子出血。交流只能是靠着半醒的状态在手机上打字，还时不时打错字。按照医嘱，我一天要喝2000ml的水和牛奶，米汤等东西，哪有那么容易啊，喝水变得非常非常苦难，主要是太痛了，还不能前仰得喝，会从鼻子里面出来，出来的还不是水，主要是血。每次吐口水，反正是各种黑色的淤血，一开始觉得好恶心，后面也就习惯了。呼吸只能靠嘴巴，病床上有氧气，我就只能洗着氧气，挂着点滴，处于半昏迷状态。由于有喝水的任务，我无数次被叫起来喝水，每次喝一口就吐一口，就是痛得喝不下，米粥也就是喝了一小口，基本也不喝了。还好每天挂着少量葡萄糖，不然我几乎就没有吃过东西。到了晚上睡觉，反正就是睡不着，不舒服，麻药的效果我觉得和醉酒是类似的，\n\n## 2018-06-27，周三\n医生把我鼻子里面的棉条用镊子夹了出来，非常痛，这时我才感受到这东西放得有多深，大概有10cm，拉出来的面条被黑色的淤血包裹着，不过没有新鲜的血流出来，说明鼻子没有出血，也算是一个好消息，毕竟当时鼻子里面也是切除了一点东西的。在漱口时，用镜子照了下嘴巴里面，舌苔上有很厚一层白色物质，咽腔两侧有一些手术缝的线，里面有黄黄的物质，感觉非常恶心。\n\n## 2018-06-28，周四\n麻药的效果基本上是过了，脖子也有力气了，头也没有那么痛，但是晚上睡觉嘴巴和喉咙真的太干了，这样醒了后又要喝水，但是喝水会很痛，我基本也是喝不了几口。鸡蛋羹吃得非常恶心，导致我现在都排斥吃东西。\n\n## 2018-06-29，周五\n每一天都比上一天好了点，但还是非常难熬，主要是不能吃喜欢吃的东西，精神和肉体上开始双重折磨。助理医生拿吸管从鼻子里面吸出了好多血，但鼻子还是不通。找到了和我做同一种手术的一个哥们，当时他的状态比我差很多，和他交流了下，基本也是非常痛苦。了解到，他是一名在四季青卖衣服的小老板，常年喝酒应酬，家人反应后他做了检测，也是OSAHS，但他现在已经40+岁了，肯定恢复得没有我快。\n\n## 2018-06-30，周六\n大概6点不到就抽了次血。上午主刀医生查房时，看到我在用嘴巴呼吸，把我叫到换药室，将涂了药水的棉花再一次赛到我的鼻子里，这次赛进去就比较痛，过了几秒再拔出来，又是全部都是黑色的淤血，但感觉鼻子有一点点通了，于是回病床上，叫老爸不停往我鼻子喷清洗剂，我用力把多余的脏东西都排了出来。这时，在站立状态下，我终于可以用鼻子呼吸了。但在躺下的状态下，我还是不能用鼻子呼吸，嘴巴还是很干，晚上根本不能睡好。但是，由于各种用药和点滴，我必须一直在病床上，很容易就睡着了，又开始用嘴巴呼吸，这时鼻子里面又会开始分泌各种物质，醒来时鼻子又会塞住，反反复复。\n\n## 2018-07-01，周日\n由于在医院睡不好，精神状态很差，发了一次脾气，非常后悔。但相对而言，我身体恢复得还行，我就打算提前一天出院，想想在家里睡得比在医院好些。周六的血液报告虽然有几项有问题，但不影响我出院，我就顺利在周日中午出院，我的那位病友当时血液检测都没有通过，他至少还要在医院多待3天。回到家整理了下东西，洗了个澡，伴随着开着中档的加湿器，就睡觉了。期间就醒了两三次，嘴巴还是很干，感觉比医院睡得好些。\n\n## 2018-07-02，周一\n现在是手术后的第7天，已经出院，选择来上班试试，意识还行，身体很疲惫，很饿，晚上睡觉呼吸只能靠嘴巴，会非常干，很容易干醒，讲话可以讲一点，但舌头太干，讲不清楚。早餐照例是流质食品——豆腐脑，咽下去时，喉咙有点痛，非常容易吃到鼻子里去，吃了几小口就吃不下了，如果按照这个速度继续吃，估计1个多小时才能把一碗2块钱的豆腐脑吃完。肚子里面一直是空的，也一直是饥饿的状态，接下去每一天估计只会吃牛奶和一点点糖水/汤水补充能量，加上一些纯净水平衡体内水盐，这样的情况要持续到2018-07-09拆线前。每天都挺漫长。。。\n\n## 2018-07-20，周五\n现在是手术后的第25天，已经可以用鼻子平躺着呼吸，吃东西稍有不适，角度不对会吃进鼻子。恢复很快。","source":"_posts/OSAHS.md","raw":"---\ntitle: OSAHS手术回忆\ndate: 2018-07-02 10:32:32\ntags:\n---\n\n### OSAHS——「阻塞性睡眠呼吸暂停综合征」手术回忆\nOSAHS，最大的风险就是睡眠时上气道塌陷阻塞引起的呼吸暂停和低通气，导致血氧饱和度非常低，引起白天嗜睡，注意力不集中，记忆力下降等病症，更严重的可能导致窒息。我其实从高中开始就每天睡不好，白天没有精神，可能跟那个时候吃胖得有关。\n\n## 2018-06-25，周一\n请假来到「浙江大学医学院附属邵逸夫医院」办理住院手续，心情愉悦，一脸微笑，病床靠窗，窗外是钱江新城的高楼，着实有种度假的感觉，同病房的两位老爷爷还在奇怪我好像没有病啊。由于没有去查阅过任何治疗经历，所以也其实自己也不知道是怎么回事，只知道可能要切除下扁桃体。术前手续其实不多，作为医生的女朋友给我安排得妥妥当当的。\n\n下午被手术助手之一的金医生叫到办公室，简单得描述了下手术的原理还有流程，我只注意到，这哥们说，手术做完后，会很痛苦，我呢是被安排在周二早上第2台手术，10点左右开始，大概会持续一个小时，全程麻醉，由于要动刀，所以也有可能会痛，要忍，由于手术有窒息风险，插在呼吸道的管子必须到我意识恢复后才能拔出来，那时会非常不舒服，术后要大量饮水，把血冲到肚子里面，保证喉咙湿润。这时我算对这个手术有了一定的认识，还是有点紧张的，毕竟从小到大没有做过手术，还全麻，以上就是我在手术前所需要知道的所有东西。晚上在病床休息，临时被通知被换到明早第一台手术，心里有点慌。\n\n## 2018-06-26，周二\n早上6点左右就被工作人员拖出了病房，带到了一个「护士流动站」的地方，不知道有没有记错名字，我是最初几个被拉进来的，然后看着房间里面越来越多的病人被工作人员推进来。做肝肾，胆手术的都有，心情确实不好受，感觉是待宰的羔羊。最最难受的是，在这个房间里面，意识非常清醒的状态下，等了近两个小时，非常煎药，还不如直接来个痛快的。还好女朋友是本院医生，走关系进来陪我说说话，不然是心慌慌。大概8点半，我被推进了看上去挺豪华的手术室，主刀医生和各位助理医生早已在那里等我，随后就是在我身上贴了各种不知道干嘛的小片，还给我开了个玩笑，具体内容真忘记了，然后护士小姐给我带了个氧气罩，让我深呼吸，同时我知道输液的液体已经被换成了麻醉药，一小会儿，我就失去了意识，慢慢睡着了。。。\n\n当我醒来的时候，还好不是在动刀子的时候，不然想想挺奔溃的。只记得那时我口中插了管子，靠着呼吸机在呼吸，口中感觉不时冒出一点血，量不大，吸一吸就行，身边是女朋友和一个带着口罩面向着显示器的医院，不停得和我说话。我虽然有点头痛，但好像也不是特别难受，不时还能用动作回他们的话，我知道最危险的时候度过了。医生觉得我状态还行，就说可以把管子了，期间要忍一忍，可能有点恶心，其实我觉得也就这样。随后就被拉回了病房，我爸也在病房等我。\n\n接下去噩梦开始到来，由于从深度麻醉中醒来，头痛得不行，喉咙也非常痛，连舌头也不敢乱动，讲话几乎是不可能的，只能像小孩子一样发出点声音，右边的鼻子中被严严实实得塞了棉条，防止鼻子出血。交流只能是靠着半醒的状态在手机上打字，还时不时打错字。按照医嘱，我一天要喝2000ml的水和牛奶，米汤等东西，哪有那么容易啊，喝水变得非常非常苦难，主要是太痛了，还不能前仰得喝，会从鼻子里面出来，出来的还不是水，主要是血。每次吐口水，反正是各种黑色的淤血，一开始觉得好恶心，后面也就习惯了。呼吸只能靠嘴巴，病床上有氧气，我就只能洗着氧气，挂着点滴，处于半昏迷状态。由于有喝水的任务，我无数次被叫起来喝水，每次喝一口就吐一口，就是痛得喝不下，米粥也就是喝了一小口，基本也不喝了。还好每天挂着少量葡萄糖，不然我几乎就没有吃过东西。到了晚上睡觉，反正就是睡不着，不舒服，麻药的效果我觉得和醉酒是类似的，\n\n## 2018-06-27，周三\n医生把我鼻子里面的棉条用镊子夹了出来，非常痛，这时我才感受到这东西放得有多深，大概有10cm，拉出来的面条被黑色的淤血包裹着，不过没有新鲜的血流出来，说明鼻子没有出血，也算是一个好消息，毕竟当时鼻子里面也是切除了一点东西的。在漱口时，用镜子照了下嘴巴里面，舌苔上有很厚一层白色物质，咽腔两侧有一些手术缝的线，里面有黄黄的物质，感觉非常恶心。\n\n## 2018-06-28，周四\n麻药的效果基本上是过了，脖子也有力气了，头也没有那么痛，但是晚上睡觉嘴巴和喉咙真的太干了，这样醒了后又要喝水，但是喝水会很痛，我基本也是喝不了几口。鸡蛋羹吃得非常恶心，导致我现在都排斥吃东西。\n\n## 2018-06-29，周五\n每一天都比上一天好了点，但还是非常难熬，主要是不能吃喜欢吃的东西，精神和肉体上开始双重折磨。助理医生拿吸管从鼻子里面吸出了好多血，但鼻子还是不通。找到了和我做同一种手术的一个哥们，当时他的状态比我差很多，和他交流了下，基本也是非常痛苦。了解到，他是一名在四季青卖衣服的小老板，常年喝酒应酬，家人反应后他做了检测，也是OSAHS，但他现在已经40+岁了，肯定恢复得没有我快。\n\n## 2018-06-30，周六\n大概6点不到就抽了次血。上午主刀医生查房时，看到我在用嘴巴呼吸，把我叫到换药室，将涂了药水的棉花再一次赛到我的鼻子里，这次赛进去就比较痛，过了几秒再拔出来，又是全部都是黑色的淤血，但感觉鼻子有一点点通了，于是回病床上，叫老爸不停往我鼻子喷清洗剂，我用力把多余的脏东西都排了出来。这时，在站立状态下，我终于可以用鼻子呼吸了。但在躺下的状态下，我还是不能用鼻子呼吸，嘴巴还是很干，晚上根本不能睡好。但是，由于各种用药和点滴，我必须一直在病床上，很容易就睡着了，又开始用嘴巴呼吸，这时鼻子里面又会开始分泌各种物质，醒来时鼻子又会塞住，反反复复。\n\n## 2018-07-01，周日\n由于在医院睡不好，精神状态很差，发了一次脾气，非常后悔。但相对而言，我身体恢复得还行，我就打算提前一天出院，想想在家里睡得比在医院好些。周六的血液报告虽然有几项有问题，但不影响我出院，我就顺利在周日中午出院，我的那位病友当时血液检测都没有通过，他至少还要在医院多待3天。回到家整理了下东西，洗了个澡，伴随着开着中档的加湿器，就睡觉了。期间就醒了两三次，嘴巴还是很干，感觉比医院睡得好些。\n\n## 2018-07-02，周一\n现在是手术后的第7天，已经出院，选择来上班试试，意识还行，身体很疲惫，很饿，晚上睡觉呼吸只能靠嘴巴，会非常干，很容易干醒，讲话可以讲一点，但舌头太干，讲不清楚。早餐照例是流质食品——豆腐脑，咽下去时，喉咙有点痛，非常容易吃到鼻子里去，吃了几小口就吃不下了，如果按照这个速度继续吃，估计1个多小时才能把一碗2块钱的豆腐脑吃完。肚子里面一直是空的，也一直是饥饿的状态，接下去每一天估计只会吃牛奶和一点点糖水/汤水补充能量，加上一些纯净水平衡体内水盐，这样的情况要持续到2018-07-09拆线前。每天都挺漫长。。。\n\n## 2018-07-20，周五\n现在是手术后的第25天，已经可以用鼻子平躺着呼吸，吃东西稍有不适，角度不对会吃进鼻子。恢复很快。","slug":"OSAHS","published":1,"updated":"2019-09-28T08:51:00.913Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84g004iv1npjygfdcnt","content":"<h3 id=\"OSAHS——「阻塞性睡眠呼吸暂停综合征」手术回忆\"><a href=\"#OSAHS——「阻塞性睡眠呼吸暂停综合征」手术回忆\" class=\"headerlink\" title=\"OSAHS——「阻塞性睡眠呼吸暂停综合征」手术回忆\"></a>OSAHS——「阻塞性睡眠呼吸暂停综合征」手术回忆</h3><p>OSAHS，最大的风险就是睡眠时上气道塌陷阻塞引起的呼吸暂停和低通气，导致血氧饱和度非常低，引起白天嗜睡，注意力不集中，记忆力下降等病症，更严重的可能导致窒息。我其实从高中开始就每天睡不好，白天没有精神，可能跟那个时候吃胖得有关。</p>\n<h2 id=\"2018-06-25，周一\"><a href=\"#2018-06-25，周一\" class=\"headerlink\" title=\"2018-06-25，周一\"></a>2018-06-25，周一</h2><p>请假来到「浙江大学医学院附属邵逸夫医院」办理住院手续，心情愉悦，一脸微笑，病床靠窗，窗外是钱江新城的高楼，着实有种度假的感觉，同病房的两位老爷爷还在奇怪我好像没有病啊。由于没有去查阅过任何治疗经历，所以也其实自己也不知道是怎么回事，只知道可能要切除下扁桃体。术前手续其实不多，作为医生的女朋友给我安排得妥妥当当的。</p>\n<p>下午被手术助手之一的金医生叫到办公室，简单得描述了下手术的原理还有流程，我只注意到，这哥们说，手术做完后，会很痛苦，我呢是被安排在周二早上第2台手术，10点左右开始，大概会持续一个小时，全程麻醉，由于要动刀，所以也有可能会痛，要忍，由于手术有窒息风险，插在呼吸道的管子必须到我意识恢复后才能拔出来，那时会非常不舒服，术后要大量饮水，把血冲到肚子里面，保证喉咙湿润。这时我算对这个手术有了一定的认识，还是有点紧张的，毕竟从小到大没有做过手术，还全麻，以上就是我在手术前所需要知道的所有东西。晚上在病床休息，临时被通知被换到明早第一台手术，心里有点慌。</p>\n<h2 id=\"2018-06-26，周二\"><a href=\"#2018-06-26，周二\" class=\"headerlink\" title=\"2018-06-26，周二\"></a>2018-06-26，周二</h2><p>早上6点左右就被工作人员拖出了病房，带到了一个「护士流动站」的地方，不知道有没有记错名字，我是最初几个被拉进来的，然后看着房间里面越来越多的病人被工作人员推进来。做肝肾，胆手术的都有，心情确实不好受，感觉是待宰的羔羊。最最难受的是，在这个房间里面，意识非常清醒的状态下，等了近两个小时，非常煎药，还不如直接来个痛快的。还好女朋友是本院医生，走关系进来陪我说说话，不然是心慌慌。大概8点半，我被推进了看上去挺豪华的手术室，主刀医生和各位助理医生早已在那里等我，随后就是在我身上贴了各种不知道干嘛的小片，还给我开了个玩笑，具体内容真忘记了，然后护士小姐给我带了个氧气罩，让我深呼吸，同时我知道输液的液体已经被换成了麻醉药，一小会儿，我就失去了意识，慢慢睡着了。。。</p>\n<p>当我醒来的时候，还好不是在动刀子的时候，不然想想挺奔溃的。只记得那时我口中插了管子，靠着呼吸机在呼吸，口中感觉不时冒出一点血，量不大，吸一吸就行，身边是女朋友和一个带着口罩面向着显示器的医院，不停得和我说话。我虽然有点头痛，但好像也不是特别难受，不时还能用动作回他们的话，我知道最危险的时候度过了。医生觉得我状态还行，就说可以把管子了，期间要忍一忍，可能有点恶心，其实我觉得也就这样。随后就被拉回了病房，我爸也在病房等我。</p>\n<p>接下去噩梦开始到来，由于从深度麻醉中醒来，头痛得不行，喉咙也非常痛，连舌头也不敢乱动，讲话几乎是不可能的，只能像小孩子一样发出点声音，右边的鼻子中被严严实实得塞了棉条，防止鼻子出血。交流只能是靠着半醒的状态在手机上打字，还时不时打错字。按照医嘱，我一天要喝2000ml的水和牛奶，米汤等东西，哪有那么容易啊，喝水变得非常非常苦难，主要是太痛了，还不能前仰得喝，会从鼻子里面出来，出来的还不是水，主要是血。每次吐口水，反正是各种黑色的淤血，一开始觉得好恶心，后面也就习惯了。呼吸只能靠嘴巴，病床上有氧气，我就只能洗着氧气，挂着点滴，处于半昏迷状态。由于有喝水的任务，我无数次被叫起来喝水，每次喝一口就吐一口，就是痛得喝不下，米粥也就是喝了一小口，基本也不喝了。还好每天挂着少量葡萄糖，不然我几乎就没有吃过东西。到了晚上睡觉，反正就是睡不着，不舒服，麻药的效果我觉得和醉酒是类似的，</p>\n<h2 id=\"2018-06-27，周三\"><a href=\"#2018-06-27，周三\" class=\"headerlink\" title=\"2018-06-27，周三\"></a>2018-06-27，周三</h2><p>医生把我鼻子里面的棉条用镊子夹了出来，非常痛，这时我才感受到这东西放得有多深，大概有10cm，拉出来的面条被黑色的淤血包裹着，不过没有新鲜的血流出来，说明鼻子没有出血，也算是一个好消息，毕竟当时鼻子里面也是切除了一点东西的。在漱口时，用镜子照了下嘴巴里面，舌苔上有很厚一层白色物质，咽腔两侧有一些手术缝的线，里面有黄黄的物质，感觉非常恶心。</p>\n<h2 id=\"2018-06-28，周四\"><a href=\"#2018-06-28，周四\" class=\"headerlink\" title=\"2018-06-28，周四\"></a>2018-06-28，周四</h2><p>麻药的效果基本上是过了，脖子也有力气了，头也没有那么痛，但是晚上睡觉嘴巴和喉咙真的太干了，这样醒了后又要喝水，但是喝水会很痛，我基本也是喝不了几口。鸡蛋羹吃得非常恶心，导致我现在都排斥吃东西。</p>\n<h2 id=\"2018-06-29，周五\"><a href=\"#2018-06-29，周五\" class=\"headerlink\" title=\"2018-06-29，周五\"></a>2018-06-29，周五</h2><p>每一天都比上一天好了点，但还是非常难熬，主要是不能吃喜欢吃的东西，精神和肉体上开始双重折磨。助理医生拿吸管从鼻子里面吸出了好多血，但鼻子还是不通。找到了和我做同一种手术的一个哥们，当时他的状态比我差很多，和他交流了下，基本也是非常痛苦。了解到，他是一名在四季青卖衣服的小老板，常年喝酒应酬，家人反应后他做了检测，也是OSAHS，但他现在已经40+岁了，肯定恢复得没有我快。</p>\n<h2 id=\"2018-06-30，周六\"><a href=\"#2018-06-30，周六\" class=\"headerlink\" title=\"2018-06-30，周六\"></a>2018-06-30，周六</h2><p>大概6点不到就抽了次血。上午主刀医生查房时，看到我在用嘴巴呼吸，把我叫到换药室，将涂了药水的棉花再一次赛到我的鼻子里，这次赛进去就比较痛，过了几秒再拔出来，又是全部都是黑色的淤血，但感觉鼻子有一点点通了，于是回病床上，叫老爸不停往我鼻子喷清洗剂，我用力把多余的脏东西都排了出来。这时，在站立状态下，我终于可以用鼻子呼吸了。但在躺下的状态下，我还是不能用鼻子呼吸，嘴巴还是很干，晚上根本不能睡好。但是，由于各种用药和点滴，我必须一直在病床上，很容易就睡着了，又开始用嘴巴呼吸，这时鼻子里面又会开始分泌各种物质，醒来时鼻子又会塞住，反反复复。</p>\n<h2 id=\"2018-07-01，周日\"><a href=\"#2018-07-01，周日\" class=\"headerlink\" title=\"2018-07-01，周日\"></a>2018-07-01，周日</h2><p>由于在医院睡不好，精神状态很差，发了一次脾气，非常后悔。但相对而言，我身体恢复得还行，我就打算提前一天出院，想想在家里睡得比在医院好些。周六的血液报告虽然有几项有问题，但不影响我出院，我就顺利在周日中午出院，我的那位病友当时血液检测都没有通过，他至少还要在医院多待3天。回到家整理了下东西，洗了个澡，伴随着开着中档的加湿器，就睡觉了。期间就醒了两三次，嘴巴还是很干，感觉比医院睡得好些。</p>\n<h2 id=\"2018-07-02，周一\"><a href=\"#2018-07-02，周一\" class=\"headerlink\" title=\"2018-07-02，周一\"></a>2018-07-02，周一</h2><p>现在是手术后的第7天，已经出院，选择来上班试试，意识还行，身体很疲惫，很饿，晚上睡觉呼吸只能靠嘴巴，会非常干，很容易干醒，讲话可以讲一点，但舌头太干，讲不清楚。早餐照例是流质食品——豆腐脑，咽下去时，喉咙有点痛，非常容易吃到鼻子里去，吃了几小口就吃不下了，如果按照这个速度继续吃，估计1个多小时才能把一碗2块钱的豆腐脑吃完。肚子里面一直是空的，也一直是饥饿的状态，接下去每一天估计只会吃牛奶和一点点糖水/汤水补充能量，加上一些纯净水平衡体内水盐，这样的情况要持续到2018-07-09拆线前。每天都挺漫长。。。</p>\n<h2 id=\"2018-07-20，周五\"><a href=\"#2018-07-20，周五\" class=\"headerlink\" title=\"2018-07-20，周五\"></a>2018-07-20，周五</h2><p>现在是手术后的第25天，已经可以用鼻子平躺着呼吸，吃东西稍有不适，角度不对会吃进鼻子。恢复很快。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"OSAHS——「阻塞性睡眠呼吸暂停综合征」手术回忆\"><a href=\"#OSAHS——「阻塞性睡眠呼吸暂停综合征」手术回忆\" class=\"headerlink\" title=\"OSAHS——「阻塞性睡眠呼吸暂停综合征」手术回忆\"></a>OSAHS——「阻塞性睡眠呼吸暂停综合征」手术回忆</h3><p>OSAHS，最大的风险就是睡眠时上气道塌陷阻塞引起的呼吸暂停和低通气，导致血氧饱和度非常低，引起白天嗜睡，注意力不集中，记忆力下降等病症，更严重的可能导致窒息。我其实从高中开始就每天睡不好，白天没有精神，可能跟那个时候吃胖得有关。</p>\n<h2 id=\"2018-06-25，周一\"><a href=\"#2018-06-25，周一\" class=\"headerlink\" title=\"2018-06-25，周一\"></a>2018-06-25，周一</h2><p>请假来到「浙江大学医学院附属邵逸夫医院」办理住院手续，心情愉悦，一脸微笑，病床靠窗，窗外是钱江新城的高楼，着实有种度假的感觉，同病房的两位老爷爷还在奇怪我好像没有病啊。由于没有去查阅过任何治疗经历，所以也其实自己也不知道是怎么回事，只知道可能要切除下扁桃体。术前手续其实不多，作为医生的女朋友给我安排得妥妥当当的。</p>\n<p>下午被手术助手之一的金医生叫到办公室，简单得描述了下手术的原理还有流程，我只注意到，这哥们说，手术做完后，会很痛苦，我呢是被安排在周二早上第2台手术，10点左右开始，大概会持续一个小时，全程麻醉，由于要动刀，所以也有可能会痛，要忍，由于手术有窒息风险，插在呼吸道的管子必须到我意识恢复后才能拔出来，那时会非常不舒服，术后要大量饮水，把血冲到肚子里面，保证喉咙湿润。这时我算对这个手术有了一定的认识，还是有点紧张的，毕竟从小到大没有做过手术，还全麻，以上就是我在手术前所需要知道的所有东西。晚上在病床休息，临时被通知被换到明早第一台手术，心里有点慌。</p>\n<h2 id=\"2018-06-26，周二\"><a href=\"#2018-06-26，周二\" class=\"headerlink\" title=\"2018-06-26，周二\"></a>2018-06-26，周二</h2><p>早上6点左右就被工作人员拖出了病房，带到了一个「护士流动站」的地方，不知道有没有记错名字，我是最初几个被拉进来的，然后看着房间里面越来越多的病人被工作人员推进来。做肝肾，胆手术的都有，心情确实不好受，感觉是待宰的羔羊。最最难受的是，在这个房间里面，意识非常清醒的状态下，等了近两个小时，非常煎药，还不如直接来个痛快的。还好女朋友是本院医生，走关系进来陪我说说话，不然是心慌慌。大概8点半，我被推进了看上去挺豪华的手术室，主刀医生和各位助理医生早已在那里等我，随后就是在我身上贴了各种不知道干嘛的小片，还给我开了个玩笑，具体内容真忘记了，然后护士小姐给我带了个氧气罩，让我深呼吸，同时我知道输液的液体已经被换成了麻醉药，一小会儿，我就失去了意识，慢慢睡着了。。。</p>\n<p>当我醒来的时候，还好不是在动刀子的时候，不然想想挺奔溃的。只记得那时我口中插了管子，靠着呼吸机在呼吸，口中感觉不时冒出一点血，量不大，吸一吸就行，身边是女朋友和一个带着口罩面向着显示器的医院，不停得和我说话。我虽然有点头痛，但好像也不是特别难受，不时还能用动作回他们的话，我知道最危险的时候度过了。医生觉得我状态还行，就说可以把管子了，期间要忍一忍，可能有点恶心，其实我觉得也就这样。随后就被拉回了病房，我爸也在病房等我。</p>\n<p>接下去噩梦开始到来，由于从深度麻醉中醒来，头痛得不行，喉咙也非常痛，连舌头也不敢乱动，讲话几乎是不可能的，只能像小孩子一样发出点声音，右边的鼻子中被严严实实得塞了棉条，防止鼻子出血。交流只能是靠着半醒的状态在手机上打字，还时不时打错字。按照医嘱，我一天要喝2000ml的水和牛奶，米汤等东西，哪有那么容易啊，喝水变得非常非常苦难，主要是太痛了，还不能前仰得喝，会从鼻子里面出来，出来的还不是水，主要是血。每次吐口水，反正是各种黑色的淤血，一开始觉得好恶心，后面也就习惯了。呼吸只能靠嘴巴，病床上有氧气，我就只能洗着氧气，挂着点滴，处于半昏迷状态。由于有喝水的任务，我无数次被叫起来喝水，每次喝一口就吐一口，就是痛得喝不下，米粥也就是喝了一小口，基本也不喝了。还好每天挂着少量葡萄糖，不然我几乎就没有吃过东西。到了晚上睡觉，反正就是睡不着，不舒服，麻药的效果我觉得和醉酒是类似的，</p>\n<h2 id=\"2018-06-27，周三\"><a href=\"#2018-06-27，周三\" class=\"headerlink\" title=\"2018-06-27，周三\"></a>2018-06-27，周三</h2><p>医生把我鼻子里面的棉条用镊子夹了出来，非常痛，这时我才感受到这东西放得有多深，大概有10cm，拉出来的面条被黑色的淤血包裹着，不过没有新鲜的血流出来，说明鼻子没有出血，也算是一个好消息，毕竟当时鼻子里面也是切除了一点东西的。在漱口时，用镜子照了下嘴巴里面，舌苔上有很厚一层白色物质，咽腔两侧有一些手术缝的线，里面有黄黄的物质，感觉非常恶心。</p>\n<h2 id=\"2018-06-28，周四\"><a href=\"#2018-06-28，周四\" class=\"headerlink\" title=\"2018-06-28，周四\"></a>2018-06-28，周四</h2><p>麻药的效果基本上是过了，脖子也有力气了，头也没有那么痛，但是晚上睡觉嘴巴和喉咙真的太干了，这样醒了后又要喝水，但是喝水会很痛，我基本也是喝不了几口。鸡蛋羹吃得非常恶心，导致我现在都排斥吃东西。</p>\n<h2 id=\"2018-06-29，周五\"><a href=\"#2018-06-29，周五\" class=\"headerlink\" title=\"2018-06-29，周五\"></a>2018-06-29，周五</h2><p>每一天都比上一天好了点，但还是非常难熬，主要是不能吃喜欢吃的东西，精神和肉体上开始双重折磨。助理医生拿吸管从鼻子里面吸出了好多血，但鼻子还是不通。找到了和我做同一种手术的一个哥们，当时他的状态比我差很多，和他交流了下，基本也是非常痛苦。了解到，他是一名在四季青卖衣服的小老板，常年喝酒应酬，家人反应后他做了检测，也是OSAHS，但他现在已经40+岁了，肯定恢复得没有我快。</p>\n<h2 id=\"2018-06-30，周六\"><a href=\"#2018-06-30，周六\" class=\"headerlink\" title=\"2018-06-30，周六\"></a>2018-06-30，周六</h2><p>大概6点不到就抽了次血。上午主刀医生查房时，看到我在用嘴巴呼吸，把我叫到换药室，将涂了药水的棉花再一次赛到我的鼻子里，这次赛进去就比较痛，过了几秒再拔出来，又是全部都是黑色的淤血，但感觉鼻子有一点点通了，于是回病床上，叫老爸不停往我鼻子喷清洗剂，我用力把多余的脏东西都排了出来。这时，在站立状态下，我终于可以用鼻子呼吸了。但在躺下的状态下，我还是不能用鼻子呼吸，嘴巴还是很干，晚上根本不能睡好。但是，由于各种用药和点滴，我必须一直在病床上，很容易就睡着了，又开始用嘴巴呼吸，这时鼻子里面又会开始分泌各种物质，醒来时鼻子又会塞住，反反复复。</p>\n<h2 id=\"2018-07-01，周日\"><a href=\"#2018-07-01，周日\" class=\"headerlink\" title=\"2018-07-01，周日\"></a>2018-07-01，周日</h2><p>由于在医院睡不好，精神状态很差，发了一次脾气，非常后悔。但相对而言，我身体恢复得还行，我就打算提前一天出院，想想在家里睡得比在医院好些。周六的血液报告虽然有几项有问题，但不影响我出院，我就顺利在周日中午出院，我的那位病友当时血液检测都没有通过，他至少还要在医院多待3天。回到家整理了下东西，洗了个澡，伴随着开着中档的加湿器，就睡觉了。期间就醒了两三次，嘴巴还是很干，感觉比医院睡得好些。</p>\n<h2 id=\"2018-07-02，周一\"><a href=\"#2018-07-02，周一\" class=\"headerlink\" title=\"2018-07-02，周一\"></a>2018-07-02，周一</h2><p>现在是手术后的第7天，已经出院，选择来上班试试，意识还行，身体很疲惫，很饿，晚上睡觉呼吸只能靠嘴巴，会非常干，很容易干醒，讲话可以讲一点，但舌头太干，讲不清楚。早餐照例是流质食品——豆腐脑，咽下去时，喉咙有点痛，非常容易吃到鼻子里去，吃了几小口就吃不下了，如果按照这个速度继续吃，估计1个多小时才能把一碗2块钱的豆腐脑吃完。肚子里面一直是空的，也一直是饥饿的状态，接下去每一天估计只会吃牛奶和一点点糖水/汤水补充能量，加上一些纯净水平衡体内水盐，这样的情况要持续到2018-07-09拆线前。每天都挺漫长。。。</p>\n<h2 id=\"2018-07-20，周五\"><a href=\"#2018-07-20，周五\" class=\"headerlink\" title=\"2018-07-20，周五\"></a>2018-07-20，周五</h2><p>现在是手术后的第25天，已经可以用鼻子平躺着呼吸，吃东西稍有不适，角度不对会吃进鼻子。恢复很快。</p>\n"},{"title":"Pulsar-Bookkeeper-LSM-Like-SingleDirectoryDbLedgerStorage","date":"2019-05-27T12:12:19.000Z","_content":"\n\n## 写入逻辑\n## org.apache.bookkeeper.proto.WriteEntryProcessorV3#getAddResponse\n```\nprivate AddResponse getAddResponse() {\n    final long startTimeNanos = MathUtils.nowInNano();\n    AddRequest addRequest = request.getAddRequest();\n    long ledgerId = addRequest.getLedgerId();\n    long entryId = addRequest.getEntryId();\n\n    final AddResponse.Builder addResponse = AddResponse.newBuilder()\n            .setLedgerId(ledgerId)\n            .setEntryId(entryId);\n\n    if (!isVersionCompatible()) {\n        addResponse.setStatus(StatusCode.EBADVERSION);\n        return addResponse.build();\n    }\n\n    if (requestProcessor.getBookie().isReadOnly()\n        && !(RequestUtils.isHighPriority(request)\n                && requestProcessor.getBookie().isAvailableForHighPriorityWrites())) {\n        logger.warn(\"BookieServer is running as readonly mode, so rejecting the request from the client!\");\n        addResponse.setStatus(StatusCode.EREADONLY);\n        return addResponse.build();\n    }\n\n    // 这里构造了一个addEntry的callback，触发时机是，当Bookkeeper的journal成功将消息fsync到磁盘后（注意journalSyncData=true）\n    BookkeeperInternalCallbacks.WriteCallback wcb = new BookkeeperInternalCallbacks.WriteCallback() {\n        @Override\n        public void writeComplete(int rc, long ledgerId, long entryId,\n                                  BookieSocketAddress addr, Object ctx) {\n            if (BookieProtocol.EOK == rc) {\n                requestProcessor.getRequestStats().getAddEntryStats()\n                    .registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);\n            } else {\n                requestProcessor.getRequestStats().getAddEntryStats()\n                    .registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);\n            }\n\n            StatusCode status;\n            switch (rc) {\n                case BookieProtocol.EOK:\n                    status = StatusCode.EOK;\n                    break;\n                case BookieProtocol.EIO:\n                    status = StatusCode.EIO;\n                    break;\n                default:\n                    status = StatusCode.EUA;\n                    break;\n            }\n            addResponse.setStatus(status);\n            Response.Builder response = Response.newBuilder()\n                    .setHeader(getHeader())\n                    .setStatus(addResponse.getStatus())\n                    .setAddResponse(addResponse);\n            Response resp = response.build();\n            sendResponse(status, resp, requestProcessor.getRequestStats().getAddRequestStats());\n        }\n    };\n    final EnumSet<WriteFlag> writeFlags;\n    if (addRequest.hasWriteFlags()) {\n        writeFlags = WriteFlag.getWriteFlags(addRequest.getWriteFlags());\n    } else {\n        writeFlags = WriteFlag.NONE;\n    }\n    final boolean ackBeforeSync = writeFlags.contains(WriteFlag.DEFERRED_SYNC);\n    StatusCode status = null;\n    byte[] masterKey = addRequest.getMasterKey().toByteArray();\n    ByteBuf entryToAdd = Unpooled.wrappedBuffer(addRequest.getBody().asReadOnlyByteBuffer());\n    try {\n        if (RequestUtils.hasFlag(addRequest, AddRequest.Flag.RECOVERY_ADD)) {\n            requestProcessor.getBookie().recoveryAddEntry(entryToAdd, wcb, channel, masterKey);\n        } else {\n            requestProcessor.getBookie().addEntry(entryToAdd, ackBeforeSync, wcb, channel, masterKey);\n        }\n        status = StatusCode.EOK;\n    } catch (OperationRejectedException e) {\n        // Avoid to log each occurence of this exception as this can happen when the ledger storage is\n        // unable to keep up with the write rate.\n        if (logger.isDebugEnabled()) {\n            logger.debug(\"Operation rejected while writing {}\", request, e);\n        }\n        status = StatusCode.EIO;\n    } catch (IOException e) {\n        logger.error(\"Error writing entry:{} to ledger:{}\",\n                entryId, ledgerId, e);\n        status = StatusCode.EIO;\n    } catch (BookieException.LedgerFencedException e) {\n        logger.error(\"Ledger fenced while writing entry:{} to ledger:{}\",\n                entryId, ledgerId, e);\n        status = StatusCode.EFENCED;\n    } catch (BookieException e) {\n        logger.error(\"Unauthorized access to ledger:{} while writing entry:{}\",\n                ledgerId, entryId, e);\n        status = StatusCode.EUA;\n    } catch (Throwable t) {\n        logger.error(\"Unexpected exception while writing {}@{} : \",\n                entryId, ledgerId, t);\n        // some bad request which cause unexpected exception\n        status = StatusCode.EBADREQ;\n    }\n\n    // If everything is okay, we return null so that the calling function\n    // doesn't return a response back to the caller.\n    if (!status.equals(StatusCode.EOK)) {\n        addResponse.setStatus(status);\n        return addResponse.build();\n    }\n    return null;\n}\n```\n\n\n## 读取逻辑\n## org.apache.bookkeeper.bookie.storage.ldb.SingleDirectoryDbLedgerStorage#getEntry\n```\npublic ByteBuf getEntry(long ledgerId, long entryId) throws IOException {\n    long startTime = MathUtils.nowInNano();\n    if (log.isDebugEnabled()) {\n        log.debug(\"Get Entry: {}@{}\", ledgerId, entryId);\n    }\n\n    if (entryId == BookieProtocol.LAST_ADD_CONFIRMED) {\n        return getLastEntry(ledgerId);\n    }\n\n    // We need to try to read from both write caches, since recent entries could be found in either of the two. The\n    // write caches are already thread safe on their own, here we just need to make sure we get references to both\n    // of them. Using an optimistic lock since the read lock is always free, unless we're swapping the caches.\n    long stamp = writeCacheRotationLock.tryOptimisticRead();\n    WriteCache localWriteCache = writeCache;\n    WriteCache localWriteCacheBeingFlushed = writeCacheBeingFlushed;\n    if (!writeCacheRotationLock.validate(stamp)) {\n        // Fallback to regular read lock approach\n        stamp = writeCacheRotationLock.readLock();\n        try {\n            localWriteCache = writeCache;\n            localWriteCacheBeingFlushed = writeCacheBeingFlushed;\n        } finally {\n            writeCacheRotationLock.unlockRead(stamp);\n        }\n    }\n\n    // First try to read from the write cache of recent entries\n    ByteBuf entry = localWriteCache.get(ledgerId, entryId);\n    if (entry != null) {\n        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);\n        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);\n        return entry;\n    }\n\n    // If there's a flush going on, the entry might be in the flush buffer\n    entry = localWriteCacheBeingFlushed.get(ledgerId, entryId);\n    if (entry != null) {\n        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);\n        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);\n        return entry;\n    }\n\n    // Try reading from read-ahead cache\n    entry = readCache.get(ledgerId, entryId);\n    if (entry != null) {\n        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);\n        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);\n        return entry;\n    }\n\n    // Read from main storage\n    long entryLocation;\n    try {\n        entryLocation = entryLocationIndex.getLocation(ledgerId, entryId);\n        if (entryLocation == 0) {\n            throw new NoEntryException(ledgerId, entryId);\n        }\n        entry = entryLogger.readEntry(ledgerId, entryId, entryLocation);\n    } catch (NoEntryException e) {\n        recordFailedEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);\n        throw e;\n    }\n\n    readCache.put(ledgerId, entryId, entry);\n\n    // Try to read more entries\n    long nextEntryLocation = entryLocation + 4 /* size header */ + entry.readableBytes();\n    fillReadAheadCache(ledgerId, entryId + 1, nextEntryLocation);\n\n    recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheMissStats(), startTime);\n    recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);\n    return entry;\n}\n```","source":"_posts/Pulsar-Bookkeeper-LSM-Like-SingleDirectoryDbLedgerStorage.md","raw":"---\ntitle: Pulsar-Bookkeeper-LSM-Like-SingleDirectoryDbLedgerStorage\ndate: 2019-05-27 20:12:19\ntags:\n---\n\n\n## 写入逻辑\n## org.apache.bookkeeper.proto.WriteEntryProcessorV3#getAddResponse\n```\nprivate AddResponse getAddResponse() {\n    final long startTimeNanos = MathUtils.nowInNano();\n    AddRequest addRequest = request.getAddRequest();\n    long ledgerId = addRequest.getLedgerId();\n    long entryId = addRequest.getEntryId();\n\n    final AddResponse.Builder addResponse = AddResponse.newBuilder()\n            .setLedgerId(ledgerId)\n            .setEntryId(entryId);\n\n    if (!isVersionCompatible()) {\n        addResponse.setStatus(StatusCode.EBADVERSION);\n        return addResponse.build();\n    }\n\n    if (requestProcessor.getBookie().isReadOnly()\n        && !(RequestUtils.isHighPriority(request)\n                && requestProcessor.getBookie().isAvailableForHighPriorityWrites())) {\n        logger.warn(\"BookieServer is running as readonly mode, so rejecting the request from the client!\");\n        addResponse.setStatus(StatusCode.EREADONLY);\n        return addResponse.build();\n    }\n\n    // 这里构造了一个addEntry的callback，触发时机是，当Bookkeeper的journal成功将消息fsync到磁盘后（注意journalSyncData=true）\n    BookkeeperInternalCallbacks.WriteCallback wcb = new BookkeeperInternalCallbacks.WriteCallback() {\n        @Override\n        public void writeComplete(int rc, long ledgerId, long entryId,\n                                  BookieSocketAddress addr, Object ctx) {\n            if (BookieProtocol.EOK == rc) {\n                requestProcessor.getRequestStats().getAddEntryStats()\n                    .registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);\n            } else {\n                requestProcessor.getRequestStats().getAddEntryStats()\n                    .registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);\n            }\n\n            StatusCode status;\n            switch (rc) {\n                case BookieProtocol.EOK:\n                    status = StatusCode.EOK;\n                    break;\n                case BookieProtocol.EIO:\n                    status = StatusCode.EIO;\n                    break;\n                default:\n                    status = StatusCode.EUA;\n                    break;\n            }\n            addResponse.setStatus(status);\n            Response.Builder response = Response.newBuilder()\n                    .setHeader(getHeader())\n                    .setStatus(addResponse.getStatus())\n                    .setAddResponse(addResponse);\n            Response resp = response.build();\n            sendResponse(status, resp, requestProcessor.getRequestStats().getAddRequestStats());\n        }\n    };\n    final EnumSet<WriteFlag> writeFlags;\n    if (addRequest.hasWriteFlags()) {\n        writeFlags = WriteFlag.getWriteFlags(addRequest.getWriteFlags());\n    } else {\n        writeFlags = WriteFlag.NONE;\n    }\n    final boolean ackBeforeSync = writeFlags.contains(WriteFlag.DEFERRED_SYNC);\n    StatusCode status = null;\n    byte[] masterKey = addRequest.getMasterKey().toByteArray();\n    ByteBuf entryToAdd = Unpooled.wrappedBuffer(addRequest.getBody().asReadOnlyByteBuffer());\n    try {\n        if (RequestUtils.hasFlag(addRequest, AddRequest.Flag.RECOVERY_ADD)) {\n            requestProcessor.getBookie().recoveryAddEntry(entryToAdd, wcb, channel, masterKey);\n        } else {\n            requestProcessor.getBookie().addEntry(entryToAdd, ackBeforeSync, wcb, channel, masterKey);\n        }\n        status = StatusCode.EOK;\n    } catch (OperationRejectedException e) {\n        // Avoid to log each occurence of this exception as this can happen when the ledger storage is\n        // unable to keep up with the write rate.\n        if (logger.isDebugEnabled()) {\n            logger.debug(\"Operation rejected while writing {}\", request, e);\n        }\n        status = StatusCode.EIO;\n    } catch (IOException e) {\n        logger.error(\"Error writing entry:{} to ledger:{}\",\n                entryId, ledgerId, e);\n        status = StatusCode.EIO;\n    } catch (BookieException.LedgerFencedException e) {\n        logger.error(\"Ledger fenced while writing entry:{} to ledger:{}\",\n                entryId, ledgerId, e);\n        status = StatusCode.EFENCED;\n    } catch (BookieException e) {\n        logger.error(\"Unauthorized access to ledger:{} while writing entry:{}\",\n                ledgerId, entryId, e);\n        status = StatusCode.EUA;\n    } catch (Throwable t) {\n        logger.error(\"Unexpected exception while writing {}@{} : \",\n                entryId, ledgerId, t);\n        // some bad request which cause unexpected exception\n        status = StatusCode.EBADREQ;\n    }\n\n    // If everything is okay, we return null so that the calling function\n    // doesn't return a response back to the caller.\n    if (!status.equals(StatusCode.EOK)) {\n        addResponse.setStatus(status);\n        return addResponse.build();\n    }\n    return null;\n}\n```\n\n\n## 读取逻辑\n## org.apache.bookkeeper.bookie.storage.ldb.SingleDirectoryDbLedgerStorage#getEntry\n```\npublic ByteBuf getEntry(long ledgerId, long entryId) throws IOException {\n    long startTime = MathUtils.nowInNano();\n    if (log.isDebugEnabled()) {\n        log.debug(\"Get Entry: {}@{}\", ledgerId, entryId);\n    }\n\n    if (entryId == BookieProtocol.LAST_ADD_CONFIRMED) {\n        return getLastEntry(ledgerId);\n    }\n\n    // We need to try to read from both write caches, since recent entries could be found in either of the two. The\n    // write caches are already thread safe on their own, here we just need to make sure we get references to both\n    // of them. Using an optimistic lock since the read lock is always free, unless we're swapping the caches.\n    long stamp = writeCacheRotationLock.tryOptimisticRead();\n    WriteCache localWriteCache = writeCache;\n    WriteCache localWriteCacheBeingFlushed = writeCacheBeingFlushed;\n    if (!writeCacheRotationLock.validate(stamp)) {\n        // Fallback to regular read lock approach\n        stamp = writeCacheRotationLock.readLock();\n        try {\n            localWriteCache = writeCache;\n            localWriteCacheBeingFlushed = writeCacheBeingFlushed;\n        } finally {\n            writeCacheRotationLock.unlockRead(stamp);\n        }\n    }\n\n    // First try to read from the write cache of recent entries\n    ByteBuf entry = localWriteCache.get(ledgerId, entryId);\n    if (entry != null) {\n        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);\n        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);\n        return entry;\n    }\n\n    // If there's a flush going on, the entry might be in the flush buffer\n    entry = localWriteCacheBeingFlushed.get(ledgerId, entryId);\n    if (entry != null) {\n        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);\n        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);\n        return entry;\n    }\n\n    // Try reading from read-ahead cache\n    entry = readCache.get(ledgerId, entryId);\n    if (entry != null) {\n        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);\n        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);\n        return entry;\n    }\n\n    // Read from main storage\n    long entryLocation;\n    try {\n        entryLocation = entryLocationIndex.getLocation(ledgerId, entryId);\n        if (entryLocation == 0) {\n            throw new NoEntryException(ledgerId, entryId);\n        }\n        entry = entryLogger.readEntry(ledgerId, entryId, entryLocation);\n    } catch (NoEntryException e) {\n        recordFailedEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);\n        throw e;\n    }\n\n    readCache.put(ledgerId, entryId, entry);\n\n    // Try to read more entries\n    long nextEntryLocation = entryLocation + 4 /* size header */ + entry.readableBytes();\n    fillReadAheadCache(ledgerId, entryId + 1, nextEntryLocation);\n\n    recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheMissStats(), startTime);\n    recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);\n    return entry;\n}\n```","slug":"Pulsar-Bookkeeper-LSM-Like-SingleDirectoryDbLedgerStorage","published":1,"updated":"2019-09-28T08:51:00.913Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84h004jv1npzapngdb8","content":"<h2 id=\"写入逻辑\"><a href=\"#写入逻辑\" class=\"headerlink\" title=\"写入逻辑\"></a>写入逻辑</h2><h2 id=\"org-apache-bookkeeper-proto-WriteEntryProcessorV3-getAddResponse\"><a href=\"#org-apache-bookkeeper-proto-WriteEntryProcessorV3-getAddResponse\" class=\"headerlink\" title=\"org.apache.bookkeeper.proto.WriteEntryProcessorV3#getAddResponse\"></a>org.apache.bookkeeper.proto.WriteEntryProcessorV3#getAddResponse</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private AddResponse getAddResponse() &#123;</span><br><span class=\"line\">    final long startTimeNanos = MathUtils.nowInNano();</span><br><span class=\"line\">    AddRequest addRequest = request.getAddRequest();</span><br><span class=\"line\">    long ledgerId = addRequest.getLedgerId();</span><br><span class=\"line\">    long entryId = addRequest.getEntryId();</span><br><span class=\"line\"></span><br><span class=\"line\">    final AddResponse.Builder addResponse = AddResponse.newBuilder()</span><br><span class=\"line\">            .setLedgerId(ledgerId)</span><br><span class=\"line\">            .setEntryId(entryId);</span><br><span class=\"line\"></span><br><span class=\"line\">    if (!isVersionCompatible()) &#123;</span><br><span class=\"line\">        addResponse.setStatus(StatusCode.EBADVERSION);</span><br><span class=\"line\">        return addResponse.build();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (requestProcessor.getBookie().isReadOnly()</span><br><span class=\"line\">        &amp;&amp; !(RequestUtils.isHighPriority(request)</span><br><span class=\"line\">                &amp;&amp; requestProcessor.getBookie().isAvailableForHighPriorityWrites())) &#123;</span><br><span class=\"line\">        logger.warn(&quot;BookieServer is running as readonly mode, so rejecting the request from the client!&quot;);</span><br><span class=\"line\">        addResponse.setStatus(StatusCode.EREADONLY);</span><br><span class=\"line\">        return addResponse.build();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 这里构造了一个addEntry的callback，触发时机是，当Bookkeeper的journal成功将消息fsync到磁盘后（注意journalSyncData=true）</span><br><span class=\"line\">    BookkeeperInternalCallbacks.WriteCallback wcb = new BookkeeperInternalCallbacks.WriteCallback() &#123;</span><br><span class=\"line\">        @Override</span><br><span class=\"line\">        public void writeComplete(int rc, long ledgerId, long entryId,</span><br><span class=\"line\">                                  BookieSocketAddress addr, Object ctx) &#123;</span><br><span class=\"line\">            if (BookieProtocol.EOK == rc) &#123;</span><br><span class=\"line\">                requestProcessor.getRequestStats().getAddEntryStats()</span><br><span class=\"line\">                    .registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                requestProcessor.getRequestStats().getAddEntryStats()</span><br><span class=\"line\">                    .registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            StatusCode status;</span><br><span class=\"line\">            switch (rc) &#123;</span><br><span class=\"line\">                case BookieProtocol.EOK:</span><br><span class=\"line\">                    status = StatusCode.EOK;</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                case BookieProtocol.EIO:</span><br><span class=\"line\">                    status = StatusCode.EIO;</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                default:</span><br><span class=\"line\">                    status = StatusCode.EUA;</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            addResponse.setStatus(status);</span><br><span class=\"line\">            Response.Builder response = Response.newBuilder()</span><br><span class=\"line\">                    .setHeader(getHeader())</span><br><span class=\"line\">                    .setStatus(addResponse.getStatus())</span><br><span class=\"line\">                    .setAddResponse(addResponse);</span><br><span class=\"line\">            Response resp = response.build();</span><br><span class=\"line\">            sendResponse(status, resp, requestProcessor.getRequestStats().getAddRequestStats());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    final EnumSet&lt;WriteFlag&gt; writeFlags;</span><br><span class=\"line\">    if (addRequest.hasWriteFlags()) &#123;</span><br><span class=\"line\">        writeFlags = WriteFlag.getWriteFlags(addRequest.getWriteFlags());</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        writeFlags = WriteFlag.NONE;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    final boolean ackBeforeSync = writeFlags.contains(WriteFlag.DEFERRED_SYNC);</span><br><span class=\"line\">    StatusCode status = null;</span><br><span class=\"line\">    byte[] masterKey = addRequest.getMasterKey().toByteArray();</span><br><span class=\"line\">    ByteBuf entryToAdd = Unpooled.wrappedBuffer(addRequest.getBody().asReadOnlyByteBuffer());</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        if (RequestUtils.hasFlag(addRequest, AddRequest.Flag.RECOVERY_ADD)) &#123;</span><br><span class=\"line\">            requestProcessor.getBookie().recoveryAddEntry(entryToAdd, wcb, channel, masterKey);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            requestProcessor.getBookie().addEntry(entryToAdd, ackBeforeSync, wcb, channel, masterKey);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        status = StatusCode.EOK;</span><br><span class=\"line\">    &#125; catch (OperationRejectedException e) &#123;</span><br><span class=\"line\">        // Avoid to log each occurence of this exception as this can happen when the ledger storage is</span><br><span class=\"line\">        // unable to keep up with the write rate.</span><br><span class=\"line\">        if (logger.isDebugEnabled()) &#123;</span><br><span class=\"line\">            logger.debug(&quot;Operation rejected while writing &#123;&#125;&quot;, request, e);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        status = StatusCode.EIO;</span><br><span class=\"line\">    &#125; catch (IOException e) &#123;</span><br><span class=\"line\">        logger.error(&quot;Error writing entry:&#123;&#125; to ledger:&#123;&#125;&quot;,</span><br><span class=\"line\">                entryId, ledgerId, e);</span><br><span class=\"line\">        status = StatusCode.EIO;</span><br><span class=\"line\">    &#125; catch (BookieException.LedgerFencedException e) &#123;</span><br><span class=\"line\">        logger.error(&quot;Ledger fenced while writing entry:&#123;&#125; to ledger:&#123;&#125;&quot;,</span><br><span class=\"line\">                entryId, ledgerId, e);</span><br><span class=\"line\">        status = StatusCode.EFENCED;</span><br><span class=\"line\">    &#125; catch (BookieException e) &#123;</span><br><span class=\"line\">        logger.error(&quot;Unauthorized access to ledger:&#123;&#125; while writing entry:&#123;&#125;&quot;,</span><br><span class=\"line\">                ledgerId, entryId, e);</span><br><span class=\"line\">        status = StatusCode.EUA;</span><br><span class=\"line\">    &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">        logger.error(&quot;Unexpected exception while writing &#123;&#125;@&#123;&#125; : &quot;,</span><br><span class=\"line\">                entryId, ledgerId, t);</span><br><span class=\"line\">        // some bad request which cause unexpected exception</span><br><span class=\"line\">        status = StatusCode.EBADREQ;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // If everything is okay, we return null so that the calling function</span><br><span class=\"line\">    // doesn&apos;t return a response back to the caller.</span><br><span class=\"line\">    if (!status.equals(StatusCode.EOK)) &#123;</span><br><span class=\"line\">        addResponse.setStatus(status);</span><br><span class=\"line\">        return addResponse.build();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return null;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"读取逻辑\"><a href=\"#读取逻辑\" class=\"headerlink\" title=\"读取逻辑\"></a>读取逻辑</h2><h2 id=\"org-apache-bookkeeper-bookie-storage-ldb-SingleDirectoryDbLedgerStorage-getEntry\"><a href=\"#org-apache-bookkeeper-bookie-storage-ldb-SingleDirectoryDbLedgerStorage-getEntry\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.storage.ldb.SingleDirectoryDbLedgerStorage#getEntry\"></a>org.apache.bookkeeper.bookie.storage.ldb.SingleDirectoryDbLedgerStorage#getEntry</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public ByteBuf getEntry(long ledgerId, long entryId) throws IOException &#123;</span><br><span class=\"line\">    long startTime = MathUtils.nowInNano();</span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(&quot;Get Entry: &#123;&#125;@&#123;&#125;&quot;, ledgerId, entryId);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (entryId == BookieProtocol.LAST_ADD_CONFIRMED) &#123;</span><br><span class=\"line\">        return getLastEntry(ledgerId);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // We need to try to read from both write caches, since recent entries could be found in either of the two. The</span><br><span class=\"line\">    // write caches are already thread safe on their own, here we just need to make sure we get references to both</span><br><span class=\"line\">    // of them. Using an optimistic lock since the read lock is always free, unless we&apos;re swapping the caches.</span><br><span class=\"line\">    long stamp = writeCacheRotationLock.tryOptimisticRead();</span><br><span class=\"line\">    WriteCache localWriteCache = writeCache;</span><br><span class=\"line\">    WriteCache localWriteCacheBeingFlushed = writeCacheBeingFlushed;</span><br><span class=\"line\">    if (!writeCacheRotationLock.validate(stamp)) &#123;</span><br><span class=\"line\">        // Fallback to regular read lock approach</span><br><span class=\"line\">        stamp = writeCacheRotationLock.readLock();</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            localWriteCache = writeCache;</span><br><span class=\"line\">            localWriteCacheBeingFlushed = writeCacheBeingFlushed;</span><br><span class=\"line\">        &#125; finally &#123;</span><br><span class=\"line\">            writeCacheRotationLock.unlockRead(stamp);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // First try to read from the write cache of recent entries</span><br><span class=\"line\">    ByteBuf entry = localWriteCache.get(ledgerId, entryId);</span><br><span class=\"line\">    if (entry != null) &#123;</span><br><span class=\"line\">        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span><br><span class=\"line\">        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span><br><span class=\"line\">        return entry;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // If there&apos;s a flush going on, the entry might be in the flush buffer</span><br><span class=\"line\">    entry = localWriteCacheBeingFlushed.get(ledgerId, entryId);</span><br><span class=\"line\">    if (entry != null) &#123;</span><br><span class=\"line\">        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span><br><span class=\"line\">        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span><br><span class=\"line\">        return entry;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Try reading from read-ahead cache</span><br><span class=\"line\">    entry = readCache.get(ledgerId, entryId);</span><br><span class=\"line\">    if (entry != null) &#123;</span><br><span class=\"line\">        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span><br><span class=\"line\">        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span><br><span class=\"line\">        return entry;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Read from main storage</span><br><span class=\"line\">    long entryLocation;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        entryLocation = entryLocationIndex.getLocation(ledgerId, entryId);</span><br><span class=\"line\">        if (entryLocation == 0) &#123;</span><br><span class=\"line\">            throw new NoEntryException(ledgerId, entryId);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        entry = entryLogger.readEntry(ledgerId, entryId, entryLocation);</span><br><span class=\"line\">    &#125; catch (NoEntryException e) &#123;</span><br><span class=\"line\">        recordFailedEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span><br><span class=\"line\">        throw e;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    readCache.put(ledgerId, entryId, entry);</span><br><span class=\"line\"></span><br><span class=\"line\">    // Try to read more entries</span><br><span class=\"line\">    long nextEntryLocation = entryLocation + 4 /* size header */ + entry.readableBytes();</span><br><span class=\"line\">    fillReadAheadCache(ledgerId, entryId + 1, nextEntryLocation);</span><br><span class=\"line\"></span><br><span class=\"line\">    recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheMissStats(), startTime);</span><br><span class=\"line\">    recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span><br><span class=\"line\">    return entry;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"写入逻辑\"><a href=\"#写入逻辑\" class=\"headerlink\" title=\"写入逻辑\"></a>写入逻辑</h2><h2 id=\"org-apache-bookkeeper-proto-WriteEntryProcessorV3-getAddResponse\"><a href=\"#org-apache-bookkeeper-proto-WriteEntryProcessorV3-getAddResponse\" class=\"headerlink\" title=\"org.apache.bookkeeper.proto.WriteEntryProcessorV3#getAddResponse\"></a>org.apache.bookkeeper.proto.WriteEntryProcessorV3#getAddResponse</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private AddResponse getAddResponse() &#123;</span><br><span class=\"line\">    final long startTimeNanos = MathUtils.nowInNano();</span><br><span class=\"line\">    AddRequest addRequest = request.getAddRequest();</span><br><span class=\"line\">    long ledgerId = addRequest.getLedgerId();</span><br><span class=\"line\">    long entryId = addRequest.getEntryId();</span><br><span class=\"line\"></span><br><span class=\"line\">    final AddResponse.Builder addResponse = AddResponse.newBuilder()</span><br><span class=\"line\">            .setLedgerId(ledgerId)</span><br><span class=\"line\">            .setEntryId(entryId);</span><br><span class=\"line\"></span><br><span class=\"line\">    if (!isVersionCompatible()) &#123;</span><br><span class=\"line\">        addResponse.setStatus(StatusCode.EBADVERSION);</span><br><span class=\"line\">        return addResponse.build();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (requestProcessor.getBookie().isReadOnly()</span><br><span class=\"line\">        &amp;&amp; !(RequestUtils.isHighPriority(request)</span><br><span class=\"line\">                &amp;&amp; requestProcessor.getBookie().isAvailableForHighPriorityWrites())) &#123;</span><br><span class=\"line\">        logger.warn(&quot;BookieServer is running as readonly mode, so rejecting the request from the client!&quot;);</span><br><span class=\"line\">        addResponse.setStatus(StatusCode.EREADONLY);</span><br><span class=\"line\">        return addResponse.build();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 这里构造了一个addEntry的callback，触发时机是，当Bookkeeper的journal成功将消息fsync到磁盘后（注意journalSyncData=true）</span><br><span class=\"line\">    BookkeeperInternalCallbacks.WriteCallback wcb = new BookkeeperInternalCallbacks.WriteCallback() &#123;</span><br><span class=\"line\">        @Override</span><br><span class=\"line\">        public void writeComplete(int rc, long ledgerId, long entryId,</span><br><span class=\"line\">                                  BookieSocketAddress addr, Object ctx) &#123;</span><br><span class=\"line\">            if (BookieProtocol.EOK == rc) &#123;</span><br><span class=\"line\">                requestProcessor.getRequestStats().getAddEntryStats()</span><br><span class=\"line\">                    .registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                requestProcessor.getRequestStats().getAddEntryStats()</span><br><span class=\"line\">                    .registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            StatusCode status;</span><br><span class=\"line\">            switch (rc) &#123;</span><br><span class=\"line\">                case BookieProtocol.EOK:</span><br><span class=\"line\">                    status = StatusCode.EOK;</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                case BookieProtocol.EIO:</span><br><span class=\"line\">                    status = StatusCode.EIO;</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                default:</span><br><span class=\"line\">                    status = StatusCode.EUA;</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            addResponse.setStatus(status);</span><br><span class=\"line\">            Response.Builder response = Response.newBuilder()</span><br><span class=\"line\">                    .setHeader(getHeader())</span><br><span class=\"line\">                    .setStatus(addResponse.getStatus())</span><br><span class=\"line\">                    .setAddResponse(addResponse);</span><br><span class=\"line\">            Response resp = response.build();</span><br><span class=\"line\">            sendResponse(status, resp, requestProcessor.getRequestStats().getAddRequestStats());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    final EnumSet&lt;WriteFlag&gt; writeFlags;</span><br><span class=\"line\">    if (addRequest.hasWriteFlags()) &#123;</span><br><span class=\"line\">        writeFlags = WriteFlag.getWriteFlags(addRequest.getWriteFlags());</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        writeFlags = WriteFlag.NONE;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    final boolean ackBeforeSync = writeFlags.contains(WriteFlag.DEFERRED_SYNC);</span><br><span class=\"line\">    StatusCode status = null;</span><br><span class=\"line\">    byte[] masterKey = addRequest.getMasterKey().toByteArray();</span><br><span class=\"line\">    ByteBuf entryToAdd = Unpooled.wrappedBuffer(addRequest.getBody().asReadOnlyByteBuffer());</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        if (RequestUtils.hasFlag(addRequest, AddRequest.Flag.RECOVERY_ADD)) &#123;</span><br><span class=\"line\">            requestProcessor.getBookie().recoveryAddEntry(entryToAdd, wcb, channel, masterKey);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            requestProcessor.getBookie().addEntry(entryToAdd, ackBeforeSync, wcb, channel, masterKey);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        status = StatusCode.EOK;</span><br><span class=\"line\">    &#125; catch (OperationRejectedException e) &#123;</span><br><span class=\"line\">        // Avoid to log each occurence of this exception as this can happen when the ledger storage is</span><br><span class=\"line\">        // unable to keep up with the write rate.</span><br><span class=\"line\">        if (logger.isDebugEnabled()) &#123;</span><br><span class=\"line\">            logger.debug(&quot;Operation rejected while writing &#123;&#125;&quot;, request, e);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        status = StatusCode.EIO;</span><br><span class=\"line\">    &#125; catch (IOException e) &#123;</span><br><span class=\"line\">        logger.error(&quot;Error writing entry:&#123;&#125; to ledger:&#123;&#125;&quot;,</span><br><span class=\"line\">                entryId, ledgerId, e);</span><br><span class=\"line\">        status = StatusCode.EIO;</span><br><span class=\"line\">    &#125; catch (BookieException.LedgerFencedException e) &#123;</span><br><span class=\"line\">        logger.error(&quot;Ledger fenced while writing entry:&#123;&#125; to ledger:&#123;&#125;&quot;,</span><br><span class=\"line\">                entryId, ledgerId, e);</span><br><span class=\"line\">        status = StatusCode.EFENCED;</span><br><span class=\"line\">    &#125; catch (BookieException e) &#123;</span><br><span class=\"line\">        logger.error(&quot;Unauthorized access to ledger:&#123;&#125; while writing entry:&#123;&#125;&quot;,</span><br><span class=\"line\">                ledgerId, entryId, e);</span><br><span class=\"line\">        status = StatusCode.EUA;</span><br><span class=\"line\">    &#125; catch (Throwable t) &#123;</span><br><span class=\"line\">        logger.error(&quot;Unexpected exception while writing &#123;&#125;@&#123;&#125; : &quot;,</span><br><span class=\"line\">                entryId, ledgerId, t);</span><br><span class=\"line\">        // some bad request which cause unexpected exception</span><br><span class=\"line\">        status = StatusCode.EBADREQ;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // If everything is okay, we return null so that the calling function</span><br><span class=\"line\">    // doesn&apos;t return a response back to the caller.</span><br><span class=\"line\">    if (!status.equals(StatusCode.EOK)) &#123;</span><br><span class=\"line\">        addResponse.setStatus(status);</span><br><span class=\"line\">        return addResponse.build();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return null;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"读取逻辑\"><a href=\"#读取逻辑\" class=\"headerlink\" title=\"读取逻辑\"></a>读取逻辑</h2><h2 id=\"org-apache-bookkeeper-bookie-storage-ldb-SingleDirectoryDbLedgerStorage-getEntry\"><a href=\"#org-apache-bookkeeper-bookie-storage-ldb-SingleDirectoryDbLedgerStorage-getEntry\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.storage.ldb.SingleDirectoryDbLedgerStorage#getEntry\"></a>org.apache.bookkeeper.bookie.storage.ldb.SingleDirectoryDbLedgerStorage#getEntry</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public ByteBuf getEntry(long ledgerId, long entryId) throws IOException &#123;</span><br><span class=\"line\">    long startTime = MathUtils.nowInNano();</span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(&quot;Get Entry: &#123;&#125;@&#123;&#125;&quot;, ledgerId, entryId);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (entryId == BookieProtocol.LAST_ADD_CONFIRMED) &#123;</span><br><span class=\"line\">        return getLastEntry(ledgerId);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // We need to try to read from both write caches, since recent entries could be found in either of the two. The</span><br><span class=\"line\">    // write caches are already thread safe on their own, here we just need to make sure we get references to both</span><br><span class=\"line\">    // of them. Using an optimistic lock since the read lock is always free, unless we&apos;re swapping the caches.</span><br><span class=\"line\">    long stamp = writeCacheRotationLock.tryOptimisticRead();</span><br><span class=\"line\">    WriteCache localWriteCache = writeCache;</span><br><span class=\"line\">    WriteCache localWriteCacheBeingFlushed = writeCacheBeingFlushed;</span><br><span class=\"line\">    if (!writeCacheRotationLock.validate(stamp)) &#123;</span><br><span class=\"line\">        // Fallback to regular read lock approach</span><br><span class=\"line\">        stamp = writeCacheRotationLock.readLock();</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            localWriteCache = writeCache;</span><br><span class=\"line\">            localWriteCacheBeingFlushed = writeCacheBeingFlushed;</span><br><span class=\"line\">        &#125; finally &#123;</span><br><span class=\"line\">            writeCacheRotationLock.unlockRead(stamp);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // First try to read from the write cache of recent entries</span><br><span class=\"line\">    ByteBuf entry = localWriteCache.get(ledgerId, entryId);</span><br><span class=\"line\">    if (entry != null) &#123;</span><br><span class=\"line\">        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span><br><span class=\"line\">        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span><br><span class=\"line\">        return entry;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // If there&apos;s a flush going on, the entry might be in the flush buffer</span><br><span class=\"line\">    entry = localWriteCacheBeingFlushed.get(ledgerId, entryId);</span><br><span class=\"line\">    if (entry != null) &#123;</span><br><span class=\"line\">        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span><br><span class=\"line\">        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span><br><span class=\"line\">        return entry;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Try reading from read-ahead cache</span><br><span class=\"line\">    entry = readCache.get(ledgerId, entryId);</span><br><span class=\"line\">    if (entry != null) &#123;</span><br><span class=\"line\">        recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheHitStats(), startTime);</span><br><span class=\"line\">        recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span><br><span class=\"line\">        return entry;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // Read from main storage</span><br><span class=\"line\">    long entryLocation;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        entryLocation = entryLocationIndex.getLocation(ledgerId, entryId);</span><br><span class=\"line\">        if (entryLocation == 0) &#123;</span><br><span class=\"line\">            throw new NoEntryException(ledgerId, entryId);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        entry = entryLogger.readEntry(ledgerId, entryId, entryLocation);</span><br><span class=\"line\">    &#125; catch (NoEntryException e) &#123;</span><br><span class=\"line\">        recordFailedEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span><br><span class=\"line\">        throw e;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    readCache.put(ledgerId, entryId, entry);</span><br><span class=\"line\"></span><br><span class=\"line\">    // Try to read more entries</span><br><span class=\"line\">    long nextEntryLocation = entryLocation + 4 /* size header */ + entry.readableBytes();</span><br><span class=\"line\">    fillReadAheadCache(ledgerId, entryId + 1, nextEntryLocation);</span><br><span class=\"line\"></span><br><span class=\"line\">    recordSuccessfulEvent(dbLedgerStorageStats.getReadCacheMissStats(), startTime);</span><br><span class=\"line\">    recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime);</span><br><span class=\"line\">    return entry;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Personal-Marketing","date":"2019-02-25T08:33:13.000Z","_content":"\n在简书上把下面的链接也放进去。让他欲罢不能得把所有的知识点都过一遍。\n「前置知识点」\n「进阶知识点」\n\n对「Netty」「RocketMQ」「JVM」有什么样的细粒度的疑问，比如\n\n「Netty」      Server端是在什么时候给每个Client连接分配（线程）的，怎么分配？\n\n「Netty」      Netty的SocketChannel是怎么在Pipeline中读数据的？\n\n「Netty」      Netty在读数据的时候，会申请多大的ByteBuf？\n\n「Netty」      怎么样避免Netty发生内存泄露？\n\n「RocketMQ」   RocketMQ的tag过滤是在Consumer端做的，还是在Broker端做的？\n\n「RocketMQ」   为什么开启transientStorePoolEnable后，RocketMQ写入的性能会提高？\n\n「JVM」        JVM是如何使用TLAB给对象分配内存的？\n\n「JVM」        在Mac上如何调试Hotspot C++源码？","source":"_posts/Personal-Marketing.md","raw":"---\ntitle: Personal-Marketing\ndate: 2019-02-25 16:33:13\ntags:\n---\n\n在简书上把下面的链接也放进去。让他欲罢不能得把所有的知识点都过一遍。\n「前置知识点」\n「进阶知识点」\n\n对「Netty」「RocketMQ」「JVM」有什么样的细粒度的疑问，比如\n\n「Netty」      Server端是在什么时候给每个Client连接分配（线程）的，怎么分配？\n\n「Netty」      Netty的SocketChannel是怎么在Pipeline中读数据的？\n\n「Netty」      Netty在读数据的时候，会申请多大的ByteBuf？\n\n「Netty」      怎么样避免Netty发生内存泄露？\n\n「RocketMQ」   RocketMQ的tag过滤是在Consumer端做的，还是在Broker端做的？\n\n「RocketMQ」   为什么开启transientStorePoolEnable后，RocketMQ写入的性能会提高？\n\n「JVM」        JVM是如何使用TLAB给对象分配内存的？\n\n「JVM」        在Mac上如何调试Hotspot C++源码？","slug":"Personal-Marketing","published":1,"updated":"2019-09-28T08:51:00.913Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84i004kv1npzoemrn6k","content":"<p>在简书上把下面的链接也放进去。让他欲罢不能得把所有的知识点都过一遍。<br>「前置知识点」<br>「进阶知识点」</p>\n<p>对「Netty」「RocketMQ」「JVM」有什么样的细粒度的疑问，比如</p>\n<p>「Netty」      Server端是在什么时候给每个Client连接分配（线程）的，怎么分配？</p>\n<p>「Netty」      Netty的SocketChannel是怎么在Pipeline中读数据的？</p>\n<p>「Netty」      Netty在读数据的时候，会申请多大的ByteBuf？</p>\n<p>「Netty」      怎么样避免Netty发生内存泄露？</p>\n<p>「RocketMQ」   RocketMQ的tag过滤是在Consumer端做的，还是在Broker端做的？</p>\n<p>「RocketMQ」   为什么开启transientStorePoolEnable后，RocketMQ写入的性能会提高？</p>\n<p>「JVM」        JVM是如何使用TLAB给对象分配内存的？</p>\n<p>「JVM」        在Mac上如何调试Hotspot C++源码？</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在简书上把下面的链接也放进去。让他欲罢不能得把所有的知识点都过一遍。<br>「前置知识点」<br>「进阶知识点」</p>\n<p>对「Netty」「RocketMQ」「JVM」有什么样的细粒度的疑问，比如</p>\n<p>「Netty」      Server端是在什么时候给每个Client连接分配（线程）的，怎么分配？</p>\n<p>「Netty」      Netty的SocketChannel是怎么在Pipeline中读数据的？</p>\n<p>「Netty」      Netty在读数据的时候，会申请多大的ByteBuf？</p>\n<p>「Netty」      怎么样避免Netty发生内存泄露？</p>\n<p>「RocketMQ」   RocketMQ的tag过滤是在Consumer端做的，还是在Broker端做的？</p>\n<p>「RocketMQ」   为什么开启transientStorePoolEnable后，RocketMQ写入的性能会提高？</p>\n<p>「JVM」        JVM是如何使用TLAB给对象分配内存的？</p>\n<p>「JVM」        在Mac上如何调试Hotspot C++源码？</p>\n"},{"title":"Pulsar-Bookkeeper-LSM","date":"2019-05-20T07:44:41.000Z","_content":"\n\n## org.apache.bookkeeper.bookie.Bookie#addEntryInternal\n```\n/**\n * Add an entry to a ledger as specified by handle.\n */\nprivate void addEntryInternal(LedgerDescriptor handle, ByteBuf entry,\n                              boolean ackBeforeSync, WriteCallback cb, Object ctx, byte[] masterKey)\n        throws IOException, BookieException, InterruptedException {\n    long ledgerId = handle.getLedgerId();\n    long entryId = handle.addEntry(entry);\n\n    bookieStats.getWriteBytes().add(entry.readableBytes());\n\n    // journal `addEntry` should happen after the entry is added to ledger storage.\n    // otherwise the journal entry can potentially be rolled before the ledger is created in ledger storage.\n    if (masterKeyCache.get(ledgerId) == null) {\n        // Force the load into masterKey cache\n        byte[] oldValue = masterKeyCache.putIfAbsent(ledgerId, masterKey);\n        if (oldValue == null) {\n            // new handle, we should add the key to journal ensure we can rebuild\n            ByteBuffer bb = ByteBuffer.allocate(8 + 8 + 4 + masterKey.length);\n            bb.putLong(ledgerId);\n            bb.putLong(METAENTRY_ID_LEDGER_KEY);\n            bb.putInt(masterKey.length);\n            bb.put(masterKey);\n            bb.flip();\n\n            getJournal(ledgerId).logAddEntry(bb, false /* ackBeforeSync */, new NopWriteCallback(), null);\n        }\n    }\n\n    if (LOG.isTraceEnabled()) {\n        LOG.trace(\"Adding {}@{}\", entryId, ledgerId);\n    }\n    getJournal(ledgerId).logAddEntry(entry, ackBeforeSync, cb, ctx);\n}\n```\n\n## org.apache.bookkeeper.bookie.SortedLedgerStorage#addEntry\n```\n@Override\npublic long addEntry(ByteBuf entry) throws IOException {\n    long ledgerId = entry.getLong(entry.readerIndex() + 0);\n    long entryId = entry.getLong(entry.readerIndex() + 8);\n    long lac = entry.getLong(entry.readerIndex() + 16);\n\n    memTable.addEntry(ledgerId, entryId, entry.nioBuffer(), this);\n    interleavedLedgerStorage.ledgerCache.updateLastAddConfirmed(ledgerId, lac);\n    return entryId;\n}\n```\n\n## org.apache.bookkeeper.bookie.EntryMemTable#addEntry\n```\npublic long addEntry(long ledgerId, long entryId, final ByteBuffer entry, final CacheCallback cb)\n        throws IOException {\n    long size = 0;\n    long startTimeNanos = MathUtils.nowInNano();\n    boolean success = false;\n    try {\n        if (isSizeLimitReached() || (!previousFlushSucceeded.get())) {\n            Checkpoint cp = snapshot();\n            if ((null != cp) || (!previousFlushSucceeded.get())) {\n                cb.onSizeLimitReached(cp);\n            }\n        }\n\n        final int len = entry.remaining();\n        if (!skipListSemaphore.tryAcquire(len)) {\n            memTableStats.getThrottlingCounter().inc();\n            final long throttlingStartTimeNanos = MathUtils.nowInNano();\n            skipListSemaphore.acquireUninterruptibly(len);\n            memTableStats.getThrottlingStats()\n                .registerSuccessfulEvent(MathUtils.elapsedNanos(throttlingStartTimeNanos), TimeUnit.NANOSECONDS);\n        }\n\n        this.lock.readLock().lock();\n        try {\n            EntryKeyValue toAdd = cloneWithAllocator(ledgerId, entryId, entry);\n            size = internalAdd(toAdd);\n        } finally {\n            this.lock.readLock().unlock();\n        }\n        success = true;\n        return size;\n    } finally {\n        if (success) {\n            memTableStats.getPutEntryStats()\n                .registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);\n        } else {\n            memTableStats.getPutEntryStats()\n                .registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);\n        }\n    }\n}\n```\n\n## org.apache.bookkeeper.bookie.EntryMemTable#snapshot(org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint)\n```\n/**\n * Snapshot current EntryMemTable. if given <i>oldCp</i> is older than current checkpoint,\n * we don't do any snapshot. If snapshot happened, we return the checkpoint of the snapshot.\n *\n * @param oldCp\n *          checkpoint\n * @return checkpoint of the snapshot, null means no snapshot\n * @throws IOException\n */\nCheckpoint snapshot(Checkpoint oldCp) throws IOException {\n    Checkpoint cp = null;\n    // No-op if snapshot currently has entries\n    if (this.snapshot.isEmpty() && this.kvmap.compareTo(oldCp) < 0) {\n        final long startTimeNanos = MathUtils.nowInNano();\n        this.lock.writeLock().lock();\n        try {\n            if (this.snapshot.isEmpty() && !this.kvmap.isEmpty()\n                    && this.kvmap.compareTo(oldCp) < 0) {\n                this.snapshot = this.kvmap;\n                this.kvmap = newSkipList();\n                // get the checkpoint of the memtable.\n                cp = this.kvmap.cp;\n                // Reset heap to not include any keys\n                this.size.set(0);\n                // Reset allocator so we get a fresh buffer for the new EntryMemTable\n                this.allocator = new SkipListArena(conf);\n            }\n        } finally {\n            this.lock.writeLock().unlock();\n        }\n\n        if (null != cp) {\n            memTableStats.getSnapshotStats()\n                .registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);\n        } else {\n            memTableStats.getSnapshotStats()\n                .registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);\n        }\n    }\n    return cp;\n}\n```\n\n## org.apache.bookkeeper.bookie.SortedLedgerStorage#onSizeLimitReached\n```\n// CacheCallback functions.\n@Override\npublic void onSizeLimitReached(final Checkpoint cp) throws IOException {\n    LOG.info(\"Reached size {}\", cp);\n    // when size limit reached, we get the previous checkpoint from snapshot mem-table.\n    // at this point, we are safer to schedule a checkpoint, since the entries added before\n    // this checkpoint already written to entry logger.\n    // but it would be better not to let mem-table flush to different entry log files,\n    // so we roll entry log files in SortedLedgerStorage itself.\n    // After that, we could make the process writing data to entry logger file not bound with checkpoint.\n    // otherwise, it hurts add performance.\n    //\n    // The only exception for the size limitation is if a file grows to be more than hard limit 2GB,\n    // we have to force rolling log, which it might cause slight performance effects\n    scheduler.execute(new Runnable() {\n        @Override\n        public void run() {\n            try {\n                LOG.info(\"Started flushing mem table.\");\n                interleavedLedgerStorage.getEntryLogger().prepareEntryMemTableFlush();\n                memTable.flush(SortedLedgerStorage.this);\n                if (interleavedLedgerStorage.getEntryLogger().commitEntryMemTableFlush()) {\n                    interleavedLedgerStorage.checkpointer.startCheckpoint(cp);\n                }\n            } catch (Exception e) {\n                stateManager.transitionToReadOnlyMode();\n                LOG.error(\"Exception thrown while flushing skip list cache.\", e);\n            }\n        }\n    });\n}\n```\n\n## org.apache.bookkeeper.bookie.EntryMemTable#flush(org.apache.bookkeeper.bookie.SkipListFlusher)\n```\n/**\n * Flush snapshot and clear it.\n */\nlong flush(final SkipListFlusher flusher) throws IOException {\n    try {\n        long flushSize = flushSnapshot(flusher, Checkpoint.MAX);\n        previousFlushSucceeded.set(true);\n        return flushSize;\n    } catch (IOException ioe) {\n        previousFlushSucceeded.set(false);\n        throw ioe;\n    }\n}\n```\n\n##","source":"_posts/Pulsar-Bookkeeper-LSM-Like-SortedLedgerStorage.md","raw":"---\ntitle: Pulsar-Bookkeeper-LSM\ndate: 2019-05-20 15:44:41\ntags:\n---\n\n\n## org.apache.bookkeeper.bookie.Bookie#addEntryInternal\n```\n/**\n * Add an entry to a ledger as specified by handle.\n */\nprivate void addEntryInternal(LedgerDescriptor handle, ByteBuf entry,\n                              boolean ackBeforeSync, WriteCallback cb, Object ctx, byte[] masterKey)\n        throws IOException, BookieException, InterruptedException {\n    long ledgerId = handle.getLedgerId();\n    long entryId = handle.addEntry(entry);\n\n    bookieStats.getWriteBytes().add(entry.readableBytes());\n\n    // journal `addEntry` should happen after the entry is added to ledger storage.\n    // otherwise the journal entry can potentially be rolled before the ledger is created in ledger storage.\n    if (masterKeyCache.get(ledgerId) == null) {\n        // Force the load into masterKey cache\n        byte[] oldValue = masterKeyCache.putIfAbsent(ledgerId, masterKey);\n        if (oldValue == null) {\n            // new handle, we should add the key to journal ensure we can rebuild\n            ByteBuffer bb = ByteBuffer.allocate(8 + 8 + 4 + masterKey.length);\n            bb.putLong(ledgerId);\n            bb.putLong(METAENTRY_ID_LEDGER_KEY);\n            bb.putInt(masterKey.length);\n            bb.put(masterKey);\n            bb.flip();\n\n            getJournal(ledgerId).logAddEntry(bb, false /* ackBeforeSync */, new NopWriteCallback(), null);\n        }\n    }\n\n    if (LOG.isTraceEnabled()) {\n        LOG.trace(\"Adding {}@{}\", entryId, ledgerId);\n    }\n    getJournal(ledgerId).logAddEntry(entry, ackBeforeSync, cb, ctx);\n}\n```\n\n## org.apache.bookkeeper.bookie.SortedLedgerStorage#addEntry\n```\n@Override\npublic long addEntry(ByteBuf entry) throws IOException {\n    long ledgerId = entry.getLong(entry.readerIndex() + 0);\n    long entryId = entry.getLong(entry.readerIndex() + 8);\n    long lac = entry.getLong(entry.readerIndex() + 16);\n\n    memTable.addEntry(ledgerId, entryId, entry.nioBuffer(), this);\n    interleavedLedgerStorage.ledgerCache.updateLastAddConfirmed(ledgerId, lac);\n    return entryId;\n}\n```\n\n## org.apache.bookkeeper.bookie.EntryMemTable#addEntry\n```\npublic long addEntry(long ledgerId, long entryId, final ByteBuffer entry, final CacheCallback cb)\n        throws IOException {\n    long size = 0;\n    long startTimeNanos = MathUtils.nowInNano();\n    boolean success = false;\n    try {\n        if (isSizeLimitReached() || (!previousFlushSucceeded.get())) {\n            Checkpoint cp = snapshot();\n            if ((null != cp) || (!previousFlushSucceeded.get())) {\n                cb.onSizeLimitReached(cp);\n            }\n        }\n\n        final int len = entry.remaining();\n        if (!skipListSemaphore.tryAcquire(len)) {\n            memTableStats.getThrottlingCounter().inc();\n            final long throttlingStartTimeNanos = MathUtils.nowInNano();\n            skipListSemaphore.acquireUninterruptibly(len);\n            memTableStats.getThrottlingStats()\n                .registerSuccessfulEvent(MathUtils.elapsedNanos(throttlingStartTimeNanos), TimeUnit.NANOSECONDS);\n        }\n\n        this.lock.readLock().lock();\n        try {\n            EntryKeyValue toAdd = cloneWithAllocator(ledgerId, entryId, entry);\n            size = internalAdd(toAdd);\n        } finally {\n            this.lock.readLock().unlock();\n        }\n        success = true;\n        return size;\n    } finally {\n        if (success) {\n            memTableStats.getPutEntryStats()\n                .registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);\n        } else {\n            memTableStats.getPutEntryStats()\n                .registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);\n        }\n    }\n}\n```\n\n## org.apache.bookkeeper.bookie.EntryMemTable#snapshot(org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint)\n```\n/**\n * Snapshot current EntryMemTable. if given <i>oldCp</i> is older than current checkpoint,\n * we don't do any snapshot. If snapshot happened, we return the checkpoint of the snapshot.\n *\n * @param oldCp\n *          checkpoint\n * @return checkpoint of the snapshot, null means no snapshot\n * @throws IOException\n */\nCheckpoint snapshot(Checkpoint oldCp) throws IOException {\n    Checkpoint cp = null;\n    // No-op if snapshot currently has entries\n    if (this.snapshot.isEmpty() && this.kvmap.compareTo(oldCp) < 0) {\n        final long startTimeNanos = MathUtils.nowInNano();\n        this.lock.writeLock().lock();\n        try {\n            if (this.snapshot.isEmpty() && !this.kvmap.isEmpty()\n                    && this.kvmap.compareTo(oldCp) < 0) {\n                this.snapshot = this.kvmap;\n                this.kvmap = newSkipList();\n                // get the checkpoint of the memtable.\n                cp = this.kvmap.cp;\n                // Reset heap to not include any keys\n                this.size.set(0);\n                // Reset allocator so we get a fresh buffer for the new EntryMemTable\n                this.allocator = new SkipListArena(conf);\n            }\n        } finally {\n            this.lock.writeLock().unlock();\n        }\n\n        if (null != cp) {\n            memTableStats.getSnapshotStats()\n                .registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);\n        } else {\n            memTableStats.getSnapshotStats()\n                .registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);\n        }\n    }\n    return cp;\n}\n```\n\n## org.apache.bookkeeper.bookie.SortedLedgerStorage#onSizeLimitReached\n```\n// CacheCallback functions.\n@Override\npublic void onSizeLimitReached(final Checkpoint cp) throws IOException {\n    LOG.info(\"Reached size {}\", cp);\n    // when size limit reached, we get the previous checkpoint from snapshot mem-table.\n    // at this point, we are safer to schedule a checkpoint, since the entries added before\n    // this checkpoint already written to entry logger.\n    // but it would be better not to let mem-table flush to different entry log files,\n    // so we roll entry log files in SortedLedgerStorage itself.\n    // After that, we could make the process writing data to entry logger file not bound with checkpoint.\n    // otherwise, it hurts add performance.\n    //\n    // The only exception for the size limitation is if a file grows to be more than hard limit 2GB,\n    // we have to force rolling log, which it might cause slight performance effects\n    scheduler.execute(new Runnable() {\n        @Override\n        public void run() {\n            try {\n                LOG.info(\"Started flushing mem table.\");\n                interleavedLedgerStorage.getEntryLogger().prepareEntryMemTableFlush();\n                memTable.flush(SortedLedgerStorage.this);\n                if (interleavedLedgerStorage.getEntryLogger().commitEntryMemTableFlush()) {\n                    interleavedLedgerStorage.checkpointer.startCheckpoint(cp);\n                }\n            } catch (Exception e) {\n                stateManager.transitionToReadOnlyMode();\n                LOG.error(\"Exception thrown while flushing skip list cache.\", e);\n            }\n        }\n    });\n}\n```\n\n## org.apache.bookkeeper.bookie.EntryMemTable#flush(org.apache.bookkeeper.bookie.SkipListFlusher)\n```\n/**\n * Flush snapshot and clear it.\n */\nlong flush(final SkipListFlusher flusher) throws IOException {\n    try {\n        long flushSize = flushSnapshot(flusher, Checkpoint.MAX);\n        previousFlushSucceeded.set(true);\n        return flushSize;\n    } catch (IOException ioe) {\n        previousFlushSucceeded.set(false);\n        throw ioe;\n    }\n}\n```\n\n##","slug":"Pulsar-Bookkeeper-LSM-Like-SortedLedgerStorage","published":1,"updated":"2019-09-28T08:51:00.913Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84i004lv1npljftx3ax","content":"<h2 id=\"org-apache-bookkeeper-bookie-Bookie-addEntryInternal\"><a href=\"#org-apache-bookkeeper-bookie-Bookie-addEntryInternal\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.Bookie#addEntryInternal\"></a>org.apache.bookkeeper.bookie.Bookie#addEntryInternal</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Add an entry to a ledger as specified by handle.</span><br><span class=\"line\"> */</span><br><span class=\"line\">private void addEntryInternal(LedgerDescriptor handle, ByteBuf entry,</span><br><span class=\"line\">                              boolean ackBeforeSync, WriteCallback cb, Object ctx, byte[] masterKey)</span><br><span class=\"line\">        throws IOException, BookieException, InterruptedException &#123;</span><br><span class=\"line\">    long ledgerId = handle.getLedgerId();</span><br><span class=\"line\">    long entryId = handle.addEntry(entry);</span><br><span class=\"line\"></span><br><span class=\"line\">    bookieStats.getWriteBytes().add(entry.readableBytes());</span><br><span class=\"line\"></span><br><span class=\"line\">    // journal `addEntry` should happen after the entry is added to ledger storage.</span><br><span class=\"line\">    // otherwise the journal entry can potentially be rolled before the ledger is created in ledger storage.</span><br><span class=\"line\">    if (masterKeyCache.get(ledgerId) == null) &#123;</span><br><span class=\"line\">        // Force the load into masterKey cache</span><br><span class=\"line\">        byte[] oldValue = masterKeyCache.putIfAbsent(ledgerId, masterKey);</span><br><span class=\"line\">        if (oldValue == null) &#123;</span><br><span class=\"line\">            // new handle, we should add the key to journal ensure we can rebuild</span><br><span class=\"line\">            ByteBuffer bb = ByteBuffer.allocate(8 + 8 + 4 + masterKey.length);</span><br><span class=\"line\">            bb.putLong(ledgerId);</span><br><span class=\"line\">            bb.putLong(METAENTRY_ID_LEDGER_KEY);</span><br><span class=\"line\">            bb.putInt(masterKey.length);</span><br><span class=\"line\">            bb.put(masterKey);</span><br><span class=\"line\">            bb.flip();</span><br><span class=\"line\"></span><br><span class=\"line\">            getJournal(ledgerId).logAddEntry(bb, false /* ackBeforeSync */, new NopWriteCallback(), null);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (LOG.isTraceEnabled()) &#123;</span><br><span class=\"line\">        LOG.trace(&quot;Adding &#123;&#125;@&#123;&#125;&quot;, entryId, ledgerId);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    getJournal(ledgerId).logAddEntry(entry, ackBeforeSync, cb, ctx);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"org-apache-bookkeeper-bookie-SortedLedgerStorage-addEntry\"><a href=\"#org-apache-bookkeeper-bookie-SortedLedgerStorage-addEntry\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.SortedLedgerStorage#addEntry\"></a>org.apache.bookkeeper.bookie.SortedLedgerStorage#addEntry</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">public long addEntry(ByteBuf entry) throws IOException &#123;</span><br><span class=\"line\">    long ledgerId = entry.getLong(entry.readerIndex() + 0);</span><br><span class=\"line\">    long entryId = entry.getLong(entry.readerIndex() + 8);</span><br><span class=\"line\">    long lac = entry.getLong(entry.readerIndex() + 16);</span><br><span class=\"line\"></span><br><span class=\"line\">    memTable.addEntry(ledgerId, entryId, entry.nioBuffer(), this);</span><br><span class=\"line\">    interleavedLedgerStorage.ledgerCache.updateLastAddConfirmed(ledgerId, lac);</span><br><span class=\"line\">    return entryId;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"org-apache-bookkeeper-bookie-EntryMemTable-addEntry\"><a href=\"#org-apache-bookkeeper-bookie-EntryMemTable-addEntry\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.EntryMemTable#addEntry\"></a>org.apache.bookkeeper.bookie.EntryMemTable#addEntry</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public long addEntry(long ledgerId, long entryId, final ByteBuffer entry, final CacheCallback cb)</span><br><span class=\"line\">        throws IOException &#123;</span><br><span class=\"line\">    long size = 0;</span><br><span class=\"line\">    long startTimeNanos = MathUtils.nowInNano();</span><br><span class=\"line\">    boolean success = false;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        if (isSizeLimitReached() || (!previousFlushSucceeded.get())) &#123;</span><br><span class=\"line\">            Checkpoint cp = snapshot();</span><br><span class=\"line\">            if ((null != cp) || (!previousFlushSucceeded.get())) &#123;</span><br><span class=\"line\">                cb.onSizeLimitReached(cp);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        final int len = entry.remaining();</span><br><span class=\"line\">        if (!skipListSemaphore.tryAcquire(len)) &#123;</span><br><span class=\"line\">            memTableStats.getThrottlingCounter().inc();</span><br><span class=\"line\">            final long throttlingStartTimeNanos = MathUtils.nowInNano();</span><br><span class=\"line\">            skipListSemaphore.acquireUninterruptibly(len);</span><br><span class=\"line\">            memTableStats.getThrottlingStats()</span><br><span class=\"line\">                .registerSuccessfulEvent(MathUtils.elapsedNanos(throttlingStartTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        this.lock.readLock().lock();</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            EntryKeyValue toAdd = cloneWithAllocator(ledgerId, entryId, entry);</span><br><span class=\"line\">            size = internalAdd(toAdd);</span><br><span class=\"line\">        &#125; finally &#123;</span><br><span class=\"line\">            this.lock.readLock().unlock();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        success = true;</span><br><span class=\"line\">        return size;</span><br><span class=\"line\">    &#125; finally &#123;</span><br><span class=\"line\">        if (success) &#123;</span><br><span class=\"line\">            memTableStats.getPutEntryStats()</span><br><span class=\"line\">                .registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            memTableStats.getPutEntryStats()</span><br><span class=\"line\">                .registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"org-apache-bookkeeper-bookie-EntryMemTable-snapshot-org-apache-bookkeeper-bookie-CheckpointSource-Checkpoint\"><a href=\"#org-apache-bookkeeper-bookie-EntryMemTable-snapshot-org-apache-bookkeeper-bookie-CheckpointSource-Checkpoint\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.EntryMemTable#snapshot(org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint)\"></a>org.apache.bookkeeper.bookie.EntryMemTable#snapshot(org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint)</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Snapshot current EntryMemTable. if given &lt;i&gt;oldCp&lt;/i&gt; is older than current checkpoint,</span><br><span class=\"line\"> * we don&apos;t do any snapshot. If snapshot happened, we return the checkpoint of the snapshot.</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @param oldCp</span><br><span class=\"line\"> *          checkpoint</span><br><span class=\"line\"> * @return checkpoint of the snapshot, null means no snapshot</span><br><span class=\"line\"> * @throws IOException</span><br><span class=\"line\"> */</span><br><span class=\"line\">Checkpoint snapshot(Checkpoint oldCp) throws IOException &#123;</span><br><span class=\"line\">    Checkpoint cp = null;</span><br><span class=\"line\">    // No-op if snapshot currently has entries</span><br><span class=\"line\">    if (this.snapshot.isEmpty() &amp;&amp; this.kvmap.compareTo(oldCp) &lt; 0) &#123;</span><br><span class=\"line\">        final long startTimeNanos = MathUtils.nowInNano();</span><br><span class=\"line\">        this.lock.writeLock().lock();</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            if (this.snapshot.isEmpty() &amp;&amp; !this.kvmap.isEmpty()</span><br><span class=\"line\">                    &amp;&amp; this.kvmap.compareTo(oldCp) &lt; 0) &#123;</span><br><span class=\"line\">                this.snapshot = this.kvmap;</span><br><span class=\"line\">                this.kvmap = newSkipList();</span><br><span class=\"line\">                // get the checkpoint of the memtable.</span><br><span class=\"line\">                cp = this.kvmap.cp;</span><br><span class=\"line\">                // Reset heap to not include any keys</span><br><span class=\"line\">                this.size.set(0);</span><br><span class=\"line\">                // Reset allocator so we get a fresh buffer for the new EntryMemTable</span><br><span class=\"line\">                this.allocator = new SkipListArena(conf);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; finally &#123;</span><br><span class=\"line\">            this.lock.writeLock().unlock();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        if (null != cp) &#123;</span><br><span class=\"line\">            memTableStats.getSnapshotStats()</span><br><span class=\"line\">                .registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            memTableStats.getSnapshotStats()</span><br><span class=\"line\">                .registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return cp;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"org-apache-bookkeeper-bookie-SortedLedgerStorage-onSizeLimitReached\"><a href=\"#org-apache-bookkeeper-bookie-SortedLedgerStorage-onSizeLimitReached\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.SortedLedgerStorage#onSizeLimitReached\"></a>org.apache.bookkeeper.bookie.SortedLedgerStorage#onSizeLimitReached</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// CacheCallback functions.</span><br><span class=\"line\">@Override</span><br><span class=\"line\">public void onSizeLimitReached(final Checkpoint cp) throws IOException &#123;</span><br><span class=\"line\">    LOG.info(&quot;Reached size &#123;&#125;&quot;, cp);</span><br><span class=\"line\">    // when size limit reached, we get the previous checkpoint from snapshot mem-table.</span><br><span class=\"line\">    // at this point, we are safer to schedule a checkpoint, since the entries added before</span><br><span class=\"line\">    // this checkpoint already written to entry logger.</span><br><span class=\"line\">    // but it would be better not to let mem-table flush to different entry log files,</span><br><span class=\"line\">    // so we roll entry log files in SortedLedgerStorage itself.</span><br><span class=\"line\">    // After that, we could make the process writing data to entry logger file not bound with checkpoint.</span><br><span class=\"line\">    // otherwise, it hurts add performance.</span><br><span class=\"line\">    //</span><br><span class=\"line\">    // The only exception for the size limitation is if a file grows to be more than hard limit 2GB,</span><br><span class=\"line\">    // we have to force rolling log, which it might cause slight performance effects</span><br><span class=\"line\">    scheduler.execute(new Runnable() &#123;</span><br><span class=\"line\">        @Override</span><br><span class=\"line\">        public void run() &#123;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                LOG.info(&quot;Started flushing mem table.&quot;);</span><br><span class=\"line\">                interleavedLedgerStorage.getEntryLogger().prepareEntryMemTableFlush();</span><br><span class=\"line\">                memTable.flush(SortedLedgerStorage.this);</span><br><span class=\"line\">                if (interleavedLedgerStorage.getEntryLogger().commitEntryMemTableFlush()) &#123;</span><br><span class=\"line\">                    interleavedLedgerStorage.checkpointer.startCheckpoint(cp);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; catch (Exception e) &#123;</span><br><span class=\"line\">                stateManager.transitionToReadOnlyMode();</span><br><span class=\"line\">                LOG.error(&quot;Exception thrown while flushing skip list cache.&quot;, e);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"org-apache-bookkeeper-bookie-EntryMemTable-flush-org-apache-bookkeeper-bookie-SkipListFlusher\"><a href=\"#org-apache-bookkeeper-bookie-EntryMemTable-flush-org-apache-bookkeeper-bookie-SkipListFlusher\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.EntryMemTable#flush(org.apache.bookkeeper.bookie.SkipListFlusher)\"></a>org.apache.bookkeeper.bookie.EntryMemTable#flush(org.apache.bookkeeper.bookie.SkipListFlusher)</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Flush snapshot and clear it.</span><br><span class=\"line\"> */</span><br><span class=\"line\">long flush(final SkipListFlusher flusher) throws IOException &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        long flushSize = flushSnapshot(flusher, Checkpoint.MAX);</span><br><span class=\"line\">        previousFlushSucceeded.set(true);</span><br><span class=\"line\">        return flushSize;</span><br><span class=\"line\">    &#125; catch (IOException ioe) &#123;</span><br><span class=\"line\">        previousFlushSucceeded.set(false);</span><br><span class=\"line\">        throw ioe;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>##</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"org-apache-bookkeeper-bookie-Bookie-addEntryInternal\"><a href=\"#org-apache-bookkeeper-bookie-Bookie-addEntryInternal\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.Bookie#addEntryInternal\"></a>org.apache.bookkeeper.bookie.Bookie#addEntryInternal</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Add an entry to a ledger as specified by handle.</span><br><span class=\"line\"> */</span><br><span class=\"line\">private void addEntryInternal(LedgerDescriptor handle, ByteBuf entry,</span><br><span class=\"line\">                              boolean ackBeforeSync, WriteCallback cb, Object ctx, byte[] masterKey)</span><br><span class=\"line\">        throws IOException, BookieException, InterruptedException &#123;</span><br><span class=\"line\">    long ledgerId = handle.getLedgerId();</span><br><span class=\"line\">    long entryId = handle.addEntry(entry);</span><br><span class=\"line\"></span><br><span class=\"line\">    bookieStats.getWriteBytes().add(entry.readableBytes());</span><br><span class=\"line\"></span><br><span class=\"line\">    // journal `addEntry` should happen after the entry is added to ledger storage.</span><br><span class=\"line\">    // otherwise the journal entry can potentially be rolled before the ledger is created in ledger storage.</span><br><span class=\"line\">    if (masterKeyCache.get(ledgerId) == null) &#123;</span><br><span class=\"line\">        // Force the load into masterKey cache</span><br><span class=\"line\">        byte[] oldValue = masterKeyCache.putIfAbsent(ledgerId, masterKey);</span><br><span class=\"line\">        if (oldValue == null) &#123;</span><br><span class=\"line\">            // new handle, we should add the key to journal ensure we can rebuild</span><br><span class=\"line\">            ByteBuffer bb = ByteBuffer.allocate(8 + 8 + 4 + masterKey.length);</span><br><span class=\"line\">            bb.putLong(ledgerId);</span><br><span class=\"line\">            bb.putLong(METAENTRY_ID_LEDGER_KEY);</span><br><span class=\"line\">            bb.putInt(masterKey.length);</span><br><span class=\"line\">            bb.put(masterKey);</span><br><span class=\"line\">            bb.flip();</span><br><span class=\"line\"></span><br><span class=\"line\">            getJournal(ledgerId).logAddEntry(bb, false /* ackBeforeSync */, new NopWriteCallback(), null);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (LOG.isTraceEnabled()) &#123;</span><br><span class=\"line\">        LOG.trace(&quot;Adding &#123;&#125;@&#123;&#125;&quot;, entryId, ledgerId);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    getJournal(ledgerId).logAddEntry(entry, ackBeforeSync, cb, ctx);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"org-apache-bookkeeper-bookie-SortedLedgerStorage-addEntry\"><a href=\"#org-apache-bookkeeper-bookie-SortedLedgerStorage-addEntry\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.SortedLedgerStorage#addEntry\"></a>org.apache.bookkeeper.bookie.SortedLedgerStorage#addEntry</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">public long addEntry(ByteBuf entry) throws IOException &#123;</span><br><span class=\"line\">    long ledgerId = entry.getLong(entry.readerIndex() + 0);</span><br><span class=\"line\">    long entryId = entry.getLong(entry.readerIndex() + 8);</span><br><span class=\"line\">    long lac = entry.getLong(entry.readerIndex() + 16);</span><br><span class=\"line\"></span><br><span class=\"line\">    memTable.addEntry(ledgerId, entryId, entry.nioBuffer(), this);</span><br><span class=\"line\">    interleavedLedgerStorage.ledgerCache.updateLastAddConfirmed(ledgerId, lac);</span><br><span class=\"line\">    return entryId;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"org-apache-bookkeeper-bookie-EntryMemTable-addEntry\"><a href=\"#org-apache-bookkeeper-bookie-EntryMemTable-addEntry\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.EntryMemTable#addEntry\"></a>org.apache.bookkeeper.bookie.EntryMemTable#addEntry</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public long addEntry(long ledgerId, long entryId, final ByteBuffer entry, final CacheCallback cb)</span><br><span class=\"line\">        throws IOException &#123;</span><br><span class=\"line\">    long size = 0;</span><br><span class=\"line\">    long startTimeNanos = MathUtils.nowInNano();</span><br><span class=\"line\">    boolean success = false;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        if (isSizeLimitReached() || (!previousFlushSucceeded.get())) &#123;</span><br><span class=\"line\">            Checkpoint cp = snapshot();</span><br><span class=\"line\">            if ((null != cp) || (!previousFlushSucceeded.get())) &#123;</span><br><span class=\"line\">                cb.onSizeLimitReached(cp);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        final int len = entry.remaining();</span><br><span class=\"line\">        if (!skipListSemaphore.tryAcquire(len)) &#123;</span><br><span class=\"line\">            memTableStats.getThrottlingCounter().inc();</span><br><span class=\"line\">            final long throttlingStartTimeNanos = MathUtils.nowInNano();</span><br><span class=\"line\">            skipListSemaphore.acquireUninterruptibly(len);</span><br><span class=\"line\">            memTableStats.getThrottlingStats()</span><br><span class=\"line\">                .registerSuccessfulEvent(MathUtils.elapsedNanos(throttlingStartTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        this.lock.readLock().lock();</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            EntryKeyValue toAdd = cloneWithAllocator(ledgerId, entryId, entry);</span><br><span class=\"line\">            size = internalAdd(toAdd);</span><br><span class=\"line\">        &#125; finally &#123;</span><br><span class=\"line\">            this.lock.readLock().unlock();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        success = true;</span><br><span class=\"line\">        return size;</span><br><span class=\"line\">    &#125; finally &#123;</span><br><span class=\"line\">        if (success) &#123;</span><br><span class=\"line\">            memTableStats.getPutEntryStats()</span><br><span class=\"line\">                .registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            memTableStats.getPutEntryStats()</span><br><span class=\"line\">                .registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"org-apache-bookkeeper-bookie-EntryMemTable-snapshot-org-apache-bookkeeper-bookie-CheckpointSource-Checkpoint\"><a href=\"#org-apache-bookkeeper-bookie-EntryMemTable-snapshot-org-apache-bookkeeper-bookie-CheckpointSource-Checkpoint\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.EntryMemTable#snapshot(org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint)\"></a>org.apache.bookkeeper.bookie.EntryMemTable#snapshot(org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint)</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Snapshot current EntryMemTable. if given &lt;i&gt;oldCp&lt;/i&gt; is older than current checkpoint,</span><br><span class=\"line\"> * we don&apos;t do any snapshot. If snapshot happened, we return the checkpoint of the snapshot.</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @param oldCp</span><br><span class=\"line\"> *          checkpoint</span><br><span class=\"line\"> * @return checkpoint of the snapshot, null means no snapshot</span><br><span class=\"line\"> * @throws IOException</span><br><span class=\"line\"> */</span><br><span class=\"line\">Checkpoint snapshot(Checkpoint oldCp) throws IOException &#123;</span><br><span class=\"line\">    Checkpoint cp = null;</span><br><span class=\"line\">    // No-op if snapshot currently has entries</span><br><span class=\"line\">    if (this.snapshot.isEmpty() &amp;&amp; this.kvmap.compareTo(oldCp) &lt; 0) &#123;</span><br><span class=\"line\">        final long startTimeNanos = MathUtils.nowInNano();</span><br><span class=\"line\">        this.lock.writeLock().lock();</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            if (this.snapshot.isEmpty() &amp;&amp; !this.kvmap.isEmpty()</span><br><span class=\"line\">                    &amp;&amp; this.kvmap.compareTo(oldCp) &lt; 0) &#123;</span><br><span class=\"line\">                this.snapshot = this.kvmap;</span><br><span class=\"line\">                this.kvmap = newSkipList();</span><br><span class=\"line\">                // get the checkpoint of the memtable.</span><br><span class=\"line\">                cp = this.kvmap.cp;</span><br><span class=\"line\">                // Reset heap to not include any keys</span><br><span class=\"line\">                this.size.set(0);</span><br><span class=\"line\">                // Reset allocator so we get a fresh buffer for the new EntryMemTable</span><br><span class=\"line\">                this.allocator = new SkipListArena(conf);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; finally &#123;</span><br><span class=\"line\">            this.lock.writeLock().unlock();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        if (null != cp) &#123;</span><br><span class=\"line\">            memTableStats.getSnapshotStats()</span><br><span class=\"line\">                .registerSuccessfulEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            memTableStats.getSnapshotStats()</span><br><span class=\"line\">                .registerFailedEvent(MathUtils.elapsedNanos(startTimeNanos), TimeUnit.NANOSECONDS);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return cp;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"org-apache-bookkeeper-bookie-SortedLedgerStorage-onSizeLimitReached\"><a href=\"#org-apache-bookkeeper-bookie-SortedLedgerStorage-onSizeLimitReached\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.SortedLedgerStorage#onSizeLimitReached\"></a>org.apache.bookkeeper.bookie.SortedLedgerStorage#onSizeLimitReached</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// CacheCallback functions.</span><br><span class=\"line\">@Override</span><br><span class=\"line\">public void onSizeLimitReached(final Checkpoint cp) throws IOException &#123;</span><br><span class=\"line\">    LOG.info(&quot;Reached size &#123;&#125;&quot;, cp);</span><br><span class=\"line\">    // when size limit reached, we get the previous checkpoint from snapshot mem-table.</span><br><span class=\"line\">    // at this point, we are safer to schedule a checkpoint, since the entries added before</span><br><span class=\"line\">    // this checkpoint already written to entry logger.</span><br><span class=\"line\">    // but it would be better not to let mem-table flush to different entry log files,</span><br><span class=\"line\">    // so we roll entry log files in SortedLedgerStorage itself.</span><br><span class=\"line\">    // After that, we could make the process writing data to entry logger file not bound with checkpoint.</span><br><span class=\"line\">    // otherwise, it hurts add performance.</span><br><span class=\"line\">    //</span><br><span class=\"line\">    // The only exception for the size limitation is if a file grows to be more than hard limit 2GB,</span><br><span class=\"line\">    // we have to force rolling log, which it might cause slight performance effects</span><br><span class=\"line\">    scheduler.execute(new Runnable() &#123;</span><br><span class=\"line\">        @Override</span><br><span class=\"line\">        public void run() &#123;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                LOG.info(&quot;Started flushing mem table.&quot;);</span><br><span class=\"line\">                interleavedLedgerStorage.getEntryLogger().prepareEntryMemTableFlush();</span><br><span class=\"line\">                memTable.flush(SortedLedgerStorage.this);</span><br><span class=\"line\">                if (interleavedLedgerStorage.getEntryLogger().commitEntryMemTableFlush()) &#123;</span><br><span class=\"line\">                    interleavedLedgerStorage.checkpointer.startCheckpoint(cp);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; catch (Exception e) &#123;</span><br><span class=\"line\">                stateManager.transitionToReadOnlyMode();</span><br><span class=\"line\">                LOG.error(&quot;Exception thrown while flushing skip list cache.&quot;, e);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"org-apache-bookkeeper-bookie-EntryMemTable-flush-org-apache-bookkeeper-bookie-SkipListFlusher\"><a href=\"#org-apache-bookkeeper-bookie-EntryMemTable-flush-org-apache-bookkeeper-bookie-SkipListFlusher\" class=\"headerlink\" title=\"org.apache.bookkeeper.bookie.EntryMemTable#flush(org.apache.bookkeeper.bookie.SkipListFlusher)\"></a>org.apache.bookkeeper.bookie.EntryMemTable#flush(org.apache.bookkeeper.bookie.SkipListFlusher)</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * Flush snapshot and clear it.</span><br><span class=\"line\"> */</span><br><span class=\"line\">long flush(final SkipListFlusher flusher) throws IOException &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        long flushSize = flushSnapshot(flusher, Checkpoint.MAX);</span><br><span class=\"line\">        previousFlushSucceeded.set(true);</span><br><span class=\"line\">        return flushSize;</span><br><span class=\"line\">    &#125; catch (IOException ioe) &#123;</span><br><span class=\"line\">        previousFlushSucceeded.set(false);</span><br><span class=\"line\">        throw ioe;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>##</p>\n"},{"title":"Pulsar-BrokerCache","date":"2019-06-13T10:59:09.000Z","_content":"\n\n\n### 写缓存\n```\ninsert(EntryImpl):87, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java\nsafeRun():156, OpAddEntry (org.apache.bookkeeper.mledger.impl), OpAddEntry.java\nrun():36, SafeRunnable (org.apache.bookkeeper.common.util), SafeRunnable.java\nrunWorker(ThreadPoolExecutor$Worker):1149, ThreadPoolExecutor (java.util.concurrent), ThreadPoolExecutor.java\nrun():624, ThreadPoolExecutor$Worker (java.util.concurrent), ThreadPoolExecutor.java\nrun():30, FastThreadLocalRunnable (io.netty.util.concurrent), FastThreadLocalRunnable.java\nrun():748, Thread (java.lang), Thread.java\n```\n\n### 读缓存\n```\ngetRange(Comparable, Comparable):109, RangeCache (org.apache.bookkeeper.mledger.util), RangeCache.java\nasyncReadEntry0(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):261, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java\nasyncReadEntry(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):238, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java\nasyncReadEntry(ReadHandle, long, long, boolean, OpReadEntry, Object):1553, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java\ninternalReadFromLedger(ReadHandle, OpReadEntry):1527, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java\nasyncReadEntries(OpReadEntry):1380, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java\nasyncReadEntries(int, AsyncCallbacks$ReadEntriesCallback, Object):476, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java\nasyncReadEntriesOrWait(int, AsyncCallbacks$ReadEntriesCallback, Object):594, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java\nreadMoreEntries():326, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java\nconsumerFlow(Consumer, int):240, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java\nconsumerFlow(Consumer, int):215, PersistentSubscription (org.apache.pulsar.broker.service.persistent), PersistentSubscription.java\nflowPermits(int):376, Consumer (org.apache.pulsar.broker.service), Consumer.java\nhandleFlow(PulsarApi$CommandFlow):1090, ServerCnx (org.apache.pulsar.broker.service), ServerCnx.java\nchannelRead(ChannelHandlerContext, Object):160, PulsarDecoder (org.apache.pulsar.common.api), PulsarDecoder.java\ninvokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(ChannelHandlerContext, CodecOutputList, int):323, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java\nchannelRead(ChannelHandlerContext, Object):297, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java\ninvokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nchannelRead(ChannelHandlerContext, Object):1434, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java\ninvokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(Object):965, DefaultChannelPipeline (io.netty.channel), DefaultChannelPipeline.java\nread():163, AbstractNioByteChannel$NioByteUnsafe (io.netty.channel.nio), AbstractNioByteChannel.java\nprocessSelectedKey(SelectionKey, AbstractNioChannel):656, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nprocessSelectedKeysOptimized():591, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nprocessSelectedKeys():508, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nrun():470, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nrun():909, SingleThreadEventExecutor$5 (io.netty.util.concurrent), SingleThreadEventExecutor.java\nrun():30, FastThreadLocalRunnable (io.netty.util.concurrent), FastThreadLocalRunnable.java\nrun():748, Thread (java.lang), Thread.java\n```\n\n### org.apache.bookkeeper.mledger.impl.EntryCacheImpl\n```\npublic boolean insert(EntryImpl entry) {\n    if (!manager.hasSpaceInCache()) {\n        if (log.isDebugEnabled()) {\n            log.debug(\"[{}] Skipping cache while doing eviction: {} - size: {}\", ml.getName(), entry.getPosition(),\n                    entry.getLength());\n        }\n        return false;\n    }\n\n    if (log.isDebugEnabled()) {\n        log.debug(\"[{}] Adding entry to cache: {} - size: {}\", ml.getName(), entry.getPosition(),\n                entry.getLength());\n    }\n\n    ByteBuf cachedData = null;\n    if (copyEntries) {\n        cachedData = copyEntry(entry);\n        if (cachedData == null) {\n            return false;\n        }\n    } else {\n        // Use retain here to have the same counter increase as in the copy entry scenario\n        cachedData = entry.getDataBuffer().retain();\n    }\n\n    PositionImpl position = entry.getPosition();\n    EntryImpl cacheEntry = EntryImpl.create(position, cachedData);\n    cachedData.release();\n    if (entries.put(position, cacheEntry)) {\n        manager.entryAdded(entry.getLength());\n        return true;\n    } else {\n        // entry was not inserted into cache, we need to discard it\n        cacheEntry.release();\n        return false;\n    }\n}\n```\n","source":"_posts/Pulsar-BrokerCache.md","raw":"---\ntitle: Pulsar-BrokerCache\ndate: 2019-06-13 18:59:09\ntags:\n---\n\n\n\n### 写缓存\n```\ninsert(EntryImpl):87, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java\nsafeRun():156, OpAddEntry (org.apache.bookkeeper.mledger.impl), OpAddEntry.java\nrun():36, SafeRunnable (org.apache.bookkeeper.common.util), SafeRunnable.java\nrunWorker(ThreadPoolExecutor$Worker):1149, ThreadPoolExecutor (java.util.concurrent), ThreadPoolExecutor.java\nrun():624, ThreadPoolExecutor$Worker (java.util.concurrent), ThreadPoolExecutor.java\nrun():30, FastThreadLocalRunnable (io.netty.util.concurrent), FastThreadLocalRunnable.java\nrun():748, Thread (java.lang), Thread.java\n```\n\n### 读缓存\n```\ngetRange(Comparable, Comparable):109, RangeCache (org.apache.bookkeeper.mledger.util), RangeCache.java\nasyncReadEntry0(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):261, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java\nasyncReadEntry(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):238, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java\nasyncReadEntry(ReadHandle, long, long, boolean, OpReadEntry, Object):1553, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java\ninternalReadFromLedger(ReadHandle, OpReadEntry):1527, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java\nasyncReadEntries(OpReadEntry):1380, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java\nasyncReadEntries(int, AsyncCallbacks$ReadEntriesCallback, Object):476, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java\nasyncReadEntriesOrWait(int, AsyncCallbacks$ReadEntriesCallback, Object):594, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java\nreadMoreEntries():326, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java\nconsumerFlow(Consumer, int):240, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java\nconsumerFlow(Consumer, int):215, PersistentSubscription (org.apache.pulsar.broker.service.persistent), PersistentSubscription.java\nflowPermits(int):376, Consumer (org.apache.pulsar.broker.service), Consumer.java\nhandleFlow(PulsarApi$CommandFlow):1090, ServerCnx (org.apache.pulsar.broker.service), ServerCnx.java\nchannelRead(ChannelHandlerContext, Object):160, PulsarDecoder (org.apache.pulsar.common.api), PulsarDecoder.java\ninvokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(ChannelHandlerContext, CodecOutputList, int):323, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java\nchannelRead(ChannelHandlerContext, Object):297, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java\ninvokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nchannelRead(ChannelHandlerContext, Object):1434, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java\ninvokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(Object):965, DefaultChannelPipeline (io.netty.channel), DefaultChannelPipeline.java\nread():163, AbstractNioByteChannel$NioByteUnsafe (io.netty.channel.nio), AbstractNioByteChannel.java\nprocessSelectedKey(SelectionKey, AbstractNioChannel):656, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nprocessSelectedKeysOptimized():591, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nprocessSelectedKeys():508, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nrun():470, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nrun():909, SingleThreadEventExecutor$5 (io.netty.util.concurrent), SingleThreadEventExecutor.java\nrun():30, FastThreadLocalRunnable (io.netty.util.concurrent), FastThreadLocalRunnable.java\nrun():748, Thread (java.lang), Thread.java\n```\n\n### org.apache.bookkeeper.mledger.impl.EntryCacheImpl\n```\npublic boolean insert(EntryImpl entry) {\n    if (!manager.hasSpaceInCache()) {\n        if (log.isDebugEnabled()) {\n            log.debug(\"[{}] Skipping cache while doing eviction: {} - size: {}\", ml.getName(), entry.getPosition(),\n                    entry.getLength());\n        }\n        return false;\n    }\n\n    if (log.isDebugEnabled()) {\n        log.debug(\"[{}] Adding entry to cache: {} - size: {}\", ml.getName(), entry.getPosition(),\n                entry.getLength());\n    }\n\n    ByteBuf cachedData = null;\n    if (copyEntries) {\n        cachedData = copyEntry(entry);\n        if (cachedData == null) {\n            return false;\n        }\n    } else {\n        // Use retain here to have the same counter increase as in the copy entry scenario\n        cachedData = entry.getDataBuffer().retain();\n    }\n\n    PositionImpl position = entry.getPosition();\n    EntryImpl cacheEntry = EntryImpl.create(position, cachedData);\n    cachedData.release();\n    if (entries.put(position, cacheEntry)) {\n        manager.entryAdded(entry.getLength());\n        return true;\n    } else {\n        // entry was not inserted into cache, we need to discard it\n        cacheEntry.release();\n        return false;\n    }\n}\n```\n","slug":"Pulsar-BrokerCache","published":1,"updated":"2019-09-28T08:51:00.913Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84j004mv1npwi0tffpb","content":"<h3 id=\"写缓存\"><a href=\"#写缓存\" class=\"headerlink\" title=\"写缓存\"></a>写缓存</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">insert(EntryImpl):87, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java</span><br><span class=\"line\">safeRun():156, OpAddEntry (org.apache.bookkeeper.mledger.impl), OpAddEntry.java</span><br><span class=\"line\">run():36, SafeRunnable (org.apache.bookkeeper.common.util), SafeRunnable.java</span><br><span class=\"line\">runWorker(ThreadPoolExecutor$Worker):1149, ThreadPoolExecutor (java.util.concurrent), ThreadPoolExecutor.java</span><br><span class=\"line\">run():624, ThreadPoolExecutor$Worker (java.util.concurrent), ThreadPoolExecutor.java</span><br><span class=\"line\">run():30, FastThreadLocalRunnable (io.netty.util.concurrent), FastThreadLocalRunnable.java</span><br><span class=\"line\">run():748, Thread (java.lang), Thread.java</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"读缓存\"><a href=\"#读缓存\" class=\"headerlink\" title=\"读缓存\"></a>读缓存</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">getRange(Comparable, Comparable):109, RangeCache (org.apache.bookkeeper.mledger.util), RangeCache.java</span><br><span class=\"line\">asyncReadEntry0(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):261, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java</span><br><span class=\"line\">asyncReadEntry(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):238, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java</span><br><span class=\"line\">asyncReadEntry(ReadHandle, long, long, boolean, OpReadEntry, Object):1553, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java</span><br><span class=\"line\">internalReadFromLedger(ReadHandle, OpReadEntry):1527, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java</span><br><span class=\"line\">asyncReadEntries(OpReadEntry):1380, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java</span><br><span class=\"line\">asyncReadEntries(int, AsyncCallbacks$ReadEntriesCallback, Object):476, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java</span><br><span class=\"line\">asyncReadEntriesOrWait(int, AsyncCallbacks$ReadEntriesCallback, Object):594, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java</span><br><span class=\"line\">readMoreEntries():326, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java</span><br><span class=\"line\">consumerFlow(Consumer, int):240, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java</span><br><span class=\"line\">consumerFlow(Consumer, int):215, PersistentSubscription (org.apache.pulsar.broker.service.persistent), PersistentSubscription.java</span><br><span class=\"line\">flowPermits(int):376, Consumer (org.apache.pulsar.broker.service), Consumer.java</span><br><span class=\"line\">handleFlow(PulsarApi$CommandFlow):1090, ServerCnx (org.apache.pulsar.broker.service), ServerCnx.java</span><br><span class=\"line\">channelRead(ChannelHandlerContext, Object):160, PulsarDecoder (org.apache.pulsar.common.api), PulsarDecoder.java</span><br><span class=\"line\">invokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">invokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">fireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">fireChannelRead(ChannelHandlerContext, CodecOutputList, int):323, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java</span><br><span class=\"line\">channelRead(ChannelHandlerContext, Object):297, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java</span><br><span class=\"line\">invokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">invokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">fireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">channelRead(ChannelHandlerContext, Object):1434, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java</span><br><span class=\"line\">invokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">invokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">fireChannelRead(Object):965, DefaultChannelPipeline (io.netty.channel), DefaultChannelPipeline.java</span><br><span class=\"line\">read():163, AbstractNioByteChannel$NioByteUnsafe (io.netty.channel.nio), AbstractNioByteChannel.java</span><br><span class=\"line\">processSelectedKey(SelectionKey, AbstractNioChannel):656, NioEventLoop (io.netty.channel.nio), NioEventLoop.java</span><br><span class=\"line\">processSelectedKeysOptimized():591, NioEventLoop (io.netty.channel.nio), NioEventLoop.java</span><br><span class=\"line\">processSelectedKeys():508, NioEventLoop (io.netty.channel.nio), NioEventLoop.java</span><br><span class=\"line\">run():470, NioEventLoop (io.netty.channel.nio), NioEventLoop.java</span><br><span class=\"line\">run():909, SingleThreadEventExecutor$5 (io.netty.util.concurrent), SingleThreadEventExecutor.java</span><br><span class=\"line\">run():30, FastThreadLocalRunnable (io.netty.util.concurrent), FastThreadLocalRunnable.java</span><br><span class=\"line\">run():748, Thread (java.lang), Thread.java</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"org-apache-bookkeeper-mledger-impl-EntryCacheImpl\"><a href=\"#org-apache-bookkeeper-mledger-impl-EntryCacheImpl\" class=\"headerlink\" title=\"org.apache.bookkeeper.mledger.impl.EntryCacheImpl\"></a>org.apache.bookkeeper.mledger.impl.EntryCacheImpl</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public boolean insert(EntryImpl entry) &#123;</span><br><span class=\"line\">    if (!manager.hasSpaceInCache()) &#123;</span><br><span class=\"line\">        if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">            log.debug(&quot;[&#123;&#125;] Skipping cache while doing eviction: &#123;&#125; - size: &#123;&#125;&quot;, ml.getName(), entry.getPosition(),</span><br><span class=\"line\">                    entry.getLength());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        return false;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(&quot;[&#123;&#125;] Adding entry to cache: &#123;&#125; - size: &#123;&#125;&quot;, ml.getName(), entry.getPosition(),</span><br><span class=\"line\">                entry.getLength());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    ByteBuf cachedData = null;</span><br><span class=\"line\">    if (copyEntries) &#123;</span><br><span class=\"line\">        cachedData = copyEntry(entry);</span><br><span class=\"line\">        if (cachedData == null) &#123;</span><br><span class=\"line\">            return false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        // Use retain here to have the same counter increase as in the copy entry scenario</span><br><span class=\"line\">        cachedData = entry.getDataBuffer().retain();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    PositionImpl position = entry.getPosition();</span><br><span class=\"line\">    EntryImpl cacheEntry = EntryImpl.create(position, cachedData);</span><br><span class=\"line\">    cachedData.release();</span><br><span class=\"line\">    if (entries.put(position, cacheEntry)) &#123;</span><br><span class=\"line\">        manager.entryAdded(entry.getLength());</span><br><span class=\"line\">        return true;</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        // entry was not inserted into cache, we need to discard it</span><br><span class=\"line\">        cacheEntry.release();</span><br><span class=\"line\">        return false;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"写缓存\"><a href=\"#写缓存\" class=\"headerlink\" title=\"写缓存\"></a>写缓存</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">insert(EntryImpl):87, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java</span><br><span class=\"line\">safeRun():156, OpAddEntry (org.apache.bookkeeper.mledger.impl), OpAddEntry.java</span><br><span class=\"line\">run():36, SafeRunnable (org.apache.bookkeeper.common.util), SafeRunnable.java</span><br><span class=\"line\">runWorker(ThreadPoolExecutor$Worker):1149, ThreadPoolExecutor (java.util.concurrent), ThreadPoolExecutor.java</span><br><span class=\"line\">run():624, ThreadPoolExecutor$Worker (java.util.concurrent), ThreadPoolExecutor.java</span><br><span class=\"line\">run():30, FastThreadLocalRunnable (io.netty.util.concurrent), FastThreadLocalRunnable.java</span><br><span class=\"line\">run():748, Thread (java.lang), Thread.java</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"读缓存\"><a href=\"#读缓存\" class=\"headerlink\" title=\"读缓存\"></a>读缓存</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">getRange(Comparable, Comparable):109, RangeCache (org.apache.bookkeeper.mledger.util), RangeCache.java</span><br><span class=\"line\">asyncReadEntry0(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):261, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java</span><br><span class=\"line\">asyncReadEntry(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):238, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java</span><br><span class=\"line\">asyncReadEntry(ReadHandle, long, long, boolean, OpReadEntry, Object):1553, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java</span><br><span class=\"line\">internalReadFromLedger(ReadHandle, OpReadEntry):1527, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java</span><br><span class=\"line\">asyncReadEntries(OpReadEntry):1380, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java</span><br><span class=\"line\">asyncReadEntries(int, AsyncCallbacks$ReadEntriesCallback, Object):476, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java</span><br><span class=\"line\">asyncReadEntriesOrWait(int, AsyncCallbacks$ReadEntriesCallback, Object):594, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java</span><br><span class=\"line\">readMoreEntries():326, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java</span><br><span class=\"line\">consumerFlow(Consumer, int):240, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java</span><br><span class=\"line\">consumerFlow(Consumer, int):215, PersistentSubscription (org.apache.pulsar.broker.service.persistent), PersistentSubscription.java</span><br><span class=\"line\">flowPermits(int):376, Consumer (org.apache.pulsar.broker.service), Consumer.java</span><br><span class=\"line\">handleFlow(PulsarApi$CommandFlow):1090, ServerCnx (org.apache.pulsar.broker.service), ServerCnx.java</span><br><span class=\"line\">channelRead(ChannelHandlerContext, Object):160, PulsarDecoder (org.apache.pulsar.common.api), PulsarDecoder.java</span><br><span class=\"line\">invokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">invokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">fireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">fireChannelRead(ChannelHandlerContext, CodecOutputList, int):323, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java</span><br><span class=\"line\">channelRead(ChannelHandlerContext, Object):297, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java</span><br><span class=\"line\">invokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">invokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">fireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">channelRead(ChannelHandlerContext, Object):1434, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java</span><br><span class=\"line\">invokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">invokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java</span><br><span class=\"line\">fireChannelRead(Object):965, DefaultChannelPipeline (io.netty.channel), DefaultChannelPipeline.java</span><br><span class=\"line\">read():163, AbstractNioByteChannel$NioByteUnsafe (io.netty.channel.nio), AbstractNioByteChannel.java</span><br><span class=\"line\">processSelectedKey(SelectionKey, AbstractNioChannel):656, NioEventLoop (io.netty.channel.nio), NioEventLoop.java</span><br><span class=\"line\">processSelectedKeysOptimized():591, NioEventLoop (io.netty.channel.nio), NioEventLoop.java</span><br><span class=\"line\">processSelectedKeys():508, NioEventLoop (io.netty.channel.nio), NioEventLoop.java</span><br><span class=\"line\">run():470, NioEventLoop (io.netty.channel.nio), NioEventLoop.java</span><br><span class=\"line\">run():909, SingleThreadEventExecutor$5 (io.netty.util.concurrent), SingleThreadEventExecutor.java</span><br><span class=\"line\">run():30, FastThreadLocalRunnable (io.netty.util.concurrent), FastThreadLocalRunnable.java</span><br><span class=\"line\">run():748, Thread (java.lang), Thread.java</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"org-apache-bookkeeper-mledger-impl-EntryCacheImpl\"><a href=\"#org-apache-bookkeeper-mledger-impl-EntryCacheImpl\" class=\"headerlink\" title=\"org.apache.bookkeeper.mledger.impl.EntryCacheImpl\"></a>org.apache.bookkeeper.mledger.impl.EntryCacheImpl</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public boolean insert(EntryImpl entry) &#123;</span><br><span class=\"line\">    if (!manager.hasSpaceInCache()) &#123;</span><br><span class=\"line\">        if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">            log.debug(&quot;[&#123;&#125;] Skipping cache while doing eviction: &#123;&#125; - size: &#123;&#125;&quot;, ml.getName(), entry.getPosition(),</span><br><span class=\"line\">                    entry.getLength());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        return false;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(&quot;[&#123;&#125;] Adding entry to cache: &#123;&#125; - size: &#123;&#125;&quot;, ml.getName(), entry.getPosition(),</span><br><span class=\"line\">                entry.getLength());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    ByteBuf cachedData = null;</span><br><span class=\"line\">    if (copyEntries) &#123;</span><br><span class=\"line\">        cachedData = copyEntry(entry);</span><br><span class=\"line\">        if (cachedData == null) &#123;</span><br><span class=\"line\">            return false;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        // Use retain here to have the same counter increase as in the copy entry scenario</span><br><span class=\"line\">        cachedData = entry.getDataBuffer().retain();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    PositionImpl position = entry.getPosition();</span><br><span class=\"line\">    EntryImpl cacheEntry = EntryImpl.create(position, cachedData);</span><br><span class=\"line\">    cachedData.release();</span><br><span class=\"line\">    if (entries.put(position, cacheEntry)) &#123;</span><br><span class=\"line\">        manager.entryAdded(entry.getLength());</span><br><span class=\"line\">        return true;</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        // entry was not inserted into cache, we need to discard it</span><br><span class=\"line\">        cacheEntry.release();</span><br><span class=\"line\">        return false;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"Pulsar-FAQ","date":"2019-04-29T06:48:18.000Z","_content":"\n\n### 这个bundle是什么意思？\nOne can either change the system default, or override it when creating a new namespace:\n\n$ bin/pulsar-admin namespaces create my-tenant/my-namespace --clusters us-west --bundles 16\n\nCopy\nWith this command, we're creating a namespace with 16 initial bundles. Therefore the topics for this namespaces can immediately be spread across up to 16 brokers.\n\nIn general, if the expected traffic and number of topics is known in advance, it's a good idea to start with a reasonable number of bundles instead of waiting for the system to auto-correct the distribution.\n\nOn a same note, it is normally beneficial to start with more bundles than number of brokers, primarily because of the hashing nature of the distribution of topics into bundles. For example, for a namespace with 1000 topics, using something like 64 bundles will achieve a good distribution of traffic across 16 brokers.\n\n############# ThreadID:342 Time: 1559563265289 ################\njava.lang.Thread Thread.java 1559 getStackTrace\n-----------------------------------\norg.apache.pulsar.debug.DebugUtil DebugUtil.java 15 commonStacktrace\n-----------------------------------\norg.apache.pulsar.debug.DebugUtil DebugUtil.java 11 stacktrace\n-----------------------------------\norg.apache.pulsar.broker.lookup.TopicLookupBase TopicLookupBase.java 280 lookupTopicAsync\n-----------------------------------\norg.apache.pulsar.broker.service.ServerCnx ServerCnx.java 263 lambda$handleLookup$3\n-----------------------------------\njava.util.concurrent.CompletableFuture CompletableFuture.java 602 uniApply\n-----------------------------------\njava.util.concurrent.CompletableFuture CompletableFuture.java 614 uniApplyStage\n-----------------------------------\njava.util.concurrent.CompletableFuture CompletableFuture.java 1983 thenApply\n-----------------------------------\norg.apache.pulsar.broker.service.ServerCnx ServerCnx.java 261 handleLookup\n-----------------------------------\norg.apache.pulsar.common.api.PulsarDecoder PulsarDecoder.java 112 channelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 340 fireChannelRead\n-----------------------------------\nio.netty.handler.codec.ByteToMessageDecoder ByteToMessageDecoder.java 323 fireChannelRead\n-----------------------------------\nio.netty.handler.codec.ByteToMessageDecoder ByteToMessageDecoder.java 297 channelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 340 fireChannelRead\n-----------------------------------\nio.netty.channel.DefaultChannelPipeline$HeadContext DefaultChannelPipeline.java 1434 channelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead\n-----------------------------------\nio.netty.channel.DefaultChannelPipeline DefaultChannelPipeline.java 965 fireChannelRead\n-----------------------------------\nio.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe AbstractNioByteChannel.java 163 read\n-----------------------------------\nio.netty.channel.nio.NioEventLoop NioEventLoop.java 656 processSelectedKey\n-----------------------------------\nio.netty.channel.nio.NioEventLoop NioEventLoop.java 591 processSelectedKeysOptimized\n-----------------------------------\nio.netty.channel.nio.NioEventLoop NioEventLoop.java 508 processSelectedKeys\n-----------------------------------\nio.netty.channel.nio.NioEventLoop NioEventLoop.java 470 run\n-----------------------------------\nio.netty.util.concurrent.SingleThreadEventExecutor$5 SingleThreadEventExecutor.java 909 run\n-----------------------------------\nio.netty.util.concurrent.FastThreadLocalRunnable FastThreadLocalRunnable.java 30 run\n-----------------------------------\njava.lang.Thread Thread.java 748 run\n-----------------------------------\n#############################\n\n\n\n```\n/**\n     *\n     * Lookup broker-service address for a given namespace-bundle which contains given topic.\n     *\n     * a. Returns broker-address if namespace-bundle is already owned by any broker b. If current-broker receives\n     * lookup-request and if it's not a leader then current broker redirects request to leader by returning\n     * leader-service address. c. If current-broker is leader then it finds out least-loaded broker to own namespace\n     * bundle and redirects request by returning least-loaded broker. d. If current-broker receives request to own the\n     * namespace-bundle then it owns a bundle and returns success(connect) response to client.\n     *\n     * @param pulsarService\n     * @param topicName\n     * @param authoritative\n     * @param clientAppId\n     * @param requestId\n     * @return\n     */\n    public static CompletableFuture<ByteBuf> lookupTopicAsync(PulsarService pulsarService, TopicName topicName,\n        boolean authoritative, String clientAppId, AuthenticationDataSource authenticationData, long requestId) {\n\n    final CompletableFuture<ByteBuf> validationFuture = new CompletableFuture<>();\n    final CompletableFuture<ByteBuf> lookupfuture = new CompletableFuture<>();\n    final String cluster = topicName.getCluster();\n\n    // (1) validate cluster\n    getClusterDataIfDifferentCluster(pulsarService, cluster, clientAppId).thenAccept(differentClusterData -> {\n\n        if (differentClusterData != null) {\n            if (log.isDebugEnabled()) {\n                log.debug(\"[{}] Redirecting the lookup call to {}/{} cluster={}\", clientAppId,\n                        differentClusterData.getBrokerServiceUrl(), differentClusterData.getBrokerServiceUrlTls(),\n                        cluster);\n            }\n            validationFuture.complete(newLookupResponse(differentClusterData.getBrokerServiceUrl(),\n                    differentClusterData.getBrokerServiceUrlTls(), true, LookupType.Redirect, requestId, false));\n        } else {\n            // (2) authorize client\n            try {\n                checkAuthorization(pulsarService, topicName, clientAppId, authenticationData);\n            } catch (RestException authException) {\n                log.warn(\"Failed to authorized {} on cluster {}\", clientAppId, topicName.toString());\n                validationFuture.complete(newLookupErrorResponse(ServerError.AuthorizationError,\n                        authException.getMessage(), requestId));\n                return;\n            } catch (Exception e) {\n                log.warn(\"Unknown error while authorizing {} on cluster {}\", clientAppId, topicName.toString());\n                validationFuture.completeExceptionally(e);\n                return;\n            }\n            // (3) validate global namespace\n            checkLocalOrGetPeerReplicationCluster(pulsarService, topicName.getNamespaceObject())\n                    .thenAccept(peerClusterData -> {\n                        if (peerClusterData == null) {\n                            // (4) all validation passed: initiate lookup\n                            validationFuture.complete(null);\n                            return;\n                        }\n                        // if peer-cluster-data is present it means namespace is owned by that peer-cluster and\n                        // request should be redirect to the peer-cluster\n                        if (StringUtils.isBlank(peerClusterData.getBrokerServiceUrl())\n                                && StringUtils.isBlank(peerClusterData.getBrokerServiceUrl())) {\n                            validationFuture.complete(newLookupErrorResponse(ServerError.MetadataError,\n                                    \"Redirected cluster's brokerService url is not configured\", requestId));\n                            return;\n                        }\n                        validationFuture.complete(newLookupResponse(peerClusterData.getBrokerServiceUrl(),\n                                peerClusterData.getBrokerServiceUrlTls(), true, LookupType.Redirect, requestId,\n                                false));\n\n                    }).exceptionally(ex -> {\n                        validationFuture.complete(\n                                newLookupErrorResponse(ServerError.MetadataError, ex.getMessage(), requestId));\n                        return null;\n                    });\n        }\n    }).exceptionally(ex -> {\n        validationFuture.completeExceptionally(ex);\n        return null;\n    });\n\n    // Initiate lookup once validation completes\n    validationFuture.thenAccept(validaitonFailureResponse -> {\n        if (validaitonFailureResponse != null) {\n            lookupfuture.complete(validaitonFailureResponse);\n        } else {\n            pulsarService.getNamespaceService().getBrokerServiceUrlAsync(topicName, authoritative)\n                    .thenAccept(lookupResult -> {\n\n                        if (log.isDebugEnabled()) {\n                            log.debug(\"[{}] Lookup result {}\", topicName.toString(), lookupResult);\n                        }\n\n                        if (!lookupResult.isPresent()) {\n                            lookupfuture.complete(newLookupErrorResponse(ServerError.ServiceNotReady,\n                                    \"No broker was available to own \" + topicName, requestId));\n                            return;\n                        }\n\n                        LookupData lookupData = lookupResult.get().getLookupData();\n                        if (lookupResult.get().isRedirect()) {\n                            boolean newAuthoritative = isLeaderBroker(pulsarService);\n                            lookupfuture.complete(\n                                    newLookupResponse(lookupData.getBrokerUrl(), lookupData.getBrokerUrlTls(),\n                                            newAuthoritative, LookupType.Redirect, requestId, false));\n                        } else {\n                            // When running in standalone mode we want to redirect the client through the service\n                            // url, so that the advertised address configuration is not relevant anymore.\n                            boolean redirectThroughServiceUrl = pulsarService.getConfiguration()\n                                    .isRunningStandalone();\n\n                            lookupfuture.complete(newLookupResponse(lookupData.getBrokerUrl(),\n                                    lookupData.getBrokerUrlTls(), true /* authoritative */, LookupType.Connect,\n                                    requestId, redirectThroughServiceUrl));\n                        }\n                    }).exceptionally(ex -> {\n                        if (ex instanceof CompletionException && ex.getCause() instanceof IllegalStateException) {\n                            log.info(\"Failed to lookup {} for topic {} with error {}\", clientAppId,\n                                    topicName.toString(), ex.getCause().getMessage());\n                        } else {\n                            log.warn(\"Failed to lookup {} for topic {} with error {}\", clientAppId,\n                                    topicName.toString(), ex.getMessage(), ex);\n                        }\n                        lookupfuture.complete(\n                                newLookupErrorResponse(ServerError.ServiceNotReady, ex.getMessage(), requestId));\n                        return null;\n                    });\n        }\n\n    }).exceptionally(ex -> {\n        if (ex instanceof CompletionException && ex.getCause() instanceof IllegalStateException) {\n            log.info(\"Failed to lookup {} for topic {} with error {}\", clientAppId, topicName.toString(),\n                    ex.getCause().getMessage());\n        } else {\n            log.warn(\"Failed to lookup {} for topic {} with error {}\", clientAppId, topicName.toString(),\n                    ex.getMessage(), ex);\n        }\n\n        lookupfuture.complete(newLookupErrorResponse(ServerError.ServiceNotReady, ex.getMessage(), requestId));\n        return null;\n    });\n\n    DebugUtil.stacktrace();\n\n    return lookupfuture;\n}\n```","source":"_posts/Pulsar-FAQ.md","raw":"---\ntitle: Pulsar-FAQ\ndate: 2019-04-29 14:48:18\ntags:\n---\n\n\n### 这个bundle是什么意思？\nOne can either change the system default, or override it when creating a new namespace:\n\n$ bin/pulsar-admin namespaces create my-tenant/my-namespace --clusters us-west --bundles 16\n\nCopy\nWith this command, we're creating a namespace with 16 initial bundles. Therefore the topics for this namespaces can immediately be spread across up to 16 brokers.\n\nIn general, if the expected traffic and number of topics is known in advance, it's a good idea to start with a reasonable number of bundles instead of waiting for the system to auto-correct the distribution.\n\nOn a same note, it is normally beneficial to start with more bundles than number of brokers, primarily because of the hashing nature of the distribution of topics into bundles. For example, for a namespace with 1000 topics, using something like 64 bundles will achieve a good distribution of traffic across 16 brokers.\n\n############# ThreadID:342 Time: 1559563265289 ################\njava.lang.Thread Thread.java 1559 getStackTrace\n-----------------------------------\norg.apache.pulsar.debug.DebugUtil DebugUtil.java 15 commonStacktrace\n-----------------------------------\norg.apache.pulsar.debug.DebugUtil DebugUtil.java 11 stacktrace\n-----------------------------------\norg.apache.pulsar.broker.lookup.TopicLookupBase TopicLookupBase.java 280 lookupTopicAsync\n-----------------------------------\norg.apache.pulsar.broker.service.ServerCnx ServerCnx.java 263 lambda$handleLookup$3\n-----------------------------------\njava.util.concurrent.CompletableFuture CompletableFuture.java 602 uniApply\n-----------------------------------\njava.util.concurrent.CompletableFuture CompletableFuture.java 614 uniApplyStage\n-----------------------------------\njava.util.concurrent.CompletableFuture CompletableFuture.java 1983 thenApply\n-----------------------------------\norg.apache.pulsar.broker.service.ServerCnx ServerCnx.java 261 handleLookup\n-----------------------------------\norg.apache.pulsar.common.api.PulsarDecoder PulsarDecoder.java 112 channelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 340 fireChannelRead\n-----------------------------------\nio.netty.handler.codec.ByteToMessageDecoder ByteToMessageDecoder.java 323 fireChannelRead\n-----------------------------------\nio.netty.handler.codec.ByteToMessageDecoder ByteToMessageDecoder.java 297 channelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 340 fireChannelRead\n-----------------------------------\nio.netty.channel.DefaultChannelPipeline$HeadContext DefaultChannelPipeline.java 1434 channelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead\n-----------------------------------\nio.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead\n-----------------------------------\nio.netty.channel.DefaultChannelPipeline DefaultChannelPipeline.java 965 fireChannelRead\n-----------------------------------\nio.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe AbstractNioByteChannel.java 163 read\n-----------------------------------\nio.netty.channel.nio.NioEventLoop NioEventLoop.java 656 processSelectedKey\n-----------------------------------\nio.netty.channel.nio.NioEventLoop NioEventLoop.java 591 processSelectedKeysOptimized\n-----------------------------------\nio.netty.channel.nio.NioEventLoop NioEventLoop.java 508 processSelectedKeys\n-----------------------------------\nio.netty.channel.nio.NioEventLoop NioEventLoop.java 470 run\n-----------------------------------\nio.netty.util.concurrent.SingleThreadEventExecutor$5 SingleThreadEventExecutor.java 909 run\n-----------------------------------\nio.netty.util.concurrent.FastThreadLocalRunnable FastThreadLocalRunnable.java 30 run\n-----------------------------------\njava.lang.Thread Thread.java 748 run\n-----------------------------------\n#############################\n\n\n\n```\n/**\n     *\n     * Lookup broker-service address for a given namespace-bundle which contains given topic.\n     *\n     * a. Returns broker-address if namespace-bundle is already owned by any broker b. If current-broker receives\n     * lookup-request and if it's not a leader then current broker redirects request to leader by returning\n     * leader-service address. c. If current-broker is leader then it finds out least-loaded broker to own namespace\n     * bundle and redirects request by returning least-loaded broker. d. If current-broker receives request to own the\n     * namespace-bundle then it owns a bundle and returns success(connect) response to client.\n     *\n     * @param pulsarService\n     * @param topicName\n     * @param authoritative\n     * @param clientAppId\n     * @param requestId\n     * @return\n     */\n    public static CompletableFuture<ByteBuf> lookupTopicAsync(PulsarService pulsarService, TopicName topicName,\n        boolean authoritative, String clientAppId, AuthenticationDataSource authenticationData, long requestId) {\n\n    final CompletableFuture<ByteBuf> validationFuture = new CompletableFuture<>();\n    final CompletableFuture<ByteBuf> lookupfuture = new CompletableFuture<>();\n    final String cluster = topicName.getCluster();\n\n    // (1) validate cluster\n    getClusterDataIfDifferentCluster(pulsarService, cluster, clientAppId).thenAccept(differentClusterData -> {\n\n        if (differentClusterData != null) {\n            if (log.isDebugEnabled()) {\n                log.debug(\"[{}] Redirecting the lookup call to {}/{} cluster={}\", clientAppId,\n                        differentClusterData.getBrokerServiceUrl(), differentClusterData.getBrokerServiceUrlTls(),\n                        cluster);\n            }\n            validationFuture.complete(newLookupResponse(differentClusterData.getBrokerServiceUrl(),\n                    differentClusterData.getBrokerServiceUrlTls(), true, LookupType.Redirect, requestId, false));\n        } else {\n            // (2) authorize client\n            try {\n                checkAuthorization(pulsarService, topicName, clientAppId, authenticationData);\n            } catch (RestException authException) {\n                log.warn(\"Failed to authorized {} on cluster {}\", clientAppId, topicName.toString());\n                validationFuture.complete(newLookupErrorResponse(ServerError.AuthorizationError,\n                        authException.getMessage(), requestId));\n                return;\n            } catch (Exception e) {\n                log.warn(\"Unknown error while authorizing {} on cluster {}\", clientAppId, topicName.toString());\n                validationFuture.completeExceptionally(e);\n                return;\n            }\n            // (3) validate global namespace\n            checkLocalOrGetPeerReplicationCluster(pulsarService, topicName.getNamespaceObject())\n                    .thenAccept(peerClusterData -> {\n                        if (peerClusterData == null) {\n                            // (4) all validation passed: initiate lookup\n                            validationFuture.complete(null);\n                            return;\n                        }\n                        // if peer-cluster-data is present it means namespace is owned by that peer-cluster and\n                        // request should be redirect to the peer-cluster\n                        if (StringUtils.isBlank(peerClusterData.getBrokerServiceUrl())\n                                && StringUtils.isBlank(peerClusterData.getBrokerServiceUrl())) {\n                            validationFuture.complete(newLookupErrorResponse(ServerError.MetadataError,\n                                    \"Redirected cluster's brokerService url is not configured\", requestId));\n                            return;\n                        }\n                        validationFuture.complete(newLookupResponse(peerClusterData.getBrokerServiceUrl(),\n                                peerClusterData.getBrokerServiceUrlTls(), true, LookupType.Redirect, requestId,\n                                false));\n\n                    }).exceptionally(ex -> {\n                        validationFuture.complete(\n                                newLookupErrorResponse(ServerError.MetadataError, ex.getMessage(), requestId));\n                        return null;\n                    });\n        }\n    }).exceptionally(ex -> {\n        validationFuture.completeExceptionally(ex);\n        return null;\n    });\n\n    // Initiate lookup once validation completes\n    validationFuture.thenAccept(validaitonFailureResponse -> {\n        if (validaitonFailureResponse != null) {\n            lookupfuture.complete(validaitonFailureResponse);\n        } else {\n            pulsarService.getNamespaceService().getBrokerServiceUrlAsync(topicName, authoritative)\n                    .thenAccept(lookupResult -> {\n\n                        if (log.isDebugEnabled()) {\n                            log.debug(\"[{}] Lookup result {}\", topicName.toString(), lookupResult);\n                        }\n\n                        if (!lookupResult.isPresent()) {\n                            lookupfuture.complete(newLookupErrorResponse(ServerError.ServiceNotReady,\n                                    \"No broker was available to own \" + topicName, requestId));\n                            return;\n                        }\n\n                        LookupData lookupData = lookupResult.get().getLookupData();\n                        if (lookupResult.get().isRedirect()) {\n                            boolean newAuthoritative = isLeaderBroker(pulsarService);\n                            lookupfuture.complete(\n                                    newLookupResponse(lookupData.getBrokerUrl(), lookupData.getBrokerUrlTls(),\n                                            newAuthoritative, LookupType.Redirect, requestId, false));\n                        } else {\n                            // When running in standalone mode we want to redirect the client through the service\n                            // url, so that the advertised address configuration is not relevant anymore.\n                            boolean redirectThroughServiceUrl = pulsarService.getConfiguration()\n                                    .isRunningStandalone();\n\n                            lookupfuture.complete(newLookupResponse(lookupData.getBrokerUrl(),\n                                    lookupData.getBrokerUrlTls(), true /* authoritative */, LookupType.Connect,\n                                    requestId, redirectThroughServiceUrl));\n                        }\n                    }).exceptionally(ex -> {\n                        if (ex instanceof CompletionException && ex.getCause() instanceof IllegalStateException) {\n                            log.info(\"Failed to lookup {} for topic {} with error {}\", clientAppId,\n                                    topicName.toString(), ex.getCause().getMessage());\n                        } else {\n                            log.warn(\"Failed to lookup {} for topic {} with error {}\", clientAppId,\n                                    topicName.toString(), ex.getMessage(), ex);\n                        }\n                        lookupfuture.complete(\n                                newLookupErrorResponse(ServerError.ServiceNotReady, ex.getMessage(), requestId));\n                        return null;\n                    });\n        }\n\n    }).exceptionally(ex -> {\n        if (ex instanceof CompletionException && ex.getCause() instanceof IllegalStateException) {\n            log.info(\"Failed to lookup {} for topic {} with error {}\", clientAppId, topicName.toString(),\n                    ex.getCause().getMessage());\n        } else {\n            log.warn(\"Failed to lookup {} for topic {} with error {}\", clientAppId, topicName.toString(),\n                    ex.getMessage(), ex);\n        }\n\n        lookupfuture.complete(newLookupErrorResponse(ServerError.ServiceNotReady, ex.getMessage(), requestId));\n        return null;\n    });\n\n    DebugUtil.stacktrace();\n\n    return lookupfuture;\n}\n```","slug":"Pulsar-FAQ","published":1,"updated":"2019-09-28T08:51:00.914Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84j004nv1np04ms35cx","content":"<h3 id=\"这个bundle是什么意思？\"><a href=\"#这个bundle是什么意思？\" class=\"headerlink\" title=\"这个bundle是什么意思？\"></a>这个bundle是什么意思？</h3><p>One can either change the system default, or override it when creating a new namespace:</p>\n<p>$ bin/pulsar-admin namespaces create my-tenant/my-namespace –clusters us-west –bundles 16</p>\n<p>Copy<br>With this command, we’re creating a namespace with 16 initial bundles. Therefore the topics for this namespaces can immediately be spread across up to 16 brokers.</p>\n<p>In general, if the expected traffic and number of topics is known in advance, it’s a good idea to start with a reasonable number of bundles instead of waiting for the system to auto-correct the distribution.</p>\n<p>On a same note, it is normally beneficial to start with more bundles than number of brokers, primarily because of the hashing nature of the distribution of topics into bundles. For example, for a namespace with 1000 topics, using something like 64 bundles will achieve a good distribution of traffic across 16 brokers.</p>\n<p>############# ThreadID:342 Time: 1559563265289 ################<br>java.lang.Thread Thread.java 1559 getStackTrace</p>\n<hr>\n<h2 id=\"org-apache-pulsar-debug-DebugUtil-DebugUtil-java-15-commonStacktrace\"><a href=\"#org-apache-pulsar-debug-DebugUtil-DebugUtil-java-15-commonStacktrace\" class=\"headerlink\" title=\"org.apache.pulsar.debug.DebugUtil DebugUtil.java 15 commonStacktrace\"></a>org.apache.pulsar.debug.DebugUtil DebugUtil.java 15 commonStacktrace</h2><h2 id=\"org-apache-pulsar-debug-DebugUtil-DebugUtil-java-11-stacktrace\"><a href=\"#org-apache-pulsar-debug-DebugUtil-DebugUtil-java-11-stacktrace\" class=\"headerlink\" title=\"org.apache.pulsar.debug.DebugUtil DebugUtil.java 11 stacktrace\"></a>org.apache.pulsar.debug.DebugUtil DebugUtil.java 11 stacktrace</h2><h2 id=\"org-apache-pulsar-broker-lookup-TopicLookupBase-TopicLookupBase-java-280-lookupTopicAsync\"><a href=\"#org-apache-pulsar-broker-lookup-TopicLookupBase-TopicLookupBase-java-280-lookupTopicAsync\" class=\"headerlink\" title=\"org.apache.pulsar.broker.lookup.TopicLookupBase TopicLookupBase.java 280 lookupTopicAsync\"></a>org.apache.pulsar.broker.lookup.TopicLookupBase TopicLookupBase.java 280 lookupTopicAsync</h2><h2 id=\"org-apache-pulsar-broker-service-ServerCnx-ServerCnx-java-263-lambda-handleLookup-3\"><a href=\"#org-apache-pulsar-broker-service-ServerCnx-ServerCnx-java-263-lambda-handleLookup-3\" class=\"headerlink\" title=\"org.apache.pulsar.broker.service.ServerCnx ServerCnx.java 263 lambda$handleLookup$3\"></a>org.apache.pulsar.broker.service.ServerCnx ServerCnx.java 263 lambda$handleLookup$3</h2><h2 id=\"java-util-concurrent-CompletableFuture-CompletableFuture-java-602-uniApply\"><a href=\"#java-util-concurrent-CompletableFuture-CompletableFuture-java-602-uniApply\" class=\"headerlink\" title=\"java.util.concurrent.CompletableFuture CompletableFuture.java 602 uniApply\"></a>java.util.concurrent.CompletableFuture CompletableFuture.java 602 uniApply</h2><h2 id=\"java-util-concurrent-CompletableFuture-CompletableFuture-java-614-uniApplyStage\"><a href=\"#java-util-concurrent-CompletableFuture-CompletableFuture-java-614-uniApplyStage\" class=\"headerlink\" title=\"java.util.concurrent.CompletableFuture CompletableFuture.java 614 uniApplyStage\"></a>java.util.concurrent.CompletableFuture CompletableFuture.java 614 uniApplyStage</h2><h2 id=\"java-util-concurrent-CompletableFuture-CompletableFuture-java-1983-thenApply\"><a href=\"#java-util-concurrent-CompletableFuture-CompletableFuture-java-1983-thenApply\" class=\"headerlink\" title=\"java.util.concurrent.CompletableFuture CompletableFuture.java 1983 thenApply\"></a>java.util.concurrent.CompletableFuture CompletableFuture.java 1983 thenApply</h2><h2 id=\"org-apache-pulsar-broker-service-ServerCnx-ServerCnx-java-261-handleLookup\"><a href=\"#org-apache-pulsar-broker-service-ServerCnx-ServerCnx-java-261-handleLookup\" class=\"headerlink\" title=\"org.apache.pulsar.broker.service.ServerCnx ServerCnx.java 261 handleLookup\"></a>org.apache.pulsar.broker.service.ServerCnx ServerCnx.java 261 handleLookup</h2><h2 id=\"org-apache-pulsar-common-api-PulsarDecoder-PulsarDecoder-java-112-channelRead\"><a href=\"#org-apache-pulsar-common-api-PulsarDecoder-PulsarDecoder-java-112-channelRead\" class=\"headerlink\" title=\"org.apache.pulsar.common.api.PulsarDecoder PulsarDecoder.java 112 channelRead\"></a>org.apache.pulsar.common.api.PulsarDecoder PulsarDecoder.java 112 channelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-362-invokeChannelRead\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-362-invokeChannelRead\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-348-invokeChannelRead\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-348-invokeChannelRead\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-340-fireChannelRead\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-340-fireChannelRead\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 340 fireChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 340 fireChannelRead</h2><h2 id=\"io-netty-handler-codec-ByteToMessageDecoder-ByteToMessageDecoder-java-323-fireChannelRead\"><a href=\"#io-netty-handler-codec-ByteToMessageDecoder-ByteToMessageDecoder-java-323-fireChannelRead\" class=\"headerlink\" title=\"io.netty.handler.codec.ByteToMessageDecoder ByteToMessageDecoder.java 323 fireChannelRead\"></a>io.netty.handler.codec.ByteToMessageDecoder ByteToMessageDecoder.java 323 fireChannelRead</h2><h2 id=\"io-netty-handler-codec-ByteToMessageDecoder-ByteToMessageDecoder-java-297-channelRead\"><a href=\"#io-netty-handler-codec-ByteToMessageDecoder-ByteToMessageDecoder-java-297-channelRead\" class=\"headerlink\" title=\"io.netty.handler.codec.ByteToMessageDecoder ByteToMessageDecoder.java 297 channelRead\"></a>io.netty.handler.codec.ByteToMessageDecoder ByteToMessageDecoder.java 297 channelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-362-invokeChannelRead-1\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-362-invokeChannelRead-1\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-348-invokeChannelRead-1\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-348-invokeChannelRead-1\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-340-fireChannelRead-1\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-340-fireChannelRead-1\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 340 fireChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 340 fireChannelRead</h2><h2 id=\"io-netty-channel-DefaultChannelPipeline-HeadContext-DefaultChannelPipeline-java-1434-channelRead\"><a href=\"#io-netty-channel-DefaultChannelPipeline-HeadContext-DefaultChannelPipeline-java-1434-channelRead\" class=\"headerlink\" title=\"io.netty.channel.DefaultChannelPipeline$HeadContext DefaultChannelPipeline.java 1434 channelRead\"></a>io.netty.channel.DefaultChannelPipeline$HeadContext DefaultChannelPipeline.java 1434 channelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-362-invokeChannelRead-2\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-362-invokeChannelRead-2\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-348-invokeChannelRead-2\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-348-invokeChannelRead-2\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead</h2><h2 id=\"io-netty-channel-DefaultChannelPipeline-DefaultChannelPipeline-java-965-fireChannelRead\"><a href=\"#io-netty-channel-DefaultChannelPipeline-DefaultChannelPipeline-java-965-fireChannelRead\" class=\"headerlink\" title=\"io.netty.channel.DefaultChannelPipeline DefaultChannelPipeline.java 965 fireChannelRead\"></a>io.netty.channel.DefaultChannelPipeline DefaultChannelPipeline.java 965 fireChannelRead</h2><h2 id=\"io-netty-channel-nio-AbstractNioByteChannel-NioByteUnsafe-AbstractNioByteChannel-java-163-read\"><a href=\"#io-netty-channel-nio-AbstractNioByteChannel-NioByteUnsafe-AbstractNioByteChannel-java-163-read\" class=\"headerlink\" title=\"io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe AbstractNioByteChannel.java 163 read\"></a>io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe AbstractNioByteChannel.java 163 read</h2><h2 id=\"io-netty-channel-nio-NioEventLoop-NioEventLoop-java-656-processSelectedKey\"><a href=\"#io-netty-channel-nio-NioEventLoop-NioEventLoop-java-656-processSelectedKey\" class=\"headerlink\" title=\"io.netty.channel.nio.NioEventLoop NioEventLoop.java 656 processSelectedKey\"></a>io.netty.channel.nio.NioEventLoop NioEventLoop.java 656 processSelectedKey</h2><h2 id=\"io-netty-channel-nio-NioEventLoop-NioEventLoop-java-591-processSelectedKeysOptimized\"><a href=\"#io-netty-channel-nio-NioEventLoop-NioEventLoop-java-591-processSelectedKeysOptimized\" class=\"headerlink\" title=\"io.netty.channel.nio.NioEventLoop NioEventLoop.java 591 processSelectedKeysOptimized\"></a>io.netty.channel.nio.NioEventLoop NioEventLoop.java 591 processSelectedKeysOptimized</h2><h2 id=\"io-netty-channel-nio-NioEventLoop-NioEventLoop-java-508-processSelectedKeys\"><a href=\"#io-netty-channel-nio-NioEventLoop-NioEventLoop-java-508-processSelectedKeys\" class=\"headerlink\" title=\"io.netty.channel.nio.NioEventLoop NioEventLoop.java 508 processSelectedKeys\"></a>io.netty.channel.nio.NioEventLoop NioEventLoop.java 508 processSelectedKeys</h2><h2 id=\"io-netty-channel-nio-NioEventLoop-NioEventLoop-java-470-run\"><a href=\"#io-netty-channel-nio-NioEventLoop-NioEventLoop-java-470-run\" class=\"headerlink\" title=\"io.netty.channel.nio.NioEventLoop NioEventLoop.java 470 run\"></a>io.netty.channel.nio.NioEventLoop NioEventLoop.java 470 run</h2><h2 id=\"io-netty-util-concurrent-SingleThreadEventExecutor-5-SingleThreadEventExecutor-java-909-run\"><a href=\"#io-netty-util-concurrent-SingleThreadEventExecutor-5-SingleThreadEventExecutor-java-909-run\" class=\"headerlink\" title=\"io.netty.util.concurrent.SingleThreadEventExecutor$5 SingleThreadEventExecutor.java 909 run\"></a>io.netty.util.concurrent.SingleThreadEventExecutor$5 SingleThreadEventExecutor.java 909 run</h2><h2 id=\"io-netty-util-concurrent-FastThreadLocalRunnable-FastThreadLocalRunnable-java-30-run\"><a href=\"#io-netty-util-concurrent-FastThreadLocalRunnable-FastThreadLocalRunnable-java-30-run\" class=\"headerlink\" title=\"io.netty.util.concurrent.FastThreadLocalRunnable FastThreadLocalRunnable.java 30 run\"></a>io.netty.util.concurrent.FastThreadLocalRunnable FastThreadLocalRunnable.java 30 run</h2><h2 id=\"java-lang-Thread-Thread-java-748-run\"><a href=\"#java-lang-Thread-Thread-java-748-run\" class=\"headerlink\" title=\"java.lang.Thread Thread.java 748 run\"></a>java.lang.Thread Thread.java 748 run</h2><p>#############################</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * Lookup broker-service address for a given namespace-bundle which contains given topic.</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * a. Returns broker-address if namespace-bundle is already owned by any broker b. If current-broker receives</span><br><span class=\"line\">     * lookup-request and if it&apos;s not a leader then current broker redirects request to leader by returning</span><br><span class=\"line\">     * leader-service address. c. If current-broker is leader then it finds out least-loaded broker to own namespace</span><br><span class=\"line\">     * bundle and redirects request by returning least-loaded broker. d. If current-broker receives request to own the</span><br><span class=\"line\">     * namespace-bundle then it owns a bundle and returns success(connect) response to client.</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * @param pulsarService</span><br><span class=\"line\">     * @param topicName</span><br><span class=\"line\">     * @param authoritative</span><br><span class=\"line\">     * @param clientAppId</span><br><span class=\"line\">     * @param requestId</span><br><span class=\"line\">     * @return</span><br><span class=\"line\">     */</span><br><span class=\"line\">    public static CompletableFuture&lt;ByteBuf&gt; lookupTopicAsync(PulsarService pulsarService, TopicName topicName,</span><br><span class=\"line\">        boolean authoritative, String clientAppId, AuthenticationDataSource authenticationData, long requestId) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    final CompletableFuture&lt;ByteBuf&gt; validationFuture = new CompletableFuture&lt;&gt;();</span><br><span class=\"line\">    final CompletableFuture&lt;ByteBuf&gt; lookupfuture = new CompletableFuture&lt;&gt;();</span><br><span class=\"line\">    final String cluster = topicName.getCluster();</span><br><span class=\"line\"></span><br><span class=\"line\">    // (1) validate cluster</span><br><span class=\"line\">    getClusterDataIfDifferentCluster(pulsarService, cluster, clientAppId).thenAccept(differentClusterData -&gt; &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        if (differentClusterData != null) &#123;</span><br><span class=\"line\">            if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">                log.debug(&quot;[&#123;&#125;] Redirecting the lookup call to &#123;&#125;/&#123;&#125; cluster=&#123;&#125;&quot;, clientAppId,</span><br><span class=\"line\">                        differentClusterData.getBrokerServiceUrl(), differentClusterData.getBrokerServiceUrlTls(),</span><br><span class=\"line\">                        cluster);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            validationFuture.complete(newLookupResponse(differentClusterData.getBrokerServiceUrl(),</span><br><span class=\"line\">                    differentClusterData.getBrokerServiceUrlTls(), true, LookupType.Redirect, requestId, false));</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            // (2) authorize client</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                checkAuthorization(pulsarService, topicName, clientAppId, authenticationData);</span><br><span class=\"line\">            &#125; catch (RestException authException) &#123;</span><br><span class=\"line\">                log.warn(&quot;Failed to authorized &#123;&#125; on cluster &#123;&#125;&quot;, clientAppId, topicName.toString());</span><br><span class=\"line\">                validationFuture.complete(newLookupErrorResponse(ServerError.AuthorizationError,</span><br><span class=\"line\">                        authException.getMessage(), requestId));</span><br><span class=\"line\">                return;</span><br><span class=\"line\">            &#125; catch (Exception e) &#123;</span><br><span class=\"line\">                log.warn(&quot;Unknown error while authorizing &#123;&#125; on cluster &#123;&#125;&quot;, clientAppId, topicName.toString());</span><br><span class=\"line\">                validationFuture.completeExceptionally(e);</span><br><span class=\"line\">                return;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // (3) validate global namespace</span><br><span class=\"line\">            checkLocalOrGetPeerReplicationCluster(pulsarService, topicName.getNamespaceObject())</span><br><span class=\"line\">                    .thenAccept(peerClusterData -&gt; &#123;</span><br><span class=\"line\">                        if (peerClusterData == null) &#123;</span><br><span class=\"line\">                            // (4) all validation passed: initiate lookup</span><br><span class=\"line\">                            validationFuture.complete(null);</span><br><span class=\"line\">                            return;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        // if peer-cluster-data is present it means namespace is owned by that peer-cluster and</span><br><span class=\"line\">                        // request should be redirect to the peer-cluster</span><br><span class=\"line\">                        if (StringUtils.isBlank(peerClusterData.getBrokerServiceUrl())</span><br><span class=\"line\">                                &amp;&amp; StringUtils.isBlank(peerClusterData.getBrokerServiceUrl())) &#123;</span><br><span class=\"line\">                            validationFuture.complete(newLookupErrorResponse(ServerError.MetadataError,</span><br><span class=\"line\">                                    &quot;Redirected cluster&apos;s brokerService url is not configured&quot;, requestId));</span><br><span class=\"line\">                            return;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        validationFuture.complete(newLookupResponse(peerClusterData.getBrokerServiceUrl(),</span><br><span class=\"line\">                                peerClusterData.getBrokerServiceUrlTls(), true, LookupType.Redirect, requestId,</span><br><span class=\"line\">                                false));</span><br><span class=\"line\"></span><br><span class=\"line\">                    &#125;).exceptionally(ex -&gt; &#123;</span><br><span class=\"line\">                        validationFuture.complete(</span><br><span class=\"line\">                                newLookupErrorResponse(ServerError.MetadataError, ex.getMessage(), requestId));</span><br><span class=\"line\">                        return null;</span><br><span class=\"line\">                    &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;).exceptionally(ex -&gt; &#123;</span><br><span class=\"line\">        validationFuture.completeExceptionally(ex);</span><br><span class=\"line\">        return null;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">    // Initiate lookup once validation completes</span><br><span class=\"line\">    validationFuture.thenAccept(validaitonFailureResponse -&gt; &#123;</span><br><span class=\"line\">        if (validaitonFailureResponse != null) &#123;</span><br><span class=\"line\">            lookupfuture.complete(validaitonFailureResponse);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            pulsarService.getNamespaceService().getBrokerServiceUrlAsync(topicName, authoritative)</span><br><span class=\"line\">                    .thenAccept(lookupResult -&gt; &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">                        if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">                            log.debug(&quot;[&#123;&#125;] Lookup result &#123;&#125;&quot;, topicName.toString(), lookupResult);</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                        if (!lookupResult.isPresent()) &#123;</span><br><span class=\"line\">                            lookupfuture.complete(newLookupErrorResponse(ServerError.ServiceNotReady,</span><br><span class=\"line\">                                    &quot;No broker was available to own &quot; + topicName, requestId));</span><br><span class=\"line\">                            return;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                        LookupData lookupData = lookupResult.get().getLookupData();</span><br><span class=\"line\">                        if (lookupResult.get().isRedirect()) &#123;</span><br><span class=\"line\">                            boolean newAuthoritative = isLeaderBroker(pulsarService);</span><br><span class=\"line\">                            lookupfuture.complete(</span><br><span class=\"line\">                                    newLookupResponse(lookupData.getBrokerUrl(), lookupData.getBrokerUrlTls(),</span><br><span class=\"line\">                                            newAuthoritative, LookupType.Redirect, requestId, false));</span><br><span class=\"line\">                        &#125; else &#123;</span><br><span class=\"line\">                            // When running in standalone mode we want to redirect the client through the service</span><br><span class=\"line\">                            // url, so that the advertised address configuration is not relevant anymore.</span><br><span class=\"line\">                            boolean redirectThroughServiceUrl = pulsarService.getConfiguration()</span><br><span class=\"line\">                                    .isRunningStandalone();</span><br><span class=\"line\"></span><br><span class=\"line\">                            lookupfuture.complete(newLookupResponse(lookupData.getBrokerUrl(),</span><br><span class=\"line\">                                    lookupData.getBrokerUrlTls(), true /* authoritative */, LookupType.Connect,</span><br><span class=\"line\">                                    requestId, redirectThroughServiceUrl));</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;).exceptionally(ex -&gt; &#123;</span><br><span class=\"line\">                        if (ex instanceof CompletionException &amp;&amp; ex.getCause() instanceof IllegalStateException) &#123;</span><br><span class=\"line\">                            log.info(&quot;Failed to lookup &#123;&#125; for topic &#123;&#125; with error &#123;&#125;&quot;, clientAppId,</span><br><span class=\"line\">                                    topicName.toString(), ex.getCause().getMessage());</span><br><span class=\"line\">                        &#125; else &#123;</span><br><span class=\"line\">                            log.warn(&quot;Failed to lookup &#123;&#125; for topic &#123;&#125; with error &#123;&#125;&quot;, clientAppId,</span><br><span class=\"line\">                                    topicName.toString(), ex.getMessage(), ex);</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        lookupfuture.complete(</span><br><span class=\"line\">                                newLookupErrorResponse(ServerError.ServiceNotReady, ex.getMessage(), requestId));</span><br><span class=\"line\">                        return null;</span><br><span class=\"line\">                    &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;).exceptionally(ex -&gt; &#123;</span><br><span class=\"line\">        if (ex instanceof CompletionException &amp;&amp; ex.getCause() instanceof IllegalStateException) &#123;</span><br><span class=\"line\">            log.info(&quot;Failed to lookup &#123;&#125; for topic &#123;&#125; with error &#123;&#125;&quot;, clientAppId, topicName.toString(),</span><br><span class=\"line\">                    ex.getCause().getMessage());</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            log.warn(&quot;Failed to lookup &#123;&#125; for topic &#123;&#125; with error &#123;&#125;&quot;, clientAppId, topicName.toString(),</span><br><span class=\"line\">                    ex.getMessage(), ex);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        lookupfuture.complete(newLookupErrorResponse(ServerError.ServiceNotReady, ex.getMessage(), requestId));</span><br><span class=\"line\">        return null;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">    DebugUtil.stacktrace();</span><br><span class=\"line\"></span><br><span class=\"line\">    return lookupfuture;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"这个bundle是什么意思？\"><a href=\"#这个bundle是什么意思？\" class=\"headerlink\" title=\"这个bundle是什么意思？\"></a>这个bundle是什么意思？</h3><p>One can either change the system default, or override it when creating a new namespace:</p>\n<p>$ bin/pulsar-admin namespaces create my-tenant/my-namespace –clusters us-west –bundles 16</p>\n<p>Copy<br>With this command, we’re creating a namespace with 16 initial bundles. Therefore the topics for this namespaces can immediately be spread across up to 16 brokers.</p>\n<p>In general, if the expected traffic and number of topics is known in advance, it’s a good idea to start with a reasonable number of bundles instead of waiting for the system to auto-correct the distribution.</p>\n<p>On a same note, it is normally beneficial to start with more bundles than number of brokers, primarily because of the hashing nature of the distribution of topics into bundles. For example, for a namespace with 1000 topics, using something like 64 bundles will achieve a good distribution of traffic across 16 brokers.</p>\n<p>############# ThreadID:342 Time: 1559563265289 ################<br>java.lang.Thread Thread.java 1559 getStackTrace</p>\n<hr>\n<h2 id=\"org-apache-pulsar-debug-DebugUtil-DebugUtil-java-15-commonStacktrace\"><a href=\"#org-apache-pulsar-debug-DebugUtil-DebugUtil-java-15-commonStacktrace\" class=\"headerlink\" title=\"org.apache.pulsar.debug.DebugUtil DebugUtil.java 15 commonStacktrace\"></a>org.apache.pulsar.debug.DebugUtil DebugUtil.java 15 commonStacktrace</h2><h2 id=\"org-apache-pulsar-debug-DebugUtil-DebugUtil-java-11-stacktrace\"><a href=\"#org-apache-pulsar-debug-DebugUtil-DebugUtil-java-11-stacktrace\" class=\"headerlink\" title=\"org.apache.pulsar.debug.DebugUtil DebugUtil.java 11 stacktrace\"></a>org.apache.pulsar.debug.DebugUtil DebugUtil.java 11 stacktrace</h2><h2 id=\"org-apache-pulsar-broker-lookup-TopicLookupBase-TopicLookupBase-java-280-lookupTopicAsync\"><a href=\"#org-apache-pulsar-broker-lookup-TopicLookupBase-TopicLookupBase-java-280-lookupTopicAsync\" class=\"headerlink\" title=\"org.apache.pulsar.broker.lookup.TopicLookupBase TopicLookupBase.java 280 lookupTopicAsync\"></a>org.apache.pulsar.broker.lookup.TopicLookupBase TopicLookupBase.java 280 lookupTopicAsync</h2><h2 id=\"org-apache-pulsar-broker-service-ServerCnx-ServerCnx-java-263-lambda-handleLookup-3\"><a href=\"#org-apache-pulsar-broker-service-ServerCnx-ServerCnx-java-263-lambda-handleLookup-3\" class=\"headerlink\" title=\"org.apache.pulsar.broker.service.ServerCnx ServerCnx.java 263 lambda$handleLookup$3\"></a>org.apache.pulsar.broker.service.ServerCnx ServerCnx.java 263 lambda$handleLookup$3</h2><h2 id=\"java-util-concurrent-CompletableFuture-CompletableFuture-java-602-uniApply\"><a href=\"#java-util-concurrent-CompletableFuture-CompletableFuture-java-602-uniApply\" class=\"headerlink\" title=\"java.util.concurrent.CompletableFuture CompletableFuture.java 602 uniApply\"></a>java.util.concurrent.CompletableFuture CompletableFuture.java 602 uniApply</h2><h2 id=\"java-util-concurrent-CompletableFuture-CompletableFuture-java-614-uniApplyStage\"><a href=\"#java-util-concurrent-CompletableFuture-CompletableFuture-java-614-uniApplyStage\" class=\"headerlink\" title=\"java.util.concurrent.CompletableFuture CompletableFuture.java 614 uniApplyStage\"></a>java.util.concurrent.CompletableFuture CompletableFuture.java 614 uniApplyStage</h2><h2 id=\"java-util-concurrent-CompletableFuture-CompletableFuture-java-1983-thenApply\"><a href=\"#java-util-concurrent-CompletableFuture-CompletableFuture-java-1983-thenApply\" class=\"headerlink\" title=\"java.util.concurrent.CompletableFuture CompletableFuture.java 1983 thenApply\"></a>java.util.concurrent.CompletableFuture CompletableFuture.java 1983 thenApply</h2><h2 id=\"org-apache-pulsar-broker-service-ServerCnx-ServerCnx-java-261-handleLookup\"><a href=\"#org-apache-pulsar-broker-service-ServerCnx-ServerCnx-java-261-handleLookup\" class=\"headerlink\" title=\"org.apache.pulsar.broker.service.ServerCnx ServerCnx.java 261 handleLookup\"></a>org.apache.pulsar.broker.service.ServerCnx ServerCnx.java 261 handleLookup</h2><h2 id=\"org-apache-pulsar-common-api-PulsarDecoder-PulsarDecoder-java-112-channelRead\"><a href=\"#org-apache-pulsar-common-api-PulsarDecoder-PulsarDecoder-java-112-channelRead\" class=\"headerlink\" title=\"org.apache.pulsar.common.api.PulsarDecoder PulsarDecoder.java 112 channelRead\"></a>org.apache.pulsar.common.api.PulsarDecoder PulsarDecoder.java 112 channelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-362-invokeChannelRead\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-362-invokeChannelRead\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-348-invokeChannelRead\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-348-invokeChannelRead\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-340-fireChannelRead\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-340-fireChannelRead\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 340 fireChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 340 fireChannelRead</h2><h2 id=\"io-netty-handler-codec-ByteToMessageDecoder-ByteToMessageDecoder-java-323-fireChannelRead\"><a href=\"#io-netty-handler-codec-ByteToMessageDecoder-ByteToMessageDecoder-java-323-fireChannelRead\" class=\"headerlink\" title=\"io.netty.handler.codec.ByteToMessageDecoder ByteToMessageDecoder.java 323 fireChannelRead\"></a>io.netty.handler.codec.ByteToMessageDecoder ByteToMessageDecoder.java 323 fireChannelRead</h2><h2 id=\"io-netty-handler-codec-ByteToMessageDecoder-ByteToMessageDecoder-java-297-channelRead\"><a href=\"#io-netty-handler-codec-ByteToMessageDecoder-ByteToMessageDecoder-java-297-channelRead\" class=\"headerlink\" title=\"io.netty.handler.codec.ByteToMessageDecoder ByteToMessageDecoder.java 297 channelRead\"></a>io.netty.handler.codec.ByteToMessageDecoder ByteToMessageDecoder.java 297 channelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-362-invokeChannelRead-1\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-362-invokeChannelRead-1\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-348-invokeChannelRead-1\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-348-invokeChannelRead-1\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-340-fireChannelRead-1\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-340-fireChannelRead-1\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 340 fireChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 340 fireChannelRead</h2><h2 id=\"io-netty-channel-DefaultChannelPipeline-HeadContext-DefaultChannelPipeline-java-1434-channelRead\"><a href=\"#io-netty-channel-DefaultChannelPipeline-HeadContext-DefaultChannelPipeline-java-1434-channelRead\" class=\"headerlink\" title=\"io.netty.channel.DefaultChannelPipeline$HeadContext DefaultChannelPipeline.java 1434 channelRead\"></a>io.netty.channel.DefaultChannelPipeline$HeadContext DefaultChannelPipeline.java 1434 channelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-362-invokeChannelRead-2\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-362-invokeChannelRead-2\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 362 invokeChannelRead</h2><h2 id=\"io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-348-invokeChannelRead-2\"><a href=\"#io-netty-channel-AbstractChannelHandlerContext-AbstractChannelHandlerContext-java-348-invokeChannelRead-2\" class=\"headerlink\" title=\"io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead\"></a>io.netty.channel.AbstractChannelHandlerContext AbstractChannelHandlerContext.java 348 invokeChannelRead</h2><h2 id=\"io-netty-channel-DefaultChannelPipeline-DefaultChannelPipeline-java-965-fireChannelRead\"><a href=\"#io-netty-channel-DefaultChannelPipeline-DefaultChannelPipeline-java-965-fireChannelRead\" class=\"headerlink\" title=\"io.netty.channel.DefaultChannelPipeline DefaultChannelPipeline.java 965 fireChannelRead\"></a>io.netty.channel.DefaultChannelPipeline DefaultChannelPipeline.java 965 fireChannelRead</h2><h2 id=\"io-netty-channel-nio-AbstractNioByteChannel-NioByteUnsafe-AbstractNioByteChannel-java-163-read\"><a href=\"#io-netty-channel-nio-AbstractNioByteChannel-NioByteUnsafe-AbstractNioByteChannel-java-163-read\" class=\"headerlink\" title=\"io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe AbstractNioByteChannel.java 163 read\"></a>io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe AbstractNioByteChannel.java 163 read</h2><h2 id=\"io-netty-channel-nio-NioEventLoop-NioEventLoop-java-656-processSelectedKey\"><a href=\"#io-netty-channel-nio-NioEventLoop-NioEventLoop-java-656-processSelectedKey\" class=\"headerlink\" title=\"io.netty.channel.nio.NioEventLoop NioEventLoop.java 656 processSelectedKey\"></a>io.netty.channel.nio.NioEventLoop NioEventLoop.java 656 processSelectedKey</h2><h2 id=\"io-netty-channel-nio-NioEventLoop-NioEventLoop-java-591-processSelectedKeysOptimized\"><a href=\"#io-netty-channel-nio-NioEventLoop-NioEventLoop-java-591-processSelectedKeysOptimized\" class=\"headerlink\" title=\"io.netty.channel.nio.NioEventLoop NioEventLoop.java 591 processSelectedKeysOptimized\"></a>io.netty.channel.nio.NioEventLoop NioEventLoop.java 591 processSelectedKeysOptimized</h2><h2 id=\"io-netty-channel-nio-NioEventLoop-NioEventLoop-java-508-processSelectedKeys\"><a href=\"#io-netty-channel-nio-NioEventLoop-NioEventLoop-java-508-processSelectedKeys\" class=\"headerlink\" title=\"io.netty.channel.nio.NioEventLoop NioEventLoop.java 508 processSelectedKeys\"></a>io.netty.channel.nio.NioEventLoop NioEventLoop.java 508 processSelectedKeys</h2><h2 id=\"io-netty-channel-nio-NioEventLoop-NioEventLoop-java-470-run\"><a href=\"#io-netty-channel-nio-NioEventLoop-NioEventLoop-java-470-run\" class=\"headerlink\" title=\"io.netty.channel.nio.NioEventLoop NioEventLoop.java 470 run\"></a>io.netty.channel.nio.NioEventLoop NioEventLoop.java 470 run</h2><h2 id=\"io-netty-util-concurrent-SingleThreadEventExecutor-5-SingleThreadEventExecutor-java-909-run\"><a href=\"#io-netty-util-concurrent-SingleThreadEventExecutor-5-SingleThreadEventExecutor-java-909-run\" class=\"headerlink\" title=\"io.netty.util.concurrent.SingleThreadEventExecutor$5 SingleThreadEventExecutor.java 909 run\"></a>io.netty.util.concurrent.SingleThreadEventExecutor$5 SingleThreadEventExecutor.java 909 run</h2><h2 id=\"io-netty-util-concurrent-FastThreadLocalRunnable-FastThreadLocalRunnable-java-30-run\"><a href=\"#io-netty-util-concurrent-FastThreadLocalRunnable-FastThreadLocalRunnable-java-30-run\" class=\"headerlink\" title=\"io.netty.util.concurrent.FastThreadLocalRunnable FastThreadLocalRunnable.java 30 run\"></a>io.netty.util.concurrent.FastThreadLocalRunnable FastThreadLocalRunnable.java 30 run</h2><h2 id=\"java-lang-Thread-Thread-java-748-run\"><a href=\"#java-lang-Thread-Thread-java-748-run\" class=\"headerlink\" title=\"java.lang.Thread Thread.java 748 run\"></a>java.lang.Thread Thread.java 748 run</h2><p>#############################</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * Lookup broker-service address for a given namespace-bundle which contains given topic.</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * a. Returns broker-address if namespace-bundle is already owned by any broker b. If current-broker receives</span><br><span class=\"line\">     * lookup-request and if it&apos;s not a leader then current broker redirects request to leader by returning</span><br><span class=\"line\">     * leader-service address. c. If current-broker is leader then it finds out least-loaded broker to own namespace</span><br><span class=\"line\">     * bundle and redirects request by returning least-loaded broker. d. If current-broker receives request to own the</span><br><span class=\"line\">     * namespace-bundle then it owns a bundle and returns success(connect) response to client.</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * @param pulsarService</span><br><span class=\"line\">     * @param topicName</span><br><span class=\"line\">     * @param authoritative</span><br><span class=\"line\">     * @param clientAppId</span><br><span class=\"line\">     * @param requestId</span><br><span class=\"line\">     * @return</span><br><span class=\"line\">     */</span><br><span class=\"line\">    public static CompletableFuture&lt;ByteBuf&gt; lookupTopicAsync(PulsarService pulsarService, TopicName topicName,</span><br><span class=\"line\">        boolean authoritative, String clientAppId, AuthenticationDataSource authenticationData, long requestId) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    final CompletableFuture&lt;ByteBuf&gt; validationFuture = new CompletableFuture&lt;&gt;();</span><br><span class=\"line\">    final CompletableFuture&lt;ByteBuf&gt; lookupfuture = new CompletableFuture&lt;&gt;();</span><br><span class=\"line\">    final String cluster = topicName.getCluster();</span><br><span class=\"line\"></span><br><span class=\"line\">    // (1) validate cluster</span><br><span class=\"line\">    getClusterDataIfDifferentCluster(pulsarService, cluster, clientAppId).thenAccept(differentClusterData -&gt; &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        if (differentClusterData != null) &#123;</span><br><span class=\"line\">            if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">                log.debug(&quot;[&#123;&#125;] Redirecting the lookup call to &#123;&#125;/&#123;&#125; cluster=&#123;&#125;&quot;, clientAppId,</span><br><span class=\"line\">                        differentClusterData.getBrokerServiceUrl(), differentClusterData.getBrokerServiceUrlTls(),</span><br><span class=\"line\">                        cluster);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            validationFuture.complete(newLookupResponse(differentClusterData.getBrokerServiceUrl(),</span><br><span class=\"line\">                    differentClusterData.getBrokerServiceUrlTls(), true, LookupType.Redirect, requestId, false));</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            // (2) authorize client</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                checkAuthorization(pulsarService, topicName, clientAppId, authenticationData);</span><br><span class=\"line\">            &#125; catch (RestException authException) &#123;</span><br><span class=\"line\">                log.warn(&quot;Failed to authorized &#123;&#125; on cluster &#123;&#125;&quot;, clientAppId, topicName.toString());</span><br><span class=\"line\">                validationFuture.complete(newLookupErrorResponse(ServerError.AuthorizationError,</span><br><span class=\"line\">                        authException.getMessage(), requestId));</span><br><span class=\"line\">                return;</span><br><span class=\"line\">            &#125; catch (Exception e) &#123;</span><br><span class=\"line\">                log.warn(&quot;Unknown error while authorizing &#123;&#125; on cluster &#123;&#125;&quot;, clientAppId, topicName.toString());</span><br><span class=\"line\">                validationFuture.completeExceptionally(e);</span><br><span class=\"line\">                return;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            // (3) validate global namespace</span><br><span class=\"line\">            checkLocalOrGetPeerReplicationCluster(pulsarService, topicName.getNamespaceObject())</span><br><span class=\"line\">                    .thenAccept(peerClusterData -&gt; &#123;</span><br><span class=\"line\">                        if (peerClusterData == null) &#123;</span><br><span class=\"line\">                            // (4) all validation passed: initiate lookup</span><br><span class=\"line\">                            validationFuture.complete(null);</span><br><span class=\"line\">                            return;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        // if peer-cluster-data is present it means namespace is owned by that peer-cluster and</span><br><span class=\"line\">                        // request should be redirect to the peer-cluster</span><br><span class=\"line\">                        if (StringUtils.isBlank(peerClusterData.getBrokerServiceUrl())</span><br><span class=\"line\">                                &amp;&amp; StringUtils.isBlank(peerClusterData.getBrokerServiceUrl())) &#123;</span><br><span class=\"line\">                            validationFuture.complete(newLookupErrorResponse(ServerError.MetadataError,</span><br><span class=\"line\">                                    &quot;Redirected cluster&apos;s brokerService url is not configured&quot;, requestId));</span><br><span class=\"line\">                            return;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        validationFuture.complete(newLookupResponse(peerClusterData.getBrokerServiceUrl(),</span><br><span class=\"line\">                                peerClusterData.getBrokerServiceUrlTls(), true, LookupType.Redirect, requestId,</span><br><span class=\"line\">                                false));</span><br><span class=\"line\"></span><br><span class=\"line\">                    &#125;).exceptionally(ex -&gt; &#123;</span><br><span class=\"line\">                        validationFuture.complete(</span><br><span class=\"line\">                                newLookupErrorResponse(ServerError.MetadataError, ex.getMessage(), requestId));</span><br><span class=\"line\">                        return null;</span><br><span class=\"line\">                    &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;).exceptionally(ex -&gt; &#123;</span><br><span class=\"line\">        validationFuture.completeExceptionally(ex);</span><br><span class=\"line\">        return null;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">    // Initiate lookup once validation completes</span><br><span class=\"line\">    validationFuture.thenAccept(validaitonFailureResponse -&gt; &#123;</span><br><span class=\"line\">        if (validaitonFailureResponse != null) &#123;</span><br><span class=\"line\">            lookupfuture.complete(validaitonFailureResponse);</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            pulsarService.getNamespaceService().getBrokerServiceUrlAsync(topicName, authoritative)</span><br><span class=\"line\">                    .thenAccept(lookupResult -&gt; &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">                        if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">                            log.debug(&quot;[&#123;&#125;] Lookup result &#123;&#125;&quot;, topicName.toString(), lookupResult);</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                        if (!lookupResult.isPresent()) &#123;</span><br><span class=\"line\">                            lookupfuture.complete(newLookupErrorResponse(ServerError.ServiceNotReady,</span><br><span class=\"line\">                                    &quot;No broker was available to own &quot; + topicName, requestId));</span><br><span class=\"line\">                            return;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                        LookupData lookupData = lookupResult.get().getLookupData();</span><br><span class=\"line\">                        if (lookupResult.get().isRedirect()) &#123;</span><br><span class=\"line\">                            boolean newAuthoritative = isLeaderBroker(pulsarService);</span><br><span class=\"line\">                            lookupfuture.complete(</span><br><span class=\"line\">                                    newLookupResponse(lookupData.getBrokerUrl(), lookupData.getBrokerUrlTls(),</span><br><span class=\"line\">                                            newAuthoritative, LookupType.Redirect, requestId, false));</span><br><span class=\"line\">                        &#125; else &#123;</span><br><span class=\"line\">                            // When running in standalone mode we want to redirect the client through the service</span><br><span class=\"line\">                            // url, so that the advertised address configuration is not relevant anymore.</span><br><span class=\"line\">                            boolean redirectThroughServiceUrl = pulsarService.getConfiguration()</span><br><span class=\"line\">                                    .isRunningStandalone();</span><br><span class=\"line\"></span><br><span class=\"line\">                            lookupfuture.complete(newLookupResponse(lookupData.getBrokerUrl(),</span><br><span class=\"line\">                                    lookupData.getBrokerUrlTls(), true /* authoritative */, LookupType.Connect,</span><br><span class=\"line\">                                    requestId, redirectThroughServiceUrl));</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;).exceptionally(ex -&gt; &#123;</span><br><span class=\"line\">                        if (ex instanceof CompletionException &amp;&amp; ex.getCause() instanceof IllegalStateException) &#123;</span><br><span class=\"line\">                            log.info(&quot;Failed to lookup &#123;&#125; for topic &#123;&#125; with error &#123;&#125;&quot;, clientAppId,</span><br><span class=\"line\">                                    topicName.toString(), ex.getCause().getMessage());</span><br><span class=\"line\">                        &#125; else &#123;</span><br><span class=\"line\">                            log.warn(&quot;Failed to lookup &#123;&#125; for topic &#123;&#125; with error &#123;&#125;&quot;, clientAppId,</span><br><span class=\"line\">                                    topicName.toString(), ex.getMessage(), ex);</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        lookupfuture.complete(</span><br><span class=\"line\">                                newLookupErrorResponse(ServerError.ServiceNotReady, ex.getMessage(), requestId));</span><br><span class=\"line\">                        return null;</span><br><span class=\"line\">                    &#125;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;).exceptionally(ex -&gt; &#123;</span><br><span class=\"line\">        if (ex instanceof CompletionException &amp;&amp; ex.getCause() instanceof IllegalStateException) &#123;</span><br><span class=\"line\">            log.info(&quot;Failed to lookup &#123;&#125; for topic &#123;&#125; with error &#123;&#125;&quot;, clientAppId, topicName.toString(),</span><br><span class=\"line\">                    ex.getCause().getMessage());</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            log.warn(&quot;Failed to lookup &#123;&#125; for topic &#123;&#125; with error &#123;&#125;&quot;, clientAppId, topicName.toString(),</span><br><span class=\"line\">                    ex.getMessage(), ex);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        lookupfuture.complete(newLookupErrorResponse(ServerError.ServiceNotReady, ex.getMessage(), requestId));</span><br><span class=\"line\">        return null;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">    DebugUtil.stacktrace();</span><br><span class=\"line\"></span><br><span class=\"line\">    return lookupfuture;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Pulsar-Consume-Msg","date":"2019-06-13T11:11:45.000Z","_content":"\n\n### 居然是从FLOW开始的！！！\n\ngetRange(Comparable, Comparable):109, RangeCache (org.apache.bookkeeper.mledger.util), RangeCache.java\nasyncReadEntry0(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):261, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java\nasyncReadEntry(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):238, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java\nasyncReadEntry(ReadHandle, long, long, boolean, OpReadEntry, Object):1553, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java\ninternalReadFromLedger(ReadHandle, OpReadEntry):1527, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java\nasyncReadEntries(OpReadEntry):1380, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java\nasyncReadEntries(int, AsyncCallbacks$ReadEntriesCallback, Object):476, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java\nasyncReadEntriesOrWait(int, AsyncCallbacks$ReadEntriesCallback, Object):594, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java\nreadMoreEntries():326, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java\nconsumerFlow(Consumer, int):240, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java\nconsumerFlow(Consumer, int):215, PersistentSubscription (org.apache.pulsar.broker.service.persistent), PersistentSubscription.java\nflowPermits(int):376, Consumer (org.apache.pulsar.broker.service), Consumer.java\nhandleFlow(PulsarApi$CommandFlow):1090, ServerCnx (org.apache.pulsar.broker.service), ServerCnx.java\nchannelRead(ChannelHandlerContext, Object):160, PulsarDecoder (org.apache.pulsar.common.api), PulsarDecoder.java\ninvokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(ChannelHandlerContext, CodecOutputList, int):323, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java\nchannelRead(ChannelHandlerContext, Object):297, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java\ninvokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nchannelRead(ChannelHandlerContext, Object):1434, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java\ninvokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(Object):965, DefaultChannelPipeline (io.netty.channel), DefaultChannelPipeline.java\nread():163, AbstractNioByteChannel$NioByteUnsafe (io.netty.channel.nio), AbstractNioByteChannel.java\nprocessSelectedKey(SelectionKey, AbstractNioChannel):656, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nprocessSelectedKeysOptimized():591, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nprocessSelectedKeys():508, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nrun():470, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nrun():909, SingleThreadEventExecutor$5 (io.netty.util.concurrent), SingleThreadEventExecutor.java\nrun():30, FastThreadLocalRunnable (io.netty.util.concurrent), FastThreadLocalRunnable.java\nrun():748, Thread (java.lang), Thread.java\n\n\n### 如果缓存中没有，那么就从bk中去读\n```\nprivate void asyncReadEntry0(ReadHandle lh, long firstEntry, long lastEntry, boolean isSlowestReader,\n        final ReadEntriesCallback callback, Object ctx) {\n    final long ledgerId = lh.getId();\n    final int entriesToRead = (int) (lastEntry - firstEntry) + 1;\n    final PositionImpl firstPosition = PositionImpl.get(lh.getId(), firstEntry);\n    final PositionImpl lastPosition = PositionImpl.get(lh.getId(), lastEntry);\n\n    if (log.isDebugEnabled()) {\n        log.debug(\"[{}] Reading entries range ledger {}: {} to {}\", ml.getName(), ledgerId, firstEntry, lastEntry);\n    }\n\n    Collection<EntryImpl> cachedEntries = entries.getRange(firstPosition, lastPosition);\n\n    if (cachedEntries.size() == entriesToRead) {\n        long totalCachedSize = 0;\n        final List<EntryImpl> entriesToReturn = Lists.newArrayListWithExpectedSize(entriesToRead);\n\n        // All entries found in cache\n        for (EntryImpl entry : cachedEntries) {\n            entriesToReturn.add(EntryImpl.create(entry));\n            totalCachedSize += entry.getLength();\n            entry.release();\n        }\n\n        manager.mlFactoryMBean.recordCacheHits(entriesToReturn.size(), totalCachedSize);\n        if (log.isDebugEnabled()) {\n            log.debug(\"[{}] Ledger {} -- Found in cache entries: {}-{}\", ml.getName(), ledgerId, firstEntry,\n                    lastEntry);\n        }\n\n        callback.readEntriesComplete((List) entriesToReturn, ctx);\n\n    } else {\n        if (!cachedEntries.isEmpty()) {\n            cachedEntries.forEach(entry -> entry.release());\n        }\n\n        // Read all the entries from bookkeeper\n        lh.readAsync(firstEntry, lastEntry).whenCompleteAsync(\n                (ledgerEntries, exception) -> {\n                    if (exception != null) {\n                        if (exception instanceof BKException\n                            && ((BKException)exception).getCode() == BKException.Code.TooManyRequestsException) {\n                            callback.readEntriesFailed(createManagedLedgerException(exception), ctx);\n                        } else {\n                            ml.invalidateLedgerHandle(lh, exception);\n                            ManagedLedgerException mlException = createManagedLedgerException(exception);\n                            callback.readEntriesFailed(mlException, ctx);\n                        }\n                        return;\n                    }\n\n                    checkNotNull(ml.getName());\n                    checkNotNull(ml.getExecutor());\n\n                    try {\n                        // We got the entries, we need to transform them to a List<> type\n                        long totalSize = 0;\n                        final List<EntryImpl> entriesToReturn\n                            = Lists.newArrayListWithExpectedSize(entriesToRead);\n                        for (LedgerEntry e : ledgerEntries) {\n                            EntryImpl entry = EntryImpl.create(e);\n\n                            entriesToReturn.add(entry);\n                            totalSize += entry.getLength();\n                        }\n\n                        manager.mlFactoryMBean.recordCacheMiss(entriesToReturn.size(), totalSize);\n                        ml.getMBean().addReadEntriesSample(entriesToReturn.size(), totalSize);\n\n                        callback.readEntriesComplete((List) entriesToReturn, ctx);\n                    } finally {\n                        ledgerEntries.close();\n                    }\n                }, ml.getExecutor().chooseThread(ml.getName()));\n    }\n}\n```","source":"_posts/Pulsar-Consume-Msg.md","raw":"---\ntitle: Pulsar-Consume-Msg\ndate: 2019-06-13 19:11:45\ntags:\n---\n\n\n### 居然是从FLOW开始的！！！\n\ngetRange(Comparable, Comparable):109, RangeCache (org.apache.bookkeeper.mledger.util), RangeCache.java\nasyncReadEntry0(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):261, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java\nasyncReadEntry(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):238, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java\nasyncReadEntry(ReadHandle, long, long, boolean, OpReadEntry, Object):1553, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java\ninternalReadFromLedger(ReadHandle, OpReadEntry):1527, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java\nasyncReadEntries(OpReadEntry):1380, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java\nasyncReadEntries(int, AsyncCallbacks$ReadEntriesCallback, Object):476, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java\nasyncReadEntriesOrWait(int, AsyncCallbacks$ReadEntriesCallback, Object):594, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java\nreadMoreEntries():326, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java\nconsumerFlow(Consumer, int):240, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java\nconsumerFlow(Consumer, int):215, PersistentSubscription (org.apache.pulsar.broker.service.persistent), PersistentSubscription.java\nflowPermits(int):376, Consumer (org.apache.pulsar.broker.service), Consumer.java\nhandleFlow(PulsarApi$CommandFlow):1090, ServerCnx (org.apache.pulsar.broker.service), ServerCnx.java\nchannelRead(ChannelHandlerContext, Object):160, PulsarDecoder (org.apache.pulsar.common.api), PulsarDecoder.java\ninvokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(ChannelHandlerContext, CodecOutputList, int):323, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java\nchannelRead(ChannelHandlerContext, Object):297, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java\ninvokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nchannelRead(ChannelHandlerContext, Object):1434, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java\ninvokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\ninvokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java\nfireChannelRead(Object):965, DefaultChannelPipeline (io.netty.channel), DefaultChannelPipeline.java\nread():163, AbstractNioByteChannel$NioByteUnsafe (io.netty.channel.nio), AbstractNioByteChannel.java\nprocessSelectedKey(SelectionKey, AbstractNioChannel):656, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nprocessSelectedKeysOptimized():591, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nprocessSelectedKeys():508, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nrun():470, NioEventLoop (io.netty.channel.nio), NioEventLoop.java\nrun():909, SingleThreadEventExecutor$5 (io.netty.util.concurrent), SingleThreadEventExecutor.java\nrun():30, FastThreadLocalRunnable (io.netty.util.concurrent), FastThreadLocalRunnable.java\nrun():748, Thread (java.lang), Thread.java\n\n\n### 如果缓存中没有，那么就从bk中去读\n```\nprivate void asyncReadEntry0(ReadHandle lh, long firstEntry, long lastEntry, boolean isSlowestReader,\n        final ReadEntriesCallback callback, Object ctx) {\n    final long ledgerId = lh.getId();\n    final int entriesToRead = (int) (lastEntry - firstEntry) + 1;\n    final PositionImpl firstPosition = PositionImpl.get(lh.getId(), firstEntry);\n    final PositionImpl lastPosition = PositionImpl.get(lh.getId(), lastEntry);\n\n    if (log.isDebugEnabled()) {\n        log.debug(\"[{}] Reading entries range ledger {}: {} to {}\", ml.getName(), ledgerId, firstEntry, lastEntry);\n    }\n\n    Collection<EntryImpl> cachedEntries = entries.getRange(firstPosition, lastPosition);\n\n    if (cachedEntries.size() == entriesToRead) {\n        long totalCachedSize = 0;\n        final List<EntryImpl> entriesToReturn = Lists.newArrayListWithExpectedSize(entriesToRead);\n\n        // All entries found in cache\n        for (EntryImpl entry : cachedEntries) {\n            entriesToReturn.add(EntryImpl.create(entry));\n            totalCachedSize += entry.getLength();\n            entry.release();\n        }\n\n        manager.mlFactoryMBean.recordCacheHits(entriesToReturn.size(), totalCachedSize);\n        if (log.isDebugEnabled()) {\n            log.debug(\"[{}] Ledger {} -- Found in cache entries: {}-{}\", ml.getName(), ledgerId, firstEntry,\n                    lastEntry);\n        }\n\n        callback.readEntriesComplete((List) entriesToReturn, ctx);\n\n    } else {\n        if (!cachedEntries.isEmpty()) {\n            cachedEntries.forEach(entry -> entry.release());\n        }\n\n        // Read all the entries from bookkeeper\n        lh.readAsync(firstEntry, lastEntry).whenCompleteAsync(\n                (ledgerEntries, exception) -> {\n                    if (exception != null) {\n                        if (exception instanceof BKException\n                            && ((BKException)exception).getCode() == BKException.Code.TooManyRequestsException) {\n                            callback.readEntriesFailed(createManagedLedgerException(exception), ctx);\n                        } else {\n                            ml.invalidateLedgerHandle(lh, exception);\n                            ManagedLedgerException mlException = createManagedLedgerException(exception);\n                            callback.readEntriesFailed(mlException, ctx);\n                        }\n                        return;\n                    }\n\n                    checkNotNull(ml.getName());\n                    checkNotNull(ml.getExecutor());\n\n                    try {\n                        // We got the entries, we need to transform them to a List<> type\n                        long totalSize = 0;\n                        final List<EntryImpl> entriesToReturn\n                            = Lists.newArrayListWithExpectedSize(entriesToRead);\n                        for (LedgerEntry e : ledgerEntries) {\n                            EntryImpl entry = EntryImpl.create(e);\n\n                            entriesToReturn.add(entry);\n                            totalSize += entry.getLength();\n                        }\n\n                        manager.mlFactoryMBean.recordCacheMiss(entriesToReturn.size(), totalSize);\n                        ml.getMBean().addReadEntriesSample(entriesToReturn.size(), totalSize);\n\n                        callback.readEntriesComplete((List) entriesToReturn, ctx);\n                    } finally {\n                        ledgerEntries.close();\n                    }\n                }, ml.getExecutor().chooseThread(ml.getName()));\n    }\n}\n```","slug":"Pulsar-Consume-Msg","published":1,"updated":"2019-09-28T08:51:00.914Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84k004ov1np3uevhkgc","content":"<h3 id=\"居然是从FLOW开始的！！！\"><a href=\"#居然是从FLOW开始的！！！\" class=\"headerlink\" title=\"居然是从FLOW开始的！！！\"></a>居然是从FLOW开始的！！！</h3><p>getRange(Comparable, Comparable):109, RangeCache (org.apache.bookkeeper.mledger.util), RangeCache.java<br>asyncReadEntry0(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):261, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java<br>asyncReadEntry(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):238, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java<br>asyncReadEntry(ReadHandle, long, long, boolean, OpReadEntry, Object):1553, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java<br>internalReadFromLedger(ReadHandle, OpReadEntry):1527, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java<br>asyncReadEntries(OpReadEntry):1380, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java<br>asyncReadEntries(int, AsyncCallbacks$ReadEntriesCallback, Object):476, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java<br>asyncReadEntriesOrWait(int, AsyncCallbacks$ReadEntriesCallback, Object):594, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java<br>readMoreEntries():326, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java<br>consumerFlow(Consumer, int):240, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java<br>consumerFlow(Consumer, int):215, PersistentSubscription (org.apache.pulsar.broker.service.persistent), PersistentSubscription.java<br>flowPermits(int):376, Consumer (org.apache.pulsar.broker.service), Consumer.java<br>handleFlow(PulsarApi$CommandFlow):1090, ServerCnx (org.apache.pulsar.broker.service), ServerCnx.java<br>channelRead(ChannelHandlerContext, Object):160, PulsarDecoder (org.apache.pulsar.common.api), PulsarDecoder.java<br>invokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>invokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>fireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>fireChannelRead(ChannelHandlerContext, CodecOutputList, int):323, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java<br>channelRead(ChannelHandlerContext, Object):297, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java<br>invokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>invokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>fireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>channelRead(ChannelHandlerContext, Object):1434, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java<br>invokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>invokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>fireChannelRead(Object):965, DefaultChannelPipeline (io.netty.channel), DefaultChannelPipeline.java<br>read():163, AbstractNioByteChannel$NioByteUnsafe (io.netty.channel.nio), AbstractNioByteChannel.java<br>processSelectedKey(SelectionKey, AbstractNioChannel):656, NioEventLoop (io.netty.channel.nio), NioEventLoop.java<br>processSelectedKeysOptimized():591, NioEventLoop (io.netty.channel.nio), NioEventLoop.java<br>processSelectedKeys():508, NioEventLoop (io.netty.channel.nio), NioEventLoop.java<br>run():470, NioEventLoop (io.netty.channel.nio), NioEventLoop.java<br>run():909, SingleThreadEventExecutor$5 (io.netty.util.concurrent), SingleThreadEventExecutor.java<br>run():30, FastThreadLocalRunnable (io.netty.util.concurrent), FastThreadLocalRunnable.java<br>run():748, Thread (java.lang), Thread.java</p>\n<h3 id=\"如果缓存中没有，那么就从bk中去读\"><a href=\"#如果缓存中没有，那么就从bk中去读\" class=\"headerlink\" title=\"如果缓存中没有，那么就从bk中去读\"></a>如果缓存中没有，那么就从bk中去读</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private void asyncReadEntry0(ReadHandle lh, long firstEntry, long lastEntry, boolean isSlowestReader,</span><br><span class=\"line\">        final ReadEntriesCallback callback, Object ctx) &#123;</span><br><span class=\"line\">    final long ledgerId = lh.getId();</span><br><span class=\"line\">    final int entriesToRead = (int) (lastEntry - firstEntry) + 1;</span><br><span class=\"line\">    final PositionImpl firstPosition = PositionImpl.get(lh.getId(), firstEntry);</span><br><span class=\"line\">    final PositionImpl lastPosition = PositionImpl.get(lh.getId(), lastEntry);</span><br><span class=\"line\"></span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(&quot;[&#123;&#125;] Reading entries range ledger &#123;&#125;: &#123;&#125; to &#123;&#125;&quot;, ml.getName(), ledgerId, firstEntry, lastEntry);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    Collection&lt;EntryImpl&gt; cachedEntries = entries.getRange(firstPosition, lastPosition);</span><br><span class=\"line\"></span><br><span class=\"line\">    if (cachedEntries.size() == entriesToRead) &#123;</span><br><span class=\"line\">        long totalCachedSize = 0;</span><br><span class=\"line\">        final List&lt;EntryImpl&gt; entriesToReturn = Lists.newArrayListWithExpectedSize(entriesToRead);</span><br><span class=\"line\"></span><br><span class=\"line\">        // All entries found in cache</span><br><span class=\"line\">        for (EntryImpl entry : cachedEntries) &#123;</span><br><span class=\"line\">            entriesToReturn.add(EntryImpl.create(entry));</span><br><span class=\"line\">            totalCachedSize += entry.getLength();</span><br><span class=\"line\">            entry.release();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        manager.mlFactoryMBean.recordCacheHits(entriesToReturn.size(), totalCachedSize);</span><br><span class=\"line\">        if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">            log.debug(&quot;[&#123;&#125;] Ledger &#123;&#125; -- Found in cache entries: &#123;&#125;-&#123;&#125;&quot;, ml.getName(), ledgerId, firstEntry,</span><br><span class=\"line\">                    lastEntry);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        callback.readEntriesComplete((List) entriesToReturn, ctx);</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        if (!cachedEntries.isEmpty()) &#123;</span><br><span class=\"line\">            cachedEntries.forEach(entry -&gt; entry.release());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        // Read all the entries from bookkeeper</span><br><span class=\"line\">        lh.readAsync(firstEntry, lastEntry).whenCompleteAsync(</span><br><span class=\"line\">                (ledgerEntries, exception) -&gt; &#123;</span><br><span class=\"line\">                    if (exception != null) &#123;</span><br><span class=\"line\">                        if (exception instanceof BKException</span><br><span class=\"line\">                            &amp;&amp; ((BKException)exception).getCode() == BKException.Code.TooManyRequestsException) &#123;</span><br><span class=\"line\">                            callback.readEntriesFailed(createManagedLedgerException(exception), ctx);</span><br><span class=\"line\">                        &#125; else &#123;</span><br><span class=\"line\">                            ml.invalidateLedgerHandle(lh, exception);</span><br><span class=\"line\">                            ManagedLedgerException mlException = createManagedLedgerException(exception);</span><br><span class=\"line\">                            callback.readEntriesFailed(mlException, ctx);</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        return;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                    checkNotNull(ml.getName());</span><br><span class=\"line\">                    checkNotNull(ml.getExecutor());</span><br><span class=\"line\"></span><br><span class=\"line\">                    try &#123;</span><br><span class=\"line\">                        // We got the entries, we need to transform them to a List&lt;&gt; type</span><br><span class=\"line\">                        long totalSize = 0;</span><br><span class=\"line\">                        final List&lt;EntryImpl&gt; entriesToReturn</span><br><span class=\"line\">                            = Lists.newArrayListWithExpectedSize(entriesToRead);</span><br><span class=\"line\">                        for (LedgerEntry e : ledgerEntries) &#123;</span><br><span class=\"line\">                            EntryImpl entry = EntryImpl.create(e);</span><br><span class=\"line\"></span><br><span class=\"line\">                            entriesToReturn.add(entry);</span><br><span class=\"line\">                            totalSize += entry.getLength();</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                        manager.mlFactoryMBean.recordCacheMiss(entriesToReturn.size(), totalSize);</span><br><span class=\"line\">                        ml.getMBean().addReadEntriesSample(entriesToReturn.size(), totalSize);</span><br><span class=\"line\"></span><br><span class=\"line\">                        callback.readEntriesComplete((List) entriesToReturn, ctx);</span><br><span class=\"line\">                    &#125; finally &#123;</span><br><span class=\"line\">                        ledgerEntries.close();</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;, ml.getExecutor().chooseThread(ml.getName()));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"居然是从FLOW开始的！！！\"><a href=\"#居然是从FLOW开始的！！！\" class=\"headerlink\" title=\"居然是从FLOW开始的！！！\"></a>居然是从FLOW开始的！！！</h3><p>getRange(Comparable, Comparable):109, RangeCache (org.apache.bookkeeper.mledger.util), RangeCache.java<br>asyncReadEntry0(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):261, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java<br>asyncReadEntry(ReadHandle, long, long, boolean, AsyncCallbacks$ReadEntriesCallback, Object):238, EntryCacheImpl (org.apache.bookkeeper.mledger.impl), EntryCacheImpl.java<br>asyncReadEntry(ReadHandle, long, long, boolean, OpReadEntry, Object):1553, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java<br>internalReadFromLedger(ReadHandle, OpReadEntry):1527, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java<br>asyncReadEntries(OpReadEntry):1380, ManagedLedgerImpl (org.apache.bookkeeper.mledger.impl), ManagedLedgerImpl.java<br>asyncReadEntries(int, AsyncCallbacks$ReadEntriesCallback, Object):476, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java<br>asyncReadEntriesOrWait(int, AsyncCallbacks$ReadEntriesCallback, Object):594, ManagedCursorImpl (org.apache.bookkeeper.mledger.impl), ManagedCursorImpl.java<br>readMoreEntries():326, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java<br>consumerFlow(Consumer, int):240, PersistentDispatcherMultipleConsumers (org.apache.pulsar.broker.service.persistent), PersistentDispatcherMultipleConsumers.java<br>consumerFlow(Consumer, int):215, PersistentSubscription (org.apache.pulsar.broker.service.persistent), PersistentSubscription.java<br>flowPermits(int):376, Consumer (org.apache.pulsar.broker.service), Consumer.java<br>handleFlow(PulsarApi$CommandFlow):1090, ServerCnx (org.apache.pulsar.broker.service), ServerCnx.java<br>channelRead(ChannelHandlerContext, Object):160, PulsarDecoder (org.apache.pulsar.common.api), PulsarDecoder.java<br>invokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>invokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>fireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>fireChannelRead(ChannelHandlerContext, CodecOutputList, int):323, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java<br>channelRead(ChannelHandlerContext, Object):297, ByteToMessageDecoder (io.netty.handler.codec), ByteToMessageDecoder.java<br>invokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>invokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>fireChannelRead(Object):340, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>channelRead(ChannelHandlerContext, Object):1434, DefaultChannelPipeline$HeadContext (io.netty.channel), DefaultChannelPipeline.java<br>invokeChannelRead(Object):362, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>invokeChannelRead(AbstractChannelHandlerContext, Object):348, AbstractChannelHandlerContext (io.netty.channel), AbstractChannelHandlerContext.java<br>fireChannelRead(Object):965, DefaultChannelPipeline (io.netty.channel), DefaultChannelPipeline.java<br>read():163, AbstractNioByteChannel$NioByteUnsafe (io.netty.channel.nio), AbstractNioByteChannel.java<br>processSelectedKey(SelectionKey, AbstractNioChannel):656, NioEventLoop (io.netty.channel.nio), NioEventLoop.java<br>processSelectedKeysOptimized():591, NioEventLoop (io.netty.channel.nio), NioEventLoop.java<br>processSelectedKeys():508, NioEventLoop (io.netty.channel.nio), NioEventLoop.java<br>run():470, NioEventLoop (io.netty.channel.nio), NioEventLoop.java<br>run():909, SingleThreadEventExecutor$5 (io.netty.util.concurrent), SingleThreadEventExecutor.java<br>run():30, FastThreadLocalRunnable (io.netty.util.concurrent), FastThreadLocalRunnable.java<br>run():748, Thread (java.lang), Thread.java</p>\n<h3 id=\"如果缓存中没有，那么就从bk中去读\"><a href=\"#如果缓存中没有，那么就从bk中去读\" class=\"headerlink\" title=\"如果缓存中没有，那么就从bk中去读\"></a>如果缓存中没有，那么就从bk中去读</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private void asyncReadEntry0(ReadHandle lh, long firstEntry, long lastEntry, boolean isSlowestReader,</span><br><span class=\"line\">        final ReadEntriesCallback callback, Object ctx) &#123;</span><br><span class=\"line\">    final long ledgerId = lh.getId();</span><br><span class=\"line\">    final int entriesToRead = (int) (lastEntry - firstEntry) + 1;</span><br><span class=\"line\">    final PositionImpl firstPosition = PositionImpl.get(lh.getId(), firstEntry);</span><br><span class=\"line\">    final PositionImpl lastPosition = PositionImpl.get(lh.getId(), lastEntry);</span><br><span class=\"line\"></span><br><span class=\"line\">    if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">        log.debug(&quot;[&#123;&#125;] Reading entries range ledger &#123;&#125;: &#123;&#125; to &#123;&#125;&quot;, ml.getName(), ledgerId, firstEntry, lastEntry);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    Collection&lt;EntryImpl&gt; cachedEntries = entries.getRange(firstPosition, lastPosition);</span><br><span class=\"line\"></span><br><span class=\"line\">    if (cachedEntries.size() == entriesToRead) &#123;</span><br><span class=\"line\">        long totalCachedSize = 0;</span><br><span class=\"line\">        final List&lt;EntryImpl&gt; entriesToReturn = Lists.newArrayListWithExpectedSize(entriesToRead);</span><br><span class=\"line\"></span><br><span class=\"line\">        // All entries found in cache</span><br><span class=\"line\">        for (EntryImpl entry : cachedEntries) &#123;</span><br><span class=\"line\">            entriesToReturn.add(EntryImpl.create(entry));</span><br><span class=\"line\">            totalCachedSize += entry.getLength();</span><br><span class=\"line\">            entry.release();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        manager.mlFactoryMBean.recordCacheHits(entriesToReturn.size(), totalCachedSize);</span><br><span class=\"line\">        if (log.isDebugEnabled()) &#123;</span><br><span class=\"line\">            log.debug(&quot;[&#123;&#125;] Ledger &#123;&#125; -- Found in cache entries: &#123;&#125;-&#123;&#125;&quot;, ml.getName(), ledgerId, firstEntry,</span><br><span class=\"line\">                    lastEntry);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        callback.readEntriesComplete((List) entriesToReturn, ctx);</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        if (!cachedEntries.isEmpty()) &#123;</span><br><span class=\"line\">            cachedEntries.forEach(entry -&gt; entry.release());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        // Read all the entries from bookkeeper</span><br><span class=\"line\">        lh.readAsync(firstEntry, lastEntry).whenCompleteAsync(</span><br><span class=\"line\">                (ledgerEntries, exception) -&gt; &#123;</span><br><span class=\"line\">                    if (exception != null) &#123;</span><br><span class=\"line\">                        if (exception instanceof BKException</span><br><span class=\"line\">                            &amp;&amp; ((BKException)exception).getCode() == BKException.Code.TooManyRequestsException) &#123;</span><br><span class=\"line\">                            callback.readEntriesFailed(createManagedLedgerException(exception), ctx);</span><br><span class=\"line\">                        &#125; else &#123;</span><br><span class=\"line\">                            ml.invalidateLedgerHandle(lh, exception);</span><br><span class=\"line\">                            ManagedLedgerException mlException = createManagedLedgerException(exception);</span><br><span class=\"line\">                            callback.readEntriesFailed(mlException, ctx);</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                        return;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                    checkNotNull(ml.getName());</span><br><span class=\"line\">                    checkNotNull(ml.getExecutor());</span><br><span class=\"line\"></span><br><span class=\"line\">                    try &#123;</span><br><span class=\"line\">                        // We got the entries, we need to transform them to a List&lt;&gt; type</span><br><span class=\"line\">                        long totalSize = 0;</span><br><span class=\"line\">                        final List&lt;EntryImpl&gt; entriesToReturn</span><br><span class=\"line\">                            = Lists.newArrayListWithExpectedSize(entriesToRead);</span><br><span class=\"line\">                        for (LedgerEntry e : ledgerEntries) &#123;</span><br><span class=\"line\">                            EntryImpl entry = EntryImpl.create(e);</span><br><span class=\"line\"></span><br><span class=\"line\">                            entriesToReturn.add(entry);</span><br><span class=\"line\">                            totalSize += entry.getLength();</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                        manager.mlFactoryMBean.recordCacheMiss(entriesToReturn.size(), totalSize);</span><br><span class=\"line\">                        ml.getMBean().addReadEntriesSample(entriesToReturn.size(), totalSize);</span><br><span class=\"line\"></span><br><span class=\"line\">                        callback.readEntriesComplete((List) entriesToReturn, ctx);</span><br><span class=\"line\">                    &#125; finally &#123;</span><br><span class=\"line\">                        ledgerEntries.close();</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;, ml.getExecutor().chooseThread(ml.getName()));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Pulsar-Produce-Msg","date":"2019-06-14T03:43:31.000Z","_content":"\n\n","source":"_posts/Pulsar-Produce-Msg.md","raw":"---\ntitle: Pulsar-Produce-Msg\ndate: 2019-06-14 11:43:31\ntags:\n---\n\n\n","slug":"Pulsar-Produce-Msg","published":1,"updated":"2019-09-28T08:51:00.914Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84k004pv1npavqbzg30","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"RocketMQ——Consumer Rebalance 原理分析","date":"2017-09-25T08:58:43.000Z","_content":"\n### 细节控\nhttps://www.jianshu.com/p/fac642f3c1af?utm_source=oschina-app\n```\n根据isTransferMsgByHeap的设置情况（默认为true），选择下面两种方式之一来真正读取GetMessageResult的消息内容并返回至Consumer端；\n方式1：使用JDK NIO的ByteBuffer，循环地读取存有消息内容的messageBufferList至堆内内存中，返回byte[]字节数组，并设置到响应的body中；然后，通过RPC通信组件—NettyRemotingServer发送响应至Consumer端；\n方式2：采用基于Zero-Copy的Netty组件的FileRegion，其包装的“FileChannel.tranferTo”实现文件传输，可以直接将文件缓冲区的数据发送至通信目标通道Channel中，避免了通过循环write方式导致的内存拷贝开销，这种方式性能上更优；\n\n作者：癫狂侠\n链接：https://www.jianshu.com/p/fac642f3c1af\n來源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n```\n\n### ProcessOn配图\nhttps://processon.com/diagraming/5badd204e4b075b9fe5b5d59\n\n\n以topic为维度，开始进行Rebalance\n以集群模式为例，先调用`List<String> cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup)`找到所有Consumer，然后根据topic路由信息，找到所有的MessageQueue。举个例子，有8个MessageQueue，4个Consumer,可以把MessageQueue理解为任务队列，4个Consumer大家一起分下任务，默认是平均分配（AllocateMessageQueueStrategy）策略，即说好，大家一人固定拉取并消费2个队列，如果队列的数量或者Consumer的数量不变，那这个关系就不要打破。可能有人要问了，这个给Consumer分配任务的工作，总得由一个老大哥（Leader）来执行吧，要么是Consumer里面有个Leader，要么是将该模块给集群协调者来做，不然怎么保证大家的分的方式都一样嘞。但RocketMQ恰恰是由每个Consumer各自都来做这个分配，秘诀在于下面两行代码\n```\nCollections.sort(mqAll);\nCollections.sort(cidAll);\n```\n当大家获取的mqAll和cidAll集合内容和顺序都一样，按照AllocateMessageQueueAveragely#allocate的分配方式，每个Consumer就能获取到属于自己的任务队列。\n\n```\nprivate void rebalanceByTopic(final String topic, final boolean isOrder) {\n    switch (messageModel) {\n        case BROADCASTING: {\n            Set<MessageQueue> mqSet = this.topicSubscribeInfoTable.get(topic);\n            if (mqSet != null) {\n                boolean changed = this.updateProcessQueueTableInRebalance(topic, mqSet, isOrder);\n                if (changed) {\n                    this.messageQueueChanged(topic, mqSet, mqSet);\n                    log.info(\"messageQueueChanged {} {} {} {}\",\n                        consumerGroup,\n                        topic,\n                        mqSet,\n                        mqSet);\n                }\n            } else {\n                log.warn(\"doRebalance, {}, but the topic[{}] not exist.\", consumerGroup, topic);\n            }\n            break;\n        }\n        case CLUSTERING: {\n            Set<MessageQueue> mqSet = this.topicSubscribeInfoTable.get(topic);\n            List<String> cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);\n            if (null == mqSet) {\n                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {\n                    log.warn(\"doRebalance, {}, but the topic[{}] not exist.\", consumerGroup, topic);\n                }\n            }\n\n            if (null == cidAll) {\n                log.warn(\"doRebalance, {} {}, get consumer id list failed\", consumerGroup, topic);\n            }\n\n            if (mqSet != null && cidAll != null) {\n                List<MessageQueue> mqAll = new ArrayList<MessageQueue>();\n                mqAll.addAll(mqSet);\n\n                Collections.sort(mqAll);\n                Collections.sort(cidAll);\n\n                AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy;\n\n                List<MessageQueue> allocateResult = null;\n                try {\n                    allocateResult = strategy.allocate(\n                        this.consumerGroup,\n                        this.mQClientFactory.getClientId(),\n                        mqAll,\n                        cidAll);\n                } catch (Throwable e) {\n                    log.error(\"AllocateMessageQueueStrategy.allocate Exception. allocateMessageQueueStrategyName={}\", strategy.getName(),\n                        e);\n                    return;\n                }\n\n                Set<MessageQueue> allocateResultSet = new HashSet<MessageQueue>();\n                if (allocateResult != null) {\n                    allocateResultSet.addAll(allocateResult);\n                }\n\n                boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder);\n                if (changed) {\n                    log.info(\n                        \"rebalanced result changed. allocateMessageQueueStrategyName={}, group={}, topic={}, clientId={}, mqAllSize={}, cidAllSize={}, rebalanceResultSize={}, rebalanceResultSet={}\",\n                        strategy.getName(), consumerGroup, topic, this.mQClientFactory.getClientId(), mqSet.size(), cidAll.size(),\n                        allocateResultSet.size(), allocateResultSet);\n                    this.messageQueueChanged(topic, mqSet, allocateResultSet);\n                }\n            }\n            break;\n        }\n        default:\n            break;\n    }\n}\n``` \n\n在确定了当前Consumer需要拉取消费的队列后，如果这个关系发生了变化，那要删除以前正在消费，但是现在不用消费的队列。比如，当前Consumer本来被分到了MessageQueue1和MessageQueue3，但是新加入两个Consumer，重新分配（ReBalance）后，当前消费者不再需要消费MessageQueue3了，那需要把这个关系给删除掉。\n``` RebalanceImpl#updateProcessQueueTableInRebalance\nIterator<Entry<MessageQueue, ProcessQueue>> it = this.processQueueTable.entrySet().iterator();\nwhile (it.hasNext()) {\n    Entry<MessageQueue, ProcessQueue> next = it.next();\n    MessageQueue mq = next.getKey();\n    ProcessQueue pq = next.getValue();\n\n    if (mq.getTopic().equals(topic)) {\n        if (!mqSet.contains(mq)) {\n            pq.setDropped(true);\n            if (this.removeUnnecessaryMessageQueue(mq, pq)) {\n                it.remove();\n                changed = true;\n                log.info(\"doRebalance, {}, remove unnecessary mq, {}\", consumerGroup, mq);\n            }\n        } else if (pq.isPullExpired()) {\n            switch (this.consumeType()) {\n                case CONSUME_ACTIVELY:\n                    break;\n                case CONSUME_PASSIVELY:\n                    pq.setDropped(true);\n                    if (this.removeUnnecessaryMessageQueue(mq, pq)) {\n                        it.remove();\n                        changed = true;\n                        log.error(\"[BUG]doRebalance, {}, remove unnecessary mq, {}, because pull is pause, so try to fixed it\",\n                            consumerGroup, mq);\n                    }\n                    break;\n                default:\n                    break;\n            }\n        }\n    }\n}\n```\n\n删除多余的消费关系后，当前Consumer就要开始给`每一个被分配到的MessageQueue`发送消息拉取请求（PullRequest）。\n``` RebalanceImpl#updateProcessQueueTableInRebalance\nList<PullRequest> pullRequestList = new ArrayList<PullRequest>();\nfor (MessageQueue mq : mqSet) {\n    if (!this.processQueueTable.containsKey(mq)) {\n        if (isOrder && !this.lock(mq)) {\n            log.warn(\"doRebalance, {}, add a new mq failed, {}, because lock failed\", consumerGroup, mq);\n            continue;\n        }\n\n        this.removeDirtyOffset(mq);\n        ProcessQueue pq = new ProcessQueue();\n        long nextOffset = this.computePullFromWhere(mq);\n        if (nextOffset >= 0) {\n            ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq);\n            if (pre != null) {\n                log.info(\"doRebalance, {}, mq already exists, {}\", consumerGroup, mq);\n            } else {\n                log.info(\"doRebalance, {}, add a new mq, {}\", consumerGroup, mq);\n                PullRequest pullRequest = new PullRequest();\n                pullRequest.setConsumerGroup(consumerGroup);\n                pullRequest.setNextOffset(nextOffset);\n                pullRequest.setMessageQueue(mq);\n                pullRequest.setProcessQueue(pq);\n                pullRequestList.add(pullRequest);\n                changed = true;\n            }\n        } else {\n            log.warn(\"doRebalance, {}, add new mq failed, {}\", consumerGroup, mq);\n        }\n    }\n}\n\nthis.dispatchPullRequest(pullRequestList);\n```\n\n```\npublic void dispatchPullRequest(List<PullRequest> pullRequestList) {\n    for (PullRequest pullRequest : pullRequestList) {\n        this.defaultMQPushConsumerImpl.executePullRequestImmediately(pullRequest);\n        log.info(\"doRebalance, {}, add a new pull request {}\", consumerGroup, pullRequest);\n    }\n}\n```\n\n以上所有的代码全部都是RebalanceService，用于管理Consumer和MessageQueue之间的对应关系，以及当两者任一一个数量非常变化时的重新均衡。消息真正拉取是由PullMessageService来处理的，注意到，它其实是一个线程。`class PullMessageService extends ServiceThread`，前面RebalanceSerivce的代码是在`class RebalanceService extends ServiceThread`Rebalance的线程中。现在是Rebalance线程要将PullRequest数据给PullMessage线程，肯定是通过阻塞队列，就是pullRequestQueue。\n```\npublic void executePullRequestImmediately(final PullRequest pullRequest) {\n    try {\n        this.pullRequestQueue.put(pullRequest);\n    } catch (InterruptedException e) {\n        log.error(\"executePullRequestImmediately pullRequestQueue.put\", e);\n    }\n}\n```\n随后就是从pullRequestQueue拉取pullRequest，去做真正的消息拉取。\n```\n@Override\npublic void run() {\n    log.info(this.getServiceName() + \" service started\");\n\n    while (!this.isStopped()) {\n        try {\n            PullRequest pullRequest = this.pullRequestQueue.take();\n            this.pullMessage(pullRequest);\n        } catch (InterruptedException ignored) {\n        } catch (Exception e) {\n            log.error(\"Pull Message Service Run Method exception\", e);\n        }\n    }\n\n    log.info(this.getServiceName() + \" service end\");\n}\n```\n真正拉取的部分，是DefaultMQPushConsumerImpl#pullMessage方法中的实现。\n``` DefaultMQPushConsumerImpl#pullMessage\n    final ProcessQueue processQueue = pullRequest.getProcessQueue();\n    if (processQueue.isDropped()) {\n        log.info(\"the pull request[{}] is dropped.\", pullRequest.toString());\n        return;\n    }\n```\nProcessQueue会多次出现在正在拉取和消费的代码中，它存放的是某一个MessageQueue的`拉取后，但并未被消费的消息集合`，消息内部用用TreeMap`TreeMap<Long, MessageExt> msgTreeMap`来存储，用MessageQueueOffset来排序，以达到单队列内部严格的顺序。经过Rebalance后，当前Consumer可能不会再消费曾经被分配到的MessageQueue，自然也就无需再次消费之前没有消费完的数据。\n```\nlong cachedMessageCount = processQueue.getMsgCount().get();\nlong cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024);\n\nif (cachedMessageCount > this.defaultMQPushConsumer.getPullThresholdForQueue()) {\n    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);\n    if ((queueFlowControlTimes++ % 1000) == 0) {\n        log.warn(\n            \"the cached message count exceeds the threshold {}, so do flow control, minOffset={}, maxOffset={}, count={}, size={} MiB, pullRequest={}, flowControlTimes={}\",\n            this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);\n    }\n    return;\n}\n\nif (cachedMessageSizeInMiB > this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) {\n    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);\n    if ((queueFlowControlTimes++ % 1000) == 0) {\n        log.warn(\n            \"the cached message size exceeds the threshold {} MiB, so do flow control, minOffset={}, maxOffset={}, count={}, size={} MiB, pullRequest={}, flowControlTimes={}\",\n            this.defaultMQPushConsumer.getPullThresholdSizeForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);\n    }\n    return;\n}\n\nif (!this.consumeOrderly) {\n    if (processQueue.getMaxSpan() > this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) {\n        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);\n        if ((queueMaxSpanFlowControlTimes++ % 1000) == 0) {\n            log.warn(\n                \"the queue's messages, span too long, so do flow control, minOffset={}, maxOffset={}, maxSpan={}, pullRequest={}, flowControlTimes={}\",\n                processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), processQueue.getMaxSpan(),\n                pullRequest, queueMaxSpanFlowControlTimes);\n        }\n        return;\n    }\n}\n```\n以上描述了三种情况下，会让拉取消息限流。\n\n之后构造了一个非常复杂的`PullCallback`，其实就是描述调用`pullAPIWrapper.pullKernelImpl`后，对于各种结果的回调（Callback）。\n```\nPullCallback pullCallback = new PullCallback() {\n    @Override\n    public void onSuccess(PullResult pullResult) {\n        if (pullResult != null) {\n            pullResult = DefaultMQPushConsumerImpl.this.pullAPIWrapper.processPullResult(pullRequest.getMessageQueue(), pullResult,\n                subscriptionData);\n\n            switch (pullResult.getPullStatus()) {\n                case FOUND:\n                    // deal with this case\n                    break;\n                case NO_NEW_MSG:\n                    // deal with this case\n                    break;\n                case NO_MATCHED_MSG:\n                    // deal with this case\n                    break;\n                case OFFSET_ILLEGAL:\n                    // deal with this case\n                    break;\n                default:\n                    break;\n            }\n        }\n    }\n\n    @Override\n    public void onException(Throwable e) {\n        // deal with this case\n        DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);\n    }\n};\n```\n","source":"_posts/RocketMQ-Consumer-rebalance.md","raw":"---\ntitle: RocketMQ——Consumer Rebalance 原理分析\ndate: 2017-09-25 16:58:43\ntags: RocketMQ\n---\n\n### 细节控\nhttps://www.jianshu.com/p/fac642f3c1af?utm_source=oschina-app\n```\n根据isTransferMsgByHeap的设置情况（默认为true），选择下面两种方式之一来真正读取GetMessageResult的消息内容并返回至Consumer端；\n方式1：使用JDK NIO的ByteBuffer，循环地读取存有消息内容的messageBufferList至堆内内存中，返回byte[]字节数组，并设置到响应的body中；然后，通过RPC通信组件—NettyRemotingServer发送响应至Consumer端；\n方式2：采用基于Zero-Copy的Netty组件的FileRegion，其包装的“FileChannel.tranferTo”实现文件传输，可以直接将文件缓冲区的数据发送至通信目标通道Channel中，避免了通过循环write方式导致的内存拷贝开销，这种方式性能上更优；\n\n作者：癫狂侠\n链接：https://www.jianshu.com/p/fac642f3c1af\n來源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n```\n\n### ProcessOn配图\nhttps://processon.com/diagraming/5badd204e4b075b9fe5b5d59\n\n\n以topic为维度，开始进行Rebalance\n以集群模式为例，先调用`List<String> cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup)`找到所有Consumer，然后根据topic路由信息，找到所有的MessageQueue。举个例子，有8个MessageQueue，4个Consumer,可以把MessageQueue理解为任务队列，4个Consumer大家一起分下任务，默认是平均分配（AllocateMessageQueueStrategy）策略，即说好，大家一人固定拉取并消费2个队列，如果队列的数量或者Consumer的数量不变，那这个关系就不要打破。可能有人要问了，这个给Consumer分配任务的工作，总得由一个老大哥（Leader）来执行吧，要么是Consumer里面有个Leader，要么是将该模块给集群协调者来做，不然怎么保证大家的分的方式都一样嘞。但RocketMQ恰恰是由每个Consumer各自都来做这个分配，秘诀在于下面两行代码\n```\nCollections.sort(mqAll);\nCollections.sort(cidAll);\n```\n当大家获取的mqAll和cidAll集合内容和顺序都一样，按照AllocateMessageQueueAveragely#allocate的分配方式，每个Consumer就能获取到属于自己的任务队列。\n\n```\nprivate void rebalanceByTopic(final String topic, final boolean isOrder) {\n    switch (messageModel) {\n        case BROADCASTING: {\n            Set<MessageQueue> mqSet = this.topicSubscribeInfoTable.get(topic);\n            if (mqSet != null) {\n                boolean changed = this.updateProcessQueueTableInRebalance(topic, mqSet, isOrder);\n                if (changed) {\n                    this.messageQueueChanged(topic, mqSet, mqSet);\n                    log.info(\"messageQueueChanged {} {} {} {}\",\n                        consumerGroup,\n                        topic,\n                        mqSet,\n                        mqSet);\n                }\n            } else {\n                log.warn(\"doRebalance, {}, but the topic[{}] not exist.\", consumerGroup, topic);\n            }\n            break;\n        }\n        case CLUSTERING: {\n            Set<MessageQueue> mqSet = this.topicSubscribeInfoTable.get(topic);\n            List<String> cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);\n            if (null == mqSet) {\n                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {\n                    log.warn(\"doRebalance, {}, but the topic[{}] not exist.\", consumerGroup, topic);\n                }\n            }\n\n            if (null == cidAll) {\n                log.warn(\"doRebalance, {} {}, get consumer id list failed\", consumerGroup, topic);\n            }\n\n            if (mqSet != null && cidAll != null) {\n                List<MessageQueue> mqAll = new ArrayList<MessageQueue>();\n                mqAll.addAll(mqSet);\n\n                Collections.sort(mqAll);\n                Collections.sort(cidAll);\n\n                AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy;\n\n                List<MessageQueue> allocateResult = null;\n                try {\n                    allocateResult = strategy.allocate(\n                        this.consumerGroup,\n                        this.mQClientFactory.getClientId(),\n                        mqAll,\n                        cidAll);\n                } catch (Throwable e) {\n                    log.error(\"AllocateMessageQueueStrategy.allocate Exception. allocateMessageQueueStrategyName={}\", strategy.getName(),\n                        e);\n                    return;\n                }\n\n                Set<MessageQueue> allocateResultSet = new HashSet<MessageQueue>();\n                if (allocateResult != null) {\n                    allocateResultSet.addAll(allocateResult);\n                }\n\n                boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder);\n                if (changed) {\n                    log.info(\n                        \"rebalanced result changed. allocateMessageQueueStrategyName={}, group={}, topic={}, clientId={}, mqAllSize={}, cidAllSize={}, rebalanceResultSize={}, rebalanceResultSet={}\",\n                        strategy.getName(), consumerGroup, topic, this.mQClientFactory.getClientId(), mqSet.size(), cidAll.size(),\n                        allocateResultSet.size(), allocateResultSet);\n                    this.messageQueueChanged(topic, mqSet, allocateResultSet);\n                }\n            }\n            break;\n        }\n        default:\n            break;\n    }\n}\n``` \n\n在确定了当前Consumer需要拉取消费的队列后，如果这个关系发生了变化，那要删除以前正在消费，但是现在不用消费的队列。比如，当前Consumer本来被分到了MessageQueue1和MessageQueue3，但是新加入两个Consumer，重新分配（ReBalance）后，当前消费者不再需要消费MessageQueue3了，那需要把这个关系给删除掉。\n``` RebalanceImpl#updateProcessQueueTableInRebalance\nIterator<Entry<MessageQueue, ProcessQueue>> it = this.processQueueTable.entrySet().iterator();\nwhile (it.hasNext()) {\n    Entry<MessageQueue, ProcessQueue> next = it.next();\n    MessageQueue mq = next.getKey();\n    ProcessQueue pq = next.getValue();\n\n    if (mq.getTopic().equals(topic)) {\n        if (!mqSet.contains(mq)) {\n            pq.setDropped(true);\n            if (this.removeUnnecessaryMessageQueue(mq, pq)) {\n                it.remove();\n                changed = true;\n                log.info(\"doRebalance, {}, remove unnecessary mq, {}\", consumerGroup, mq);\n            }\n        } else if (pq.isPullExpired()) {\n            switch (this.consumeType()) {\n                case CONSUME_ACTIVELY:\n                    break;\n                case CONSUME_PASSIVELY:\n                    pq.setDropped(true);\n                    if (this.removeUnnecessaryMessageQueue(mq, pq)) {\n                        it.remove();\n                        changed = true;\n                        log.error(\"[BUG]doRebalance, {}, remove unnecessary mq, {}, because pull is pause, so try to fixed it\",\n                            consumerGroup, mq);\n                    }\n                    break;\n                default:\n                    break;\n            }\n        }\n    }\n}\n```\n\n删除多余的消费关系后，当前Consumer就要开始给`每一个被分配到的MessageQueue`发送消息拉取请求（PullRequest）。\n``` RebalanceImpl#updateProcessQueueTableInRebalance\nList<PullRequest> pullRequestList = new ArrayList<PullRequest>();\nfor (MessageQueue mq : mqSet) {\n    if (!this.processQueueTable.containsKey(mq)) {\n        if (isOrder && !this.lock(mq)) {\n            log.warn(\"doRebalance, {}, add a new mq failed, {}, because lock failed\", consumerGroup, mq);\n            continue;\n        }\n\n        this.removeDirtyOffset(mq);\n        ProcessQueue pq = new ProcessQueue();\n        long nextOffset = this.computePullFromWhere(mq);\n        if (nextOffset >= 0) {\n            ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq);\n            if (pre != null) {\n                log.info(\"doRebalance, {}, mq already exists, {}\", consumerGroup, mq);\n            } else {\n                log.info(\"doRebalance, {}, add a new mq, {}\", consumerGroup, mq);\n                PullRequest pullRequest = new PullRequest();\n                pullRequest.setConsumerGroup(consumerGroup);\n                pullRequest.setNextOffset(nextOffset);\n                pullRequest.setMessageQueue(mq);\n                pullRequest.setProcessQueue(pq);\n                pullRequestList.add(pullRequest);\n                changed = true;\n            }\n        } else {\n            log.warn(\"doRebalance, {}, add new mq failed, {}\", consumerGroup, mq);\n        }\n    }\n}\n\nthis.dispatchPullRequest(pullRequestList);\n```\n\n```\npublic void dispatchPullRequest(List<PullRequest> pullRequestList) {\n    for (PullRequest pullRequest : pullRequestList) {\n        this.defaultMQPushConsumerImpl.executePullRequestImmediately(pullRequest);\n        log.info(\"doRebalance, {}, add a new pull request {}\", consumerGroup, pullRequest);\n    }\n}\n```\n\n以上所有的代码全部都是RebalanceService，用于管理Consumer和MessageQueue之间的对应关系，以及当两者任一一个数量非常变化时的重新均衡。消息真正拉取是由PullMessageService来处理的，注意到，它其实是一个线程。`class PullMessageService extends ServiceThread`，前面RebalanceSerivce的代码是在`class RebalanceService extends ServiceThread`Rebalance的线程中。现在是Rebalance线程要将PullRequest数据给PullMessage线程，肯定是通过阻塞队列，就是pullRequestQueue。\n```\npublic void executePullRequestImmediately(final PullRequest pullRequest) {\n    try {\n        this.pullRequestQueue.put(pullRequest);\n    } catch (InterruptedException e) {\n        log.error(\"executePullRequestImmediately pullRequestQueue.put\", e);\n    }\n}\n```\n随后就是从pullRequestQueue拉取pullRequest，去做真正的消息拉取。\n```\n@Override\npublic void run() {\n    log.info(this.getServiceName() + \" service started\");\n\n    while (!this.isStopped()) {\n        try {\n            PullRequest pullRequest = this.pullRequestQueue.take();\n            this.pullMessage(pullRequest);\n        } catch (InterruptedException ignored) {\n        } catch (Exception e) {\n            log.error(\"Pull Message Service Run Method exception\", e);\n        }\n    }\n\n    log.info(this.getServiceName() + \" service end\");\n}\n```\n真正拉取的部分，是DefaultMQPushConsumerImpl#pullMessage方法中的实现。\n``` DefaultMQPushConsumerImpl#pullMessage\n    final ProcessQueue processQueue = pullRequest.getProcessQueue();\n    if (processQueue.isDropped()) {\n        log.info(\"the pull request[{}] is dropped.\", pullRequest.toString());\n        return;\n    }\n```\nProcessQueue会多次出现在正在拉取和消费的代码中，它存放的是某一个MessageQueue的`拉取后，但并未被消费的消息集合`，消息内部用用TreeMap`TreeMap<Long, MessageExt> msgTreeMap`来存储，用MessageQueueOffset来排序，以达到单队列内部严格的顺序。经过Rebalance后，当前Consumer可能不会再消费曾经被分配到的MessageQueue，自然也就无需再次消费之前没有消费完的数据。\n```\nlong cachedMessageCount = processQueue.getMsgCount().get();\nlong cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024);\n\nif (cachedMessageCount > this.defaultMQPushConsumer.getPullThresholdForQueue()) {\n    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);\n    if ((queueFlowControlTimes++ % 1000) == 0) {\n        log.warn(\n            \"the cached message count exceeds the threshold {}, so do flow control, minOffset={}, maxOffset={}, count={}, size={} MiB, pullRequest={}, flowControlTimes={}\",\n            this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);\n    }\n    return;\n}\n\nif (cachedMessageSizeInMiB > this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) {\n    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);\n    if ((queueFlowControlTimes++ % 1000) == 0) {\n        log.warn(\n            \"the cached message size exceeds the threshold {} MiB, so do flow control, minOffset={}, maxOffset={}, count={}, size={} MiB, pullRequest={}, flowControlTimes={}\",\n            this.defaultMQPushConsumer.getPullThresholdSizeForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);\n    }\n    return;\n}\n\nif (!this.consumeOrderly) {\n    if (processQueue.getMaxSpan() > this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) {\n        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);\n        if ((queueMaxSpanFlowControlTimes++ % 1000) == 0) {\n            log.warn(\n                \"the queue's messages, span too long, so do flow control, minOffset={}, maxOffset={}, maxSpan={}, pullRequest={}, flowControlTimes={}\",\n                processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), processQueue.getMaxSpan(),\n                pullRequest, queueMaxSpanFlowControlTimes);\n        }\n        return;\n    }\n}\n```\n以上描述了三种情况下，会让拉取消息限流。\n\n之后构造了一个非常复杂的`PullCallback`，其实就是描述调用`pullAPIWrapper.pullKernelImpl`后，对于各种结果的回调（Callback）。\n```\nPullCallback pullCallback = new PullCallback() {\n    @Override\n    public void onSuccess(PullResult pullResult) {\n        if (pullResult != null) {\n            pullResult = DefaultMQPushConsumerImpl.this.pullAPIWrapper.processPullResult(pullRequest.getMessageQueue(), pullResult,\n                subscriptionData);\n\n            switch (pullResult.getPullStatus()) {\n                case FOUND:\n                    // deal with this case\n                    break;\n                case NO_NEW_MSG:\n                    // deal with this case\n                    break;\n                case NO_MATCHED_MSG:\n                    // deal with this case\n                    break;\n                case OFFSET_ILLEGAL:\n                    // deal with this case\n                    break;\n                default:\n                    break;\n            }\n        }\n    }\n\n    @Override\n    public void onException(Throwable e) {\n        // deal with this case\n        DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);\n    }\n};\n```\n","slug":"RocketMQ-Consumer-rebalance","published":1,"updated":"2019-09-28T08:51:00.914Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84k004qv1npk3rhile2","content":"<h3 id=\"细节控\"><a href=\"#细节控\" class=\"headerlink\" title=\"细节控\"></a>细节控</h3><p><a href=\"https://www.jianshu.com/p/fac642f3c1af?utm_source=oschina-app\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/fac642f3c1af?utm_source=oschina-app</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">根据isTransferMsgByHeap的设置情况（默认为true），选择下面两种方式之一来真正读取GetMessageResult的消息内容并返回至Consumer端；</span><br><span class=\"line\">方式1：使用JDK NIO的ByteBuffer，循环地读取存有消息内容的messageBufferList至堆内内存中，返回byte[]字节数组，并设置到响应的body中；然后，通过RPC通信组件—NettyRemotingServer发送响应至Consumer端；</span><br><span class=\"line\">方式2：采用基于Zero-Copy的Netty组件的FileRegion，其包装的“FileChannel.tranferTo”实现文件传输，可以直接将文件缓冲区的数据发送至通信目标通道Channel中，避免了通过循环write方式导致的内存拷贝开销，这种方式性能上更优；</span><br><span class=\"line\"></span><br><span class=\"line\">作者：癫狂侠</span><br><span class=\"line\">链接：https://www.jianshu.com/p/fac642f3c1af</span><br><span class=\"line\">來源：简书</span><br><span class=\"line\">简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"ProcessOn配图\"><a href=\"#ProcessOn配图\" class=\"headerlink\" title=\"ProcessOn配图\"></a>ProcessOn配图</h3><p><a href=\"https://processon.com/diagraming/5badd204e4b075b9fe5b5d59\" target=\"_blank\" rel=\"noopener\">https://processon.com/diagraming/5badd204e4b075b9fe5b5d59</a></p>\n<p>以topic为维度，开始进行Rebalance<br>以集群模式为例，先调用<code>List&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup)</code>找到所有Consumer，然后根据topic路由信息，找到所有的MessageQueue。举个例子，有8个MessageQueue，4个Consumer,可以把MessageQueue理解为任务队列，4个Consumer大家一起分下任务，默认是平均分配（AllocateMessageQueueStrategy）策略，即说好，大家一人固定拉取并消费2个队列，如果队列的数量或者Consumer的数量不变，那这个关系就不要打破。可能有人要问了，这个给Consumer分配任务的工作，总得由一个老大哥（Leader）来执行吧，要么是Consumer里面有个Leader，要么是将该模块给集群协调者来做，不然怎么保证大家的分的方式都一样嘞。但RocketMQ恰恰是由每个Consumer各自都来做这个分配，秘诀在于下面两行代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Collections.sort(mqAll);</span><br><span class=\"line\">Collections.sort(cidAll);</span><br></pre></td></tr></table></figure>\n\n<p>当大家获取的mqAll和cidAll集合内容和顺序都一样，按照AllocateMessageQueueAveragely#allocate的分配方式，每个Consumer就能获取到属于自己的任务队列。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private void rebalanceByTopic(final String topic, final boolean isOrder) &#123;</span><br><span class=\"line\">    switch (messageModel) &#123;</span><br><span class=\"line\">        case BROADCASTING: &#123;</span><br><span class=\"line\">            Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic);</span><br><span class=\"line\">            if (mqSet != null) &#123;</span><br><span class=\"line\">                boolean changed = this.updateProcessQueueTableInRebalance(topic, mqSet, isOrder);</span><br><span class=\"line\">                if (changed) &#123;</span><br><span class=\"line\">                    this.messageQueueChanged(topic, mqSet, mqSet);</span><br><span class=\"line\">                    log.info(&quot;messageQueueChanged &#123;&#125; &#123;&#125; &#123;&#125; &#123;&#125;&quot;,</span><br><span class=\"line\">                        consumerGroup,</span><br><span class=\"line\">                        topic,</span><br><span class=\"line\">                        mqSet,</span><br><span class=\"line\">                        mqSet);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                log.warn(&quot;doRebalance, &#123;&#125;, but the topic[&#123;&#125;] not exist.&quot;, consumerGroup, topic);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        case CLUSTERING: &#123;</span><br><span class=\"line\">            Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic);</span><br><span class=\"line\">            List&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);</span><br><span class=\"line\">            if (null == mqSet) &#123;</span><br><span class=\"line\">                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123;</span><br><span class=\"line\">                    log.warn(&quot;doRebalance, &#123;&#125;, but the topic[&#123;&#125;] not exist.&quot;, consumerGroup, topic);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            if (null == cidAll) &#123;</span><br><span class=\"line\">                log.warn(&quot;doRebalance, &#123;&#125; &#123;&#125;, get consumer id list failed&quot;, consumerGroup, topic);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            if (mqSet != null &amp;&amp; cidAll != null) &#123;</span><br><span class=\"line\">                List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;();</span><br><span class=\"line\">                mqAll.addAll(mqSet);</span><br><span class=\"line\"></span><br><span class=\"line\">                Collections.sort(mqAll);</span><br><span class=\"line\">                Collections.sort(cidAll);</span><br><span class=\"line\"></span><br><span class=\"line\">                AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy;</span><br><span class=\"line\"></span><br><span class=\"line\">                List&lt;MessageQueue&gt; allocateResult = null;</span><br><span class=\"line\">                try &#123;</span><br><span class=\"line\">                    allocateResult = strategy.allocate(</span><br><span class=\"line\">                        this.consumerGroup,</span><br><span class=\"line\">                        this.mQClientFactory.getClientId(),</span><br><span class=\"line\">                        mqAll,</span><br><span class=\"line\">                        cidAll);</span><br><span class=\"line\">                &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">                    log.error(&quot;AllocateMessageQueueStrategy.allocate Exception. allocateMessageQueueStrategyName=&#123;&#125;&quot;, strategy.getName(),</span><br><span class=\"line\">                        e);</span><br><span class=\"line\">                    return;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                Set&lt;MessageQueue&gt; allocateResultSet = new HashSet&lt;MessageQueue&gt;();</span><br><span class=\"line\">                if (allocateResult != null) &#123;</span><br><span class=\"line\">                    allocateResultSet.addAll(allocateResult);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder);</span><br><span class=\"line\">                if (changed) &#123;</span><br><span class=\"line\">                    log.info(</span><br><span class=\"line\">                        &quot;rebalanced result changed. allocateMessageQueueStrategyName=&#123;&#125;, group=&#123;&#125;, topic=&#123;&#125;, clientId=&#123;&#125;, mqAllSize=&#123;&#125;, cidAllSize=&#123;&#125;, rebalanceResultSize=&#123;&#125;, rebalanceResultSet=&#123;&#125;&quot;,</span><br><span class=\"line\">                        strategy.getName(), consumerGroup, topic, this.mQClientFactory.getClientId(), mqSet.size(), cidAll.size(),</span><br><span class=\"line\">                        allocateResultSet.size(), allocateResultSet);</span><br><span class=\"line\">                    this.messageQueueChanged(topic, mqSet, allocateResultSet);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        default:</span><br><span class=\"line\">            break;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">``` </span><br><span class=\"line\"></span><br><span class=\"line\">在确定了当前Consumer需要拉取消费的队列后，如果这个关系发生了变化，那要删除以前正在消费，但是现在不用消费的队列。比如，当前Consumer本来被分到了MessageQueue1和MessageQueue3，但是新加入两个Consumer，重新分配（ReBalance）后，当前消费者不再需要消费MessageQueue3了，那需要把这个关系给删除掉。</span><br><span class=\"line\">``` RebalanceImpl#updateProcessQueueTableInRebalance</span><br><span class=\"line\">Iterator&lt;Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it = this.processQueueTable.entrySet().iterator();</span><br><span class=\"line\">while (it.hasNext()) &#123;</span><br><span class=\"line\">    Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next();</span><br><span class=\"line\">    MessageQueue mq = next.getKey();</span><br><span class=\"line\">    ProcessQueue pq = next.getValue();</span><br><span class=\"line\"></span><br><span class=\"line\">    if (mq.getTopic().equals(topic)) &#123;</span><br><span class=\"line\">        if (!mqSet.contains(mq)) &#123;</span><br><span class=\"line\">            pq.setDropped(true);</span><br><span class=\"line\">            if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123;</span><br><span class=\"line\">                it.remove();</span><br><span class=\"line\">                changed = true;</span><br><span class=\"line\">                log.info(&quot;doRebalance, &#123;&#125;, remove unnecessary mq, &#123;&#125;&quot;, consumerGroup, mq);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; else if (pq.isPullExpired()) &#123;</span><br><span class=\"line\">            switch (this.consumeType()) &#123;</span><br><span class=\"line\">                case CONSUME_ACTIVELY:</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                case CONSUME_PASSIVELY:</span><br><span class=\"line\">                    pq.setDropped(true);</span><br><span class=\"line\">                    if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123;</span><br><span class=\"line\">                        it.remove();</span><br><span class=\"line\">                        changed = true;</span><br><span class=\"line\">                        log.error(&quot;[BUG]doRebalance, &#123;&#125;, remove unnecessary mq, &#123;&#125;, because pull is pause, so try to fixed it&quot;,</span><br><span class=\"line\">                            consumerGroup, mq);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                default:</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>删除多余的消费关系后，当前Consumer就要开始给<code>每一个被分配到的MessageQueue</code>发送消息拉取请求（PullRequest）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;();</span><br><span class=\"line\">for (MessageQueue mq : mqSet) &#123;</span><br><span class=\"line\">    if (!this.processQueueTable.containsKey(mq)) &#123;</span><br><span class=\"line\">        if (isOrder &amp;&amp; !this.lock(mq)) &#123;</span><br><span class=\"line\">            log.warn(&quot;doRebalance, &#123;&#125;, add a new mq failed, &#123;&#125;, because lock failed&quot;, consumerGroup, mq);</span><br><span class=\"line\">            continue;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        this.removeDirtyOffset(mq);</span><br><span class=\"line\">        ProcessQueue pq = new ProcessQueue();</span><br><span class=\"line\">        long nextOffset = this.computePullFromWhere(mq);</span><br><span class=\"line\">        if (nextOffset &gt;= 0) &#123;</span><br><span class=\"line\">            ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq);</span><br><span class=\"line\">            if (pre != null) &#123;</span><br><span class=\"line\">                log.info(&quot;doRebalance, &#123;&#125;, mq already exists, &#123;&#125;&quot;, consumerGroup, mq);</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                log.info(&quot;doRebalance, &#123;&#125;, add a new mq, &#123;&#125;&quot;, consumerGroup, mq);</span><br><span class=\"line\">                PullRequest pullRequest = new PullRequest();</span><br><span class=\"line\">                pullRequest.setConsumerGroup(consumerGroup);</span><br><span class=\"line\">                pullRequest.setNextOffset(nextOffset);</span><br><span class=\"line\">                pullRequest.setMessageQueue(mq);</span><br><span class=\"line\">                pullRequest.setProcessQueue(pq);</span><br><span class=\"line\">                pullRequestList.add(pullRequest);</span><br><span class=\"line\">                changed = true;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            log.warn(&quot;doRebalance, &#123;&#125;, add new mq failed, &#123;&#125;&quot;, consumerGroup, mq);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">this.dispatchPullRequest(pullRequestList);</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void dispatchPullRequest(List&lt;PullRequest&gt; pullRequestList) &#123;</span><br><span class=\"line\">    for (PullRequest pullRequest : pullRequestList) &#123;</span><br><span class=\"line\">        this.defaultMQPushConsumerImpl.executePullRequestImmediately(pullRequest);</span><br><span class=\"line\">        log.info(&quot;doRebalance, &#123;&#125;, add a new pull request &#123;&#125;&quot;, consumerGroup, pullRequest);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>以上所有的代码全部都是RebalanceService，用于管理Consumer和MessageQueue之间的对应关系，以及当两者任一一个数量非常变化时的重新均衡。消息真正拉取是由PullMessageService来处理的，注意到，它其实是一个线程。<code>class PullMessageService extends ServiceThread</code>，前面RebalanceSerivce的代码是在<code>class RebalanceService extends ServiceThread</code>Rebalance的线程中。现在是Rebalance线程要将PullRequest数据给PullMessage线程，肯定是通过阻塞队列，就是pullRequestQueue。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void executePullRequestImmediately(final PullRequest pullRequest) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        this.pullRequestQueue.put(pullRequest);</span><br><span class=\"line\">    &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">        log.error(&quot;executePullRequestImmediately pullRequestQueue.put&quot;, e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>随后就是从pullRequestQueue拉取pullRequest，去做真正的消息拉取。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">public void run() &#123;</span><br><span class=\"line\">    log.info(this.getServiceName() + &quot; service started&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    while (!this.isStopped()) &#123;</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            PullRequest pullRequest = this.pullRequestQueue.take();</span><br><span class=\"line\">            this.pullMessage(pullRequest);</span><br><span class=\"line\">        &#125; catch (InterruptedException ignored) &#123;</span><br><span class=\"line\">        &#125; catch (Exception e) &#123;</span><br><span class=\"line\">            log.error(&quot;Pull Message Service Run Method exception&quot;, e);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    log.info(this.getServiceName() + &quot; service end&quot;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>真正拉取的部分，是DefaultMQPushConsumerImpl#pullMessage方法中的实现。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">final ProcessQueue processQueue = pullRequest.getProcessQueue();</span><br><span class=\"line\">if (processQueue.isDropped()) &#123;</span><br><span class=\"line\">    log.info(&quot;the pull request[&#123;&#125;] is dropped.&quot;, pullRequest.toString());</span><br><span class=\"line\">    return;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>ProcessQueue会多次出现在正在拉取和消费的代码中，它存放的是某一个MessageQueue的<code>拉取后，但并未被消费的消息集合</code>，消息内部用用TreeMap<code>TreeMap&lt;Long, MessageExt&gt; msgTreeMap</code>来存储，用MessageQueueOffset来排序，以达到单队列内部严格的顺序。经过Rebalance后，当前Consumer可能不会再消费曾经被分配到的MessageQueue，自然也就无需再次消费之前没有消费完的数据。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">long cachedMessageCount = processQueue.getMsgCount().get();</span><br><span class=\"line\">long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024);</span><br><span class=\"line\"></span><br><span class=\"line\">if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123;</span><br><span class=\"line\">    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);</span><br><span class=\"line\">    if ((queueFlowControlTimes++ % 1000) == 0) &#123;</span><br><span class=\"line\">        log.warn(</span><br><span class=\"line\">            &quot;the cached message count exceeds the threshold &#123;&#125;, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,</span><br><span class=\"line\">            this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">if (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) &#123;</span><br><span class=\"line\">    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);</span><br><span class=\"line\">    if ((queueFlowControlTimes++ % 1000) == 0) &#123;</span><br><span class=\"line\">        log.warn(</span><br><span class=\"line\">            &quot;the cached message size exceeds the threshold &#123;&#125; MiB, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,</span><br><span class=\"line\">            this.defaultMQPushConsumer.getPullThresholdSizeForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">if (!this.consumeOrderly) &#123;</span><br><span class=\"line\">    if (processQueue.getMaxSpan() &gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) &#123;</span><br><span class=\"line\">        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);</span><br><span class=\"line\">        if ((queueMaxSpanFlowControlTimes++ % 1000) == 0) &#123;</span><br><span class=\"line\">            log.warn(</span><br><span class=\"line\">                &quot;the queue&apos;s messages, span too long, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, maxSpan=&#123;&#125;, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,</span><br><span class=\"line\">                processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), processQueue.getMaxSpan(),</span><br><span class=\"line\">                pullRequest, queueMaxSpanFlowControlTimes);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>以上描述了三种情况下，会让拉取消息限流。</p>\n<p>之后构造了一个非常复杂的<code>PullCallback</code>，其实就是描述调用<code>pullAPIWrapper.pullKernelImpl</code>后，对于各种结果的回调（Callback）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PullCallback pullCallback = new PullCallback() &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void onSuccess(PullResult pullResult) &#123;</span><br><span class=\"line\">        if (pullResult != null) &#123;</span><br><span class=\"line\">            pullResult = DefaultMQPushConsumerImpl.this.pullAPIWrapper.processPullResult(pullRequest.getMessageQueue(), pullResult,</span><br><span class=\"line\">                subscriptionData);</span><br><span class=\"line\"></span><br><span class=\"line\">            switch (pullResult.getPullStatus()) &#123;</span><br><span class=\"line\">                case FOUND:</span><br><span class=\"line\">                    // deal with this case</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                case NO_NEW_MSG:</span><br><span class=\"line\">                    // deal with this case</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                case NO_MATCHED_MSG:</span><br><span class=\"line\">                    // deal with this case</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                case OFFSET_ILLEGAL:</span><br><span class=\"line\">                    // deal with this case</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                default:</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void onException(Throwable e) &#123;</span><br><span class=\"line\">        // deal with this case</span><br><span class=\"line\">        DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"细节控\"><a href=\"#细节控\" class=\"headerlink\" title=\"细节控\"></a>细节控</h3><p><a href=\"https://www.jianshu.com/p/fac642f3c1af?utm_source=oschina-app\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/fac642f3c1af?utm_source=oschina-app</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">根据isTransferMsgByHeap的设置情况（默认为true），选择下面两种方式之一来真正读取GetMessageResult的消息内容并返回至Consumer端；</span><br><span class=\"line\">方式1：使用JDK NIO的ByteBuffer，循环地读取存有消息内容的messageBufferList至堆内内存中，返回byte[]字节数组，并设置到响应的body中；然后，通过RPC通信组件—NettyRemotingServer发送响应至Consumer端；</span><br><span class=\"line\">方式2：采用基于Zero-Copy的Netty组件的FileRegion，其包装的“FileChannel.tranferTo”实现文件传输，可以直接将文件缓冲区的数据发送至通信目标通道Channel中，避免了通过循环write方式导致的内存拷贝开销，这种方式性能上更优；</span><br><span class=\"line\"></span><br><span class=\"line\">作者：癫狂侠</span><br><span class=\"line\">链接：https://www.jianshu.com/p/fac642f3c1af</span><br><span class=\"line\">來源：简书</span><br><span class=\"line\">简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"ProcessOn配图\"><a href=\"#ProcessOn配图\" class=\"headerlink\" title=\"ProcessOn配图\"></a>ProcessOn配图</h3><p><a href=\"https://processon.com/diagraming/5badd204e4b075b9fe5b5d59\" target=\"_blank\" rel=\"noopener\">https://processon.com/diagraming/5badd204e4b075b9fe5b5d59</a></p>\n<p>以topic为维度，开始进行Rebalance<br>以集群模式为例，先调用<code>List&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup)</code>找到所有Consumer，然后根据topic路由信息，找到所有的MessageQueue。举个例子，有8个MessageQueue，4个Consumer,可以把MessageQueue理解为任务队列，4个Consumer大家一起分下任务，默认是平均分配（AllocateMessageQueueStrategy）策略，即说好，大家一人固定拉取并消费2个队列，如果队列的数量或者Consumer的数量不变，那这个关系就不要打破。可能有人要问了，这个给Consumer分配任务的工作，总得由一个老大哥（Leader）来执行吧，要么是Consumer里面有个Leader，要么是将该模块给集群协调者来做，不然怎么保证大家的分的方式都一样嘞。但RocketMQ恰恰是由每个Consumer各自都来做这个分配，秘诀在于下面两行代码</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Collections.sort(mqAll);</span><br><span class=\"line\">Collections.sort(cidAll);</span><br></pre></td></tr></table></figure>\n\n<p>当大家获取的mqAll和cidAll集合内容和顺序都一样，按照AllocateMessageQueueAveragely#allocate的分配方式，每个Consumer就能获取到属于自己的任务队列。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private void rebalanceByTopic(final String topic, final boolean isOrder) &#123;</span><br><span class=\"line\">    switch (messageModel) &#123;</span><br><span class=\"line\">        case BROADCASTING: &#123;</span><br><span class=\"line\">            Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic);</span><br><span class=\"line\">            if (mqSet != null) &#123;</span><br><span class=\"line\">                boolean changed = this.updateProcessQueueTableInRebalance(topic, mqSet, isOrder);</span><br><span class=\"line\">                if (changed) &#123;</span><br><span class=\"line\">                    this.messageQueueChanged(topic, mqSet, mqSet);</span><br><span class=\"line\">                    log.info(&quot;messageQueueChanged &#123;&#125; &#123;&#125; &#123;&#125; &#123;&#125;&quot;,</span><br><span class=\"line\">                        consumerGroup,</span><br><span class=\"line\">                        topic,</span><br><span class=\"line\">                        mqSet,</span><br><span class=\"line\">                        mqSet);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                log.warn(&quot;doRebalance, &#123;&#125;, but the topic[&#123;&#125;] not exist.&quot;, consumerGroup, topic);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        case CLUSTERING: &#123;</span><br><span class=\"line\">            Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic);</span><br><span class=\"line\">            List&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);</span><br><span class=\"line\">            if (null == mqSet) &#123;</span><br><span class=\"line\">                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123;</span><br><span class=\"line\">                    log.warn(&quot;doRebalance, &#123;&#125;, but the topic[&#123;&#125;] not exist.&quot;, consumerGroup, topic);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            if (null == cidAll) &#123;</span><br><span class=\"line\">                log.warn(&quot;doRebalance, &#123;&#125; &#123;&#125;, get consumer id list failed&quot;, consumerGroup, topic);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            if (mqSet != null &amp;&amp; cidAll != null) &#123;</span><br><span class=\"line\">                List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;();</span><br><span class=\"line\">                mqAll.addAll(mqSet);</span><br><span class=\"line\"></span><br><span class=\"line\">                Collections.sort(mqAll);</span><br><span class=\"line\">                Collections.sort(cidAll);</span><br><span class=\"line\"></span><br><span class=\"line\">                AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy;</span><br><span class=\"line\"></span><br><span class=\"line\">                List&lt;MessageQueue&gt; allocateResult = null;</span><br><span class=\"line\">                try &#123;</span><br><span class=\"line\">                    allocateResult = strategy.allocate(</span><br><span class=\"line\">                        this.consumerGroup,</span><br><span class=\"line\">                        this.mQClientFactory.getClientId(),</span><br><span class=\"line\">                        mqAll,</span><br><span class=\"line\">                        cidAll);</span><br><span class=\"line\">                &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">                    log.error(&quot;AllocateMessageQueueStrategy.allocate Exception. allocateMessageQueueStrategyName=&#123;&#125;&quot;, strategy.getName(),</span><br><span class=\"line\">                        e);</span><br><span class=\"line\">                    return;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                Set&lt;MessageQueue&gt; allocateResultSet = new HashSet&lt;MessageQueue&gt;();</span><br><span class=\"line\">                if (allocateResult != null) &#123;</span><br><span class=\"line\">                    allocateResultSet.addAll(allocateResult);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder);</span><br><span class=\"line\">                if (changed) &#123;</span><br><span class=\"line\">                    log.info(</span><br><span class=\"line\">                        &quot;rebalanced result changed. allocateMessageQueueStrategyName=&#123;&#125;, group=&#123;&#125;, topic=&#123;&#125;, clientId=&#123;&#125;, mqAllSize=&#123;&#125;, cidAllSize=&#123;&#125;, rebalanceResultSize=&#123;&#125;, rebalanceResultSet=&#123;&#125;&quot;,</span><br><span class=\"line\">                        strategy.getName(), consumerGroup, topic, this.mQClientFactory.getClientId(), mqSet.size(), cidAll.size(),</span><br><span class=\"line\">                        allocateResultSet.size(), allocateResultSet);</span><br><span class=\"line\">                    this.messageQueueChanged(topic, mqSet, allocateResultSet);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        default:</span><br><span class=\"line\">            break;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">``` </span><br><span class=\"line\"></span><br><span class=\"line\">在确定了当前Consumer需要拉取消费的队列后，如果这个关系发生了变化，那要删除以前正在消费，但是现在不用消费的队列。比如，当前Consumer本来被分到了MessageQueue1和MessageQueue3，但是新加入两个Consumer，重新分配（ReBalance）后，当前消费者不再需要消费MessageQueue3了，那需要把这个关系给删除掉。</span><br><span class=\"line\">``` RebalanceImpl#updateProcessQueueTableInRebalance</span><br><span class=\"line\">Iterator&lt;Entry&lt;MessageQueue, ProcessQueue&gt;&gt; it = this.processQueueTable.entrySet().iterator();</span><br><span class=\"line\">while (it.hasNext()) &#123;</span><br><span class=\"line\">    Entry&lt;MessageQueue, ProcessQueue&gt; next = it.next();</span><br><span class=\"line\">    MessageQueue mq = next.getKey();</span><br><span class=\"line\">    ProcessQueue pq = next.getValue();</span><br><span class=\"line\"></span><br><span class=\"line\">    if (mq.getTopic().equals(topic)) &#123;</span><br><span class=\"line\">        if (!mqSet.contains(mq)) &#123;</span><br><span class=\"line\">            pq.setDropped(true);</span><br><span class=\"line\">            if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123;</span><br><span class=\"line\">                it.remove();</span><br><span class=\"line\">                changed = true;</span><br><span class=\"line\">                log.info(&quot;doRebalance, &#123;&#125;, remove unnecessary mq, &#123;&#125;&quot;, consumerGroup, mq);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; else if (pq.isPullExpired()) &#123;</span><br><span class=\"line\">            switch (this.consumeType()) &#123;</span><br><span class=\"line\">                case CONSUME_ACTIVELY:</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                case CONSUME_PASSIVELY:</span><br><span class=\"line\">                    pq.setDropped(true);</span><br><span class=\"line\">                    if (this.removeUnnecessaryMessageQueue(mq, pq)) &#123;</span><br><span class=\"line\">                        it.remove();</span><br><span class=\"line\">                        changed = true;</span><br><span class=\"line\">                        log.error(&quot;[BUG]doRebalance, &#123;&#125;, remove unnecessary mq, &#123;&#125;, because pull is pause, so try to fixed it&quot;,</span><br><span class=\"line\">                            consumerGroup, mq);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                default:</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>删除多余的消费关系后，当前Consumer就要开始给<code>每一个被分配到的MessageQueue</code>发送消息拉取请求（PullRequest）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;PullRequest&gt; pullRequestList = new ArrayList&lt;PullRequest&gt;();</span><br><span class=\"line\">for (MessageQueue mq : mqSet) &#123;</span><br><span class=\"line\">    if (!this.processQueueTable.containsKey(mq)) &#123;</span><br><span class=\"line\">        if (isOrder &amp;&amp; !this.lock(mq)) &#123;</span><br><span class=\"line\">            log.warn(&quot;doRebalance, &#123;&#125;, add a new mq failed, &#123;&#125;, because lock failed&quot;, consumerGroup, mq);</span><br><span class=\"line\">            continue;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        this.removeDirtyOffset(mq);</span><br><span class=\"line\">        ProcessQueue pq = new ProcessQueue();</span><br><span class=\"line\">        long nextOffset = this.computePullFromWhere(mq);</span><br><span class=\"line\">        if (nextOffset &gt;= 0) &#123;</span><br><span class=\"line\">            ProcessQueue pre = this.processQueueTable.putIfAbsent(mq, pq);</span><br><span class=\"line\">            if (pre != null) &#123;</span><br><span class=\"line\">                log.info(&quot;doRebalance, &#123;&#125;, mq already exists, &#123;&#125;&quot;, consumerGroup, mq);</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                log.info(&quot;doRebalance, &#123;&#125;, add a new mq, &#123;&#125;&quot;, consumerGroup, mq);</span><br><span class=\"line\">                PullRequest pullRequest = new PullRequest();</span><br><span class=\"line\">                pullRequest.setConsumerGroup(consumerGroup);</span><br><span class=\"line\">                pullRequest.setNextOffset(nextOffset);</span><br><span class=\"line\">                pullRequest.setMessageQueue(mq);</span><br><span class=\"line\">                pullRequest.setProcessQueue(pq);</span><br><span class=\"line\">                pullRequestList.add(pullRequest);</span><br><span class=\"line\">                changed = true;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            log.warn(&quot;doRebalance, &#123;&#125;, add new mq failed, &#123;&#125;&quot;, consumerGroup, mq);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">this.dispatchPullRequest(pullRequestList);</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void dispatchPullRequest(List&lt;PullRequest&gt; pullRequestList) &#123;</span><br><span class=\"line\">    for (PullRequest pullRequest : pullRequestList) &#123;</span><br><span class=\"line\">        this.defaultMQPushConsumerImpl.executePullRequestImmediately(pullRequest);</span><br><span class=\"line\">        log.info(&quot;doRebalance, &#123;&#125;, add a new pull request &#123;&#125;&quot;, consumerGroup, pullRequest);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>以上所有的代码全部都是RebalanceService，用于管理Consumer和MessageQueue之间的对应关系，以及当两者任一一个数量非常变化时的重新均衡。消息真正拉取是由PullMessageService来处理的，注意到，它其实是一个线程。<code>class PullMessageService extends ServiceThread</code>，前面RebalanceSerivce的代码是在<code>class RebalanceService extends ServiceThread</code>Rebalance的线程中。现在是Rebalance线程要将PullRequest数据给PullMessage线程，肯定是通过阻塞队列，就是pullRequestQueue。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void executePullRequestImmediately(final PullRequest pullRequest) &#123;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        this.pullRequestQueue.put(pullRequest);</span><br><span class=\"line\">    &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">        log.error(&quot;executePullRequestImmediately pullRequestQueue.put&quot;, e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>随后就是从pullRequestQueue拉取pullRequest，去做真正的消息拉取。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@Override</span><br><span class=\"line\">public void run() &#123;</span><br><span class=\"line\">    log.info(this.getServiceName() + &quot; service started&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">    while (!this.isStopped()) &#123;</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            PullRequest pullRequest = this.pullRequestQueue.take();</span><br><span class=\"line\">            this.pullMessage(pullRequest);</span><br><span class=\"line\">        &#125; catch (InterruptedException ignored) &#123;</span><br><span class=\"line\">        &#125; catch (Exception e) &#123;</span><br><span class=\"line\">            log.error(&quot;Pull Message Service Run Method exception&quot;, e);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    log.info(this.getServiceName() + &quot; service end&quot;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>真正拉取的部分，是DefaultMQPushConsumerImpl#pullMessage方法中的实现。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">final ProcessQueue processQueue = pullRequest.getProcessQueue();</span><br><span class=\"line\">if (processQueue.isDropped()) &#123;</span><br><span class=\"line\">    log.info(&quot;the pull request[&#123;&#125;] is dropped.&quot;, pullRequest.toString());</span><br><span class=\"line\">    return;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>ProcessQueue会多次出现在正在拉取和消费的代码中，它存放的是某一个MessageQueue的<code>拉取后，但并未被消费的消息集合</code>，消息内部用用TreeMap<code>TreeMap&lt;Long, MessageExt&gt; msgTreeMap</code>来存储，用MessageQueueOffset来排序，以达到单队列内部严格的顺序。经过Rebalance后，当前Consumer可能不会再消费曾经被分配到的MessageQueue，自然也就无需再次消费之前没有消费完的数据。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">long cachedMessageCount = processQueue.getMsgCount().get();</span><br><span class=\"line\">long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024);</span><br><span class=\"line\"></span><br><span class=\"line\">if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123;</span><br><span class=\"line\">    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);</span><br><span class=\"line\">    if ((queueFlowControlTimes++ % 1000) == 0) &#123;</span><br><span class=\"line\">        log.warn(</span><br><span class=\"line\">            &quot;the cached message count exceeds the threshold &#123;&#125;, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,</span><br><span class=\"line\">            this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">if (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) &#123;</span><br><span class=\"line\">    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);</span><br><span class=\"line\">    if ((queueFlowControlTimes++ % 1000) == 0) &#123;</span><br><span class=\"line\">        log.warn(</span><br><span class=\"line\">            &quot;the cached message size exceeds the threshold &#123;&#125; MiB, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,</span><br><span class=\"line\">            this.defaultMQPushConsumer.getPullThresholdSizeForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">if (!this.consumeOrderly) &#123;</span><br><span class=\"line\">    if (processQueue.getMaxSpan() &gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) &#123;</span><br><span class=\"line\">        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);</span><br><span class=\"line\">        if ((queueMaxSpanFlowControlTimes++ % 1000) == 0) &#123;</span><br><span class=\"line\">            log.warn(</span><br><span class=\"line\">                &quot;the queue&apos;s messages, span too long, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, maxSpan=&#123;&#125;, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,</span><br><span class=\"line\">                processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), processQueue.getMaxSpan(),</span><br><span class=\"line\">                pullRequest, queueMaxSpanFlowControlTimes);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>以上描述了三种情况下，会让拉取消息限流。</p>\n<p>之后构造了一个非常复杂的<code>PullCallback</code>，其实就是描述调用<code>pullAPIWrapper.pullKernelImpl</code>后，对于各种结果的回调（Callback）。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PullCallback pullCallback = new PullCallback() &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void onSuccess(PullResult pullResult) &#123;</span><br><span class=\"line\">        if (pullResult != null) &#123;</span><br><span class=\"line\">            pullResult = DefaultMQPushConsumerImpl.this.pullAPIWrapper.processPullResult(pullRequest.getMessageQueue(), pullResult,</span><br><span class=\"line\">                subscriptionData);</span><br><span class=\"line\"></span><br><span class=\"line\">            switch (pullResult.getPullStatus()) &#123;</span><br><span class=\"line\">                case FOUND:</span><br><span class=\"line\">                    // deal with this case</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                case NO_NEW_MSG:</span><br><span class=\"line\">                    // deal with this case</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                case NO_MATCHED_MSG:</span><br><span class=\"line\">                    // deal with this case</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                case OFFSET_ILLEGAL:</span><br><span class=\"line\">                    // deal with this case</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">                default:</span><br><span class=\"line\">                    break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void onException(Throwable e) &#123;</span><br><span class=\"line\">        // deal with this case</span><br><span class=\"line\">        DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"RocketMQ——延时消息投递原理分析","date":"2017-10-13T02:38:19.000Z","_content":"\n### 被动延时消费\n\n``` java\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\n    @Override\n    public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,\n        ConsumeConcurrentlyContext context) {\n        // 可能抛出异常\n        boolean success = doConsume(msgs);\n        \n        if (success) {\n            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n        } else {\n            return ConsumeConcurrentlyStatus.RECONSUME_LATER;\n        }\n    }\n});\n```\n\n### 主动延时消费\n\n``` java\n\n```\n\n### 分布式事务之 Best Effort Delivery","source":"_posts/RocketMQ-Delay-message-delivery.md","raw":"---\ntitle: RocketMQ——延时消息投递原理分析\ndate: 2017-10-13 10:38:19\ntags: RocketMQ\n---\n\n### 被动延时消费\n\n``` java\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\n    @Override\n    public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,\n        ConsumeConcurrentlyContext context) {\n        // 可能抛出异常\n        boolean success = doConsume(msgs);\n        \n        if (success) {\n            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n        } else {\n            return ConsumeConcurrentlyStatus.RECONSUME_LATER;\n        }\n    }\n});\n```\n\n### 主动延时消费\n\n``` java\n\n```\n\n### 分布式事务之 Best Effort Delivery","slug":"RocketMQ-Delay-message-delivery","published":1,"updated":"2019-09-28T08:51:00.915Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84l004rv1npynmp0h8q","content":"<h3 id=\"被动延时消费\"><a href=\"#被动延时消费\" class=\"headerlink\" title=\"被动延时消费\"></a>被动延时消费</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">consumer.registerMessageListener(<span class=\"keyword\">new</span> MessageListenerConcurrently() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> ConsumeConcurrentlyStatus <span class=\"title\">consumeMessage</span><span class=\"params\">(List&lt;MessageExt&gt; msgs,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 可能抛出异常</span></span><br><span class=\"line\">        <span class=\"keyword\">boolean</span> success = doConsume(msgs);</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> (success) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ConsumeConcurrentlyStatus.RECONSUME_LATER;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"主动延时消费\"><a href=\"#主动延时消费\" class=\"headerlink\" title=\"主动延时消费\"></a>主动延时消费</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"分布式事务之-Best-Effort-Delivery\"><a href=\"#分布式事务之-Best-Effort-Delivery\" class=\"headerlink\" title=\"分布式事务之 Best Effort Delivery\"></a>分布式事务之 Best Effort Delivery</h3>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"被动延时消费\"><a href=\"#被动延时消费\" class=\"headerlink\" title=\"被动延时消费\"></a>被动延时消费</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">consumer.registerMessageListener(<span class=\"keyword\">new</span> MessageListenerConcurrently() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> ConsumeConcurrentlyStatus <span class=\"title\">consumeMessage</span><span class=\"params\">(List&lt;MessageExt&gt; msgs,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 可能抛出异常</span></span><br><span class=\"line\">        <span class=\"keyword\">boolean</span> success = doConsume(msgs);</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> (success) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ConsumeConcurrentlyStatus.RECONSUME_LATER;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"主动延时消费\"><a href=\"#主动延时消费\" class=\"headerlink\" title=\"主动延时消费\"></a>主动延时消费</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"分布式事务之-Best-Effort-Delivery\"><a href=\"#分布式事务之-Best-Effort-Delivery\" class=\"headerlink\" title=\"分布式事务之 Best Effort Delivery\"></a>分布式事务之 Best Effort Delivery</h3>"},{"title":"面向问题的RocketMQ原理整理","date":"2017-08-09T06:42:53.000Z","_content":"\n> 先来一个图，总结得非常好\n\nhttps://blog.csdn.net/qq_27529917/article/details/79595395\nhttps://upload-images.jianshu.io/upload_images/6302559-48fbc4f75fbf2412.png\n\n### 顺序消息是怎么实现的？\n消息的重复消费是不可避免的，但是消息的顺序需要保证。\na b c d e -> a a b c d eee，但是不能a c b d e\n\n### RocketMQ与Kafka架构上的巨大差异 -- CommitLog与ConsumeQueue\nhttps://blog.csdn.net/chunlongyu/article/details/54576649\n```\n每个topic_partition对应一个日志文件，Producer对该日志文件进行“顺序写”，Consumer对该文件进行“顺序读”。\n\n但正如在“拨乱反正”续篇中所提到的：这种存储方式，对于每个文件来说是顺序IO，但是当并发的读写多个partition的时候，对应多个文件的顺序IO，表现在文件系统的磁盘层面，还是随机IO。\n\n因此出现了当partition或者topic个数过多时，Kafka的性能急剧下降\n\n虽然每个文件是顺序IO，但topic或者partition过多，每个文件的顺序IO，表现到磁盘上，还是随机IO。\n```\n\n### RMQ的Name Server怎么动态扩展？\n\n### RMQ的Broker怎么动态扩展？\n\n### msgId和offsetMsgId的区别\n对于客户端来说msgId是由客户端producer实例端生成的（具体来说，调用“MessageClientIDSetter.createUniqIDBuffer()”方法生成唯一的Id），offsetMsgId是由服务端Broker端在写入消息时生成的（采用“IP地址+Port端口”与“CommitLog的物理偏移量地址”做了一个字符串拼接），其中offsetMsgId就是我们在rocketMQ控制台直接输入查询的那个messageId。\n\n### 异步刷盘，CommitLog和ConsumeQueue哪一个先落盘？\n当消息放到了commitlog 的page cache（即没有刷盘）后，异步写入consumequeue。从逻辑上来讲，consumequeue的构建是依赖commitlog 的，但是由于刷盘是异步的，所以落盘的顺序是不一定的。\n\n### MQ为什么内部要使用好多队列？\n\n1. send性能\n理论上队列入口要加锁（要么是程序的锁，要么是文件的锁）来保证同步，如果队列非常多，虽然不能把锁去掉，但可以减小并发线程对锁的竞争。这个是以前的结论，但实际情况是，consume queue只有一个线程来做。首先，commit log文件只有一个，假如要执行sendMessage，一定要用sync或者自旋锁（之后的版本为了考虑性能），消息都是顺序写进commit log的。对于一个topic的某一个consumer group，consumerQueue文件就有很多个，写consumerQueue文件由一个ReputMessageService的线程近实时空转而触发，也是单个线程。从写consumerQueue文件（send message）的角度来分析，多个队列是没有好处的。\n2. consume性能\n如果从读consumerQueue文件（pull message）的角度来分析，那确实是可以提高并行度。\n\n### MQ的NameServer集群节点中间有没有同步数据？与Zookeeper集群的区别是什么？\n\n### MQ的topic有序性怎么保证\n\nMessageQueueSelector中的List<MessageQueue> mqs指的是所有的broker加起来的队列。\n\n### 怎么让两个Broker中都有某个topic的信息，如果只有一个有，就没法做send的双broker负载均衡\n\nClient发送一个新的topic，在name server上是取不到信息的，所以先用在本地放上Map来缓存，那问题是Broker什么时候给name server发送创建Topic route info的请求？在checkMsg方法中，this.brokerController.registerBrokerAll(false, true);\nMQ的消费者端如果是用push的方式回调，执行listener会开启新的线程用来接收和返回（确认）ack，但一般我们会再开我们的新线程去做消费的事情，这个时候如果由于外界原因进程死亡，那么这些消息就丢失了。\n\n### 哪些情况会引起rebalance?    \n\nmq数量，客户端数量\n\n### 怎么设计Netty的同步调用与异步调用？\n\n掌握CountDownLatch和（限流）\n\n### 万一NameServer都被重启过，那producer或者consumer调用getTopicRouteInfo，信息从何而来？\n\n1. UpdateRouteInfo应该会上传一个新的Topic的信息。\n\n### RocketMQ落盘是异步+定时的，还是就异步的？\n\n异步+定时，时间默认为500ms。\n\nClient向broker pull message 都是以一个一个queue为单位的。processQueueTable代表，这里面的queue正在源源不断向broker请求数据中。而broker的queue的数量是可能发生变化的，所以，要时常对processQueueTable进行必要的整理。\n\n一个Subscription对应一次rebalance调用，一般的情况是n个topic+1个Retry topic。每一次rebalance调用，都会对当前的topic分配broker中的MQ队列，如果分到n个，那个生成n个PullRequest。\n\nRebalanceServer生成 PullRequest 会调用PullMessageService 放入 PullRequest的pullRequestQueue中，PullMessageService从pullRequestQueue队列中take出PullRequest，异步调用Netty。当网络将数据传输回来时，调用PullCallback中的ConsumeMessageService，遍历所有原始消费，对每个消息，生成一个ConsumeRequest，开启多线程进行消费。消费时，返回值怎么处理？比如 Re-consume-later, success。客户端开启一个线程定时去更新Broker的consumerOffset。\n\n### 为什么一旦有producer发送了消息，consumer会几乎无延迟得立刻收到消息？\n\n1. consumer长轮询，在没有消息时hold在server端。\n2. commit log的max offset增大，触发空轮询ReputMessageService，构建完consume queue之后，调用messageArrivingListener通知消息到了，从而重新processRequest来pull消息。\n但是问题发现了，构建ConsumeQueue理论上是有一个性能极限值的，那这样的话，不是会很容易发送的消息，消费会有延时么？\n```java\n@Override\npublic void run() {\n    DefaultMessageStore.log.info(this.getServiceName() + \" service started\");\n\n    while (!this.isStopped()) {\n        try {\n            // 这里睡眠了1ms，可以算出写入ConsumerQueue的性能极限值\n            Thread.sleep(1);\n            this.doReput();\n        } catch (Exception e) {\n            DefaultMessageStore.log.warn(this.getServiceName() + \" service has exception. \", e);\n        }\n    }\n\n    DefaultMessageStore.log.info(this.getServiceName() + \" service end\");\n}\n```\n\n未解决问题：\n\n### Broker里面的protectBroker是用来做什么的？\n\n### CommitLog和ConsumerQueue这两个文件的读写是顺序的么？效率怎么样？\n\n### RocketMQ在哪几种情况下，可能会出现消息重复的问题？\n\n1. 一个consume_group一开始订阅了*tag，之后加了具体的，会发生什么。\n\n### kafka的发送消息性能非常高，常用于日志缓冲，是不是用「Oneway」的方式？不然producer发送请求，broker处理请求，producer接受响应，这三段的时间是无论如何都无法缩减的。\n\n### RocketMQ的事务消息是什么？\n看到一段描述很有趣，当发送了分布式事务消息时，如果Producer因为意外宕机，Broker会回调Producer Group的另一一台Producer来确认事务状态。\n2. Commit Log 中存储了所有的元信息，包含消息体，类似于 Mysql、Oracle 的 redolog，所以只要有 Commit\n   Log 在，Consume Queue 即使数据丢失，仍然可以恢复出来。怎么理解？\n3. 在Broker的SendMessageProcessor中，主干线程中只做了一件事，那就是把最新的消息Append到CommitLog中，并且通知Flush线程去force() mmap。所以，构建ConsumeQueue，构建索引这些事情都是异步的，那好像也没有看到通知这些线程，究竟是在哪里通知的呢？ Dispatcher（调度器）ReputMessageService。\n\n### Debug形式启动Producer，Producer发送消息，断点停止后，Producer发送消息会超时失败3次，但此时如果松开断点，让他执行完，那消息是在CommitLog中呢，还是不在？\n\n### MQ在关闭的时候，CommitLog的内容和ConsumeQueue的内容需要能对上号的，但万一异常关闭导致没有对上号，应该怎么处理？CheckPoint机制有没有用？\n\n### 一个消息已经消费过了，能在控制台上选择进行重复投递么？\n\n可以。\n\n### pagecache到底是个什么东西？\n\n### 对于不可读的Consume Queue，Consumer rebalance时会不会考虑到？\n\n如果没有考虑到，那不可读的队列也分给了Consumer，造成Consumer的浪费。看过源码了，没有问题。\n\n### topic中有readQ, writeQ, 那topic本身的权限是用来做什么的？\n\n### 多个namesrv不一致问题\n\n### 如果某个topic的consume queue上有数据，那设置可读可写队列为0后，数据是不是读不到了。（我知道不会丢失）\n\n### 写Consume queue完全是一个单线程DefaultMessageStore.ReputMessageService中，那就没有锁竞争了，一个Topic到底放多少个队列效率达到最高，是越少越好，还是越多越好？\n\n### namesrv是无状态的，可以随意部署，但Broker启动后怎么是怎么知道新增加的namesrv的？\n\n### 如果发送了某个topic的某个tag的消息，那订阅了该topic的consumer是有可能过滤掉该tag的信息的。那怎么样才能知道该消息是“订阅了，被过滤了”的状态呢？\n\n首先，根据queueId和consume offset可以判断出当前消息是不是已经被\n\n### ConsumerQueue文件删除了，能够复原么？原理\n\n可以\n\n### index file删除了，能够复原么？原理\n\n可以\n\n### CommitLog和ConsumeQueue在非正常关机下变得不一致，如何恢复？\n\n### ReputMessageService中空转监听是Commitog的offset，当有新的消息时，先是构建consume queue，然后通知PullMessageHoldService，那整个过程在哪里对消息进行过滤，过滤用的是tag，consume queue中也有tag的hash，是不是只需要对比这两个值就好？\n5. 如果一个4G的文件用mmap映射到Java的MappedByteBuffer中，是绝对不可能整体加载进内存的。一个ByteBuffer就是一个有限的byte数组，但是，我们理论上可以在这个数组的任何位置（position）对数组进行读和写，然后映射进文件。如果OS能预感到我们的文件是顺序读写的，那么内存到文件的速度会非常快，如果是随机的，OS没法预测下次的读写位置，这样速度会变慢（这部分去查询下）\n6. PullConsumer：用consumer.pull(MessageQueue mq, String subExpression, long offset, int maxNums)方法去获取Broker的消息，如果第一次offset传了0，获取到了数据，第二次还是传0，还是能获取到数据，是什么原因？Broker的consumerOffset.json为什么不起作用？Pull和Push消费到的点什么时候会被persist到config/consumerOffset.json?详见MQClientInstance.persistAllConsumerOffset会把offsetTable定时发到Broker。\n\n### 程序中处理MappedByteBuffer要特别注意些什么？\n\nA MemoryMappedBuffer has a fixed size, but the file it’s mapped to is elastic.所以一旦当前的程序（或者说当前的线程）对文件的内容失去了独占权，比如文件的内容被其它的线程改了，那原先的线程访问MappedByteBuffer对应位置的缓存就会抛出异常，所以，当我们要用MappedByteBuffer时，一定要确保在多线程下是互斥的。\n这个理解是不对的！！！！\n\n### RocketMQ发送，接受消息的性能与队列数量的关系。\n\n可以查看kafka相关的信息。\n\n### 如果让你设计一个消息中间件？你会怎么设计？\n\n### 如果一个消息没有消费成功，会隔1s,5s,ns重新消费，这个是怎么实现的？\n\n### 构建IndexService是否可以做成异步？\n\n因为它如果卡住，会影响长轮询，从而影响消息接收的实时性。\n\n### Netty线程问题\nnetty在触发channelRead0的时候，所用的线程是不是workEventLoopGroup所指定的线程\nnettyClientWorkerThread\n\n### netty eventLoopGroup 是什么？\n\n### 网络端口映射\nServer:8080\ncurl 'localhost:8080'\nlsof -i:8080\n\n### 待解决问题\n```\norg.apache.rocketmq.client.exception.MQClientException: No route info of this topic, binlog-msg\nSee http://rocketmq.apache.org/docs/faq/ for further details.\n\tat org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendDefaultImpl(DefaultMQProducerImpl.java:537)\n\tat org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:1038)\n\tat org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:996)\n\tat org.apache.rocketmq.client.producer.DefaultMQProducer.send(DefaultMQProducer.java:212)\n\tat org.apache.rock\n```\n\n### 问题\n2017-10-11 07:21:38 WARN SendMessageThread_1 - Offset for /root/store/commitlog/00000000002147483648 not matched. Request offset: 4051326754958557513, index: -521875234, mappedFileSize: 1073741824, mappedFiles count: 1\n2017-10-11 07:21:38 WARN SendMessageThread_1 - findMappedFileByOffset failure. \njava.lang.ArrayIndexOutOfBoundsException: -521875234\n\n请教：rocketmq的这个异常应该如何解决呢？\n\n\n### RocketMQ水位线设置\n\n非常重要\n\n### RocketMQ 业务KEY相同导致哈希冲突\n\n### RocketMQ的Commit log什么时候munmap\n\n### RocketMQ协议\n\nRocketMQ LengthBasedField\n\n### MQ系统限流和Flow Control\n\n### RocketMQ的NameServer是不是支持分布式一致性\n\n### 现在这个版本，当Master挂掉时，Slave可以升级成新的Master么\n\n\n### RocketMQ怎么样使用性能会非常差？\n\n刷盘的策略，linux 配置的脏页的数量。脏页的比例，和脏页的大小\n\n在公司遇到一种情况，就是不断消费失败\n\n### RocketMQ到底用的是poll,epoll,还是其它的东西？？？？？？\nhttp://www.jianshu.com/p/7835726dc78b?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation\n\nhttp://www.jianshu.com/p/5ab57182af89?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation\n\n### 同步刷盘会不会丢消息?\n\n### 为什么kafka没有commitlog文件，而rocketmq有?\n\n### kafka什么场景下，性能会比较低？\n\n### 为什么有了kafka，阿里还要开发出rocketmq，rocketmq解决了什么kafka的问题？\n\n### RocketMQ怎么通过Pagecache加速的？\n![image.png](http://processon.com/chart_image/5b892eb9e4b0bd4db926c7a4.png?=1)\n\n### 怎么保证同步刷盘也有效率？\n发送消息的并发线程非常多，但是CommitLog只有一个，要想顺序写入内存然后刷盘必须上锁串行化（串行化后，磁盘IO竞争小）。串行排队等待刷盘的消息非常非常多，肯定要进行批处理，GroupCommit就是这个思想。GroupCommit首先处理队列A那些已经轮到的消息，当等待排队的刷盘的消息过来后，先把它们放到队列B中，等A中的所有消息都持久化后，锁住队列B，不让消息再进来，处理队列B，让刚刚空的队列A去接受之后排队的消息。\n\n批量一次性全部刷盘\n\n### RocketMQ QueueSelector怎么应对Topic的ConsumeQueue扩容？\n```\nAlthough it’s possible to increase the number of partitions over time, one has to be careful if messages are produced with keys. When publishing a keyed message, Kafka deterministically maps the message to a partition based on the hash of the key. This provides a guarantee that messages with the same key are always routed to the same partition. This guarantee can be important for certain applications since messages within a partition are always delivered in order to the consumer. If the number of partitions changes, such a guarantee may no longer hold. To avoid this situation, a common practice is to over-partition a bit.\n```\n\n### 消费情况\nproducerGroup只是往topic发送消息。consumerGroup只是消费topic。在broker端，消费的key为topic@consumerGroup，消费的offset取决于consumer设置的，CONSUME_FROM_LAST_OFFSET，CONSUME_FROM_FIRST_OFFSET,CONSUME_FROM_TIMESTAMP\n.CONSUME_FROM_TIMESTAMP在实际应用中还是比较少的使用。这三个区别是什么呢？\n1. 假如consumer配置为cluster模式，相同的consumerGroup，且设置客户端消费offset为CONSUME_FROM_FIRST_OFFSET，\n假如topic T的队列1的maxoffset为100，那么consumerA在启动后的队列1的消费是从0消费到100，consumerB在启动后的队列1也会从0消费到100。后续的消息即要么consumerA，要么consumerB消费。\n如果客户端设置的offset为CONSUME_FROM_LAST_OFFSET，那么consumerB在启动后的队列1是从100开始消费。后续消息消费方式相同。\nCONSUME_FROM_TIMESTAMP表示从0到100之间的某个时间点后开始消费。\n2. 假如consumer配置为cluster模式，不同的consumerGroup，这种情况的消费和广播模式一样。也就是说，后续的消息，不同的组都会收到。唯一区别在于，广播模式把已消费的进度信息保存在consumer的机器上，而集群模式保存在broker上。","source":"_posts/RocketMQ-FAQ.md","raw":"---\ntitle: 面向问题的RocketMQ原理整理\ndate: 2017-08-09 14:42:53\ntags: RocketMQ\n---\n\n> 先来一个图，总结得非常好\n\nhttps://blog.csdn.net/qq_27529917/article/details/79595395\nhttps://upload-images.jianshu.io/upload_images/6302559-48fbc4f75fbf2412.png\n\n### 顺序消息是怎么实现的？\n消息的重复消费是不可避免的，但是消息的顺序需要保证。\na b c d e -> a a b c d eee，但是不能a c b d e\n\n### RocketMQ与Kafka架构上的巨大差异 -- CommitLog与ConsumeQueue\nhttps://blog.csdn.net/chunlongyu/article/details/54576649\n```\n每个topic_partition对应一个日志文件，Producer对该日志文件进行“顺序写”，Consumer对该文件进行“顺序读”。\n\n但正如在“拨乱反正”续篇中所提到的：这种存储方式，对于每个文件来说是顺序IO，但是当并发的读写多个partition的时候，对应多个文件的顺序IO，表现在文件系统的磁盘层面，还是随机IO。\n\n因此出现了当partition或者topic个数过多时，Kafka的性能急剧下降\n\n虽然每个文件是顺序IO，但topic或者partition过多，每个文件的顺序IO，表现到磁盘上，还是随机IO。\n```\n\n### RMQ的Name Server怎么动态扩展？\n\n### RMQ的Broker怎么动态扩展？\n\n### msgId和offsetMsgId的区别\n对于客户端来说msgId是由客户端producer实例端生成的（具体来说，调用“MessageClientIDSetter.createUniqIDBuffer()”方法生成唯一的Id），offsetMsgId是由服务端Broker端在写入消息时生成的（采用“IP地址+Port端口”与“CommitLog的物理偏移量地址”做了一个字符串拼接），其中offsetMsgId就是我们在rocketMQ控制台直接输入查询的那个messageId。\n\n### 异步刷盘，CommitLog和ConsumeQueue哪一个先落盘？\n当消息放到了commitlog 的page cache（即没有刷盘）后，异步写入consumequeue。从逻辑上来讲，consumequeue的构建是依赖commitlog 的，但是由于刷盘是异步的，所以落盘的顺序是不一定的。\n\n### MQ为什么内部要使用好多队列？\n\n1. send性能\n理论上队列入口要加锁（要么是程序的锁，要么是文件的锁）来保证同步，如果队列非常多，虽然不能把锁去掉，但可以减小并发线程对锁的竞争。这个是以前的结论，但实际情况是，consume queue只有一个线程来做。首先，commit log文件只有一个，假如要执行sendMessage，一定要用sync或者自旋锁（之后的版本为了考虑性能），消息都是顺序写进commit log的。对于一个topic的某一个consumer group，consumerQueue文件就有很多个，写consumerQueue文件由一个ReputMessageService的线程近实时空转而触发，也是单个线程。从写consumerQueue文件（send message）的角度来分析，多个队列是没有好处的。\n2. consume性能\n如果从读consumerQueue文件（pull message）的角度来分析，那确实是可以提高并行度。\n\n### MQ的NameServer集群节点中间有没有同步数据？与Zookeeper集群的区别是什么？\n\n### MQ的topic有序性怎么保证\n\nMessageQueueSelector中的List<MessageQueue> mqs指的是所有的broker加起来的队列。\n\n### 怎么让两个Broker中都有某个topic的信息，如果只有一个有，就没法做send的双broker负载均衡\n\nClient发送一个新的topic，在name server上是取不到信息的，所以先用在本地放上Map来缓存，那问题是Broker什么时候给name server发送创建Topic route info的请求？在checkMsg方法中，this.brokerController.registerBrokerAll(false, true);\nMQ的消费者端如果是用push的方式回调，执行listener会开启新的线程用来接收和返回（确认）ack，但一般我们会再开我们的新线程去做消费的事情，这个时候如果由于外界原因进程死亡，那么这些消息就丢失了。\n\n### 哪些情况会引起rebalance?    \n\nmq数量，客户端数量\n\n### 怎么设计Netty的同步调用与异步调用？\n\n掌握CountDownLatch和（限流）\n\n### 万一NameServer都被重启过，那producer或者consumer调用getTopicRouteInfo，信息从何而来？\n\n1. UpdateRouteInfo应该会上传一个新的Topic的信息。\n\n### RocketMQ落盘是异步+定时的，还是就异步的？\n\n异步+定时，时间默认为500ms。\n\nClient向broker pull message 都是以一个一个queue为单位的。processQueueTable代表，这里面的queue正在源源不断向broker请求数据中。而broker的queue的数量是可能发生变化的，所以，要时常对processQueueTable进行必要的整理。\n\n一个Subscription对应一次rebalance调用，一般的情况是n个topic+1个Retry topic。每一次rebalance调用，都会对当前的topic分配broker中的MQ队列，如果分到n个，那个生成n个PullRequest。\n\nRebalanceServer生成 PullRequest 会调用PullMessageService 放入 PullRequest的pullRequestQueue中，PullMessageService从pullRequestQueue队列中take出PullRequest，异步调用Netty。当网络将数据传输回来时，调用PullCallback中的ConsumeMessageService，遍历所有原始消费，对每个消息，生成一个ConsumeRequest，开启多线程进行消费。消费时，返回值怎么处理？比如 Re-consume-later, success。客户端开启一个线程定时去更新Broker的consumerOffset。\n\n### 为什么一旦有producer发送了消息，consumer会几乎无延迟得立刻收到消息？\n\n1. consumer长轮询，在没有消息时hold在server端。\n2. commit log的max offset增大，触发空轮询ReputMessageService，构建完consume queue之后，调用messageArrivingListener通知消息到了，从而重新processRequest来pull消息。\n但是问题发现了，构建ConsumeQueue理论上是有一个性能极限值的，那这样的话，不是会很容易发送的消息，消费会有延时么？\n```java\n@Override\npublic void run() {\n    DefaultMessageStore.log.info(this.getServiceName() + \" service started\");\n\n    while (!this.isStopped()) {\n        try {\n            // 这里睡眠了1ms，可以算出写入ConsumerQueue的性能极限值\n            Thread.sleep(1);\n            this.doReput();\n        } catch (Exception e) {\n            DefaultMessageStore.log.warn(this.getServiceName() + \" service has exception. \", e);\n        }\n    }\n\n    DefaultMessageStore.log.info(this.getServiceName() + \" service end\");\n}\n```\n\n未解决问题：\n\n### Broker里面的protectBroker是用来做什么的？\n\n### CommitLog和ConsumerQueue这两个文件的读写是顺序的么？效率怎么样？\n\n### RocketMQ在哪几种情况下，可能会出现消息重复的问题？\n\n1. 一个consume_group一开始订阅了*tag，之后加了具体的，会发生什么。\n\n### kafka的发送消息性能非常高，常用于日志缓冲，是不是用「Oneway」的方式？不然producer发送请求，broker处理请求，producer接受响应，这三段的时间是无论如何都无法缩减的。\n\n### RocketMQ的事务消息是什么？\n看到一段描述很有趣，当发送了分布式事务消息时，如果Producer因为意外宕机，Broker会回调Producer Group的另一一台Producer来确认事务状态。\n2. Commit Log 中存储了所有的元信息，包含消息体，类似于 Mysql、Oracle 的 redolog，所以只要有 Commit\n   Log 在，Consume Queue 即使数据丢失，仍然可以恢复出来。怎么理解？\n3. 在Broker的SendMessageProcessor中，主干线程中只做了一件事，那就是把最新的消息Append到CommitLog中，并且通知Flush线程去force() mmap。所以，构建ConsumeQueue，构建索引这些事情都是异步的，那好像也没有看到通知这些线程，究竟是在哪里通知的呢？ Dispatcher（调度器）ReputMessageService。\n\n### Debug形式启动Producer，Producer发送消息，断点停止后，Producer发送消息会超时失败3次，但此时如果松开断点，让他执行完，那消息是在CommitLog中呢，还是不在？\n\n### MQ在关闭的时候，CommitLog的内容和ConsumeQueue的内容需要能对上号的，但万一异常关闭导致没有对上号，应该怎么处理？CheckPoint机制有没有用？\n\n### 一个消息已经消费过了，能在控制台上选择进行重复投递么？\n\n可以。\n\n### pagecache到底是个什么东西？\n\n### 对于不可读的Consume Queue，Consumer rebalance时会不会考虑到？\n\n如果没有考虑到，那不可读的队列也分给了Consumer，造成Consumer的浪费。看过源码了，没有问题。\n\n### topic中有readQ, writeQ, 那topic本身的权限是用来做什么的？\n\n### 多个namesrv不一致问题\n\n### 如果某个topic的consume queue上有数据，那设置可读可写队列为0后，数据是不是读不到了。（我知道不会丢失）\n\n### 写Consume queue完全是一个单线程DefaultMessageStore.ReputMessageService中，那就没有锁竞争了，一个Topic到底放多少个队列效率达到最高，是越少越好，还是越多越好？\n\n### namesrv是无状态的，可以随意部署，但Broker启动后怎么是怎么知道新增加的namesrv的？\n\n### 如果发送了某个topic的某个tag的消息，那订阅了该topic的consumer是有可能过滤掉该tag的信息的。那怎么样才能知道该消息是“订阅了，被过滤了”的状态呢？\n\n首先，根据queueId和consume offset可以判断出当前消息是不是已经被\n\n### ConsumerQueue文件删除了，能够复原么？原理\n\n可以\n\n### index file删除了，能够复原么？原理\n\n可以\n\n### CommitLog和ConsumeQueue在非正常关机下变得不一致，如何恢复？\n\n### ReputMessageService中空转监听是Commitog的offset，当有新的消息时，先是构建consume queue，然后通知PullMessageHoldService，那整个过程在哪里对消息进行过滤，过滤用的是tag，consume queue中也有tag的hash，是不是只需要对比这两个值就好？\n5. 如果一个4G的文件用mmap映射到Java的MappedByteBuffer中，是绝对不可能整体加载进内存的。一个ByteBuffer就是一个有限的byte数组，但是，我们理论上可以在这个数组的任何位置（position）对数组进行读和写，然后映射进文件。如果OS能预感到我们的文件是顺序读写的，那么内存到文件的速度会非常快，如果是随机的，OS没法预测下次的读写位置，这样速度会变慢（这部分去查询下）\n6. PullConsumer：用consumer.pull(MessageQueue mq, String subExpression, long offset, int maxNums)方法去获取Broker的消息，如果第一次offset传了0，获取到了数据，第二次还是传0，还是能获取到数据，是什么原因？Broker的consumerOffset.json为什么不起作用？Pull和Push消费到的点什么时候会被persist到config/consumerOffset.json?详见MQClientInstance.persistAllConsumerOffset会把offsetTable定时发到Broker。\n\n### 程序中处理MappedByteBuffer要特别注意些什么？\n\nA MemoryMappedBuffer has a fixed size, but the file it’s mapped to is elastic.所以一旦当前的程序（或者说当前的线程）对文件的内容失去了独占权，比如文件的内容被其它的线程改了，那原先的线程访问MappedByteBuffer对应位置的缓存就会抛出异常，所以，当我们要用MappedByteBuffer时，一定要确保在多线程下是互斥的。\n这个理解是不对的！！！！\n\n### RocketMQ发送，接受消息的性能与队列数量的关系。\n\n可以查看kafka相关的信息。\n\n### 如果让你设计一个消息中间件？你会怎么设计？\n\n### 如果一个消息没有消费成功，会隔1s,5s,ns重新消费，这个是怎么实现的？\n\n### 构建IndexService是否可以做成异步？\n\n因为它如果卡住，会影响长轮询，从而影响消息接收的实时性。\n\n### Netty线程问题\nnetty在触发channelRead0的时候，所用的线程是不是workEventLoopGroup所指定的线程\nnettyClientWorkerThread\n\n### netty eventLoopGroup 是什么？\n\n### 网络端口映射\nServer:8080\ncurl 'localhost:8080'\nlsof -i:8080\n\n### 待解决问题\n```\norg.apache.rocketmq.client.exception.MQClientException: No route info of this topic, binlog-msg\nSee http://rocketmq.apache.org/docs/faq/ for further details.\n\tat org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendDefaultImpl(DefaultMQProducerImpl.java:537)\n\tat org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:1038)\n\tat org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:996)\n\tat org.apache.rocketmq.client.producer.DefaultMQProducer.send(DefaultMQProducer.java:212)\n\tat org.apache.rock\n```\n\n### 问题\n2017-10-11 07:21:38 WARN SendMessageThread_1 - Offset for /root/store/commitlog/00000000002147483648 not matched. Request offset: 4051326754958557513, index: -521875234, mappedFileSize: 1073741824, mappedFiles count: 1\n2017-10-11 07:21:38 WARN SendMessageThread_1 - findMappedFileByOffset failure. \njava.lang.ArrayIndexOutOfBoundsException: -521875234\n\n请教：rocketmq的这个异常应该如何解决呢？\n\n\n### RocketMQ水位线设置\n\n非常重要\n\n### RocketMQ 业务KEY相同导致哈希冲突\n\n### RocketMQ的Commit log什么时候munmap\n\n### RocketMQ协议\n\nRocketMQ LengthBasedField\n\n### MQ系统限流和Flow Control\n\n### RocketMQ的NameServer是不是支持分布式一致性\n\n### 现在这个版本，当Master挂掉时，Slave可以升级成新的Master么\n\n\n### RocketMQ怎么样使用性能会非常差？\n\n刷盘的策略，linux 配置的脏页的数量。脏页的比例，和脏页的大小\n\n在公司遇到一种情况，就是不断消费失败\n\n### RocketMQ到底用的是poll,epoll,还是其它的东西？？？？？？\nhttp://www.jianshu.com/p/7835726dc78b?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation\n\nhttp://www.jianshu.com/p/5ab57182af89?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation\n\n### 同步刷盘会不会丢消息?\n\n### 为什么kafka没有commitlog文件，而rocketmq有?\n\n### kafka什么场景下，性能会比较低？\n\n### 为什么有了kafka，阿里还要开发出rocketmq，rocketmq解决了什么kafka的问题？\n\n### RocketMQ怎么通过Pagecache加速的？\n![image.png](http://processon.com/chart_image/5b892eb9e4b0bd4db926c7a4.png?=1)\n\n### 怎么保证同步刷盘也有效率？\n发送消息的并发线程非常多，但是CommitLog只有一个，要想顺序写入内存然后刷盘必须上锁串行化（串行化后，磁盘IO竞争小）。串行排队等待刷盘的消息非常非常多，肯定要进行批处理，GroupCommit就是这个思想。GroupCommit首先处理队列A那些已经轮到的消息，当等待排队的刷盘的消息过来后，先把它们放到队列B中，等A中的所有消息都持久化后，锁住队列B，不让消息再进来，处理队列B，让刚刚空的队列A去接受之后排队的消息。\n\n批量一次性全部刷盘\n\n### RocketMQ QueueSelector怎么应对Topic的ConsumeQueue扩容？\n```\nAlthough it’s possible to increase the number of partitions over time, one has to be careful if messages are produced with keys. When publishing a keyed message, Kafka deterministically maps the message to a partition based on the hash of the key. This provides a guarantee that messages with the same key are always routed to the same partition. This guarantee can be important for certain applications since messages within a partition are always delivered in order to the consumer. If the number of partitions changes, such a guarantee may no longer hold. To avoid this situation, a common practice is to over-partition a bit.\n```\n\n### 消费情况\nproducerGroup只是往topic发送消息。consumerGroup只是消费topic。在broker端，消费的key为topic@consumerGroup，消费的offset取决于consumer设置的，CONSUME_FROM_LAST_OFFSET，CONSUME_FROM_FIRST_OFFSET,CONSUME_FROM_TIMESTAMP\n.CONSUME_FROM_TIMESTAMP在实际应用中还是比较少的使用。这三个区别是什么呢？\n1. 假如consumer配置为cluster模式，相同的consumerGroup，且设置客户端消费offset为CONSUME_FROM_FIRST_OFFSET，\n假如topic T的队列1的maxoffset为100，那么consumerA在启动后的队列1的消费是从0消费到100，consumerB在启动后的队列1也会从0消费到100。后续的消息即要么consumerA，要么consumerB消费。\n如果客户端设置的offset为CONSUME_FROM_LAST_OFFSET，那么consumerB在启动后的队列1是从100开始消费。后续消息消费方式相同。\nCONSUME_FROM_TIMESTAMP表示从0到100之间的某个时间点后开始消费。\n2. 假如consumer配置为cluster模式，不同的consumerGroup，这种情况的消费和广播模式一样。也就是说，后续的消息，不同的组都会收到。唯一区别在于，广播模式把已消费的进度信息保存在consumer的机器上，而集群模式保存在broker上。","slug":"RocketMQ-FAQ","published":1,"updated":"2019-09-28T08:51:00.915Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84m004sv1npyiob7eb5","content":"<blockquote>\n<p>先来一个图，总结得非常好</p>\n</blockquote>\n<p><a href=\"https://blog.csdn.net/qq_27529917/article/details/79595395\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_27529917/article/details/79595395</a><br><a href=\"https://upload-images.jianshu.io/upload_images/6302559-48fbc4f75fbf2412.png\" target=\"_blank\" rel=\"noopener\">https://upload-images.jianshu.io/upload_images/6302559-48fbc4f75fbf2412.png</a></p>\n<h3 id=\"顺序消息是怎么实现的？\"><a href=\"#顺序消息是怎么实现的？\" class=\"headerlink\" title=\"顺序消息是怎么实现的？\"></a>顺序消息是怎么实现的？</h3><p>消息的重复消费是不可避免的，但是消息的顺序需要保证。<br>a b c d e -&gt; a a b c d eee，但是不能a c b d e</p>\n<h3 id=\"RocketMQ与Kafka架构上的巨大差异-–-CommitLog与ConsumeQueue\"><a href=\"#RocketMQ与Kafka架构上的巨大差异-–-CommitLog与ConsumeQueue\" class=\"headerlink\" title=\"RocketMQ与Kafka架构上的巨大差异 – CommitLog与ConsumeQueue\"></a>RocketMQ与Kafka架构上的巨大差异 – CommitLog与ConsumeQueue</h3><p><a href=\"https://blog.csdn.net/chunlongyu/article/details/54576649\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/chunlongyu/article/details/54576649</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">每个topic_partition对应一个日志文件，Producer对该日志文件进行“顺序写”，Consumer对该文件进行“顺序读”。</span><br><span class=\"line\"></span><br><span class=\"line\">但正如在“拨乱反正”续篇中所提到的：这种存储方式，对于每个文件来说是顺序IO，但是当并发的读写多个partition的时候，对应多个文件的顺序IO，表现在文件系统的磁盘层面，还是随机IO。</span><br><span class=\"line\"></span><br><span class=\"line\">因此出现了当partition或者topic个数过多时，Kafka的性能急剧下降</span><br><span class=\"line\"></span><br><span class=\"line\">虽然每个文件是顺序IO，但topic或者partition过多，每个文件的顺序IO，表现到磁盘上，还是随机IO。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"RMQ的Name-Server怎么动态扩展？\"><a href=\"#RMQ的Name-Server怎么动态扩展？\" class=\"headerlink\" title=\"RMQ的Name Server怎么动态扩展？\"></a>RMQ的Name Server怎么动态扩展？</h3><h3 id=\"RMQ的Broker怎么动态扩展？\"><a href=\"#RMQ的Broker怎么动态扩展？\" class=\"headerlink\" title=\"RMQ的Broker怎么动态扩展？\"></a>RMQ的Broker怎么动态扩展？</h3><h3 id=\"msgId和offsetMsgId的区别\"><a href=\"#msgId和offsetMsgId的区别\" class=\"headerlink\" title=\"msgId和offsetMsgId的区别\"></a>msgId和offsetMsgId的区别</h3><p>对于客户端来说msgId是由客户端producer实例端生成的（具体来说，调用“MessageClientIDSetter.createUniqIDBuffer()”方法生成唯一的Id），offsetMsgId是由服务端Broker端在写入消息时生成的（采用“IP地址+Port端口”与“CommitLog的物理偏移量地址”做了一个字符串拼接），其中offsetMsgId就是我们在rocketMQ控制台直接输入查询的那个messageId。</p>\n<h3 id=\"异步刷盘，CommitLog和ConsumeQueue哪一个先落盘？\"><a href=\"#异步刷盘，CommitLog和ConsumeQueue哪一个先落盘？\" class=\"headerlink\" title=\"异步刷盘，CommitLog和ConsumeQueue哪一个先落盘？\"></a>异步刷盘，CommitLog和ConsumeQueue哪一个先落盘？</h3><p>当消息放到了commitlog 的page cache（即没有刷盘）后，异步写入consumequeue。从逻辑上来讲，consumequeue的构建是依赖commitlog 的，但是由于刷盘是异步的，所以落盘的顺序是不一定的。</p>\n<h3 id=\"MQ为什么内部要使用好多队列？\"><a href=\"#MQ为什么内部要使用好多队列？\" class=\"headerlink\" title=\"MQ为什么内部要使用好多队列？\"></a>MQ为什么内部要使用好多队列？</h3><ol>\n<li>send性能<br>理论上队列入口要加锁（要么是程序的锁，要么是文件的锁）来保证同步，如果队列非常多，虽然不能把锁去掉，但可以减小并发线程对锁的竞争。这个是以前的结论，但实际情况是，consume queue只有一个线程来做。首先，commit log文件只有一个，假如要执行sendMessage，一定要用sync或者自旋锁（之后的版本为了考虑性能），消息都是顺序写进commit log的。对于一个topic的某一个consumer group，consumerQueue文件就有很多个，写consumerQueue文件由一个ReputMessageService的线程近实时空转而触发，也是单个线程。从写consumerQueue文件（send message）的角度来分析，多个队列是没有好处的。</li>\n<li>consume性能<br>如果从读consumerQueue文件（pull message）的角度来分析，那确实是可以提高并行度。</li>\n</ol>\n<h3 id=\"MQ的NameServer集群节点中间有没有同步数据？与Zookeeper集群的区别是什么？\"><a href=\"#MQ的NameServer集群节点中间有没有同步数据？与Zookeeper集群的区别是什么？\" class=\"headerlink\" title=\"MQ的NameServer集群节点中间有没有同步数据？与Zookeeper集群的区别是什么？\"></a>MQ的NameServer集群节点中间有没有同步数据？与Zookeeper集群的区别是什么？</h3><h3 id=\"MQ的topic有序性怎么保证\"><a href=\"#MQ的topic有序性怎么保证\" class=\"headerlink\" title=\"MQ的topic有序性怎么保证\"></a>MQ的topic有序性怎么保证</h3><p>MessageQueueSelector中的List<messagequeue> mqs指的是所有的broker加起来的队列。</messagequeue></p>\n<h3 id=\"怎么让两个Broker中都有某个topic的信息，如果只有一个有，就没法做send的双broker负载均衡\"><a href=\"#怎么让两个Broker中都有某个topic的信息，如果只有一个有，就没法做send的双broker负载均衡\" class=\"headerlink\" title=\"怎么让两个Broker中都有某个topic的信息，如果只有一个有，就没法做send的双broker负载均衡\"></a>怎么让两个Broker中都有某个topic的信息，如果只有一个有，就没法做send的双broker负载均衡</h3><p>Client发送一个新的topic，在name server上是取不到信息的，所以先用在本地放上Map来缓存，那问题是Broker什么时候给name server发送创建Topic route info的请求？在checkMsg方法中，this.brokerController.registerBrokerAll(false, true);<br>MQ的消费者端如果是用push的方式回调，执行listener会开启新的线程用来接收和返回（确认）ack，但一般我们会再开我们的新线程去做消费的事情，这个时候如果由于外界原因进程死亡，那么这些消息就丢失了。</p>\n<h3 id=\"哪些情况会引起rebalance\"><a href=\"#哪些情况会引起rebalance\" class=\"headerlink\" title=\"哪些情况会引起rebalance?\"></a>哪些情况会引起rebalance?</h3><p>mq数量，客户端数量</p>\n<h3 id=\"怎么设计Netty的同步调用与异步调用？\"><a href=\"#怎么设计Netty的同步调用与异步调用？\" class=\"headerlink\" title=\"怎么设计Netty的同步调用与异步调用？\"></a>怎么设计Netty的同步调用与异步调用？</h3><p>掌握CountDownLatch和（限流）</p>\n<h3 id=\"万一NameServer都被重启过，那producer或者consumer调用getTopicRouteInfo，信息从何而来？\"><a href=\"#万一NameServer都被重启过，那producer或者consumer调用getTopicRouteInfo，信息从何而来？\" class=\"headerlink\" title=\"万一NameServer都被重启过，那producer或者consumer调用getTopicRouteInfo，信息从何而来？\"></a>万一NameServer都被重启过，那producer或者consumer调用getTopicRouteInfo，信息从何而来？</h3><ol>\n<li>UpdateRouteInfo应该会上传一个新的Topic的信息。</li>\n</ol>\n<h3 id=\"RocketMQ落盘是异步-定时的，还是就异步的？\"><a href=\"#RocketMQ落盘是异步-定时的，还是就异步的？\" class=\"headerlink\" title=\"RocketMQ落盘是异步+定时的，还是就异步的？\"></a>RocketMQ落盘是异步+定时的，还是就异步的？</h3><p>异步+定时，时间默认为500ms。</p>\n<p>Client向broker pull message 都是以一个一个queue为单位的。processQueueTable代表，这里面的queue正在源源不断向broker请求数据中。而broker的queue的数量是可能发生变化的，所以，要时常对processQueueTable进行必要的整理。</p>\n<p>一个Subscription对应一次rebalance调用，一般的情况是n个topic+1个Retry topic。每一次rebalance调用，都会对当前的topic分配broker中的MQ队列，如果分到n个，那个生成n个PullRequest。</p>\n<p>RebalanceServer生成 PullRequest 会调用PullMessageService 放入 PullRequest的pullRequestQueue中，PullMessageService从pullRequestQueue队列中take出PullRequest，异步调用Netty。当网络将数据传输回来时，调用PullCallback中的ConsumeMessageService，遍历所有原始消费，对每个消息，生成一个ConsumeRequest，开启多线程进行消费。消费时，返回值怎么处理？比如 Re-consume-later, success。客户端开启一个线程定时去更新Broker的consumerOffset。</p>\n<h3 id=\"为什么一旦有producer发送了消息，consumer会几乎无延迟得立刻收到消息？\"><a href=\"#为什么一旦有producer发送了消息，consumer会几乎无延迟得立刻收到消息？\" class=\"headerlink\" title=\"为什么一旦有producer发送了消息，consumer会几乎无延迟得立刻收到消息？\"></a>为什么一旦有producer发送了消息，consumer会几乎无延迟得立刻收到消息？</h3><ol>\n<li>consumer长轮询，在没有消息时hold在server端。</li>\n<li>commit log的max offset增大，触发空轮询ReputMessageService，构建完consume queue之后，调用messageArrivingListener通知消息到了，从而重新processRequest来pull消息。<br>但是问题发现了，构建ConsumeQueue理论上是有一个性能极限值的，那这样的话，不是会很容易发送的消息，消费会有延时么？<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    DefaultMessageStore.log.info(<span class=\"keyword\">this</span>.getServiceName() + <span class=\"string\">\" service started\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!<span class=\"keyword\">this</span>.isStopped()) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 这里睡眠了1ms，可以算出写入ConsumerQueue的性能极限值</span></span><br><span class=\"line\">            Thread.sleep(<span class=\"number\">1</span>);</span><br><span class=\"line\">            <span class=\"keyword\">this</span>.doReput();</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">            DefaultMessageStore.log.warn(<span class=\"keyword\">this</span>.getServiceName() + <span class=\"string\">\" service has exception. \"</span>, e);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    DefaultMessageStore.log.info(<span class=\"keyword\">this</span>.getServiceName() + <span class=\"string\">\" service end\"</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>未解决问题：</p>\n<h3 id=\"Broker里面的protectBroker是用来做什么的？\"><a href=\"#Broker里面的protectBroker是用来做什么的？\" class=\"headerlink\" title=\"Broker里面的protectBroker是用来做什么的？\"></a>Broker里面的protectBroker是用来做什么的？</h3><h3 id=\"CommitLog和ConsumerQueue这两个文件的读写是顺序的么？效率怎么样？\"><a href=\"#CommitLog和ConsumerQueue这两个文件的读写是顺序的么？效率怎么样？\" class=\"headerlink\" title=\"CommitLog和ConsumerQueue这两个文件的读写是顺序的么？效率怎么样？\"></a>CommitLog和ConsumerQueue这两个文件的读写是顺序的么？效率怎么样？</h3><h3 id=\"RocketMQ在哪几种情况下，可能会出现消息重复的问题？\"><a href=\"#RocketMQ在哪几种情况下，可能会出现消息重复的问题？\" class=\"headerlink\" title=\"RocketMQ在哪几种情况下，可能会出现消息重复的问题？\"></a>RocketMQ在哪几种情况下，可能会出现消息重复的问题？</h3><ol>\n<li>一个consume_group一开始订阅了*tag，之后加了具体的，会发生什么。</li>\n</ol>\n<h3 id=\"kafka的发送消息性能非常高，常用于日志缓冲，是不是用「Oneway」的方式？不然producer发送请求，broker处理请求，producer接受响应，这三段的时间是无论如何都无法缩减的。\"><a href=\"#kafka的发送消息性能非常高，常用于日志缓冲，是不是用「Oneway」的方式？不然producer发送请求，broker处理请求，producer接受响应，这三段的时间是无论如何都无法缩减的。\" class=\"headerlink\" title=\"kafka的发送消息性能非常高，常用于日志缓冲，是不是用「Oneway」的方式？不然producer发送请求，broker处理请求，producer接受响应，这三段的时间是无论如何都无法缩减的。\"></a>kafka的发送消息性能非常高，常用于日志缓冲，是不是用「Oneway」的方式？不然producer发送请求，broker处理请求，producer接受响应，这三段的时间是无论如何都无法缩减的。</h3><h3 id=\"RocketMQ的事务消息是什么？\"><a href=\"#RocketMQ的事务消息是什么？\" class=\"headerlink\" title=\"RocketMQ的事务消息是什么？\"></a>RocketMQ的事务消息是什么？</h3><p>看到一段描述很有趣，当发送了分布式事务消息时，如果Producer因为意外宕机，Broker会回调Producer Group的另一一台Producer来确认事务状态。<br>2. Commit Log 中存储了所有的元信息，包含消息体，类似于 Mysql、Oracle 的 redolog，所以只要有 Commit<br>   Log 在，Consume Queue 即使数据丢失，仍然可以恢复出来。怎么理解？<br>3. 在Broker的SendMessageProcessor中，主干线程中只做了一件事，那就是把最新的消息Append到CommitLog中，并且通知Flush线程去force() mmap。所以，构建ConsumeQueue，构建索引这些事情都是异步的，那好像也没有看到通知这些线程，究竟是在哪里通知的呢？ Dispatcher（调度器）ReputMessageService。</p>\n<h3 id=\"Debug形式启动Producer，Producer发送消息，断点停止后，Producer发送消息会超时失败3次，但此时如果松开断点，让他执行完，那消息是在CommitLog中呢，还是不在？\"><a href=\"#Debug形式启动Producer，Producer发送消息，断点停止后，Producer发送消息会超时失败3次，但此时如果松开断点，让他执行完，那消息是在CommitLog中呢，还是不在？\" class=\"headerlink\" title=\"Debug形式启动Producer，Producer发送消息，断点停止后，Producer发送消息会超时失败3次，但此时如果松开断点，让他执行完，那消息是在CommitLog中呢，还是不在？\"></a>Debug形式启动Producer，Producer发送消息，断点停止后，Producer发送消息会超时失败3次，但此时如果松开断点，让他执行完，那消息是在CommitLog中呢，还是不在？</h3><h3 id=\"MQ在关闭的时候，CommitLog的内容和ConsumeQueue的内容需要能对上号的，但万一异常关闭导致没有对上号，应该怎么处理？CheckPoint机制有没有用？\"><a href=\"#MQ在关闭的时候，CommitLog的内容和ConsumeQueue的内容需要能对上号的，但万一异常关闭导致没有对上号，应该怎么处理？CheckPoint机制有没有用？\" class=\"headerlink\" title=\"MQ在关闭的时候，CommitLog的内容和ConsumeQueue的内容需要能对上号的，但万一异常关闭导致没有对上号，应该怎么处理？CheckPoint机制有没有用？\"></a>MQ在关闭的时候，CommitLog的内容和ConsumeQueue的内容需要能对上号的，但万一异常关闭导致没有对上号，应该怎么处理？CheckPoint机制有没有用？</h3><h3 id=\"一个消息已经消费过了，能在控制台上选择进行重复投递么？\"><a href=\"#一个消息已经消费过了，能在控制台上选择进行重复投递么？\" class=\"headerlink\" title=\"一个消息已经消费过了，能在控制台上选择进行重复投递么？\"></a>一个消息已经消费过了，能在控制台上选择进行重复投递么？</h3><p>可以。</p>\n<h3 id=\"pagecache到底是个什么东西？\"><a href=\"#pagecache到底是个什么东西？\" class=\"headerlink\" title=\"pagecache到底是个什么东西？\"></a>pagecache到底是个什么东西？</h3><h3 id=\"对于不可读的Consume-Queue，Consumer-rebalance时会不会考虑到？\"><a href=\"#对于不可读的Consume-Queue，Consumer-rebalance时会不会考虑到？\" class=\"headerlink\" title=\"对于不可读的Consume Queue，Consumer rebalance时会不会考虑到？\"></a>对于不可读的Consume Queue，Consumer rebalance时会不会考虑到？</h3><p>如果没有考虑到，那不可读的队列也分给了Consumer，造成Consumer的浪费。看过源码了，没有问题。</p>\n<h3 id=\"topic中有readQ-writeQ-那topic本身的权限是用来做什么的？\"><a href=\"#topic中有readQ-writeQ-那topic本身的权限是用来做什么的？\" class=\"headerlink\" title=\"topic中有readQ, writeQ, 那topic本身的权限是用来做什么的？\"></a>topic中有readQ, writeQ, 那topic本身的权限是用来做什么的？</h3><h3 id=\"多个namesrv不一致问题\"><a href=\"#多个namesrv不一致问题\" class=\"headerlink\" title=\"多个namesrv不一致问题\"></a>多个namesrv不一致问题</h3><h3 id=\"如果某个topic的consume-queue上有数据，那设置可读可写队列为0后，数据是不是读不到了。（我知道不会丢失）\"><a href=\"#如果某个topic的consume-queue上有数据，那设置可读可写队列为0后，数据是不是读不到了。（我知道不会丢失）\" class=\"headerlink\" title=\"如果某个topic的consume queue上有数据，那设置可读可写队列为0后，数据是不是读不到了。（我知道不会丢失）\"></a>如果某个topic的consume queue上有数据，那设置可读可写队列为0后，数据是不是读不到了。（我知道不会丢失）</h3><h3 id=\"写Consume-queue完全是一个单线程DefaultMessageStore-ReputMessageService中，那就没有锁竞争了，一个Topic到底放多少个队列效率达到最高，是越少越好，还是越多越好？\"><a href=\"#写Consume-queue完全是一个单线程DefaultMessageStore-ReputMessageService中，那就没有锁竞争了，一个Topic到底放多少个队列效率达到最高，是越少越好，还是越多越好？\" class=\"headerlink\" title=\"写Consume queue完全是一个单线程DefaultMessageStore.ReputMessageService中，那就没有锁竞争了，一个Topic到底放多少个队列效率达到最高，是越少越好，还是越多越好？\"></a>写Consume queue完全是一个单线程DefaultMessageStore.ReputMessageService中，那就没有锁竞争了，一个Topic到底放多少个队列效率达到最高，是越少越好，还是越多越好？</h3><h3 id=\"namesrv是无状态的，可以随意部署，但Broker启动后怎么是怎么知道新增加的namesrv的？\"><a href=\"#namesrv是无状态的，可以随意部署，但Broker启动后怎么是怎么知道新增加的namesrv的？\" class=\"headerlink\" title=\"namesrv是无状态的，可以随意部署，但Broker启动后怎么是怎么知道新增加的namesrv的？\"></a>namesrv是无状态的，可以随意部署，但Broker启动后怎么是怎么知道新增加的namesrv的？</h3><h3 id=\"如果发送了某个topic的某个tag的消息，那订阅了该topic的consumer是有可能过滤掉该tag的信息的。那怎么样才能知道该消息是“订阅了，被过滤了”的状态呢？\"><a href=\"#如果发送了某个topic的某个tag的消息，那订阅了该topic的consumer是有可能过滤掉该tag的信息的。那怎么样才能知道该消息是“订阅了，被过滤了”的状态呢？\" class=\"headerlink\" title=\"如果发送了某个topic的某个tag的消息，那订阅了该topic的consumer是有可能过滤掉该tag的信息的。那怎么样才能知道该消息是“订阅了，被过滤了”的状态呢？\"></a>如果发送了某个topic的某个tag的消息，那订阅了该topic的consumer是有可能过滤掉该tag的信息的。那怎么样才能知道该消息是“订阅了，被过滤了”的状态呢？</h3><p>首先，根据queueId和consume offset可以判断出当前消息是不是已经被</p>\n<h3 id=\"ConsumerQueue文件删除了，能够复原么？原理\"><a href=\"#ConsumerQueue文件删除了，能够复原么？原理\" class=\"headerlink\" title=\"ConsumerQueue文件删除了，能够复原么？原理\"></a>ConsumerQueue文件删除了，能够复原么？原理</h3><p>可以</p>\n<h3 id=\"index-file删除了，能够复原么？原理\"><a href=\"#index-file删除了，能够复原么？原理\" class=\"headerlink\" title=\"index file删除了，能够复原么？原理\"></a>index file删除了，能够复原么？原理</h3><p>可以</p>\n<h3 id=\"CommitLog和ConsumeQueue在非正常关机下变得不一致，如何恢复？\"><a href=\"#CommitLog和ConsumeQueue在非正常关机下变得不一致，如何恢复？\" class=\"headerlink\" title=\"CommitLog和ConsumeQueue在非正常关机下变得不一致，如何恢复？\"></a>CommitLog和ConsumeQueue在非正常关机下变得不一致，如何恢复？</h3><h3 id=\"ReputMessageService中空转监听是Commitog的offset，当有新的消息时，先是构建consume-queue，然后通知PullMessageHoldService，那整个过程在哪里对消息进行过滤，过滤用的是tag，consume-queue中也有tag的hash，是不是只需要对比这两个值就好？\"><a href=\"#ReputMessageService中空转监听是Commitog的offset，当有新的消息时，先是构建consume-queue，然后通知PullMessageHoldService，那整个过程在哪里对消息进行过滤，过滤用的是tag，consume-queue中也有tag的hash，是不是只需要对比这两个值就好？\" class=\"headerlink\" title=\"ReputMessageService中空转监听是Commitog的offset，当有新的消息时，先是构建consume queue，然后通知PullMessageHoldService，那整个过程在哪里对消息进行过滤，过滤用的是tag，consume queue中也有tag的hash，是不是只需要对比这两个值就好？\"></a>ReputMessageService中空转监听是Commitog的offset，当有新的消息时，先是构建consume queue，然后通知PullMessageHoldService，那整个过程在哪里对消息进行过滤，过滤用的是tag，consume queue中也有tag的hash，是不是只需要对比这两个值就好？</h3><ol start=\"5\">\n<li>如果一个4G的文件用mmap映射到Java的MappedByteBuffer中，是绝对不可能整体加载进内存的。一个ByteBuffer就是一个有限的byte数组，但是，我们理论上可以在这个数组的任何位置（position）对数组进行读和写，然后映射进文件。如果OS能预感到我们的文件是顺序读写的，那么内存到文件的速度会非常快，如果是随机的，OS没法预测下次的读写位置，这样速度会变慢（这部分去查询下）</li>\n<li>PullConsumer：用consumer.pull(MessageQueue mq, String subExpression, long offset, int maxNums)方法去获取Broker的消息，如果第一次offset传了0，获取到了数据，第二次还是传0，还是能获取到数据，是什么原因？Broker的consumerOffset.json为什么不起作用？Pull和Push消费到的点什么时候会被persist到config/consumerOffset.json?详见MQClientInstance.persistAllConsumerOffset会把offsetTable定时发到Broker。</li>\n</ol>\n<h3 id=\"程序中处理MappedByteBuffer要特别注意些什么？\"><a href=\"#程序中处理MappedByteBuffer要特别注意些什么？\" class=\"headerlink\" title=\"程序中处理MappedByteBuffer要特别注意些什么？\"></a>程序中处理MappedByteBuffer要特别注意些什么？</h3><p>A MemoryMappedBuffer has a fixed size, but the file it’s mapped to is elastic.所以一旦当前的程序（或者说当前的线程）对文件的内容失去了独占权，比如文件的内容被其它的线程改了，那原先的线程访问MappedByteBuffer对应位置的缓存就会抛出异常，所以，当我们要用MappedByteBuffer时，一定要确保在多线程下是互斥的。<br>这个理解是不对的！！！！</p>\n<h3 id=\"RocketMQ发送，接受消息的性能与队列数量的关系。\"><a href=\"#RocketMQ发送，接受消息的性能与队列数量的关系。\" class=\"headerlink\" title=\"RocketMQ发送，接受消息的性能与队列数量的关系。\"></a>RocketMQ发送，接受消息的性能与队列数量的关系。</h3><p>可以查看kafka相关的信息。</p>\n<h3 id=\"如果让你设计一个消息中间件？你会怎么设计？\"><a href=\"#如果让你设计一个消息中间件？你会怎么设计？\" class=\"headerlink\" title=\"如果让你设计一个消息中间件？你会怎么设计？\"></a>如果让你设计一个消息中间件？你会怎么设计？</h3><h3 id=\"如果一个消息没有消费成功，会隔1s-5s-ns重新消费，这个是怎么实现的？\"><a href=\"#如果一个消息没有消费成功，会隔1s-5s-ns重新消费，这个是怎么实现的？\" class=\"headerlink\" title=\"如果一个消息没有消费成功，会隔1s,5s,ns重新消费，这个是怎么实现的？\"></a>如果一个消息没有消费成功，会隔1s,5s,ns重新消费，这个是怎么实现的？</h3><h3 id=\"构建IndexService是否可以做成异步？\"><a href=\"#构建IndexService是否可以做成异步？\" class=\"headerlink\" title=\"构建IndexService是否可以做成异步？\"></a>构建IndexService是否可以做成异步？</h3><p>因为它如果卡住，会影响长轮询，从而影响消息接收的实时性。</p>\n<h3 id=\"Netty线程问题\"><a href=\"#Netty线程问题\" class=\"headerlink\" title=\"Netty线程问题\"></a>Netty线程问题</h3><p>netty在触发channelRead0的时候，所用的线程是不是workEventLoopGroup所指定的线程<br>nettyClientWorkerThread</p>\n<h3 id=\"netty-eventLoopGroup-是什么？\"><a href=\"#netty-eventLoopGroup-是什么？\" class=\"headerlink\" title=\"netty eventLoopGroup 是什么？\"></a>netty eventLoopGroup 是什么？</h3><h3 id=\"网络端口映射\"><a href=\"#网络端口映射\" class=\"headerlink\" title=\"网络端口映射\"></a>网络端口映射</h3><p>Server:8080<br>curl ‘localhost:8080’<br>lsof -i:8080</p>\n<h3 id=\"待解决问题\"><a href=\"#待解决问题\" class=\"headerlink\" title=\"待解决问题\"></a>待解决问题</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">org.apache.rocketmq.client.exception.MQClientException: No route info of this topic, binlog-msg</span><br><span class=\"line\">See http://rocketmq.apache.org/docs/faq/ for further details.</span><br><span class=\"line\">\tat org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendDefaultImpl(DefaultMQProducerImpl.java:537)</span><br><span class=\"line\">\tat org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:1038)</span><br><span class=\"line\">\tat org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:996)</span><br><span class=\"line\">\tat org.apache.rocketmq.client.producer.DefaultMQProducer.send(DefaultMQProducer.java:212)</span><br><span class=\"line\">\tat org.apache.rock</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><p>2017-10-11 07:21:38 WARN SendMessageThread_1 - Offset for /root/store/commitlog/00000000002147483648 not matched. Request offset: 4051326754958557513, index: -521875234, mappedFileSize: 1073741824, mappedFiles count: 1<br>2017-10-11 07:21:38 WARN SendMessageThread_1 - findMappedFileByOffset failure.<br>java.lang.ArrayIndexOutOfBoundsException: -521875234</p>\n<p>请教：rocketmq的这个异常应该如何解决呢？</p>\n<h3 id=\"RocketMQ水位线设置\"><a href=\"#RocketMQ水位线设置\" class=\"headerlink\" title=\"RocketMQ水位线设置\"></a>RocketMQ水位线设置</h3><p>非常重要</p>\n<h3 id=\"RocketMQ-业务KEY相同导致哈希冲突\"><a href=\"#RocketMQ-业务KEY相同导致哈希冲突\" class=\"headerlink\" title=\"RocketMQ 业务KEY相同导致哈希冲突\"></a>RocketMQ 业务KEY相同导致哈希冲突</h3><h3 id=\"RocketMQ的Commit-log什么时候munmap\"><a href=\"#RocketMQ的Commit-log什么时候munmap\" class=\"headerlink\" title=\"RocketMQ的Commit log什么时候munmap\"></a>RocketMQ的Commit log什么时候munmap</h3><h3 id=\"RocketMQ协议\"><a href=\"#RocketMQ协议\" class=\"headerlink\" title=\"RocketMQ协议\"></a>RocketMQ协议</h3><p>RocketMQ LengthBasedField</p>\n<h3 id=\"MQ系统限流和Flow-Control\"><a href=\"#MQ系统限流和Flow-Control\" class=\"headerlink\" title=\"MQ系统限流和Flow Control\"></a>MQ系统限流和Flow Control</h3><h3 id=\"RocketMQ的NameServer是不是支持分布式一致性\"><a href=\"#RocketMQ的NameServer是不是支持分布式一致性\" class=\"headerlink\" title=\"RocketMQ的NameServer是不是支持分布式一致性\"></a>RocketMQ的NameServer是不是支持分布式一致性</h3><h3 id=\"现在这个版本，当Master挂掉时，Slave可以升级成新的Master么\"><a href=\"#现在这个版本，当Master挂掉时，Slave可以升级成新的Master么\" class=\"headerlink\" title=\"现在这个版本，当Master挂掉时，Slave可以升级成新的Master么\"></a>现在这个版本，当Master挂掉时，Slave可以升级成新的Master么</h3><h3 id=\"RocketMQ怎么样使用性能会非常差？\"><a href=\"#RocketMQ怎么样使用性能会非常差？\" class=\"headerlink\" title=\"RocketMQ怎么样使用性能会非常差？\"></a>RocketMQ怎么样使用性能会非常差？</h3><p>刷盘的策略，linux 配置的脏页的数量。脏页的比例，和脏页的大小</p>\n<p>在公司遇到一种情况，就是不断消费失败</p>\n<h3 id=\"RocketMQ到底用的是poll-epoll-还是其它的东西？？？？？？\"><a href=\"#RocketMQ到底用的是poll-epoll-还是其它的东西？？？？？？\" class=\"headerlink\" title=\"RocketMQ到底用的是poll,epoll,还是其它的东西？？？？？？\"></a>RocketMQ到底用的是poll,epoll,还是其它的东西？？？？？？</h3><p><a href=\"http://www.jianshu.com/p/7835726dc78b?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/7835726dc78b?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation</a></p>\n<p><a href=\"http://www.jianshu.com/p/5ab57182af89?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/5ab57182af89?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation</a></p>\n<h3 id=\"同步刷盘会不会丢消息\"><a href=\"#同步刷盘会不会丢消息\" class=\"headerlink\" title=\"同步刷盘会不会丢消息?\"></a>同步刷盘会不会丢消息?</h3><h3 id=\"为什么kafka没有commitlog文件，而rocketmq有\"><a href=\"#为什么kafka没有commitlog文件，而rocketmq有\" class=\"headerlink\" title=\"为什么kafka没有commitlog文件，而rocketmq有?\"></a>为什么kafka没有commitlog文件，而rocketmq有?</h3><h3 id=\"kafka什么场景下，性能会比较低？\"><a href=\"#kafka什么场景下，性能会比较低？\" class=\"headerlink\" title=\"kafka什么场景下，性能会比较低？\"></a>kafka什么场景下，性能会比较低？</h3><h3 id=\"为什么有了kafka，阿里还要开发出rocketmq，rocketmq解决了什么kafka的问题？\"><a href=\"#为什么有了kafka，阿里还要开发出rocketmq，rocketmq解决了什么kafka的问题？\" class=\"headerlink\" title=\"为什么有了kafka，阿里还要开发出rocketmq，rocketmq解决了什么kafka的问题？\"></a>为什么有了kafka，阿里还要开发出rocketmq，rocketmq解决了什么kafka的问题？</h3><h3 id=\"RocketMQ怎么通过Pagecache加速的？\"><a href=\"#RocketMQ怎么通过Pagecache加速的？\" class=\"headerlink\" title=\"RocketMQ怎么通过Pagecache加速的？\"></a>RocketMQ怎么通过Pagecache加速的？</h3><p><img src=\"http://processon.com/chart_image/5b892eb9e4b0bd4db926c7a4.png?=1\" alt=\"image.png\"></p>\n<h3 id=\"怎么保证同步刷盘也有效率？\"><a href=\"#怎么保证同步刷盘也有效率？\" class=\"headerlink\" title=\"怎么保证同步刷盘也有效率？\"></a>怎么保证同步刷盘也有效率？</h3><p>发送消息的并发线程非常多，但是CommitLog只有一个，要想顺序写入内存然后刷盘必须上锁串行化（串行化后，磁盘IO竞争小）。串行排队等待刷盘的消息非常非常多，肯定要进行批处理，GroupCommit就是这个思想。GroupCommit首先处理队列A那些已经轮到的消息，当等待排队的刷盘的消息过来后，先把它们放到队列B中，等A中的所有消息都持久化后，锁住队列B，不让消息再进来，处理队列B，让刚刚空的队列A去接受之后排队的消息。</p>\n<p>批量一次性全部刷盘</p>\n<h3 id=\"RocketMQ-QueueSelector怎么应对Topic的ConsumeQueue扩容？\"><a href=\"#RocketMQ-QueueSelector怎么应对Topic的ConsumeQueue扩容？\" class=\"headerlink\" title=\"RocketMQ QueueSelector怎么应对Topic的ConsumeQueue扩容？\"></a>RocketMQ QueueSelector怎么应对Topic的ConsumeQueue扩容？</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Although it’s possible to increase the number of partitions over time, one has to be careful if messages are produced with keys. When publishing a keyed message, Kafka deterministically maps the message to a partition based on the hash of the key. This provides a guarantee that messages with the same key are always routed to the same partition. This guarantee can be important for certain applications since messages within a partition are always delivered in order to the consumer. If the number of partitions changes, such a guarantee may no longer hold. To avoid this situation, a common practice is to over-partition a bit.</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"消费情况\"><a href=\"#消费情况\" class=\"headerlink\" title=\"消费情况\"></a>消费情况</h3><p>producerGroup只是往topic发送消息。consumerGroup只是消费topic。在broker端，消费的key为topic@consumerGroup，消费的offset取决于consumer设置的，CONSUME_FROM_LAST_OFFSET，CONSUME_FROM_FIRST_OFFSET,CONSUME_FROM_TIMESTAMP<br>.CONSUME_FROM_TIMESTAMP在实际应用中还是比较少的使用。这三个区别是什么呢？</p>\n<ol>\n<li>假如consumer配置为cluster模式，相同的consumerGroup，且设置客户端消费offset为CONSUME_FROM_FIRST_OFFSET，<br>假如topic T的队列1的maxoffset为100，那么consumerA在启动后的队列1的消费是从0消费到100，consumerB在启动后的队列1也会从0消费到100。后续的消息即要么consumerA，要么consumerB消费。<br>如果客户端设置的offset为CONSUME_FROM_LAST_OFFSET，那么consumerB在启动后的队列1是从100开始消费。后续消息消费方式相同。<br>CONSUME_FROM_TIMESTAMP表示从0到100之间的某个时间点后开始消费。</li>\n<li>假如consumer配置为cluster模式，不同的consumerGroup，这种情况的消费和广播模式一样。也就是说，后续的消息，不同的组都会收到。唯一区别在于，广播模式把已消费的进度信息保存在consumer的机器上，而集群模式保存在broker上。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>先来一个图，总结得非常好</p>\n</blockquote>\n<p><a href=\"https://blog.csdn.net/qq_27529917/article/details/79595395\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_27529917/article/details/79595395</a><br><a href=\"https://upload-images.jianshu.io/upload_images/6302559-48fbc4f75fbf2412.png\" target=\"_blank\" rel=\"noopener\">https://upload-images.jianshu.io/upload_images/6302559-48fbc4f75fbf2412.png</a></p>\n<h3 id=\"顺序消息是怎么实现的？\"><a href=\"#顺序消息是怎么实现的？\" class=\"headerlink\" title=\"顺序消息是怎么实现的？\"></a>顺序消息是怎么实现的？</h3><p>消息的重复消费是不可避免的，但是消息的顺序需要保证。<br>a b c d e -&gt; a a b c d eee，但是不能a c b d e</p>\n<h3 id=\"RocketMQ与Kafka架构上的巨大差异-–-CommitLog与ConsumeQueue\"><a href=\"#RocketMQ与Kafka架构上的巨大差异-–-CommitLog与ConsumeQueue\" class=\"headerlink\" title=\"RocketMQ与Kafka架构上的巨大差异 – CommitLog与ConsumeQueue\"></a>RocketMQ与Kafka架构上的巨大差异 – CommitLog与ConsumeQueue</h3><p><a href=\"https://blog.csdn.net/chunlongyu/article/details/54576649\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/chunlongyu/article/details/54576649</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">每个topic_partition对应一个日志文件，Producer对该日志文件进行“顺序写”，Consumer对该文件进行“顺序读”。</span><br><span class=\"line\"></span><br><span class=\"line\">但正如在“拨乱反正”续篇中所提到的：这种存储方式，对于每个文件来说是顺序IO，但是当并发的读写多个partition的时候，对应多个文件的顺序IO，表现在文件系统的磁盘层面，还是随机IO。</span><br><span class=\"line\"></span><br><span class=\"line\">因此出现了当partition或者topic个数过多时，Kafka的性能急剧下降</span><br><span class=\"line\"></span><br><span class=\"line\">虽然每个文件是顺序IO，但topic或者partition过多，每个文件的顺序IO，表现到磁盘上，还是随机IO。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"RMQ的Name-Server怎么动态扩展？\"><a href=\"#RMQ的Name-Server怎么动态扩展？\" class=\"headerlink\" title=\"RMQ的Name Server怎么动态扩展？\"></a>RMQ的Name Server怎么动态扩展？</h3><h3 id=\"RMQ的Broker怎么动态扩展？\"><a href=\"#RMQ的Broker怎么动态扩展？\" class=\"headerlink\" title=\"RMQ的Broker怎么动态扩展？\"></a>RMQ的Broker怎么动态扩展？</h3><h3 id=\"msgId和offsetMsgId的区别\"><a href=\"#msgId和offsetMsgId的区别\" class=\"headerlink\" title=\"msgId和offsetMsgId的区别\"></a>msgId和offsetMsgId的区别</h3><p>对于客户端来说msgId是由客户端producer实例端生成的（具体来说，调用“MessageClientIDSetter.createUniqIDBuffer()”方法生成唯一的Id），offsetMsgId是由服务端Broker端在写入消息时生成的（采用“IP地址+Port端口”与“CommitLog的物理偏移量地址”做了一个字符串拼接），其中offsetMsgId就是我们在rocketMQ控制台直接输入查询的那个messageId。</p>\n<h3 id=\"异步刷盘，CommitLog和ConsumeQueue哪一个先落盘？\"><a href=\"#异步刷盘，CommitLog和ConsumeQueue哪一个先落盘？\" class=\"headerlink\" title=\"异步刷盘，CommitLog和ConsumeQueue哪一个先落盘？\"></a>异步刷盘，CommitLog和ConsumeQueue哪一个先落盘？</h3><p>当消息放到了commitlog 的page cache（即没有刷盘）后，异步写入consumequeue。从逻辑上来讲，consumequeue的构建是依赖commitlog 的，但是由于刷盘是异步的，所以落盘的顺序是不一定的。</p>\n<h3 id=\"MQ为什么内部要使用好多队列？\"><a href=\"#MQ为什么内部要使用好多队列？\" class=\"headerlink\" title=\"MQ为什么内部要使用好多队列？\"></a>MQ为什么内部要使用好多队列？</h3><ol>\n<li>send性能<br>理论上队列入口要加锁（要么是程序的锁，要么是文件的锁）来保证同步，如果队列非常多，虽然不能把锁去掉，但可以减小并发线程对锁的竞争。这个是以前的结论，但实际情况是，consume queue只有一个线程来做。首先，commit log文件只有一个，假如要执行sendMessage，一定要用sync或者自旋锁（之后的版本为了考虑性能），消息都是顺序写进commit log的。对于一个topic的某一个consumer group，consumerQueue文件就有很多个，写consumerQueue文件由一个ReputMessageService的线程近实时空转而触发，也是单个线程。从写consumerQueue文件（send message）的角度来分析，多个队列是没有好处的。</li>\n<li>consume性能<br>如果从读consumerQueue文件（pull message）的角度来分析，那确实是可以提高并行度。</li>\n</ol>\n<h3 id=\"MQ的NameServer集群节点中间有没有同步数据？与Zookeeper集群的区别是什么？\"><a href=\"#MQ的NameServer集群节点中间有没有同步数据？与Zookeeper集群的区别是什么？\" class=\"headerlink\" title=\"MQ的NameServer集群节点中间有没有同步数据？与Zookeeper集群的区别是什么？\"></a>MQ的NameServer集群节点中间有没有同步数据？与Zookeeper集群的区别是什么？</h3><h3 id=\"MQ的topic有序性怎么保证\"><a href=\"#MQ的topic有序性怎么保证\" class=\"headerlink\" title=\"MQ的topic有序性怎么保证\"></a>MQ的topic有序性怎么保证</h3><p>MessageQueueSelector中的List<messagequeue> mqs指的是所有的broker加起来的队列。</messagequeue></p>\n<h3 id=\"怎么让两个Broker中都有某个topic的信息，如果只有一个有，就没法做send的双broker负载均衡\"><a href=\"#怎么让两个Broker中都有某个topic的信息，如果只有一个有，就没法做send的双broker负载均衡\" class=\"headerlink\" title=\"怎么让两个Broker中都有某个topic的信息，如果只有一个有，就没法做send的双broker负载均衡\"></a>怎么让两个Broker中都有某个topic的信息，如果只有一个有，就没法做send的双broker负载均衡</h3><p>Client发送一个新的topic，在name server上是取不到信息的，所以先用在本地放上Map来缓存，那问题是Broker什么时候给name server发送创建Topic route info的请求？在checkMsg方法中，this.brokerController.registerBrokerAll(false, true);<br>MQ的消费者端如果是用push的方式回调，执行listener会开启新的线程用来接收和返回（确认）ack，但一般我们会再开我们的新线程去做消费的事情，这个时候如果由于外界原因进程死亡，那么这些消息就丢失了。</p>\n<h3 id=\"哪些情况会引起rebalance\"><a href=\"#哪些情况会引起rebalance\" class=\"headerlink\" title=\"哪些情况会引起rebalance?\"></a>哪些情况会引起rebalance?</h3><p>mq数量，客户端数量</p>\n<h3 id=\"怎么设计Netty的同步调用与异步调用？\"><a href=\"#怎么设计Netty的同步调用与异步调用？\" class=\"headerlink\" title=\"怎么设计Netty的同步调用与异步调用？\"></a>怎么设计Netty的同步调用与异步调用？</h3><p>掌握CountDownLatch和（限流）</p>\n<h3 id=\"万一NameServer都被重启过，那producer或者consumer调用getTopicRouteInfo，信息从何而来？\"><a href=\"#万一NameServer都被重启过，那producer或者consumer调用getTopicRouteInfo，信息从何而来？\" class=\"headerlink\" title=\"万一NameServer都被重启过，那producer或者consumer调用getTopicRouteInfo，信息从何而来？\"></a>万一NameServer都被重启过，那producer或者consumer调用getTopicRouteInfo，信息从何而来？</h3><ol>\n<li>UpdateRouteInfo应该会上传一个新的Topic的信息。</li>\n</ol>\n<h3 id=\"RocketMQ落盘是异步-定时的，还是就异步的？\"><a href=\"#RocketMQ落盘是异步-定时的，还是就异步的？\" class=\"headerlink\" title=\"RocketMQ落盘是异步+定时的，还是就异步的？\"></a>RocketMQ落盘是异步+定时的，还是就异步的？</h3><p>异步+定时，时间默认为500ms。</p>\n<p>Client向broker pull message 都是以一个一个queue为单位的。processQueueTable代表，这里面的queue正在源源不断向broker请求数据中。而broker的queue的数量是可能发生变化的，所以，要时常对processQueueTable进行必要的整理。</p>\n<p>一个Subscription对应一次rebalance调用，一般的情况是n个topic+1个Retry topic。每一次rebalance调用，都会对当前的topic分配broker中的MQ队列，如果分到n个，那个生成n个PullRequest。</p>\n<p>RebalanceServer生成 PullRequest 会调用PullMessageService 放入 PullRequest的pullRequestQueue中，PullMessageService从pullRequestQueue队列中take出PullRequest，异步调用Netty。当网络将数据传输回来时，调用PullCallback中的ConsumeMessageService，遍历所有原始消费，对每个消息，生成一个ConsumeRequest，开启多线程进行消费。消费时，返回值怎么处理？比如 Re-consume-later, success。客户端开启一个线程定时去更新Broker的consumerOffset。</p>\n<h3 id=\"为什么一旦有producer发送了消息，consumer会几乎无延迟得立刻收到消息？\"><a href=\"#为什么一旦有producer发送了消息，consumer会几乎无延迟得立刻收到消息？\" class=\"headerlink\" title=\"为什么一旦有producer发送了消息，consumer会几乎无延迟得立刻收到消息？\"></a>为什么一旦有producer发送了消息，consumer会几乎无延迟得立刻收到消息？</h3><ol>\n<li>consumer长轮询，在没有消息时hold在server端。</li>\n<li>commit log的max offset增大，触发空轮询ReputMessageService，构建完consume queue之后，调用messageArrivingListener通知消息到了，从而重新processRequest来pull消息。<br>但是问题发现了，构建ConsumeQueue理论上是有一个性能极限值的，那这样的话，不是会很容易发送的消息，消费会有延时么？<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Override</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    DefaultMessageStore.log.info(<span class=\"keyword\">this</span>.getServiceName() + <span class=\"string\">\" service started\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (!<span class=\"keyword\">this</span>.isStopped()) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 这里睡眠了1ms，可以算出写入ConsumerQueue的性能极限值</span></span><br><span class=\"line\">            Thread.sleep(<span class=\"number\">1</span>);</span><br><span class=\"line\">            <span class=\"keyword\">this</span>.doReput();</span><br><span class=\"line\">        &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">            DefaultMessageStore.log.warn(<span class=\"keyword\">this</span>.getServiceName() + <span class=\"string\">\" service has exception. \"</span>, e);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    DefaultMessageStore.log.info(<span class=\"keyword\">this</span>.getServiceName() + <span class=\"string\">\" service end\"</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n</li>\n</ol>\n<p>未解决问题：</p>\n<h3 id=\"Broker里面的protectBroker是用来做什么的？\"><a href=\"#Broker里面的protectBroker是用来做什么的？\" class=\"headerlink\" title=\"Broker里面的protectBroker是用来做什么的？\"></a>Broker里面的protectBroker是用来做什么的？</h3><h3 id=\"CommitLog和ConsumerQueue这两个文件的读写是顺序的么？效率怎么样？\"><a href=\"#CommitLog和ConsumerQueue这两个文件的读写是顺序的么？效率怎么样？\" class=\"headerlink\" title=\"CommitLog和ConsumerQueue这两个文件的读写是顺序的么？效率怎么样？\"></a>CommitLog和ConsumerQueue这两个文件的读写是顺序的么？效率怎么样？</h3><h3 id=\"RocketMQ在哪几种情况下，可能会出现消息重复的问题？\"><a href=\"#RocketMQ在哪几种情况下，可能会出现消息重复的问题？\" class=\"headerlink\" title=\"RocketMQ在哪几种情况下，可能会出现消息重复的问题？\"></a>RocketMQ在哪几种情况下，可能会出现消息重复的问题？</h3><ol>\n<li>一个consume_group一开始订阅了*tag，之后加了具体的，会发生什么。</li>\n</ol>\n<h3 id=\"kafka的发送消息性能非常高，常用于日志缓冲，是不是用「Oneway」的方式？不然producer发送请求，broker处理请求，producer接受响应，这三段的时间是无论如何都无法缩减的。\"><a href=\"#kafka的发送消息性能非常高，常用于日志缓冲，是不是用「Oneway」的方式？不然producer发送请求，broker处理请求，producer接受响应，这三段的时间是无论如何都无法缩减的。\" class=\"headerlink\" title=\"kafka的发送消息性能非常高，常用于日志缓冲，是不是用「Oneway」的方式？不然producer发送请求，broker处理请求，producer接受响应，这三段的时间是无论如何都无法缩减的。\"></a>kafka的发送消息性能非常高，常用于日志缓冲，是不是用「Oneway」的方式？不然producer发送请求，broker处理请求，producer接受响应，这三段的时间是无论如何都无法缩减的。</h3><h3 id=\"RocketMQ的事务消息是什么？\"><a href=\"#RocketMQ的事务消息是什么？\" class=\"headerlink\" title=\"RocketMQ的事务消息是什么？\"></a>RocketMQ的事务消息是什么？</h3><p>看到一段描述很有趣，当发送了分布式事务消息时，如果Producer因为意外宕机，Broker会回调Producer Group的另一一台Producer来确认事务状态。<br>2. Commit Log 中存储了所有的元信息，包含消息体，类似于 Mysql、Oracle 的 redolog，所以只要有 Commit<br>   Log 在，Consume Queue 即使数据丢失，仍然可以恢复出来。怎么理解？<br>3. 在Broker的SendMessageProcessor中，主干线程中只做了一件事，那就是把最新的消息Append到CommitLog中，并且通知Flush线程去force() mmap。所以，构建ConsumeQueue，构建索引这些事情都是异步的，那好像也没有看到通知这些线程，究竟是在哪里通知的呢？ Dispatcher（调度器）ReputMessageService。</p>\n<h3 id=\"Debug形式启动Producer，Producer发送消息，断点停止后，Producer发送消息会超时失败3次，但此时如果松开断点，让他执行完，那消息是在CommitLog中呢，还是不在？\"><a href=\"#Debug形式启动Producer，Producer发送消息，断点停止后，Producer发送消息会超时失败3次，但此时如果松开断点，让他执行完，那消息是在CommitLog中呢，还是不在？\" class=\"headerlink\" title=\"Debug形式启动Producer，Producer发送消息，断点停止后，Producer发送消息会超时失败3次，但此时如果松开断点，让他执行完，那消息是在CommitLog中呢，还是不在？\"></a>Debug形式启动Producer，Producer发送消息，断点停止后，Producer发送消息会超时失败3次，但此时如果松开断点，让他执行完，那消息是在CommitLog中呢，还是不在？</h3><h3 id=\"MQ在关闭的时候，CommitLog的内容和ConsumeQueue的内容需要能对上号的，但万一异常关闭导致没有对上号，应该怎么处理？CheckPoint机制有没有用？\"><a href=\"#MQ在关闭的时候，CommitLog的内容和ConsumeQueue的内容需要能对上号的，但万一异常关闭导致没有对上号，应该怎么处理？CheckPoint机制有没有用？\" class=\"headerlink\" title=\"MQ在关闭的时候，CommitLog的内容和ConsumeQueue的内容需要能对上号的，但万一异常关闭导致没有对上号，应该怎么处理？CheckPoint机制有没有用？\"></a>MQ在关闭的时候，CommitLog的内容和ConsumeQueue的内容需要能对上号的，但万一异常关闭导致没有对上号，应该怎么处理？CheckPoint机制有没有用？</h3><h3 id=\"一个消息已经消费过了，能在控制台上选择进行重复投递么？\"><a href=\"#一个消息已经消费过了，能在控制台上选择进行重复投递么？\" class=\"headerlink\" title=\"一个消息已经消费过了，能在控制台上选择进行重复投递么？\"></a>一个消息已经消费过了，能在控制台上选择进行重复投递么？</h3><p>可以。</p>\n<h3 id=\"pagecache到底是个什么东西？\"><a href=\"#pagecache到底是个什么东西？\" class=\"headerlink\" title=\"pagecache到底是个什么东西？\"></a>pagecache到底是个什么东西？</h3><h3 id=\"对于不可读的Consume-Queue，Consumer-rebalance时会不会考虑到？\"><a href=\"#对于不可读的Consume-Queue，Consumer-rebalance时会不会考虑到？\" class=\"headerlink\" title=\"对于不可读的Consume Queue，Consumer rebalance时会不会考虑到？\"></a>对于不可读的Consume Queue，Consumer rebalance时会不会考虑到？</h3><p>如果没有考虑到，那不可读的队列也分给了Consumer，造成Consumer的浪费。看过源码了，没有问题。</p>\n<h3 id=\"topic中有readQ-writeQ-那topic本身的权限是用来做什么的？\"><a href=\"#topic中有readQ-writeQ-那topic本身的权限是用来做什么的？\" class=\"headerlink\" title=\"topic中有readQ, writeQ, 那topic本身的权限是用来做什么的？\"></a>topic中有readQ, writeQ, 那topic本身的权限是用来做什么的？</h3><h3 id=\"多个namesrv不一致问题\"><a href=\"#多个namesrv不一致问题\" class=\"headerlink\" title=\"多个namesrv不一致问题\"></a>多个namesrv不一致问题</h3><h3 id=\"如果某个topic的consume-queue上有数据，那设置可读可写队列为0后，数据是不是读不到了。（我知道不会丢失）\"><a href=\"#如果某个topic的consume-queue上有数据，那设置可读可写队列为0后，数据是不是读不到了。（我知道不会丢失）\" class=\"headerlink\" title=\"如果某个topic的consume queue上有数据，那设置可读可写队列为0后，数据是不是读不到了。（我知道不会丢失）\"></a>如果某个topic的consume queue上有数据，那设置可读可写队列为0后，数据是不是读不到了。（我知道不会丢失）</h3><h3 id=\"写Consume-queue完全是一个单线程DefaultMessageStore-ReputMessageService中，那就没有锁竞争了，一个Topic到底放多少个队列效率达到最高，是越少越好，还是越多越好？\"><a href=\"#写Consume-queue完全是一个单线程DefaultMessageStore-ReputMessageService中，那就没有锁竞争了，一个Topic到底放多少个队列效率达到最高，是越少越好，还是越多越好？\" class=\"headerlink\" title=\"写Consume queue完全是一个单线程DefaultMessageStore.ReputMessageService中，那就没有锁竞争了，一个Topic到底放多少个队列效率达到最高，是越少越好，还是越多越好？\"></a>写Consume queue完全是一个单线程DefaultMessageStore.ReputMessageService中，那就没有锁竞争了，一个Topic到底放多少个队列效率达到最高，是越少越好，还是越多越好？</h3><h3 id=\"namesrv是无状态的，可以随意部署，但Broker启动后怎么是怎么知道新增加的namesrv的？\"><a href=\"#namesrv是无状态的，可以随意部署，但Broker启动后怎么是怎么知道新增加的namesrv的？\" class=\"headerlink\" title=\"namesrv是无状态的，可以随意部署，但Broker启动后怎么是怎么知道新增加的namesrv的？\"></a>namesrv是无状态的，可以随意部署，但Broker启动后怎么是怎么知道新增加的namesrv的？</h3><h3 id=\"如果发送了某个topic的某个tag的消息，那订阅了该topic的consumer是有可能过滤掉该tag的信息的。那怎么样才能知道该消息是“订阅了，被过滤了”的状态呢？\"><a href=\"#如果发送了某个topic的某个tag的消息，那订阅了该topic的consumer是有可能过滤掉该tag的信息的。那怎么样才能知道该消息是“订阅了，被过滤了”的状态呢？\" class=\"headerlink\" title=\"如果发送了某个topic的某个tag的消息，那订阅了该topic的consumer是有可能过滤掉该tag的信息的。那怎么样才能知道该消息是“订阅了，被过滤了”的状态呢？\"></a>如果发送了某个topic的某个tag的消息，那订阅了该topic的consumer是有可能过滤掉该tag的信息的。那怎么样才能知道该消息是“订阅了，被过滤了”的状态呢？</h3><p>首先，根据queueId和consume offset可以判断出当前消息是不是已经被</p>\n<h3 id=\"ConsumerQueue文件删除了，能够复原么？原理\"><a href=\"#ConsumerQueue文件删除了，能够复原么？原理\" class=\"headerlink\" title=\"ConsumerQueue文件删除了，能够复原么？原理\"></a>ConsumerQueue文件删除了，能够复原么？原理</h3><p>可以</p>\n<h3 id=\"index-file删除了，能够复原么？原理\"><a href=\"#index-file删除了，能够复原么？原理\" class=\"headerlink\" title=\"index file删除了，能够复原么？原理\"></a>index file删除了，能够复原么？原理</h3><p>可以</p>\n<h3 id=\"CommitLog和ConsumeQueue在非正常关机下变得不一致，如何恢复？\"><a href=\"#CommitLog和ConsumeQueue在非正常关机下变得不一致，如何恢复？\" class=\"headerlink\" title=\"CommitLog和ConsumeQueue在非正常关机下变得不一致，如何恢复？\"></a>CommitLog和ConsumeQueue在非正常关机下变得不一致，如何恢复？</h3><h3 id=\"ReputMessageService中空转监听是Commitog的offset，当有新的消息时，先是构建consume-queue，然后通知PullMessageHoldService，那整个过程在哪里对消息进行过滤，过滤用的是tag，consume-queue中也有tag的hash，是不是只需要对比这两个值就好？\"><a href=\"#ReputMessageService中空转监听是Commitog的offset，当有新的消息时，先是构建consume-queue，然后通知PullMessageHoldService，那整个过程在哪里对消息进行过滤，过滤用的是tag，consume-queue中也有tag的hash，是不是只需要对比这两个值就好？\" class=\"headerlink\" title=\"ReputMessageService中空转监听是Commitog的offset，当有新的消息时，先是构建consume queue，然后通知PullMessageHoldService，那整个过程在哪里对消息进行过滤，过滤用的是tag，consume queue中也有tag的hash，是不是只需要对比这两个值就好？\"></a>ReputMessageService中空转监听是Commitog的offset，当有新的消息时，先是构建consume queue，然后通知PullMessageHoldService，那整个过程在哪里对消息进行过滤，过滤用的是tag，consume queue中也有tag的hash，是不是只需要对比这两个值就好？</h3><ol start=\"5\">\n<li>如果一个4G的文件用mmap映射到Java的MappedByteBuffer中，是绝对不可能整体加载进内存的。一个ByteBuffer就是一个有限的byte数组，但是，我们理论上可以在这个数组的任何位置（position）对数组进行读和写，然后映射进文件。如果OS能预感到我们的文件是顺序读写的，那么内存到文件的速度会非常快，如果是随机的，OS没法预测下次的读写位置，这样速度会变慢（这部分去查询下）</li>\n<li>PullConsumer：用consumer.pull(MessageQueue mq, String subExpression, long offset, int maxNums)方法去获取Broker的消息，如果第一次offset传了0，获取到了数据，第二次还是传0，还是能获取到数据，是什么原因？Broker的consumerOffset.json为什么不起作用？Pull和Push消费到的点什么时候会被persist到config/consumerOffset.json?详见MQClientInstance.persistAllConsumerOffset会把offsetTable定时发到Broker。</li>\n</ol>\n<h3 id=\"程序中处理MappedByteBuffer要特别注意些什么？\"><a href=\"#程序中处理MappedByteBuffer要特别注意些什么？\" class=\"headerlink\" title=\"程序中处理MappedByteBuffer要特别注意些什么？\"></a>程序中处理MappedByteBuffer要特别注意些什么？</h3><p>A MemoryMappedBuffer has a fixed size, but the file it’s mapped to is elastic.所以一旦当前的程序（或者说当前的线程）对文件的内容失去了独占权，比如文件的内容被其它的线程改了，那原先的线程访问MappedByteBuffer对应位置的缓存就会抛出异常，所以，当我们要用MappedByteBuffer时，一定要确保在多线程下是互斥的。<br>这个理解是不对的！！！！</p>\n<h3 id=\"RocketMQ发送，接受消息的性能与队列数量的关系。\"><a href=\"#RocketMQ发送，接受消息的性能与队列数量的关系。\" class=\"headerlink\" title=\"RocketMQ发送，接受消息的性能与队列数量的关系。\"></a>RocketMQ发送，接受消息的性能与队列数量的关系。</h3><p>可以查看kafka相关的信息。</p>\n<h3 id=\"如果让你设计一个消息中间件？你会怎么设计？\"><a href=\"#如果让你设计一个消息中间件？你会怎么设计？\" class=\"headerlink\" title=\"如果让你设计一个消息中间件？你会怎么设计？\"></a>如果让你设计一个消息中间件？你会怎么设计？</h3><h3 id=\"如果一个消息没有消费成功，会隔1s-5s-ns重新消费，这个是怎么实现的？\"><a href=\"#如果一个消息没有消费成功，会隔1s-5s-ns重新消费，这个是怎么实现的？\" class=\"headerlink\" title=\"如果一个消息没有消费成功，会隔1s,5s,ns重新消费，这个是怎么实现的？\"></a>如果一个消息没有消费成功，会隔1s,5s,ns重新消费，这个是怎么实现的？</h3><h3 id=\"构建IndexService是否可以做成异步？\"><a href=\"#构建IndexService是否可以做成异步？\" class=\"headerlink\" title=\"构建IndexService是否可以做成异步？\"></a>构建IndexService是否可以做成异步？</h3><p>因为它如果卡住，会影响长轮询，从而影响消息接收的实时性。</p>\n<h3 id=\"Netty线程问题\"><a href=\"#Netty线程问题\" class=\"headerlink\" title=\"Netty线程问题\"></a>Netty线程问题</h3><p>netty在触发channelRead0的时候，所用的线程是不是workEventLoopGroup所指定的线程<br>nettyClientWorkerThread</p>\n<h3 id=\"netty-eventLoopGroup-是什么？\"><a href=\"#netty-eventLoopGroup-是什么？\" class=\"headerlink\" title=\"netty eventLoopGroup 是什么？\"></a>netty eventLoopGroup 是什么？</h3><h3 id=\"网络端口映射\"><a href=\"#网络端口映射\" class=\"headerlink\" title=\"网络端口映射\"></a>网络端口映射</h3><p>Server:8080<br>curl ‘localhost:8080’<br>lsof -i:8080</p>\n<h3 id=\"待解决问题\"><a href=\"#待解决问题\" class=\"headerlink\" title=\"待解决问题\"></a>待解决问题</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">org.apache.rocketmq.client.exception.MQClientException: No route info of this topic, binlog-msg</span><br><span class=\"line\">See http://rocketmq.apache.org/docs/faq/ for further details.</span><br><span class=\"line\">\tat org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendDefaultImpl(DefaultMQProducerImpl.java:537)</span><br><span class=\"line\">\tat org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:1038)</span><br><span class=\"line\">\tat org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:996)</span><br><span class=\"line\">\tat org.apache.rocketmq.client.producer.DefaultMQProducer.send(DefaultMQProducer.java:212)</span><br><span class=\"line\">\tat org.apache.rock</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><p>2017-10-11 07:21:38 WARN SendMessageThread_1 - Offset for /root/store/commitlog/00000000002147483648 not matched. Request offset: 4051326754958557513, index: -521875234, mappedFileSize: 1073741824, mappedFiles count: 1<br>2017-10-11 07:21:38 WARN SendMessageThread_1 - findMappedFileByOffset failure.<br>java.lang.ArrayIndexOutOfBoundsException: -521875234</p>\n<p>请教：rocketmq的这个异常应该如何解决呢？</p>\n<h3 id=\"RocketMQ水位线设置\"><a href=\"#RocketMQ水位线设置\" class=\"headerlink\" title=\"RocketMQ水位线设置\"></a>RocketMQ水位线设置</h3><p>非常重要</p>\n<h3 id=\"RocketMQ-业务KEY相同导致哈希冲突\"><a href=\"#RocketMQ-业务KEY相同导致哈希冲突\" class=\"headerlink\" title=\"RocketMQ 业务KEY相同导致哈希冲突\"></a>RocketMQ 业务KEY相同导致哈希冲突</h3><h3 id=\"RocketMQ的Commit-log什么时候munmap\"><a href=\"#RocketMQ的Commit-log什么时候munmap\" class=\"headerlink\" title=\"RocketMQ的Commit log什么时候munmap\"></a>RocketMQ的Commit log什么时候munmap</h3><h3 id=\"RocketMQ协议\"><a href=\"#RocketMQ协议\" class=\"headerlink\" title=\"RocketMQ协议\"></a>RocketMQ协议</h3><p>RocketMQ LengthBasedField</p>\n<h3 id=\"MQ系统限流和Flow-Control\"><a href=\"#MQ系统限流和Flow-Control\" class=\"headerlink\" title=\"MQ系统限流和Flow Control\"></a>MQ系统限流和Flow Control</h3><h3 id=\"RocketMQ的NameServer是不是支持分布式一致性\"><a href=\"#RocketMQ的NameServer是不是支持分布式一致性\" class=\"headerlink\" title=\"RocketMQ的NameServer是不是支持分布式一致性\"></a>RocketMQ的NameServer是不是支持分布式一致性</h3><h3 id=\"现在这个版本，当Master挂掉时，Slave可以升级成新的Master么\"><a href=\"#现在这个版本，当Master挂掉时，Slave可以升级成新的Master么\" class=\"headerlink\" title=\"现在这个版本，当Master挂掉时，Slave可以升级成新的Master么\"></a>现在这个版本，当Master挂掉时，Slave可以升级成新的Master么</h3><h3 id=\"RocketMQ怎么样使用性能会非常差？\"><a href=\"#RocketMQ怎么样使用性能会非常差？\" class=\"headerlink\" title=\"RocketMQ怎么样使用性能会非常差？\"></a>RocketMQ怎么样使用性能会非常差？</h3><p>刷盘的策略，linux 配置的脏页的数量。脏页的比例，和脏页的大小</p>\n<p>在公司遇到一种情况，就是不断消费失败</p>\n<h3 id=\"RocketMQ到底用的是poll-epoll-还是其它的东西？？？？？？\"><a href=\"#RocketMQ到底用的是poll-epoll-还是其它的东西？？？？？？\" class=\"headerlink\" title=\"RocketMQ到底用的是poll,epoll,还是其它的东西？？？？？？\"></a>RocketMQ到底用的是poll,epoll,还是其它的东西？？？？？？</h3><p><a href=\"http://www.jianshu.com/p/7835726dc78b?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/7835726dc78b?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation</a></p>\n<p><a href=\"http://www.jianshu.com/p/5ab57182af89?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/5ab57182af89?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation</a></p>\n<h3 id=\"同步刷盘会不会丢消息\"><a href=\"#同步刷盘会不会丢消息\" class=\"headerlink\" title=\"同步刷盘会不会丢消息?\"></a>同步刷盘会不会丢消息?</h3><h3 id=\"为什么kafka没有commitlog文件，而rocketmq有\"><a href=\"#为什么kafka没有commitlog文件，而rocketmq有\" class=\"headerlink\" title=\"为什么kafka没有commitlog文件，而rocketmq有?\"></a>为什么kafka没有commitlog文件，而rocketmq有?</h3><h3 id=\"kafka什么场景下，性能会比较低？\"><a href=\"#kafka什么场景下，性能会比较低？\" class=\"headerlink\" title=\"kafka什么场景下，性能会比较低？\"></a>kafka什么场景下，性能会比较低？</h3><h3 id=\"为什么有了kafka，阿里还要开发出rocketmq，rocketmq解决了什么kafka的问题？\"><a href=\"#为什么有了kafka，阿里还要开发出rocketmq，rocketmq解决了什么kafka的问题？\" class=\"headerlink\" title=\"为什么有了kafka，阿里还要开发出rocketmq，rocketmq解决了什么kafka的问题？\"></a>为什么有了kafka，阿里还要开发出rocketmq，rocketmq解决了什么kafka的问题？</h3><h3 id=\"RocketMQ怎么通过Pagecache加速的？\"><a href=\"#RocketMQ怎么通过Pagecache加速的？\" class=\"headerlink\" title=\"RocketMQ怎么通过Pagecache加速的？\"></a>RocketMQ怎么通过Pagecache加速的？</h3><p><img src=\"http://processon.com/chart_image/5b892eb9e4b0bd4db926c7a4.png?=1\" alt=\"image.png\"></p>\n<h3 id=\"怎么保证同步刷盘也有效率？\"><a href=\"#怎么保证同步刷盘也有效率？\" class=\"headerlink\" title=\"怎么保证同步刷盘也有效率？\"></a>怎么保证同步刷盘也有效率？</h3><p>发送消息的并发线程非常多，但是CommitLog只有一个，要想顺序写入内存然后刷盘必须上锁串行化（串行化后，磁盘IO竞争小）。串行排队等待刷盘的消息非常非常多，肯定要进行批处理，GroupCommit就是这个思想。GroupCommit首先处理队列A那些已经轮到的消息，当等待排队的刷盘的消息过来后，先把它们放到队列B中，等A中的所有消息都持久化后，锁住队列B，不让消息再进来，处理队列B，让刚刚空的队列A去接受之后排队的消息。</p>\n<p>批量一次性全部刷盘</p>\n<h3 id=\"RocketMQ-QueueSelector怎么应对Topic的ConsumeQueue扩容？\"><a href=\"#RocketMQ-QueueSelector怎么应对Topic的ConsumeQueue扩容？\" class=\"headerlink\" title=\"RocketMQ QueueSelector怎么应对Topic的ConsumeQueue扩容？\"></a>RocketMQ QueueSelector怎么应对Topic的ConsumeQueue扩容？</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Although it’s possible to increase the number of partitions over time, one has to be careful if messages are produced with keys. When publishing a keyed message, Kafka deterministically maps the message to a partition based on the hash of the key. This provides a guarantee that messages with the same key are always routed to the same partition. This guarantee can be important for certain applications since messages within a partition are always delivered in order to the consumer. If the number of partitions changes, such a guarantee may no longer hold. To avoid this situation, a common practice is to over-partition a bit.</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"消费情况\"><a href=\"#消费情况\" class=\"headerlink\" title=\"消费情况\"></a>消费情况</h3><p>producerGroup只是往topic发送消息。consumerGroup只是消费topic。在broker端，消费的key为topic@consumerGroup，消费的offset取决于consumer设置的，CONSUME_FROM_LAST_OFFSET，CONSUME_FROM_FIRST_OFFSET,CONSUME_FROM_TIMESTAMP<br>.CONSUME_FROM_TIMESTAMP在实际应用中还是比较少的使用。这三个区别是什么呢？</p>\n<ol>\n<li>假如consumer配置为cluster模式，相同的consumerGroup，且设置客户端消费offset为CONSUME_FROM_FIRST_OFFSET，<br>假如topic T的队列1的maxoffset为100，那么consumerA在启动后的队列1的消费是从0消费到100，consumerB在启动后的队列1也会从0消费到100。后续的消息即要么consumerA，要么consumerB消费。<br>如果客户端设置的offset为CONSUME_FROM_LAST_OFFSET，那么consumerB在启动后的队列1是从100开始消费。后续消息消费方式相同。<br>CONSUME_FROM_TIMESTAMP表示从0到100之间的某个时间点后开始消费。</li>\n<li>假如consumer配置为cluster模式，不同的consumerGroup，这种情况的消费和广播模式一样。也就是说，后续的消息，不同的组都会收到。唯一区别在于，广播模式把已消费的进度信息保存在consumer的机器上，而集群模式保存在broker上。</li>\n</ol>\n"},{"title":"RocketMQ在Intellij中的终极调试技巧（一）","date":"2017-08-20T05:28:52.000Z","_content":"\n### 调试难点\n\n如果虚拟机够多\n可以规划将MQ的各个部分部署在不同机器上，并且在所有子系统启动时加上远程调试。然后Intellij创建几个Remote debug窗口。\n\n如果没有虚拟机，只有一台Mac，接下去的内容将对RocketMQ的调试有非常大的帮助。\n\n### 调试界面\n\n![image.png](http://upload-images.jianshu.io/upload_images/716353-1c36c4f4f54283e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n### Name Server\n\nvm options: -Drocketmq.home.dir=/Users/eric/Code/middleware/rocketmq\n\n### Broker\nBroker的调试最为麻烦，\n如果在学习RocketMQ的初期，建议单启动一个Broker，减少复杂度，关注主要流程代码。\n如果要深入学习和调试，要启动Master和Slave，开启主从同步功能，也是会发生端口和文件目录冲突的地方。\n\nstore的目录都为`System.getProperty(\"user.home\") + File.separator + \"store\"`，\n所以我们需要对Master和Slave进行分离，方法很多种，这里介绍一种，在启动参数中配置不同的`user.home`。\n\nPort的分离可以放在不同的配置文件中：broker-a.properties，broker-a-s.properties\n\n#### Master Broker\n\n```\nVM options:-Drocketmq.home.dir=/Users/eric/Code/middleware/rocketmq -Drocketmq.namesrv.addr=mac:9876 -Duser.home=/Users/eric/store/master\nProgram arguments:-c /Users/eric/Code/middleware/rocketmq/distribution/conf/2m-noslave/broker-a.properties\n\nbroker-a.properties:\nbrokerClusterName=DefaultCluster\nbrokerName=broker-a\nbrokerId=0\ndeleteWhen=04\nfileReservedTime=48\nbrokerRole=SYNC_MASTER\nflushDiskType=ASYNC_FLUSH\nlistenPort=11111\n```\n\n![image.png](http://upload-images.jianshu.io/upload_images/716353-269519f3558de100.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n#### Slave Broker\n```\nVM options:-Drocketmq.home.dir=/Users/eric/Code/middleware/incubator-rocketmq -Drocketmq.namesrv.addr=mac:9876 -Duser.home=/Users/eric/store/slave\nProgram arguments:-c /Users/eric/Code/middleware/incubator-rocketmq/conf/2m-2s-sync/broker-a-s.properties\n\nbroker-a-s.properties:\nbrokerClusterName=DefaultCluster\nbrokerName=broker-a\nbrokerId=1\ndeleteWhen=04\nfileReservedTime=48\nbrokerRole=SLAVE\nflushDiskType=ASYNC_FLUSH\nlistenPort=22222\n```\n\n### Producer\nVM options: -Drocketmq.client.logRoot=/Users/eric/store/master/logs/consume/\n\n![image.png](http://upload-images.jianshu.io/upload_images/716353-473218e8e6936674.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n配置完后依次启动 Name Server, Master Broker, Slave Broker， Producer\n\n完整的Store目录结构截图\n\n![](https://ws1.sinaimg.cn/large/006tKfTcgy1fkedpuigp8j317e1a80zy.jpg)\n\n技巧\n\n1. 充分利用作者写好的单元测试，对原理的掌握会有帮助\n2. RocketMQ有太多的事情是用 （短时间）定时+唤醒 的方式异步执行的，想要更好得了解原理，最好把定时的时间改得大一点，这样多线程的调试会好做很多。","source":"_posts/RocketMQ-Debug-with-intellij.md","raw":"---\ntitle: RocketMQ在Intellij中的终极调试技巧（一）\ndate: 2017-08-20 13:28:52\ntags: RocketMQ\n---\n\n### 调试难点\n\n如果虚拟机够多\n可以规划将MQ的各个部分部署在不同机器上，并且在所有子系统启动时加上远程调试。然后Intellij创建几个Remote debug窗口。\n\n如果没有虚拟机，只有一台Mac，接下去的内容将对RocketMQ的调试有非常大的帮助。\n\n### 调试界面\n\n![image.png](http://upload-images.jianshu.io/upload_images/716353-1c36c4f4f54283e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n### Name Server\n\nvm options: -Drocketmq.home.dir=/Users/eric/Code/middleware/rocketmq\n\n### Broker\nBroker的调试最为麻烦，\n如果在学习RocketMQ的初期，建议单启动一个Broker，减少复杂度，关注主要流程代码。\n如果要深入学习和调试，要启动Master和Slave，开启主从同步功能，也是会发生端口和文件目录冲突的地方。\n\nstore的目录都为`System.getProperty(\"user.home\") + File.separator + \"store\"`，\n所以我们需要对Master和Slave进行分离，方法很多种，这里介绍一种，在启动参数中配置不同的`user.home`。\n\nPort的分离可以放在不同的配置文件中：broker-a.properties，broker-a-s.properties\n\n#### Master Broker\n\n```\nVM options:-Drocketmq.home.dir=/Users/eric/Code/middleware/rocketmq -Drocketmq.namesrv.addr=mac:9876 -Duser.home=/Users/eric/store/master\nProgram arguments:-c /Users/eric/Code/middleware/rocketmq/distribution/conf/2m-noslave/broker-a.properties\n\nbroker-a.properties:\nbrokerClusterName=DefaultCluster\nbrokerName=broker-a\nbrokerId=0\ndeleteWhen=04\nfileReservedTime=48\nbrokerRole=SYNC_MASTER\nflushDiskType=ASYNC_FLUSH\nlistenPort=11111\n```\n\n![image.png](http://upload-images.jianshu.io/upload_images/716353-269519f3558de100.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n#### Slave Broker\n```\nVM options:-Drocketmq.home.dir=/Users/eric/Code/middleware/incubator-rocketmq -Drocketmq.namesrv.addr=mac:9876 -Duser.home=/Users/eric/store/slave\nProgram arguments:-c /Users/eric/Code/middleware/incubator-rocketmq/conf/2m-2s-sync/broker-a-s.properties\n\nbroker-a-s.properties:\nbrokerClusterName=DefaultCluster\nbrokerName=broker-a\nbrokerId=1\ndeleteWhen=04\nfileReservedTime=48\nbrokerRole=SLAVE\nflushDiskType=ASYNC_FLUSH\nlistenPort=22222\n```\n\n### Producer\nVM options: -Drocketmq.client.logRoot=/Users/eric/store/master/logs/consume/\n\n![image.png](http://upload-images.jianshu.io/upload_images/716353-473218e8e6936674.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n配置完后依次启动 Name Server, Master Broker, Slave Broker， Producer\n\n完整的Store目录结构截图\n\n![](https://ws1.sinaimg.cn/large/006tKfTcgy1fkedpuigp8j317e1a80zy.jpg)\n\n技巧\n\n1. 充分利用作者写好的单元测试，对原理的掌握会有帮助\n2. RocketMQ有太多的事情是用 （短时间）定时+唤醒 的方式异步执行的，想要更好得了解原理，最好把定时的时间改得大一点，这样多线程的调试会好做很多。","slug":"RocketMQ-Debug-with-intellij","published":1,"updated":"2019-09-28T08:51:00.914Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84m004tv1nprhwta91x","content":"<h3 id=\"调试难点\"><a href=\"#调试难点\" class=\"headerlink\" title=\"调试难点\"></a>调试难点</h3><p>如果虚拟机够多<br>可以规划将MQ的各个部分部署在不同机器上，并且在所有子系统启动时加上远程调试。然后Intellij创建几个Remote debug窗口。</p>\n<p>如果没有虚拟机，只有一台Mac，接下去的内容将对RocketMQ的调试有非常大的帮助。</p>\n<h3 id=\"调试界面\"><a href=\"#调试界面\" class=\"headerlink\" title=\"调试界面\"></a>调试界面</h3><p><img src=\"http://upload-images.jianshu.io/upload_images/716353-1c36c4f4f54283e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h3 id=\"Name-Server\"><a href=\"#Name-Server\" class=\"headerlink\" title=\"Name Server\"></a>Name Server</h3><p>vm options: -Drocketmq.home.dir=/Users/eric/Code/middleware/rocketmq</p>\n<h3 id=\"Broker\"><a href=\"#Broker\" class=\"headerlink\" title=\"Broker\"></a>Broker</h3><p>Broker的调试最为麻烦，<br>如果在学习RocketMQ的初期，建议单启动一个Broker，减少复杂度，关注主要流程代码。<br>如果要深入学习和调试，要启动Master和Slave，开启主从同步功能，也是会发生端口和文件目录冲突的地方。</p>\n<p>store的目录都为<code>System.getProperty(&quot;user.home&quot;) + File.separator + &quot;store&quot;</code>，<br>所以我们需要对Master和Slave进行分离，方法很多种，这里介绍一种，在启动参数中配置不同的<code>user.home</code>。</p>\n<p>Port的分离可以放在不同的配置文件中：broker-a.properties，broker-a-s.properties</p>\n<h4 id=\"Master-Broker\"><a href=\"#Master-Broker\" class=\"headerlink\" title=\"Master Broker\"></a>Master Broker</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">VM options:-Drocketmq.home.dir=/Users/eric/Code/middleware/rocketmq -Drocketmq.namesrv.addr=mac:9876 -Duser.home=/Users/eric/store/master</span><br><span class=\"line\">Program arguments:-c /Users/eric/Code/middleware/rocketmq/distribution/conf/2m-noslave/broker-a.properties</span><br><span class=\"line\"></span><br><span class=\"line\">broker-a.properties:</span><br><span class=\"line\">brokerClusterName=DefaultCluster</span><br><span class=\"line\">brokerName=broker-a</span><br><span class=\"line\">brokerId=0</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\">fileReservedTime=48</span><br><span class=\"line\">brokerRole=SYNC_MASTER</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\">listenPort=11111</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"http://upload-images.jianshu.io/upload_images/716353-269519f3558de100.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h4 id=\"Slave-Broker\"><a href=\"#Slave-Broker\" class=\"headerlink\" title=\"Slave Broker\"></a>Slave Broker</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">VM options:-Drocketmq.home.dir=/Users/eric/Code/middleware/incubator-rocketmq -Drocketmq.namesrv.addr=mac:9876 -Duser.home=/Users/eric/store/slave</span><br><span class=\"line\">Program arguments:-c /Users/eric/Code/middleware/incubator-rocketmq/conf/2m-2s-sync/broker-a-s.properties</span><br><span class=\"line\"></span><br><span class=\"line\">broker-a-s.properties:</span><br><span class=\"line\">brokerClusterName=DefaultCluster</span><br><span class=\"line\">brokerName=broker-a</span><br><span class=\"line\">brokerId=1</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\">fileReservedTime=48</span><br><span class=\"line\">brokerRole=SLAVE</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\">listenPort=22222</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Producer\"><a href=\"#Producer\" class=\"headerlink\" title=\"Producer\"></a>Producer</h3><p>VM options: -Drocketmq.client.logRoot=/Users/eric/store/master/logs/consume/</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/716353-473218e8e6936674.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<p>配置完后依次启动 Name Server, Master Broker, Slave Broker， Producer</p>\n<p>完整的Store目录结构截图</p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tKfTcgy1fkedpuigp8j317e1a80zy.jpg\" alt=\"\"></p>\n<p>技巧</p>\n<ol>\n<li>充分利用作者写好的单元测试，对原理的掌握会有帮助</li>\n<li>RocketMQ有太多的事情是用 （短时间）定时+唤醒 的方式异步执行的，想要更好得了解原理，最好把定时的时间改得大一点，这样多线程的调试会好做很多。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"调试难点\"><a href=\"#调试难点\" class=\"headerlink\" title=\"调试难点\"></a>调试难点</h3><p>如果虚拟机够多<br>可以规划将MQ的各个部分部署在不同机器上，并且在所有子系统启动时加上远程调试。然后Intellij创建几个Remote debug窗口。</p>\n<p>如果没有虚拟机，只有一台Mac，接下去的内容将对RocketMQ的调试有非常大的帮助。</p>\n<h3 id=\"调试界面\"><a href=\"#调试界面\" class=\"headerlink\" title=\"调试界面\"></a>调试界面</h3><p><img src=\"http://upload-images.jianshu.io/upload_images/716353-1c36c4f4f54283e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h3 id=\"Name-Server\"><a href=\"#Name-Server\" class=\"headerlink\" title=\"Name Server\"></a>Name Server</h3><p>vm options: -Drocketmq.home.dir=/Users/eric/Code/middleware/rocketmq</p>\n<h3 id=\"Broker\"><a href=\"#Broker\" class=\"headerlink\" title=\"Broker\"></a>Broker</h3><p>Broker的调试最为麻烦，<br>如果在学习RocketMQ的初期，建议单启动一个Broker，减少复杂度，关注主要流程代码。<br>如果要深入学习和调试，要启动Master和Slave，开启主从同步功能，也是会发生端口和文件目录冲突的地方。</p>\n<p>store的目录都为<code>System.getProperty(&quot;user.home&quot;) + File.separator + &quot;store&quot;</code>，<br>所以我们需要对Master和Slave进行分离，方法很多种，这里介绍一种，在启动参数中配置不同的<code>user.home</code>。</p>\n<p>Port的分离可以放在不同的配置文件中：broker-a.properties，broker-a-s.properties</p>\n<h4 id=\"Master-Broker\"><a href=\"#Master-Broker\" class=\"headerlink\" title=\"Master Broker\"></a>Master Broker</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">VM options:-Drocketmq.home.dir=/Users/eric/Code/middleware/rocketmq -Drocketmq.namesrv.addr=mac:9876 -Duser.home=/Users/eric/store/master</span><br><span class=\"line\">Program arguments:-c /Users/eric/Code/middleware/rocketmq/distribution/conf/2m-noslave/broker-a.properties</span><br><span class=\"line\"></span><br><span class=\"line\">broker-a.properties:</span><br><span class=\"line\">brokerClusterName=DefaultCluster</span><br><span class=\"line\">brokerName=broker-a</span><br><span class=\"line\">brokerId=0</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\">fileReservedTime=48</span><br><span class=\"line\">brokerRole=SYNC_MASTER</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\">listenPort=11111</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"http://upload-images.jianshu.io/upload_images/716353-269519f3558de100.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<h4 id=\"Slave-Broker\"><a href=\"#Slave-Broker\" class=\"headerlink\" title=\"Slave Broker\"></a>Slave Broker</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">VM options:-Drocketmq.home.dir=/Users/eric/Code/middleware/incubator-rocketmq -Drocketmq.namesrv.addr=mac:9876 -Duser.home=/Users/eric/store/slave</span><br><span class=\"line\">Program arguments:-c /Users/eric/Code/middleware/incubator-rocketmq/conf/2m-2s-sync/broker-a-s.properties</span><br><span class=\"line\"></span><br><span class=\"line\">broker-a-s.properties:</span><br><span class=\"line\">brokerClusterName=DefaultCluster</span><br><span class=\"line\">brokerName=broker-a</span><br><span class=\"line\">brokerId=1</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\">fileReservedTime=48</span><br><span class=\"line\">brokerRole=SLAVE</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\">listenPort=22222</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Producer\"><a href=\"#Producer\" class=\"headerlink\" title=\"Producer\"></a>Producer</h3><p>VM options: -Drocketmq.client.logRoot=/Users/eric/store/master/logs/consume/</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/716353-473218e8e6936674.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<p>配置完后依次启动 Name Server, Master Broker, Slave Broker， Producer</p>\n<p>完整的Store目录结构截图</p>\n<p><img src=\"https://ws1.sinaimg.cn/large/006tKfTcgy1fkedpuigp8j317e1a80zy.jpg\" alt=\"\"></p>\n<p>技巧</p>\n<ol>\n<li>充分利用作者写好的单元测试，对原理的掌握会有帮助</li>\n<li>RocketMQ有太多的事情是用 （短时间）定时+唤醒 的方式异步执行的，想要更好得了解原理，最好把定时的时间改得大一点，这样多线程的调试会好做很多。</li>\n</ol>\n"},{"title":"RocketMQ-Error-Code","date":"2018-11-30T03:39:21.000Z","_content":"\n\n### PCBUSY_CLEAN_QUEUE\n```\norg.apache.rocketmq.broker.latency.BrokerFastFailure\n```\n\n\n\n### TIMEOUT_CLEAN_QUEUE\n```\norg.apache.rocketmq.broker.latency.BrokerFastFailure\nRocketMQ Broker作为一台服务器，会并发接受大量的请求(SendMessageRequest, PullMessageRequest, HeartbeatRequest)。但是如果服务器由于某些原因无法及时处理请求，需要FastFailure，让客户端及时作出反应。\n服务器处理慢的原因：\n1. Page Cache busy，也就是刷盘的时间超过osPageCacheBusyTimeOutMills(1000ms by default)，这时Broker会把SendMessage线程池里面所有排队的请求都直接返回\n[PCBUSY_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: %sms, size of queue: %d]\n@Override\npublic boolean isOSPageCacheBusy() {\n    long begin = this.getCommitLog().getBeginTimeInLock();\n    long diff = this.systemClock.now() - begin;\n\n    return diff < 10000000\n            && diff > this.messageStoreConfig.getOsPageCacheBusyTimeOutMills();\n}\n2.\n\n\n\n2018-12-03 18:41:45 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 0\n2018-12-03 18:47:48 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 1\n2018-12-03 18:47:48 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 0\n2018-12-03 18:48:47 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 0\n2018-12-03 18:49:10 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 205 ms, size of queue: 0\n2018-12-03 18:49:56 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 258 ms, size of queue: 1\n2018-12-03 18:49:56 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 258 ms, size of queue: 0\n2018-12-03 18:51:29 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 206 ms, size of queue: 0\n2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 24\n2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 23\n2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 22\n2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 21\n2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 20\n\n```\n\n\nConsumer限流\n```\nif (cachedMessageCount > this.defaultMQPushConsumer.getPullThresholdForQueue()) {\n    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);\n    if ((queueFlowControlTimes++ % 1000) == 0) {\n        log.warn(\n            \"the cached message count exceeds the threshold {}, so do flow control, minOffset={}, maxOffset={}, count={}, size={} MiB, pullRequest={}, flowControlTimes={}\",\n            this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);\n    }\n    return;\n}\n2018-12-18 12:29:41,041 WARN RocketmqClient - the cached message count exceeds the threshold 1000, so do flow control, minOffset=68, maxOffset=1091, count=1024, size=0 MiB, pullRequest=PullRequest [consumerGroup=eric_cg, messageQueue=MessageQueue [topic=EricTpc, brokerName=broker-a, queueId=2], nextOffset=1092], flowControlTimes=711001\n```\n\n\n\n\n### 刷盘慢问题，看日志是文件预热的时候，对SSD压力过大\n```\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=251000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=252000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=253000, costTime=4\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=254000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=255000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=256000, costTime=4\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=257000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=258000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=259000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=260000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=261000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=262000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - mapped file warm-up done. mappedFile=/opt/data/rocketmq/store/commitlog/00000037095632535552, costTime=4450\n2019-03-22 10:34:39 INFO AllocateMappedFileService - mlock 139888250814464 /opt/data/rocketmq/store/commitlog/00000037095632535552 1073741824 ret = 0 time consuming = 161\n2019-03-22 10:34:39 INFO AllocateMappedFileService - madvise 139888250814464 /opt/data/rocketmq/store/commitlog/00000037095632535552 1073741824 ret = 0 time consuming = 161\n2019-03-22 10:34:41 INFO StoreScheduledThread1 - munlock 139890398298112 /opt/data/rocketmq/store/commitlog/00000037093485051904 1073741824 ret = 0 time consuming = 123\n\nsar -B\n         AM  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff\n10:33:01 AM      2.27   2490.55    403.91      0.05  15716.03      0.00      0.00      0.00      0.00\n10:34:01 AM      0.00   2115.41    532.05      0.00  15597.60      0.00      0.00      0.00      0.00\n10:35:01 AM      0.80  22780.21   5033.77      0.03  22221.77   3186.27   6828.45   6035.93     60.27\n10:36:01 AM      0.00   2487.04    406.26      0.00  17695.18      0.00    887.67    887.67    100.00\n10:37:01 AM      0.93   2262.00    481.78      0.02  17252.16      0.00    812.66    812.66    100.00\n\n2019-03-22 10:41:42 INFO AllocateMappedFileService - j=242000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=243000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=244000, costTime=5\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=245000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=246000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=247000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=248000, costTime=5\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=249000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=250000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=251000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=252000, costTime=5\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=253000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=254000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=255000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=256000, costTime=5\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=257000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=258000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=259000, costTime=5\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=260000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=261000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=262000, costTime=3\n2019-03-22 10:41:43 INFO AllocateMappedFileService - mapped file warm-up done. mappedFile=/opt/data/rocketmq/store/commitlog/00000037096706277376, costTime=1222\n2019-03-22 10:41:43 INFO AllocateMappedFileService - mlock 139887177072640 /opt/data/rocketmq/store/commitlog/00000037096706277376 1073741824 ret = 0 time consuming = 170\n2019-03-22 10:41:43 INFO AllocateMappedFileService - madvise 139887177072640 /opt/data/rocketmq/store/commitlog/00000037096706277376 1073741824 ret = 0 time consuming = 170\n2019-03-22 10:41:43 INFO FlushRealTimeService - Flush data to disk costs 2074 ms\n2019-03-22 10:41:47 INFO StoreScheduledThread1 - munlock 139889324556288 /opt/data/rocketmq/store/commitlog/00000037094558793728 1073741824 ret = 0 time consuming = 116\n\n\nsar -B\n         AM  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff\n10:40:01 AM      2.53   2404.46    536.20      0.05  13776.71      0.00      0.00      0.00      0.00\n10:41:01 AM      0.00   6429.72    426.92      0.00  18859.91      0.00      0.00      0.00      0.00\n10:42:01 AM      0.60  21695.09   4842.20      0.03  16396.72      0.00      0.00      0.00      0.00\n10:43:01 AM      0.93   2507.08    476.69      0.02  14196.68      0.00      0.00      0.00      0.00\n10:44:02 AM      2.40   2343.42    404.17      0.05  14700.77      0.00      0.00      0.00      0.00\n\n```\n","source":"_posts/RocketMQ-Error-Code.md","raw":"---\ntitle: RocketMQ-Error-Code\ndate: 2018-11-30 11:39:21\ntags:\n---\n\n\n### PCBUSY_CLEAN_QUEUE\n```\norg.apache.rocketmq.broker.latency.BrokerFastFailure\n```\n\n\n\n### TIMEOUT_CLEAN_QUEUE\n```\norg.apache.rocketmq.broker.latency.BrokerFastFailure\nRocketMQ Broker作为一台服务器，会并发接受大量的请求(SendMessageRequest, PullMessageRequest, HeartbeatRequest)。但是如果服务器由于某些原因无法及时处理请求，需要FastFailure，让客户端及时作出反应。\n服务器处理慢的原因：\n1. Page Cache busy，也就是刷盘的时间超过osPageCacheBusyTimeOutMills(1000ms by default)，这时Broker会把SendMessage线程池里面所有排队的请求都直接返回\n[PCBUSY_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: %sms, size of queue: %d]\n@Override\npublic boolean isOSPageCacheBusy() {\n    long begin = this.getCommitLog().getBeginTimeInLock();\n    long diff = this.systemClock.now() - begin;\n\n    return diff < 10000000\n            && diff > this.messageStoreConfig.getOsPageCacheBusyTimeOutMills();\n}\n2.\n\n\n\n2018-12-03 18:41:45 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 0\n2018-12-03 18:47:48 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 1\n2018-12-03 18:47:48 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 0\n2018-12-03 18:48:47 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 0\n2018-12-03 18:49:10 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 205 ms, size of queue: 0\n2018-12-03 18:49:56 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 258 ms, size of queue: 1\n2018-12-03 18:49:56 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 258 ms, size of queue: 0\n2018-12-03 18:51:29 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 206 ms, size of queue: 0\n2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 24\n2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 23\n2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 22\n2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 21\n2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 20\n\n```\n\n\nConsumer限流\n```\nif (cachedMessageCount > this.defaultMQPushConsumer.getPullThresholdForQueue()) {\n    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);\n    if ((queueFlowControlTimes++ % 1000) == 0) {\n        log.warn(\n            \"the cached message count exceeds the threshold {}, so do flow control, minOffset={}, maxOffset={}, count={}, size={} MiB, pullRequest={}, flowControlTimes={}\",\n            this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);\n    }\n    return;\n}\n2018-12-18 12:29:41,041 WARN RocketmqClient - the cached message count exceeds the threshold 1000, so do flow control, minOffset=68, maxOffset=1091, count=1024, size=0 MiB, pullRequest=PullRequest [consumerGroup=eric_cg, messageQueue=MessageQueue [topic=EricTpc, brokerName=broker-a, queueId=2], nextOffset=1092], flowControlTimes=711001\n```\n\n\n\n\n### 刷盘慢问题，看日志是文件预热的时候，对SSD压力过大\n```\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=251000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=252000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=253000, costTime=4\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=254000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=255000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=256000, costTime=4\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=257000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=258000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=259000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=260000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=261000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - j=262000, costTime=5\n2019-03-22 10:34:39 INFO AllocateMappedFileService - mapped file warm-up done. mappedFile=/opt/data/rocketmq/store/commitlog/00000037095632535552, costTime=4450\n2019-03-22 10:34:39 INFO AllocateMappedFileService - mlock 139888250814464 /opt/data/rocketmq/store/commitlog/00000037095632535552 1073741824 ret = 0 time consuming = 161\n2019-03-22 10:34:39 INFO AllocateMappedFileService - madvise 139888250814464 /opt/data/rocketmq/store/commitlog/00000037095632535552 1073741824 ret = 0 time consuming = 161\n2019-03-22 10:34:41 INFO StoreScheduledThread1 - munlock 139890398298112 /opt/data/rocketmq/store/commitlog/00000037093485051904 1073741824 ret = 0 time consuming = 123\n\nsar -B\n         AM  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff\n10:33:01 AM      2.27   2490.55    403.91      0.05  15716.03      0.00      0.00      0.00      0.00\n10:34:01 AM      0.00   2115.41    532.05      0.00  15597.60      0.00      0.00      0.00      0.00\n10:35:01 AM      0.80  22780.21   5033.77      0.03  22221.77   3186.27   6828.45   6035.93     60.27\n10:36:01 AM      0.00   2487.04    406.26      0.00  17695.18      0.00    887.67    887.67    100.00\n10:37:01 AM      0.93   2262.00    481.78      0.02  17252.16      0.00    812.66    812.66    100.00\n\n2019-03-22 10:41:42 INFO AllocateMappedFileService - j=242000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=243000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=244000, costTime=5\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=245000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=246000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=247000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=248000, costTime=5\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=249000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=250000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=251000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=252000, costTime=5\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=253000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=254000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=255000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=256000, costTime=5\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=257000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=258000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=259000, costTime=5\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=260000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=261000, costTime=4\n2019-03-22 10:41:43 INFO AllocateMappedFileService - j=262000, costTime=3\n2019-03-22 10:41:43 INFO AllocateMappedFileService - mapped file warm-up done. mappedFile=/opt/data/rocketmq/store/commitlog/00000037096706277376, costTime=1222\n2019-03-22 10:41:43 INFO AllocateMappedFileService - mlock 139887177072640 /opt/data/rocketmq/store/commitlog/00000037096706277376 1073741824 ret = 0 time consuming = 170\n2019-03-22 10:41:43 INFO AllocateMappedFileService - madvise 139887177072640 /opt/data/rocketmq/store/commitlog/00000037096706277376 1073741824 ret = 0 time consuming = 170\n2019-03-22 10:41:43 INFO FlushRealTimeService - Flush data to disk costs 2074 ms\n2019-03-22 10:41:47 INFO StoreScheduledThread1 - munlock 139889324556288 /opt/data/rocketmq/store/commitlog/00000037094558793728 1073741824 ret = 0 time consuming = 116\n\n\nsar -B\n         AM  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff\n10:40:01 AM      2.53   2404.46    536.20      0.05  13776.71      0.00      0.00      0.00      0.00\n10:41:01 AM      0.00   6429.72    426.92      0.00  18859.91      0.00      0.00      0.00      0.00\n10:42:01 AM      0.60  21695.09   4842.20      0.03  16396.72      0.00      0.00      0.00      0.00\n10:43:01 AM      0.93   2507.08    476.69      0.02  14196.68      0.00      0.00      0.00      0.00\n10:44:02 AM      2.40   2343.42    404.17      0.05  14700.77      0.00      0.00      0.00      0.00\n\n```\n","slug":"RocketMQ-Error-Code","published":1,"updated":"2019-09-28T08:51:00.915Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84n004uv1npbkjn69tr","content":"<h3 id=\"PCBUSY-CLEAN-QUEUE\"><a href=\"#PCBUSY-CLEAN-QUEUE\" class=\"headerlink\" title=\"PCBUSY_CLEAN_QUEUE\"></a>PCBUSY_CLEAN_QUEUE</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">org.apache.rocketmq.broker.latency.BrokerFastFailure</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"TIMEOUT-CLEAN-QUEUE\"><a href=\"#TIMEOUT-CLEAN-QUEUE\" class=\"headerlink\" title=\"TIMEOUT_CLEAN_QUEUE\"></a>TIMEOUT_CLEAN_QUEUE</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">org.apache.rocketmq.broker.latency.BrokerFastFailure</span><br><span class=\"line\">RocketMQ Broker作为一台服务器，会并发接受大量的请求(SendMessageRequest, PullMessageRequest, HeartbeatRequest)。但是如果服务器由于某些原因无法及时处理请求，需要FastFailure，让客户端及时作出反应。</span><br><span class=\"line\">服务器处理慢的原因：</span><br><span class=\"line\">1. Page Cache busy，也就是刷盘的时间超过osPageCacheBusyTimeOutMills(1000ms by default)，这时Broker会把SendMessage线程池里面所有排队的请求都直接返回</span><br><span class=\"line\">[PCBUSY_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: %sms, size of queue: %d]</span><br><span class=\"line\">@Override</span><br><span class=\"line\">public boolean isOSPageCacheBusy() &#123;</span><br><span class=\"line\">    long begin = this.getCommitLog().getBeginTimeInLock();</span><br><span class=\"line\">    long diff = this.systemClock.now() - begin;</span><br><span class=\"line\"></span><br><span class=\"line\">    return diff &lt; 10000000</span><br><span class=\"line\">            &amp;&amp; diff &gt; this.messageStoreConfig.getOsPageCacheBusyTimeOutMills();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">2.</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">2018-12-03 18:41:45 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 0</span><br><span class=\"line\">2018-12-03 18:47:48 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 1</span><br><span class=\"line\">2018-12-03 18:47:48 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 0</span><br><span class=\"line\">2018-12-03 18:48:47 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 0</span><br><span class=\"line\">2018-12-03 18:49:10 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 205 ms, size of queue: 0</span><br><span class=\"line\">2018-12-03 18:49:56 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 258 ms, size of queue: 1</span><br><span class=\"line\">2018-12-03 18:49:56 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 258 ms, size of queue: 0</span><br><span class=\"line\">2018-12-03 18:51:29 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 206 ms, size of queue: 0</span><br><span class=\"line\">2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 24</span><br><span class=\"line\">2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 23</span><br><span class=\"line\">2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 22</span><br><span class=\"line\">2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 21</span><br><span class=\"line\">2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 20</span><br></pre></td></tr></table></figure>\n\n<p>Consumer限流</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123;</span><br><span class=\"line\">    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);</span><br><span class=\"line\">    if ((queueFlowControlTimes++ % 1000) == 0) &#123;</span><br><span class=\"line\">        log.warn(</span><br><span class=\"line\">            &quot;the cached message count exceeds the threshold &#123;&#125;, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,</span><br><span class=\"line\">            this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">2018-12-18 12:29:41,041 WARN RocketmqClient - the cached message count exceeds the threshold 1000, so do flow control, minOffset=68, maxOffset=1091, count=1024, size=0 MiB, pullRequest=PullRequest [consumerGroup=eric_cg, messageQueue=MessageQueue [topic=EricTpc, brokerName=broker-a, queueId=2], nextOffset=1092], flowControlTimes=711001</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"刷盘慢问题，看日志是文件预热的时候，对SSD压力过大\"><a href=\"#刷盘慢问题，看日志是文件预热的时候，对SSD压力过大\" class=\"headerlink\" title=\"刷盘慢问题，看日志是文件预热的时候，对SSD压力过大\"></a>刷盘慢问题，看日志是文件预热的时候，对SSD压力过大</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=251000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=252000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=253000, costTime=4</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=254000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=255000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=256000, costTime=4</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=257000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=258000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=259000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=260000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=261000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=262000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - mapped file warm-up done. mappedFile=/opt/data/rocketmq/store/commitlog/00000037095632535552, costTime=4450</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - mlock 139888250814464 /opt/data/rocketmq/store/commitlog/00000037095632535552 1073741824 ret = 0 time consuming = 161</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - madvise 139888250814464 /opt/data/rocketmq/store/commitlog/00000037095632535552 1073741824 ret = 0 time consuming = 161</span><br><span class=\"line\">2019-03-22 10:34:41 INFO StoreScheduledThread1 - munlock 139890398298112 /opt/data/rocketmq/store/commitlog/00000037093485051904 1073741824 ret = 0 time consuming = 123</span><br><span class=\"line\"></span><br><span class=\"line\">sar -B</span><br><span class=\"line\">         AM  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff</span><br><span class=\"line\">10:33:01 AM      2.27   2490.55    403.91      0.05  15716.03      0.00      0.00      0.00      0.00</span><br><span class=\"line\">10:34:01 AM      0.00   2115.41    532.05      0.00  15597.60      0.00      0.00      0.00      0.00</span><br><span class=\"line\">10:35:01 AM      0.80  22780.21   5033.77      0.03  22221.77   3186.27   6828.45   6035.93     60.27</span><br><span class=\"line\">10:36:01 AM      0.00   2487.04    406.26      0.00  17695.18      0.00    887.67    887.67    100.00</span><br><span class=\"line\">10:37:01 AM      0.93   2262.00    481.78      0.02  17252.16      0.00    812.66    812.66    100.00</span><br><span class=\"line\"></span><br><span class=\"line\">2019-03-22 10:41:42 INFO AllocateMappedFileService - j=242000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=243000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=244000, costTime=5</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=245000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=246000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=247000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=248000, costTime=5</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=249000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=250000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=251000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=252000, costTime=5</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=253000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=254000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=255000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=256000, costTime=5</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=257000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=258000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=259000, costTime=5</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=260000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=261000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=262000, costTime=3</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - mapped file warm-up done. mappedFile=/opt/data/rocketmq/store/commitlog/00000037096706277376, costTime=1222</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - mlock 139887177072640 /opt/data/rocketmq/store/commitlog/00000037096706277376 1073741824 ret = 0 time consuming = 170</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - madvise 139887177072640 /opt/data/rocketmq/store/commitlog/00000037096706277376 1073741824 ret = 0 time consuming = 170</span><br><span class=\"line\">2019-03-22 10:41:43 INFO FlushRealTimeService - Flush data to disk costs 2074 ms</span><br><span class=\"line\">2019-03-22 10:41:47 INFO StoreScheduledThread1 - munlock 139889324556288 /opt/data/rocketmq/store/commitlog/00000037094558793728 1073741824 ret = 0 time consuming = 116</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">sar -B</span><br><span class=\"line\">         AM  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff</span><br><span class=\"line\">10:40:01 AM      2.53   2404.46    536.20      0.05  13776.71      0.00      0.00      0.00      0.00</span><br><span class=\"line\">10:41:01 AM      0.00   6429.72    426.92      0.00  18859.91      0.00      0.00      0.00      0.00</span><br><span class=\"line\">10:42:01 AM      0.60  21695.09   4842.20      0.03  16396.72      0.00      0.00      0.00      0.00</span><br><span class=\"line\">10:43:01 AM      0.93   2507.08    476.69      0.02  14196.68      0.00      0.00      0.00      0.00</span><br><span class=\"line\">10:44:02 AM      2.40   2343.42    404.17      0.05  14700.77      0.00      0.00      0.00      0.00</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"PCBUSY-CLEAN-QUEUE\"><a href=\"#PCBUSY-CLEAN-QUEUE\" class=\"headerlink\" title=\"PCBUSY_CLEAN_QUEUE\"></a>PCBUSY_CLEAN_QUEUE</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">org.apache.rocketmq.broker.latency.BrokerFastFailure</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"TIMEOUT-CLEAN-QUEUE\"><a href=\"#TIMEOUT-CLEAN-QUEUE\" class=\"headerlink\" title=\"TIMEOUT_CLEAN_QUEUE\"></a>TIMEOUT_CLEAN_QUEUE</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">org.apache.rocketmq.broker.latency.BrokerFastFailure</span><br><span class=\"line\">RocketMQ Broker作为一台服务器，会并发接受大量的请求(SendMessageRequest, PullMessageRequest, HeartbeatRequest)。但是如果服务器由于某些原因无法及时处理请求，需要FastFailure，让客户端及时作出反应。</span><br><span class=\"line\">服务器处理慢的原因：</span><br><span class=\"line\">1. Page Cache busy，也就是刷盘的时间超过osPageCacheBusyTimeOutMills(1000ms by default)，这时Broker会把SendMessage线程池里面所有排队的请求都直接返回</span><br><span class=\"line\">[PCBUSY_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: %sms, size of queue: %d]</span><br><span class=\"line\">@Override</span><br><span class=\"line\">public boolean isOSPageCacheBusy() &#123;</span><br><span class=\"line\">    long begin = this.getCommitLog().getBeginTimeInLock();</span><br><span class=\"line\">    long diff = this.systemClock.now() - begin;</span><br><span class=\"line\"></span><br><span class=\"line\">    return diff &lt; 10000000</span><br><span class=\"line\">            &amp;&amp; diff &gt; this.messageStoreConfig.getOsPageCacheBusyTimeOutMills();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">2.</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">2018-12-03 18:41:45 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 0</span><br><span class=\"line\">2018-12-03 18:47:48 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 1</span><br><span class=\"line\">2018-12-03 18:47:48 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 0</span><br><span class=\"line\">2018-12-03 18:48:47 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 204 ms, size of queue: 0</span><br><span class=\"line\">2018-12-03 18:49:10 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 205 ms, size of queue: 0</span><br><span class=\"line\">2018-12-03 18:49:56 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 258 ms, size of queue: 1</span><br><span class=\"line\">2018-12-03 18:49:56 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 258 ms, size of queue: 0</span><br><span class=\"line\">2018-12-03 18:51:29 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 206 ms, size of queue: 0</span><br><span class=\"line\">2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 24</span><br><span class=\"line\">2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 23</span><br><span class=\"line\">2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 22</span><br><span class=\"line\">2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 21</span><br><span class=\"line\">2018-12-03 18:53:51 WARN BrokerFastFailureScheduledThread1 - [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 200 ms, size of queue: 20</span><br></pre></td></tr></table></figure>\n\n<p>Consumer限流</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123;</span><br><span class=\"line\">    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);</span><br><span class=\"line\">    if ((queueFlowControlTimes++ % 1000) == 0) &#123;</span><br><span class=\"line\">        log.warn(</span><br><span class=\"line\">            &quot;the cached message count exceeds the threshold &#123;&#125;, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;&quot;,</span><br><span class=\"line\">            this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">2018-12-18 12:29:41,041 WARN RocketmqClient - the cached message count exceeds the threshold 1000, so do flow control, minOffset=68, maxOffset=1091, count=1024, size=0 MiB, pullRequest=PullRequest [consumerGroup=eric_cg, messageQueue=MessageQueue [topic=EricTpc, brokerName=broker-a, queueId=2], nextOffset=1092], flowControlTimes=711001</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"刷盘慢问题，看日志是文件预热的时候，对SSD压力过大\"><a href=\"#刷盘慢问题，看日志是文件预热的时候，对SSD压力过大\" class=\"headerlink\" title=\"刷盘慢问题，看日志是文件预热的时候，对SSD压力过大\"></a>刷盘慢问题，看日志是文件预热的时候，对SSD压力过大</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=251000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=252000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=253000, costTime=4</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=254000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=255000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=256000, costTime=4</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=257000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=258000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=259000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=260000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=261000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - j=262000, costTime=5</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - mapped file warm-up done. mappedFile=/opt/data/rocketmq/store/commitlog/00000037095632535552, costTime=4450</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - mlock 139888250814464 /opt/data/rocketmq/store/commitlog/00000037095632535552 1073741824 ret = 0 time consuming = 161</span><br><span class=\"line\">2019-03-22 10:34:39 INFO AllocateMappedFileService - madvise 139888250814464 /opt/data/rocketmq/store/commitlog/00000037095632535552 1073741824 ret = 0 time consuming = 161</span><br><span class=\"line\">2019-03-22 10:34:41 INFO StoreScheduledThread1 - munlock 139890398298112 /opt/data/rocketmq/store/commitlog/00000037093485051904 1073741824 ret = 0 time consuming = 123</span><br><span class=\"line\"></span><br><span class=\"line\">sar -B</span><br><span class=\"line\">         AM  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff</span><br><span class=\"line\">10:33:01 AM      2.27   2490.55    403.91      0.05  15716.03      0.00      0.00      0.00      0.00</span><br><span class=\"line\">10:34:01 AM      0.00   2115.41    532.05      0.00  15597.60      0.00      0.00      0.00      0.00</span><br><span class=\"line\">10:35:01 AM      0.80  22780.21   5033.77      0.03  22221.77   3186.27   6828.45   6035.93     60.27</span><br><span class=\"line\">10:36:01 AM      0.00   2487.04    406.26      0.00  17695.18      0.00    887.67    887.67    100.00</span><br><span class=\"line\">10:37:01 AM      0.93   2262.00    481.78      0.02  17252.16      0.00    812.66    812.66    100.00</span><br><span class=\"line\"></span><br><span class=\"line\">2019-03-22 10:41:42 INFO AllocateMappedFileService - j=242000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=243000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=244000, costTime=5</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=245000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=246000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=247000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=248000, costTime=5</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=249000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=250000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=251000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=252000, costTime=5</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=253000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=254000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=255000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=256000, costTime=5</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=257000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=258000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=259000, costTime=5</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=260000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=261000, costTime=4</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - j=262000, costTime=3</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - mapped file warm-up done. mappedFile=/opt/data/rocketmq/store/commitlog/00000037096706277376, costTime=1222</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - mlock 139887177072640 /opt/data/rocketmq/store/commitlog/00000037096706277376 1073741824 ret = 0 time consuming = 170</span><br><span class=\"line\">2019-03-22 10:41:43 INFO AllocateMappedFileService - madvise 139887177072640 /opt/data/rocketmq/store/commitlog/00000037096706277376 1073741824 ret = 0 time consuming = 170</span><br><span class=\"line\">2019-03-22 10:41:43 INFO FlushRealTimeService - Flush data to disk costs 2074 ms</span><br><span class=\"line\">2019-03-22 10:41:47 INFO StoreScheduledThread1 - munlock 139889324556288 /opt/data/rocketmq/store/commitlog/00000037094558793728 1073741824 ret = 0 time consuming = 116</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">sar -B</span><br><span class=\"line\">         AM  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff</span><br><span class=\"line\">10:40:01 AM      2.53   2404.46    536.20      0.05  13776.71      0.00      0.00      0.00      0.00</span><br><span class=\"line\">10:41:01 AM      0.00   6429.72    426.92      0.00  18859.91      0.00      0.00      0.00      0.00</span><br><span class=\"line\">10:42:01 AM      0.60  21695.09   4842.20      0.03  16396.72      0.00      0.00      0.00      0.00</span><br><span class=\"line\">10:43:01 AM      0.93   2507.08    476.69      0.02  14196.68      0.00      0.00      0.00      0.00</span><br><span class=\"line\">10:44:02 AM      2.40   2343.42    404.17      0.05  14700.77      0.00      0.00      0.00      0.00</span><br></pre></td></tr></table></figure>\n\n"},{"title":"RocketMQ——IndexService 原理分析","date":"2017-10-12T11:29:40.000Z","_content":"\n\n### ProcessOn配图\nhttps://processon.com/diagraming/5be3a0d4e4b0ad314e823909\n\n#### RocmetMQ的IndexService设计原理  \n\n![你想输入的替代文字](RocketMQ-Index-service/index-file.gif)\n\n在RocketMQ中，IndexService底层是通过文件来存储的，所以，即使MQ的进程在中途重启过，索引的功能是不受影响的。\n索引文件的路径是 `System.getProperty(\"user.home\") + File.separator + \"store\"`，文件名是文件创建的时间，可以有多个，但，\n在一个文件没有满的情况下，所有的topic的所有的列队的消息，全部都是顺序得存放在一个文件中的，这很重要，下面会详解。\n![image.png](http://upload-images.jianshu.io/upload_images/716353-2ed415df19a3040b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n在MQ源码中，用IndexFile这个类代表索引文件，对于每一个index file，大小都是固定的，即，都是设计好的。\nindex file在逻辑上被拆分成了3个部分，IndexHead + HashSlotPart + MsgIndexPart，\nIndexHead\n索引的开头，和索引的结构没有关系\nHashSlotPart\nhash的槽位，是索引的目录，用于定位消息索引在该文件的「MsgIndexPart」的位置，\n可能有点绕，往下就会觉得很简单，每个槽位是等长的，占4 Byte，一个文件总的槽位数量也是定的，不可改变，槽位数越大，索引的消息越多。\nMsgIndexPart\n真实的消息索引，即，每个msgIndex段代表改消息在CommitLog上的PhyicOffset。每个msgIndex段也是等长的，占20 Byte（int + long + int + int）。\n等长的MsgIndexPart可以理解成功一个有capacity的数组，为了使数组的空间不浪费，那消息就要从前往后一个一个append进去。\n\n\n所以，在默认配置下，\n每个索引文件的大小为 \n`int fileTotalSize = IndexHeader.INDEX_HEADER_SIZE + (hashSlotNum * hashSlotSize) + (indexNum * indexSize);`\n\nCommitLogDispatcherBuildIndex调用dispatch\n``` java\npublic void dispatch(DispatchRequest request) {\n    if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) {\n        DefaultMessageStore.this.indexService.buildIndex(request);\n    }\n}\n```\nbuildIndex时会构建好几个索引，topic#msgId=>msgIndex, topic#key1=>msgIndex, topic#key2=>msgIndex\n``` java\npublic void buildIndex(DispatchRequest req) {\n    IndexFile indexFile = retryGetAndCreateIndexFile();\n    if (indexFile != null) {\n        long endPhyOffset = indexFile.getEndPhyOffset();\n        DispatchRequest msg = req;\n        String topic = msg.getTopic();\n        String keys = msg.getKeys();\n\n        ...\n        if (req.getUniqKey() != null) {\n            // 构建UniqKey，也就是msgId的索引\n            indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey()));\n            ...\n        }\n\n        if (keys != null && keys.length() > 0) {\n            String[] keyset = keys.split(MessageConst.KEY_SEPARATOR);\n            for (int i = 0; i < keyset.length; i++) {\n                String key = keyset[i];\n                if (key.length() > 0) {\n                    // 构建业务Key的索引\n                    indexFile = putKey(indexFile, msg, buildKey(topic, key));\n                    ...\n                }\n            }\n        }\n    } else {\n        log.error(\"build index error, stop building index\");\n    }\n}\n```\n","source":"_posts/RocketMQ-Index-service.md","raw":"---\ntitle: RocketMQ——IndexService 原理分析\ndate: 2017-10-12 19:29:40\ntags: RocketMQ\n---\n\n\n### ProcessOn配图\nhttps://processon.com/diagraming/5be3a0d4e4b0ad314e823909\n\n#### RocmetMQ的IndexService设计原理  \n\n![你想输入的替代文字](RocketMQ-Index-service/index-file.gif)\n\n在RocketMQ中，IndexService底层是通过文件来存储的，所以，即使MQ的进程在中途重启过，索引的功能是不受影响的。\n索引文件的路径是 `System.getProperty(\"user.home\") + File.separator + \"store\"`，文件名是文件创建的时间，可以有多个，但，\n在一个文件没有满的情况下，所有的topic的所有的列队的消息，全部都是顺序得存放在一个文件中的，这很重要，下面会详解。\n![image.png](http://upload-images.jianshu.io/upload_images/716353-2ed415df19a3040b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n在MQ源码中，用IndexFile这个类代表索引文件，对于每一个index file，大小都是固定的，即，都是设计好的。\nindex file在逻辑上被拆分成了3个部分，IndexHead + HashSlotPart + MsgIndexPart，\nIndexHead\n索引的开头，和索引的结构没有关系\nHashSlotPart\nhash的槽位，是索引的目录，用于定位消息索引在该文件的「MsgIndexPart」的位置，\n可能有点绕，往下就会觉得很简单，每个槽位是等长的，占4 Byte，一个文件总的槽位数量也是定的，不可改变，槽位数越大，索引的消息越多。\nMsgIndexPart\n真实的消息索引，即，每个msgIndex段代表改消息在CommitLog上的PhyicOffset。每个msgIndex段也是等长的，占20 Byte（int + long + int + int）。\n等长的MsgIndexPart可以理解成功一个有capacity的数组，为了使数组的空间不浪费，那消息就要从前往后一个一个append进去。\n\n\n所以，在默认配置下，\n每个索引文件的大小为 \n`int fileTotalSize = IndexHeader.INDEX_HEADER_SIZE + (hashSlotNum * hashSlotSize) + (indexNum * indexSize);`\n\nCommitLogDispatcherBuildIndex调用dispatch\n``` java\npublic void dispatch(DispatchRequest request) {\n    if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) {\n        DefaultMessageStore.this.indexService.buildIndex(request);\n    }\n}\n```\nbuildIndex时会构建好几个索引，topic#msgId=>msgIndex, topic#key1=>msgIndex, topic#key2=>msgIndex\n``` java\npublic void buildIndex(DispatchRequest req) {\n    IndexFile indexFile = retryGetAndCreateIndexFile();\n    if (indexFile != null) {\n        long endPhyOffset = indexFile.getEndPhyOffset();\n        DispatchRequest msg = req;\n        String topic = msg.getTopic();\n        String keys = msg.getKeys();\n\n        ...\n        if (req.getUniqKey() != null) {\n            // 构建UniqKey，也就是msgId的索引\n            indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey()));\n            ...\n        }\n\n        if (keys != null && keys.length() > 0) {\n            String[] keyset = keys.split(MessageConst.KEY_SEPARATOR);\n            for (int i = 0; i < keyset.length; i++) {\n                String key = keyset[i];\n                if (key.length() > 0) {\n                    // 构建业务Key的索引\n                    indexFile = putKey(indexFile, msg, buildKey(topic, key));\n                    ...\n                }\n            }\n        }\n    } else {\n        log.error(\"build index error, stop building index\");\n    }\n}\n```\n","slug":"RocketMQ-Index-service","published":1,"updated":"2019-09-28T08:51:00.915Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84n004vv1np9v6nnjeo","content":"<h3 id=\"ProcessOn配图\"><a href=\"#ProcessOn配图\" class=\"headerlink\" title=\"ProcessOn配图\"></a>ProcessOn配图</h3><p><a href=\"https://processon.com/diagraming/5be3a0d4e4b0ad314e823909\" target=\"_blank\" rel=\"noopener\">https://processon.com/diagraming/5be3a0d4e4b0ad314e823909</a></p>\n<h4 id=\"RocmetMQ的IndexService设计原理\"><a href=\"#RocmetMQ的IndexService设计原理\" class=\"headerlink\" title=\"RocmetMQ的IndexService设计原理\"></a>RocmetMQ的IndexService设计原理</h4><p><img src=\"/2017/10/12/RocketMQ-Index-service/index-file.gif\" alt=\"你想输入的替代文字\"></p>\n<p>在RocketMQ中，IndexService底层是通过文件来存储的，所以，即使MQ的进程在中途重启过，索引的功能是不受影响的。<br>索引文件的路径是 <code>System.getProperty(&quot;user.home&quot;) + File.separator + &quot;store&quot;</code>，文件名是文件创建的时间，可以有多个，但，<br>在一个文件没有满的情况下，所有的topic的所有的列队的消息，全部都是顺序得存放在一个文件中的，这很重要，下面会详解。<br><img src=\"http://upload-images.jianshu.io/upload_images/716353-2ed415df19a3040b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"><br>在MQ源码中，用IndexFile这个类代表索引文件，对于每一个index file，大小都是固定的，即，都是设计好的。<br>index file在逻辑上被拆分成了3个部分，IndexHead + HashSlotPart + MsgIndexPart，<br>IndexHead<br>索引的开头，和索引的结构没有关系<br>HashSlotPart<br>hash的槽位，是索引的目录，用于定位消息索引在该文件的「MsgIndexPart」的位置，<br>可能有点绕，往下就会觉得很简单，每个槽位是等长的，占4 Byte，一个文件总的槽位数量也是定的，不可改变，槽位数越大，索引的消息越多。<br>MsgIndexPart<br>真实的消息索引，即，每个msgIndex段代表改消息在CommitLog上的PhyicOffset。每个msgIndex段也是等长的，占20 Byte（int + long + int + int）。<br>等长的MsgIndexPart可以理解成功一个有capacity的数组，为了使数组的空间不浪费，那消息就要从前往后一个一个append进去。</p>\n<p>所以，在默认配置下，<br>每个索引文件的大小为<br><code>int fileTotalSize = IndexHeader.INDEX_HEADER_SIZE + (hashSlotNum * hashSlotSize) + (indexNum * indexSize);</code></p>\n<p>CommitLogDispatcherBuildIndex调用dispatch</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">dispatch</span><span class=\"params\">(DispatchRequest request)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (DefaultMessageStore.<span class=\"keyword\">this</span>.messageStoreConfig.isMessageIndexEnable()) &#123;</span><br><span class=\"line\">        DefaultMessageStore.<span class=\"keyword\">this</span>.indexService.buildIndex(request);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>buildIndex时会构建好几个索引，topic#msgId=&gt;msgIndex, topic#key1=&gt;msgIndex, topic#key2=&gt;msgIndex</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">buildIndex</span><span class=\"params\">(DispatchRequest req)</span> </span>&#123;</span><br><span class=\"line\">    IndexFile indexFile = retryGetAndCreateIndexFile();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (indexFile != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> endPhyOffset = indexFile.getEndPhyOffset();</span><br><span class=\"line\">        DispatchRequest msg = req;</span><br><span class=\"line\">        String topic = msg.getTopic();</span><br><span class=\"line\">        String keys = msg.getKeys();</span><br><span class=\"line\"></span><br><span class=\"line\">        ...</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (req.getUniqKey() != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 构建UniqKey，也就是msgId的索引</span></span><br><span class=\"line\">            indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey()));</span><br><span class=\"line\">            ...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (keys != <span class=\"keyword\">null</span> &amp;&amp; keys.length() &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            String[] keyset = keys.split(MessageConst.KEY_SEPARATOR);</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; keyset.length; i++) &#123;</span><br><span class=\"line\">                String key = keyset[i];</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (key.length() &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 构建业务Key的索引</span></span><br><span class=\"line\">                    indexFile = putKey(indexFile, msg, buildKey(topic, key));</span><br><span class=\"line\">                    ...</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        log.error(<span class=\"string\">\"build index error, stop building index\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"ProcessOn配图\"><a href=\"#ProcessOn配图\" class=\"headerlink\" title=\"ProcessOn配图\"></a>ProcessOn配图</h3><p><a href=\"https://processon.com/diagraming/5be3a0d4e4b0ad314e823909\" target=\"_blank\" rel=\"noopener\">https://processon.com/diagraming/5be3a0d4e4b0ad314e823909</a></p>\n<h4 id=\"RocmetMQ的IndexService设计原理\"><a href=\"#RocmetMQ的IndexService设计原理\" class=\"headerlink\" title=\"RocmetMQ的IndexService设计原理\"></a>RocmetMQ的IndexService设计原理</h4><p><img src=\"/2017/10/12/RocketMQ-Index-service/index-file.gif\" alt=\"你想输入的替代文字\"></p>\n<p>在RocketMQ中，IndexService底层是通过文件来存储的，所以，即使MQ的进程在中途重启过，索引的功能是不受影响的。<br>索引文件的路径是 <code>System.getProperty(&quot;user.home&quot;) + File.separator + &quot;store&quot;</code>，文件名是文件创建的时间，可以有多个，但，<br>在一个文件没有满的情况下，所有的topic的所有的列队的消息，全部都是顺序得存放在一个文件中的，这很重要，下面会详解。<br><img src=\"http://upload-images.jianshu.io/upload_images/716353-2ed415df19a3040b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"><br>在MQ源码中，用IndexFile这个类代表索引文件，对于每一个index file，大小都是固定的，即，都是设计好的。<br>index file在逻辑上被拆分成了3个部分，IndexHead + HashSlotPart + MsgIndexPart，<br>IndexHead<br>索引的开头，和索引的结构没有关系<br>HashSlotPart<br>hash的槽位，是索引的目录，用于定位消息索引在该文件的「MsgIndexPart」的位置，<br>可能有点绕，往下就会觉得很简单，每个槽位是等长的，占4 Byte，一个文件总的槽位数量也是定的，不可改变，槽位数越大，索引的消息越多。<br>MsgIndexPart<br>真实的消息索引，即，每个msgIndex段代表改消息在CommitLog上的PhyicOffset。每个msgIndex段也是等长的，占20 Byte（int + long + int + int）。<br>等长的MsgIndexPart可以理解成功一个有capacity的数组，为了使数组的空间不浪费，那消息就要从前往后一个一个append进去。</p>\n<p>所以，在默认配置下，<br>每个索引文件的大小为<br><code>int fileTotalSize = IndexHeader.INDEX_HEADER_SIZE + (hashSlotNum * hashSlotSize) + (indexNum * indexSize);</code></p>\n<p>CommitLogDispatcherBuildIndex调用dispatch</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">dispatch</span><span class=\"params\">(DispatchRequest request)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (DefaultMessageStore.<span class=\"keyword\">this</span>.messageStoreConfig.isMessageIndexEnable()) &#123;</span><br><span class=\"line\">        DefaultMessageStore.<span class=\"keyword\">this</span>.indexService.buildIndex(request);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>buildIndex时会构建好几个索引，topic#msgId=&gt;msgIndex, topic#key1=&gt;msgIndex, topic#key2=&gt;msgIndex</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">buildIndex</span><span class=\"params\">(DispatchRequest req)</span> </span>&#123;</span><br><span class=\"line\">    IndexFile indexFile = retryGetAndCreateIndexFile();</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (indexFile != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> endPhyOffset = indexFile.getEndPhyOffset();</span><br><span class=\"line\">        DispatchRequest msg = req;</span><br><span class=\"line\">        String topic = msg.getTopic();</span><br><span class=\"line\">        String keys = msg.getKeys();</span><br><span class=\"line\"></span><br><span class=\"line\">        ...</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (req.getUniqKey() != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 构建UniqKey，也就是msgId的索引</span></span><br><span class=\"line\">            indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey()));</span><br><span class=\"line\">            ...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (keys != <span class=\"keyword\">null</span> &amp;&amp; keys.length() &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            String[] keyset = keys.split(MessageConst.KEY_SEPARATOR);</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; keyset.length; i++) &#123;</span><br><span class=\"line\">                String key = keyset[i];</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (key.length() &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 构建业务Key的索引</span></span><br><span class=\"line\">                    indexFile = putKey(indexFile, msg, buildKey(topic, key));</span><br><span class=\"line\">                    ...</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        log.error(<span class=\"string\">\"build index error, stop building index\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"RocketMQ——Broker的主从复制原理分析（双写机制）","date":"2017-10-12T08:28:24.000Z","_content":"\n``` java\n\n```\n![](https://ws3.sinaimg.cn/large/006tNbRwgy1fkfij3xtx8j31kw1514e0.jpg)","source":"_posts/RocketMQ-Master-slave-high-availability.md","raw":"---\ntitle: RocketMQ——Broker的主从复制原理分析（双写机制）\ndate: 2017-10-12 16:28:24\ntags: RocketMQ\n---\n\n``` java\n\n```\n![](https://ws3.sinaimg.cn/large/006tNbRwgy1fkfij3xtx8j31kw1514e0.jpg)","slug":"RocketMQ-Master-slave-high-availability","published":1,"updated":"2019-09-28T08:51:00.918Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84o004wv1npexa5sndv","content":"<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://ws3.sinaimg.cn/large/006tNbRwgy1fkfij3xtx8j31kw1514e0.jpg\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://ws3.sinaimg.cn/large/006tNbRwgy1fkfij3xtx8j31kw1514e0.jpg\" alt=\"\"></p>\n"},{"title":"Netty-ChannelPool","date":"2019-02-27T03:01:18.000Z","_content":"\n\nhttps://blog.csdn.net/a975261294/article/details/77568782","source":"_posts/Netty-ChannelPool.md","raw":"---\ntitle: Netty-ChannelPool\ndate: 2019-02-27 11:01:18\ntags:\n---\n\n\nhttps://blog.csdn.net/a975261294/article/details/77568782","slug":"Netty-ChannelPool","published":1,"updated":"2019-09-28T08:51:00.909Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84o004xv1npsbwnhc4m","content":"<p><a href=\"https://blog.csdn.net/a975261294/article/details/77568782\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/a975261294/article/details/77568782</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.csdn.net/a975261294/article/details/77568782\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/a975261294/article/details/77568782</a></p>\n"},{"title":"RocketMQ——消息发送与落盘（三）","date":"2017-11-03T06:38:10.000Z","_content":"\n\nproducer发送消息，如果是立马被消费这种场景\n1.对于consume queue，肯定是顺序读写，所以写进pagecache后，直接就从pagecache被读出来了\n2.对于commit log，虽然不是顺序读，但也是基本有序读，最后大部分也能命中pagecache，不需要走系统IO\n\n如果是消费历史消息，很大程度上，会发现在pagecache中没有，由系统产生缺页中断，从磁盘中重新读到pagecache中（可能还会根据顺序预读很多），然后再将数据从pagecache复制到socket中传输到consumer。\n\n### 异步刷盘有两种方式\n\n``` java\n// Synchronization flush\nif (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) {\n    final GroupCommitService service = (GroupCommitService) this.flushCommitLogService;\n}\n// Asynchronous flush\nelse {\n    if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) {\n        // FlushRealTimeService\n        flushCommitLogService.wakeup();\n    } else {\n        // CommitRealTimeService\n        commitLogService.wakeup();\n    }\n}\n```\n\n``` java\npublic boolean isTransientStorePoolEnable() {\n    return transientStorePoolEnable && FlushDiskType.ASYNC_FLUSH == getFlushDiskType()\n        && BrokerRole.SLAVE != getBrokerRole();\n}\n```\n\n\n### 功力深厚的文章\ntransientStorePoolEnable的具体含义是什么？\nFlushRealTimeService和CommitRealTimeService刷盘的方式有什么区别，在性能有什么区别？\n\n```\nNAME\n     mlock, munlock -- lock (unlock) physical pages in memory\n\nSYNOPSIS\n     #include <sys/mman.h>\n\n     int\n     mlock(const void *addr, size_t len);\n\n     int\n     munlock(const void *addr, size_t len);\n\nDESCRIPTION\n     The mlock system call locks a set of physical pages into memory.  The pages are associated with a virtual address range\n     that starts at addr and extends for len bytes.  The munlock call unlocks pages that were previously locked by one or more\n     mlock calls.  For both calls, the addr parameter should be aligned to a multiple of the page size.  If the len parameter\n     is not a multiple of the page size, it will be rounded up to be so.  The entire range must be allocated.\n\n     After an mlock call, the indicated pages will cause neither a non-resident page nor address-translation fault until they\n     are unlocked.  They may still cause protection-violation faults or TLB-miss faults on architectures with software-managed\n     TLBs.  The physical pages remain in memory until all locked mappings for the pages are removed.\n\n     Multiple processes may have the same physical pages locked via their own virtual address mappings.  Similarly, a single\n     process may have pages multiply-locked via different virtual mappings of the same pages or via nested mlock calls on the\n     same address range.  Unlocking is performed explicitly by munlock or implicitly by a call to munmap, which deallocates\n     the unmapped address range.  Locked mappings are not inherited by the child process after a fork(2).\n\n     Because physical memory is a potentially scarce resource, processes are limited in how much memory they can lock down.  A\n     single process can mlock the minimum of a system-wide ``wired pages'' limit and the per-process RLIMIT_MEMLOCK resource\n     limit.\n\nRETURN VALUES\n     A return value of 0 indicates that the call succeeded and all pages in the range have either been locked or unlocked, as\n     requested.  A return value of -1 indicates an error occurred and the locked status of all pages in the range remains\n     unchanged.  In this case, the global location errno is set to indicate the error.\n```\n\n![你想输入的替代文字](RocketMQ-Message-send-and-persistence/disc-fall.gif)\n\n### 逻辑Offset队列: ConsumerQueue\n\n\n### 物理Offset队列: CommitLog\n\n### MappedByteBuffer\n\n操纵MappedByteBuffer的线程或者进程必须对某一个文件的映射Buffer有独占权，\n在设计上，消息的顺序是由CommitLog决定，所以CommitLog在Append新的消息时，必须上锁进行互斥。\n\n*传统的synchronized叫做monitor lock，当一个线程进入了synchronized的代码块时，我们说，该线程own（拥有）了monitor lock。这种锁是一种重量级锁，用mutual exclusive（互斥）的特性来实现了同步的需求。\n*自旋锁，JDK1.6引进，我们知道，线程状态与状态的切换，是需要内核参与的，简单点来讲，这个过程是需要点时间的。线程B已经own了一个锁，这是线程A去尝试获取锁，本来线程A应该要挂起，JVM不让它挂起，让A在那里做自旋操作，JVM要赌当前持有锁的B会很快释放锁。如果线程B确实很快释放了锁，那对于A来讲是一个非常好事情，因为A可以不用切换状态，立刻持有锁。那什么时候会用到呢？http://blog.csdn.net/u013080921/article/details/42676231\n\n#### Spin Lock(自旋锁)\n\n#### ReentrantLock(重入锁)\n\n\n### 异步刷盘机制\n\nhttp://blog.csdn.net/vonzhoufz/article/details/47248777\n\n#### 磁盘顺序读写与随机读写的差异\n\nhttps://kafka.apache.org/documentation/#design_filesystem\n\nhttp://blog.csdn.net/evankaka/article/details/48464013\n\n需要好好研究：http://blog.csdn.net/javahongxi/article/details/72956619?locationNum=2&fps=1\n虽然讲的是kafka，研究价值极高：http://blog.csdn.net/tototuzuoquan/article/details/73437890\npagecache是一个现在操作系统带有的天然的缓存！！！！！\n\nhttp://blog.csdn.net/mg0832058/article/details/5890688\n内存映射文件原理探索\n\n\n如何查看内存的 PAGESIZE\n``` bash\ngetconf PAGESIZE\n```\n\n终于理解了！！！！ 首先，Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。同时如果有其他进程申请内存，回收PageCache的代价又很小，所以现代的OS都支持PageCache。 \n\n所以说 commit(atLeastSize)的参数就是现代操作系统pagecache的大小\n\n\nhttp://www.jianshu.com/p/6494e33c9b1f\nConsume Queue 顺序写，顺序读 几乎都是完全命中Page Cache，和内存速度几乎一样\nCommit Log 顺序写，顺序跳跃读，相比完全的随机读，性能也还好\n\nhttp://blog.csdn.net/mg0832058/article/details/5890688\n内存映射文件原理探索\n\n\nhttp://www.jianshu.com/p/6494e33c9b1f\n1).充分利用page cache降低读数据的时间开销. 读取时尽可能让其命中page cache, 减少IO读操作, 所以内存越大越好. 如果系统中堆积的消息过多, 读数据要访问磁盘会不会由于随机读导致系统性能急剧下降, 答案是否定的.\n访问page cache 时, 即使只访问1k的消息, 系统也会提前预读出更多数据, 在下次读时, 就可能命中内存.\n随机访问Commit Log磁盘数据, 系统IO调度算法设置为NOOP方式, 会在一定程度上将完全的随机读变成顺序跳跃方式, 而顺序跳跃方式读较完全的随机读性能会高5倍以上.\n另外4k的消息在完全随机访问情况下, 仍然可以达到8K次每秒以上的读性能.\n由于Consume Queue存储数据量极少, 而且是顺序读, 在PAGECACHE预读作用下, Consume Queue的读性能几乎与内存一致, 即使堆积情况下. 所以可认为Consume Queue完全不会阻碍读性能.\n2).Commit Log中存储了所有的元信息, 包含消息体, 类似于Mysql、Oracle的redolog, 所以只要有Commit Log在, Consume Queue即使数据丢失, 仍然可以恢复出来.\n\nhttps://segmentfault.com/a/1190000003985468\nkafka底层原理\n\n\n\nlinux最多可以容忍多少大小的脏页。脏页－linux内核中的概念，因为硬盘的读写速度远赶不上内存的速度，系统就把读写比较频繁的数据事先放到内存中，以提高读写速度，这就叫高速缓存，linux是以页作为高速缓存的单位，当进程修改了高速缓存里的数据时，该页就被内核标记为脏页，内核将会在合适的时间把脏页的数据写到磁盘中去，以保持高速缓存中的数据和磁盘中的数据是一致的。\n\n### 问题\n\npage cache是内存的东西（物理内存还是虚拟内存），我们写文件时先写进内存page cache，然后从page cache刷到disc上\n\n现在MQ异步刷盘是有个间隔的，如果说pagecache中的数据一直没有被刷进磁盘，那所谓的脏页会越来越大，jvm crash后会丢失数据么。那什么时候是不会丢消息的\n\n对于读是好理解的，但对于写，如果文件是顺序写的，commit log和consume queue都是顺序写的，那pagecache的存在如何让速度提升了？是从java heap到pagecache的速度提升了，还是说从pagecache到disc的速度提升了？\n\nproducer发送消息，如果是立马被消费这种场景\n1.对于consume queue，肯定是顺序读写，所以写进pagecache（物理内存）后，直接就从pagecache（物理内存）被读出来了\n2.对于commit log，虽然不是顺序读，但也是基本有序读，最后大部分也能命中pagecache，不需要走系统IO\n\n如果是消费历史消息，很大程度上，会发现在pagecache（虚拟内存）中没有，由系统产生缺页中断，从磁盘中重新读到pagecache中（可能还会根据顺序预读很多），然后再将数据从pagecache复制到socket中传输到consumer。\n\nMappedByteBuffer 能不能映射大于操作系统内存的文件？\nMappedByteBuffer所占用的内存是堆外内存，那什么时候才能被回收\n\nhttp://www.iocoder.cn/RocketMQ/message-store/\nCommitRealTimeService\t异步刷盘 && 开启内存字节缓冲区\t第一\nFlushRealTimeService\t异步刷盘 && 关闭内存字节缓冲区\t第二\nGroupCommitService\t同步刷盘\t第三\n没看懂\n\nhttp://blog.csdn.net/iie_libi/article/details/54289580\n零拷贝技术\n\nConsumer 消费消息过程，使用了零拷贝技术，因为有小块数据传输的需求，效果会比 sendfile 更好，所以RocketMQ选择了mmap+write方式。\n① 优点：即使频繁调用，使用小块文件传输，效率也很高\n② 缺点：不能很好的利用 DMA 方式，会比 sendfile 多消耗CPU，内存安全性控制复杂，需要避免JVM Crash问题。\n\n文件系统\n\n建议选择ext4文件系统，删除文件的实时性强。\n调优：文件系统的io调度算法需要调整为deadline，因为deadline 算法在随机读情况下，可以合并读请求为顺序跳跃方式，从而提高读IO 吞吐量。\n\n文件读写冲突？\n\n写文件的时候，如果消费者在读怎么办？\n依赖于操作系统对文件读写操作的处理，，，永远一个一个进程在写文件，如果其他进程需要访问文件，只能是读，或者是再创建一个副本，写文件。（读写锁+写时复制） 读写锁在哪里\n\n提高pagecache？\n\nRocketMQ用的是FileChannel.map()出来的MappedByteBuffer，这种Buffer是堆外内存，MQ怎么对这部分的内存进行回收？\n``` java\npublic static void clean(final ByteBuffer buffer) {\n    if (buffer == null || !buffer.isDirect() || buffer.capacity() == 0)\n        return;\n    invoke(invoke(viewed(buffer), \"cleaner\"), \"clean\");\n}\n```\n\n``` java\nprivate static class Deallocator\n        implements Runnable {\n    private static Unsafe unsafe = Unsafe.getUnsafe();\n\n    private long address;\n    private long size;\n    private int capacity;\n\n    private Deallocator(long address, long size, int capacity) {\n        assert (address != 0);\n        this.address = address;\n        this.size = size;\n        this.capacity = capacity;\n    }\n\n    public void run() {\n        if (address == 0) {\n            // Paranoia\n            return;\n        }\n        unsafe.freeMemory(address);\n        address = 0;\n        Bits.unreserveMemory(size, capacity);\n    }\n\n}\n```\n\n堆外内存的回收需要依赖显式Full GC或者隐式Full GC，一般来说DisableExplicitGC可以开，也可以关，但是如果禁用了显式GC，当系统没有足够的Full GC时，堆外内存无法回收。\n\n  想要提高pagecache的命中率，即尽量让访问的页在物理内存中，而不是在虚拟内存中，减少IO 读操作，所以从硬件的角度，当然是内存越大越好。\n而在软件角度，rocketmq有以下策略：\n尽量顺序读\n 如果需要随机读的话：\n访问 PAGECACHE 时，即使只访问 1k 的消息，系统也会提前预读出更多数据，在下次读时，就可能命中内存。\n 随机访问 Commit Log 磁盘数据，系统 IO 调度算法设置为NOOP 方式，会在一定程度上将完全的随机读变成顺序跳跃方式，而顺序跳跃方式读较完全的随机读性能会高5 倍以上。\n \n 可能的优化策略\n \n 1．线程绑定核+线程池（取模）\n a) 将每个线程绑定核，一个函数就可以\n b) 优势：避免线程核间调度\n 2．改用互斥锁为读写锁\n a) 读读场景的线程可以并行\n 3．使用xxhash代替crc算法，性能可以提高很多\n a) 参考链接：https://cyan4973.github.io/xxHash/\n 4．使用topic划分多个逻辑队列（链表）\n a) 避免topic的多次字符串的比较\n 5．改用STL的deque来替代MESA list\n a) Deque类似于vector，可以支持随机访问\n b) 常量时间内在头部和尾部插入，删除元素\n 6．改用跳表来代替MESA list\n a) 跳表可以高并发+log（n）的随机访问\n b) 不能删除元素 \n i. 设为标志位，当内存数据达到一定阈值时，写到磁盘或者持久化到leveldb中（hbase也是这样做的）。\n \n _java.nio.channels.FileChannel_\n `public abstract void force(boolean metaData) throws java.io.IOException`\n Forces any updates to this channel's file to be written to the storage device that contains it.\n If this channel's file resides on a local storage device then when this method returns it is guaranteed that all changes made to the file since this channel was created, or since this method was last invoked, will have been written to that device. This is useful for ensuring that critical information is not lost in the event of a system crash.\n If the file does not reside on a local device then no such guarantee is made.\n The metaData parameter can be used to limit the number of I/O operations that this method is required to perform. Passing false for this parameter indicates that only updates to the file's content need be written to storage; passing true indicates that updates to both the file's content and metadata must be written, which generally requires at least one more I/O operation. Whether this parameter actually has any effect is dependent upon the underlying operating system and is therefore unspecified.\n Invoking this method may cause an I/O operation to occur even if the channel was only opened for reading. Some operating systems, for example, maintain a last-access time as part of a file's metadata, and this time is updated whenever the file is read. Whether or not this is actually done is system-dependent and is therefore unspecified.\n This method is only guaranteed to force changes that were made to this channel's file via the methods defined in this class. **It may or may not force changes that were made by modifying the content of a mapped byte buffer obtained by invoking the map method. Invoking the force method of the mapped byte buffer will force changes made to the buffer's content to be written.**\n \n _java.nio.MappedByteBuffer_\n `public final MappedByteBuffer force()`\n Forces any changes made to this buffer's content to be written to the storage device containing the mapped file.\n If the file mapped into this buffer resides on a local storage device then when this method returns it is guaranteed that all changes made to the buffer since it was created, or since this method was last invoked, will have been written to that device.\n If the file does not reside on a local device then no such guarantee is made.\n If this buffer was not mapped in read/write mode (java.nio.channels.FileChannel.MapMode.READ_WRITE) then invoking this method has no effect.\n \n \n ### 写得超级好的一篇文章\n \n http://blog.csdn.net/a417930422/article/details/52585862\n\n包括下面的问题：\n\nwangbin00162017-08-08 17:011楼\n楼主确定 零拷贝-sendfile 对应到java中\n为FileChannel.transferTo(long position, long count, WritableByteChannel target)//？？\n\nrocketmq 文档上面写到 RocketMQ选择了第一种方式，mmap+write方式，因为有小块数据传输的需求，效果会比sendfile更好。\n\n源码里面使用的是netty的FileRegion 用的是FileChannel.transferTo\n\nFileRegion fileRegion =\nnew ManyMessageTransfer(response.encodeHeader(getMessageResult.getBufferTotalSize()), getMessageResult);\nchannel.writeAndFlush(fileRegion)\n            回复  2条回复\n             a417930422\n            a4179304222017-09-21 10:35\n            回复wangbin0016：另外，rocketmq主要使用的是mmap，即java的MappedByteBuffer用于快速读写。\n             a417930422\n            a4179304222017-09-21 10:32\n            回复wangbin0016：rocketmq文档中写的是Consumer 消费消息过程使用了mmap+write，即内存映射文件的方式，请参照我写的rocketmq存储相关文章：http://blog.csdn.net/a417930422/article/details/52585180.\n            你说的netty的FileRegion其实是被rocketmq重新实现的ManyMessageTransfer，而transfer过程其实是将GetMessageResult对象的数据写到netty的channel中，本质是从内核获取数据直接发送至socket，不会复制到用户空间。\n            GetMessageResult其实是mmap的一个子缓冲区而已。\n            有兴趣可以看看源码 com.alibaba.rocketmq.store.DefaultMessageStore.getMessage方法\n            \n            \n            \n            \n            \n为何要懂零拷贝原理？因为rocketmq存储核心使用的就是零拷贝原理。\n\n1. io读写的方式\n   \n   1. 中断\n   2. DMA\n2. 中断方式\n   1. 中断方式的流程图如下：\n      \n      \n      \n      1. 用户进程发起数据读取请求\n      2. 系统调度为该进程分配cpu\n      3. cpu向io控制器(ide,scsi)发送io请求\n      4. 用户进程等待io完成，让出cpu\n      5. 系统调度cpu执行其他任务\n      6. 数据写入至io控制器的缓冲寄存器\n      7. 缓冲寄存器满了向cpu发出中断信号\n      8. cpu读取数据至内存\n   2. 缺点：中断次数取决于缓冲寄存器的大小\n3. DMA ： 直接内存存取\n   1. DMA方式的流程图如下：\n      \n      \n      \n      1. 用户进程发起数据读取请求\n      2. 系统调度为该进程分配cpu\n      3. cpu向DMA发送io请求\n      4. 用户进程等待io完成，让出cpu\n      5. 系统调度cpu执行其他任务\n      6. 数据写入至io控制器的缓冲寄存器\n      7. DMA不断获取缓冲寄存器中的数据（需要cpu时钟）\n      8. 传输至内存（需要cpu时钟）\n      9. 所需的全部数据获取完毕后向cpu发出中断信号\n   2. 优点：减少cpu中断次数，不用cpu拷贝数据\n4. 数据拷贝\n   1. 下面展示了 传统方式读取数据后并通过网络发送 所发生的数据拷贝：\n      \n      \n      \n      1. 一个read系统调用后，DMA执行了一次数据拷贝，从磁盘到内核空间\n      2. read结束后，发生第二次数据拷贝，由cpu将数据从内核空间拷贝至用户空间\n      3. send系统调用，cpu发生第三次数据拷贝，由cpu将数据从用户空间拷贝至内核空间(socket缓冲区)\n      4. send系统调用结束后，DMA执行第四次数据拷贝，将数据从内核拷贝至协议引擎\n      5. 另外，这四个过程中，每个过程都发生一次上下文切换\n   2. 内存缓冲数据，主要是为了提高性能，内核可以预读部分数据，当所需数据小于内存缓冲区大小时，将极大的提高性能。\n   3. 零拷贝是为了消除这个过程中冗余的拷贝\n5. 零拷贝-sendfile 对应到java中\n   \n   为FileChannel.transferTo(long position, long count, WritableByteChannel target)//\n   将数据从文件通道传输到了给定的可写字节通道\n   1. 避免了第2，3步的数据拷贝，参考下图：\n      \n      \n      \n      1. DMA从拷贝至内核缓冲区\n      2. cpu将数据从内核缓冲区拷贝至内核空间(socket缓冲区)\n      3. DMA将数据从内核拷贝至协议引擎\n      4. 这三个过程中共发生2次上下文切换，分别为发起读取文件和发送数据\n   2. 以上过程发生了三次数据拷贝，其中有一次为cpu完成\n   3. linux内核2.4以后，socket缓冲区做了调整，DMA带收集功能，如下图：\n      \n      \n      \n      1. DMA从拷贝至内核缓冲区\n      2. 将数据的位置和长度的信息的描述符增加至内核空间(socket缓冲区)\n      3. DMA将数据从内核拷贝至协议引擎\n6. 零拷贝-mmap 对应到java中\n   \n   为MappedByteBuffer//文件内存映射\n   1. 数据不会复制到用户空间，只在内核空间，与sendfile类似，但是应用程序可以直接操作该内存。\n7. 参考资料\n   1. http://blog.chinaunix.net/uid-25314474-id-3325879.html\n   2. http://blog.chinaunix.net/uid-28874972-id-3725082.html\n   3. https://www.ibm.com/developerworks/cn/java/j-zerocopy/#fig1\n   4. http://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/\n   5. https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/\n","source":"_posts/RocketMQ-Message-send-and-persistence.md","raw":"---\ntitle: RocketMQ——消息发送与落盘（三）\ndate: 2017-11-03 14:38:10\ntags: RocketMQ\n---\n\n\nproducer发送消息，如果是立马被消费这种场景\n1.对于consume queue，肯定是顺序读写，所以写进pagecache后，直接就从pagecache被读出来了\n2.对于commit log，虽然不是顺序读，但也是基本有序读，最后大部分也能命中pagecache，不需要走系统IO\n\n如果是消费历史消息，很大程度上，会发现在pagecache中没有，由系统产生缺页中断，从磁盘中重新读到pagecache中（可能还会根据顺序预读很多），然后再将数据从pagecache复制到socket中传输到consumer。\n\n### 异步刷盘有两种方式\n\n``` java\n// Synchronization flush\nif (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) {\n    final GroupCommitService service = (GroupCommitService) this.flushCommitLogService;\n}\n// Asynchronous flush\nelse {\n    if (!this.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) {\n        // FlushRealTimeService\n        flushCommitLogService.wakeup();\n    } else {\n        // CommitRealTimeService\n        commitLogService.wakeup();\n    }\n}\n```\n\n``` java\npublic boolean isTransientStorePoolEnable() {\n    return transientStorePoolEnable && FlushDiskType.ASYNC_FLUSH == getFlushDiskType()\n        && BrokerRole.SLAVE != getBrokerRole();\n}\n```\n\n\n### 功力深厚的文章\ntransientStorePoolEnable的具体含义是什么？\nFlushRealTimeService和CommitRealTimeService刷盘的方式有什么区别，在性能有什么区别？\n\n```\nNAME\n     mlock, munlock -- lock (unlock) physical pages in memory\n\nSYNOPSIS\n     #include <sys/mman.h>\n\n     int\n     mlock(const void *addr, size_t len);\n\n     int\n     munlock(const void *addr, size_t len);\n\nDESCRIPTION\n     The mlock system call locks a set of physical pages into memory.  The pages are associated with a virtual address range\n     that starts at addr and extends for len bytes.  The munlock call unlocks pages that were previously locked by one or more\n     mlock calls.  For both calls, the addr parameter should be aligned to a multiple of the page size.  If the len parameter\n     is not a multiple of the page size, it will be rounded up to be so.  The entire range must be allocated.\n\n     After an mlock call, the indicated pages will cause neither a non-resident page nor address-translation fault until they\n     are unlocked.  They may still cause protection-violation faults or TLB-miss faults on architectures with software-managed\n     TLBs.  The physical pages remain in memory until all locked mappings for the pages are removed.\n\n     Multiple processes may have the same physical pages locked via their own virtual address mappings.  Similarly, a single\n     process may have pages multiply-locked via different virtual mappings of the same pages or via nested mlock calls on the\n     same address range.  Unlocking is performed explicitly by munlock or implicitly by a call to munmap, which deallocates\n     the unmapped address range.  Locked mappings are not inherited by the child process after a fork(2).\n\n     Because physical memory is a potentially scarce resource, processes are limited in how much memory they can lock down.  A\n     single process can mlock the minimum of a system-wide ``wired pages'' limit and the per-process RLIMIT_MEMLOCK resource\n     limit.\n\nRETURN VALUES\n     A return value of 0 indicates that the call succeeded and all pages in the range have either been locked or unlocked, as\n     requested.  A return value of -1 indicates an error occurred and the locked status of all pages in the range remains\n     unchanged.  In this case, the global location errno is set to indicate the error.\n```\n\n![你想输入的替代文字](RocketMQ-Message-send-and-persistence/disc-fall.gif)\n\n### 逻辑Offset队列: ConsumerQueue\n\n\n### 物理Offset队列: CommitLog\n\n### MappedByteBuffer\n\n操纵MappedByteBuffer的线程或者进程必须对某一个文件的映射Buffer有独占权，\n在设计上，消息的顺序是由CommitLog决定，所以CommitLog在Append新的消息时，必须上锁进行互斥。\n\n*传统的synchronized叫做monitor lock，当一个线程进入了synchronized的代码块时，我们说，该线程own（拥有）了monitor lock。这种锁是一种重量级锁，用mutual exclusive（互斥）的特性来实现了同步的需求。\n*自旋锁，JDK1.6引进，我们知道，线程状态与状态的切换，是需要内核参与的，简单点来讲，这个过程是需要点时间的。线程B已经own了一个锁，这是线程A去尝试获取锁，本来线程A应该要挂起，JVM不让它挂起，让A在那里做自旋操作，JVM要赌当前持有锁的B会很快释放锁。如果线程B确实很快释放了锁，那对于A来讲是一个非常好事情，因为A可以不用切换状态，立刻持有锁。那什么时候会用到呢？http://blog.csdn.net/u013080921/article/details/42676231\n\n#### Spin Lock(自旋锁)\n\n#### ReentrantLock(重入锁)\n\n\n### 异步刷盘机制\n\nhttp://blog.csdn.net/vonzhoufz/article/details/47248777\n\n#### 磁盘顺序读写与随机读写的差异\n\nhttps://kafka.apache.org/documentation/#design_filesystem\n\nhttp://blog.csdn.net/evankaka/article/details/48464013\n\n需要好好研究：http://blog.csdn.net/javahongxi/article/details/72956619?locationNum=2&fps=1\n虽然讲的是kafka，研究价值极高：http://blog.csdn.net/tototuzuoquan/article/details/73437890\npagecache是一个现在操作系统带有的天然的缓存！！！！！\n\nhttp://blog.csdn.net/mg0832058/article/details/5890688\n内存映射文件原理探索\n\n\n如何查看内存的 PAGESIZE\n``` bash\ngetconf PAGESIZE\n```\n\n终于理解了！！！！ 首先，Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。同时如果有其他进程申请内存，回收PageCache的代价又很小，所以现代的OS都支持PageCache。 \n\n所以说 commit(atLeastSize)的参数就是现代操作系统pagecache的大小\n\n\nhttp://www.jianshu.com/p/6494e33c9b1f\nConsume Queue 顺序写，顺序读 几乎都是完全命中Page Cache，和内存速度几乎一样\nCommit Log 顺序写，顺序跳跃读，相比完全的随机读，性能也还好\n\nhttp://blog.csdn.net/mg0832058/article/details/5890688\n内存映射文件原理探索\n\n\nhttp://www.jianshu.com/p/6494e33c9b1f\n1).充分利用page cache降低读数据的时间开销. 读取时尽可能让其命中page cache, 减少IO读操作, 所以内存越大越好. 如果系统中堆积的消息过多, 读数据要访问磁盘会不会由于随机读导致系统性能急剧下降, 答案是否定的.\n访问page cache 时, 即使只访问1k的消息, 系统也会提前预读出更多数据, 在下次读时, 就可能命中内存.\n随机访问Commit Log磁盘数据, 系统IO调度算法设置为NOOP方式, 会在一定程度上将完全的随机读变成顺序跳跃方式, 而顺序跳跃方式读较完全的随机读性能会高5倍以上.\n另外4k的消息在完全随机访问情况下, 仍然可以达到8K次每秒以上的读性能.\n由于Consume Queue存储数据量极少, 而且是顺序读, 在PAGECACHE预读作用下, Consume Queue的读性能几乎与内存一致, 即使堆积情况下. 所以可认为Consume Queue完全不会阻碍读性能.\n2).Commit Log中存储了所有的元信息, 包含消息体, 类似于Mysql、Oracle的redolog, 所以只要有Commit Log在, Consume Queue即使数据丢失, 仍然可以恢复出来.\n\nhttps://segmentfault.com/a/1190000003985468\nkafka底层原理\n\n\n\nlinux最多可以容忍多少大小的脏页。脏页－linux内核中的概念，因为硬盘的读写速度远赶不上内存的速度，系统就把读写比较频繁的数据事先放到内存中，以提高读写速度，这就叫高速缓存，linux是以页作为高速缓存的单位，当进程修改了高速缓存里的数据时，该页就被内核标记为脏页，内核将会在合适的时间把脏页的数据写到磁盘中去，以保持高速缓存中的数据和磁盘中的数据是一致的。\n\n### 问题\n\npage cache是内存的东西（物理内存还是虚拟内存），我们写文件时先写进内存page cache，然后从page cache刷到disc上\n\n现在MQ异步刷盘是有个间隔的，如果说pagecache中的数据一直没有被刷进磁盘，那所谓的脏页会越来越大，jvm crash后会丢失数据么。那什么时候是不会丢消息的\n\n对于读是好理解的，但对于写，如果文件是顺序写的，commit log和consume queue都是顺序写的，那pagecache的存在如何让速度提升了？是从java heap到pagecache的速度提升了，还是说从pagecache到disc的速度提升了？\n\nproducer发送消息，如果是立马被消费这种场景\n1.对于consume queue，肯定是顺序读写，所以写进pagecache（物理内存）后，直接就从pagecache（物理内存）被读出来了\n2.对于commit log，虽然不是顺序读，但也是基本有序读，最后大部分也能命中pagecache，不需要走系统IO\n\n如果是消费历史消息，很大程度上，会发现在pagecache（虚拟内存）中没有，由系统产生缺页中断，从磁盘中重新读到pagecache中（可能还会根据顺序预读很多），然后再将数据从pagecache复制到socket中传输到consumer。\n\nMappedByteBuffer 能不能映射大于操作系统内存的文件？\nMappedByteBuffer所占用的内存是堆外内存，那什么时候才能被回收\n\nhttp://www.iocoder.cn/RocketMQ/message-store/\nCommitRealTimeService\t异步刷盘 && 开启内存字节缓冲区\t第一\nFlushRealTimeService\t异步刷盘 && 关闭内存字节缓冲区\t第二\nGroupCommitService\t同步刷盘\t第三\n没看懂\n\nhttp://blog.csdn.net/iie_libi/article/details/54289580\n零拷贝技术\n\nConsumer 消费消息过程，使用了零拷贝技术，因为有小块数据传输的需求，效果会比 sendfile 更好，所以RocketMQ选择了mmap+write方式。\n① 优点：即使频繁调用，使用小块文件传输，效率也很高\n② 缺点：不能很好的利用 DMA 方式，会比 sendfile 多消耗CPU，内存安全性控制复杂，需要避免JVM Crash问题。\n\n文件系统\n\n建议选择ext4文件系统，删除文件的实时性强。\n调优：文件系统的io调度算法需要调整为deadline，因为deadline 算法在随机读情况下，可以合并读请求为顺序跳跃方式，从而提高读IO 吞吐量。\n\n文件读写冲突？\n\n写文件的时候，如果消费者在读怎么办？\n依赖于操作系统对文件读写操作的处理，，，永远一个一个进程在写文件，如果其他进程需要访问文件，只能是读，或者是再创建一个副本，写文件。（读写锁+写时复制） 读写锁在哪里\n\n提高pagecache？\n\nRocketMQ用的是FileChannel.map()出来的MappedByteBuffer，这种Buffer是堆外内存，MQ怎么对这部分的内存进行回收？\n``` java\npublic static void clean(final ByteBuffer buffer) {\n    if (buffer == null || !buffer.isDirect() || buffer.capacity() == 0)\n        return;\n    invoke(invoke(viewed(buffer), \"cleaner\"), \"clean\");\n}\n```\n\n``` java\nprivate static class Deallocator\n        implements Runnable {\n    private static Unsafe unsafe = Unsafe.getUnsafe();\n\n    private long address;\n    private long size;\n    private int capacity;\n\n    private Deallocator(long address, long size, int capacity) {\n        assert (address != 0);\n        this.address = address;\n        this.size = size;\n        this.capacity = capacity;\n    }\n\n    public void run() {\n        if (address == 0) {\n            // Paranoia\n            return;\n        }\n        unsafe.freeMemory(address);\n        address = 0;\n        Bits.unreserveMemory(size, capacity);\n    }\n\n}\n```\n\n堆外内存的回收需要依赖显式Full GC或者隐式Full GC，一般来说DisableExplicitGC可以开，也可以关，但是如果禁用了显式GC，当系统没有足够的Full GC时，堆外内存无法回收。\n\n  想要提高pagecache的命中率，即尽量让访问的页在物理内存中，而不是在虚拟内存中，减少IO 读操作，所以从硬件的角度，当然是内存越大越好。\n而在软件角度，rocketmq有以下策略：\n尽量顺序读\n 如果需要随机读的话：\n访问 PAGECACHE 时，即使只访问 1k 的消息，系统也会提前预读出更多数据，在下次读时，就可能命中内存。\n 随机访问 Commit Log 磁盘数据，系统 IO 调度算法设置为NOOP 方式，会在一定程度上将完全的随机读变成顺序跳跃方式，而顺序跳跃方式读较完全的随机读性能会高5 倍以上。\n \n 可能的优化策略\n \n 1．线程绑定核+线程池（取模）\n a) 将每个线程绑定核，一个函数就可以\n b) 优势：避免线程核间调度\n 2．改用互斥锁为读写锁\n a) 读读场景的线程可以并行\n 3．使用xxhash代替crc算法，性能可以提高很多\n a) 参考链接：https://cyan4973.github.io/xxHash/\n 4．使用topic划分多个逻辑队列（链表）\n a) 避免topic的多次字符串的比较\n 5．改用STL的deque来替代MESA list\n a) Deque类似于vector，可以支持随机访问\n b) 常量时间内在头部和尾部插入，删除元素\n 6．改用跳表来代替MESA list\n a) 跳表可以高并发+log（n）的随机访问\n b) 不能删除元素 \n i. 设为标志位，当内存数据达到一定阈值时，写到磁盘或者持久化到leveldb中（hbase也是这样做的）。\n \n _java.nio.channels.FileChannel_\n `public abstract void force(boolean metaData) throws java.io.IOException`\n Forces any updates to this channel's file to be written to the storage device that contains it.\n If this channel's file resides on a local storage device then when this method returns it is guaranteed that all changes made to the file since this channel was created, or since this method was last invoked, will have been written to that device. This is useful for ensuring that critical information is not lost in the event of a system crash.\n If the file does not reside on a local device then no such guarantee is made.\n The metaData parameter can be used to limit the number of I/O operations that this method is required to perform. Passing false for this parameter indicates that only updates to the file's content need be written to storage; passing true indicates that updates to both the file's content and metadata must be written, which generally requires at least one more I/O operation. Whether this parameter actually has any effect is dependent upon the underlying operating system and is therefore unspecified.\n Invoking this method may cause an I/O operation to occur even if the channel was only opened for reading. Some operating systems, for example, maintain a last-access time as part of a file's metadata, and this time is updated whenever the file is read. Whether or not this is actually done is system-dependent and is therefore unspecified.\n This method is only guaranteed to force changes that were made to this channel's file via the methods defined in this class. **It may or may not force changes that were made by modifying the content of a mapped byte buffer obtained by invoking the map method. Invoking the force method of the mapped byte buffer will force changes made to the buffer's content to be written.**\n \n _java.nio.MappedByteBuffer_\n `public final MappedByteBuffer force()`\n Forces any changes made to this buffer's content to be written to the storage device containing the mapped file.\n If the file mapped into this buffer resides on a local storage device then when this method returns it is guaranteed that all changes made to the buffer since it was created, or since this method was last invoked, will have been written to that device.\n If the file does not reside on a local device then no such guarantee is made.\n If this buffer was not mapped in read/write mode (java.nio.channels.FileChannel.MapMode.READ_WRITE) then invoking this method has no effect.\n \n \n ### 写得超级好的一篇文章\n \n http://blog.csdn.net/a417930422/article/details/52585862\n\n包括下面的问题：\n\nwangbin00162017-08-08 17:011楼\n楼主确定 零拷贝-sendfile 对应到java中\n为FileChannel.transferTo(long position, long count, WritableByteChannel target)//？？\n\nrocketmq 文档上面写到 RocketMQ选择了第一种方式，mmap+write方式，因为有小块数据传输的需求，效果会比sendfile更好。\n\n源码里面使用的是netty的FileRegion 用的是FileChannel.transferTo\n\nFileRegion fileRegion =\nnew ManyMessageTransfer(response.encodeHeader(getMessageResult.getBufferTotalSize()), getMessageResult);\nchannel.writeAndFlush(fileRegion)\n            回复  2条回复\n             a417930422\n            a4179304222017-09-21 10:35\n            回复wangbin0016：另外，rocketmq主要使用的是mmap，即java的MappedByteBuffer用于快速读写。\n             a417930422\n            a4179304222017-09-21 10:32\n            回复wangbin0016：rocketmq文档中写的是Consumer 消费消息过程使用了mmap+write，即内存映射文件的方式，请参照我写的rocketmq存储相关文章：http://blog.csdn.net/a417930422/article/details/52585180.\n            你说的netty的FileRegion其实是被rocketmq重新实现的ManyMessageTransfer，而transfer过程其实是将GetMessageResult对象的数据写到netty的channel中，本质是从内核获取数据直接发送至socket，不会复制到用户空间。\n            GetMessageResult其实是mmap的一个子缓冲区而已。\n            有兴趣可以看看源码 com.alibaba.rocketmq.store.DefaultMessageStore.getMessage方法\n            \n            \n            \n            \n            \n为何要懂零拷贝原理？因为rocketmq存储核心使用的就是零拷贝原理。\n\n1. io读写的方式\n   \n   1. 中断\n   2. DMA\n2. 中断方式\n   1. 中断方式的流程图如下：\n      \n      \n      \n      1. 用户进程发起数据读取请求\n      2. 系统调度为该进程分配cpu\n      3. cpu向io控制器(ide,scsi)发送io请求\n      4. 用户进程等待io完成，让出cpu\n      5. 系统调度cpu执行其他任务\n      6. 数据写入至io控制器的缓冲寄存器\n      7. 缓冲寄存器满了向cpu发出中断信号\n      8. cpu读取数据至内存\n   2. 缺点：中断次数取决于缓冲寄存器的大小\n3. DMA ： 直接内存存取\n   1. DMA方式的流程图如下：\n      \n      \n      \n      1. 用户进程发起数据读取请求\n      2. 系统调度为该进程分配cpu\n      3. cpu向DMA发送io请求\n      4. 用户进程等待io完成，让出cpu\n      5. 系统调度cpu执行其他任务\n      6. 数据写入至io控制器的缓冲寄存器\n      7. DMA不断获取缓冲寄存器中的数据（需要cpu时钟）\n      8. 传输至内存（需要cpu时钟）\n      9. 所需的全部数据获取完毕后向cpu发出中断信号\n   2. 优点：减少cpu中断次数，不用cpu拷贝数据\n4. 数据拷贝\n   1. 下面展示了 传统方式读取数据后并通过网络发送 所发生的数据拷贝：\n      \n      \n      \n      1. 一个read系统调用后，DMA执行了一次数据拷贝，从磁盘到内核空间\n      2. read结束后，发生第二次数据拷贝，由cpu将数据从内核空间拷贝至用户空间\n      3. send系统调用，cpu发生第三次数据拷贝，由cpu将数据从用户空间拷贝至内核空间(socket缓冲区)\n      4. send系统调用结束后，DMA执行第四次数据拷贝，将数据从内核拷贝至协议引擎\n      5. 另外，这四个过程中，每个过程都发生一次上下文切换\n   2. 内存缓冲数据，主要是为了提高性能，内核可以预读部分数据，当所需数据小于内存缓冲区大小时，将极大的提高性能。\n   3. 零拷贝是为了消除这个过程中冗余的拷贝\n5. 零拷贝-sendfile 对应到java中\n   \n   为FileChannel.transferTo(long position, long count, WritableByteChannel target)//\n   将数据从文件通道传输到了给定的可写字节通道\n   1. 避免了第2，3步的数据拷贝，参考下图：\n      \n      \n      \n      1. DMA从拷贝至内核缓冲区\n      2. cpu将数据从内核缓冲区拷贝至内核空间(socket缓冲区)\n      3. DMA将数据从内核拷贝至协议引擎\n      4. 这三个过程中共发生2次上下文切换，分别为发起读取文件和发送数据\n   2. 以上过程发生了三次数据拷贝，其中有一次为cpu完成\n   3. linux内核2.4以后，socket缓冲区做了调整，DMA带收集功能，如下图：\n      \n      \n      \n      1. DMA从拷贝至内核缓冲区\n      2. 将数据的位置和长度的信息的描述符增加至内核空间(socket缓冲区)\n      3. DMA将数据从内核拷贝至协议引擎\n6. 零拷贝-mmap 对应到java中\n   \n   为MappedByteBuffer//文件内存映射\n   1. 数据不会复制到用户空间，只在内核空间，与sendfile类似，但是应用程序可以直接操作该内存。\n7. 参考资料\n   1. http://blog.chinaunix.net/uid-25314474-id-3325879.html\n   2. http://blog.chinaunix.net/uid-28874972-id-3725082.html\n   3. https://www.ibm.com/developerworks/cn/java/j-zerocopy/#fig1\n   4. http://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/\n   5. https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/\n","slug":"RocketMQ-Message-send-and-persistence","published":1,"updated":"2019-09-28T08:51:00.919Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84p004yv1npsjkspm45","content":"<p>producer发送消息，如果是立马被消费这种场景<br>1.对于consume queue，肯定是顺序读写，所以写进pagecache后，直接就从pagecache被读出来了<br>2.对于commit log，虽然不是顺序读，但也是基本有序读，最后大部分也能命中pagecache，不需要走系统IO</p>\n<p>如果是消费历史消息，很大程度上，会发现在pagecache中没有，由系统产生缺页中断，从磁盘中重新读到pagecache中（可能还会根据顺序预读很多），然后再将数据从pagecache复制到socket中传输到consumer。</p>\n<h3 id=\"异步刷盘有两种方式\"><a href=\"#异步刷盘有两种方式\" class=\"headerlink\" title=\"异步刷盘有两种方式\"></a>异步刷盘有两种方式</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Synchronization flush</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (FlushDiskType.SYNC_FLUSH == <span class=\"keyword\">this</span>.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> GroupCommitService service = (GroupCommitService) <span class=\"keyword\">this</span>.flushCommitLogService;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// Asynchronous flush</span></span><br><span class=\"line\"><span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!<span class=\"keyword\">this</span>.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// FlushRealTimeService</span></span><br><span class=\"line\">        flushCommitLogService.wakeup();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// CommitRealTimeService</span></span><br><span class=\"line\">        commitLogService.wakeup();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">isTransientStorePoolEnable</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> transientStorePoolEnable &amp;&amp; FlushDiskType.ASYNC_FLUSH == getFlushDiskType()</span><br><span class=\"line\">        &amp;&amp; BrokerRole.SLAVE != getBrokerRole();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"功力深厚的文章\"><a href=\"#功力深厚的文章\" class=\"headerlink\" title=\"功力深厚的文章\"></a>功力深厚的文章</h3><p>transientStorePoolEnable的具体含义是什么？<br>FlushRealTimeService和CommitRealTimeService刷盘的方式有什么区别，在性能有什么区别？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NAME</span><br><span class=\"line\">     mlock, munlock -- lock (unlock) physical pages in memory</span><br><span class=\"line\"></span><br><span class=\"line\">SYNOPSIS</span><br><span class=\"line\">     #include &lt;sys/mman.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">     int</span><br><span class=\"line\">     mlock(const void *addr, size_t len);</span><br><span class=\"line\"></span><br><span class=\"line\">     int</span><br><span class=\"line\">     munlock(const void *addr, size_t len);</span><br><span class=\"line\"></span><br><span class=\"line\">DESCRIPTION</span><br><span class=\"line\">     The mlock system call locks a set of physical pages into memory.  The pages are associated with a virtual address range</span><br><span class=\"line\">     that starts at addr and extends for len bytes.  The munlock call unlocks pages that were previously locked by one or more</span><br><span class=\"line\">     mlock calls.  For both calls, the addr parameter should be aligned to a multiple of the page size.  If the len parameter</span><br><span class=\"line\">     is not a multiple of the page size, it will be rounded up to be so.  The entire range must be allocated.</span><br><span class=\"line\"></span><br><span class=\"line\">     After an mlock call, the indicated pages will cause neither a non-resident page nor address-translation fault until they</span><br><span class=\"line\">     are unlocked.  They may still cause protection-violation faults or TLB-miss faults on architectures with software-managed</span><br><span class=\"line\">     TLBs.  The physical pages remain in memory until all locked mappings for the pages are removed.</span><br><span class=\"line\"></span><br><span class=\"line\">     Multiple processes may have the same physical pages locked via their own virtual address mappings.  Similarly, a single</span><br><span class=\"line\">     process may have pages multiply-locked via different virtual mappings of the same pages or via nested mlock calls on the</span><br><span class=\"line\">     same address range.  Unlocking is performed explicitly by munlock or implicitly by a call to munmap, which deallocates</span><br><span class=\"line\">     the unmapped address range.  Locked mappings are not inherited by the child process after a fork(2).</span><br><span class=\"line\"></span><br><span class=\"line\">     Because physical memory is a potentially scarce resource, processes are limited in how much memory they can lock down.  A</span><br><span class=\"line\">     single process can mlock the minimum of a system-wide ``wired pages&apos;&apos; limit and the per-process RLIMIT_MEMLOCK resource</span><br><span class=\"line\">     limit.</span><br><span class=\"line\"></span><br><span class=\"line\">RETURN VALUES</span><br><span class=\"line\">     A return value of 0 indicates that the call succeeded and all pages in the range have either been locked or unlocked, as</span><br><span class=\"line\">     requested.  A return value of -1 indicates an error occurred and the locked status of all pages in the range remains</span><br><span class=\"line\">     unchanged.  In this case, the global location errno is set to indicate the error.</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2017/11/03/RocketMQ-Message-send-and-persistence/disc-fall.gif\" alt=\"你想输入的替代文字\"></p>\n<h3 id=\"逻辑Offset队列-ConsumerQueue\"><a href=\"#逻辑Offset队列-ConsumerQueue\" class=\"headerlink\" title=\"逻辑Offset队列: ConsumerQueue\"></a>逻辑Offset队列: ConsumerQueue</h3><h3 id=\"物理Offset队列-CommitLog\"><a href=\"#物理Offset队列-CommitLog\" class=\"headerlink\" title=\"物理Offset队列: CommitLog\"></a>物理Offset队列: CommitLog</h3><h3 id=\"MappedByteBuffer\"><a href=\"#MappedByteBuffer\" class=\"headerlink\" title=\"MappedByteBuffer\"></a>MappedByteBuffer</h3><p>操纵MappedByteBuffer的线程或者进程必须对某一个文件的映射Buffer有独占权，<br>在设计上，消息的顺序是由CommitLog决定，所以CommitLog在Append新的消息时，必须上锁进行互斥。</p>\n<p>*传统的synchronized叫做monitor lock，当一个线程进入了synchronized的代码块时，我们说，该线程own（拥有）了monitor lock。这种锁是一种重量级锁，用mutual exclusive（互斥）的特性来实现了同步的需求。<br>*自旋锁，JDK1.6引进，我们知道，线程状态与状态的切换，是需要内核参与的，简单点来讲，这个过程是需要点时间的。线程B已经own了一个锁，这是线程A去尝试获取锁，本来线程A应该要挂起，JVM不让它挂起，让A在那里做自旋操作，JVM要赌当前持有锁的B会很快释放锁。如果线程B确实很快释放了锁，那对于A来讲是一个非常好事情，因为A可以不用切换状态，立刻持有锁。那什么时候会用到呢？<a href=\"http://blog.csdn.net/u013080921/article/details/42676231\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/u013080921/article/details/42676231</a></p>\n<h4 id=\"Spin-Lock-自旋锁\"><a href=\"#Spin-Lock-自旋锁\" class=\"headerlink\" title=\"Spin Lock(自旋锁)\"></a>Spin Lock(自旋锁)</h4><h4 id=\"ReentrantLock-重入锁\"><a href=\"#ReentrantLock-重入锁\" class=\"headerlink\" title=\"ReentrantLock(重入锁)\"></a>ReentrantLock(重入锁)</h4><h3 id=\"异步刷盘机制\"><a href=\"#异步刷盘机制\" class=\"headerlink\" title=\"异步刷盘机制\"></a>异步刷盘机制</h3><p><a href=\"http://blog.csdn.net/vonzhoufz/article/details/47248777\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/vonzhoufz/article/details/47248777</a></p>\n<h4 id=\"磁盘顺序读写与随机读写的差异\"><a href=\"#磁盘顺序读写与随机读写的差异\" class=\"headerlink\" title=\"磁盘顺序读写与随机读写的差异\"></a>磁盘顺序读写与随机读写的差异</h4><p><a href=\"https://kafka.apache.org/documentation/#design_filesystem\" target=\"_blank\" rel=\"noopener\">https://kafka.apache.org/documentation/#design_filesystem</a></p>\n<p><a href=\"http://blog.csdn.net/evankaka/article/details/48464013\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/evankaka/article/details/48464013</a></p>\n<p>需要好好研究：<a href=\"http://blog.csdn.net/javahongxi/article/details/72956619?locationNum=2&amp;fps=1\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/javahongxi/article/details/72956619?locationNum=2&amp;fps=1</a><br>虽然讲的是kafka，研究价值极高：<a href=\"http://blog.csdn.net/tototuzuoquan/article/details/73437890\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/tototuzuoquan/article/details/73437890</a><br>pagecache是一个现在操作系统带有的天然的缓存！！！！！</p>\n<p><a href=\"http://blog.csdn.net/mg0832058/article/details/5890688\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/mg0832058/article/details/5890688</a><br>内存映射文件原理探索</p>\n<p>如何查看内存的 PAGESIZE</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">getconf PAGESIZE</span><br></pre></td></tr></table></figure>\n\n<p>终于理解了！！！！ 首先，Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。同时如果有其他进程申请内存，回收PageCache的代价又很小，所以现代的OS都支持PageCache。 </p>\n<p>所以说 commit(atLeastSize)的参数就是现代操作系统pagecache的大小</p>\n<p><a href=\"http://www.jianshu.com/p/6494e33c9b1f\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/6494e33c9b1f</a><br>Consume Queue 顺序写，顺序读 几乎都是完全命中Page Cache，和内存速度几乎一样<br>Commit Log 顺序写，顺序跳跃读，相比完全的随机读，性能也还好</p>\n<p><a href=\"http://blog.csdn.net/mg0832058/article/details/5890688\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/mg0832058/article/details/5890688</a><br>内存映射文件原理探索</p>\n<p><a href=\"http://www.jianshu.com/p/6494e33c9b1f\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/6494e33c9b1f</a><br>1).充分利用page cache降低读数据的时间开销. 读取时尽可能让其命中page cache, 减少IO读操作, 所以内存越大越好. 如果系统中堆积的消息过多, 读数据要访问磁盘会不会由于随机读导致系统性能急剧下降, 答案是否定的.<br>访问page cache 时, 即使只访问1k的消息, 系统也会提前预读出更多数据, 在下次读时, 就可能命中内存.<br>随机访问Commit Log磁盘数据, 系统IO调度算法设置为NOOP方式, 会在一定程度上将完全的随机读变成顺序跳跃方式, 而顺序跳跃方式读较完全的随机读性能会高5倍以上.<br>另外4k的消息在完全随机访问情况下, 仍然可以达到8K次每秒以上的读性能.<br>由于Consume Queue存储数据量极少, 而且是顺序读, 在PAGECACHE预读作用下, Consume Queue的读性能几乎与内存一致, 即使堆积情况下. 所以可认为Consume Queue完全不会阻碍读性能.<br>2).Commit Log中存储了所有的元信息, 包含消息体, 类似于Mysql、Oracle的redolog, 所以只要有Commit Log在, Consume Queue即使数据丢失, 仍然可以恢复出来.</p>\n<p><a href=\"https://segmentfault.com/a/1190000003985468\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000003985468</a><br>kafka底层原理</p>\n<p>linux最多可以容忍多少大小的脏页。脏页－linux内核中的概念，因为硬盘的读写速度远赶不上内存的速度，系统就把读写比较频繁的数据事先放到内存中，以提高读写速度，这就叫高速缓存，linux是以页作为高速缓存的单位，当进程修改了高速缓存里的数据时，该页就被内核标记为脏页，内核将会在合适的时间把脏页的数据写到磁盘中去，以保持高速缓存中的数据和磁盘中的数据是一致的。</p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><p>page cache是内存的东西（物理内存还是虚拟内存），我们写文件时先写进内存page cache，然后从page cache刷到disc上</p>\n<p>现在MQ异步刷盘是有个间隔的，如果说pagecache中的数据一直没有被刷进磁盘，那所谓的脏页会越来越大，jvm crash后会丢失数据么。那什么时候是不会丢消息的</p>\n<p>对于读是好理解的，但对于写，如果文件是顺序写的，commit log和consume queue都是顺序写的，那pagecache的存在如何让速度提升了？是从java heap到pagecache的速度提升了，还是说从pagecache到disc的速度提升了？</p>\n<p>producer发送消息，如果是立马被消费这种场景<br>1.对于consume queue，肯定是顺序读写，所以写进pagecache（物理内存）后，直接就从pagecache（物理内存）被读出来了<br>2.对于commit log，虽然不是顺序读，但也是基本有序读，最后大部分也能命中pagecache，不需要走系统IO</p>\n<p>如果是消费历史消息，很大程度上，会发现在pagecache（虚拟内存）中没有，由系统产生缺页中断，从磁盘中重新读到pagecache中（可能还会根据顺序预读很多），然后再将数据从pagecache复制到socket中传输到consumer。</p>\n<p>MappedByteBuffer 能不能映射大于操作系统内存的文件？<br>MappedByteBuffer所占用的内存是堆外内存，那什么时候才能被回收</p>\n<p><a href=\"http://www.iocoder.cn/RocketMQ/message-store/\" target=\"_blank\" rel=\"noopener\">http://www.iocoder.cn/RocketMQ/message-store/</a><br>CommitRealTimeService    异步刷盘 &amp;&amp; 开启内存字节缓冲区    第一<br>FlushRealTimeService    异步刷盘 &amp;&amp; 关闭内存字节缓冲区    第二<br>GroupCommitService    同步刷盘    第三<br>没看懂</p>\n<p><a href=\"http://blog.csdn.net/iie_libi/article/details/54289580\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/iie_libi/article/details/54289580</a><br>零拷贝技术</p>\n<p>Consumer 消费消息过程，使用了零拷贝技术，因为有小块数据传输的需求，效果会比 sendfile 更好，所以RocketMQ选择了mmap+write方式。<br>① 优点：即使频繁调用，使用小块文件传输，效率也很高<br>② 缺点：不能很好的利用 DMA 方式，会比 sendfile 多消耗CPU，内存安全性控制复杂，需要避免JVM Crash问题。</p>\n<p>文件系统</p>\n<p>建议选择ext4文件系统，删除文件的实时性强。<br>调优：文件系统的io调度算法需要调整为deadline，因为deadline 算法在随机读情况下，可以合并读请求为顺序跳跃方式，从而提高读IO 吞吐量。</p>\n<p>文件读写冲突？</p>\n<p>写文件的时候，如果消费者在读怎么办？<br>依赖于操作系统对文件读写操作的处理，，，永远一个一个进程在写文件，如果其他进程需要访问文件，只能是读，或者是再创建一个副本，写文件。（读写锁+写时复制） 读写锁在哪里</p>\n<p>提高pagecache？</p>\n<p>RocketMQ用的是FileChannel.map()出来的MappedByteBuffer，这种Buffer是堆外内存，MQ怎么对这部分的内存进行回收？</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">clean</span><span class=\"params\">(<span class=\"keyword\">final</span> ByteBuffer buffer)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (buffer == <span class=\"keyword\">null</span> || !buffer.isDirect() || buffer.capacity() == <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    invoke(invoke(viewed(buffer), <span class=\"string\">\"cleaner\"</span>), <span class=\"string\">\"clean\"</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Deallocator</span></span></span><br><span class=\"line\"><span class=\"class\">        <span class=\"keyword\">implements</span> <span class=\"title\">Runnable</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Unsafe unsafe = Unsafe.getUnsafe();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> address;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> size;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">int</span> capacity;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"title\">Deallocator</span><span class=\"params\">(<span class=\"keyword\">long</span> address, <span class=\"keyword\">long</span> size, <span class=\"keyword\">int</span> capacity)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">assert</span> (address != <span class=\"number\">0</span>);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.address = address;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.size = size;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.capacity = capacity;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (address == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// Paranoia</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        unsafe.freeMemory(address);</span><br><span class=\"line\">        address = <span class=\"number\">0</span>;</span><br><span class=\"line\">        Bits.unreserveMemory(size, capacity);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>堆外内存的回收需要依赖显式Full GC或者隐式Full GC，一般来说DisableExplicitGC可以开，也可以关，但是如果禁用了显式GC，当系统没有足够的Full GC时，堆外内存无法回收。</p>\n<p>  想要提高pagecache的命中率，即尽量让访问的页在物理内存中，而不是在虚拟内存中，减少IO 读操作，所以从硬件的角度，当然是内存越大越好。<br>而在软件角度，rocketmq有以下策略：<br>尽量顺序读<br> 如果需要随机读的话：<br>访问 PAGECACHE 时，即使只访问 1k 的消息，系统也会提前预读出更多数据，在下次读时，就可能命中内存。<br> 随机访问 Commit Log 磁盘数据，系统 IO 调度算法设置为NOOP 方式，会在一定程度上将完全的随机读变成顺序跳跃方式，而顺序跳跃方式读较完全的随机读性能会高5 倍以上。</p>\n<p> 可能的优化策略</p>\n<p> 1．线程绑定核+线程池（取模）<br> a) 将每个线程绑定核，一个函数就可以<br> b) 优势：避免线程核间调度<br> 2．改用互斥锁为读写锁<br> a) 读读场景的线程可以并行<br> 3．使用xxhash代替crc算法，性能可以提高很多<br> a) 参考链接：<a href=\"https://cyan4973.github.io/xxHash/\" target=\"_blank\" rel=\"noopener\">https://cyan4973.github.io/xxHash/</a><br> 4．使用topic划分多个逻辑队列（链表）<br> a) 避免topic的多次字符串的比较<br> 5．改用STL的deque来替代MESA list<br> a) Deque类似于vector，可以支持随机访问<br> b) 常量时间内在头部和尾部插入，删除元素<br> 6．改用跳表来代替MESA list<br> a) 跳表可以高并发+log（n）的随机访问<br> b) 不能删除元素<br> i. 设为标志位，当内存数据达到一定阈值时，写到磁盘或者持久化到leveldb中（hbase也是这样做的）。</p>\n<p> <em>java.nio.channels.FileChannel</em><br> <code>public abstract void force(boolean metaData) throws java.io.IOException</code><br> Forces any updates to this channel’s file to be written to the storage device that contains it.<br> If this channel’s file resides on a local storage device then when this method returns it is guaranteed that all changes made to the file since this channel was created, or since this method was last invoked, will have been written to that device. This is useful for ensuring that critical information is not lost in the event of a system crash.<br> If the file does not reside on a local device then no such guarantee is made.<br> The metaData parameter can be used to limit the number of I/O operations that this method is required to perform. Passing false for this parameter indicates that only updates to the file’s content need be written to storage; passing true indicates that updates to both the file’s content and metadata must be written, which generally requires at least one more I/O operation. Whether this parameter actually has any effect is dependent upon the underlying operating system and is therefore unspecified.<br> Invoking this method may cause an I/O operation to occur even if the channel was only opened for reading. Some operating systems, for example, maintain a last-access time as part of a file’s metadata, and this time is updated whenever the file is read. Whether or not this is actually done is system-dependent and is therefore unspecified.<br> This method is only guaranteed to force changes that were made to this channel’s file via the methods defined in this class. <strong>It may or may not force changes that were made by modifying the content of a mapped byte buffer obtained by invoking the map method. Invoking the force method of the mapped byte buffer will force changes made to the buffer’s content to be written.</strong></p>\n<p> <em>java.nio.MappedByteBuffer</em><br> <code>public final MappedByteBuffer force()</code><br> Forces any changes made to this buffer’s content to be written to the storage device containing the mapped file.<br> If the file mapped into this buffer resides on a local storage device then when this method returns it is guaranteed that all changes made to the buffer since it was created, or since this method was last invoked, will have been written to that device.<br> If the file does not reside on a local device then no such guarantee is made.<br> If this buffer was not mapped in read/write mode (java.nio.channels.FileChannel.MapMode.READ_WRITE) then invoking this method has no effect.</p>\n<h3 id=\"写得超级好的一篇文章\"><a href=\"#写得超级好的一篇文章\" class=\"headerlink\" title=\"写得超级好的一篇文章\"></a>写得超级好的一篇文章</h3><p> <a href=\"http://blog.csdn.net/a417930422/article/details/52585862\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/a417930422/article/details/52585862</a></p>\n<p>包括下面的问题：</p>\n<p>wangbin00162017-08-08 17:011楼<br>楼主确定 零拷贝-sendfile 对应到java中<br>为FileChannel.transferTo(long position, long count, WritableByteChannel target)//？？</p>\n<p>rocketmq 文档上面写到 RocketMQ选择了第一种方式，mmap+write方式，因为有小块数据传输的需求，效果会比sendfile更好。</p>\n<p>源码里面使用的是netty的FileRegion 用的是FileChannel.transferTo</p>\n<p>FileRegion fileRegion =<br>new ManyMessageTransfer(response.encodeHeader(getMessageResult.getBufferTotalSize()), getMessageResult);<br>channel.writeAndFlush(fileRegion)<br>            回复  2条回复<br>             a417930422<br>            a4179304222017-09-21 10:35<br>            回复wangbin0016：另外，rocketmq主要使用的是mmap，即java的MappedByteBuffer用于快速读写。<br>             a417930422<br>            a4179304222017-09-21 10:32<br>            回复wangbin0016：rocketmq文档中写的是Consumer 消费消息过程使用了mmap+write，即内存映射文件的方式，请参照我写的rocketmq存储相关文章：<a href=\"http://blog.csdn.net/a417930422/article/details/52585180\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/a417930422/article/details/52585180</a>.<br>            你说的netty的FileRegion其实是被rocketmq重新实现的ManyMessageTransfer，而transfer过程其实是将GetMessageResult对象的数据写到netty的channel中，本质是从内核获取数据直接发送至socket，不会复制到用户空间。<br>            GetMessageResult其实是mmap的一个子缓冲区而已。<br>            有兴趣可以看看源码 com.alibaba.rocketmq.store.DefaultMessageStore.getMessage方法</p>\n<p>为何要懂零拷贝原理？因为rocketmq存储核心使用的就是零拷贝原理。</p>\n<ol>\n<li><p>io读写的方式</p>\n<ol>\n<li>中断</li>\n<li>DMA</li>\n</ol>\n</li>\n<li><p>中断方式</p>\n<ol>\n<li>中断方式的流程图如下：</li>\n</ol>\n</li>\n</ol>\n<pre><code>1. 用户进程发起数据读取请求\n2. 系统调度为该进程分配cpu\n3. cpu向io控制器(ide,scsi)发送io请求\n4. 用户进程等待io完成，让出cpu\n5. 系统调度cpu执行其他任务\n6. 数据写入至io控制器的缓冲寄存器\n7. 缓冲寄存器满了向cpu发出中断信号\n8. cpu读取数据至内存</code></pre><ol start=\"2\">\n<li>缺点：中断次数取决于缓冲寄存器的大小<ol start=\"3\">\n<li>DMA ： 直接内存存取</li>\n</ol>\n</li>\n<li>DMA方式的流程图如下：</li>\n</ol>\n<pre><code>1. 用户进程发起数据读取请求\n2. 系统调度为该进程分配cpu\n3. cpu向DMA发送io请求\n4. 用户进程等待io完成，让出cpu\n5. 系统调度cpu执行其他任务\n6. 数据写入至io控制器的缓冲寄存器\n7. DMA不断获取缓冲寄存器中的数据（需要cpu时钟）\n8. 传输至内存（需要cpu时钟）\n9. 所需的全部数据获取完毕后向cpu发出中断信号</code></pre><ol start=\"2\">\n<li>优点：减少cpu中断次数，不用cpu拷贝数据<ol start=\"4\">\n<li>数据拷贝</li>\n</ol>\n</li>\n<li>下面展示了 传统方式读取数据后并通过网络发送 所发生的数据拷贝：</li>\n</ol>\n<pre><code>1. 一个read系统调用后，DMA执行了一次数据拷贝，从磁盘到内核空间\n2. read结束后，发生第二次数据拷贝，由cpu将数据从内核空间拷贝至用户空间\n3. send系统调用，cpu发生第三次数据拷贝，由cpu将数据从用户空间拷贝至内核空间(socket缓冲区)\n4. send系统调用结束后，DMA执行第四次数据拷贝，将数据从内核拷贝至协议引擎\n5. 另外，这四个过程中，每个过程都发生一次上下文切换</code></pre><ol start=\"2\">\n<li><p>内存缓冲数据，主要是为了提高性能，内核可以预读部分数据，当所需数据小于内存缓冲区大小时，将极大的提高性能。</p>\n</li>\n<li><p>零拷贝是为了消除这个过程中冗余的拷贝</p>\n<ol start=\"5\">\n<li>零拷贝-sendfile 对应到java中</li>\n</ol>\n<p>为FileChannel.transferTo(long position, long count, WritableByteChannel target)//<br>将数据从文件通道传输到了给定的可写字节通道</p>\n</li>\n<li><p>避免了第2，3步的数据拷贝，参考下图：</p>\n</li>\n</ol>\n<pre><code>1. DMA从拷贝至内核缓冲区\n2. cpu将数据从内核缓冲区拷贝至内核空间(socket缓冲区)\n3. DMA将数据从内核拷贝至协议引擎\n4. 这三个过程中共发生2次上下文切换，分别为发起读取文件和发送数据</code></pre><ol start=\"2\">\n<li>以上过程发生了三次数据拷贝，其中有一次为cpu完成</li>\n<li>linux内核2.4以后，socket缓冲区做了调整，DMA带收集功能，如下图：</li>\n</ol>\n<pre><code>1. DMA从拷贝至内核缓冲区\n2. 将数据的位置和长度的信息的描述符增加至内核空间(socket缓冲区)\n3. DMA将数据从内核拷贝至协议引擎</code></pre><ol start=\"6\">\n<li><p>零拷贝-mmap 对应到java中</p>\n<p>为MappedByteBuffer//文件内存映射</p>\n<ol>\n<li>数据不会复制到用户空间，只在内核空间，与sendfile类似，但是应用程序可以直接操作该内存。</li>\n</ol>\n</li>\n<li><p>参考资料</p>\n<ol>\n<li><a href=\"http://blog.chinaunix.net/uid-25314474-id-3325879.html\" target=\"_blank\" rel=\"noopener\">http://blog.chinaunix.net/uid-25314474-id-3325879.html</a></li>\n<li><a href=\"http://blog.chinaunix.net/uid-28874972-id-3725082.html\" target=\"_blank\" rel=\"noopener\">http://blog.chinaunix.net/uid-28874972-id-3725082.html</a></li>\n<li><a href=\"https://www.ibm.com/developerworks/cn/java/j-zerocopy/#fig1\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/java/j-zerocopy/#fig1</a></li>\n<li><a href=\"http://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/\" target=\"_blank\" rel=\"noopener\">http://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/</a></li>\n<li><a href=\"https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/</a></li>\n</ol>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>producer发送消息，如果是立马被消费这种场景<br>1.对于consume queue，肯定是顺序读写，所以写进pagecache后，直接就从pagecache被读出来了<br>2.对于commit log，虽然不是顺序读，但也是基本有序读，最后大部分也能命中pagecache，不需要走系统IO</p>\n<p>如果是消费历史消息，很大程度上，会发现在pagecache中没有，由系统产生缺页中断，从磁盘中重新读到pagecache中（可能还会根据顺序预读很多），然后再将数据从pagecache复制到socket中传输到consumer。</p>\n<h3 id=\"异步刷盘有两种方式\"><a href=\"#异步刷盘有两种方式\" class=\"headerlink\" title=\"异步刷盘有两种方式\"></a>异步刷盘有两种方式</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Synchronization flush</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (FlushDiskType.SYNC_FLUSH == <span class=\"keyword\">this</span>.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> GroupCommitService service = (GroupCommitService) <span class=\"keyword\">this</span>.flushCommitLogService;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// Asynchronous flush</span></span><br><span class=\"line\"><span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!<span class=\"keyword\">this</span>.defaultMessageStore.getMessageStoreConfig().isTransientStorePoolEnable()) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// FlushRealTimeService</span></span><br><span class=\"line\">        flushCommitLogService.wakeup();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// CommitRealTimeService</span></span><br><span class=\"line\">        commitLogService.wakeup();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">boolean</span> <span class=\"title\">isTransientStorePoolEnable</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> transientStorePoolEnable &amp;&amp; FlushDiskType.ASYNC_FLUSH == getFlushDiskType()</span><br><span class=\"line\">        &amp;&amp; BrokerRole.SLAVE != getBrokerRole();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"功力深厚的文章\"><a href=\"#功力深厚的文章\" class=\"headerlink\" title=\"功力深厚的文章\"></a>功力深厚的文章</h3><p>transientStorePoolEnable的具体含义是什么？<br>FlushRealTimeService和CommitRealTimeService刷盘的方式有什么区别，在性能有什么区别？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NAME</span><br><span class=\"line\">     mlock, munlock -- lock (unlock) physical pages in memory</span><br><span class=\"line\"></span><br><span class=\"line\">SYNOPSIS</span><br><span class=\"line\">     #include &lt;sys/mman.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">     int</span><br><span class=\"line\">     mlock(const void *addr, size_t len);</span><br><span class=\"line\"></span><br><span class=\"line\">     int</span><br><span class=\"line\">     munlock(const void *addr, size_t len);</span><br><span class=\"line\"></span><br><span class=\"line\">DESCRIPTION</span><br><span class=\"line\">     The mlock system call locks a set of physical pages into memory.  The pages are associated with a virtual address range</span><br><span class=\"line\">     that starts at addr and extends for len bytes.  The munlock call unlocks pages that were previously locked by one or more</span><br><span class=\"line\">     mlock calls.  For both calls, the addr parameter should be aligned to a multiple of the page size.  If the len parameter</span><br><span class=\"line\">     is not a multiple of the page size, it will be rounded up to be so.  The entire range must be allocated.</span><br><span class=\"line\"></span><br><span class=\"line\">     After an mlock call, the indicated pages will cause neither a non-resident page nor address-translation fault until they</span><br><span class=\"line\">     are unlocked.  They may still cause protection-violation faults or TLB-miss faults on architectures with software-managed</span><br><span class=\"line\">     TLBs.  The physical pages remain in memory until all locked mappings for the pages are removed.</span><br><span class=\"line\"></span><br><span class=\"line\">     Multiple processes may have the same physical pages locked via their own virtual address mappings.  Similarly, a single</span><br><span class=\"line\">     process may have pages multiply-locked via different virtual mappings of the same pages or via nested mlock calls on the</span><br><span class=\"line\">     same address range.  Unlocking is performed explicitly by munlock or implicitly by a call to munmap, which deallocates</span><br><span class=\"line\">     the unmapped address range.  Locked mappings are not inherited by the child process after a fork(2).</span><br><span class=\"line\"></span><br><span class=\"line\">     Because physical memory is a potentially scarce resource, processes are limited in how much memory they can lock down.  A</span><br><span class=\"line\">     single process can mlock the minimum of a system-wide ``wired pages&apos;&apos; limit and the per-process RLIMIT_MEMLOCK resource</span><br><span class=\"line\">     limit.</span><br><span class=\"line\"></span><br><span class=\"line\">RETURN VALUES</span><br><span class=\"line\">     A return value of 0 indicates that the call succeeded and all pages in the range have either been locked or unlocked, as</span><br><span class=\"line\">     requested.  A return value of -1 indicates an error occurred and the locked status of all pages in the range remains</span><br><span class=\"line\">     unchanged.  In this case, the global location errno is set to indicate the error.</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/2017/11/03/RocketMQ-Message-send-and-persistence/disc-fall.gif\" alt=\"你想输入的替代文字\"></p>\n<h3 id=\"逻辑Offset队列-ConsumerQueue\"><a href=\"#逻辑Offset队列-ConsumerQueue\" class=\"headerlink\" title=\"逻辑Offset队列: ConsumerQueue\"></a>逻辑Offset队列: ConsumerQueue</h3><h3 id=\"物理Offset队列-CommitLog\"><a href=\"#物理Offset队列-CommitLog\" class=\"headerlink\" title=\"物理Offset队列: CommitLog\"></a>物理Offset队列: CommitLog</h3><h3 id=\"MappedByteBuffer\"><a href=\"#MappedByteBuffer\" class=\"headerlink\" title=\"MappedByteBuffer\"></a>MappedByteBuffer</h3><p>操纵MappedByteBuffer的线程或者进程必须对某一个文件的映射Buffer有独占权，<br>在设计上，消息的顺序是由CommitLog决定，所以CommitLog在Append新的消息时，必须上锁进行互斥。</p>\n<p>*传统的synchronized叫做monitor lock，当一个线程进入了synchronized的代码块时，我们说，该线程own（拥有）了monitor lock。这种锁是一种重量级锁，用mutual exclusive（互斥）的特性来实现了同步的需求。<br>*自旋锁，JDK1.6引进，我们知道，线程状态与状态的切换，是需要内核参与的，简单点来讲，这个过程是需要点时间的。线程B已经own了一个锁，这是线程A去尝试获取锁，本来线程A应该要挂起，JVM不让它挂起，让A在那里做自旋操作，JVM要赌当前持有锁的B会很快释放锁。如果线程B确实很快释放了锁，那对于A来讲是一个非常好事情，因为A可以不用切换状态，立刻持有锁。那什么时候会用到呢？<a href=\"http://blog.csdn.net/u013080921/article/details/42676231\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/u013080921/article/details/42676231</a></p>\n<h4 id=\"Spin-Lock-自旋锁\"><a href=\"#Spin-Lock-自旋锁\" class=\"headerlink\" title=\"Spin Lock(自旋锁)\"></a>Spin Lock(自旋锁)</h4><h4 id=\"ReentrantLock-重入锁\"><a href=\"#ReentrantLock-重入锁\" class=\"headerlink\" title=\"ReentrantLock(重入锁)\"></a>ReentrantLock(重入锁)</h4><h3 id=\"异步刷盘机制\"><a href=\"#异步刷盘机制\" class=\"headerlink\" title=\"异步刷盘机制\"></a>异步刷盘机制</h3><p><a href=\"http://blog.csdn.net/vonzhoufz/article/details/47248777\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/vonzhoufz/article/details/47248777</a></p>\n<h4 id=\"磁盘顺序读写与随机读写的差异\"><a href=\"#磁盘顺序读写与随机读写的差异\" class=\"headerlink\" title=\"磁盘顺序读写与随机读写的差异\"></a>磁盘顺序读写与随机读写的差异</h4><p><a href=\"https://kafka.apache.org/documentation/#design_filesystem\" target=\"_blank\" rel=\"noopener\">https://kafka.apache.org/documentation/#design_filesystem</a></p>\n<p><a href=\"http://blog.csdn.net/evankaka/article/details/48464013\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/evankaka/article/details/48464013</a></p>\n<p>需要好好研究：<a href=\"http://blog.csdn.net/javahongxi/article/details/72956619?locationNum=2&amp;fps=1\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/javahongxi/article/details/72956619?locationNum=2&amp;fps=1</a><br>虽然讲的是kafka，研究价值极高：<a href=\"http://blog.csdn.net/tototuzuoquan/article/details/73437890\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/tototuzuoquan/article/details/73437890</a><br>pagecache是一个现在操作系统带有的天然的缓存！！！！！</p>\n<p><a href=\"http://blog.csdn.net/mg0832058/article/details/5890688\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/mg0832058/article/details/5890688</a><br>内存映射文件原理探索</p>\n<p>如何查看内存的 PAGESIZE</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">getconf PAGESIZE</span><br></pre></td></tr></table></figure>\n\n<p>终于理解了！！！！ 首先，Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。同时如果有其他进程申请内存，回收PageCache的代价又很小，所以现代的OS都支持PageCache。 </p>\n<p>所以说 commit(atLeastSize)的参数就是现代操作系统pagecache的大小</p>\n<p><a href=\"http://www.jianshu.com/p/6494e33c9b1f\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/6494e33c9b1f</a><br>Consume Queue 顺序写，顺序读 几乎都是完全命中Page Cache，和内存速度几乎一样<br>Commit Log 顺序写，顺序跳跃读，相比完全的随机读，性能也还好</p>\n<p><a href=\"http://blog.csdn.net/mg0832058/article/details/5890688\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/mg0832058/article/details/5890688</a><br>内存映射文件原理探索</p>\n<p><a href=\"http://www.jianshu.com/p/6494e33c9b1f\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/6494e33c9b1f</a><br>1).充分利用page cache降低读数据的时间开销. 读取时尽可能让其命中page cache, 减少IO读操作, 所以内存越大越好. 如果系统中堆积的消息过多, 读数据要访问磁盘会不会由于随机读导致系统性能急剧下降, 答案是否定的.<br>访问page cache 时, 即使只访问1k的消息, 系统也会提前预读出更多数据, 在下次读时, 就可能命中内存.<br>随机访问Commit Log磁盘数据, 系统IO调度算法设置为NOOP方式, 会在一定程度上将完全的随机读变成顺序跳跃方式, 而顺序跳跃方式读较完全的随机读性能会高5倍以上.<br>另外4k的消息在完全随机访问情况下, 仍然可以达到8K次每秒以上的读性能.<br>由于Consume Queue存储数据量极少, 而且是顺序读, 在PAGECACHE预读作用下, Consume Queue的读性能几乎与内存一致, 即使堆积情况下. 所以可认为Consume Queue完全不会阻碍读性能.<br>2).Commit Log中存储了所有的元信息, 包含消息体, 类似于Mysql、Oracle的redolog, 所以只要有Commit Log在, Consume Queue即使数据丢失, 仍然可以恢复出来.</p>\n<p><a href=\"https://segmentfault.com/a/1190000003985468\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000003985468</a><br>kafka底层原理</p>\n<p>linux最多可以容忍多少大小的脏页。脏页－linux内核中的概念，因为硬盘的读写速度远赶不上内存的速度，系统就把读写比较频繁的数据事先放到内存中，以提高读写速度，这就叫高速缓存，linux是以页作为高速缓存的单位，当进程修改了高速缓存里的数据时，该页就被内核标记为脏页，内核将会在合适的时间把脏页的数据写到磁盘中去，以保持高速缓存中的数据和磁盘中的数据是一致的。</p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><p>page cache是内存的东西（物理内存还是虚拟内存），我们写文件时先写进内存page cache，然后从page cache刷到disc上</p>\n<p>现在MQ异步刷盘是有个间隔的，如果说pagecache中的数据一直没有被刷进磁盘，那所谓的脏页会越来越大，jvm crash后会丢失数据么。那什么时候是不会丢消息的</p>\n<p>对于读是好理解的，但对于写，如果文件是顺序写的，commit log和consume queue都是顺序写的，那pagecache的存在如何让速度提升了？是从java heap到pagecache的速度提升了，还是说从pagecache到disc的速度提升了？</p>\n<p>producer发送消息，如果是立马被消费这种场景<br>1.对于consume queue，肯定是顺序读写，所以写进pagecache（物理内存）后，直接就从pagecache（物理内存）被读出来了<br>2.对于commit log，虽然不是顺序读，但也是基本有序读，最后大部分也能命中pagecache，不需要走系统IO</p>\n<p>如果是消费历史消息，很大程度上，会发现在pagecache（虚拟内存）中没有，由系统产生缺页中断，从磁盘中重新读到pagecache中（可能还会根据顺序预读很多），然后再将数据从pagecache复制到socket中传输到consumer。</p>\n<p>MappedByteBuffer 能不能映射大于操作系统内存的文件？<br>MappedByteBuffer所占用的内存是堆外内存，那什么时候才能被回收</p>\n<p><a href=\"http://www.iocoder.cn/RocketMQ/message-store/\" target=\"_blank\" rel=\"noopener\">http://www.iocoder.cn/RocketMQ/message-store/</a><br>CommitRealTimeService    异步刷盘 &amp;&amp; 开启内存字节缓冲区    第一<br>FlushRealTimeService    异步刷盘 &amp;&amp; 关闭内存字节缓冲区    第二<br>GroupCommitService    同步刷盘    第三<br>没看懂</p>\n<p><a href=\"http://blog.csdn.net/iie_libi/article/details/54289580\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/iie_libi/article/details/54289580</a><br>零拷贝技术</p>\n<p>Consumer 消费消息过程，使用了零拷贝技术，因为有小块数据传输的需求，效果会比 sendfile 更好，所以RocketMQ选择了mmap+write方式。<br>① 优点：即使频繁调用，使用小块文件传输，效率也很高<br>② 缺点：不能很好的利用 DMA 方式，会比 sendfile 多消耗CPU，内存安全性控制复杂，需要避免JVM Crash问题。</p>\n<p>文件系统</p>\n<p>建议选择ext4文件系统，删除文件的实时性强。<br>调优：文件系统的io调度算法需要调整为deadline，因为deadline 算法在随机读情况下，可以合并读请求为顺序跳跃方式，从而提高读IO 吞吐量。</p>\n<p>文件读写冲突？</p>\n<p>写文件的时候，如果消费者在读怎么办？<br>依赖于操作系统对文件读写操作的处理，，，永远一个一个进程在写文件，如果其他进程需要访问文件，只能是读，或者是再创建一个副本，写文件。（读写锁+写时复制） 读写锁在哪里</p>\n<p>提高pagecache？</p>\n<p>RocketMQ用的是FileChannel.map()出来的MappedByteBuffer，这种Buffer是堆外内存，MQ怎么对这部分的内存进行回收？</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">clean</span><span class=\"params\">(<span class=\"keyword\">final</span> ByteBuffer buffer)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (buffer == <span class=\"keyword\">null</span> || !buffer.isDirect() || buffer.capacity() == <span class=\"number\">0</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    invoke(invoke(viewed(buffer), <span class=\"string\">\"cleaner\"</span>), <span class=\"string\">\"clean\"</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Deallocator</span></span></span><br><span class=\"line\"><span class=\"class\">        <span class=\"keyword\">implements</span> <span class=\"title\">Runnable</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Unsafe unsafe = Unsafe.getUnsafe();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> address;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">long</span> size;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">int</span> capacity;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"title\">Deallocator</span><span class=\"params\">(<span class=\"keyword\">long</span> address, <span class=\"keyword\">long</span> size, <span class=\"keyword\">int</span> capacity)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">assert</span> (address != <span class=\"number\">0</span>);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.address = address;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.size = size;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.capacity = capacity;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (address == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// Paranoia</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        unsafe.freeMemory(address);</span><br><span class=\"line\">        address = <span class=\"number\">0</span>;</span><br><span class=\"line\">        Bits.unreserveMemory(size, capacity);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>堆外内存的回收需要依赖显式Full GC或者隐式Full GC，一般来说DisableExplicitGC可以开，也可以关，但是如果禁用了显式GC，当系统没有足够的Full GC时，堆外内存无法回收。</p>\n<p>  想要提高pagecache的命中率，即尽量让访问的页在物理内存中，而不是在虚拟内存中，减少IO 读操作，所以从硬件的角度，当然是内存越大越好。<br>而在软件角度，rocketmq有以下策略：<br>尽量顺序读<br> 如果需要随机读的话：<br>访问 PAGECACHE 时，即使只访问 1k 的消息，系统也会提前预读出更多数据，在下次读时，就可能命中内存。<br> 随机访问 Commit Log 磁盘数据，系统 IO 调度算法设置为NOOP 方式，会在一定程度上将完全的随机读变成顺序跳跃方式，而顺序跳跃方式读较完全的随机读性能会高5 倍以上。</p>\n<p> 可能的优化策略</p>\n<p> 1．线程绑定核+线程池（取模）<br> a) 将每个线程绑定核，一个函数就可以<br> b) 优势：避免线程核间调度<br> 2．改用互斥锁为读写锁<br> a) 读读场景的线程可以并行<br> 3．使用xxhash代替crc算法，性能可以提高很多<br> a) 参考链接：<a href=\"https://cyan4973.github.io/xxHash/\" target=\"_blank\" rel=\"noopener\">https://cyan4973.github.io/xxHash/</a><br> 4．使用topic划分多个逻辑队列（链表）<br> a) 避免topic的多次字符串的比较<br> 5．改用STL的deque来替代MESA list<br> a) Deque类似于vector，可以支持随机访问<br> b) 常量时间内在头部和尾部插入，删除元素<br> 6．改用跳表来代替MESA list<br> a) 跳表可以高并发+log（n）的随机访问<br> b) 不能删除元素<br> i. 设为标志位，当内存数据达到一定阈值时，写到磁盘或者持久化到leveldb中（hbase也是这样做的）。</p>\n<p> <em>java.nio.channels.FileChannel</em><br> <code>public abstract void force(boolean metaData) throws java.io.IOException</code><br> Forces any updates to this channel’s file to be written to the storage device that contains it.<br> If this channel’s file resides on a local storage device then when this method returns it is guaranteed that all changes made to the file since this channel was created, or since this method was last invoked, will have been written to that device. This is useful for ensuring that critical information is not lost in the event of a system crash.<br> If the file does not reside on a local device then no such guarantee is made.<br> The metaData parameter can be used to limit the number of I/O operations that this method is required to perform. Passing false for this parameter indicates that only updates to the file’s content need be written to storage; passing true indicates that updates to both the file’s content and metadata must be written, which generally requires at least one more I/O operation. Whether this parameter actually has any effect is dependent upon the underlying operating system and is therefore unspecified.<br> Invoking this method may cause an I/O operation to occur even if the channel was only opened for reading. Some operating systems, for example, maintain a last-access time as part of a file’s metadata, and this time is updated whenever the file is read. Whether or not this is actually done is system-dependent and is therefore unspecified.<br> This method is only guaranteed to force changes that were made to this channel’s file via the methods defined in this class. <strong>It may or may not force changes that were made by modifying the content of a mapped byte buffer obtained by invoking the map method. Invoking the force method of the mapped byte buffer will force changes made to the buffer’s content to be written.</strong></p>\n<p> <em>java.nio.MappedByteBuffer</em><br> <code>public final MappedByteBuffer force()</code><br> Forces any changes made to this buffer’s content to be written to the storage device containing the mapped file.<br> If the file mapped into this buffer resides on a local storage device then when this method returns it is guaranteed that all changes made to the buffer since it was created, or since this method was last invoked, will have been written to that device.<br> If the file does not reside on a local device then no such guarantee is made.<br> If this buffer was not mapped in read/write mode (java.nio.channels.FileChannel.MapMode.READ_WRITE) then invoking this method has no effect.</p>\n<h3 id=\"写得超级好的一篇文章\"><a href=\"#写得超级好的一篇文章\" class=\"headerlink\" title=\"写得超级好的一篇文章\"></a>写得超级好的一篇文章</h3><p> <a href=\"http://blog.csdn.net/a417930422/article/details/52585862\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/a417930422/article/details/52585862</a></p>\n<p>包括下面的问题：</p>\n<p>wangbin00162017-08-08 17:011楼<br>楼主确定 零拷贝-sendfile 对应到java中<br>为FileChannel.transferTo(long position, long count, WritableByteChannel target)//？？</p>\n<p>rocketmq 文档上面写到 RocketMQ选择了第一种方式，mmap+write方式，因为有小块数据传输的需求，效果会比sendfile更好。</p>\n<p>源码里面使用的是netty的FileRegion 用的是FileChannel.transferTo</p>\n<p>FileRegion fileRegion =<br>new ManyMessageTransfer(response.encodeHeader(getMessageResult.getBufferTotalSize()), getMessageResult);<br>channel.writeAndFlush(fileRegion)<br>            回复  2条回复<br>             a417930422<br>            a4179304222017-09-21 10:35<br>            回复wangbin0016：另外，rocketmq主要使用的是mmap，即java的MappedByteBuffer用于快速读写。<br>             a417930422<br>            a4179304222017-09-21 10:32<br>            回复wangbin0016：rocketmq文档中写的是Consumer 消费消息过程使用了mmap+write，即内存映射文件的方式，请参照我写的rocketmq存储相关文章：<a href=\"http://blog.csdn.net/a417930422/article/details/52585180\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/a417930422/article/details/52585180</a>.<br>            你说的netty的FileRegion其实是被rocketmq重新实现的ManyMessageTransfer，而transfer过程其实是将GetMessageResult对象的数据写到netty的channel中，本质是从内核获取数据直接发送至socket，不会复制到用户空间。<br>            GetMessageResult其实是mmap的一个子缓冲区而已。<br>            有兴趣可以看看源码 com.alibaba.rocketmq.store.DefaultMessageStore.getMessage方法</p>\n<p>为何要懂零拷贝原理？因为rocketmq存储核心使用的就是零拷贝原理。</p>\n<ol>\n<li><p>io读写的方式</p>\n<ol>\n<li>中断</li>\n<li>DMA</li>\n</ol>\n</li>\n<li><p>中断方式</p>\n<ol>\n<li>中断方式的流程图如下：</li>\n</ol>\n</li>\n</ol>\n<pre><code>1. 用户进程发起数据读取请求\n2. 系统调度为该进程分配cpu\n3. cpu向io控制器(ide,scsi)发送io请求\n4. 用户进程等待io完成，让出cpu\n5. 系统调度cpu执行其他任务\n6. 数据写入至io控制器的缓冲寄存器\n7. 缓冲寄存器满了向cpu发出中断信号\n8. cpu读取数据至内存</code></pre><ol start=\"2\">\n<li>缺点：中断次数取决于缓冲寄存器的大小<ol start=\"3\">\n<li>DMA ： 直接内存存取</li>\n</ol>\n</li>\n<li>DMA方式的流程图如下：</li>\n</ol>\n<pre><code>1. 用户进程发起数据读取请求\n2. 系统调度为该进程分配cpu\n3. cpu向DMA发送io请求\n4. 用户进程等待io完成，让出cpu\n5. 系统调度cpu执行其他任务\n6. 数据写入至io控制器的缓冲寄存器\n7. DMA不断获取缓冲寄存器中的数据（需要cpu时钟）\n8. 传输至内存（需要cpu时钟）\n9. 所需的全部数据获取完毕后向cpu发出中断信号</code></pre><ol start=\"2\">\n<li>优点：减少cpu中断次数，不用cpu拷贝数据<ol start=\"4\">\n<li>数据拷贝</li>\n</ol>\n</li>\n<li>下面展示了 传统方式读取数据后并通过网络发送 所发生的数据拷贝：</li>\n</ol>\n<pre><code>1. 一个read系统调用后，DMA执行了一次数据拷贝，从磁盘到内核空间\n2. read结束后，发生第二次数据拷贝，由cpu将数据从内核空间拷贝至用户空间\n3. send系统调用，cpu发生第三次数据拷贝，由cpu将数据从用户空间拷贝至内核空间(socket缓冲区)\n4. send系统调用结束后，DMA执行第四次数据拷贝，将数据从内核拷贝至协议引擎\n5. 另外，这四个过程中，每个过程都发生一次上下文切换</code></pre><ol start=\"2\">\n<li><p>内存缓冲数据，主要是为了提高性能，内核可以预读部分数据，当所需数据小于内存缓冲区大小时，将极大的提高性能。</p>\n</li>\n<li><p>零拷贝是为了消除这个过程中冗余的拷贝</p>\n<ol start=\"5\">\n<li>零拷贝-sendfile 对应到java中</li>\n</ol>\n<p>为FileChannel.transferTo(long position, long count, WritableByteChannel target)//<br>将数据从文件通道传输到了给定的可写字节通道</p>\n</li>\n<li><p>避免了第2，3步的数据拷贝，参考下图：</p>\n</li>\n</ol>\n<pre><code>1. DMA从拷贝至内核缓冲区\n2. cpu将数据从内核缓冲区拷贝至内核空间(socket缓冲区)\n3. DMA将数据从内核拷贝至协议引擎\n4. 这三个过程中共发生2次上下文切换，分别为发起读取文件和发送数据</code></pre><ol start=\"2\">\n<li>以上过程发生了三次数据拷贝，其中有一次为cpu完成</li>\n<li>linux内核2.4以后，socket缓冲区做了调整，DMA带收集功能，如下图：</li>\n</ol>\n<pre><code>1. DMA从拷贝至内核缓冲区\n2. 将数据的位置和长度的信息的描述符增加至内核空间(socket缓冲区)\n3. DMA将数据从内核拷贝至协议引擎</code></pre><ol start=\"6\">\n<li><p>零拷贝-mmap 对应到java中</p>\n<p>为MappedByteBuffer//文件内存映射</p>\n<ol>\n<li>数据不会复制到用户空间，只在内核空间，与sendfile类似，但是应用程序可以直接操作该内存。</li>\n</ol>\n</li>\n<li><p>参考资料</p>\n<ol>\n<li><a href=\"http://blog.chinaunix.net/uid-25314474-id-3325879.html\" target=\"_blank\" rel=\"noopener\">http://blog.chinaunix.net/uid-25314474-id-3325879.html</a></li>\n<li><a href=\"http://blog.chinaunix.net/uid-28874972-id-3725082.html\" target=\"_blank\" rel=\"noopener\">http://blog.chinaunix.net/uid-28874972-id-3725082.html</a></li>\n<li><a href=\"https://www.ibm.com/developerworks/cn/java/j-zerocopy/#fig1\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/java/j-zerocopy/#fig1</a></li>\n<li><a href=\"http://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/\" target=\"_blank\" rel=\"noopener\">http://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/</a></li>\n<li><a href=\"https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/</a></li>\n</ol>\n</li>\n</ol>\n"},{"title":"RocketMQ——Netty实现的远程同步与异步调用（二）","date":"2017-08-21T04:36:42.000Z","_content":"\n### Netty IO框架\nnetty是一个异步IO框架，异步API最大的特点就是基于事件，netty当然也不例外。\n\n### Remote同步调用\n![你想输入的替代文字](RocketMQ-Netty-imp-sync-and-async-invoke/invokeSync.png)\n\n### Remote异步调用\n异步调用不会使Caller线程等待，理论上可以在短时间内不限次数得调用，这将对系统造成非常大压力，所以在异步调用设计中引入了限流机制\n![你想输入的替代文字](RocketMQ-Netty-imp-sync-and-async-invoke/invokeAsync.png)\n\n###","source":"_posts/RocketMQ-Netty-imp-sync-and-async-invoke.md","raw":"---\ntitle: RocketMQ——Netty实现的远程同步与异步调用（二）\ndate: 2017-08-21 12:36:42\ntags: RocketMQ\n---\n\n### Netty IO框架\nnetty是一个异步IO框架，异步API最大的特点就是基于事件，netty当然也不例外。\n\n### Remote同步调用\n![你想输入的替代文字](RocketMQ-Netty-imp-sync-and-async-invoke/invokeSync.png)\n\n### Remote异步调用\n异步调用不会使Caller线程等待，理论上可以在短时间内不限次数得调用，这将对系统造成非常大压力，所以在异步调用设计中引入了限流机制\n![你想输入的替代文字](RocketMQ-Netty-imp-sync-and-async-invoke/invokeAsync.png)\n\n###","slug":"RocketMQ-Netty-imp-sync-and-async-invoke","published":1,"updated":"2019-09-28T08:51:00.921Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84p004zv1npxquqri17","content":"<h3 id=\"Netty-IO框架\"><a href=\"#Netty-IO框架\" class=\"headerlink\" title=\"Netty IO框架\"></a>Netty IO框架</h3><p>netty是一个异步IO框架，异步API最大的特点就是基于事件，netty当然也不例外。</p>\n<h3 id=\"Remote同步调用\"><a href=\"#Remote同步调用\" class=\"headerlink\" title=\"Remote同步调用\"></a>Remote同步调用</h3><p><img src=\"/2017/08/21/RocketMQ-Netty-imp-sync-and-async-invoke/invokeSync.png\" alt=\"你想输入的替代文字\"></p>\n<h3 id=\"Remote异步调用\"><a href=\"#Remote异步调用\" class=\"headerlink\" title=\"Remote异步调用\"></a>Remote异步调用</h3><p>异步调用不会使Caller线程等待，理论上可以在短时间内不限次数得调用，这将对系统造成非常大压力，所以在异步调用设计中引入了限流机制<br><img src=\"/2017/08/21/RocketMQ-Netty-imp-sync-and-async-invoke/invokeAsync.png\" alt=\"你想输入的替代文字\"></p>\n<p>###</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Netty-IO框架\"><a href=\"#Netty-IO框架\" class=\"headerlink\" title=\"Netty IO框架\"></a>Netty IO框架</h3><p>netty是一个异步IO框架，异步API最大的特点就是基于事件，netty当然也不例外。</p>\n<h3 id=\"Remote同步调用\"><a href=\"#Remote同步调用\" class=\"headerlink\" title=\"Remote同步调用\"></a>Remote同步调用</h3><p><img src=\"/2017/08/21/RocketMQ-Netty-imp-sync-and-async-invoke/invokeSync.png\" alt=\"你想输入的替代文字\"></p>\n<h3 id=\"Remote异步调用\"><a href=\"#Remote异步调用\" class=\"headerlink\" title=\"Remote异步调用\"></a>Remote异步调用</h3><p>异步调用不会使Caller线程等待，理论上可以在短时间内不限次数得调用，这将对系统造成非常大压力，所以在异步调用设计中引入了限流机制<br><img src=\"/2017/08/21/RocketMQ-Netty-imp-sync-and-async-invoke/invokeAsync.png\" alt=\"你想输入的替代文字\"></p>\n<p>###</p>\n"},{"title":"RocketMQ-Pagecache","date":"2018-08-11T07:46:50.000Z","_content":"\n### RocketMQ对\n\n\n```\nman free\nDESCRIPTION\n    cache  Memory used by the page cache and slabs (Cached and Slab in /proc/meminfo)\n```\n\n### Linux文件读写机制及优化方式\nhttps://blog.csdn.net/littlewhite1989/article/details/52583879\n\npagecache是RocketMQ高性能实现上使用的一个利器。虽然源码中没有对pagecache的做过多解释，但是作为RocketMQ的研究者，必须清楚得认识到pagecache对于性能的影响有多么巨大。本文借用一些工具帮助我们更好理解RocketMQ是如何在设计上就利用上pagecache。\n\n首先推荐一款工具pcstat(https://github.com/tobert/pcstat)，它可以直观得显示出指定文件是否被cache，甚至可以知道cache的比例是多少。\n```\n[root@mq003 bin]# ./pcstat /opt/data/rocketmq/store/commitlog/*\n|---------------------------------------------------------+----------------+------------+-----------+---------|\n| Name                                                    | Size           | Pages      | Cached    | Percent |\n|---------------------------------------------------------+----------------+------------+-----------+---------|\n| /opt/data/rocketmq/store/commitlog/00000000303868936192 | 1073741824     | 262144     | 40        | 000.015 |\n| /opt/data/rocketmq/store/commitlog/00000000304942678016 | 1073741824     | 262144     | 18        | 000.007 |\n| /opt/data/rocketmq/store/commitlog/00000000306016419840 | 1073741824     | 262144     | 1         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000307090161664 | 1073741824     | 262144     | 1         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000308163903488 | 1073741824     | 262144     | 1         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000309237645312 | 1073741824     | 262144     | 4         | 000.002 |\n| /opt/data/rocketmq/store/commitlog/00000000310311387136 | 1073741824     | 262144     | 0         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000311385128960 | 1073741824     | 262144     | 0         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000312458870784 | 1073741824     | 262144     | 0         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000313532612608 | 1073741824     | 262144     | 16        | 000.006 |\n| /opt/data/rocketmq/store/commitlog/00000000314606354432 | 1073741824     | 262144     | 16        | 000.006 |\n| /opt/data/rocketmq/store/commitlog/00000000315680096256 | 1073741824     | 262144     | 2         | 000.001 |\n| /opt/data/rocketmq/store/commitlog/00000000316753838080 | 1073741824     | 262144     | 0         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000317827579904 | 1073741824     | 262144     | 2         | 000.001 |\n| /opt/data/rocketmq/store/commitlog/00000000318901321728 | 1073741824     | 262144     | 11        | 000.004 |\n| /opt/data/rocketmq/store/commitlog/00000000319975063552 | 1073741824     | 262144     | 5         | 000.002 |\n| /opt/data/rocketmq/store/commitlog/00000000321048805376 | 1073741824     | 262144     | 40        | 000.015 |\n| /opt/data/rocketmq/store/commitlog/00000000322122547200 | 1073741824     | 262144     | 14        | 000.005 |\n| /opt/data/rocketmq/store/commitlog/00000000323196289024 | 1073741824     | 262144     | 17        | 000.006 |\n| /opt/data/rocketmq/store/commitlog/00000000324270030848 | 1073741824     | 262144     | 18        | 000.007 |\n| /opt/data/rocketmq/store/commitlog/00000000325343772672 | 1073741824     | 262144     | 17        | 000.006 |\n| /opt/data/rocketmq/store/commitlog/00000000326417514496 | 1073741824     | 262144     | 13        | 000.005 |\n| /opt/data/rocketmq/store/commitlog/00000000327491256320 | 1073741824     | 262144     | 5         | 000.002 |\n| /opt/data/rocketmq/store/commitlog/00000000328564998144 | 1073741824     | 262144     | 13        | 000.005 |\n| /opt/data/rocketmq/store/commitlog/00000000329638739968 | 1073741824     | 262144     | 16        | 000.006 |\n| /opt/data/rocketmq/store/commitlog/00000000330712481792 | 1073741824     | 262144     | 0         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000331786223616 | 1073741824     | 262144     | 0         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000332859965440 | 1073741824     | 262144     | 2         | 000.001 |\n| /opt/data/rocketmq/store/commitlog/00000000333933707264 | 1073741824     | 262144     | 36        | 000.014 |\n| /opt/data/rocketmq/store/commitlog/00000000335007449088 | 1073741824     | 262144     | 29313     | 011.182 |\n| /opt/data/rocketmq/store/commitlog/00000000336081190912 | 1073741824     | 262144     | 0         | 000.000 |\n|---------------------------------------------------------+----------------+------------+-----------+---------|\n```\n可以看到`/opt/data/rocketmq/store/commitlog/00000000335007449088`有11.182%都被cache了\n\n\n\n```\npublic void warmMappedFile(FlushDiskType type, int pages) {\n    long beginTime = System.currentTimeMillis();\n    ByteBuffer byteBuffer = this.mappedByteBuffer.slice();\n    int flush = 0;\n    long time = System.currentTimeMillis();\n    for (int i = 0, j = 0; i < this.fileSize; i += MappedFile.OS_PAGE_SIZE, j++) {\n        byteBuffer.put(i, (byte) 0);\n        // force flush when flush disk type is sync\n        if (type == FlushDiskType.SYNC_FLUSH) {\n            if ((i / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE) >= pages) {\n                flush = i;\n                mappedByteBuffer.force();\n            }\n        }\n\n        // prevent gc\n        if (j % 1000 == 0) {\n            log.info(\"j={}, costTime={}\", j, System.currentTimeMillis() - time);\n            time = System.currentTimeMillis();\n            try {\n                Thread.sleep(0);\n            } catch (InterruptedException e) {\n                log.error(\"Interrupted\", e);\n            }\n        }\n    }\n\n    // force flush when prepare load finished\n    if (type == FlushDiskType.SYNC_FLUSH) {\n        log.info(\"mapped file warm-up done, force to disk, mappedFile={}, costTime={}\",\n            this.getFileName(), System.currentTimeMillis() - beginTime);\n        mappedByteBuffer.force();\n    }\n    log.info(\"mapped file warm-up done. mappedFile={}, costTime={}\", this.getFileName(),\n        System.currentTimeMillis() - beginTime);\n\n    this.mlock();\n}\n\npublic void mlock() {\n        final long beginTime = System.currentTimeMillis();\n        final long address = ((DirectBuffer) (this.mappedByteBuffer)).address();\n        Pointer pointer = new Pointer(address);\n        {\n            int ret = LibC.INSTANCE.mlock(pointer, new NativeLong(this.fileSize));\n            log.info(\"mlock {} {} {} ret = {} time consuming = {}\", address, this.fileName, this.fileSize, ret, System.currentTimeMillis() - beginTime);\n        }\n\n        {\n            int ret = LibC.INSTANCE.madvise(pointer, new NativeLong(this.fileSize), LibC.MADV_WILLNEED);\n            log.info(\"madvise {} {} {} ret = {} time consuming = {}\", address, this.fileName, this.fileSize, ret, System.currentTimeMillis() - beginTime);\n        }\n    }\n```\n这个写入一个随机值，告诉内核，强制让内核发生缺页中断，去做虚拟内存和物理内存的mapping。注意，这个是给预创建的Commit Log。即使做了mapping，这部分的内存物理内存还是会变冷（LRU），还是有可能被内核回收走，干别的事情。这时要调用 mlock，告诉内核，这部分虚拟内存mapping的物理内存，千万别swap out 到swap区域，要持续放入物理内存中。madvise 传入will_need是高速操作系统，这块内存我等下就要使用，即使我暂时不用，也不要让它变冷，而被回收走。\n\n\n\n在 2018年4月8日 上午10:07，Zhanhui Li <lizhanhui@apache.org>写道：\n\n> writeBuffer 是预分配的anonymous pages, 并且mlock到物理内存了. 往里面写消息,\n不会因为内存不足回收带来延迟.\n> mmap的文件page cache, 在物理内存分配过快, background reclaim速度跟不上的时候,\n线程会被block住,进行direct reclaim, 带来延迟.\n>\n> 可参考:  https://events.static.linuxfound.org/sites/events/\n> files/lcjp13_moriya.pdf","source":"_posts/RocketMQ-Pagecache.md","raw":"---\ntitle: RocketMQ-Pagecache\ndate: 2018-08-11 15:46:50\ntags:\n---\n\n### RocketMQ对\n\n\n```\nman free\nDESCRIPTION\n    cache  Memory used by the page cache and slabs (Cached and Slab in /proc/meminfo)\n```\n\n### Linux文件读写机制及优化方式\nhttps://blog.csdn.net/littlewhite1989/article/details/52583879\n\npagecache是RocketMQ高性能实现上使用的一个利器。虽然源码中没有对pagecache的做过多解释，但是作为RocketMQ的研究者，必须清楚得认识到pagecache对于性能的影响有多么巨大。本文借用一些工具帮助我们更好理解RocketMQ是如何在设计上就利用上pagecache。\n\n首先推荐一款工具pcstat(https://github.com/tobert/pcstat)，它可以直观得显示出指定文件是否被cache，甚至可以知道cache的比例是多少。\n```\n[root@mq003 bin]# ./pcstat /opt/data/rocketmq/store/commitlog/*\n|---------------------------------------------------------+----------------+------------+-----------+---------|\n| Name                                                    | Size           | Pages      | Cached    | Percent |\n|---------------------------------------------------------+----------------+------------+-----------+---------|\n| /opt/data/rocketmq/store/commitlog/00000000303868936192 | 1073741824     | 262144     | 40        | 000.015 |\n| /opt/data/rocketmq/store/commitlog/00000000304942678016 | 1073741824     | 262144     | 18        | 000.007 |\n| /opt/data/rocketmq/store/commitlog/00000000306016419840 | 1073741824     | 262144     | 1         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000307090161664 | 1073741824     | 262144     | 1         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000308163903488 | 1073741824     | 262144     | 1         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000309237645312 | 1073741824     | 262144     | 4         | 000.002 |\n| /opt/data/rocketmq/store/commitlog/00000000310311387136 | 1073741824     | 262144     | 0         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000311385128960 | 1073741824     | 262144     | 0         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000312458870784 | 1073741824     | 262144     | 0         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000313532612608 | 1073741824     | 262144     | 16        | 000.006 |\n| /opt/data/rocketmq/store/commitlog/00000000314606354432 | 1073741824     | 262144     | 16        | 000.006 |\n| /opt/data/rocketmq/store/commitlog/00000000315680096256 | 1073741824     | 262144     | 2         | 000.001 |\n| /opt/data/rocketmq/store/commitlog/00000000316753838080 | 1073741824     | 262144     | 0         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000317827579904 | 1073741824     | 262144     | 2         | 000.001 |\n| /opt/data/rocketmq/store/commitlog/00000000318901321728 | 1073741824     | 262144     | 11        | 000.004 |\n| /opt/data/rocketmq/store/commitlog/00000000319975063552 | 1073741824     | 262144     | 5         | 000.002 |\n| /opt/data/rocketmq/store/commitlog/00000000321048805376 | 1073741824     | 262144     | 40        | 000.015 |\n| /opt/data/rocketmq/store/commitlog/00000000322122547200 | 1073741824     | 262144     | 14        | 000.005 |\n| /opt/data/rocketmq/store/commitlog/00000000323196289024 | 1073741824     | 262144     | 17        | 000.006 |\n| /opt/data/rocketmq/store/commitlog/00000000324270030848 | 1073741824     | 262144     | 18        | 000.007 |\n| /opt/data/rocketmq/store/commitlog/00000000325343772672 | 1073741824     | 262144     | 17        | 000.006 |\n| /opt/data/rocketmq/store/commitlog/00000000326417514496 | 1073741824     | 262144     | 13        | 000.005 |\n| /opt/data/rocketmq/store/commitlog/00000000327491256320 | 1073741824     | 262144     | 5         | 000.002 |\n| /opt/data/rocketmq/store/commitlog/00000000328564998144 | 1073741824     | 262144     | 13        | 000.005 |\n| /opt/data/rocketmq/store/commitlog/00000000329638739968 | 1073741824     | 262144     | 16        | 000.006 |\n| /opt/data/rocketmq/store/commitlog/00000000330712481792 | 1073741824     | 262144     | 0         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000331786223616 | 1073741824     | 262144     | 0         | 000.000 |\n| /opt/data/rocketmq/store/commitlog/00000000332859965440 | 1073741824     | 262144     | 2         | 000.001 |\n| /opt/data/rocketmq/store/commitlog/00000000333933707264 | 1073741824     | 262144     | 36        | 000.014 |\n| /opt/data/rocketmq/store/commitlog/00000000335007449088 | 1073741824     | 262144     | 29313     | 011.182 |\n| /opt/data/rocketmq/store/commitlog/00000000336081190912 | 1073741824     | 262144     | 0         | 000.000 |\n|---------------------------------------------------------+----------------+------------+-----------+---------|\n```\n可以看到`/opt/data/rocketmq/store/commitlog/00000000335007449088`有11.182%都被cache了\n\n\n\n```\npublic void warmMappedFile(FlushDiskType type, int pages) {\n    long beginTime = System.currentTimeMillis();\n    ByteBuffer byteBuffer = this.mappedByteBuffer.slice();\n    int flush = 0;\n    long time = System.currentTimeMillis();\n    for (int i = 0, j = 0; i < this.fileSize; i += MappedFile.OS_PAGE_SIZE, j++) {\n        byteBuffer.put(i, (byte) 0);\n        // force flush when flush disk type is sync\n        if (type == FlushDiskType.SYNC_FLUSH) {\n            if ((i / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE) >= pages) {\n                flush = i;\n                mappedByteBuffer.force();\n            }\n        }\n\n        // prevent gc\n        if (j % 1000 == 0) {\n            log.info(\"j={}, costTime={}\", j, System.currentTimeMillis() - time);\n            time = System.currentTimeMillis();\n            try {\n                Thread.sleep(0);\n            } catch (InterruptedException e) {\n                log.error(\"Interrupted\", e);\n            }\n        }\n    }\n\n    // force flush when prepare load finished\n    if (type == FlushDiskType.SYNC_FLUSH) {\n        log.info(\"mapped file warm-up done, force to disk, mappedFile={}, costTime={}\",\n            this.getFileName(), System.currentTimeMillis() - beginTime);\n        mappedByteBuffer.force();\n    }\n    log.info(\"mapped file warm-up done. mappedFile={}, costTime={}\", this.getFileName(),\n        System.currentTimeMillis() - beginTime);\n\n    this.mlock();\n}\n\npublic void mlock() {\n        final long beginTime = System.currentTimeMillis();\n        final long address = ((DirectBuffer) (this.mappedByteBuffer)).address();\n        Pointer pointer = new Pointer(address);\n        {\n            int ret = LibC.INSTANCE.mlock(pointer, new NativeLong(this.fileSize));\n            log.info(\"mlock {} {} {} ret = {} time consuming = {}\", address, this.fileName, this.fileSize, ret, System.currentTimeMillis() - beginTime);\n        }\n\n        {\n            int ret = LibC.INSTANCE.madvise(pointer, new NativeLong(this.fileSize), LibC.MADV_WILLNEED);\n            log.info(\"madvise {} {} {} ret = {} time consuming = {}\", address, this.fileName, this.fileSize, ret, System.currentTimeMillis() - beginTime);\n        }\n    }\n```\n这个写入一个随机值，告诉内核，强制让内核发生缺页中断，去做虚拟内存和物理内存的mapping。注意，这个是给预创建的Commit Log。即使做了mapping，这部分的内存物理内存还是会变冷（LRU），还是有可能被内核回收走，干别的事情。这时要调用 mlock，告诉内核，这部分虚拟内存mapping的物理内存，千万别swap out 到swap区域，要持续放入物理内存中。madvise 传入will_need是高速操作系统，这块内存我等下就要使用，即使我暂时不用，也不要让它变冷，而被回收走。\n\n\n\n在 2018年4月8日 上午10:07，Zhanhui Li <lizhanhui@apache.org>写道：\n\n> writeBuffer 是预分配的anonymous pages, 并且mlock到物理内存了. 往里面写消息,\n不会因为内存不足回收带来延迟.\n> mmap的文件page cache, 在物理内存分配过快, background reclaim速度跟不上的时候,\n线程会被block住,进行direct reclaim, 带来延迟.\n>\n> 可参考:  https://events.static.linuxfound.org/sites/events/\n> files/lcjp13_moriya.pdf","slug":"RocketMQ-Pagecache","published":1,"updated":"2019-09-28T08:51:00.934Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84q0050v1nppflkc1u5","content":"<h3 id=\"RocketMQ对\"><a href=\"#RocketMQ对\" class=\"headerlink\" title=\"RocketMQ对\"></a>RocketMQ对</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">man free</span><br><span class=\"line\">DESCRIPTION</span><br><span class=\"line\">    cache  Memory used by the page cache and slabs (Cached and Slab in /proc/meminfo)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Linux文件读写机制及优化方式\"><a href=\"#Linux文件读写机制及优化方式\" class=\"headerlink\" title=\"Linux文件读写机制及优化方式\"></a>Linux文件读写机制及优化方式</h3><p><a href=\"https://blog.csdn.net/littlewhite1989/article/details/52583879\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/littlewhite1989/article/details/52583879</a></p>\n<p>pagecache是RocketMQ高性能实现上使用的一个利器。虽然源码中没有对pagecache的做过多解释，但是作为RocketMQ的研究者，必须清楚得认识到pagecache对于性能的影响有多么巨大。本文借用一些工具帮助我们更好理解RocketMQ是如何在设计上就利用上pagecache。</p>\n<p>首先推荐一款工具pcstat(<a href=\"https://github.com/tobert/pcstat)，它可以直观得显示出指定文件是否被cache，甚至可以知道cache的比例是多少。\" target=\"_blank\" rel=\"noopener\">https://github.com/tobert/pcstat)，它可以直观得显示出指定文件是否被cache，甚至可以知道cache的比例是多少。</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@mq003 bin]# ./pcstat /opt/data/rocketmq/store/commitlog/*</span><br><span class=\"line\">|---------------------------------------------------------+----------------+------------+-----------+---------|</span><br><span class=\"line\">| Name                                                    | Size           | Pages      | Cached    | Percent |</span><br><span class=\"line\">|---------------------------------------------------------+----------------+------------+-----------+---------|</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000303868936192 | 1073741824     | 262144     | 40        | 000.015 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000304942678016 | 1073741824     | 262144     | 18        | 000.007 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000306016419840 | 1073741824     | 262144     | 1         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000307090161664 | 1073741824     | 262144     | 1         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000308163903488 | 1073741824     | 262144     | 1         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000309237645312 | 1073741824     | 262144     | 4         | 000.002 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000310311387136 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000311385128960 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000312458870784 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000313532612608 | 1073741824     | 262144     | 16        | 000.006 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000314606354432 | 1073741824     | 262144     | 16        | 000.006 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000315680096256 | 1073741824     | 262144     | 2         | 000.001 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000316753838080 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000317827579904 | 1073741824     | 262144     | 2         | 000.001 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000318901321728 | 1073741824     | 262144     | 11        | 000.004 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000319975063552 | 1073741824     | 262144     | 5         | 000.002 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000321048805376 | 1073741824     | 262144     | 40        | 000.015 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000322122547200 | 1073741824     | 262144     | 14        | 000.005 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000323196289024 | 1073741824     | 262144     | 17        | 000.006 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000324270030848 | 1073741824     | 262144     | 18        | 000.007 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000325343772672 | 1073741824     | 262144     | 17        | 000.006 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000326417514496 | 1073741824     | 262144     | 13        | 000.005 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000327491256320 | 1073741824     | 262144     | 5         | 000.002 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000328564998144 | 1073741824     | 262144     | 13        | 000.005 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000329638739968 | 1073741824     | 262144     | 16        | 000.006 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000330712481792 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000331786223616 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000332859965440 | 1073741824     | 262144     | 2         | 000.001 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000333933707264 | 1073741824     | 262144     | 36        | 000.014 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000335007449088 | 1073741824     | 262144     | 29313     | 011.182 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000336081190912 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">|---------------------------------------------------------+----------------+------------+-----------+---------|</span><br></pre></td></tr></table></figure>\n\n<p>可以看到<code>/opt/data/rocketmq/store/commitlog/00000000335007449088</code>有11.182%都被cache了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void warmMappedFile(FlushDiskType type, int pages) &#123;</span><br><span class=\"line\">    long beginTime = System.currentTimeMillis();</span><br><span class=\"line\">    ByteBuffer byteBuffer = this.mappedByteBuffer.slice();</span><br><span class=\"line\">    int flush = 0;</span><br><span class=\"line\">    long time = System.currentTimeMillis();</span><br><span class=\"line\">    for (int i = 0, j = 0; i &lt; this.fileSize; i += MappedFile.OS_PAGE_SIZE, j++) &#123;</span><br><span class=\"line\">        byteBuffer.put(i, (byte) 0);</span><br><span class=\"line\">        // force flush when flush disk type is sync</span><br><span class=\"line\">        if (type == FlushDiskType.SYNC_FLUSH) &#123;</span><br><span class=\"line\">            if ((i / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE) &gt;= pages) &#123;</span><br><span class=\"line\">                flush = i;</span><br><span class=\"line\">                mappedByteBuffer.force();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        // prevent gc</span><br><span class=\"line\">        if (j % 1000 == 0) &#123;</span><br><span class=\"line\">            log.info(&quot;j=&#123;&#125;, costTime=&#123;&#125;&quot;, j, System.currentTimeMillis() - time);</span><br><span class=\"line\">            time = System.currentTimeMillis();</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                Thread.sleep(0);</span><br><span class=\"line\">            &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">                log.error(&quot;Interrupted&quot;, e);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // force flush when prepare load finished</span><br><span class=\"line\">    if (type == FlushDiskType.SYNC_FLUSH) &#123;</span><br><span class=\"line\">        log.info(&quot;mapped file warm-up done, force to disk, mappedFile=&#123;&#125;, costTime=&#123;&#125;&quot;,</span><br><span class=\"line\">            this.getFileName(), System.currentTimeMillis() - beginTime);</span><br><span class=\"line\">        mappedByteBuffer.force();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    log.info(&quot;mapped file warm-up done. mappedFile=&#123;&#125;, costTime=&#123;&#125;&quot;, this.getFileName(),</span><br><span class=\"line\">        System.currentTimeMillis() - beginTime);</span><br><span class=\"line\"></span><br><span class=\"line\">    this.mlock();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">public void mlock() &#123;</span><br><span class=\"line\">        final long beginTime = System.currentTimeMillis();</span><br><span class=\"line\">        final long address = ((DirectBuffer) (this.mappedByteBuffer)).address();</span><br><span class=\"line\">        Pointer pointer = new Pointer(address);</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            int ret = LibC.INSTANCE.mlock(pointer, new NativeLong(this.fileSize));</span><br><span class=\"line\">            log.info(&quot;mlock &#123;&#125; &#123;&#125; &#123;&#125; ret = &#123;&#125; time consuming = &#123;&#125;&quot;, address, this.fileName, this.fileSize, ret, System.currentTimeMillis() - beginTime);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            int ret = LibC.INSTANCE.madvise(pointer, new NativeLong(this.fileSize), LibC.MADV_WILLNEED);</span><br><span class=\"line\">            log.info(&quot;madvise &#123;&#125; &#123;&#125; &#123;&#125; ret = &#123;&#125; time consuming = &#123;&#125;&quot;, address, this.fileName, this.fileSize, ret, System.currentTimeMillis() - beginTime);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>这个写入一个随机值，告诉内核，强制让内核发生缺页中断，去做虚拟内存和物理内存的mapping。注意，这个是给预创建的Commit Log。即使做了mapping，这部分的内存物理内存还是会变冷（LRU），还是有可能被内核回收走，干别的事情。这时要调用 mlock，告诉内核，这部分虚拟内存mapping的物理内存，千万别swap out 到swap区域，要持续放入物理内存中。madvise 传入will_need是高速操作系统，这块内存我等下就要使用，即使我暂时不用，也不要让它变冷，而被回收走。</p>\n<p>在 2018年4月8日 上午10:07，Zhanhui Li <a href=\"mailto:&#108;&#105;&#122;&#x68;&#x61;&#x6e;&#104;&#117;&#x69;&#64;&#97;&#x70;&#97;&#x63;&#104;&#101;&#x2e;&#x6f;&#x72;&#103;\" target=\"_blank\" rel=\"noopener\">&#108;&#105;&#122;&#x68;&#x61;&#x6e;&#104;&#117;&#x69;&#64;&#97;&#x70;&#97;&#x63;&#104;&#101;&#x2e;&#x6f;&#x72;&#103;</a>写道：</p>\n<blockquote>\n<p>writeBuffer 是预分配的anonymous pages, 并且mlock到物理内存了. 往里面写消息,<br>不会因为内存不足回收带来延迟.<br>mmap的文件page cache, 在物理内存分配过快, background reclaim速度跟不上的时候,<br>线程会被block住,进行direct reclaim, 带来延迟.</p>\n<p>可参考:  <a href=\"https://events.static.linuxfound.org/sites/events/\" target=\"_blank\" rel=\"noopener\">https://events.static.linuxfound.org/sites/events/</a><br>files/lcjp13_moriya.pdf</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"RocketMQ对\"><a href=\"#RocketMQ对\" class=\"headerlink\" title=\"RocketMQ对\"></a>RocketMQ对</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">man free</span><br><span class=\"line\">DESCRIPTION</span><br><span class=\"line\">    cache  Memory used by the page cache and slabs (Cached and Slab in /proc/meminfo)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Linux文件读写机制及优化方式\"><a href=\"#Linux文件读写机制及优化方式\" class=\"headerlink\" title=\"Linux文件读写机制及优化方式\"></a>Linux文件读写机制及优化方式</h3><p><a href=\"https://blog.csdn.net/littlewhite1989/article/details/52583879\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/littlewhite1989/article/details/52583879</a></p>\n<p>pagecache是RocketMQ高性能实现上使用的一个利器。虽然源码中没有对pagecache的做过多解释，但是作为RocketMQ的研究者，必须清楚得认识到pagecache对于性能的影响有多么巨大。本文借用一些工具帮助我们更好理解RocketMQ是如何在设计上就利用上pagecache。</p>\n<p>首先推荐一款工具pcstat(<a href=\"https://github.com/tobert/pcstat)，它可以直观得显示出指定文件是否被cache，甚至可以知道cache的比例是多少。\" target=\"_blank\" rel=\"noopener\">https://github.com/tobert/pcstat)，它可以直观得显示出指定文件是否被cache，甚至可以知道cache的比例是多少。</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@mq003 bin]# ./pcstat /opt/data/rocketmq/store/commitlog/*</span><br><span class=\"line\">|---------------------------------------------------------+----------------+------------+-----------+---------|</span><br><span class=\"line\">| Name                                                    | Size           | Pages      | Cached    | Percent |</span><br><span class=\"line\">|---------------------------------------------------------+----------------+------------+-----------+---------|</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000303868936192 | 1073741824     | 262144     | 40        | 000.015 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000304942678016 | 1073741824     | 262144     | 18        | 000.007 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000306016419840 | 1073741824     | 262144     | 1         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000307090161664 | 1073741824     | 262144     | 1         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000308163903488 | 1073741824     | 262144     | 1         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000309237645312 | 1073741824     | 262144     | 4         | 000.002 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000310311387136 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000311385128960 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000312458870784 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000313532612608 | 1073741824     | 262144     | 16        | 000.006 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000314606354432 | 1073741824     | 262144     | 16        | 000.006 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000315680096256 | 1073741824     | 262144     | 2         | 000.001 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000316753838080 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000317827579904 | 1073741824     | 262144     | 2         | 000.001 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000318901321728 | 1073741824     | 262144     | 11        | 000.004 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000319975063552 | 1073741824     | 262144     | 5         | 000.002 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000321048805376 | 1073741824     | 262144     | 40        | 000.015 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000322122547200 | 1073741824     | 262144     | 14        | 000.005 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000323196289024 | 1073741824     | 262144     | 17        | 000.006 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000324270030848 | 1073741824     | 262144     | 18        | 000.007 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000325343772672 | 1073741824     | 262144     | 17        | 000.006 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000326417514496 | 1073741824     | 262144     | 13        | 000.005 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000327491256320 | 1073741824     | 262144     | 5         | 000.002 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000328564998144 | 1073741824     | 262144     | 13        | 000.005 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000329638739968 | 1073741824     | 262144     | 16        | 000.006 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000330712481792 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000331786223616 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000332859965440 | 1073741824     | 262144     | 2         | 000.001 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000333933707264 | 1073741824     | 262144     | 36        | 000.014 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000335007449088 | 1073741824     | 262144     | 29313     | 011.182 |</span><br><span class=\"line\">| /opt/data/rocketmq/store/commitlog/00000000336081190912 | 1073741824     | 262144     | 0         | 000.000 |</span><br><span class=\"line\">|---------------------------------------------------------+----------------+------------+-----------+---------|</span><br></pre></td></tr></table></figure>\n\n<p>可以看到<code>/opt/data/rocketmq/store/commitlog/00000000335007449088</code>有11.182%都被cache了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public void warmMappedFile(FlushDiskType type, int pages) &#123;</span><br><span class=\"line\">    long beginTime = System.currentTimeMillis();</span><br><span class=\"line\">    ByteBuffer byteBuffer = this.mappedByteBuffer.slice();</span><br><span class=\"line\">    int flush = 0;</span><br><span class=\"line\">    long time = System.currentTimeMillis();</span><br><span class=\"line\">    for (int i = 0, j = 0; i &lt; this.fileSize; i += MappedFile.OS_PAGE_SIZE, j++) &#123;</span><br><span class=\"line\">        byteBuffer.put(i, (byte) 0);</span><br><span class=\"line\">        // force flush when flush disk type is sync</span><br><span class=\"line\">        if (type == FlushDiskType.SYNC_FLUSH) &#123;</span><br><span class=\"line\">            if ((i / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE) &gt;= pages) &#123;</span><br><span class=\"line\">                flush = i;</span><br><span class=\"line\">                mappedByteBuffer.force();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        // prevent gc</span><br><span class=\"line\">        if (j % 1000 == 0) &#123;</span><br><span class=\"line\">            log.info(&quot;j=&#123;&#125;, costTime=&#123;&#125;&quot;, j, System.currentTimeMillis() - time);</span><br><span class=\"line\">            time = System.currentTimeMillis();</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                Thread.sleep(0);</span><br><span class=\"line\">            &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">                log.error(&quot;Interrupted&quot;, e);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // force flush when prepare load finished</span><br><span class=\"line\">    if (type == FlushDiskType.SYNC_FLUSH) &#123;</span><br><span class=\"line\">        log.info(&quot;mapped file warm-up done, force to disk, mappedFile=&#123;&#125;, costTime=&#123;&#125;&quot;,</span><br><span class=\"line\">            this.getFileName(), System.currentTimeMillis() - beginTime);</span><br><span class=\"line\">        mappedByteBuffer.force();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    log.info(&quot;mapped file warm-up done. mappedFile=&#123;&#125;, costTime=&#123;&#125;&quot;, this.getFileName(),</span><br><span class=\"line\">        System.currentTimeMillis() - beginTime);</span><br><span class=\"line\"></span><br><span class=\"line\">    this.mlock();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">public void mlock() &#123;</span><br><span class=\"line\">        final long beginTime = System.currentTimeMillis();</span><br><span class=\"line\">        final long address = ((DirectBuffer) (this.mappedByteBuffer)).address();</span><br><span class=\"line\">        Pointer pointer = new Pointer(address);</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            int ret = LibC.INSTANCE.mlock(pointer, new NativeLong(this.fileSize));</span><br><span class=\"line\">            log.info(&quot;mlock &#123;&#125; &#123;&#125; &#123;&#125; ret = &#123;&#125; time consuming = &#123;&#125;&quot;, address, this.fileName, this.fileSize, ret, System.currentTimeMillis() - beginTime);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            int ret = LibC.INSTANCE.madvise(pointer, new NativeLong(this.fileSize), LibC.MADV_WILLNEED);</span><br><span class=\"line\">            log.info(&quot;madvise &#123;&#125; &#123;&#125; &#123;&#125; ret = &#123;&#125; time consuming = &#123;&#125;&quot;, address, this.fileName, this.fileSize, ret, System.currentTimeMillis() - beginTime);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>这个写入一个随机值，告诉内核，强制让内核发生缺页中断，去做虚拟内存和物理内存的mapping。注意，这个是给预创建的Commit Log。即使做了mapping，这部分的内存物理内存还是会变冷（LRU），还是有可能被内核回收走，干别的事情。这时要调用 mlock，告诉内核，这部分虚拟内存mapping的物理内存，千万别swap out 到swap区域，要持续放入物理内存中。madvise 传入will_need是高速操作系统，这块内存我等下就要使用，即使我暂时不用，也不要让它变冷，而被回收走。</p>\n<p>在 2018年4月8日 上午10:07，Zhanhui Li <a href=\"mailto:&#108;&#105;&#122;&#x68;&#x61;&#x6e;&#104;&#117;&#x69;&#64;&#97;&#x70;&#97;&#x63;&#104;&#101;&#x2e;&#x6f;&#x72;&#103;\" target=\"_blank\" rel=\"noopener\">&#108;&#105;&#122;&#x68;&#x61;&#x6e;&#104;&#117;&#x69;&#64;&#97;&#x70;&#97;&#x63;&#104;&#101;&#x2e;&#x6f;&#x72;&#103;</a>写道：</p>\n<blockquote>\n<p>writeBuffer 是预分配的anonymous pages, 并且mlock到物理内存了. 往里面写消息,<br>不会因为内存不足回收带来延迟.<br>mmap的文件page cache, 在物理内存分配过快, background reclaim速度跟不上的时候,<br>线程会被block住,进行direct reclaim, 带来延迟.</p>\n<p>可参考:  <a href=\"https://events.static.linuxfound.org/sites/events/\" target=\"_blank\" rel=\"noopener\">https://events.static.linuxfound.org/sites/events/</a><br>files/lcjp13_moriya.pdf</p>\n</blockquote>\n"},{"title":"RocketMQ-Persistence","date":"2018-08-31T11:14:24.000Z","_content":"\n\n### 参考MySQL Redo log刷盘机制\nhttps://www.tuicool.com/articles/Y7vUBz\n\n\n```\ninnodb_flush_log_at_trx_commit\n\nControls the balance between strict ACID compliance for commit operations and higher performance that is possible when commit-related I/O operations are rearranged and done in batches. You can achieve better performance by changing the default value but then you can lose transactions in a crash.\n\nThe default setting of 1 is required for full ACID compliance. Logs are written and flushed to disk at each transaction commit.\n\nWith a setting of 0, logs are written and flushed to disk once per second. Transactions for which logs have not been flushed can be lost in a crash.\n\nWith a setting of 2, logs are written after each transaction commit and flushed to disk once per second. Transactions for which logs have not been flushed can be lost in a crash.\n```","source":"_posts/RocketMQ-Persistence.md","raw":"---\ntitle: RocketMQ-Persistence\ndate: 2018-08-31 19:14:24\ntags:\n---\n\n\n### 参考MySQL Redo log刷盘机制\nhttps://www.tuicool.com/articles/Y7vUBz\n\n\n```\ninnodb_flush_log_at_trx_commit\n\nControls the balance between strict ACID compliance for commit operations and higher performance that is possible when commit-related I/O operations are rearranged and done in batches. You can achieve better performance by changing the default value but then you can lose transactions in a crash.\n\nThe default setting of 1 is required for full ACID compliance. Logs are written and flushed to disk at each transaction commit.\n\nWith a setting of 0, logs are written and flushed to disk once per second. Transactions for which logs have not been flushed can be lost in a crash.\n\nWith a setting of 2, logs are written after each transaction commit and flushed to disk once per second. Transactions for which logs have not been flushed can be lost in a crash.\n```","slug":"RocketMQ-Persistence","published":1,"updated":"2019-09-28T08:51:00.934Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84r0051v1npgi3v0eln","content":"<h3 id=\"参考MySQL-Redo-log刷盘机制\"><a href=\"#参考MySQL-Redo-log刷盘机制\" class=\"headerlink\" title=\"参考MySQL Redo log刷盘机制\"></a>参考MySQL Redo log刷盘机制</h3><p><a href=\"https://www.tuicool.com/articles/Y7vUBz\" target=\"_blank\" rel=\"noopener\">https://www.tuicool.com/articles/Y7vUBz</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_flush_log_at_trx_commit</span><br><span class=\"line\"></span><br><span class=\"line\">Controls the balance between strict ACID compliance for commit operations and higher performance that is possible when commit-related I/O operations are rearranged and done in batches. You can achieve better performance by changing the default value but then you can lose transactions in a crash.</span><br><span class=\"line\"></span><br><span class=\"line\">The default setting of 1 is required for full ACID compliance. Logs are written and flushed to disk at each transaction commit.</span><br><span class=\"line\"></span><br><span class=\"line\">With a setting of 0, logs are written and flushed to disk once per second. Transactions for which logs have not been flushed can be lost in a crash.</span><br><span class=\"line\"></span><br><span class=\"line\">With a setting of 2, logs are written after each transaction commit and flushed to disk once per second. Transactions for which logs have not been flushed can be lost in a crash.</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"参考MySQL-Redo-log刷盘机制\"><a href=\"#参考MySQL-Redo-log刷盘机制\" class=\"headerlink\" title=\"参考MySQL Redo log刷盘机制\"></a>参考MySQL Redo log刷盘机制</h3><p><a href=\"https://www.tuicool.com/articles/Y7vUBz\" target=\"_blank\" rel=\"noopener\">https://www.tuicool.com/articles/Y7vUBz</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">innodb_flush_log_at_trx_commit</span><br><span class=\"line\"></span><br><span class=\"line\">Controls the balance between strict ACID compliance for commit operations and higher performance that is possible when commit-related I/O operations are rearranged and done in batches. You can achieve better performance by changing the default value but then you can lose transactions in a crash.</span><br><span class=\"line\"></span><br><span class=\"line\">The default setting of 1 is required for full ACID compliance. Logs are written and flushed to disk at each transaction commit.</span><br><span class=\"line\"></span><br><span class=\"line\">With a setting of 0, logs are written and flushed to disk once per second. Transactions for which logs have not been flushed can be lost in a crash.</span><br><span class=\"line\"></span><br><span class=\"line\">With a setting of 2, logs are written after each transaction commit and flushed to disk once per second. Transactions for which logs have not been flushed can be lost in a crash.</span><br></pre></td></tr></table></figure>"},{"title":"RocketMQ-Performance-tunning","date":"2018-09-22T07:25:34.000Z","_content":"\n\n### 红帽linux性能调优 参考\nhttps://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html-single/performance_tuning_guide/index\n\n\n### mq4最佳实践，极佳\nhttp://jm.taobao.org/2017/03/23/20170323/\nhttp://jm.taobao.org/2017/01/26/20170126/\n```\nRocketMQ通过GC调优后最终采取的GC参数如下所示，供大家参考。\n\n-server -Xms8g -Xmx8g -Xmn4g\n-XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25\n-XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0\n-XX:SurvivorRatio=8 -XX:+DisableExplicitGC\n-verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails\n-XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime\n-XX:+PrintAdaptiveSizePolicy\n-XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m\n可以看出，我们最终全部切换到了G1，16年双十一线上MetaQ集群采用的也是这一组参数，基本上GC时间能控制在20ms以内（一些超大的共享集群除外）。\n\n对于G1，官方推荐使用该-XX:MaxGCPauseMillis设置目标暂停时间，不要手动指定-Xmn和-XX:NewRatio，但我们在实测中发现，如果指定过小的目标停顿时间(10ms)，G1会将新生代调整为很小，导致YGC更加频繁，老年代用得更快，所有还是手动指定了-Xmn为4g，在GC频率不高的情况下完成了10ms的目标停顿时间，这里也说明有时候一些通用的调优经验并不适用于所有的产品场景，需要更多的测试才能找到最合适的调优方法，往往需要另辟蹊径。\n```\n但是事实是，我采用了这组参数，G1却最后扩大了New区，导致经常young gc停顿超过10ms，说明在极致的性能调优前，不能用官方推荐的参数，只能自己反复修改GC参数然后再测试。\n```\nJAVA_OPT=\"-server -XX:+UseG1GC -Xms8g -Xmx8g -Xss256k -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m\"\n\nJAVA_OPT=\"$JAVA_OPT -XX:MaxDirectMemorySize=30g\"\n\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintSafepointStatistics\"\nJAVA_OPT=\"$JAVA_OPT -XX:PrintSafepointStatisticsCount=1\"\nJAVA_OPT=\"$JAVA_OPT -XX:+UnlockDiagnosticVMOptions\"\nJAVA_OPT=\"$JAVA_OPT -XX:-DisplayVMOutput\"\nJAVA_OPT=\"$JAVA_OPT -XX:+LogVMOutput\"\nJAVA_OPT=\"$JAVA_OPT -XX:LogFile=/opt/logs/rocketmq/vm.log\"\n\nJAVA_OPT=\"$JAVA_OPT -XX:MaxGCPauseMillis=10\"\nJAVA_OPT=\"$JAVA_OPT -XX:ParallelGCThreads=8\"\nJAVA_OPT=\"$JAVA_OPT -XX:ConcGCThreads=2\"\nJAVA_OPT=\"$JAVA_OPT -XX:SoftRefLRUPolicyMSPerMB=0\"\nJAVA_OPT=\"$JAVA_OPT -XX:+ParallelRefProcEnabled\"\nJAVA_OPT=\"$JAVA_OPT -XX:+DisableExplicitGC\"\nJAVA_OPT=\"$JAVA_OPT -XX:-UseLargePages\"\nJAVA_OPT=\"$JAVA_OPT -verbose:gc\"\nJAVA_OPT=\"$JAVA_OPT -Xloggc:/opt/logs/rocketmq/%p_gc.log\"\n\nJAVA_OPT=\"$JAVA_OPT -XX:+AggressiveOpts\"\nJAVA_OPT=\"$JAVA_OPT -XX:-UseBiasedLocking\"\nJAVA_OPT=\"$JAVA_OPT -XX:+UseFastAccessorMethods\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintGCDetails\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintGCDateStamps\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintGCApplicationStoppedTime\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintAdaptiveSizePolicy\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintTenuringDistribution\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintHeapAtGC\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintFlagsFinal\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintPromotionFailure\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintReferenceGC\"\n\nJAVA_OPT=\"$JAVA_OPT -XX:+UseGCLogFileRotation\"\nJAVA_OPT=\"$JAVA_OPT -XX:NumberOfGCLogFiles=5\"\nJAVA_OPT=\"$JAVA_OPT -XX:GCLogFileSize=30m\"\nJAVA_OPT=\"$JAVA_OPT -XX:-OmitStackTraceInFastThrow\"\nJAVA_OPT=\"$JAVA_OPT -XX:+AlwaysPreTouch\"\nJAVA_OPT=\"$JAVA_OPT -XX:MaxTenuringThreshold=15\"\nJAVA_OPT=\"$JAVA_OPT -XX:+HeapDumpOnOutOfMemoryError\"\nJAVA_OPT=\"$JAVA_OPT -XX:HeapDumpPath=/opt/logs/rocketmq/java.hprof\"\nJAVA_OPT=\"$JAVA_OPT -XX:ErrorFile=/opt/logs/rocketmq/hs_err_pid%p.log\"\n```\n\n\n\n### 是否用ReentrantLock\n```\n/**\n 经过多人测试，在竞争非常激烈的情况下，用ReentrantLock性能会好过SpinLock，注意可以适当提高消息发送的线程数量\n * introduced since 4.0.x. Determine whether to use mutex reentrantLock when putting message.<br/>\n * By default it is set to false indicating using spin lock when putting message.\n */\nprivate boolean useReentrantLockWhenPutMessage = false;\nint sendMessageThreadPoolNums = 1; //16 + Runtime.getRuntime().availableProcessors() * 4;\n```\n如果将useReentrantLockWhenPutMessage设置为false（默认就是false），那RocketMQ会使用自旋锁。这个加锁的位置是Append到CommitLog，如果Append线程比较多，并且并发量大，自旋锁会大量在CPU上无效自旋，从而导致CPU Loader高居不下。所以高并发下，使用synchronized或者ReentrantLock是最佳的，但是由于RocketMQ没有提供synchronized这个选项，所以只能选择ReentrantLock。\n\n\n### \n```\n// Whether check the CRC32 of the records consumed.\n// This ensures no on-the-wire or on-disk corruption to the messages occurred.\n// This check adds some overhead,so it may be disabled in cases seeking extreme performance.\nprivate boolean checkCRCOnRecover = true;\n```\n\n```\nprivate boolean warmMapedFileEnable = false;\n```\nRocketMQ中每一个CommitLog都有固定1GB的大小，当某一个文件写完了，再去创建另一个文件，这个过程明显会成为性能瓶颈，所以RocketMQ的做法是每次在创建文件的时候，异步多创建几个文件来进行备用，这个想法也是非常直觉化的，但是预先创建了文件，往里边写数据还是会比较慢，由于mmap只是做了虚拟内存和文件的映射，但是虚拟内存和物理内存还没有关联上，在真实写的时候会产生多次缺页异常。如果将warmMapedFileEnable设置为true，RocketMQ会在创建完文件后，对文件进行预热（按照page为单位写0值，mlock，madvise），从而在真正写入时，能达到极致的刷盘效果。\n\n\n###\n```\n    @ImportantField\n    private boolean transientStorePoolEnable = false;\n```\nRocketMQ在消息落盘实践的最大创新点，这个机制在kafka上没有。TransientStorePool只有在异步刷盘时才能开启，是在RocketMQ启动时，会预留一个对外内存池，刷盘时，首先将ByteBuffer写入TransientStorePool，只要刷进内存，就给Producer一个成功的响应。使用了TransientStorePool，刷盘避免了使用mmap刷Page Cache，也就避免了需要Linux加锁回收内存，将刷盘的毛刺降到最低。\n\n但是，开启TransientStorePool后有一个影响，那就是当RocketMQ进程Crash，已经通知了Producer刷盘成功，但是还没有最终调用fileChannel.force()的消息将会丢失，本来就是设置异步刷盘，所以这个就是在性能和数据可靠性间做权衡。下图就是TransientStorePool开启和未开启的原理图。\n\n###\n```\n    private boolean transferMsgByHeap = true;\n```\n传统消息消费时，数据从Page Cache中拿出来后，被Copy到JVM堆内存，然后再传给JVM堆外的Socket通道，整个过程是数据在OS->JVM堆内->OS流转。将transferMsgByHeap设置为false后，就意味着数据从Page Cache中拿出来后，不会被Copy一份到JVM堆内存，直接从Page Cache到Socket通道，这样就使用到了Zero-Copy功能。下图是RocketMQ源码位置，感兴趣的同学可以读一读这段逻辑。\n\n\n###\n```\n    private boolean slaveReadEnable = false;\n```\n当消费者需要读取的数据与现在的Offset偏差比较大（比较久远），不管要读取多少数据，现代操作系统都会使用「Page Cache」，这样就会强制回收一部分在文件末端的Cache，内存分配的速度如果没有赶上内存回收的速度，在刷盘时就会产生毛刺，并且如果改消费者稳定从久远数据开始读取，会使当前的Broker Master在消息落盘和消息消费都产生影响。将slaveReadEnable设置为true后，如果读取的数据比较久远，Broker会推荐Consumer去Slave读取，从而缓解Master的压力。\n\n###\n```\n    private boolean serverPooledByteBufAllocatorEnable = true;\n```\n\n###\n```\n    /**\n     * make make install\n     *\n     *\n     * ../glibc-2.10.1/configure \\ --prefix=/usr \\ --with-headers=/usr/include \\\n     * --host=x86_64-linux-gnu \\ --build=x86_64-pc-linux-gnu \\ --without-gd\n     */\n    private boolean useEpollNativeSelector = false;\n```\n\n这块代码是否可以优化？\n```\nprivate byte[] readGetMessageResult(final GetMessageResult getMessageResult, final String group, final String topic,\n    final int queueId) {\n\n    // 这里频繁的申请堆内内存，可以进行优化\n    final ByteBuffer byteBuffer = ByteBuffer.allocate(getMessageResult.getBufferTotalSize());\n\n    long storeTimestamp = 0;\n    try {\n        List<ByteBuffer> messageBufferList = getMessageResult.getMessageBufferList();\n        for (ByteBuffer bb : messageBufferList) {\n\n            byteBuffer.put(bb);\n            storeTimestamp = bb.getLong(MessageDecoder.MESSAGE_STORE_TIMESTAMP_POSTION);\n        }\n    } finally {\n        getMessageResult.release();\n    }\n\n    this.brokerController.getBrokerStatsManager().recordDiskFallBehindTime(group, topic, queueId, this.brokerController.getMessageStore().now() - storeTimestamp);\n    return byteBuffer.array();\n}\n```","source":"_posts/RocketMQ-Performance-tunning.md","raw":"---\ntitle: RocketMQ-Performance-tunning\ndate: 2018-09-22 15:25:34\ntags:\n---\n\n\n### 红帽linux性能调优 参考\nhttps://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html-single/performance_tuning_guide/index\n\n\n### mq4最佳实践，极佳\nhttp://jm.taobao.org/2017/03/23/20170323/\nhttp://jm.taobao.org/2017/01/26/20170126/\n```\nRocketMQ通过GC调优后最终采取的GC参数如下所示，供大家参考。\n\n-server -Xms8g -Xmx8g -Xmn4g\n-XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25\n-XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0\n-XX:SurvivorRatio=8 -XX:+DisableExplicitGC\n-verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails\n-XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime\n-XX:+PrintAdaptiveSizePolicy\n-XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m\n可以看出，我们最终全部切换到了G1，16年双十一线上MetaQ集群采用的也是这一组参数，基本上GC时间能控制在20ms以内（一些超大的共享集群除外）。\n\n对于G1，官方推荐使用该-XX:MaxGCPauseMillis设置目标暂停时间，不要手动指定-Xmn和-XX:NewRatio，但我们在实测中发现，如果指定过小的目标停顿时间(10ms)，G1会将新生代调整为很小，导致YGC更加频繁，老年代用得更快，所有还是手动指定了-Xmn为4g，在GC频率不高的情况下完成了10ms的目标停顿时间，这里也说明有时候一些通用的调优经验并不适用于所有的产品场景，需要更多的测试才能找到最合适的调优方法，往往需要另辟蹊径。\n```\n但是事实是，我采用了这组参数，G1却最后扩大了New区，导致经常young gc停顿超过10ms，说明在极致的性能调优前，不能用官方推荐的参数，只能自己反复修改GC参数然后再测试。\n```\nJAVA_OPT=\"-server -XX:+UseG1GC -Xms8g -Xmx8g -Xss256k -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m\"\n\nJAVA_OPT=\"$JAVA_OPT -XX:MaxDirectMemorySize=30g\"\n\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintSafepointStatistics\"\nJAVA_OPT=\"$JAVA_OPT -XX:PrintSafepointStatisticsCount=1\"\nJAVA_OPT=\"$JAVA_OPT -XX:+UnlockDiagnosticVMOptions\"\nJAVA_OPT=\"$JAVA_OPT -XX:-DisplayVMOutput\"\nJAVA_OPT=\"$JAVA_OPT -XX:+LogVMOutput\"\nJAVA_OPT=\"$JAVA_OPT -XX:LogFile=/opt/logs/rocketmq/vm.log\"\n\nJAVA_OPT=\"$JAVA_OPT -XX:MaxGCPauseMillis=10\"\nJAVA_OPT=\"$JAVA_OPT -XX:ParallelGCThreads=8\"\nJAVA_OPT=\"$JAVA_OPT -XX:ConcGCThreads=2\"\nJAVA_OPT=\"$JAVA_OPT -XX:SoftRefLRUPolicyMSPerMB=0\"\nJAVA_OPT=\"$JAVA_OPT -XX:+ParallelRefProcEnabled\"\nJAVA_OPT=\"$JAVA_OPT -XX:+DisableExplicitGC\"\nJAVA_OPT=\"$JAVA_OPT -XX:-UseLargePages\"\nJAVA_OPT=\"$JAVA_OPT -verbose:gc\"\nJAVA_OPT=\"$JAVA_OPT -Xloggc:/opt/logs/rocketmq/%p_gc.log\"\n\nJAVA_OPT=\"$JAVA_OPT -XX:+AggressiveOpts\"\nJAVA_OPT=\"$JAVA_OPT -XX:-UseBiasedLocking\"\nJAVA_OPT=\"$JAVA_OPT -XX:+UseFastAccessorMethods\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintGCDetails\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintGCDateStamps\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintGCApplicationStoppedTime\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintAdaptiveSizePolicy\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintTenuringDistribution\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintHeapAtGC\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintFlagsFinal\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintPromotionFailure\"\nJAVA_OPT=\"$JAVA_OPT -XX:+PrintReferenceGC\"\n\nJAVA_OPT=\"$JAVA_OPT -XX:+UseGCLogFileRotation\"\nJAVA_OPT=\"$JAVA_OPT -XX:NumberOfGCLogFiles=5\"\nJAVA_OPT=\"$JAVA_OPT -XX:GCLogFileSize=30m\"\nJAVA_OPT=\"$JAVA_OPT -XX:-OmitStackTraceInFastThrow\"\nJAVA_OPT=\"$JAVA_OPT -XX:+AlwaysPreTouch\"\nJAVA_OPT=\"$JAVA_OPT -XX:MaxTenuringThreshold=15\"\nJAVA_OPT=\"$JAVA_OPT -XX:+HeapDumpOnOutOfMemoryError\"\nJAVA_OPT=\"$JAVA_OPT -XX:HeapDumpPath=/opt/logs/rocketmq/java.hprof\"\nJAVA_OPT=\"$JAVA_OPT -XX:ErrorFile=/opt/logs/rocketmq/hs_err_pid%p.log\"\n```\n\n\n\n### 是否用ReentrantLock\n```\n/**\n 经过多人测试，在竞争非常激烈的情况下，用ReentrantLock性能会好过SpinLock，注意可以适当提高消息发送的线程数量\n * introduced since 4.0.x. Determine whether to use mutex reentrantLock when putting message.<br/>\n * By default it is set to false indicating using spin lock when putting message.\n */\nprivate boolean useReentrantLockWhenPutMessage = false;\nint sendMessageThreadPoolNums = 1; //16 + Runtime.getRuntime().availableProcessors() * 4;\n```\n如果将useReentrantLockWhenPutMessage设置为false（默认就是false），那RocketMQ会使用自旋锁。这个加锁的位置是Append到CommitLog，如果Append线程比较多，并且并发量大，自旋锁会大量在CPU上无效自旋，从而导致CPU Loader高居不下。所以高并发下，使用synchronized或者ReentrantLock是最佳的，但是由于RocketMQ没有提供synchronized这个选项，所以只能选择ReentrantLock。\n\n\n### \n```\n// Whether check the CRC32 of the records consumed.\n// This ensures no on-the-wire or on-disk corruption to the messages occurred.\n// This check adds some overhead,so it may be disabled in cases seeking extreme performance.\nprivate boolean checkCRCOnRecover = true;\n```\n\n```\nprivate boolean warmMapedFileEnable = false;\n```\nRocketMQ中每一个CommitLog都有固定1GB的大小，当某一个文件写完了，再去创建另一个文件，这个过程明显会成为性能瓶颈，所以RocketMQ的做法是每次在创建文件的时候，异步多创建几个文件来进行备用，这个想法也是非常直觉化的，但是预先创建了文件，往里边写数据还是会比较慢，由于mmap只是做了虚拟内存和文件的映射，但是虚拟内存和物理内存还没有关联上，在真实写的时候会产生多次缺页异常。如果将warmMapedFileEnable设置为true，RocketMQ会在创建完文件后，对文件进行预热（按照page为单位写0值，mlock，madvise），从而在真正写入时，能达到极致的刷盘效果。\n\n\n###\n```\n    @ImportantField\n    private boolean transientStorePoolEnable = false;\n```\nRocketMQ在消息落盘实践的最大创新点，这个机制在kafka上没有。TransientStorePool只有在异步刷盘时才能开启，是在RocketMQ启动时，会预留一个对外内存池，刷盘时，首先将ByteBuffer写入TransientStorePool，只要刷进内存，就给Producer一个成功的响应。使用了TransientStorePool，刷盘避免了使用mmap刷Page Cache，也就避免了需要Linux加锁回收内存，将刷盘的毛刺降到最低。\n\n但是，开启TransientStorePool后有一个影响，那就是当RocketMQ进程Crash，已经通知了Producer刷盘成功，但是还没有最终调用fileChannel.force()的消息将会丢失，本来就是设置异步刷盘，所以这个就是在性能和数据可靠性间做权衡。下图就是TransientStorePool开启和未开启的原理图。\n\n###\n```\n    private boolean transferMsgByHeap = true;\n```\n传统消息消费时，数据从Page Cache中拿出来后，被Copy到JVM堆内存，然后再传给JVM堆外的Socket通道，整个过程是数据在OS->JVM堆内->OS流转。将transferMsgByHeap设置为false后，就意味着数据从Page Cache中拿出来后，不会被Copy一份到JVM堆内存，直接从Page Cache到Socket通道，这样就使用到了Zero-Copy功能。下图是RocketMQ源码位置，感兴趣的同学可以读一读这段逻辑。\n\n\n###\n```\n    private boolean slaveReadEnable = false;\n```\n当消费者需要读取的数据与现在的Offset偏差比较大（比较久远），不管要读取多少数据，现代操作系统都会使用「Page Cache」，这样就会强制回收一部分在文件末端的Cache，内存分配的速度如果没有赶上内存回收的速度，在刷盘时就会产生毛刺，并且如果改消费者稳定从久远数据开始读取，会使当前的Broker Master在消息落盘和消息消费都产生影响。将slaveReadEnable设置为true后，如果读取的数据比较久远，Broker会推荐Consumer去Slave读取，从而缓解Master的压力。\n\n###\n```\n    private boolean serverPooledByteBufAllocatorEnable = true;\n```\n\n###\n```\n    /**\n     * make make install\n     *\n     *\n     * ../glibc-2.10.1/configure \\ --prefix=/usr \\ --with-headers=/usr/include \\\n     * --host=x86_64-linux-gnu \\ --build=x86_64-pc-linux-gnu \\ --without-gd\n     */\n    private boolean useEpollNativeSelector = false;\n```\n\n这块代码是否可以优化？\n```\nprivate byte[] readGetMessageResult(final GetMessageResult getMessageResult, final String group, final String topic,\n    final int queueId) {\n\n    // 这里频繁的申请堆内内存，可以进行优化\n    final ByteBuffer byteBuffer = ByteBuffer.allocate(getMessageResult.getBufferTotalSize());\n\n    long storeTimestamp = 0;\n    try {\n        List<ByteBuffer> messageBufferList = getMessageResult.getMessageBufferList();\n        for (ByteBuffer bb : messageBufferList) {\n\n            byteBuffer.put(bb);\n            storeTimestamp = bb.getLong(MessageDecoder.MESSAGE_STORE_TIMESTAMP_POSTION);\n        }\n    } finally {\n        getMessageResult.release();\n    }\n\n    this.brokerController.getBrokerStatsManager().recordDiskFallBehindTime(group, topic, queueId, this.brokerController.getMessageStore().now() - storeTimestamp);\n    return byteBuffer.array();\n}\n```","slug":"RocketMQ-Performance-tunning","published":1,"updated":"2019-09-28T08:51:00.934Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84r0052v1nps68n1954","content":"<h3 id=\"红帽linux性能调优-参考\"><a href=\"#红帽linux性能调优-参考\" class=\"headerlink\" title=\"红帽linux性能调优 参考\"></a>红帽linux性能调优 参考</h3><p><a href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html-single/performance_tuning_guide/index\" target=\"_blank\" rel=\"noopener\">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html-single/performance_tuning_guide/index</a></p>\n<h3 id=\"mq4最佳实践，极佳\"><a href=\"#mq4最佳实践，极佳\" class=\"headerlink\" title=\"mq4最佳实践，极佳\"></a>mq4最佳实践，极佳</h3><p><a href=\"http://jm.taobao.org/2017/03/23/20170323/\" target=\"_blank\" rel=\"noopener\">http://jm.taobao.org/2017/03/23/20170323/</a><br><a href=\"http://jm.taobao.org/2017/01/26/20170126/\" target=\"_blank\" rel=\"noopener\">http://jm.taobao.org/2017/01/26/20170126/</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RocketMQ通过GC调优后最终采取的GC参数如下所示，供大家参考。</span><br><span class=\"line\"></span><br><span class=\"line\">-server -Xms8g -Xmx8g -Xmn4g</span><br><span class=\"line\">-XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25</span><br><span class=\"line\">-XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0</span><br><span class=\"line\">-XX:SurvivorRatio=8 -XX:+DisableExplicitGC</span><br><span class=\"line\">-verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails</span><br><span class=\"line\">-XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime</span><br><span class=\"line\">-XX:+PrintAdaptiveSizePolicy</span><br><span class=\"line\">-XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m</span><br><span class=\"line\">可以看出，我们最终全部切换到了G1，16年双十一线上MetaQ集群采用的也是这一组参数，基本上GC时间能控制在20ms以内（一些超大的共享集群除外）。</span><br><span class=\"line\"></span><br><span class=\"line\">对于G1，官方推荐使用该-XX:MaxGCPauseMillis设置目标暂停时间，不要手动指定-Xmn和-XX:NewRatio，但我们在实测中发现，如果指定过小的目标停顿时间(10ms)，G1会将新生代调整为很小，导致YGC更加频繁，老年代用得更快，所有还是手动指定了-Xmn为4g，在GC频率不高的情况下完成了10ms的目标停顿时间，这里也说明有时候一些通用的调优经验并不适用于所有的产品场景，需要更多的测试才能找到最合适的调优方法，往往需要另辟蹊径。</span><br></pre></td></tr></table></figure>\n\n<p>但是事实是，我采用了这组参数，G1却最后扩大了New区，导致经常young gc停顿超过10ms，说明在极致的性能调优前，不能用官方推荐的参数，只能自己反复修改GC参数然后再测试。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JAVA_OPT=&quot;-server -XX:+UseG1GC -Xms8g -Xmx8g -Xss256k -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:MaxDirectMemorySize=30g&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintSafepointStatistics&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:PrintSafepointStatisticsCount=1&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+UnlockDiagnosticVMOptions&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:-DisplayVMOutput&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+LogVMOutput&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:LogFile=/opt/logs/rocketmq/vm.log&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:MaxGCPauseMillis=10&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:ParallelGCThreads=8&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:ConcGCThreads=2&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:SoftRefLRUPolicyMSPerMB=0&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+ParallelRefProcEnabled&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+DisableExplicitGC&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:-UseLargePages&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -verbose:gc&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -Xloggc:/opt/logs/rocketmq/%p_gc.log&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+AggressiveOpts&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:-UseBiasedLocking&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+UseFastAccessorMethods&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintGCDetails&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintGCDateStamps&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintGCApplicationStoppedTime&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintAdaptiveSizePolicy&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintTenuringDistribution&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintHeapAtGC&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintFlagsFinal&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintPromotionFailure&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintReferenceGC&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+UseGCLogFileRotation&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:NumberOfGCLogFiles=5&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:GCLogFileSize=30m&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:-OmitStackTraceInFastThrow&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+AlwaysPreTouch&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:MaxTenuringThreshold=15&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+HeapDumpOnOutOfMemoryError&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:HeapDumpPath=/opt/logs/rocketmq/java.hprof&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:ErrorFile=/opt/logs/rocketmq/hs_err_pid%p.log&quot;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"是否用ReentrantLock\"><a href=\"#是否用ReentrantLock\" class=\"headerlink\" title=\"是否用ReentrantLock\"></a>是否用ReentrantLock</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> 经过多人测试，在竞争非常激烈的情况下，用ReentrantLock性能会好过SpinLock，注意可以适当提高消息发送的线程数量</span><br><span class=\"line\"> * introduced since 4.0.x. Determine whether to use mutex reentrantLock when putting message.&lt;br/&gt;</span><br><span class=\"line\"> * By default it is set to false indicating using spin lock when putting message.</span><br><span class=\"line\"> */</span><br><span class=\"line\">private boolean useReentrantLockWhenPutMessage = false;</span><br><span class=\"line\">int sendMessageThreadPoolNums = 1; //16 + Runtime.getRuntime().availableProcessors() * 4;</span><br></pre></td></tr></table></figure>\n\n<p>如果将useReentrantLockWhenPutMessage设置为false（默认就是false），那RocketMQ会使用自旋锁。这个加锁的位置是Append到CommitLog，如果Append线程比较多，并且并发量大，自旋锁会大量在CPU上无效自旋，从而导致CPU Loader高居不下。所以高并发下，使用synchronized或者ReentrantLock是最佳的，但是由于RocketMQ没有提供synchronized这个选项，所以只能选择ReentrantLock。</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Whether check the CRC32 of the records consumed.</span><br><span class=\"line\">// This ensures no on-the-wire or on-disk corruption to the messages occurred.</span><br><span class=\"line\">// This check adds some overhead,so it may be disabled in cases seeking extreme performance.</span><br><span class=\"line\">private boolean checkCRCOnRecover = true;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private boolean warmMapedFileEnable = false;</span><br></pre></td></tr></table></figure>\n\n<p>RocketMQ中每一个CommitLog都有固定1GB的大小，当某一个文件写完了，再去创建另一个文件，这个过程明显会成为性能瓶颈，所以RocketMQ的做法是每次在创建文件的时候，异步多创建几个文件来进行备用，这个想法也是非常直觉化的，但是预先创建了文件，往里边写数据还是会比较慢，由于mmap只是做了虚拟内存和文件的映射，但是虚拟内存和物理内存还没有关联上，在真实写的时候会产生多次缺页异常。如果将warmMapedFileEnable设置为true，RocketMQ会在创建完文件后，对文件进行预热（按照page为单位写0值，mlock，madvise），从而在真正写入时，能达到极致的刷盘效果。</p>\n<p>###</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@ImportantField</span><br><span class=\"line\">private boolean transientStorePoolEnable = false;</span><br></pre></td></tr></table></figure>\n\n<p>RocketMQ在消息落盘实践的最大创新点，这个机制在kafka上没有。TransientStorePool只有在异步刷盘时才能开启，是在RocketMQ启动时，会预留一个对外内存池，刷盘时，首先将ByteBuffer写入TransientStorePool，只要刷进内存，就给Producer一个成功的响应。使用了TransientStorePool，刷盘避免了使用mmap刷Page Cache，也就避免了需要Linux加锁回收内存，将刷盘的毛刺降到最低。</p>\n<p>但是，开启TransientStorePool后有一个影响，那就是当RocketMQ进程Crash，已经通知了Producer刷盘成功，但是还没有最终调用fileChannel.force()的消息将会丢失，本来就是设置异步刷盘，所以这个就是在性能和数据可靠性间做权衡。下图就是TransientStorePool开启和未开启的原理图。</p>\n<p>###</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private boolean transferMsgByHeap = true;</span><br></pre></td></tr></table></figure>\n\n<p>传统消息消费时，数据从Page Cache中拿出来后，被Copy到JVM堆内存，然后再传给JVM堆外的Socket通道，整个过程是数据在OS-&gt;JVM堆内-&gt;OS流转。将transferMsgByHeap设置为false后，就意味着数据从Page Cache中拿出来后，不会被Copy一份到JVM堆内存，直接从Page Cache到Socket通道，这样就使用到了Zero-Copy功能。下图是RocketMQ源码位置，感兴趣的同学可以读一读这段逻辑。</p>\n<p>###</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private boolean slaveReadEnable = false;</span><br></pre></td></tr></table></figure>\n\n<p>当消费者需要读取的数据与现在的Offset偏差比较大（比较久远），不管要读取多少数据，现代操作系统都会使用「Page Cache」，这样就会强制回收一部分在文件末端的Cache，内存分配的速度如果没有赶上内存回收的速度，在刷盘时就会产生毛刺，并且如果改消费者稳定从久远数据开始读取，会使当前的Broker Master在消息落盘和消息消费都产生影响。将slaveReadEnable设置为true后，如果读取的数据比较久远，Broker会推荐Consumer去Slave读取，从而缓解Master的压力。</p>\n<p>###</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private boolean serverPooledByteBufAllocatorEnable = true;</span><br></pre></td></tr></table></figure>\n\n<p>###</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * make make install</span><br><span class=\"line\"> *</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * ../glibc-2.10.1/configure \\ --prefix=/usr \\ --with-headers=/usr/include \\</span><br><span class=\"line\"> * --host=x86_64-linux-gnu \\ --build=x86_64-pc-linux-gnu \\ --without-gd</span><br><span class=\"line\"> */</span><br><span class=\"line\">private boolean useEpollNativeSelector = false;</span><br></pre></td></tr></table></figure>\n\n<p>这块代码是否可以优化？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private byte[] readGetMessageResult(final GetMessageResult getMessageResult, final String group, final String topic,</span><br><span class=\"line\">    final int queueId) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 这里频繁的申请堆内内存，可以进行优化</span><br><span class=\"line\">    final ByteBuffer byteBuffer = ByteBuffer.allocate(getMessageResult.getBufferTotalSize());</span><br><span class=\"line\"></span><br><span class=\"line\">    long storeTimestamp = 0;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        List&lt;ByteBuffer&gt; messageBufferList = getMessageResult.getMessageBufferList();</span><br><span class=\"line\">        for (ByteBuffer bb : messageBufferList) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">            byteBuffer.put(bb);</span><br><span class=\"line\">            storeTimestamp = bb.getLong(MessageDecoder.MESSAGE_STORE_TIMESTAMP_POSTION);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; finally &#123;</span><br><span class=\"line\">        getMessageResult.release();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    this.brokerController.getBrokerStatsManager().recordDiskFallBehindTime(group, topic, queueId, this.brokerController.getMessageStore().now() - storeTimestamp);</span><br><span class=\"line\">    return byteBuffer.array();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"红帽linux性能调优-参考\"><a href=\"#红帽linux性能调优-参考\" class=\"headerlink\" title=\"红帽linux性能调优 参考\"></a>红帽linux性能调优 参考</h3><p><a href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html-single/performance_tuning_guide/index\" target=\"_blank\" rel=\"noopener\">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html-single/performance_tuning_guide/index</a></p>\n<h3 id=\"mq4最佳实践，极佳\"><a href=\"#mq4最佳实践，极佳\" class=\"headerlink\" title=\"mq4最佳实践，极佳\"></a>mq4最佳实践，极佳</h3><p><a href=\"http://jm.taobao.org/2017/03/23/20170323/\" target=\"_blank\" rel=\"noopener\">http://jm.taobao.org/2017/03/23/20170323/</a><br><a href=\"http://jm.taobao.org/2017/01/26/20170126/\" target=\"_blank\" rel=\"noopener\">http://jm.taobao.org/2017/01/26/20170126/</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RocketMQ通过GC调优后最终采取的GC参数如下所示，供大家参考。</span><br><span class=\"line\"></span><br><span class=\"line\">-server -Xms8g -Xmx8g -Xmn4g</span><br><span class=\"line\">-XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25</span><br><span class=\"line\">-XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0</span><br><span class=\"line\">-XX:SurvivorRatio=8 -XX:+DisableExplicitGC</span><br><span class=\"line\">-verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails</span><br><span class=\"line\">-XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime</span><br><span class=\"line\">-XX:+PrintAdaptiveSizePolicy</span><br><span class=\"line\">-XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m</span><br><span class=\"line\">可以看出，我们最终全部切换到了G1，16年双十一线上MetaQ集群采用的也是这一组参数，基本上GC时间能控制在20ms以内（一些超大的共享集群除外）。</span><br><span class=\"line\"></span><br><span class=\"line\">对于G1，官方推荐使用该-XX:MaxGCPauseMillis设置目标暂停时间，不要手动指定-Xmn和-XX:NewRatio，但我们在实测中发现，如果指定过小的目标停顿时间(10ms)，G1会将新生代调整为很小，导致YGC更加频繁，老年代用得更快，所有还是手动指定了-Xmn为4g，在GC频率不高的情况下完成了10ms的目标停顿时间，这里也说明有时候一些通用的调优经验并不适用于所有的产品场景，需要更多的测试才能找到最合适的调优方法，往往需要另辟蹊径。</span><br></pre></td></tr></table></figure>\n\n<p>但是事实是，我采用了这组参数，G1却最后扩大了New区，导致经常young gc停顿超过10ms，说明在极致的性能调优前，不能用官方推荐的参数，只能自己反复修改GC参数然后再测试。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JAVA_OPT=&quot;-server -XX:+UseG1GC -Xms8g -Xmx8g -Xss256k -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:MaxDirectMemorySize=30g&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintSafepointStatistics&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:PrintSafepointStatisticsCount=1&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+UnlockDiagnosticVMOptions&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:-DisplayVMOutput&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+LogVMOutput&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:LogFile=/opt/logs/rocketmq/vm.log&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:MaxGCPauseMillis=10&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:ParallelGCThreads=8&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:ConcGCThreads=2&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:SoftRefLRUPolicyMSPerMB=0&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+ParallelRefProcEnabled&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+DisableExplicitGC&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:-UseLargePages&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -verbose:gc&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -Xloggc:/opt/logs/rocketmq/%p_gc.log&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+AggressiveOpts&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:-UseBiasedLocking&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+UseFastAccessorMethods&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintGCDetails&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintGCDateStamps&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintGCApplicationStoppedTime&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintAdaptiveSizePolicy&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintTenuringDistribution&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintHeapAtGC&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintFlagsFinal&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintPromotionFailure&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+PrintReferenceGC&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+UseGCLogFileRotation&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:NumberOfGCLogFiles=5&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:GCLogFileSize=30m&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:-OmitStackTraceInFastThrow&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+AlwaysPreTouch&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:MaxTenuringThreshold=15&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:+HeapDumpOnOutOfMemoryError&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:HeapDumpPath=/opt/logs/rocketmq/java.hprof&quot;</span><br><span class=\"line\">JAVA_OPT=&quot;$JAVA_OPT -XX:ErrorFile=/opt/logs/rocketmq/hs_err_pid%p.log&quot;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"是否用ReentrantLock\"><a href=\"#是否用ReentrantLock\" class=\"headerlink\" title=\"是否用ReentrantLock\"></a>是否用ReentrantLock</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> 经过多人测试，在竞争非常激烈的情况下，用ReentrantLock性能会好过SpinLock，注意可以适当提高消息发送的线程数量</span><br><span class=\"line\"> * introduced since 4.0.x. Determine whether to use mutex reentrantLock when putting message.&lt;br/&gt;</span><br><span class=\"line\"> * By default it is set to false indicating using spin lock when putting message.</span><br><span class=\"line\"> */</span><br><span class=\"line\">private boolean useReentrantLockWhenPutMessage = false;</span><br><span class=\"line\">int sendMessageThreadPoolNums = 1; //16 + Runtime.getRuntime().availableProcessors() * 4;</span><br></pre></td></tr></table></figure>\n\n<p>如果将useReentrantLockWhenPutMessage设置为false（默认就是false），那RocketMQ会使用自旋锁。这个加锁的位置是Append到CommitLog，如果Append线程比较多，并且并发量大，自旋锁会大量在CPU上无效自旋，从而导致CPU Loader高居不下。所以高并发下，使用synchronized或者ReentrantLock是最佳的，但是由于RocketMQ没有提供synchronized这个选项，所以只能选择ReentrantLock。</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Whether check the CRC32 of the records consumed.</span><br><span class=\"line\">// This ensures no on-the-wire or on-disk corruption to the messages occurred.</span><br><span class=\"line\">// This check adds some overhead,so it may be disabled in cases seeking extreme performance.</span><br><span class=\"line\">private boolean checkCRCOnRecover = true;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private boolean warmMapedFileEnable = false;</span><br></pre></td></tr></table></figure>\n\n<p>RocketMQ中每一个CommitLog都有固定1GB的大小，当某一个文件写完了，再去创建另一个文件，这个过程明显会成为性能瓶颈，所以RocketMQ的做法是每次在创建文件的时候，异步多创建几个文件来进行备用，这个想法也是非常直觉化的，但是预先创建了文件，往里边写数据还是会比较慢，由于mmap只是做了虚拟内存和文件的映射，但是虚拟内存和物理内存还没有关联上，在真实写的时候会产生多次缺页异常。如果将warmMapedFileEnable设置为true，RocketMQ会在创建完文件后，对文件进行预热（按照page为单位写0值，mlock，madvise），从而在真正写入时，能达到极致的刷盘效果。</p>\n<p>###</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@ImportantField</span><br><span class=\"line\">private boolean transientStorePoolEnable = false;</span><br></pre></td></tr></table></figure>\n\n<p>RocketMQ在消息落盘实践的最大创新点，这个机制在kafka上没有。TransientStorePool只有在异步刷盘时才能开启，是在RocketMQ启动时，会预留一个对外内存池，刷盘时，首先将ByteBuffer写入TransientStorePool，只要刷进内存，就给Producer一个成功的响应。使用了TransientStorePool，刷盘避免了使用mmap刷Page Cache，也就避免了需要Linux加锁回收内存，将刷盘的毛刺降到最低。</p>\n<p>但是，开启TransientStorePool后有一个影响，那就是当RocketMQ进程Crash，已经通知了Producer刷盘成功，但是还没有最终调用fileChannel.force()的消息将会丢失，本来就是设置异步刷盘，所以这个就是在性能和数据可靠性间做权衡。下图就是TransientStorePool开启和未开启的原理图。</p>\n<p>###</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private boolean transferMsgByHeap = true;</span><br></pre></td></tr></table></figure>\n\n<p>传统消息消费时，数据从Page Cache中拿出来后，被Copy到JVM堆内存，然后再传给JVM堆外的Socket通道，整个过程是数据在OS-&gt;JVM堆内-&gt;OS流转。将transferMsgByHeap设置为false后，就意味着数据从Page Cache中拿出来后，不会被Copy一份到JVM堆内存，直接从Page Cache到Socket通道，这样就使用到了Zero-Copy功能。下图是RocketMQ源码位置，感兴趣的同学可以读一读这段逻辑。</p>\n<p>###</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private boolean slaveReadEnable = false;</span><br></pre></td></tr></table></figure>\n\n<p>当消费者需要读取的数据与现在的Offset偏差比较大（比较久远），不管要读取多少数据，现代操作系统都会使用「Page Cache」，这样就会强制回收一部分在文件末端的Cache，内存分配的速度如果没有赶上内存回收的速度，在刷盘时就会产生毛刺，并且如果改消费者稳定从久远数据开始读取，会使当前的Broker Master在消息落盘和消息消费都产生影响。将slaveReadEnable设置为true后，如果读取的数据比较久远，Broker会推荐Consumer去Slave读取，从而缓解Master的压力。</p>\n<p>###</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private boolean serverPooledByteBufAllocatorEnable = true;</span><br></pre></td></tr></table></figure>\n\n<p>###</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * make make install</span><br><span class=\"line\"> *</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * ../glibc-2.10.1/configure \\ --prefix=/usr \\ --with-headers=/usr/include \\</span><br><span class=\"line\"> * --host=x86_64-linux-gnu \\ --build=x86_64-pc-linux-gnu \\ --without-gd</span><br><span class=\"line\"> */</span><br><span class=\"line\">private boolean useEpollNativeSelector = false;</span><br></pre></td></tr></table></figure>\n\n<p>这块代码是否可以优化？</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private byte[] readGetMessageResult(final GetMessageResult getMessageResult, final String group, final String topic,</span><br><span class=\"line\">    final int queueId) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 这里频繁的申请堆内内存，可以进行优化</span><br><span class=\"line\">    final ByteBuffer byteBuffer = ByteBuffer.allocate(getMessageResult.getBufferTotalSize());</span><br><span class=\"line\"></span><br><span class=\"line\">    long storeTimestamp = 0;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        List&lt;ByteBuffer&gt; messageBufferList = getMessageResult.getMessageBufferList();</span><br><span class=\"line\">        for (ByteBuffer bb : messageBufferList) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">            byteBuffer.put(bb);</span><br><span class=\"line\">            storeTimestamp = bb.getLong(MessageDecoder.MESSAGE_STORE_TIMESTAMP_POSTION);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; finally &#123;</span><br><span class=\"line\">        getMessageResult.release();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    this.brokerController.getBrokerStatsManager().recordDiskFallBehindTime(group, topic, queueId, this.brokerController.getMessageStore().now() - storeTimestamp);</span><br><span class=\"line\">    return byteBuffer.array();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"RocketMQ——远程通讯协议及其序列化","date":"2017-11-10T10:41:47.000Z","_content":"\n\n### 通信协议\n\nLengthFieldBasedFrameDecoder\n\n### 通信Request, Response序列化\n\njson，好像新版可以支持Protobuf\n\n\nhttps://zhuanlan.zhihu.com/rocketmq","source":"_posts/RocketMQ-Remote-communication-protocol-and-serialization.md","raw":"---\ntitle: RocketMQ——远程通讯协议及其序列化\ndate: 2017-11-10 18:41:47\ntags: RocketMQ\n---\n\n\n### 通信协议\n\nLengthFieldBasedFrameDecoder\n\n### 通信Request, Response序列化\n\njson，好像新版可以支持Protobuf\n\n\nhttps://zhuanlan.zhihu.com/rocketmq","slug":"RocketMQ-Remote-communication-protocol-and-serialization","published":1,"updated":"2019-09-28T08:51:00.934Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84r0053v1npdrmdwehf","content":"<h3 id=\"通信协议\"><a href=\"#通信协议\" class=\"headerlink\" title=\"通信协议\"></a>通信协议</h3><p>LengthFieldBasedFrameDecoder</p>\n<h3 id=\"通信Request-Response序列化\"><a href=\"#通信Request-Response序列化\" class=\"headerlink\" title=\"通信Request, Response序列化\"></a>通信Request, Response序列化</h3><p>json，好像新版可以支持Protobuf</p>\n<p><a href=\"https://zhuanlan.zhihu.com/rocketmq\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/rocketmq</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"通信协议\"><a href=\"#通信协议\" class=\"headerlink\" title=\"通信协议\"></a>通信协议</h3><p>LengthFieldBasedFrameDecoder</p>\n<h3 id=\"通信Request-Response序列化\"><a href=\"#通信Request-Response序列化\" class=\"headerlink\" title=\"通信Request, Response序列化\"></a>通信Request, Response序列化</h3><p>json，好像新版可以支持Protobuf</p>\n<p><a href=\"https://zhuanlan.zhihu.com/rocketmq\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/rocketmq</a></p>\n"},{"title":"RocketMQ——高性能PullRequest秘籍之长轮询(长轮询)原理分析","date":"2017-09-20T08:58:52.000Z","_content":"\n\n分成两部分，Client和Broker\n\n### Client: \n\n### Broker:\n首先PullMessageProcessor用相应的线程池调用processRequest，去ConsumerQueue中找消息，\n如果找到了，没有什么好说的，直接用Netty模块将数据写进相应的channel，客户端获取到了数据后进行并行消费；\n如果没有消息，那么将当前的pullRequest放入PullRequestHoldService的pullRequestTable进行suspend。\n``` java \ncase ResponseCode.PULL_NOT_FOUND:\n    if (brokerAllowSuspend && hasSuspendFlag) {\n        long pollingTimeMills = suspendTimeoutMillisLong;\n        if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) {\n            pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills();\n        }\n\n        String topic = requestHeader.getTopic();\n        long offset = requestHeader.getQueueOffset();\n        int queueId = requestHeader.getQueueId();\n        PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills,\n            this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter);\n        this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest);\n        // 此处将repsonse设置为null，remote-server将不会给对应的channel发送响应信息。那响应的信息何时发送，有两种情况：\n        // 1. PullRequestHoldService hold了足够的时间后\n        // 2. 有新的信息被发送至队列后\n        response = null;\n        break;\n    }\n```\n那么，消息刷入CommitLog后，怎么样让这个Hold住的PullRequest感知到消息的到来？\n答案是，DefaultMessageStore.ReputMessageService线程。\nReputMessageService开启时就进行了一个近实时的空循环(Busy Spin)，不释放CPU进行等待事件\n``` java\nwhile (!this.isStopped()) {\n    try {\n        Thread.sleep(1);\n        this.doReput();\n    } catch (Exception e) {\n        DefaultMessageStore.log.warn(this.getServiceName() + \" service has exception. \", e);\n    }\n}\n```\n检测CommitLog中的MaxOffset是否在变大，变大了说明有新的消息已经存进了CommitLog，紧接着构建一个dispatchRequest，再让DefaultMessageStore调用doDispatch(dispatchRequest)，\n该方法并没有开启新的线程，一个做了几件事情，\n第一，将新的消息刷入consumerQueue，最小2页，作用也非常明显，到时候要获取一个消息，consumerQueue可以用logicOffset定位到CommitLog的PhyicOffset，是一个无法或缺的索引，\n第二，将新的消息写入index file用于后续更加复杂的查询，\n第三，计算bitmap。当doDispatch顺利执行完后。\n\n重点来了，之后触发messageArrivingListener的arriving方法，让pullRequestHoldService调用notifyMessageArriving，\n开启新的线程再一次让PullMessageProcessor调用processRequest来处理原来的那个pullRequest，但此时由于consumerQueue已经构建好了，所以会正常获取到消息，正常用netty模块进行一个对client的应答。\n``` java\n// 用一个接近空轮询\nprivate void doReput() {\n    for (boolean doNext = true; this.isCommitLogAvailable() && doNext; ) {\n        ...\n        SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset);\n        ...\n        this.reputFromOffset = result.getStartOffset();\n\n        for (int readSize = 0; readSize < result.getSize() && doNext; ) {\n            DispatchRequest dispatchRequest =\n                DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false);\n            int size = dispatchRequest.getMsgSize();\n            ...\n            if (size > 0) {\n                // dispatch到构建consumerQueue和index file的调度器中\n                DefaultMessageStore.this.doDispatch(dispatchRequest);\n                \n                if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole()\n                    && DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) {\n                    // 通知suspend pullRequest的PullRequestHoldService解除对pullRequest的hold\n                    DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(),\n                        dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1,\n                        dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(),\n                        dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap());\n                }\n\n            } \n            ...\n        }\n    }\n}\n```\n\n整个过程时序图\n\n![](https://ws2.sinaimg.cn/large/006tKfTcgy1fkeelo8oxpj30za0g2adr.jpg)\n","source":"_posts/RocketMQ-Pull-message-with-long-polling.md","raw":"---\ntitle: RocketMQ——高性能PullRequest秘籍之长轮询(长轮询)原理分析\ndate: 2017-09-20 16:58:52\ntags: RocketMQ\n---\n\n\n分成两部分，Client和Broker\n\n### Client: \n\n### Broker:\n首先PullMessageProcessor用相应的线程池调用processRequest，去ConsumerQueue中找消息，\n如果找到了，没有什么好说的，直接用Netty模块将数据写进相应的channel，客户端获取到了数据后进行并行消费；\n如果没有消息，那么将当前的pullRequest放入PullRequestHoldService的pullRequestTable进行suspend。\n``` java \ncase ResponseCode.PULL_NOT_FOUND:\n    if (brokerAllowSuspend && hasSuspendFlag) {\n        long pollingTimeMills = suspendTimeoutMillisLong;\n        if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) {\n            pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills();\n        }\n\n        String topic = requestHeader.getTopic();\n        long offset = requestHeader.getQueueOffset();\n        int queueId = requestHeader.getQueueId();\n        PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills,\n            this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter);\n        this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest);\n        // 此处将repsonse设置为null，remote-server将不会给对应的channel发送响应信息。那响应的信息何时发送，有两种情况：\n        // 1. PullRequestHoldService hold了足够的时间后\n        // 2. 有新的信息被发送至队列后\n        response = null;\n        break;\n    }\n```\n那么，消息刷入CommitLog后，怎么样让这个Hold住的PullRequest感知到消息的到来？\n答案是，DefaultMessageStore.ReputMessageService线程。\nReputMessageService开启时就进行了一个近实时的空循环(Busy Spin)，不释放CPU进行等待事件\n``` java\nwhile (!this.isStopped()) {\n    try {\n        Thread.sleep(1);\n        this.doReput();\n    } catch (Exception e) {\n        DefaultMessageStore.log.warn(this.getServiceName() + \" service has exception. \", e);\n    }\n}\n```\n检测CommitLog中的MaxOffset是否在变大，变大了说明有新的消息已经存进了CommitLog，紧接着构建一个dispatchRequest，再让DefaultMessageStore调用doDispatch(dispatchRequest)，\n该方法并没有开启新的线程，一个做了几件事情，\n第一，将新的消息刷入consumerQueue，最小2页，作用也非常明显，到时候要获取一个消息，consumerQueue可以用logicOffset定位到CommitLog的PhyicOffset，是一个无法或缺的索引，\n第二，将新的消息写入index file用于后续更加复杂的查询，\n第三，计算bitmap。当doDispatch顺利执行完后。\n\n重点来了，之后触发messageArrivingListener的arriving方法，让pullRequestHoldService调用notifyMessageArriving，\n开启新的线程再一次让PullMessageProcessor调用processRequest来处理原来的那个pullRequest，但此时由于consumerQueue已经构建好了，所以会正常获取到消息，正常用netty模块进行一个对client的应答。\n``` java\n// 用一个接近空轮询\nprivate void doReput() {\n    for (boolean doNext = true; this.isCommitLogAvailable() && doNext; ) {\n        ...\n        SelectMappedBufferResult result = DefaultMessageStore.this.commitLog.getData(reputFromOffset);\n        ...\n        this.reputFromOffset = result.getStartOffset();\n\n        for (int readSize = 0; readSize < result.getSize() && doNext; ) {\n            DispatchRequest dispatchRequest =\n                DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false);\n            int size = dispatchRequest.getMsgSize();\n            ...\n            if (size > 0) {\n                // dispatch到构建consumerQueue和index file的调度器中\n                DefaultMessageStore.this.doDispatch(dispatchRequest);\n                \n                if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole()\n                    && DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) {\n                    // 通知suspend pullRequest的PullRequestHoldService解除对pullRequest的hold\n                    DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(),\n                        dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1,\n                        dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(),\n                        dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap());\n                }\n\n            } \n            ...\n        }\n    }\n}\n```\n\n整个过程时序图\n\n![](https://ws2.sinaimg.cn/large/006tKfTcgy1fkeelo8oxpj30za0g2adr.jpg)\n","slug":"RocketMQ-Pull-message-with-long-polling","published":1,"updated":"2019-09-28T08:51:00.934Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84s0054v1npx8sfv2fj","content":"<p>分成两部分，Client和Broker</p>\n<h3 id=\"Client\"><a href=\"#Client\" class=\"headerlink\" title=\"Client:\"></a>Client:</h3><h3 id=\"Broker\"><a href=\"#Broker\" class=\"headerlink\" title=\"Broker:\"></a>Broker:</h3><p>首先PullMessageProcessor用相应的线程池调用processRequest，去ConsumerQueue中找消息，<br>如果找到了，没有什么好说的，直接用Netty模块将数据写进相应的channel，客户端获取到了数据后进行并行消费；<br>如果没有消息，那么将当前的pullRequest放入PullRequestHoldService的pullRequestTable进行suspend。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">case</span> ResponseCode.PULL_NOT_FOUND:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (brokerAllowSuspend &amp;&amp; hasSuspendFlag) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> pollingTimeMills = suspendTimeoutMillisLong;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!<span class=\"keyword\">this</span>.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;</span><br><span class=\"line\">            pollingTimeMills = <span class=\"keyword\">this</span>.brokerController.getBrokerConfig().getShortPollingTimeMills();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        String topic = requestHeader.getTopic();</span><br><span class=\"line\">        <span class=\"keyword\">long</span> offset = requestHeader.getQueueOffset();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> queueId = requestHeader.getQueueId();</span><br><span class=\"line\">        PullRequest pullRequest = <span class=\"keyword\">new</span> PullRequest(request, channel, pollingTimeMills,</span><br><span class=\"line\">            <span class=\"keyword\">this</span>.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest);</span><br><span class=\"line\">        <span class=\"comment\">// 此处将repsonse设置为null，remote-server将不会给对应的channel发送响应信息。那响应的信息何时发送，有两种情况：</span></span><br><span class=\"line\">        <span class=\"comment\">// 1. PullRequestHoldService hold了足够的时间后</span></span><br><span class=\"line\">        <span class=\"comment\">// 2. 有新的信息被发送至队列后</span></span><br><span class=\"line\">        response = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>那么，消息刷入CommitLog后，怎么样让这个Hold住的PullRequest感知到消息的到来？<br>答案是，DefaultMessageStore.ReputMessageService线程。<br>ReputMessageService开启时就进行了一个近实时的空循环(Busy Spin)，不释放CPU进行等待事件</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> (!<span class=\"keyword\">this</span>.isStopped()) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        Thread.sleep(<span class=\"number\">1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.doReput();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">        DefaultMessageStore.log.warn(<span class=\"keyword\">this</span>.getServiceName() + <span class=\"string\">\" service has exception. \"</span>, e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>检测CommitLog中的MaxOffset是否在变大，变大了说明有新的消息已经存进了CommitLog，紧接着构建一个dispatchRequest，再让DefaultMessageStore调用doDispatch(dispatchRequest)，<br>该方法并没有开启新的线程，一个做了几件事情，<br>第一，将新的消息刷入consumerQueue，最小2页，作用也非常明显，到时候要获取一个消息，consumerQueue可以用logicOffset定位到CommitLog的PhyicOffset，是一个无法或缺的索引，<br>第二，将新的消息写入index file用于后续更加复杂的查询，<br>第三，计算bitmap。当doDispatch顺利执行完后。</p>\n<p>重点来了，之后触发messageArrivingListener的arriving方法，让pullRequestHoldService调用notifyMessageArriving，<br>开启新的线程再一次让PullMessageProcessor调用processRequest来处理原来的那个pullRequest，但此时由于consumerQueue已经构建好了，所以会正常获取到消息，正常用netty模块进行一个对client的应答。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 用一个接近空轮询</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">doReput</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">boolean</span> doNext = <span class=\"keyword\">true</span>; <span class=\"keyword\">this</span>.isCommitLogAvailable() &amp;&amp; doNext; ) &#123;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">        SelectMappedBufferResult result = DefaultMessageStore.<span class=\"keyword\">this</span>.commitLog.getData(reputFromOffset);</span><br><span class=\"line\">        ...</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.reputFromOffset = result.getStartOffset();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> readSize = <span class=\"number\">0</span>; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123;</span><br><span class=\"line\">            DispatchRequest dispatchRequest =</span><br><span class=\"line\">                DefaultMessageStore.<span class=\"keyword\">this</span>.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), <span class=\"keyword\">false</span>, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">            <span class=\"keyword\">int</span> size = dispatchRequest.getMsgSize();</span><br><span class=\"line\">            ...</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (size &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// dispatch到构建consumerQueue和index file的调度器中</span></span><br><span class=\"line\">                DefaultMessageStore.<span class=\"keyword\">this</span>.doDispatch(dispatchRequest);</span><br><span class=\"line\">                </span><br><span class=\"line\">                <span class=\"keyword\">if</span> (BrokerRole.SLAVE != DefaultMessageStore.<span class=\"keyword\">this</span>.getMessageStoreConfig().getBrokerRole()</span><br><span class=\"line\">                    &amp;&amp; DefaultMessageStore.<span class=\"keyword\">this</span>.brokerConfig.isLongPollingEnable()) &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 通知suspend pullRequest的PullRequestHoldService解除对pullRequest的hold</span></span><br><span class=\"line\">                    DefaultMessageStore.<span class=\"keyword\">this</span>.messageArrivingListener.arriving(dispatchRequest.getTopic(),</span><br><span class=\"line\">                        dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + <span class=\"number\">1</span>,</span><br><span class=\"line\">                        dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(),</span><br><span class=\"line\">                        dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap());</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            &#125; </span><br><span class=\"line\">            ...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>整个过程时序图</p>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tKfTcgy1fkeelo8oxpj30za0g2adr.jpg\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>分成两部分，Client和Broker</p>\n<h3 id=\"Client\"><a href=\"#Client\" class=\"headerlink\" title=\"Client:\"></a>Client:</h3><h3 id=\"Broker\"><a href=\"#Broker\" class=\"headerlink\" title=\"Broker:\"></a>Broker:</h3><p>首先PullMessageProcessor用相应的线程池调用processRequest，去ConsumerQueue中找消息，<br>如果找到了，没有什么好说的，直接用Netty模块将数据写进相应的channel，客户端获取到了数据后进行并行消费；<br>如果没有消息，那么将当前的pullRequest放入PullRequestHoldService的pullRequestTable进行suspend。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">case</span> ResponseCode.PULL_NOT_FOUND:</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (brokerAllowSuspend &amp;&amp; hasSuspendFlag) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">long</span> pollingTimeMills = suspendTimeoutMillisLong;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!<span class=\"keyword\">this</span>.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;</span><br><span class=\"line\">            pollingTimeMills = <span class=\"keyword\">this</span>.brokerController.getBrokerConfig().getShortPollingTimeMills();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        String topic = requestHeader.getTopic();</span><br><span class=\"line\">        <span class=\"keyword\">long</span> offset = requestHeader.getQueueOffset();</span><br><span class=\"line\">        <span class=\"keyword\">int</span> queueId = requestHeader.getQueueId();</span><br><span class=\"line\">        PullRequest pullRequest = <span class=\"keyword\">new</span> PullRequest(request, channel, pollingTimeMills,</span><br><span class=\"line\">            <span class=\"keyword\">this</span>.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest);</span><br><span class=\"line\">        <span class=\"comment\">// 此处将repsonse设置为null，remote-server将不会给对应的channel发送响应信息。那响应的信息何时发送，有两种情况：</span></span><br><span class=\"line\">        <span class=\"comment\">// 1. PullRequestHoldService hold了足够的时间后</span></span><br><span class=\"line\">        <span class=\"comment\">// 2. 有新的信息被发送至队列后</span></span><br><span class=\"line\">        response = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>那么，消息刷入CommitLog后，怎么样让这个Hold住的PullRequest感知到消息的到来？<br>答案是，DefaultMessageStore.ReputMessageService线程。<br>ReputMessageService开启时就进行了一个近实时的空循环(Busy Spin)，不释放CPU进行等待事件</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> (!<span class=\"keyword\">this</span>.isStopped()) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        Thread.sleep(<span class=\"number\">1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.doReput();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">        DefaultMessageStore.log.warn(<span class=\"keyword\">this</span>.getServiceName() + <span class=\"string\">\" service has exception. \"</span>, e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>检测CommitLog中的MaxOffset是否在变大，变大了说明有新的消息已经存进了CommitLog，紧接着构建一个dispatchRequest，再让DefaultMessageStore调用doDispatch(dispatchRequest)，<br>该方法并没有开启新的线程，一个做了几件事情，<br>第一，将新的消息刷入consumerQueue，最小2页，作用也非常明显，到时候要获取一个消息，consumerQueue可以用logicOffset定位到CommitLog的PhyicOffset，是一个无法或缺的索引，<br>第二，将新的消息写入index file用于后续更加复杂的查询，<br>第三，计算bitmap。当doDispatch顺利执行完后。</p>\n<p>重点来了，之后触发messageArrivingListener的arriving方法，让pullRequestHoldService调用notifyMessageArriving，<br>开启新的线程再一次让PullMessageProcessor调用processRequest来处理原来的那个pullRequest，但此时由于consumerQueue已经构建好了，所以会正常获取到消息，正常用netty模块进行一个对client的应答。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 用一个接近空轮询</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">doReput</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">boolean</span> doNext = <span class=\"keyword\">true</span>; <span class=\"keyword\">this</span>.isCommitLogAvailable() &amp;&amp; doNext; ) &#123;</span><br><span class=\"line\">        ...</span><br><span class=\"line\">        SelectMappedBufferResult result = DefaultMessageStore.<span class=\"keyword\">this</span>.commitLog.getData(reputFromOffset);</span><br><span class=\"line\">        ...</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.reputFromOffset = result.getStartOffset();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> readSize = <span class=\"number\">0</span>; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123;</span><br><span class=\"line\">            DispatchRequest dispatchRequest =</span><br><span class=\"line\">                DefaultMessageStore.<span class=\"keyword\">this</span>.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), <span class=\"keyword\">false</span>, <span class=\"keyword\">false</span>);</span><br><span class=\"line\">            <span class=\"keyword\">int</span> size = dispatchRequest.getMsgSize();</span><br><span class=\"line\">            ...</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (size &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// dispatch到构建consumerQueue和index file的调度器中</span></span><br><span class=\"line\">                DefaultMessageStore.<span class=\"keyword\">this</span>.doDispatch(dispatchRequest);</span><br><span class=\"line\">                </span><br><span class=\"line\">                <span class=\"keyword\">if</span> (BrokerRole.SLAVE != DefaultMessageStore.<span class=\"keyword\">this</span>.getMessageStoreConfig().getBrokerRole()</span><br><span class=\"line\">                    &amp;&amp; DefaultMessageStore.<span class=\"keyword\">this</span>.brokerConfig.isLongPollingEnable()) &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 通知suspend pullRequest的PullRequestHoldService解除对pullRequest的hold</span></span><br><span class=\"line\">                    DefaultMessageStore.<span class=\"keyword\">this</span>.messageArrivingListener.arriving(dispatchRequest.getTopic(),</span><br><span class=\"line\">                        dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + <span class=\"number\">1</span>,</span><br><span class=\"line\">                        dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(),</span><br><span class=\"line\">                        dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap());</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            &#125; </span><br><span class=\"line\">            ...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>整个过程时序图</p>\n<p><img src=\"https://ws2.sinaimg.cn/large/006tKfTcgy1fkeelo8oxpj30za0g2adr.jpg\" alt=\"\"></p>\n"},{"title":"RocketMQ——事务消息原理分析","date":"2017-10-11T08:27:43.000Z","_content":"\n### apache官方MailList\nhttp://mail-archives.apache.org/mod_mbox/rocketmq-users/201804.mbox/browser\n\nhttps://help.aliyun.com/document_detail/43348.html?spm=5176.doc43490.6.566.Zd5Bl7\n\n![你想输入的替代文字](RocketMQ-Transactional-message/transaction_rocketmq.gif)\n\n### 问题\n\nproducer发送half msg时，broker如果当它是一条普通的消息，那consumer会立刻在long pooling中收到，但实现是不会收到的，是在哪一个环节设置的。\n事务消息，提交（COMMIT）后才生成 ConsumeQueue\n``` java\nclass CommitLogDispatcherBuildConsumeQueue implements CommitLogDispatcher {\n\n    @Override\n    public void dispatch(DispatchRequest request) {\n        final int tranType = MessageSysFlag.getTransactionValue(request.getSysFlag());\n        switch (tranType) {\n            case MessageSysFlag.TRANSACTION_NOT_TYPE:\n            // 虽然所有的状态都会存储到commit log中，只有 TRANSACTION_COMMIT_TYPE 状态才会构建consume queue\n            // 也就是说让consumer进行消费\n            case MessageSysFlag.TRANSACTION_COMMIT_TYPE:\n                DefaultMessageStore.this.putMessagePositionInfo(request);\n                break;\n            case MessageSysFlag.TRANSACTION_PREPARED_TYPE:\n            case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:\n                break;\n        }\n    }\n}\n```","source":"_posts/RocketMQ-Transactional-message.md","raw":"---\ntitle: RocketMQ——事务消息原理分析\ndate: 2017-10-11 16:27:43\ntags: RocketMQ\n---\n\n### apache官方MailList\nhttp://mail-archives.apache.org/mod_mbox/rocketmq-users/201804.mbox/browser\n\nhttps://help.aliyun.com/document_detail/43348.html?spm=5176.doc43490.6.566.Zd5Bl7\n\n![你想输入的替代文字](RocketMQ-Transactional-message/transaction_rocketmq.gif)\n\n### 问题\n\nproducer发送half msg时，broker如果当它是一条普通的消息，那consumer会立刻在long pooling中收到，但实现是不会收到的，是在哪一个环节设置的。\n事务消息，提交（COMMIT）后才生成 ConsumeQueue\n``` java\nclass CommitLogDispatcherBuildConsumeQueue implements CommitLogDispatcher {\n\n    @Override\n    public void dispatch(DispatchRequest request) {\n        final int tranType = MessageSysFlag.getTransactionValue(request.getSysFlag());\n        switch (tranType) {\n            case MessageSysFlag.TRANSACTION_NOT_TYPE:\n            // 虽然所有的状态都会存储到commit log中，只有 TRANSACTION_COMMIT_TYPE 状态才会构建consume queue\n            // 也就是说让consumer进行消费\n            case MessageSysFlag.TRANSACTION_COMMIT_TYPE:\n                DefaultMessageStore.this.putMessagePositionInfo(request);\n                break;\n            case MessageSysFlag.TRANSACTION_PREPARED_TYPE:\n            case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:\n                break;\n        }\n    }\n}\n```","slug":"RocketMQ-Transactional-message","published":1,"updated":"2019-09-28T08:51:00.935Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84t0055v1npe83nckd3","content":"<h3 id=\"apache官方MailList\"><a href=\"#apache官方MailList\" class=\"headerlink\" title=\"apache官方MailList\"></a>apache官方MailList</h3><p><a href=\"http://mail-archives.apache.org/mod_mbox/rocketmq-users/201804.mbox/browser\" target=\"_blank\" rel=\"noopener\">http://mail-archives.apache.org/mod_mbox/rocketmq-users/201804.mbox/browser</a></p>\n<p><a href=\"https://help.aliyun.com/document_detail/43348.html?spm=5176.doc43490.6.566.Zd5Bl7\" target=\"_blank\" rel=\"noopener\">https://help.aliyun.com/document_detail/43348.html?spm=5176.doc43490.6.566.Zd5Bl7</a></p>\n<p><img src=\"/2017/10/11/RocketMQ-Transactional-message/transaction_rocketmq.gif\" alt=\"你想输入的替代文字\"></p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><p>producer发送half msg时，broker如果当它是一条普通的消息，那consumer会立刻在long pooling中收到，但实现是不会收到的，是在哪一个环节设置的。<br>事务消息，提交（COMMIT）后才生成 ConsumeQueue</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CommitLogDispatcherBuildConsumeQueue</span> <span class=\"keyword\">implements</span> <span class=\"title\">CommitLogDispatcher</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">dispatch</span><span class=\"params\">(DispatchRequest request)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> tranType = MessageSysFlag.getTransactionValue(request.getSysFlag());</span><br><span class=\"line\">        <span class=\"keyword\">switch</span> (tranType) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> MessageSysFlag.TRANSACTION_NOT_TYPE:</span><br><span class=\"line\">            <span class=\"comment\">// 虽然所有的状态都会存储到commit log中，只有 TRANSACTION_COMMIT_TYPE 状态才会构建consume queue</span></span><br><span class=\"line\">            <span class=\"comment\">// 也就是说让consumer进行消费</span></span><br><span class=\"line\">            <span class=\"keyword\">case</span> MessageSysFlag.TRANSACTION_COMMIT_TYPE:</span><br><span class=\"line\">                DefaultMessageStore.<span class=\"keyword\">this</span>.putMessagePositionInfo(request);</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> MessageSysFlag.TRANSACTION_PREPARED_TYPE:</span><br><span class=\"line\">            <span class=\"keyword\">case</span> MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"apache官方MailList\"><a href=\"#apache官方MailList\" class=\"headerlink\" title=\"apache官方MailList\"></a>apache官方MailList</h3><p><a href=\"http://mail-archives.apache.org/mod_mbox/rocketmq-users/201804.mbox/browser\" target=\"_blank\" rel=\"noopener\">http://mail-archives.apache.org/mod_mbox/rocketmq-users/201804.mbox/browser</a></p>\n<p><a href=\"https://help.aliyun.com/document_detail/43348.html?spm=5176.doc43490.6.566.Zd5Bl7\" target=\"_blank\" rel=\"noopener\">https://help.aliyun.com/document_detail/43348.html?spm=5176.doc43490.6.566.Zd5Bl7</a></p>\n<p><img src=\"/2017/10/11/RocketMQ-Transactional-message/transaction_rocketmq.gif\" alt=\"你想输入的替代文字\"></p>\n<h3 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h3><p>producer发送half msg时，broker如果当它是一条普通的消息，那consumer会立刻在long pooling中收到，但实现是不会收到的，是在哪一个环节设置的。<br>事务消息，提交（COMMIT）后才生成 ConsumeQueue</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CommitLogDispatcherBuildConsumeQueue</span> <span class=\"keyword\">implements</span> <span class=\"title\">CommitLogDispatcher</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">dispatch</span><span class=\"params\">(DispatchRequest request)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> tranType = MessageSysFlag.getTransactionValue(request.getSysFlag());</span><br><span class=\"line\">        <span class=\"keyword\">switch</span> (tranType) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> MessageSysFlag.TRANSACTION_NOT_TYPE:</span><br><span class=\"line\">            <span class=\"comment\">// 虽然所有的状态都会存储到commit log中，只有 TRANSACTION_COMMIT_TYPE 状态才会构建consume queue</span></span><br><span class=\"line\">            <span class=\"comment\">// 也就是说让consumer进行消费</span></span><br><span class=\"line\">            <span class=\"keyword\">case</span> MessageSysFlag.TRANSACTION_COMMIT_TYPE:</span><br><span class=\"line\">                DefaultMessageStore.<span class=\"keyword\">this</span>.putMessagePositionInfo(request);</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> MessageSysFlag.TRANSACTION_PREPARED_TYPE:</span><br><span class=\"line\">            <span class=\"keyword\">case</span> MessageSysFlag.TRANSACTION_ROLLBACK_TYPE:</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"RocketMQ-TransientStorePool","date":"2018-11-06T10:02:28.000Z","_content":"\nhttps://processon.com/diagraming/5be2bdede4b0ad314e815528\n\n操作系统内部有很多非常优秀的设计，但是，有时候这些优秀的设计并不能服务于那些需要极致性能的软件，所以有时我们需要用它的思想来设计我们自己的软件。\n\n\n\n``` 在64G内存的机器上刷盘还会出现大量毛刺，会不会是切换CommitLog时，没有做warmup造成的？\n2018-10-28 11:23:17 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=1408, bodyLength=2255 AppendMessageResult=AppendMessageResult{status=PUT_OK, wroteOffset=1253026167641, wroteBytes=2477, msgId='0A0A41C900002A9F00000123BE2DFB59', storeTimestamp=1540696996021, logicsOffset=21187262, pagecacheRT=1408, msgNum=1}\n2018-10-27 19:54:56 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=5136, bodyLength=1815 AppendMessageResult=AppendMessageResult{status=PUT_OK, wroteOffset=1192894396447, wroteBytes=2029, msgId='0A0A41C900002A9F00000115BE0BF81F', storeTimestamp=1540641291355, logicsOffset=18326688, pagecacheRT=5136, msgNum=1}\n2018-10-27 18:00:45 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=3307, bodyLength=3226 AppendMessageResult=AppendMessageResult{status=PUT_OK, wroteOffset=1148235151172, wroteBytes=3454, msgId='0A0A41C900002A9F0000010B5825F744', storeTimestamp=1540634442011, logicsOffset=26631653, pagecacheRT=3306, msgNum=1}\n2018-10-27 13:12:16 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=4586, bodyLength=2814 AppendMessageResult=AppendMessageResult{status=PUT_OK, wroteOffset=1103117022509, wroteBytes=3037, msgId='0A0A41C900002A9F00000100D6E5F52D', storeTimestamp=1540617131925, logicsOffset=14710837, pagecacheRT=4586, msgNum=1}\n```\n\n\n\n先看定义\n```\npublic class MappedFile extends ReferenceResource {\n    protected FileChannel fileChannel;\n    /**\n     * Message will put to here first, and then reput to FileChannel if writeBuffer is not null.\n     */\n    protected ByteBuffer writeBuffer = null;\n    protected TransientStorePool transientStorePool = null;\n}\n```\n\n```\n/**\n * It's a heavy init method.\n */\npublic void init() {\n    for (int i = 0; i < poolSize; i++) {\n        ByteBuffer byteBuffer = ByteBuffer.allocateDirect(fileSize);\n\n        final long address = ((DirectBuffer) byteBuffer).address();\n        Pointer pointer = new Pointer(address);\n        LibC.INSTANCE.mlock(pointer, new NativeLong(fileSize));\n\n        availableBuffers.offer(byteBuffer);\n    }\n}\n```\n\nAllocateMappedFileService#mmapOperation\n\n\n先梳理两个重要的对象，flushCommitLogService和commitLogService，它们都是类型都是FlushCommitLogService。\n```\nprivate final FlushCommitLogService flushCommitLogService;\n\n//If TransientStorePool enabled, we must flush message to FileChannel at fixed periods\nprivate final FlushCommitLogService commitLogService;\n\npublic CommitLog(final DefaultMessageStore defaultMessageStore) {\n    this.mappedFileQueue = new MappedFileQueue(defaultMessageStore.getMessageStoreConfig().getStorePathCommitLog(),\n        defaultMessageStore.getMessageStoreConfig().getMapedFileSizeCommitLog(), defaultMessageStore.getAllocateMappedFileService());\n    this.defaultMessageStore = defaultMessageStore;\n\n    if (FlushDiskType.SYNC_FLUSH == defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) {\n        this.flushCommitLogService = new GroupCommitService();\n    } else {\n        this.flushCommitLogService = new FlushRealTimeService();\n    }\n\n    this.commitLogService = new CommitRealTimeService();\n\n    this.appendMessageCallback = new DefaultAppendMessageCallback(defaultMessageStore.getMessageStoreConfig().getMaxMessageSize());\n    batchEncoderThreadLocal = new ThreadLocal<MessageExtBatchEncoder>() {\n        @Override\n        protected MessageExtBatchEncoder initialValue() {\n            return new MessageExtBatchEncoder(defaultMessageStore.getMessageStoreConfig().getMaxMessageSize());\n        }\n    };\n    this.putMessageLock = defaultMessageStore.getMessageStoreConfig().isUseReentrantLockWhenPutMessage() ? new PutMessageReentrantLock() : new PutMessageSpinLock();\n\n}\n```\n\n\n\n\n### 刷盘实现\n```\nclass CommitRealTimeService extends FlushCommitLogService {\n\n    private long lastCommitTimestamp = 0;\n\n    @Override\n    public String getServiceName() {\n        return CommitRealTimeService.class.getSimpleName();\n    }\n\n    @Override\n    public void run() {\n        CommitLog.log.info(this.getServiceName() + \" service started\");\n        while (!this.isStopped()) {\n            int interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitIntervalCommitLog();\n\n            int commitDataLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogLeastPages();\n\n            int commitDataThoroughInterval =\n                CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogThoroughInterval();\n\n            long begin = System.currentTimeMillis();\n            if (begin >= (this.lastCommitTimestamp + commitDataThoroughInterval)) {\n                this.lastCommitTimestamp = begin;\n                commitDataLeastPages = 0;\n            }\n\n            try {\n                boolean result = CommitLog.this.mappedFileQueue.commit(commitDataLeastPages);\n                long end = System.currentTimeMillis();\n                if (!result) {\n                    this.lastCommitTimestamp = end; // result = false means some data committed.\n                    //now wake up flush thread.\n                    flushCommitLogService.wakeup();\n                }\n\n                if (end - begin > 500) {\n                    log.info(\"Commit data to file costs {} ms\", end - begin);\n                }\n                this.waitForRunning(interval);\n            } catch (Throwable e) {\n                CommitLog.log.error(this.getServiceName() + \" service has exception. \", e);\n            }\n        }\n\n        boolean result = false;\n        for (int i = 0; i < RETRY_TIMES_OVER && !result; i++) {\n            result = CommitLog.this.mappedFileQueue.commit(0);\n            CommitLog.log.info(this.getServiceName() + \" service shutdown, retry \" + (i + 1) + \" times \" + (result ? \"OK\" : \"Not OK\"));\n        }\n        CommitLog.log.info(this.getServiceName() + \" service end\");\n    }\n}\n```\n\n```\n\n```","source":"_posts/RocketMQ-TransientStorePool.md","raw":"---\ntitle: RocketMQ-TransientStorePool\ndate: 2018-11-06 18:02:28\ntags:\n---\n\nhttps://processon.com/diagraming/5be2bdede4b0ad314e815528\n\n操作系统内部有很多非常优秀的设计，但是，有时候这些优秀的设计并不能服务于那些需要极致性能的软件，所以有时我们需要用它的思想来设计我们自己的软件。\n\n\n\n``` 在64G内存的机器上刷盘还会出现大量毛刺，会不会是切换CommitLog时，没有做warmup造成的？\n2018-10-28 11:23:17 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=1408, bodyLength=2255 AppendMessageResult=AppendMessageResult{status=PUT_OK, wroteOffset=1253026167641, wroteBytes=2477, msgId='0A0A41C900002A9F00000123BE2DFB59', storeTimestamp=1540696996021, logicsOffset=21187262, pagecacheRT=1408, msgNum=1}\n2018-10-27 19:54:56 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=5136, bodyLength=1815 AppendMessageResult=AppendMessageResult{status=PUT_OK, wroteOffset=1192894396447, wroteBytes=2029, msgId='0A0A41C900002A9F00000115BE0BF81F', storeTimestamp=1540641291355, logicsOffset=18326688, pagecacheRT=5136, msgNum=1}\n2018-10-27 18:00:45 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=3307, bodyLength=3226 AppendMessageResult=AppendMessageResult{status=PUT_OK, wroteOffset=1148235151172, wroteBytes=3454, msgId='0A0A41C900002A9F0000010B5825F744', storeTimestamp=1540634442011, logicsOffset=26631653, pagecacheRT=3306, msgNum=1}\n2018-10-27 13:12:16 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=4586, bodyLength=2814 AppendMessageResult=AppendMessageResult{status=PUT_OK, wroteOffset=1103117022509, wroteBytes=3037, msgId='0A0A41C900002A9F00000100D6E5F52D', storeTimestamp=1540617131925, logicsOffset=14710837, pagecacheRT=4586, msgNum=1}\n```\n\n\n\n先看定义\n```\npublic class MappedFile extends ReferenceResource {\n    protected FileChannel fileChannel;\n    /**\n     * Message will put to here first, and then reput to FileChannel if writeBuffer is not null.\n     */\n    protected ByteBuffer writeBuffer = null;\n    protected TransientStorePool transientStorePool = null;\n}\n```\n\n```\n/**\n * It's a heavy init method.\n */\npublic void init() {\n    for (int i = 0; i < poolSize; i++) {\n        ByteBuffer byteBuffer = ByteBuffer.allocateDirect(fileSize);\n\n        final long address = ((DirectBuffer) byteBuffer).address();\n        Pointer pointer = new Pointer(address);\n        LibC.INSTANCE.mlock(pointer, new NativeLong(fileSize));\n\n        availableBuffers.offer(byteBuffer);\n    }\n}\n```\n\nAllocateMappedFileService#mmapOperation\n\n\n先梳理两个重要的对象，flushCommitLogService和commitLogService，它们都是类型都是FlushCommitLogService。\n```\nprivate final FlushCommitLogService flushCommitLogService;\n\n//If TransientStorePool enabled, we must flush message to FileChannel at fixed periods\nprivate final FlushCommitLogService commitLogService;\n\npublic CommitLog(final DefaultMessageStore defaultMessageStore) {\n    this.mappedFileQueue = new MappedFileQueue(defaultMessageStore.getMessageStoreConfig().getStorePathCommitLog(),\n        defaultMessageStore.getMessageStoreConfig().getMapedFileSizeCommitLog(), defaultMessageStore.getAllocateMappedFileService());\n    this.defaultMessageStore = defaultMessageStore;\n\n    if (FlushDiskType.SYNC_FLUSH == defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) {\n        this.flushCommitLogService = new GroupCommitService();\n    } else {\n        this.flushCommitLogService = new FlushRealTimeService();\n    }\n\n    this.commitLogService = new CommitRealTimeService();\n\n    this.appendMessageCallback = new DefaultAppendMessageCallback(defaultMessageStore.getMessageStoreConfig().getMaxMessageSize());\n    batchEncoderThreadLocal = new ThreadLocal<MessageExtBatchEncoder>() {\n        @Override\n        protected MessageExtBatchEncoder initialValue() {\n            return new MessageExtBatchEncoder(defaultMessageStore.getMessageStoreConfig().getMaxMessageSize());\n        }\n    };\n    this.putMessageLock = defaultMessageStore.getMessageStoreConfig().isUseReentrantLockWhenPutMessage() ? new PutMessageReentrantLock() : new PutMessageSpinLock();\n\n}\n```\n\n\n\n\n### 刷盘实现\n```\nclass CommitRealTimeService extends FlushCommitLogService {\n\n    private long lastCommitTimestamp = 0;\n\n    @Override\n    public String getServiceName() {\n        return CommitRealTimeService.class.getSimpleName();\n    }\n\n    @Override\n    public void run() {\n        CommitLog.log.info(this.getServiceName() + \" service started\");\n        while (!this.isStopped()) {\n            int interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitIntervalCommitLog();\n\n            int commitDataLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogLeastPages();\n\n            int commitDataThoroughInterval =\n                CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogThoroughInterval();\n\n            long begin = System.currentTimeMillis();\n            if (begin >= (this.lastCommitTimestamp + commitDataThoroughInterval)) {\n                this.lastCommitTimestamp = begin;\n                commitDataLeastPages = 0;\n            }\n\n            try {\n                boolean result = CommitLog.this.mappedFileQueue.commit(commitDataLeastPages);\n                long end = System.currentTimeMillis();\n                if (!result) {\n                    this.lastCommitTimestamp = end; // result = false means some data committed.\n                    //now wake up flush thread.\n                    flushCommitLogService.wakeup();\n                }\n\n                if (end - begin > 500) {\n                    log.info(\"Commit data to file costs {} ms\", end - begin);\n                }\n                this.waitForRunning(interval);\n            } catch (Throwable e) {\n                CommitLog.log.error(this.getServiceName() + \" service has exception. \", e);\n            }\n        }\n\n        boolean result = false;\n        for (int i = 0; i < RETRY_TIMES_OVER && !result; i++) {\n            result = CommitLog.this.mappedFileQueue.commit(0);\n            CommitLog.log.info(this.getServiceName() + \" service shutdown, retry \" + (i + 1) + \" times \" + (result ? \"OK\" : \"Not OK\"));\n        }\n        CommitLog.log.info(this.getServiceName() + \" service end\");\n    }\n}\n```\n\n```\n\n```","slug":"RocketMQ-TransientStorePool","published":1,"updated":"2019-09-28T08:51:00.935Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84t0056v1npedz30u5j","content":"<p><a href=\"https://processon.com/diagraming/5be2bdede4b0ad314e815528\" target=\"_blank\" rel=\"noopener\">https://processon.com/diagraming/5be2bdede4b0ad314e815528</a></p>\n<p>操作系统内部有很多非常优秀的设计，但是，有时候这些优秀的设计并不能服务于那些需要极致性能的软件，所以有时我们需要用它的思想来设计我们自己的软件。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2018-10-28 11:23:17 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=1408, bodyLength=2255 AppendMessageResult=AppendMessageResult&#123;status=PUT_OK, wroteOffset=1253026167641, wroteBytes=2477, msgId=&apos;0A0A41C900002A9F00000123BE2DFB59&apos;, storeTimestamp=1540696996021, logicsOffset=21187262, pagecacheRT=1408, msgNum=1&#125;</span><br><span class=\"line\">2018-10-27 19:54:56 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=5136, bodyLength=1815 AppendMessageResult=AppendMessageResult&#123;status=PUT_OK, wroteOffset=1192894396447, wroteBytes=2029, msgId=&apos;0A0A41C900002A9F00000115BE0BF81F&apos;, storeTimestamp=1540641291355, logicsOffset=18326688, pagecacheRT=5136, msgNum=1&#125;</span><br><span class=\"line\">2018-10-27 18:00:45 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=3307, bodyLength=3226 AppendMessageResult=AppendMessageResult&#123;status=PUT_OK, wroteOffset=1148235151172, wroteBytes=3454, msgId=&apos;0A0A41C900002A9F0000010B5825F744&apos;, storeTimestamp=1540634442011, logicsOffset=26631653, pagecacheRT=3306, msgNum=1&#125;</span><br><span class=\"line\">2018-10-27 13:12:16 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=4586, bodyLength=2814 AppendMessageResult=AppendMessageResult&#123;status=PUT_OK, wroteOffset=1103117022509, wroteBytes=3037, msgId=&apos;0A0A41C900002A9F00000100D6E5F52D&apos;, storeTimestamp=1540617131925, logicsOffset=14710837, pagecacheRT=4586, msgNum=1&#125;</span><br></pre></td></tr></table></figure>\n\n<p>先看定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class MappedFile extends ReferenceResource &#123;</span><br><span class=\"line\">    protected FileChannel fileChannel;</span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * Message will put to here first, and then reput to FileChannel if writeBuffer is not null.</span><br><span class=\"line\">     */</span><br><span class=\"line\">    protected ByteBuffer writeBuffer = null;</span><br><span class=\"line\">    protected TransientStorePool transientStorePool = null;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * It&apos;s a heavy init method.</span><br><span class=\"line\"> */</span><br><span class=\"line\">public void init() &#123;</span><br><span class=\"line\">    for (int i = 0; i &lt; poolSize; i++) &#123;</span><br><span class=\"line\">        ByteBuffer byteBuffer = ByteBuffer.allocateDirect(fileSize);</span><br><span class=\"line\"></span><br><span class=\"line\">        final long address = ((DirectBuffer) byteBuffer).address();</span><br><span class=\"line\">        Pointer pointer = new Pointer(address);</span><br><span class=\"line\">        LibC.INSTANCE.mlock(pointer, new NativeLong(fileSize));</span><br><span class=\"line\"></span><br><span class=\"line\">        availableBuffers.offer(byteBuffer);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>AllocateMappedFileService#mmapOperation</p>\n<p>先梳理两个重要的对象，flushCommitLogService和commitLogService，它们都是类型都是FlushCommitLogService。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private final FlushCommitLogService flushCommitLogService;</span><br><span class=\"line\"></span><br><span class=\"line\">//If TransientStorePool enabled, we must flush message to FileChannel at fixed periods</span><br><span class=\"line\">private final FlushCommitLogService commitLogService;</span><br><span class=\"line\"></span><br><span class=\"line\">public CommitLog(final DefaultMessageStore defaultMessageStore) &#123;</span><br><span class=\"line\">    this.mappedFileQueue = new MappedFileQueue(defaultMessageStore.getMessageStoreConfig().getStorePathCommitLog(),</span><br><span class=\"line\">        defaultMessageStore.getMessageStoreConfig().getMapedFileSizeCommitLog(), defaultMessageStore.getAllocateMappedFileService());</span><br><span class=\"line\">    this.defaultMessageStore = defaultMessageStore;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (FlushDiskType.SYNC_FLUSH == defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) &#123;</span><br><span class=\"line\">        this.flushCommitLogService = new GroupCommitService();</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        this.flushCommitLogService = new FlushRealTimeService();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    this.commitLogService = new CommitRealTimeService();</span><br><span class=\"line\"></span><br><span class=\"line\">    this.appendMessageCallback = new DefaultAppendMessageCallback(defaultMessageStore.getMessageStoreConfig().getMaxMessageSize());</span><br><span class=\"line\">    batchEncoderThreadLocal = new ThreadLocal&lt;MessageExtBatchEncoder&gt;() &#123;</span><br><span class=\"line\">        @Override</span><br><span class=\"line\">        protected MessageExtBatchEncoder initialValue() &#123;</span><br><span class=\"line\">            return new MessageExtBatchEncoder(defaultMessageStore.getMessageStoreConfig().getMaxMessageSize());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    this.putMessageLock = defaultMessageStore.getMessageStoreConfig().isUseReentrantLockWhenPutMessage() ? new PutMessageReentrantLock() : new PutMessageSpinLock();</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"刷盘实现\"><a href=\"#刷盘实现\" class=\"headerlink\" title=\"刷盘实现\"></a>刷盘实现</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class CommitRealTimeService extends FlushCommitLogService &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    private long lastCommitTimestamp = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public String getServiceName() &#123;</span><br><span class=\"line\">        return CommitRealTimeService.class.getSimpleName();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void run() &#123;</span><br><span class=\"line\">        CommitLog.log.info(this.getServiceName() + &quot; service started&quot;);</span><br><span class=\"line\">        while (!this.isStopped()) &#123;</span><br><span class=\"line\">            int interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitIntervalCommitLog();</span><br><span class=\"line\"></span><br><span class=\"line\">            int commitDataLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogLeastPages();</span><br><span class=\"line\"></span><br><span class=\"line\">            int commitDataThoroughInterval =</span><br><span class=\"line\">                CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogThoroughInterval();</span><br><span class=\"line\"></span><br><span class=\"line\">            long begin = System.currentTimeMillis();</span><br><span class=\"line\">            if (begin &gt;= (this.lastCommitTimestamp + commitDataThoroughInterval)) &#123;</span><br><span class=\"line\">                this.lastCommitTimestamp = begin;</span><br><span class=\"line\">                commitDataLeastPages = 0;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                boolean result = CommitLog.this.mappedFileQueue.commit(commitDataLeastPages);</span><br><span class=\"line\">                long end = System.currentTimeMillis();</span><br><span class=\"line\">                if (!result) &#123;</span><br><span class=\"line\">                    this.lastCommitTimestamp = end; // result = false means some data committed.</span><br><span class=\"line\">                    //now wake up flush thread.</span><br><span class=\"line\">                    flushCommitLogService.wakeup();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                if (end - begin &gt; 500) &#123;</span><br><span class=\"line\">                    log.info(&quot;Commit data to file costs &#123;&#125; ms&quot;, end - begin);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                this.waitForRunning(interval);</span><br><span class=\"line\">            &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">                CommitLog.log.error(this.getServiceName() + &quot; service has exception. &quot;, e);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        boolean result = false;</span><br><span class=\"line\">        for (int i = 0; i &lt; RETRY_TIMES_OVER &amp;&amp; !result; i++) &#123;</span><br><span class=\"line\">            result = CommitLog.this.mappedFileQueue.commit(0);</span><br><span class=\"line\">            CommitLog.log.info(this.getServiceName() + &quot; service shutdown, retry &quot; + (i + 1) + &quot; times &quot; + (result ? &quot;OK&quot; : &quot;Not OK&quot;));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        CommitLog.log.info(this.getServiceName() + &quot; service end&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://processon.com/diagraming/5be2bdede4b0ad314e815528\" target=\"_blank\" rel=\"noopener\">https://processon.com/diagraming/5be2bdede4b0ad314e815528</a></p>\n<p>操作系统内部有很多非常优秀的设计，但是，有时候这些优秀的设计并不能服务于那些需要极致性能的软件，所以有时我们需要用它的思想来设计我们自己的软件。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2018-10-28 11:23:17 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=1408, bodyLength=2255 AppendMessageResult=AppendMessageResult&#123;status=PUT_OK, wroteOffset=1253026167641, wroteBytes=2477, msgId=&apos;0A0A41C900002A9F00000123BE2DFB59&apos;, storeTimestamp=1540696996021, logicsOffset=21187262, pagecacheRT=1408, msgNum=1&#125;</span><br><span class=\"line\">2018-10-27 19:54:56 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=5136, bodyLength=1815 AppendMessageResult=AppendMessageResult&#123;status=PUT_OK, wroteOffset=1192894396447, wroteBytes=2029, msgId=&apos;0A0A41C900002A9F00000115BE0BF81F&apos;, storeTimestamp=1540641291355, logicsOffset=18326688, pagecacheRT=5136, msgNum=1&#125;</span><br><span class=\"line\">2018-10-27 18:00:45 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=3307, bodyLength=3226 AppendMessageResult=AppendMessageResult&#123;status=PUT_OK, wroteOffset=1148235151172, wroteBytes=3454, msgId=&apos;0A0A41C900002A9F0000010B5825F744&apos;, storeTimestamp=1540634442011, logicsOffset=26631653, pagecacheRT=3306, msgNum=1&#125;</span><br><span class=\"line\">2018-10-27 13:12:16 WARN SendMessageThread_1 - [NOTIFYME]putMessage in lock cost time(ms)=4586, bodyLength=2814 AppendMessageResult=AppendMessageResult&#123;status=PUT_OK, wroteOffset=1103117022509, wroteBytes=3037, msgId=&apos;0A0A41C900002A9F00000100D6E5F52D&apos;, storeTimestamp=1540617131925, logicsOffset=14710837, pagecacheRT=4586, msgNum=1&#125;</span><br></pre></td></tr></table></figure>\n\n<p>先看定义</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class MappedFile extends ReferenceResource &#123;</span><br><span class=\"line\">    protected FileChannel fileChannel;</span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * Message will put to here first, and then reput to FileChannel if writeBuffer is not null.</span><br><span class=\"line\">     */</span><br><span class=\"line\">    protected ByteBuffer writeBuffer = null;</span><br><span class=\"line\">    protected TransientStorePool transientStorePool = null;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * It&apos;s a heavy init method.</span><br><span class=\"line\"> */</span><br><span class=\"line\">public void init() &#123;</span><br><span class=\"line\">    for (int i = 0; i &lt; poolSize; i++) &#123;</span><br><span class=\"line\">        ByteBuffer byteBuffer = ByteBuffer.allocateDirect(fileSize);</span><br><span class=\"line\"></span><br><span class=\"line\">        final long address = ((DirectBuffer) byteBuffer).address();</span><br><span class=\"line\">        Pointer pointer = new Pointer(address);</span><br><span class=\"line\">        LibC.INSTANCE.mlock(pointer, new NativeLong(fileSize));</span><br><span class=\"line\"></span><br><span class=\"line\">        availableBuffers.offer(byteBuffer);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>AllocateMappedFileService#mmapOperation</p>\n<p>先梳理两个重要的对象，flushCommitLogService和commitLogService，它们都是类型都是FlushCommitLogService。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">private final FlushCommitLogService flushCommitLogService;</span><br><span class=\"line\"></span><br><span class=\"line\">//If TransientStorePool enabled, we must flush message to FileChannel at fixed periods</span><br><span class=\"line\">private final FlushCommitLogService commitLogService;</span><br><span class=\"line\"></span><br><span class=\"line\">public CommitLog(final DefaultMessageStore defaultMessageStore) &#123;</span><br><span class=\"line\">    this.mappedFileQueue = new MappedFileQueue(defaultMessageStore.getMessageStoreConfig().getStorePathCommitLog(),</span><br><span class=\"line\">        defaultMessageStore.getMessageStoreConfig().getMapedFileSizeCommitLog(), defaultMessageStore.getAllocateMappedFileService());</span><br><span class=\"line\">    this.defaultMessageStore = defaultMessageStore;</span><br><span class=\"line\"></span><br><span class=\"line\">    if (FlushDiskType.SYNC_FLUSH == defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) &#123;</span><br><span class=\"line\">        this.flushCommitLogService = new GroupCommitService();</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">        this.flushCommitLogService = new FlushRealTimeService();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    this.commitLogService = new CommitRealTimeService();</span><br><span class=\"line\"></span><br><span class=\"line\">    this.appendMessageCallback = new DefaultAppendMessageCallback(defaultMessageStore.getMessageStoreConfig().getMaxMessageSize());</span><br><span class=\"line\">    batchEncoderThreadLocal = new ThreadLocal&lt;MessageExtBatchEncoder&gt;() &#123;</span><br><span class=\"line\">        @Override</span><br><span class=\"line\">        protected MessageExtBatchEncoder initialValue() &#123;</span><br><span class=\"line\">            return new MessageExtBatchEncoder(defaultMessageStore.getMessageStoreConfig().getMaxMessageSize());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    this.putMessageLock = defaultMessageStore.getMessageStoreConfig().isUseReentrantLockWhenPutMessage() ? new PutMessageReentrantLock() : new PutMessageSpinLock();</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"刷盘实现\"><a href=\"#刷盘实现\" class=\"headerlink\" title=\"刷盘实现\"></a>刷盘实现</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class CommitRealTimeService extends FlushCommitLogService &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    private long lastCommitTimestamp = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public String getServiceName() &#123;</span><br><span class=\"line\">        return CommitRealTimeService.class.getSimpleName();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void run() &#123;</span><br><span class=\"line\">        CommitLog.log.info(this.getServiceName() + &quot; service started&quot;);</span><br><span class=\"line\">        while (!this.isStopped()) &#123;</span><br><span class=\"line\">            int interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitIntervalCommitLog();</span><br><span class=\"line\"></span><br><span class=\"line\">            int commitDataLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogLeastPages();</span><br><span class=\"line\"></span><br><span class=\"line\">            int commitDataThoroughInterval =</span><br><span class=\"line\">                CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogThoroughInterval();</span><br><span class=\"line\"></span><br><span class=\"line\">            long begin = System.currentTimeMillis();</span><br><span class=\"line\">            if (begin &gt;= (this.lastCommitTimestamp + commitDataThoroughInterval)) &#123;</span><br><span class=\"line\">                this.lastCommitTimestamp = begin;</span><br><span class=\"line\">                commitDataLeastPages = 0;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                boolean result = CommitLog.this.mappedFileQueue.commit(commitDataLeastPages);</span><br><span class=\"line\">                long end = System.currentTimeMillis();</span><br><span class=\"line\">                if (!result) &#123;</span><br><span class=\"line\">                    this.lastCommitTimestamp = end; // result = false means some data committed.</span><br><span class=\"line\">                    //now wake up flush thread.</span><br><span class=\"line\">                    flushCommitLogService.wakeup();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                if (end - begin &gt; 500) &#123;</span><br><span class=\"line\">                    log.info(&quot;Commit data to file costs &#123;&#125; ms&quot;, end - begin);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                this.waitForRunning(interval);</span><br><span class=\"line\">            &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">                CommitLog.log.error(this.getServiceName() + &quot; service has exception. &quot;, e);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        boolean result = false;</span><br><span class=\"line\">        for (int i = 0; i &lt; RETRY_TIMES_OVER &amp;&amp; !result; i++) &#123;</span><br><span class=\"line\">            result = CommitLog.this.mappedFileQueue.commit(0);</span><br><span class=\"line\">            CommitLog.log.info(this.getServiceName() + &quot; service shutdown, retry &quot; + (i + 1) + &quot; times &quot; + (result ? &quot;OK&quot; : &quot;Not OK&quot;));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        CommitLog.log.info(this.getServiceName() + &quot; service end&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>"},{"title":"RocksDB-Options-Tuning","date":"2019-04-11T06:28:03.000Z","_content":"\nhttps://github.com/tikv/tikv/blob/master/docs/op-guide/rocksdb-option-config.md\n\n公司TiKV关于RocksDB的配置:conf/tikv.toml\n[rocksdb]\nwal-dir = \"\"\n\n[rocksdb.defaultcf]\nblock-cache-size = \"25GB\"\n\n[rocksdb.lockcf]\n\n[rocksdb.writecf]\nblock-cache-size = \"15GB\"\n\n### RocksDB 的常用调优参数\nhttps://blog.csdn.net/weixin_36145588/article/details/78541070","source":"_posts/RocksDB-Options-Tuning.md","raw":"---\ntitle: RocksDB-Options-Tuning\ndate: 2019-04-11 14:28:03\ntags:\n---\n\nhttps://github.com/tikv/tikv/blob/master/docs/op-guide/rocksdb-option-config.md\n\n公司TiKV关于RocksDB的配置:conf/tikv.toml\n[rocksdb]\nwal-dir = \"\"\n\n[rocksdb.defaultcf]\nblock-cache-size = \"25GB\"\n\n[rocksdb.lockcf]\n\n[rocksdb.writecf]\nblock-cache-size = \"15GB\"\n\n### RocksDB 的常用调优参数\nhttps://blog.csdn.net/weixin_36145588/article/details/78541070","slug":"RocksDB-Options-Tuning","published":1,"updated":"2019-09-28T08:51:00.935Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84u0057v1np0ft976as","content":"<p><a href=\"https://github.com/tikv/tikv/blob/master/docs/op-guide/rocksdb-option-config.md\" target=\"_blank\" rel=\"noopener\">https://github.com/tikv/tikv/blob/master/docs/op-guide/rocksdb-option-config.md</a></p>\n<p>公司TiKV关于RocksDB的配置:conf/tikv.toml<br>[rocksdb]<br>wal-dir = “”</p>\n<p>[rocksdb.defaultcf]<br>block-cache-size = “25GB”</p>\n<p>[rocksdb.lockcf]</p>\n<p>[rocksdb.writecf]<br>block-cache-size = “15GB”</p>\n<h3 id=\"RocksDB-的常用调优参数\"><a href=\"#RocksDB-的常用调优参数\" class=\"headerlink\" title=\"RocksDB 的常用调优参数\"></a>RocksDB 的常用调优参数</h3><p><a href=\"https://blog.csdn.net/weixin_36145588/article/details/78541070\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_36145588/article/details/78541070</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://github.com/tikv/tikv/blob/master/docs/op-guide/rocksdb-option-config.md\" target=\"_blank\" rel=\"noopener\">https://github.com/tikv/tikv/blob/master/docs/op-guide/rocksdb-option-config.md</a></p>\n<p>公司TiKV关于RocksDB的配置:conf/tikv.toml<br>[rocksdb]<br>wal-dir = “”</p>\n<p>[rocksdb.defaultcf]<br>block-cache-size = “25GB”</p>\n<p>[rocksdb.lockcf]</p>\n<p>[rocksdb.writecf]<br>block-cache-size = “15GB”</p>\n<h3 id=\"RocksDB-的常用调优参数\"><a href=\"#RocksDB-的常用调优参数\" class=\"headerlink\" title=\"RocksDB 的常用调优参数\"></a>RocksDB 的常用调优参数</h3><p><a href=\"https://blog.csdn.net/weixin_36145588/article/details/78541070\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_36145588/article/details/78541070</a></p>\n"},{"title":"RocksDB","date":"2019-03-20T06:39:31.000Z","_content":"\n\n# RocksDB对LevelDB的优化——内联跳跃表\nhttps://zhuanlan.zhihu.com/p/29277585\n\n# RocksDB参数调优\nhttps://xiking.win/2018/12/05/rocksdb-tuning/\n# 官网\nhttps://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide\n\n### LSM优化在SSD\nhttp://catkang.github.io/2017/04/30/lsm-upon-ssd.html\n\n### Features Not in LevelDB\nhttps://github.com/facebook/rocksdb/wiki/Features-Not-in-LevelDB\nPerformance\nMultithread compaction\nMultithread memtable inserts\nReduced DB mutex holding\nOptimized level-based compaction style and universal compaction style\nPrefix bloom filter\nMemtable bloom filter\nSingle bloom filter covering the whole SST file\nWrite lock optimization\nImproved Iter::Prev() performance\nFewer comparator calls during SkipList searches\nAllocate memtable memory using huge page.","source":"_posts/RocksDB.md","raw":"---\ntitle: RocksDB\ndate: 2019-03-20 14:39:31\ntags:\n---\n\n\n# RocksDB对LevelDB的优化——内联跳跃表\nhttps://zhuanlan.zhihu.com/p/29277585\n\n# RocksDB参数调优\nhttps://xiking.win/2018/12/05/rocksdb-tuning/\n# 官网\nhttps://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide\n\n### LSM优化在SSD\nhttp://catkang.github.io/2017/04/30/lsm-upon-ssd.html\n\n### Features Not in LevelDB\nhttps://github.com/facebook/rocksdb/wiki/Features-Not-in-LevelDB\nPerformance\nMultithread compaction\nMultithread memtable inserts\nReduced DB mutex holding\nOptimized level-based compaction style and universal compaction style\nPrefix bloom filter\nMemtable bloom filter\nSingle bloom filter covering the whole SST file\nWrite lock optimization\nImproved Iter::Prev() performance\nFewer comparator calls during SkipList searches\nAllocate memtable memory using huge page.","slug":"RocksDB","published":1,"updated":"2019-09-28T08:51:00.936Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84u0058v1nptqyreum6","content":"<h1 id=\"RocksDB对LevelDB的优化——内联跳跃表\"><a href=\"#RocksDB对LevelDB的优化——内联跳跃表\" class=\"headerlink\" title=\"RocksDB对LevelDB的优化——内联跳跃表\"></a>RocksDB对LevelDB的优化——内联跳跃表</h1><p><a href=\"https://zhuanlan.zhihu.com/p/29277585\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/29277585</a></p>\n<h1 id=\"RocksDB参数调优\"><a href=\"#RocksDB参数调优\" class=\"headerlink\" title=\"RocksDB参数调优\"></a>RocksDB参数调优</h1><p><a href=\"https://xiking.win/2018/12/05/rocksdb-tuning/\" target=\"_blank\" rel=\"noopener\">https://xiking.win/2018/12/05/rocksdb-tuning/</a></p>\n<h1 id=\"官网\"><a href=\"#官网\" class=\"headerlink\" title=\"官网\"></a>官网</h1><p><a href=\"https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide\" target=\"_blank\" rel=\"noopener\">https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide</a></p>\n<h3 id=\"LSM优化在SSD\"><a href=\"#LSM优化在SSD\" class=\"headerlink\" title=\"LSM优化在SSD\"></a>LSM优化在SSD</h3><p><a href=\"http://catkang.github.io/2017/04/30/lsm-upon-ssd.html\" target=\"_blank\" rel=\"noopener\">http://catkang.github.io/2017/04/30/lsm-upon-ssd.html</a></p>\n<h3 id=\"Features-Not-in-LevelDB\"><a href=\"#Features-Not-in-LevelDB\" class=\"headerlink\" title=\"Features Not in LevelDB\"></a>Features Not in LevelDB</h3><p><a href=\"https://github.com/facebook/rocksdb/wiki/Features-Not-in-LevelDB\" target=\"_blank\" rel=\"noopener\">https://github.com/facebook/rocksdb/wiki/Features-Not-in-LevelDB</a><br>Performance<br>Multithread compaction<br>Multithread memtable inserts<br>Reduced DB mutex holding<br>Optimized level-based compaction style and universal compaction style<br>Prefix bloom filter<br>Memtable bloom filter<br>Single bloom filter covering the whole SST file<br>Write lock optimization<br>Improved Iter::Prev() performance<br>Fewer comparator calls during SkipList searches<br>Allocate memtable memory using huge page.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"RocksDB对LevelDB的优化——内联跳跃表\"><a href=\"#RocksDB对LevelDB的优化——内联跳跃表\" class=\"headerlink\" title=\"RocksDB对LevelDB的优化——内联跳跃表\"></a>RocksDB对LevelDB的优化——内联跳跃表</h1><p><a href=\"https://zhuanlan.zhihu.com/p/29277585\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/29277585</a></p>\n<h1 id=\"RocksDB参数调优\"><a href=\"#RocksDB参数调优\" class=\"headerlink\" title=\"RocksDB参数调优\"></a>RocksDB参数调优</h1><p><a href=\"https://xiking.win/2018/12/05/rocksdb-tuning/\" target=\"_blank\" rel=\"noopener\">https://xiking.win/2018/12/05/rocksdb-tuning/</a></p>\n<h1 id=\"官网\"><a href=\"#官网\" class=\"headerlink\" title=\"官网\"></a>官网</h1><p><a href=\"https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide\" target=\"_blank\" rel=\"noopener\">https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide</a></p>\n<h3 id=\"LSM优化在SSD\"><a href=\"#LSM优化在SSD\" class=\"headerlink\" title=\"LSM优化在SSD\"></a>LSM优化在SSD</h3><p><a href=\"http://catkang.github.io/2017/04/30/lsm-upon-ssd.html\" target=\"_blank\" rel=\"noopener\">http://catkang.github.io/2017/04/30/lsm-upon-ssd.html</a></p>\n<h3 id=\"Features-Not-in-LevelDB\"><a href=\"#Features-Not-in-LevelDB\" class=\"headerlink\" title=\"Features Not in LevelDB\"></a>Features Not in LevelDB</h3><p><a href=\"https://github.com/facebook/rocksdb/wiki/Features-Not-in-LevelDB\" target=\"_blank\" rel=\"noopener\">https://github.com/facebook/rocksdb/wiki/Features-Not-in-LevelDB</a><br>Performance<br>Multithread compaction<br>Multithread memtable inserts<br>Reduced DB mutex holding<br>Optimized level-based compaction style and universal compaction style<br>Prefix bloom filter<br>Memtable bloom filter<br>Single bloom filter covering the whole SST file<br>Write lock optimization<br>Improved Iter::Prev() performance<br>Fewer comparator calls during SkipList searches<br>Allocate memtable memory using huge page.</p>\n"},{"title":"Sofa-Jraft","date":"2019-04-02T09:03:23.000Z","_content":"\n\nhttps://tech.antfin.com/activities/382/review/712\nppt\nhttps://mp.weixin.qq.com/s/zDusnG6WJGP0EX8UmbqtxQ\n\n\n### 源码分析文章\nhttps://zhuanlan.zhihu.com/p/66355477\n\n\n### 什么是线性一致读？\n\n\n### 在写WAL时，Log的Key是什么？单纯的LogIndex应该是没法满足需求的。\n这个问题有没有问对？如果Index是严格单调递增的呢？\nLogEntry\n/** log id with index/term */\n    private LogId                id    = new LogId(0, 0);\n\n\nBatch: 我们知道互联网两大优化法宝便是 cache 和 batch，JRaft 在 batch 上花了较大心思，整个链路几乎都是 batch 的，依靠 disruptor 的 MPSC 模型批量消费，对整体性能有着极大的提升，包括但不限于：\n批量提交 task\n批量网络发送\n本地 IO batch 写入\n要保证日志不丢，一般每条 log entry 都要进行 fsync 同步刷盘，比较耗时，JRaft 中做了合并写入的优化\n批量应用到状态机 需要说明的是，虽然 JRaft 中大量使用了 batch 技巧，但对单个请求的延时并无任何影响，JRaft 中不会对请求做延时的攒批处理\n\n// 好好分析下这个Batch模型\n@Override\npublic void onEvent(LogEntryAndClosure event, long sequence, boolean endOfBatch) throws Exception {\n    if (event.shutdownLatch != null) {\n        if (!tasks.isEmpty()) {\n            executeApplyingTasks(tasks);\n        }\n        GLOBAL_NUM_NODES.decrementAndGet();\n        event.shutdownLatch.countDown();\n        return;\n    }\n\n    tasks.add(event);\n    if (tasks.size() >= raftOptions.getApplyBatch() || endOfBatch) {\n        executeApplyingTasks(tasks);\n        tasks.clear();\n    }\n}\n\n\n########### 重要代码执行过程\n## PreVote和Vote到BecomeLeader的过程\n\n## Leader收到Client请求，将日志作为WAL持久化在本地。\n## Leader在持久化成功后（可能是并发进行的），\n## Leader发送AppendEntries后，收到了大部分的确认，开始应用状态机。\n## Leader成功应用状态机，将commitIndex通过心跳传递给Follow，Follow开始应用状态机。\n\n## Follow什么时候需要被安装Snapshot，怎么安装？\n\n## 如果Leader挂了，可能有一些废弃的LocalLog，怎么Trancate掉？\n","source":"_posts/Sofa-Jraft.md","raw":"---\ntitle: Sofa-Jraft\ndate: 2019-04-02 17:03:23\ntags:\n---\n\n\nhttps://tech.antfin.com/activities/382/review/712\nppt\nhttps://mp.weixin.qq.com/s/zDusnG6WJGP0EX8UmbqtxQ\n\n\n### 源码分析文章\nhttps://zhuanlan.zhihu.com/p/66355477\n\n\n### 什么是线性一致读？\n\n\n### 在写WAL时，Log的Key是什么？单纯的LogIndex应该是没法满足需求的。\n这个问题有没有问对？如果Index是严格单调递增的呢？\nLogEntry\n/** log id with index/term */\n    private LogId                id    = new LogId(0, 0);\n\n\nBatch: 我们知道互联网两大优化法宝便是 cache 和 batch，JRaft 在 batch 上花了较大心思，整个链路几乎都是 batch 的，依靠 disruptor 的 MPSC 模型批量消费，对整体性能有着极大的提升，包括但不限于：\n批量提交 task\n批量网络发送\n本地 IO batch 写入\n要保证日志不丢，一般每条 log entry 都要进行 fsync 同步刷盘，比较耗时，JRaft 中做了合并写入的优化\n批量应用到状态机 需要说明的是，虽然 JRaft 中大量使用了 batch 技巧，但对单个请求的延时并无任何影响，JRaft 中不会对请求做延时的攒批处理\n\n// 好好分析下这个Batch模型\n@Override\npublic void onEvent(LogEntryAndClosure event, long sequence, boolean endOfBatch) throws Exception {\n    if (event.shutdownLatch != null) {\n        if (!tasks.isEmpty()) {\n            executeApplyingTasks(tasks);\n        }\n        GLOBAL_NUM_NODES.decrementAndGet();\n        event.shutdownLatch.countDown();\n        return;\n    }\n\n    tasks.add(event);\n    if (tasks.size() >= raftOptions.getApplyBatch() || endOfBatch) {\n        executeApplyingTasks(tasks);\n        tasks.clear();\n    }\n}\n\n\n########### 重要代码执行过程\n## PreVote和Vote到BecomeLeader的过程\n\n## Leader收到Client请求，将日志作为WAL持久化在本地。\n## Leader在持久化成功后（可能是并发进行的），\n## Leader发送AppendEntries后，收到了大部分的确认，开始应用状态机。\n## Leader成功应用状态机，将commitIndex通过心跳传递给Follow，Follow开始应用状态机。\n\n## Follow什么时候需要被安装Snapshot，怎么安装？\n\n## 如果Leader挂了，可能有一些废弃的LocalLog，怎么Trancate掉？\n","slug":"Sofa-Jraft","published":1,"updated":"2019-10-10T11:21:12.213Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84v0059v1nptg1bbfr8","content":"<p><a href=\"https://tech.antfin.com/activities/382/review/712\" target=\"_blank\" rel=\"noopener\">https://tech.antfin.com/activities/382/review/712</a><br>ppt<br><a href=\"https://mp.weixin.qq.com/s/zDusnG6WJGP0EX8UmbqtxQ\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/zDusnG6WJGP0EX8UmbqtxQ</a></p>\n<h3 id=\"源码分析文章\"><a href=\"#源码分析文章\" class=\"headerlink\" title=\"源码分析文章\"></a>源码分析文章</h3><p><a href=\"https://zhuanlan.zhihu.com/p/66355477\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/66355477</a></p>\n<h3 id=\"什么是线性一致读？\"><a href=\"#什么是线性一致读？\" class=\"headerlink\" title=\"什么是线性一致读？\"></a>什么是线性一致读？</h3><h3 id=\"在写WAL时，Log的Key是什么？单纯的LogIndex应该是没法满足需求的。\"><a href=\"#在写WAL时，Log的Key是什么？单纯的LogIndex应该是没法满足需求的。\" class=\"headerlink\" title=\"在写WAL时，Log的Key是什么？单纯的LogIndex应该是没法满足需求的。\"></a>在写WAL时，Log的Key是什么？单纯的LogIndex应该是没法满足需求的。</h3><p>这个问题有没有问对？如果Index是严格单调递增的呢？<br>LogEntry<br>/** log id with index/term */<br>    private LogId                id    = new LogId(0, 0);</p>\n<p>Batch: 我们知道互联网两大优化法宝便是 cache 和 batch，JRaft 在 batch 上花了较大心思，整个链路几乎都是 batch 的，依靠 disruptor 的 MPSC 模型批量消费，对整体性能有着极大的提升，包括但不限于：<br>批量提交 task<br>批量网络发送<br>本地 IO batch 写入<br>要保证日志不丢，一般每条 log entry 都要进行 fsync 同步刷盘，比较耗时，JRaft 中做了合并写入的优化<br>批量应用到状态机 需要说明的是，虽然 JRaft 中大量使用了 batch 技巧，但对单个请求的延时并无任何影响，JRaft 中不会对请求做延时的攒批处理</p>\n<p>// 好好分析下这个Batch模型<br>@Override<br>public void onEvent(LogEntryAndClosure event, long sequence, boolean endOfBatch) throws Exception {<br>    if (event.shutdownLatch != null) {<br>        if (!tasks.isEmpty()) {<br>            executeApplyingTasks(tasks);<br>        }<br>        GLOBAL_NUM_NODES.decrementAndGet();<br>        event.shutdownLatch.countDown();<br>        return;<br>    }</p>\n<pre><code>tasks.add(event);\nif (tasks.size() &gt;= raftOptions.getApplyBatch() || endOfBatch) {\n    executeApplyingTasks(tasks);\n    tasks.clear();\n}</code></pre><p>}</p>\n<p>########### 重要代码执行过程</p>\n<h2 id=\"PreVote和Vote到BecomeLeader的过程\"><a href=\"#PreVote和Vote到BecomeLeader的过程\" class=\"headerlink\" title=\"PreVote和Vote到BecomeLeader的过程\"></a>PreVote和Vote到BecomeLeader的过程</h2><h2 id=\"Leader收到Client请求，将日志作为WAL持久化在本地。\"><a href=\"#Leader收到Client请求，将日志作为WAL持久化在本地。\" class=\"headerlink\" title=\"Leader收到Client请求，将日志作为WAL持久化在本地。\"></a>Leader收到Client请求，将日志作为WAL持久化在本地。</h2><h2 id=\"Leader在持久化成功后（可能是并发进行的），\"><a href=\"#Leader在持久化成功后（可能是并发进行的），\" class=\"headerlink\" title=\"Leader在持久化成功后（可能是并发进行的），\"></a>Leader在持久化成功后（可能是并发进行的），</h2><h2 id=\"Leader发送AppendEntries后，收到了大部分的确认，开始应用状态机。\"><a href=\"#Leader发送AppendEntries后，收到了大部分的确认，开始应用状态机。\" class=\"headerlink\" title=\"Leader发送AppendEntries后，收到了大部分的确认，开始应用状态机。\"></a>Leader发送AppendEntries后，收到了大部分的确认，开始应用状态机。</h2><h2 id=\"Leader成功应用状态机，将commitIndex通过心跳传递给Follow，Follow开始应用状态机。\"><a href=\"#Leader成功应用状态机，将commitIndex通过心跳传递给Follow，Follow开始应用状态机。\" class=\"headerlink\" title=\"Leader成功应用状态机，将commitIndex通过心跳传递给Follow，Follow开始应用状态机。\"></a>Leader成功应用状态机，将commitIndex通过心跳传递给Follow，Follow开始应用状态机。</h2><h2 id=\"Follow什么时候需要被安装Snapshot，怎么安装？\"><a href=\"#Follow什么时候需要被安装Snapshot，怎么安装？\" class=\"headerlink\" title=\"Follow什么时候需要被安装Snapshot，怎么安装？\"></a>Follow什么时候需要被安装Snapshot，怎么安装？</h2><h2 id=\"如果Leader挂了，可能有一些废弃的LocalLog，怎么Trancate掉？\"><a href=\"#如果Leader挂了，可能有一些废弃的LocalLog，怎么Trancate掉？\" class=\"headerlink\" title=\"如果Leader挂了，可能有一些废弃的LocalLog，怎么Trancate掉？\"></a>如果Leader挂了，可能有一些废弃的LocalLog，怎么Trancate掉？</h2>","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://tech.antfin.com/activities/382/review/712\" target=\"_blank\" rel=\"noopener\">https://tech.antfin.com/activities/382/review/712</a><br>ppt<br><a href=\"https://mp.weixin.qq.com/s/zDusnG6WJGP0EX8UmbqtxQ\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/zDusnG6WJGP0EX8UmbqtxQ</a></p>\n<h3 id=\"源码分析文章\"><a href=\"#源码分析文章\" class=\"headerlink\" title=\"源码分析文章\"></a>源码分析文章</h3><p><a href=\"https://zhuanlan.zhihu.com/p/66355477\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/66355477</a></p>\n<h3 id=\"什么是线性一致读？\"><a href=\"#什么是线性一致读？\" class=\"headerlink\" title=\"什么是线性一致读？\"></a>什么是线性一致读？</h3><h3 id=\"在写WAL时，Log的Key是什么？单纯的LogIndex应该是没法满足需求的。\"><a href=\"#在写WAL时，Log的Key是什么？单纯的LogIndex应该是没法满足需求的。\" class=\"headerlink\" title=\"在写WAL时，Log的Key是什么？单纯的LogIndex应该是没法满足需求的。\"></a>在写WAL时，Log的Key是什么？单纯的LogIndex应该是没法满足需求的。</h3><p>这个问题有没有问对？如果Index是严格单调递增的呢？<br>LogEntry<br>/** log id with index/term */<br>    private LogId                id    = new LogId(0, 0);</p>\n<p>Batch: 我们知道互联网两大优化法宝便是 cache 和 batch，JRaft 在 batch 上花了较大心思，整个链路几乎都是 batch 的，依靠 disruptor 的 MPSC 模型批量消费，对整体性能有着极大的提升，包括但不限于：<br>批量提交 task<br>批量网络发送<br>本地 IO batch 写入<br>要保证日志不丢，一般每条 log entry 都要进行 fsync 同步刷盘，比较耗时，JRaft 中做了合并写入的优化<br>批量应用到状态机 需要说明的是，虽然 JRaft 中大量使用了 batch 技巧，但对单个请求的延时并无任何影响，JRaft 中不会对请求做延时的攒批处理</p>\n<p>// 好好分析下这个Batch模型<br>@Override<br>public void onEvent(LogEntryAndClosure event, long sequence, boolean endOfBatch) throws Exception {<br>    if (event.shutdownLatch != null) {<br>        if (!tasks.isEmpty()) {<br>            executeApplyingTasks(tasks);<br>        }<br>        GLOBAL_NUM_NODES.decrementAndGet();<br>        event.shutdownLatch.countDown();<br>        return;<br>    }</p>\n<pre><code>tasks.add(event);\nif (tasks.size() &gt;= raftOptions.getApplyBatch() || endOfBatch) {\n    executeApplyingTasks(tasks);\n    tasks.clear();\n}</code></pre><p>}</p>\n<p>########### 重要代码执行过程</p>\n<h2 id=\"PreVote和Vote到BecomeLeader的过程\"><a href=\"#PreVote和Vote到BecomeLeader的过程\" class=\"headerlink\" title=\"PreVote和Vote到BecomeLeader的过程\"></a>PreVote和Vote到BecomeLeader的过程</h2><h2 id=\"Leader收到Client请求，将日志作为WAL持久化在本地。\"><a href=\"#Leader收到Client请求，将日志作为WAL持久化在本地。\" class=\"headerlink\" title=\"Leader收到Client请求，将日志作为WAL持久化在本地。\"></a>Leader收到Client请求，将日志作为WAL持久化在本地。</h2><h2 id=\"Leader在持久化成功后（可能是并发进行的），\"><a href=\"#Leader在持久化成功后（可能是并发进行的），\" class=\"headerlink\" title=\"Leader在持久化成功后（可能是并发进行的），\"></a>Leader在持久化成功后（可能是并发进行的），</h2><h2 id=\"Leader发送AppendEntries后，收到了大部分的确认，开始应用状态机。\"><a href=\"#Leader发送AppendEntries后，收到了大部分的确认，开始应用状态机。\" class=\"headerlink\" title=\"Leader发送AppendEntries后，收到了大部分的确认，开始应用状态机。\"></a>Leader发送AppendEntries后，收到了大部分的确认，开始应用状态机。</h2><h2 id=\"Leader成功应用状态机，将commitIndex通过心跳传递给Follow，Follow开始应用状态机。\"><a href=\"#Leader成功应用状态机，将commitIndex通过心跳传递给Follow，Follow开始应用状态机。\" class=\"headerlink\" title=\"Leader成功应用状态机，将commitIndex通过心跳传递给Follow，Follow开始应用状态机。\"></a>Leader成功应用状态机，将commitIndex通过心跳传递给Follow，Follow开始应用状态机。</h2><h2 id=\"Follow什么时候需要被安装Snapshot，怎么安装？\"><a href=\"#Follow什么时候需要被安装Snapshot，怎么安装？\" class=\"headerlink\" title=\"Follow什么时候需要被安装Snapshot，怎么安装？\"></a>Follow什么时候需要被安装Snapshot，怎么安装？</h2><h2 id=\"如果Leader挂了，可能有一些废弃的LocalLog，怎么Trancate掉？\"><a href=\"#如果Leader挂了，可能有一些废弃的LocalLog，怎么Trancate掉？\" class=\"headerlink\" title=\"如果Leader挂了，可能有一些废弃的LocalLog，怎么Trancate掉？\"></a>如果Leader挂了，可能有一些废弃的LocalLog，怎么Trancate掉？</h2>"},{"title":"Serialization-Hessian","date":"2017-12-05T02:35:33.000Z","_content":"\nhttp://www.jianshu.com/p/e800d8af4e22\n\nhttp://hessian.caucho.com/doc/hessian-serialization.html","source":"_posts/Serialization-Hessian.md","raw":"---\ntitle: Serialization-Hessian\ndate: 2017-12-05 10:35:33\ntags: 序列化\n---\n\nhttp://www.jianshu.com/p/e800d8af4e22\n\nhttp://hessian.caucho.com/doc/hessian-serialization.html","slug":"Serialization-Hessian","published":1,"updated":"2019-09-28T08:51:00.936Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84v005av1np982j10fr","content":"<p><a href=\"http://www.jianshu.com/p/e800d8af4e22\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/e800d8af4e22</a></p>\n<p><a href=\"http://hessian.caucho.com/doc/hessian-serialization.html\" target=\"_blank\" rel=\"noopener\">http://hessian.caucho.com/doc/hessian-serialization.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://www.jianshu.com/p/e800d8af4e22\" target=\"_blank\" rel=\"noopener\">http://www.jianshu.com/p/e800d8af4e22</a></p>\n<p><a href=\"http://hessian.caucho.com/doc/hessian-serialization.html\" target=\"_blank\" rel=\"noopener\">http://hessian.caucho.com/doc/hessian-serialization.html</a></p>\n"},{"title":"SourceCode-AbstractQueuedSynchronizer","date":"2017-12-03T03:15:58.000Z","_content":"\n\n\nAQS使用一个int类型的成员变量state来表示同步状态，当`state > 0`时表示已经获取了锁，当`state = 0`时表示释放了锁。它提供了三个方法（getState()、setState(int newState)、compareAndSetState(int expect,int update)）来对同步状态state进行操作，当然AQS可以确保对state的操作是安全的。\nAQS通过内置的FIFO同步队列来完成资源获取线程的排队工作，如果当前线程获取同步状态失败（锁）时，AQS则会将当前线程以及等待状态等信息构造成一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，则会把节点中的线程唤醒，使其再次尝试获取同步状态。\n\nhttp://guochenglai.com/2016/06/06/java-concurrent5-aqs-code-analysis/\n\n### 基于AQS的公平与非公平锁设计\n\n### fair\n\n严格的先来先到，如果有人来排队，不能插队，一定要排到队尾！！\n\n### nonfair\n\n总体是先来先到，但新来的可以在队头进行插队\n\n``` java\nfinal void lock() {\n    if (compareAndSetState(0, 1))\n        setExclusiveOwnerThread(Thread.currentThread());\n    else\n         acquire(1);\n }\n```\n\n``` java\n/**\n * Releases in exclusive mode.  Implemented by unblocking one or\n * more threads if {@link #tryRelease} returns true.\n * This method can be used to implement method {@link Lock#unlock}.\n *\n * @param arg the release argument.  This value is conveyed to\n *        {@link #tryRelease} but is otherwise uninterpreted and\n *        can represent anything you like.\n * @return the value returned from {@link #tryRelease}\n */\npublic final boolean release(int arg) {\n    if (tryRelease(arg)) {\n        Node h = head;\n        if (h != null && h.waitStatus != 0)\n            unparkSuccessor(h);\n        return true;\n    }\n    return false;\n}\n```\n\n\n### 基于AQS的倒计时锁设计\n\n### 基于AQS的semaphore设计\n\n\n\n\n\n### 很好的文章\nhttp://blog.csdn.net/hengyunabc/article/details/28126139\n\npark和unpark的灵活之处\n上面已经提到，unpark函数可以先于park调用，这个正是它们的灵活之处。\n\n一个线程它有可能在别的线程unPark之前，或者之后，或者同时调用了park，那么因为park的特性，它可以不用担心自己的park的时序问题，否则，如果park必须要在unpark之前，那么给编程带来很大的麻烦！！\n\n考虑一下，两个线程同步，要如何处理？\n\n在Java5里是用wait/notify/notifyAll来同步的。wait/notify机制有个很蛋疼的地方是，比如线程B要用notify通知线程A，那么线程B要确保线程A已经在wait调用上等待了，否则线程A可能永远都在等待。编程的时候就会很蛋疼。\n\n另外，是调用notify，还是notifyAll？\n\nnotify只会唤醒一个线程，如果错误地有两个线程在同一个对象上wait等待，那么又悲剧了。为了安全起见，貌似只能调用notifyAll了。\n\npark/unpark模型真正解耦了线程之间的同步，线程之间不再需要一个Object或者其它变量来存储状态，不再需要关心对方的状态。\n\nHotSpot里park/unpark的实现\n\n每个java线程都有一个Parker实例，Parker类是这样定义的：\n\n``` C++ \nclass Parker : public os::PlatformParker {  \nprivate:  \n  volatile int _counter ;  \n  ...  \npublic:  \n  void park(bool isAbsolute, jlong time);  \n  void unpark();  \n  ...  \n}  \nclass PlatformParker : public CHeapObj<mtInternal> {  \n  protected:  \n    pthread_mutex_t _mutex [1] ;  \n    pthread_cond_t  _cond  [1] ;  \n    ...  \n} \n```","source":"_posts/SourceCode-AbstractQueuedSynchronizer.md","raw":"---\ntitle: SourceCode-AbstractQueuedSynchronizer\ndate: 2017-12-03 11:15:58\ntags: 源码分析\n---\n\n\n\nAQS使用一个int类型的成员变量state来表示同步状态，当`state > 0`时表示已经获取了锁，当`state = 0`时表示释放了锁。它提供了三个方法（getState()、setState(int newState)、compareAndSetState(int expect,int update)）来对同步状态state进行操作，当然AQS可以确保对state的操作是安全的。\nAQS通过内置的FIFO同步队列来完成资源获取线程的排队工作，如果当前线程获取同步状态失败（锁）时，AQS则会将当前线程以及等待状态等信息构造成一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，则会把节点中的线程唤醒，使其再次尝试获取同步状态。\n\nhttp://guochenglai.com/2016/06/06/java-concurrent5-aqs-code-analysis/\n\n### 基于AQS的公平与非公平锁设计\n\n### fair\n\n严格的先来先到，如果有人来排队，不能插队，一定要排到队尾！！\n\n### nonfair\n\n总体是先来先到，但新来的可以在队头进行插队\n\n``` java\nfinal void lock() {\n    if (compareAndSetState(0, 1))\n        setExclusiveOwnerThread(Thread.currentThread());\n    else\n         acquire(1);\n }\n```\n\n``` java\n/**\n * Releases in exclusive mode.  Implemented by unblocking one or\n * more threads if {@link #tryRelease} returns true.\n * This method can be used to implement method {@link Lock#unlock}.\n *\n * @param arg the release argument.  This value is conveyed to\n *        {@link #tryRelease} but is otherwise uninterpreted and\n *        can represent anything you like.\n * @return the value returned from {@link #tryRelease}\n */\npublic final boolean release(int arg) {\n    if (tryRelease(arg)) {\n        Node h = head;\n        if (h != null && h.waitStatus != 0)\n            unparkSuccessor(h);\n        return true;\n    }\n    return false;\n}\n```\n\n\n### 基于AQS的倒计时锁设计\n\n### 基于AQS的semaphore设计\n\n\n\n\n\n### 很好的文章\nhttp://blog.csdn.net/hengyunabc/article/details/28126139\n\npark和unpark的灵活之处\n上面已经提到，unpark函数可以先于park调用，这个正是它们的灵活之处。\n\n一个线程它有可能在别的线程unPark之前，或者之后，或者同时调用了park，那么因为park的特性，它可以不用担心自己的park的时序问题，否则，如果park必须要在unpark之前，那么给编程带来很大的麻烦！！\n\n考虑一下，两个线程同步，要如何处理？\n\n在Java5里是用wait/notify/notifyAll来同步的。wait/notify机制有个很蛋疼的地方是，比如线程B要用notify通知线程A，那么线程B要确保线程A已经在wait调用上等待了，否则线程A可能永远都在等待。编程的时候就会很蛋疼。\n\n另外，是调用notify，还是notifyAll？\n\nnotify只会唤醒一个线程，如果错误地有两个线程在同一个对象上wait等待，那么又悲剧了。为了安全起见，貌似只能调用notifyAll了。\n\npark/unpark模型真正解耦了线程之间的同步，线程之间不再需要一个Object或者其它变量来存储状态，不再需要关心对方的状态。\n\nHotSpot里park/unpark的实现\n\n每个java线程都有一个Parker实例，Parker类是这样定义的：\n\n``` C++ \nclass Parker : public os::PlatformParker {  \nprivate:  \n  volatile int _counter ;  \n  ...  \npublic:  \n  void park(bool isAbsolute, jlong time);  \n  void unpark();  \n  ...  \n}  \nclass PlatformParker : public CHeapObj<mtInternal> {  \n  protected:  \n    pthread_mutex_t _mutex [1] ;  \n    pthread_cond_t  _cond  [1] ;  \n    ...  \n} \n```","slug":"SourceCode-AbstractQueuedSynchronizer","published":1,"updated":"2019-09-28T08:51:00.989Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84w005bv1npzzf0hwp3","content":"<p>AQS使用一个int类型的成员变量state来表示同步状态，当<code>state &gt; 0</code>时表示已经获取了锁，当<code>state = 0</code>时表示释放了锁。它提供了三个方法（getState()、setState(int newState)、compareAndSetState(int expect,int update)）来对同步状态state进行操作，当然AQS可以确保对state的操作是安全的。<br>AQS通过内置的FIFO同步队列来完成资源获取线程的排队工作，如果当前线程获取同步状态失败（锁）时，AQS则会将当前线程以及等待状态等信息构造成一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，则会把节点中的线程唤醒，使其再次尝试获取同步状态。</p>\n<p><a href=\"http://guochenglai.com/2016/06/06/java-concurrent5-aqs-code-analysis/\" target=\"_blank\" rel=\"noopener\">http://guochenglai.com/2016/06/06/java-concurrent5-aqs-code-analysis/</a></p>\n<h3 id=\"基于AQS的公平与非公平锁设计\"><a href=\"#基于AQS的公平与非公平锁设计\" class=\"headerlink\" title=\"基于AQS的公平与非公平锁设计\"></a>基于AQS的公平与非公平锁设计</h3><h3 id=\"fair\"><a href=\"#fair\" class=\"headerlink\" title=\"fair\"></a>fair</h3><p>严格的先来先到，如果有人来排队，不能插队，一定要排到队尾！！</p>\n<h3 id=\"nonfair\"><a href=\"#nonfair\" class=\"headerlink\" title=\"nonfair\"></a>nonfair</h3><p>总体是先来先到，但新来的可以在队头进行插队</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">lock</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (compareAndSetState(<span class=\"number\">0</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">        setExclusiveOwnerThread(Thread.currentThread());</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">         acquire(<span class=\"number\">1</span>);</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Releases in exclusive mode.  Implemented by unblocking one or</span></span><br><span class=\"line\"><span class=\"comment\"> * more threads if &#123;<span class=\"doctag\">@link</span> #tryRelease&#125; returns true.</span></span><br><span class=\"line\"><span class=\"comment\"> * This method can be used to implement method &#123;<span class=\"doctag\">@link</span> Lock#unlock&#125;.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span> arg the release argument.  This value is conveyed to</span></span><br><span class=\"line\"><span class=\"comment\"> *        &#123;<span class=\"doctag\">@link</span> #tryRelease&#125; but is otherwise uninterpreted and</span></span><br><span class=\"line\"><span class=\"comment\"> *        can represent anything you like.</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@return</span> the value returned from &#123;<span class=\"doctag\">@link</span> #tryRelease&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">boolean</span> <span class=\"title\">release</span><span class=\"params\">(<span class=\"keyword\">int</span> arg)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (tryRelease(arg)) &#123;</span><br><span class=\"line\">        Node h = head;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (h != <span class=\"keyword\">null</span> &amp;&amp; h.waitStatus != <span class=\"number\">0</span>)</span><br><span class=\"line\">            unparkSuccessor(h);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"基于AQS的倒计时锁设计\"><a href=\"#基于AQS的倒计时锁设计\" class=\"headerlink\" title=\"基于AQS的倒计时锁设计\"></a>基于AQS的倒计时锁设计</h3><h3 id=\"基于AQS的semaphore设计\"><a href=\"#基于AQS的semaphore设计\" class=\"headerlink\" title=\"基于AQS的semaphore设计\"></a>基于AQS的semaphore设计</h3><h3 id=\"很好的文章\"><a href=\"#很好的文章\" class=\"headerlink\" title=\"很好的文章\"></a>很好的文章</h3><p><a href=\"http://blog.csdn.net/hengyunabc/article/details/28126139\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/hengyunabc/article/details/28126139</a></p>\n<p>park和unpark的灵活之处<br>上面已经提到，unpark函数可以先于park调用，这个正是它们的灵活之处。</p>\n<p>一个线程它有可能在别的线程unPark之前，或者之后，或者同时调用了park，那么因为park的特性，它可以不用担心自己的park的时序问题，否则，如果park必须要在unpark之前，那么给编程带来很大的麻烦！！</p>\n<p>考虑一下，两个线程同步，要如何处理？</p>\n<p>在Java5里是用wait/notify/notifyAll来同步的。wait/notify机制有个很蛋疼的地方是，比如线程B要用notify通知线程A，那么线程B要确保线程A已经在wait调用上等待了，否则线程A可能永远都在等待。编程的时候就会很蛋疼。</p>\n<p>另外，是调用notify，还是notifyAll？</p>\n<p>notify只会唤醒一个线程，如果错误地有两个线程在同一个对象上wait等待，那么又悲剧了。为了安全起见，貌似只能调用notifyAll了。</p>\n<p>park/unpark模型真正解耦了线程之间的同步，线程之间不再需要一个Object或者其它变量来存储状态，不再需要关心对方的状态。</p>\n<p>HotSpot里park/unpark的实现</p>\n<p>每个java线程都有一个Parker实例，Parker类是这样定义的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Parker</span> :</span> <span class=\"keyword\">public</span> os::PlatformParker &#123;  </span><br><span class=\"line\"><span class=\"keyword\">private</span>:  </span><br><span class=\"line\">  <span class=\"keyword\">volatile</span> <span class=\"keyword\">int</span> _counter ;  </span><br><span class=\"line\">  ...  </span><br><span class=\"line\"><span class=\"keyword\">public</span>:  </span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">park</span><span class=\"params\">(<span class=\"keyword\">bool</span> isAbsolute, jlong time)</span></span>;  </span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">unpark</span><span class=\"params\">()</span></span>;  </span><br><span class=\"line\">  ...  </span><br><span class=\"line\">&#125;  </span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PlatformParker</span> :</span> <span class=\"keyword\">public</span> CHeapObj&lt;mtInternal&gt; &#123;  </span><br><span class=\"line\">  <span class=\"keyword\">protected</span>:  </span><br><span class=\"line\">    <span class=\"keyword\">pthread_mutex_t</span> _mutex [<span class=\"number\">1</span>] ;  </span><br><span class=\"line\">    <span class=\"keyword\">pthread_cond_t</span>  _cond  [<span class=\"number\">1</span>] ;  </span><br><span class=\"line\">    ...  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p>AQS使用一个int类型的成员变量state来表示同步状态，当<code>state &gt; 0</code>时表示已经获取了锁，当<code>state = 0</code>时表示释放了锁。它提供了三个方法（getState()、setState(int newState)、compareAndSetState(int expect,int update)）来对同步状态state进行操作，当然AQS可以确保对state的操作是安全的。<br>AQS通过内置的FIFO同步队列来完成资源获取线程的排队工作，如果当前线程获取同步状态失败（锁）时，AQS则会将当前线程以及等待状态等信息构造成一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，则会把节点中的线程唤醒，使其再次尝试获取同步状态。</p>\n<p><a href=\"http://guochenglai.com/2016/06/06/java-concurrent5-aqs-code-analysis/\" target=\"_blank\" rel=\"noopener\">http://guochenglai.com/2016/06/06/java-concurrent5-aqs-code-analysis/</a></p>\n<h3 id=\"基于AQS的公平与非公平锁设计\"><a href=\"#基于AQS的公平与非公平锁设计\" class=\"headerlink\" title=\"基于AQS的公平与非公平锁设计\"></a>基于AQS的公平与非公平锁设计</h3><h3 id=\"fair\"><a href=\"#fair\" class=\"headerlink\" title=\"fair\"></a>fair</h3><p>严格的先来先到，如果有人来排队，不能插队，一定要排到队尾！！</p>\n<h3 id=\"nonfair\"><a href=\"#nonfair\" class=\"headerlink\" title=\"nonfair\"></a>nonfair</h3><p>总体是先来先到，但新来的可以在队头进行插队</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">lock</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (compareAndSetState(<span class=\"number\">0</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">        setExclusiveOwnerThread(Thread.currentThread());</span><br><span class=\"line\">    <span class=\"keyword\">else</span></span><br><span class=\"line\">         acquire(<span class=\"number\">1</span>);</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Releases in exclusive mode.  Implemented by unblocking one or</span></span><br><span class=\"line\"><span class=\"comment\"> * more threads if &#123;<span class=\"doctag\">@link</span> #tryRelease&#125; returns true.</span></span><br><span class=\"line\"><span class=\"comment\"> * This method can be used to implement method &#123;<span class=\"doctag\">@link</span> Lock#unlock&#125;.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span> arg the release argument.  This value is conveyed to</span></span><br><span class=\"line\"><span class=\"comment\"> *        &#123;<span class=\"doctag\">@link</span> #tryRelease&#125; but is otherwise uninterpreted and</span></span><br><span class=\"line\"><span class=\"comment\"> *        can represent anything you like.</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@return</span> the value returned from &#123;<span class=\"doctag\">@link</span> #tryRelease&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">boolean</span> <span class=\"title\">release</span><span class=\"params\">(<span class=\"keyword\">int</span> arg)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (tryRelease(arg)) &#123;</span><br><span class=\"line\">        Node h = head;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (h != <span class=\"keyword\">null</span> &amp;&amp; h.waitStatus != <span class=\"number\">0</span>)</span><br><span class=\"line\">            unparkSuccessor(h);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">false</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"基于AQS的倒计时锁设计\"><a href=\"#基于AQS的倒计时锁设计\" class=\"headerlink\" title=\"基于AQS的倒计时锁设计\"></a>基于AQS的倒计时锁设计</h3><h3 id=\"基于AQS的semaphore设计\"><a href=\"#基于AQS的semaphore设计\" class=\"headerlink\" title=\"基于AQS的semaphore设计\"></a>基于AQS的semaphore设计</h3><h3 id=\"很好的文章\"><a href=\"#很好的文章\" class=\"headerlink\" title=\"很好的文章\"></a>很好的文章</h3><p><a href=\"http://blog.csdn.net/hengyunabc/article/details/28126139\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/hengyunabc/article/details/28126139</a></p>\n<p>park和unpark的灵活之处<br>上面已经提到，unpark函数可以先于park调用，这个正是它们的灵活之处。</p>\n<p>一个线程它有可能在别的线程unPark之前，或者之后，或者同时调用了park，那么因为park的特性，它可以不用担心自己的park的时序问题，否则，如果park必须要在unpark之前，那么给编程带来很大的麻烦！！</p>\n<p>考虑一下，两个线程同步，要如何处理？</p>\n<p>在Java5里是用wait/notify/notifyAll来同步的。wait/notify机制有个很蛋疼的地方是，比如线程B要用notify通知线程A，那么线程B要确保线程A已经在wait调用上等待了，否则线程A可能永远都在等待。编程的时候就会很蛋疼。</p>\n<p>另外，是调用notify，还是notifyAll？</p>\n<p>notify只会唤醒一个线程，如果错误地有两个线程在同一个对象上wait等待，那么又悲剧了。为了安全起见，貌似只能调用notifyAll了。</p>\n<p>park/unpark模型真正解耦了线程之间的同步，线程之间不再需要一个Object或者其它变量来存储状态，不再需要关心对方的状态。</p>\n<p>HotSpot里park/unpark的实现</p>\n<p>每个java线程都有一个Parker实例，Parker类是这样定义的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Parker</span> :</span> <span class=\"keyword\">public</span> os::PlatformParker &#123;  </span><br><span class=\"line\"><span class=\"keyword\">private</span>:  </span><br><span class=\"line\">  <span class=\"keyword\">volatile</span> <span class=\"keyword\">int</span> _counter ;  </span><br><span class=\"line\">  ...  </span><br><span class=\"line\"><span class=\"keyword\">public</span>:  </span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">park</span><span class=\"params\">(<span class=\"keyword\">bool</span> isAbsolute, jlong time)</span></span>;  </span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">unpark</span><span class=\"params\">()</span></span>;  </span><br><span class=\"line\">  ...  </span><br><span class=\"line\">&#125;  </span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PlatformParker</span> :</span> <span class=\"keyword\">public</span> CHeapObj&lt;mtInternal&gt; &#123;  </span><br><span class=\"line\">  <span class=\"keyword\">protected</span>:  </span><br><span class=\"line\">    <span class=\"keyword\">pthread_mutex_t</span> _mutex [<span class=\"number\">1</span>] ;  </span><br><span class=\"line\">    <span class=\"keyword\">pthread_cond_t</span>  _cond  [<span class=\"number\">1</span>] ;  </span><br><span class=\"line\">    ...  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"SourceCode-Map","date":"2017-11-12T13:54:26.000Z","_content":"\nhttp://www.importnew.com/26049.html\nConcurrentHashMap\n\nJDK ConcurrentHashMap如何提高并发度\nconcurrenthashmap在读写并发的时候，什么时候可见，什么时候不可见\n\nhttp://pettyandydog.com/2016/08/28/HashMap_infinite_loop/#more\nHashMap\n\nHashMap\n\n### HashMap resize() 扩容\nhttps://blog.csdn.net/aichuanwendang/article/details/53317351\n\nHashMap的工作原理是什么\nhashmap在 扩容 时为什么是乘以2. newCap = oldCap << 1 ，看看是不是和旧数据在新的Map中是否要产生偏移相关，不然所有的数据都挤在数组的前段。\n内部的数据结构是什么\nHashMap 的 table的容量如何确定？loadFactor 是什么？ 该容量如何变化？这种变化会带来什么问题？\nHashMap 实现的数据结构是什么？如何实现\nHashMap 和 HashTable、ConcurrentHashMap 的区别\nHashMap的遍历方式及效率\nHashMap、LinkedMap、TreeMap的区别\n如何决定选用HashMap还是TreeMap\n如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办\nHashMap 是线程安全的吗？并发下使用的 Map 是什么，它们内部原理分别是什么，比如存储方式、 hashcode、扩容、 默认容量等\n\nJDK1.8 中 concurrentHashMap 在扩容的时候是怎么做的，如何提高效率的，什么时候是多线程执行，什么时候单线程执行，如果某个线程正在扩容一个槽里的数据，如何保证后续线程不会重复计算。面蚂蚁金服暑期实习生的时候遇到的。\n\n分段锁\nhttp://guochenglai.com/2016/06/04/java-concurrent4-java-subsection-decompose/\n\n\n\n线程池源码分析： ExecutorService  定时任务怎么实现的？提交给线程池的任务实现runnable，线程执行完它就dead了，怎么做到线程复用的？","source":"_posts/SourceCode-Map.md","raw":"---\ntitle: SourceCode-Map\ndate: 2017-11-12 21:54:26\ntags: 源码分析\n---\n\nhttp://www.importnew.com/26049.html\nConcurrentHashMap\n\nJDK ConcurrentHashMap如何提高并发度\nconcurrenthashmap在读写并发的时候，什么时候可见，什么时候不可见\n\nhttp://pettyandydog.com/2016/08/28/HashMap_infinite_loop/#more\nHashMap\n\nHashMap\n\n### HashMap resize() 扩容\nhttps://blog.csdn.net/aichuanwendang/article/details/53317351\n\nHashMap的工作原理是什么\nhashmap在 扩容 时为什么是乘以2. newCap = oldCap << 1 ，看看是不是和旧数据在新的Map中是否要产生偏移相关，不然所有的数据都挤在数组的前段。\n内部的数据结构是什么\nHashMap 的 table的容量如何确定？loadFactor 是什么？ 该容量如何变化？这种变化会带来什么问题？\nHashMap 实现的数据结构是什么？如何实现\nHashMap 和 HashTable、ConcurrentHashMap 的区别\nHashMap的遍历方式及效率\nHashMap、LinkedMap、TreeMap的区别\n如何决定选用HashMap还是TreeMap\n如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办\nHashMap 是线程安全的吗？并发下使用的 Map 是什么，它们内部原理分别是什么，比如存储方式、 hashcode、扩容、 默认容量等\n\nJDK1.8 中 concurrentHashMap 在扩容的时候是怎么做的，如何提高效率的，什么时候是多线程执行，什么时候单线程执行，如果某个线程正在扩容一个槽里的数据，如何保证后续线程不会重复计算。面蚂蚁金服暑期实习生的时候遇到的。\n\n分段锁\nhttp://guochenglai.com/2016/06/04/java-concurrent4-java-subsection-decompose/\n\n\n\n线程池源码分析： ExecutorService  定时任务怎么实现的？提交给线程池的任务实现runnable，线程执行完它就dead了，怎么做到线程复用的？","slug":"SourceCode-Map","published":1,"updated":"2019-09-28T08:51:00.989Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84w005cv1npr74jwyda","content":"<p><a href=\"http://www.importnew.com/26049.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/26049.html</a><br>ConcurrentHashMap</p>\n<p>JDK ConcurrentHashMap如何提高并发度<br>concurrenthashmap在读写并发的时候，什么时候可见，什么时候不可见</p>\n<p><a href=\"http://pettyandydog.com/2016/08/28/HashMap_infinite_loop/#more\" target=\"_blank\" rel=\"noopener\">http://pettyandydog.com/2016/08/28/HashMap_infinite_loop/#more</a><br>HashMap</p>\n<p>HashMap</p>\n<h3 id=\"HashMap-resize-扩容\"><a href=\"#HashMap-resize-扩容\" class=\"headerlink\" title=\"HashMap resize() 扩容\"></a>HashMap resize() 扩容</h3><p><a href=\"https://blog.csdn.net/aichuanwendang/article/details/53317351\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/aichuanwendang/article/details/53317351</a></p>\n<p>HashMap的工作原理是什么<br>hashmap在 扩容 时为什么是乘以2. newCap = oldCap &lt;&lt; 1 ，看看是不是和旧数据在新的Map中是否要产生偏移相关，不然所有的数据都挤在数组的前段。<br>内部的数据结构是什么<br>HashMap 的 table的容量如何确定？loadFactor 是什么？ 该容量如何变化？这种变化会带来什么问题？<br>HashMap 实现的数据结构是什么？如何实现<br>HashMap 和 HashTable、ConcurrentHashMap 的区别<br>HashMap的遍历方式及效率<br>HashMap、LinkedMap、TreeMap的区别<br>如何决定选用HashMap还是TreeMap<br>如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办<br>HashMap 是线程安全的吗？并发下使用的 Map 是什么，它们内部原理分别是什么，比如存储方式、 hashcode、扩容、 默认容量等</p>\n<p>JDK1.8 中 concurrentHashMap 在扩容的时候是怎么做的，如何提高效率的，什么时候是多线程执行，什么时候单线程执行，如果某个线程正在扩容一个槽里的数据，如何保证后续线程不会重复计算。面蚂蚁金服暑期实习生的时候遇到的。</p>\n<p>分段锁<br><a href=\"http://guochenglai.com/2016/06/04/java-concurrent4-java-subsection-decompose/\" target=\"_blank\" rel=\"noopener\">http://guochenglai.com/2016/06/04/java-concurrent4-java-subsection-decompose/</a></p>\n<p>线程池源码分析： ExecutorService  定时任务怎么实现的？提交给线程池的任务实现runnable，线程执行完它就dead了，怎么做到线程复用的？</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://www.importnew.com/26049.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/26049.html</a><br>ConcurrentHashMap</p>\n<p>JDK ConcurrentHashMap如何提高并发度<br>concurrenthashmap在读写并发的时候，什么时候可见，什么时候不可见</p>\n<p><a href=\"http://pettyandydog.com/2016/08/28/HashMap_infinite_loop/#more\" target=\"_blank\" rel=\"noopener\">http://pettyandydog.com/2016/08/28/HashMap_infinite_loop/#more</a><br>HashMap</p>\n<p>HashMap</p>\n<h3 id=\"HashMap-resize-扩容\"><a href=\"#HashMap-resize-扩容\" class=\"headerlink\" title=\"HashMap resize() 扩容\"></a>HashMap resize() 扩容</h3><p><a href=\"https://blog.csdn.net/aichuanwendang/article/details/53317351\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/aichuanwendang/article/details/53317351</a></p>\n<p>HashMap的工作原理是什么<br>hashmap在 扩容 时为什么是乘以2. newCap = oldCap &lt;&lt; 1 ，看看是不是和旧数据在新的Map中是否要产生偏移相关，不然所有的数据都挤在数组的前段。<br>内部的数据结构是什么<br>HashMap 的 table的容量如何确定？loadFactor 是什么？ 该容量如何变化？这种变化会带来什么问题？<br>HashMap 实现的数据结构是什么？如何实现<br>HashMap 和 HashTable、ConcurrentHashMap 的区别<br>HashMap的遍历方式及效率<br>HashMap、LinkedMap、TreeMap的区别<br>如何决定选用HashMap还是TreeMap<br>如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办<br>HashMap 是线程安全的吗？并发下使用的 Map 是什么，它们内部原理分别是什么，比如存储方式、 hashcode、扩容、 默认容量等</p>\n<p>JDK1.8 中 concurrentHashMap 在扩容的时候是怎么做的，如何提高效率的，什么时候是多线程执行，什么时候单线程执行，如果某个线程正在扩容一个槽里的数据，如何保证后续线程不会重复计算。面蚂蚁金服暑期实习生的时候遇到的。</p>\n<p>分段锁<br><a href=\"http://guochenglai.com/2016/06/04/java-concurrent4-java-subsection-decompose/\" target=\"_blank\" rel=\"noopener\">http://guochenglai.com/2016/06/04/java-concurrent4-java-subsection-decompose/</a></p>\n<p>线程池源码分析： ExecutorService  定时任务怎么实现的？提交给线程池的任务实现runnable，线程执行完它就dead了，怎么做到线程复用的？</p>\n"},{"title":"TCP-Protocol-Analyzer","date":"2017-12-22T01:54:47.000Z","_content":"\nhttp://blog.csdn.net/q1007729991/article/details/70154359\n\nhttps://www.jianshu.com/p/83ff61d074bf\n\n在RocketMQ中，netty的Server端配置如下，显然，作者是有意多配置了几个TCP的参数\n``` java\nServerBootstrap childHandler =\n            this.serverBootstrap.group(this.eventLoopGroupBoss, this.eventLoopGroupSelector)\n                .channel(useEpoll() ? EpollServerSocketChannel.class : NioServerSocketChannel.class)\n                .option(ChannelOption.SO_BACKLOG, 1024)\n                .option(ChannelOption.SO_REUSEADDR, true)\n                .option(ChannelOption.SO_KEEPALIVE, false)\n                .childOption(ChannelOption.TCP_NODELAY, true)\n                .childOption(ChannelOption.SO_SNDBUF, nettyServerConfig.getServerSocketSndBufSize())\n                .childOption(ChannelOption.SO_RCVBUF, nettyServerConfig.getServerSocketRcvBufSize())\n                .localAddress(new InetSocketAddress(this.nettyServerConfig.getListenPort()))\n                .childHandler(new ChannelInitializer<SocketChannel>() {\n                    @Override\n                    public void initChannel(SocketChannel ch) throws Exception {\n                        ch.pipeline().addLast(\n                            defaultEventExecutorGroup,\n                            new NettyEncoder(),\n                            new NettyDecoder(),\n                            new IdleStateHandler(0, 0, nettyServerConfig.getServerChannelMaxIdleTimeSeconds()),\n                            new NettyConnectManageHandler(),\n                            new NettyServerHandler());\n                    }\n                });\n```\n\n带着这个疑问，让我们来看看，到底这些参数在TCP中是什么意思？以及如何调节参数才能提高应用的性能。\n\n\n用golang实现了一个MySQL Proxy，在做负载测试时，尝试用benchyou200连接向系统发送select * from xxx limit 10000的SQL，中途将benchyou关闭（ctrl+c），结果在Proxy端留下了大量[CLOSE-WAIT]的连接没有释放。\n```\n[nanxing@zerodb-proxy003 zeroproxy]$ ss |grep 9696\ntcp    ESTAB      0      0      10.12.1.62:59696                10.12.1.69:mysql                \ntcp    ESTAB      0      0      10.12.1.62:39696                10.12.1.67:mysql                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43016                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43094                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43232                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43164                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43170                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43464                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43622                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43490                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43416                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:42996                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43674                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43466                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43440                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43324                \ntcp    ESTAB      0      0       ::ffff:10.12.1.62:9696                    ::ffff:10.1.133.201:52277                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43626                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43564                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43784                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43740                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43120                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43194                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43460                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43038                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43074                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43694                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43676                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43202                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43590                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43604                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43510                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43204                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43088                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43456\n```\n\n### 服务器TIME_WAIT和CLOSE_WAIT详解和解决办法\nhttps://www.cnblogs.com/sunxucool/p/3449068.html\n\n\n### 怎么写CLOSE_WAIT\n非常简单，写一个Proxy，proxy创建很多与mysql的连接，proxy将每个连接的指针放入某个不回收的容器，这时关闭mysql，查看proxy的连接，就是CLOSE_WAIT\n\n### 为什么Proxy和MySQL连得好好的，会大量产生CLOSE-WAIT？\n原因在于MySQL 的默认设置下，当一个连接的空闲时间超过8小时后，MySQL 就会断开该连接，而proxy连接池则以为该被断开的连接依然有效，其实连接已经是CLOSE-WAIT状态。在这种情况下，如果客户端代码向proxy连接池请求连接的话，连接池就会把已经失效的连接返回给客户端，客户端在使用该失效连接的时候即抛出异常。","source":"_posts/TCP-Protocol-Analyzer.md","raw":"---\ntitle: TCP-Protocol-Analyzer\ndate: 2017-12-22 09:54:47\ntags: TCP\n---\n\nhttp://blog.csdn.net/q1007729991/article/details/70154359\n\nhttps://www.jianshu.com/p/83ff61d074bf\n\n在RocketMQ中，netty的Server端配置如下，显然，作者是有意多配置了几个TCP的参数\n``` java\nServerBootstrap childHandler =\n            this.serverBootstrap.group(this.eventLoopGroupBoss, this.eventLoopGroupSelector)\n                .channel(useEpoll() ? EpollServerSocketChannel.class : NioServerSocketChannel.class)\n                .option(ChannelOption.SO_BACKLOG, 1024)\n                .option(ChannelOption.SO_REUSEADDR, true)\n                .option(ChannelOption.SO_KEEPALIVE, false)\n                .childOption(ChannelOption.TCP_NODELAY, true)\n                .childOption(ChannelOption.SO_SNDBUF, nettyServerConfig.getServerSocketSndBufSize())\n                .childOption(ChannelOption.SO_RCVBUF, nettyServerConfig.getServerSocketRcvBufSize())\n                .localAddress(new InetSocketAddress(this.nettyServerConfig.getListenPort()))\n                .childHandler(new ChannelInitializer<SocketChannel>() {\n                    @Override\n                    public void initChannel(SocketChannel ch) throws Exception {\n                        ch.pipeline().addLast(\n                            defaultEventExecutorGroup,\n                            new NettyEncoder(),\n                            new NettyDecoder(),\n                            new IdleStateHandler(0, 0, nettyServerConfig.getServerChannelMaxIdleTimeSeconds()),\n                            new NettyConnectManageHandler(),\n                            new NettyServerHandler());\n                    }\n                });\n```\n\n带着这个疑问，让我们来看看，到底这些参数在TCP中是什么意思？以及如何调节参数才能提高应用的性能。\n\n\n用golang实现了一个MySQL Proxy，在做负载测试时，尝试用benchyou200连接向系统发送select * from xxx limit 10000的SQL，中途将benchyou关闭（ctrl+c），结果在Proxy端留下了大量[CLOSE-WAIT]的连接没有释放。\n```\n[nanxing@zerodb-proxy003 zeroproxy]$ ss |grep 9696\ntcp    ESTAB      0      0      10.12.1.62:59696                10.12.1.69:mysql                \ntcp    ESTAB      0      0      10.12.1.62:39696                10.12.1.67:mysql                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43016                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43094                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43232                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43164                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43170                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43464                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43622                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43490                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43416                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:42996                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43674                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43466                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43440                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43324                \ntcp    ESTAB      0      0       ::ffff:10.12.1.62:9696                    ::ffff:10.1.133.201:52277                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43626                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43564                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43784                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43740                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43120                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43194                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43460                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43038                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43074                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43694                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43676                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43202                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43590                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43604                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43510                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43204                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43088                \ntcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43456\n```\n\n### 服务器TIME_WAIT和CLOSE_WAIT详解和解决办法\nhttps://www.cnblogs.com/sunxucool/p/3449068.html\n\n\n### 怎么写CLOSE_WAIT\n非常简单，写一个Proxy，proxy创建很多与mysql的连接，proxy将每个连接的指针放入某个不回收的容器，这时关闭mysql，查看proxy的连接，就是CLOSE_WAIT\n\n### 为什么Proxy和MySQL连得好好的，会大量产生CLOSE-WAIT？\n原因在于MySQL 的默认设置下，当一个连接的空闲时间超过8小时后，MySQL 就会断开该连接，而proxy连接池则以为该被断开的连接依然有效，其实连接已经是CLOSE-WAIT状态。在这种情况下，如果客户端代码向proxy连接池请求连接的话，连接池就会把已经失效的连接返回给客户端，客户端在使用该失效连接的时候即抛出异常。","slug":"TCP-Protocol-Analyzer","published":1,"updated":"2019-09-28T08:51:00.989Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84x005dv1npehvx1jq9","content":"<p><a href=\"http://blog.csdn.net/q1007729991/article/details/70154359\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/q1007729991/article/details/70154359</a></p>\n<p><a href=\"https://www.jianshu.com/p/83ff61d074bf\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/83ff61d074bf</a></p>\n<p>在RocketMQ中，netty的Server端配置如下，显然，作者是有意多配置了几个TCP的参数</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ServerBootstrap childHandler =</span><br><span class=\"line\">            <span class=\"keyword\">this</span>.serverBootstrap.group(<span class=\"keyword\">this</span>.eventLoopGroupBoss, <span class=\"keyword\">this</span>.eventLoopGroupSelector)</span><br><span class=\"line\">                .channel(useEpoll() ? EpollServerSocketChannel.class : NioServerSocketChannel.class)</span><br><span class=\"line\">                .option(ChannelOption.SO_BACKLOG, <span class=\"number\">1024</span>)</span><br><span class=\"line\">                .option(ChannelOption.SO_REUSEADDR, <span class=\"keyword\">true</span>)</span><br><span class=\"line\">                .option(ChannelOption.SO_KEEPALIVE, <span class=\"keyword\">false</span>)</span><br><span class=\"line\">                .childOption(ChannelOption.TCP_NODELAY, <span class=\"keyword\">true</span>)</span><br><span class=\"line\">                .childOption(ChannelOption.SO_SNDBUF, nettyServerConfig.getServerSocketSndBufSize())</span><br><span class=\"line\">                .childOption(ChannelOption.SO_RCVBUF, nettyServerConfig.getServerSocketRcvBufSize())</span><br><span class=\"line\">                .localAddress(<span class=\"keyword\">new</span> InetSocketAddress(<span class=\"keyword\">this</span>.nettyServerConfig.getListenPort()))</span><br><span class=\"line\">                .childHandler(<span class=\"keyword\">new</span> ChannelInitializer&lt;SocketChannel&gt;() &#123;</span><br><span class=\"line\">                    <span class=\"meta\">@Override</span></span><br><span class=\"line\">                    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">initChannel</span><span class=\"params\">(SocketChannel ch)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">                        ch.pipeline().addLast(</span><br><span class=\"line\">                            defaultEventExecutorGroup,</span><br><span class=\"line\">                            <span class=\"keyword\">new</span> NettyEncoder(),</span><br><span class=\"line\">                            <span class=\"keyword\">new</span> NettyDecoder(),</span><br><span class=\"line\">                            <span class=\"keyword\">new</span> IdleStateHandler(<span class=\"number\">0</span>, <span class=\"number\">0</span>, nettyServerConfig.getServerChannelMaxIdleTimeSeconds()),</span><br><span class=\"line\">                            <span class=\"keyword\">new</span> NettyConnectManageHandler(),</span><br><span class=\"line\">                            <span class=\"keyword\">new</span> NettyServerHandler());</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;);</span><br></pre></td></tr></table></figure>\n\n<p>带着这个疑问，让我们来看看，到底这些参数在TCP中是什么意思？以及如何调节参数才能提高应用的性能。</p>\n<p>用golang实现了一个MySQL Proxy，在做负载测试时，尝试用benchyou200连接向系统发送select * from xxx limit 10000的SQL，中途将benchyou关闭（ctrl+c），结果在Proxy端留下了大量[CLOSE-WAIT]的连接没有释放。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[nanxing@zerodb-proxy003 zeroproxy]$ ss |grep 9696</span><br><span class=\"line\">tcp    ESTAB      0      0      10.12.1.62:59696                10.12.1.69:mysql                </span><br><span class=\"line\">tcp    ESTAB      0      0      10.12.1.62:39696                10.12.1.67:mysql                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43016                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43094                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43232                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43164                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43170                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43464                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43622                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43490                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43416                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:42996                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43674                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43466                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43440                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43324                </span><br><span class=\"line\">tcp    ESTAB      0      0       ::ffff:10.12.1.62:9696                    ::ffff:10.1.133.201:52277                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43626                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43564                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43784                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43740                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43120                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43194                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43460                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43038                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43074                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43694                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43676                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43202                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43590                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43604                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43510                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43204                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43088                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43456</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"服务器TIME-WAIT和CLOSE-WAIT详解和解决办法\"><a href=\"#服务器TIME-WAIT和CLOSE-WAIT详解和解决办法\" class=\"headerlink\" title=\"服务器TIME_WAIT和CLOSE_WAIT详解和解决办法\"></a>服务器TIME_WAIT和CLOSE_WAIT详解和解决办法</h3><p><a href=\"https://www.cnblogs.com/sunxucool/p/3449068.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/sunxucool/p/3449068.html</a></p>\n<h3 id=\"怎么写CLOSE-WAIT\"><a href=\"#怎么写CLOSE-WAIT\" class=\"headerlink\" title=\"怎么写CLOSE_WAIT\"></a>怎么写CLOSE_WAIT</h3><p>非常简单，写一个Proxy，proxy创建很多与mysql的连接，proxy将每个连接的指针放入某个不回收的容器，这时关闭mysql，查看proxy的连接，就是CLOSE_WAIT</p>\n<h3 id=\"为什么Proxy和MySQL连得好好的，会大量产生CLOSE-WAIT？\"><a href=\"#为什么Proxy和MySQL连得好好的，会大量产生CLOSE-WAIT？\" class=\"headerlink\" title=\"为什么Proxy和MySQL连得好好的，会大量产生CLOSE-WAIT？\"></a>为什么Proxy和MySQL连得好好的，会大量产生CLOSE-WAIT？</h3><p>原因在于MySQL 的默认设置下，当一个连接的空闲时间超过8小时后，MySQL 就会断开该连接，而proxy连接池则以为该被断开的连接依然有效，其实连接已经是CLOSE-WAIT状态。在这种情况下，如果客户端代码向proxy连接池请求连接的话，连接池就会把已经失效的连接返回给客户端，客户端在使用该失效连接的时候即抛出异常。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"http://blog.csdn.net/q1007729991/article/details/70154359\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/q1007729991/article/details/70154359</a></p>\n<p><a href=\"https://www.jianshu.com/p/83ff61d074bf\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/83ff61d074bf</a></p>\n<p>在RocketMQ中，netty的Server端配置如下，显然，作者是有意多配置了几个TCP的参数</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ServerBootstrap childHandler =</span><br><span class=\"line\">            <span class=\"keyword\">this</span>.serverBootstrap.group(<span class=\"keyword\">this</span>.eventLoopGroupBoss, <span class=\"keyword\">this</span>.eventLoopGroupSelector)</span><br><span class=\"line\">                .channel(useEpoll() ? EpollServerSocketChannel.class : NioServerSocketChannel.class)</span><br><span class=\"line\">                .option(ChannelOption.SO_BACKLOG, <span class=\"number\">1024</span>)</span><br><span class=\"line\">                .option(ChannelOption.SO_REUSEADDR, <span class=\"keyword\">true</span>)</span><br><span class=\"line\">                .option(ChannelOption.SO_KEEPALIVE, <span class=\"keyword\">false</span>)</span><br><span class=\"line\">                .childOption(ChannelOption.TCP_NODELAY, <span class=\"keyword\">true</span>)</span><br><span class=\"line\">                .childOption(ChannelOption.SO_SNDBUF, nettyServerConfig.getServerSocketSndBufSize())</span><br><span class=\"line\">                .childOption(ChannelOption.SO_RCVBUF, nettyServerConfig.getServerSocketRcvBufSize())</span><br><span class=\"line\">                .localAddress(<span class=\"keyword\">new</span> InetSocketAddress(<span class=\"keyword\">this</span>.nettyServerConfig.getListenPort()))</span><br><span class=\"line\">                .childHandler(<span class=\"keyword\">new</span> ChannelInitializer&lt;SocketChannel&gt;() &#123;</span><br><span class=\"line\">                    <span class=\"meta\">@Override</span></span><br><span class=\"line\">                    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">initChannel</span><span class=\"params\">(SocketChannel ch)</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">                        ch.pipeline().addLast(</span><br><span class=\"line\">                            defaultEventExecutorGroup,</span><br><span class=\"line\">                            <span class=\"keyword\">new</span> NettyEncoder(),</span><br><span class=\"line\">                            <span class=\"keyword\">new</span> NettyDecoder(),</span><br><span class=\"line\">                            <span class=\"keyword\">new</span> IdleStateHandler(<span class=\"number\">0</span>, <span class=\"number\">0</span>, nettyServerConfig.getServerChannelMaxIdleTimeSeconds()),</span><br><span class=\"line\">                            <span class=\"keyword\">new</span> NettyConnectManageHandler(),</span><br><span class=\"line\">                            <span class=\"keyword\">new</span> NettyServerHandler());</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;);</span><br></pre></td></tr></table></figure>\n\n<p>带着这个疑问，让我们来看看，到底这些参数在TCP中是什么意思？以及如何调节参数才能提高应用的性能。</p>\n<p>用golang实现了一个MySQL Proxy，在做负载测试时，尝试用benchyou200连接向系统发送select * from xxx limit 10000的SQL，中途将benchyou关闭（ctrl+c），结果在Proxy端留下了大量[CLOSE-WAIT]的连接没有释放。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[nanxing@zerodb-proxy003 zeroproxy]$ ss |grep 9696</span><br><span class=\"line\">tcp    ESTAB      0      0      10.12.1.62:59696                10.12.1.69:mysql                </span><br><span class=\"line\">tcp    ESTAB      0      0      10.12.1.62:39696                10.12.1.67:mysql                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43016                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43094                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43232                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43164                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43170                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43464                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43622                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43490                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43416                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:42996                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43674                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43466                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43440                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43324                </span><br><span class=\"line\">tcp    ESTAB      0      0       ::ffff:10.12.1.62:9696                    ::ffff:10.1.133.201:52277                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43626                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43564                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43784                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43740                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43120                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43194                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43460                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43038                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43074                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43694                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43676                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43202                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43590                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43604                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43510                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43204                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43088                </span><br><span class=\"line\">tcp    CLOSE-WAIT 1      0       ::ffff:10.12.1.62:9696                  ::ffff:10.12.1.74:43456</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"服务器TIME-WAIT和CLOSE-WAIT详解和解决办法\"><a href=\"#服务器TIME-WAIT和CLOSE-WAIT详解和解决办法\" class=\"headerlink\" title=\"服务器TIME_WAIT和CLOSE_WAIT详解和解决办法\"></a>服务器TIME_WAIT和CLOSE_WAIT详解和解决办法</h3><p><a href=\"https://www.cnblogs.com/sunxucool/p/3449068.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/sunxucool/p/3449068.html</a></p>\n<h3 id=\"怎么写CLOSE-WAIT\"><a href=\"#怎么写CLOSE-WAIT\" class=\"headerlink\" title=\"怎么写CLOSE_WAIT\"></a>怎么写CLOSE_WAIT</h3><p>非常简单，写一个Proxy，proxy创建很多与mysql的连接，proxy将每个连接的指针放入某个不回收的容器，这时关闭mysql，查看proxy的连接，就是CLOSE_WAIT</p>\n<h3 id=\"为什么Proxy和MySQL连得好好的，会大量产生CLOSE-WAIT？\"><a href=\"#为什么Proxy和MySQL连得好好的，会大量产生CLOSE-WAIT？\" class=\"headerlink\" title=\"为什么Proxy和MySQL连得好好的，会大量产生CLOSE-WAIT？\"></a>为什么Proxy和MySQL连得好好的，会大量产生CLOSE-WAIT？</h3><p>原因在于MySQL 的默认设置下，当一个连接的空闲时间超过8小时后，MySQL 就会断开该连接，而proxy连接池则以为该被断开的连接依然有效，其实连接已经是CLOSE-WAIT状态。在这种情况下，如果客户端代码向proxy连接池请求连接的话，连接池就会把已经失效的连接返回给客户端，客户端在使用该失效连接的时候即抛出异常。</p>\n"},{"title":"Thread-FAQ","date":"2017-10-27T03:07:35.000Z","_content":"\n\n### TODO hexo new Thread-Poolize-thread\n\n```\n假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。\n\n  因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做；\n\n  当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待；\n\n  如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来；\n\n  然后就将任务也分配给这4个临时工人做；\n\n  如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。\n\n  当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。\n```\n\n\n### Executor里面的线程是怎么被复用的？\n\n``` java\nfinal void runWorker(Worker w) {\n    Thread wt = Thread.currentThread();\n    Runnable task = w.firstTask;\n    w.firstTask = null;\n    w.unlock(); // allow interrupts\n    boolean completedAbruptly = true;\n    try {\n        while (task != null || (task = getTask()) != null) {\n            w.lock();\n            // If pool is stopping, ensure thread is interrupted;\n            // if not, ensure thread is not interrupted.  This\n            // requires a recheck in second case to deal with\n            // shutdownNow race while clearing interrupt\n            if ((runStateAtLeast(ctl.get(), STOP) ||\n                 (Thread.interrupted() &&\n                  runStateAtLeast(ctl.get(), STOP))) &&\n                !wt.isInterrupted())\n                wt.interrupt();\n            try {\n                beforeExecute(wt, task);\n                Throwable thrown = null;\n                try {\n                    task.run();\n                } catch (RuntimeException x) {\n                    thrown = x; throw x;\n                } catch (Error x) {\n                    thrown = x; throw x;\n                } catch (Throwable x) {\n                    thrown = x; throw new Error(x);\n                } finally {\n                    afterExecute(task, thrown);\n                }\n            } finally {\n                task = null;\n                w.completedTasks++;\n                w.unlock();\n            }\n        }\n        completedAbruptly = false;\n    } finally {\n        processWorkerExit(w, completedAbruptly);\n    }\n}\n```\n\n### 问题，ExecutorService的submit和execute有什么区别\n\n\n\n\n\n\n\n\nhttp://blog.csdn.net/zhandoushi1982/article/details/5506597\n线程的挂起操作实质上就是使线程进入“非可执行”状态下，在这个状态下CPU不会分给线程时间片，进入这个状态可以用来暂停一个线程的运行。在线程挂起后，可以通过重新唤醒线程来使之恢复运行。\n\n### ThreadLocal\n\n\n### Future\n\n\n### Promise\n\n### Difference between ReentrantLock and sync\n\n### join\n\n### yield\n\n### fork\n\n\n### Java线程面试题\n\n如果用了ReentrantLock，还需要设置自旋锁么？\n\n假如用sync做了线程互斥，A和B两个线程竞争monitor，A拿到了monitor，如果A迟迟不释放，B将永远等待，怎么避免这种情况？\n\nCopyOnWrite\n\n15个Java多线程面试题及回答\n\n1)现在有T1、T2、T3三个线程，你怎样保证T2在T1执行完后执行，T3在T2执行完后执行？\n\n这个线程问题通常会在第一轮或电话面试阶段被问到，目的是检测你对”join”方法是否熟悉。这个多线程问题比较简单，可以用join方法实现。\n\n2)在Java中Lock接口比synchronized块的优势是什么？你需要实现一个高效的缓存，它允许多个用户读，但只允许一个用户写，以此来保持它的完整性，你会怎样去实现它？\n\nlock接口在多线程和并发编程中最大的优势是它们为读和写分别提供了锁，它能满足你写像ConcurrentHashMap这样的高性能数据结构和有条件的阻塞。Java线程面试的问题越来越会根据面试者的回答来提问。我强烈建议在你去参加多线程的面试之前认真读一下Locks，因为当前其大量用于构建电子交易终统的客户端缓存和交易连接空间。\n\n3)在java中wait和sleep方法的不同？\n\n通常会在电话面试中经常被问到的Java线程面试问题。最大的不同是在等待时wait会释放锁，而sleep一直持有锁。Wait通常被用于线程间交互，sleep通常被用于暂停执行。\n\n4）用Java实现阻塞队列。\n\n这是一个相对艰难的多线程面试问题，它能达到很多的目的。第一，它可以检测侯选者是否能实际的用Java线程写程序；第二，可以检测侯选者对并发场景的理解，并且你可以根据这个问很多问题。如果他用wait()和notify()方法来实现阻塞队列，你可以要求他用最新的Java 5中的并发类来再写一次。\n\n5）用Java写代码来解决生产者——消费者问题。\n\n与上面的问题很类似，但这个问题更经典，有些时候面试都会问下面的问题。在Java中怎么解决生产者——消费者问题，当然有很多解决方法，我已经分享了一种用阻塞队列实现的方法。有些时候他们甚至会问怎么实现哲学家进餐问题。\n\n6）用Java编程一个会导致死锁的程序，你将怎么解决？\n\n这是我最喜欢的Java线程面试问题，因为即使死锁问题在写多线程并发程序时非常普遍，但是很多侯选者并不能写deadlock free code（无死锁代码？），他们很挣扎。只要告诉他们，你有N个资源和N个线程，并且你需要所有的资源来完成一个操作。为了简单这里的n可以替换为2，越大的数据会使问题看起来更复杂。通过避免Java中的死锁来得到关于死锁的更多信息。\n\n7) 什么是原子操作，Java中的原子操作是什么？\n\n非常简单的java线程面试问题，接下来的问题是你需要同步一个原子操作。\n\n8) Java中的volatile关键是什么作用？怎样使用它？在Java中它跟synchronized方法有什么不同？\n\n自从Java 5和Java内存模型改变以后，基于volatile关键字的线程问题越来越流行。应该准备好回答关于volatile变量怎样在并发环境中确保可见性。\n\n9) 什么是竞争条件？你怎样发现和解决竞争？\n\n这是一道出现在多线程面试的高级阶段的问题。大多数的面试官会问最近你遇到的竞争条件，以及你是怎么解决的。有些时间他们会写简单的代码，然后让你检测出代码的竞争条件。可以参考我之前发布的关于Java竞争条件的文章。在我看来这是最好的java线程面试问题之一，它可以确切的检测候选者解决竞争条件的经验，or writing code which is free of data race or any other race condition。关于这方面最好的书是《Concurrency practices in Java》。\n\n10) 你将如何使用thread dump？你将如何分析Thread dump？\n\n在UNIX中你可以使用kill -3，然后thread dump将会打印日志，在windows中你可以使用”CTRL+Break”。非常简单和专业的线程面试问题，但是如果他问你怎样分析它，就会很棘手。\n\n11) 为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？\n\n这是另一个非常经典的java多线程面试问题。这也是我刚开始写线程程序时候的困惑。现在这个问题通常在电话面试或者是在初中级Java面试的第一轮被问到。这个问题的回答应该是这样的，当你调用start()方法时你将创建新的线程，并且执行在run()方法里的代码。但是如果你直接调用run()方法，它不会创建新的线程也不会执行调用线程的代码。阅读我之前写的《start与run方法的区别》这篇文章来获得更多信息。\n\n12) Java中你怎样唤醒一个阻塞的线程？\n\n这是个关于线程和阻塞的棘手的问题，它有很多解决方法。如果线程遇到了IO阻塞，我并且不认为有一种方法可以中止线程。如果线程因为调用wait()、sleep()、或者join()方法而导致的阻塞，你可以中断线程，并且通过抛出InterruptedException来唤醒它。我之前写的《How to deal with blocking methods in java》有很多关于处理线程阻塞的信息。\n\n13)在Java中CycliBarriar和CountdownLatch有什么区别？\n\n这个线程问题主要用来检测你是否熟悉JDK5中的并发包。这两个的区别是CyclicBarrier可以重复使用已经通过的障碍，而CountdownLatch不能重复使用。\n\n14) 什么是不可变对象，它对写并发应用有什么帮助？\n\n另一个多线程经典面试问题，并不直接跟线程有关，但间接帮助很多。这个java面试问题可以变的非常棘手，如果他要求你写一个不可变对象，或者问你为什么String是不可变的。\n\n15) 你在多线程环境中遇到的常见的问题是什么？你是怎么解决它的？\n\n多线程和并发程序中常遇到的有Memory-interface、竞争条件、死锁、活锁和饥饿。问题是没有止境的，如果你弄错了，将很难发现和调试。这是大多数基于面试的，而不是基于实际应用的Java线程问题。\n\nhttp://www.importnew.com/27105.html","source":"_posts/Thread-FAQ.md","raw":"---\ntitle: Thread-FAQ\ndate: 2017-10-27 11:07:35\ntags: THread\n---\n\n\n### TODO hexo new Thread-Poolize-thread\n\n```\n假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。\n\n  因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做；\n\n  当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待；\n\n  如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来；\n\n  然后就将任务也分配给这4个临时工人做；\n\n  如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。\n\n  当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。\n```\n\n\n### Executor里面的线程是怎么被复用的？\n\n``` java\nfinal void runWorker(Worker w) {\n    Thread wt = Thread.currentThread();\n    Runnable task = w.firstTask;\n    w.firstTask = null;\n    w.unlock(); // allow interrupts\n    boolean completedAbruptly = true;\n    try {\n        while (task != null || (task = getTask()) != null) {\n            w.lock();\n            // If pool is stopping, ensure thread is interrupted;\n            // if not, ensure thread is not interrupted.  This\n            // requires a recheck in second case to deal with\n            // shutdownNow race while clearing interrupt\n            if ((runStateAtLeast(ctl.get(), STOP) ||\n                 (Thread.interrupted() &&\n                  runStateAtLeast(ctl.get(), STOP))) &&\n                !wt.isInterrupted())\n                wt.interrupt();\n            try {\n                beforeExecute(wt, task);\n                Throwable thrown = null;\n                try {\n                    task.run();\n                } catch (RuntimeException x) {\n                    thrown = x; throw x;\n                } catch (Error x) {\n                    thrown = x; throw x;\n                } catch (Throwable x) {\n                    thrown = x; throw new Error(x);\n                } finally {\n                    afterExecute(task, thrown);\n                }\n            } finally {\n                task = null;\n                w.completedTasks++;\n                w.unlock();\n            }\n        }\n        completedAbruptly = false;\n    } finally {\n        processWorkerExit(w, completedAbruptly);\n    }\n}\n```\n\n### 问题，ExecutorService的submit和execute有什么区别\n\n\n\n\n\n\n\n\nhttp://blog.csdn.net/zhandoushi1982/article/details/5506597\n线程的挂起操作实质上就是使线程进入“非可执行”状态下，在这个状态下CPU不会分给线程时间片，进入这个状态可以用来暂停一个线程的运行。在线程挂起后，可以通过重新唤醒线程来使之恢复运行。\n\n### ThreadLocal\n\n\n### Future\n\n\n### Promise\n\n### Difference between ReentrantLock and sync\n\n### join\n\n### yield\n\n### fork\n\n\n### Java线程面试题\n\n如果用了ReentrantLock，还需要设置自旋锁么？\n\n假如用sync做了线程互斥，A和B两个线程竞争monitor，A拿到了monitor，如果A迟迟不释放，B将永远等待，怎么避免这种情况？\n\nCopyOnWrite\n\n15个Java多线程面试题及回答\n\n1)现在有T1、T2、T3三个线程，你怎样保证T2在T1执行完后执行，T3在T2执行完后执行？\n\n这个线程问题通常会在第一轮或电话面试阶段被问到，目的是检测你对”join”方法是否熟悉。这个多线程问题比较简单，可以用join方法实现。\n\n2)在Java中Lock接口比synchronized块的优势是什么？你需要实现一个高效的缓存，它允许多个用户读，但只允许一个用户写，以此来保持它的完整性，你会怎样去实现它？\n\nlock接口在多线程和并发编程中最大的优势是它们为读和写分别提供了锁，它能满足你写像ConcurrentHashMap这样的高性能数据结构和有条件的阻塞。Java线程面试的问题越来越会根据面试者的回答来提问。我强烈建议在你去参加多线程的面试之前认真读一下Locks，因为当前其大量用于构建电子交易终统的客户端缓存和交易连接空间。\n\n3)在java中wait和sleep方法的不同？\n\n通常会在电话面试中经常被问到的Java线程面试问题。最大的不同是在等待时wait会释放锁，而sleep一直持有锁。Wait通常被用于线程间交互，sleep通常被用于暂停执行。\n\n4）用Java实现阻塞队列。\n\n这是一个相对艰难的多线程面试问题，它能达到很多的目的。第一，它可以检测侯选者是否能实际的用Java线程写程序；第二，可以检测侯选者对并发场景的理解，并且你可以根据这个问很多问题。如果他用wait()和notify()方法来实现阻塞队列，你可以要求他用最新的Java 5中的并发类来再写一次。\n\n5）用Java写代码来解决生产者——消费者问题。\n\n与上面的问题很类似，但这个问题更经典，有些时候面试都会问下面的问题。在Java中怎么解决生产者——消费者问题，当然有很多解决方法，我已经分享了一种用阻塞队列实现的方法。有些时候他们甚至会问怎么实现哲学家进餐问题。\n\n6）用Java编程一个会导致死锁的程序，你将怎么解决？\n\n这是我最喜欢的Java线程面试问题，因为即使死锁问题在写多线程并发程序时非常普遍，但是很多侯选者并不能写deadlock free code（无死锁代码？），他们很挣扎。只要告诉他们，你有N个资源和N个线程，并且你需要所有的资源来完成一个操作。为了简单这里的n可以替换为2，越大的数据会使问题看起来更复杂。通过避免Java中的死锁来得到关于死锁的更多信息。\n\n7) 什么是原子操作，Java中的原子操作是什么？\n\n非常简单的java线程面试问题，接下来的问题是你需要同步一个原子操作。\n\n8) Java中的volatile关键是什么作用？怎样使用它？在Java中它跟synchronized方法有什么不同？\n\n自从Java 5和Java内存模型改变以后，基于volatile关键字的线程问题越来越流行。应该准备好回答关于volatile变量怎样在并发环境中确保可见性。\n\n9) 什么是竞争条件？你怎样发现和解决竞争？\n\n这是一道出现在多线程面试的高级阶段的问题。大多数的面试官会问最近你遇到的竞争条件，以及你是怎么解决的。有些时间他们会写简单的代码，然后让你检测出代码的竞争条件。可以参考我之前发布的关于Java竞争条件的文章。在我看来这是最好的java线程面试问题之一，它可以确切的检测候选者解决竞争条件的经验，or writing code which is free of data race or any other race condition。关于这方面最好的书是《Concurrency practices in Java》。\n\n10) 你将如何使用thread dump？你将如何分析Thread dump？\n\n在UNIX中你可以使用kill -3，然后thread dump将会打印日志，在windows中你可以使用”CTRL+Break”。非常简单和专业的线程面试问题，但是如果他问你怎样分析它，就会很棘手。\n\n11) 为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？\n\n这是另一个非常经典的java多线程面试问题。这也是我刚开始写线程程序时候的困惑。现在这个问题通常在电话面试或者是在初中级Java面试的第一轮被问到。这个问题的回答应该是这样的，当你调用start()方法时你将创建新的线程，并且执行在run()方法里的代码。但是如果你直接调用run()方法，它不会创建新的线程也不会执行调用线程的代码。阅读我之前写的《start与run方法的区别》这篇文章来获得更多信息。\n\n12) Java中你怎样唤醒一个阻塞的线程？\n\n这是个关于线程和阻塞的棘手的问题，它有很多解决方法。如果线程遇到了IO阻塞，我并且不认为有一种方法可以中止线程。如果线程因为调用wait()、sleep()、或者join()方法而导致的阻塞，你可以中断线程，并且通过抛出InterruptedException来唤醒它。我之前写的《How to deal with blocking methods in java》有很多关于处理线程阻塞的信息。\n\n13)在Java中CycliBarriar和CountdownLatch有什么区别？\n\n这个线程问题主要用来检测你是否熟悉JDK5中的并发包。这两个的区别是CyclicBarrier可以重复使用已经通过的障碍，而CountdownLatch不能重复使用。\n\n14) 什么是不可变对象，它对写并发应用有什么帮助？\n\n另一个多线程经典面试问题，并不直接跟线程有关，但间接帮助很多。这个java面试问题可以变的非常棘手，如果他要求你写一个不可变对象，或者问你为什么String是不可变的。\n\n15) 你在多线程环境中遇到的常见的问题是什么？你是怎么解决它的？\n\n多线程和并发程序中常遇到的有Memory-interface、竞争条件、死锁、活锁和饥饿。问题是没有止境的，如果你弄错了，将很难发现和调试。这是大多数基于面试的，而不是基于实际应用的Java线程问题。\n\nhttp://www.importnew.com/27105.html","slug":"Thread-FAQ","published":1,"updated":"2019-09-28T08:51:00.994Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck3o9o84x005ev1npg6akec64","content":"<h3 id=\"TODO-hexo-new-Thread-Poolize-thread\"><a href=\"#TODO-hexo-new-Thread-Poolize-thread\" class=\"headerlink\" title=\"TODO hexo new Thread-Poolize-thread\"></a>TODO hexo new Thread-Poolize-thread</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。</span><br><span class=\"line\"></span><br><span class=\"line\">  因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做；</span><br><span class=\"line\"></span><br><span class=\"line\">  当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待；</span><br><span class=\"line\"></span><br><span class=\"line\">  如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来；</span><br><span class=\"line\"></span><br><span class=\"line\">  然后就将任务也分配给这4个临时工人做；</span><br><span class=\"line\"></span><br><span class=\"line\">  如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。</span><br><span class=\"line\"></span><br><span class=\"line\">  当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Executor里面的线程是怎么被复用的？\"><a href=\"#Executor里面的线程是怎么被复用的？\" class=\"headerlink\" title=\"Executor里面的线程是怎么被复用的？\"></a>Executor里面的线程是怎么被复用的？</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">runWorker</span><span class=\"params\">(Worker w)</span> </span>&#123;</span><br><span class=\"line\">    Thread wt = Thread.currentThread();</span><br><span class=\"line\">    Runnable task = w.firstTask;</span><br><span class=\"line\">    w.firstTask = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    w.unlock(); <span class=\"comment\">// allow interrupts</span></span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> completedAbruptly = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (task != <span class=\"keyword\">null</span> || (task = getTask()) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            w.lock();</span><br><span class=\"line\">            <span class=\"comment\">// If pool is stopping, ensure thread is interrupted;</span></span><br><span class=\"line\">            <span class=\"comment\">// if not, ensure thread is not interrupted.  This</span></span><br><span class=\"line\">            <span class=\"comment\">// requires a recheck in second case to deal with</span></span><br><span class=\"line\">            <span class=\"comment\">// shutdownNow race while clearing interrupt</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> ((runStateAtLeast(ctl.get(), STOP) ||</span><br><span class=\"line\">                 (Thread.interrupted() &amp;&amp;</span><br><span class=\"line\">                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;</span><br><span class=\"line\">                !wt.isInterrupted())</span><br><span class=\"line\">                wt.interrupt();</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                beforeExecute(wt, task);</span><br><span class=\"line\">                Throwable thrown = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    task.run();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (RuntimeException x) &#123;</span><br><span class=\"line\">                    thrown = x; <span class=\"keyword\">throw</span> x;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Error x) &#123;</span><br><span class=\"line\">                    thrown = x; <span class=\"keyword\">throw</span> x;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Throwable x) &#123;</span><br><span class=\"line\">                    thrown = x; <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> Error(x);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    afterExecute(task, thrown);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                task = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                w.completedTasks++;</span><br><span class=\"line\">                w.unlock();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        completedAbruptly = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        processWorkerExit(w, completedAbruptly);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"问题，ExecutorService的submit和execute有什么区别\"><a href=\"#问题，ExecutorService的submit和execute有什么区别\" class=\"headerlink\" title=\"问题，ExecutorService的submit和execute有什么区别\"></a>问题，ExecutorService的submit和execute有什么区别</h3><p><a href=\"http://blog.csdn.net/zhandoushi1982/article/details/5506597\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/zhandoushi1982/article/details/5506597</a><br>线程的挂起操作实质上就是使线程进入“非可执行”状态下，在这个状态下CPU不会分给线程时间片，进入这个状态可以用来暂停一个线程的运行。在线程挂起后，可以通过重新唤醒线程来使之恢复运行。</p>\n<h3 id=\"ThreadLocal\"><a href=\"#ThreadLocal\" class=\"headerlink\" title=\"ThreadLocal\"></a>ThreadLocal</h3><h3 id=\"Future\"><a href=\"#Future\" class=\"headerlink\" title=\"Future\"></a>Future</h3><h3 id=\"Promise\"><a href=\"#Promise\" class=\"headerlink\" title=\"Promise\"></a>Promise</h3><h3 id=\"Difference-between-ReentrantLock-and-sync\"><a href=\"#Difference-between-ReentrantLock-and-sync\" class=\"headerlink\" title=\"Difference between ReentrantLock and sync\"></a>Difference between ReentrantLock and sync</h3><h3 id=\"join\"><a href=\"#join\" class=\"headerlink\" title=\"join\"></a>join</h3><h3 id=\"yield\"><a href=\"#yield\" class=\"headerlink\" title=\"yield\"></a>yield</h3><h3 id=\"fork\"><a href=\"#fork\" class=\"headerlink\" title=\"fork\"></a>fork</h3><h3 id=\"Java线程面试题\"><a href=\"#Java线程面试题\" class=\"headerlink\" title=\"Java线程面试题\"></a>Java线程面试题</h3><p>如果用了ReentrantLock，还需要设置自旋锁么？</p>\n<p>假如用sync做了线程互斥，A和B两个线程竞争monitor，A拿到了monitor，如果A迟迟不释放，B将永远等待，怎么避免这种情况？</p>\n<p>CopyOnWrite</p>\n<p>15个Java多线程面试题及回答</p>\n<p>1)现在有T1、T2、T3三个线程，你怎样保证T2在T1执行完后执行，T3在T2执行完后执行？</p>\n<p>这个线程问题通常会在第一轮或电话面试阶段被问到，目的是检测你对”join”方法是否熟悉。这个多线程问题比较简单，可以用join方法实现。</p>\n<p>2)在Java中Lock接口比synchronized块的优势是什么？你需要实现一个高效的缓存，它允许多个用户读，但只允许一个用户写，以此来保持它的完整性，你会怎样去实现它？</p>\n<p>lock接口在多线程和并发编程中最大的优势是它们为读和写分别提供了锁，它能满足你写像ConcurrentHashMap这样的高性能数据结构和有条件的阻塞。Java线程面试的问题越来越会根据面试者的回答来提问。我强烈建议在你去参加多线程的面试之前认真读一下Locks，因为当前其大量用于构建电子交易终统的客户端缓存和交易连接空间。</p>\n<p>3)在java中wait和sleep方法的不同？</p>\n<p>通常会在电话面试中经常被问到的Java线程面试问题。最大的不同是在等待时wait会释放锁，而sleep一直持有锁。Wait通常被用于线程间交互，sleep通常被用于暂停执行。</p>\n<p>4）用Java实现阻塞队列。</p>\n<p>这是一个相对艰难的多线程面试问题，它能达到很多的目的。第一，它可以检测侯选者是否能实际的用Java线程写程序；第二，可以检测侯选者对并发场景的理解，并且你可以根据这个问很多问题。如果他用wait()和notify()方法来实现阻塞队列，你可以要求他用最新的Java 5中的并发类来再写一次。</p>\n<p>5）用Java写代码来解决生产者——消费者问题。</p>\n<p>与上面的问题很类似，但这个问题更经典，有些时候面试都会问下面的问题。在Java中怎么解决生产者——消费者问题，当然有很多解决方法，我已经分享了一种用阻塞队列实现的方法。有些时候他们甚至会问怎么实现哲学家进餐问题。</p>\n<p>6）用Java编程一个会导致死锁的程序，你将怎么解决？</p>\n<p>这是我最喜欢的Java线程面试问题，因为即使死锁问题在写多线程并发程序时非常普遍，但是很多侯选者并不能写deadlock free code（无死锁代码？），他们很挣扎。只要告诉他们，你有N个资源和N个线程，并且你需要所有的资源来完成一个操作。为了简单这里的n可以替换为2，越大的数据会使问题看起来更复杂。通过避免Java中的死锁来得到关于死锁的更多信息。</p>\n<p>7) 什么是原子操作，Java中的原子操作是什么？</p>\n<p>非常简单的java线程面试问题，接下来的问题是你需要同步一个原子操作。</p>\n<p>8) Java中的volatile关键是什么作用？怎样使用它？在Java中它跟synchronized方法有什么不同？</p>\n<p>自从Java 5和Java内存模型改变以后，基于volatile关键字的线程问题越来越流行。应该准备好回答关于volatile变量怎样在并发环境中确保可见性。</p>\n<p>9) 什么是竞争条件？你怎样发现和解决竞争？</p>\n<p>这是一道出现在多线程面试的高级阶段的问题。大多数的面试官会问最近你遇到的竞争条件，以及你是怎么解决的。有些时间他们会写简单的代码，然后让你检测出代码的竞争条件。可以参考我之前发布的关于Java竞争条件的文章。在我看来这是最好的java线程面试问题之一，它可以确切的检测候选者解决竞争条件的经验，or writing code which is free of data race or any other race condition。关于这方面最好的书是《Concurrency practices in Java》。</p>\n<p>10) 你将如何使用thread dump？你将如何分析Thread dump？</p>\n<p>在UNIX中你可以使用kill -3，然后thread dump将会打印日志，在windows中你可以使用”CTRL+Break”。非常简单和专业的线程面试问题，但是如果他问你怎样分析它，就会很棘手。</p>\n<p>11) 为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？</p>\n<p>这是另一个非常经典的java多线程面试问题。这也是我刚开始写线程程序时候的困惑。现在这个问题通常在电话面试或者是在初中级Java面试的第一轮被问到。这个问题的回答应该是这样的，当你调用start()方法时你将创建新的线程，并且执行在run()方法里的代码。但是如果你直接调用run()方法，它不会创建新的线程也不会执行调用线程的代码。阅读我之前写的《start与run方法的区别》这篇文章来获得更多信息。</p>\n<p>12) Java中你怎样唤醒一个阻塞的线程？</p>\n<p>这是个关于线程和阻塞的棘手的问题，它有很多解决方法。如果线程遇到了IO阻塞，我并且不认为有一种方法可以中止线程。如果线程因为调用wait()、sleep()、或者join()方法而导致的阻塞，你可以中断线程，并且通过抛出InterruptedException来唤醒它。我之前写的《How to deal with blocking methods in java》有很多关于处理线程阻塞的信息。</p>\n<p>13)在Java中CycliBarriar和CountdownLatch有什么区别？</p>\n<p>这个线程问题主要用来检测你是否熟悉JDK5中的并发包。这两个的区别是CyclicBarrier可以重复使用已经通过的障碍，而CountdownLatch不能重复使用。</p>\n<p>14) 什么是不可变对象，它对写并发应用有什么帮助？</p>\n<p>另一个多线程经典面试问题，并不直接跟线程有关，但间接帮助很多。这个java面试问题可以变的非常棘手，如果他要求你写一个不可变对象，或者问你为什么String是不可变的。</p>\n<p>15) 你在多线程环境中遇到的常见的问题是什么？你是怎么解决它的？</p>\n<p>多线程和并发程序中常遇到的有Memory-interface、竞争条件、死锁、活锁和饥饿。问题是没有止境的，如果你弄错了，将很难发现和调试。这是大多数基于面试的，而不是基于实际应用的Java线程问题。</p>\n<p><a href=\"http://www.importnew.com/27105.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/27105.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"TODO-hexo-new-Thread-Poolize-thread\"><a href=\"#TODO-hexo-new-Thread-Poolize-thread\" class=\"headerlink\" title=\"TODO hexo new Thread-Poolize-thread\"></a>TODO hexo new Thread-Poolize-thread</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。</span><br><span class=\"line\"></span><br><span class=\"line\">  因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做；</span><br><span class=\"line\"></span><br><span class=\"line\">  当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待；</span><br><span class=\"line\"></span><br><span class=\"line\">  如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来；</span><br><span class=\"line\"></span><br><span class=\"line\">  然后就将任务也分配给这4个临时工人做；</span><br><span class=\"line\"></span><br><span class=\"line\">  如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。</span><br><span class=\"line\"></span><br><span class=\"line\">  当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Executor里面的线程是怎么被复用的？\"><a href=\"#Executor里面的线程是怎么被复用的？\" class=\"headerlink\" title=\"Executor里面的线程是怎么被复用的？\"></a>Executor里面的线程是怎么被复用的？</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">final</span> <span class=\"keyword\">void</span> <span class=\"title\">runWorker</span><span class=\"params\">(Worker w)</span> </span>&#123;</span><br><span class=\"line\">    Thread wt = Thread.currentThread();</span><br><span class=\"line\">    Runnable task = w.firstTask;</span><br><span class=\"line\">    w.firstTask = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">    w.unlock(); <span class=\"comment\">// allow interrupts</span></span><br><span class=\"line\">    <span class=\"keyword\">boolean</span> completedAbruptly = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (task != <span class=\"keyword\">null</span> || (task = getTask()) != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            w.lock();</span><br><span class=\"line\">            <span class=\"comment\">// If pool is stopping, ensure thread is interrupted;</span></span><br><span class=\"line\">            <span class=\"comment\">// if not, ensure thread is not interrupted.  This</span></span><br><span class=\"line\">            <span class=\"comment\">// requires a recheck in second case to deal with</span></span><br><span class=\"line\">            <span class=\"comment\">// shutdownNow race while clearing interrupt</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> ((runStateAtLeast(ctl.get(), STOP) ||</span><br><span class=\"line\">                 (Thread.interrupted() &amp;&amp;</span><br><span class=\"line\">                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;</span><br><span class=\"line\">                !wt.isInterrupted())</span><br><span class=\"line\">                wt.interrupt();</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                beforeExecute(wt, task);</span><br><span class=\"line\">                Throwable thrown = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                    task.run();</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (RuntimeException x) &#123;</span><br><span class=\"line\">                    thrown = x; <span class=\"keyword\">throw</span> x;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Error x) &#123;</span><br><span class=\"line\">                    thrown = x; <span class=\"keyword\">throw</span> x;</span><br><span class=\"line\">                &#125; <span class=\"keyword\">catch</span> (Throwable x) &#123;</span><br><span class=\"line\">                    thrown = x; <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> Error(x);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                    afterExecute(task, thrown);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">                task = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">                w.completedTasks++;</span><br><span class=\"line\">                w.unlock();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        completedAbruptly = <span class=\"keyword\">false</span>;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        processWorkerExit(w, completedAbruptly);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"问题，ExecutorService的submit和execute有什么区别\"><a href=\"#问题，ExecutorService的submit和execute有什么区别\" class=\"headerlink\" title=\"问题，ExecutorService的submit和execute有什么区别\"></a>问题，ExecutorService的submit和execute有什么区别</h3><p><a href=\"http://blog.csdn.net/zhandoushi1982/article/details/5506597\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/zhandoushi1982/article/details/5506597</a><br>线程的挂起操作实质上就是使线程进入“非可执行”状态下，在这个状态下CPU不会分给线程时间片，进入这个状态可以用来暂停一个线程的运行。在线程挂起后，可以通过重新唤醒线程来使之恢复运行。</p>\n<h3 id=\"ThreadLocal\"><a href=\"#ThreadLocal\" class=\"headerlink\" title=\"ThreadLocal\"></a>ThreadLocal</h3><h3 id=\"Future\"><a href=\"#Future\" class=\"headerlink\" title=\"Future\"></a>Future</h3><h3 id=\"Promise\"><a href=\"#Promise\" class=\"headerlink\" title=\"Promise\"></a>Promise</h3><h3 id=\"Difference-between-ReentrantLock-and-sync\"><a href=\"#Difference-between-ReentrantLock-and-sync\" class=\"headerlink\" title=\"Difference between ReentrantLock and sync\"></a>Difference between ReentrantLock and sync</h3><h3 id=\"join\"><a href=\"#join\" class=\"headerlink\" title=\"join\"></a>join</h3><h3 id=\"yield\"><a href=\"#yield\" class=\"headerlink\" title=\"yield\"></a>yield</h3><h3 id=\"fork\"><a href=\"#fork\" class=\"headerlink\" title=\"fork\"></a>fork</h3><h3 id=\"Java线程面试题\"><a href=\"#Java线程面试题\" class=\"headerlink\" title=\"Java线程面试题\"></a>Java线程面试题</h3><p>如果用了ReentrantLock，还需要设置自旋锁么？</p>\n<p>假如用sync做了线程互斥，A和B两个线程竞争monitor，A拿到了monitor，如果A迟迟不释放，B将永远等待，怎么避免这种情况？</p>\n<p>CopyOnWrite</p>\n<p>15个Java多线程面试题及回答</p>\n<p>1)现在有T1、T2、T3三个线程，你怎样保证T2在T1执行完后执行，T3在T2执行完后执行？</p>\n<p>这个线程问题通常会在第一轮或电话面试阶段被问到，目的是检测你对”join”方法是否熟悉。这个多线程问题比较简单，可以用join方法实现。</p>\n<p>2)在Java中Lock接口比synchronized块的优势是什么？你需要实现一个高效的缓存，它允许多个用户读，但只允许一个用户写，以此来保持它的完整性，你会怎样去实现它？</p>\n<p>lock接口在多线程和并发编程中最大的优势是它们为读和写分别提供了锁，它能满足你写像ConcurrentHashMap这样的高性能数据结构和有条件的阻塞。Java线程面试的问题越来越会根据面试者的回答来提问。我强烈建议在你去参加多线程的面试之前认真读一下Locks，因为当前其大量用于构建电子交易终统的客户端缓存和交易连接空间。</p>\n<p>3)在java中wait和sleep方法的不同？</p>\n<p>通常会在电话面试中经常被问到的Java线程面试问题。最大的不同是在等待时wait会释放锁，而sleep一直持有锁。Wait通常被用于线程间交互，sleep通常被用于暂停执行。</p>\n<p>4）用Java实现阻塞队列。</p>\n<p>这是一个相对艰难的多线程面试问题，它能达到很多的目的。第一，它可以检测侯选者是否能实际的用Java线程写程序；第二，可以检测侯选者对并发场景的理解，并且你可以根据这个问很多问题。如果他用wait()和notify()方法来实现阻塞队列，你可以要求他用最新的Java 5中的并发类来再写一次。</p>\n<p>5）用Java写代码来解决生产者——消费者问题。</p>\n<p>与上面的问题很类似，但这个问题更经典，有些时候面试都会问下面的问题。在Java中怎么解决生产者——消费者问题，当然有很多解决方法，我已经分享了一种用阻塞队列实现的方法。有些时候他们甚至会问怎么实现哲学家进餐问题。</p>\n<p>6）用Java编程一个会导致死锁的程序，你将怎么解决？</p>\n<p>这是我最喜欢的Java线程面试问题，因为即使死锁问题在写多线程并发程序时非常普遍，但是很多侯选者并不能写deadlock free code（无死锁代码？），他们很挣扎。只要告诉他们，你有N个资源和N个线程，并且你需要所有的资源来完成一个操作。为了简单这里的n可以替换为2，越大的数据会使问题看起来更复杂。通过避免Java中的死锁来得到关于死锁的更多信息。</p>\n<p>7) 什么是原子操作，Java中的原子操作是什么？</p>\n<p>非常简单的java线程面试问题，接下来的问题是你需要同步一个原子操作。</p>\n<p>8) Java中的volatile关键是什么作用？怎样使用它？在Java中它跟synchronized方法有什么不同？</p>\n<p>自从Java 5和Java内存模型改变以后，基于volatile关键字的线程问题越来越流行。应该准备好回答关于volatile变量怎样在并发环境中确保可见性。</p>\n<p>9) 什么是竞争条件？你怎样发现和解决竞争？</p>\n<p>这是一道出现在多线程面试的高级阶段的问题。大多数的面试官会问最近你遇到的竞争条件，以及你是怎么解决的。有些时间他们会写简单的代码，然后让你检测出代码的竞争条件。可以参考我之前发布的关于Java竞争条件的文章。在我看来这是最好的java线程面试问题之一，它可以确切的检测候选者解决竞争条件的经验，or writing code which is free of data race or any other race condition。关于这方面最好的书是《Concurrency practices in Java》。</p>\n<p>10) 你将如何使用thread dump？你将如何分析Thread dump？</p>\n<p>在UNIX中你可以使用kill -3，然后thread dump将会打印日志，在windows中你可以使用”CTRL+Break”。非常简单和专业的线程面试问题，但是如果他问你怎样分析它，就会很棘手。</p>\n<p>11) 为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？</p>\n<p>这是另一个非常经典的java多线程面试问题。这也是我刚开始写线程程序时候的困惑。现在这个问题通常在电话面试或者是在初中级Java面试的第一轮被问到。这个问题的回答应该是这样的，当你调用start()方法时你将创建新的线程，并且执行在run()方法里的代码。但是如果你直接调用run()方法，它不会创建新的线程也不会执行调用线程的代码。阅读我之前写的《start与run方法的区别》这篇文章来获得更多信息。</p>\n<p>12) Java中你怎样唤醒一个阻塞的线程？</p>\n<p>这是个关于线程和阻塞的棘手的问题，它有很多解决方法。如果线程遇到了IO阻塞，我并且不认为有一种方法可以中止线程。如果线程因为调用wait()、sleep()、或者join()方法而导致的阻塞，你可以中断线程，并且通过抛出InterruptedException来唤醒它。我之前写的《How to deal with blocking methods in java》有很多关于处理线程阻塞的信息。</p>\n<p>13)在Java中CycliBarriar和CountdownLatch有什么区别？</p>\n<p>这个线程问题主要用来检测你是否熟悉JDK5中的并发包。这两个的区别是CyclicBarrier可以重复使用已经通过的障碍，而CountdownLatch不能重复使用。</p>\n<p>14) 什么是不可变对象，它对写并发应用有什么帮助？</p>\n<p>另一个多线程经典面试问题，并不直接跟线程有关，但间接帮助很多。这个java面试问题可以变的非常棘手，如果他要求你写一个不可变对象，或者问你为什么String是不可变的。</p>\n<p>15) 你在多线程环境中遇到的常见的问题是什么？你是怎么解决它的？</p>\n<p>多线程和并发程序中常遇到的有Memory-interface、竞争条件、死锁、活锁和饥饿。问题是没有止境的，如果你弄错了，将很难发现和调试。这是大多数基于面试的，而不是基于实际应用的Java线程问题。</p>\n<p><a href=\"http://www.importnew.com/27105.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/27105.html</a></p>\n"}],"PostAsset":[{"_id":"source/_posts/Distributed-Transaction/transaction_rocketmq.gif","slug":"transaction_rocketmq.gif","post":"ck3o9o82h000lv1np438d5ipr","modified":1,"renderable":0},{"_id":"source/_posts/RocketMQ-Transactional-message/transaction_rocketmq.gif","slug":"transaction_rocketmq.gif","post":"ck3o9o84t0055v1npe83nckd3","modified":1,"renderable":0},{"_id":"source/_posts/Cobar-Reactor-design-pattern/NioRegister.gif","slug":"NioRegister.gif","post":"ck3o9o82a000av1npkdn9c5fx","modified":1,"renderable":0},{"_id":"source/_posts/JVM-Synchronized/biased_lock_flow.jpg","slug":"biased_lock_flow.jpg","post":"ck3o9o83h002iv1np6gqeefys","modified":1,"renderable":0},{"_id":"source/_posts/Netty-Jemalloc/jemalloc.jpg","post":"ck3o9o84a0049v1npv9hbbkow","slug":"jemalloc.jpg","modified":1,"renderable":1},{"_id":"source/_posts/RocketMQ-Index-service/index-file.gif","post":"ck3o9o84n004vv1np9v6nnjeo","slug":"index-file.gif","modified":1,"renderable":1},{"_id":"source/_posts/RocketMQ-Message-send-and-persistence/disc-fall.gif","slug":"disc-fall.gif","post":"ck3o9o84p004yv1npsjkspm45","modified":1,"renderable":0},{"_id":"source/_posts/TCP-Protocol-Analyzer/mySql-handshake.gif","post":"ck3o9o84x005dv1npehvx1jq9","slug":"mySql-handshake.gif","modified":1,"renderable":1},{"_id":"source/_posts/Kafka-High-performance-design-with-pagecache/disk_read_write_speed.jpg","post":"ck3o9o83m002rv1npnw0qiuo9","slug":"disk_read_write_speed.jpg","modified":1,"renderable":1},{"_id":"source/_posts/Kafka-High-performance-design-with-pagecache/read_write.gif","post":"ck3o9o83m002rv1npnw0qiuo9","slug":"read_write.gif","modified":1,"renderable":1},{"_id":"source/_posts/RocketMQ-Netty-imp-sync-and-async-invoke/invokeAsync.png","slug":"invokeAsync.png","post":"ck3o9o84p004zv1npxquqri17","modified":1,"renderable":0},{"_id":"source/_posts/RocketMQ-Netty-imp-sync-and-async-invoke/invokeSync.png","slug":"invokeSync.png","post":"ck3o9o84p004zv1npxquqri17","modified":1,"renderable":0},{"_id":"source/_posts/Linux-TCP-dump/find_packet.jpg","slug":"find_packet.jpg","post":"ck3o9o83z003iv1npxwpfgs1i","modified":1,"renderable":0},{"_id":"source/_posts/Linux-TCP-dump/search_tcp_stream.jpg","slug":"search_tcp_stream.jpg","post":"ck3o9o83z003iv1npxwpfgs1i","modified":1,"renderable":0},{"_id":"source/_posts/Linux-TCP-dump/tcp_stream.jpg","slug":"tcp_stream.jpg","post":"ck3o9o83z003iv1npxwpfgs1i","modified":1,"renderable":0},{"_id":"source/_posts/Cobar-Reactor-design-pattern/CobarReactor.gif","slug":"CobarReactor.gif","post":"ck3o9o82a000av1npkdn9c5fx","modified":1,"renderable":0},{"_id":"source/_posts/Cobar-Reactor-design-pattern/CobarReactorSign.gif","post":"ck3o9o82a000av1npkdn9c5fx","slug":"CobarReactorSign.gif","modified":1,"renderable":1},{"_id":"source/_posts/Cobar-Reactor-design-pattern/NioSign.gif","post":"ck3o9o82a000av1npkdn9c5fx","slug":"NioSign.gif","modified":1,"renderable":1},{"_id":"source/_posts/JVM-Synchronized/biased_lock_convert_flow.jpg","post":"ck3o9o83h002iv1np6gqeefys","slug":"biased_lock_convert_flow.jpg","modified":1,"renderable":1},{"_id":"source/_posts/JVM-Synchronized/light_lock_flow.jpg","slug":"light_lock_flow.jpg","post":"ck3o9o83h002iv1np6gqeefys","modified":1,"renderable":0},{"_id":"source/_posts/JVM-Synchronized/markword_state.jpg","post":"ck3o9o83h002iv1np6gqeefys","slug":"markword_state.jpg","modified":1,"renderable":1}],"PostCategory":[],"PostTag":[{"post_id":"ck3o9o82a000av1npkdn9c5fx","tag_id":"ck3o9o8xn005fv1npizm9equg","_id":"ck3o9o91n007vv1np10z21ynk"},{"post_id":"ck3o9o82b000bv1npt1qx4bw6","tag_id":"ck3o9o8y7005hv1npvlkbvfhc","_id":"ck3o9o91n007wv1npp88ai5g7"},{"post_id":"ck3o9o82c000cv1npg2rlimpa","tag_id":"ck3o9o8y7005hv1npvlkbvfhc","_id":"ck3o9o91o007xv1np9f7hl2wi"},{"post_id":"ck3o9o82f000iv1npo2o3eg1u","tag_id":"ck3o9o8y9005jv1nppvpphlml","_id":"ck3o9o91o007yv1np9phdzmln"},{"post_id":"ck3o9o82g000jv1nptreffjo3","tag_id":"ck3o9o8ya005kv1np9ik3vmui","_id":"ck3o9o91o007zv1npuxiuf7py"},{"post_id":"ck3o9o82h000kv1np169wkwsl","tag_id":"ck3o9o8ya005lv1npaxjx6ig7","_id":"ck3o9o91o0080v1npzbg8yj53"},{"post_id":"ck3o9o82h000lv1np438d5ipr","tag_id":"ck3o9o8ya005kv1np9ik3vmui","_id":"ck3o9o91o0081v1np7icjzer2"},{"post_id":"ck3o9o82m000wv1npvzv1uxgm","tag_id":"ck3o9o8yb005nv1npysy6dvvw","_id":"ck3o9o91o0082v1npglgcuh7e"},{"post_id":"ck3o9o82n000xv1npsqxiplr8","tag_id":"ck3o9o8yc005ov1npj91o62rh","_id":"ck3o9o91o0083v1nphbuffmgn"},{"post_id":"ck3o9o82o0011v1np8un7p2pb","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91o0084v1npmquterxz"},{"post_id":"ck3o9o82s0019v1np0n4p3662","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91o0085v1npooupggy6"},{"post_id":"ck3o9o82u001ev1np83aqshpy","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91o0086v1nptjwky5xb"},{"post_id":"ck3o9o82u001fv1np78h3z15h","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91p0087v1np9msu15yc"},{"post_id":"ck3o9o82v001hv1np57ws7jhd","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91p0088v1nplrxu3jty"},{"post_id":"ck3o9o82w001iv1npa06luhu9","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91p0089v1nplrzyif9w"},{"post_id":"ck3o9o82w001jv1np6gb0f1fd","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91p008av1np2ee9v5v9"},{"post_id":"ck3o9o82x001kv1npwtw9f3db","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91p008bv1npxzzkap6h"},{"post_id":"ck3o9o82x001lv1npszdlr0fv","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91p008cv1np8skgkran"},{"post_id":"ck3o9o830001mv1npmbht70vv","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91p008dv1np3ra4w92q"},{"post_id":"ck3o9o831001nv1npu4un1qq7","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91p008ev1npcs6by7hp"},{"post_id":"ck3o9o831001ov1npqixf4eh7","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91p008fv1np89iqnvne"},{"post_id":"ck3o9o832001pv1nppouura90","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91q008gv1npal8098bg"},{"post_id":"ck3o9o833001qv1np6vr72tha","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91q008hv1npvej60fll"},{"post_id":"ck3o9o833001rv1np5rrqsnic","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91q008iv1npwomz8tyq"},{"post_id":"ck3o9o834001sv1npfis7zyei","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91q008jv1nps9dhhc9f"},{"post_id":"ck3o9o834001tv1npbyit37fg","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91q008kv1np7u9lans1"},{"post_id":"ck3o9o834001uv1npiwraclco","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91r008lv1npxm57lqv7"},{"post_id":"ck3o9o835001vv1npo9z10au5","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91r008mv1npxd26f4zc"},{"post_id":"ck3o9o835001wv1np8ia04f4k","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91r008nv1npsozabqco"},{"post_id":"ck3o9o836001xv1npogvlzch9","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91r008ov1np8vetca8l"},{"post_id":"ck3o9o836001yv1npujrirlsc","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91r008pv1npu11mys3p"},{"post_id":"ck3o9o837001zv1npsb3rk71b","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91r008qv1nprm5fqley"},{"post_id":"ck3o9o8390020v1npbtqkcimc","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91r008rv1np4l16zf9h"},{"post_id":"ck3o9o83a0021v1np9wbmwao9","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91s008sv1nphqcmxqrc"},{"post_id":"ck3o9o83a0022v1npsg3dhx9p","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91s008tv1np1lcgbzd1"},{"post_id":"ck3o9o83b0023v1npbps519sz","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91s008uv1nprwiw5a2d"},{"post_id":"ck3o9o83b0024v1npfybbhxhn","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91s008vv1npg1bsg2hc"},{"post_id":"ck3o9o83b0025v1npkafl49es","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91s008wv1npth32v3cb"},{"post_id":"ck3o9o83c0026v1npxrz6y25d","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t008xv1np57vtol4s"},{"post_id":"ck3o9o83c0027v1npcgz1djbk","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t008yv1npcx0xiybq"},{"post_id":"ck3o9o83d0028v1npj8ncszcv","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t008zv1np4bv6k1e8"},{"post_id":"ck3o9o83d0029v1np53x4rdv7","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t0090v1np4b6rx2tr"},{"post_id":"ck3o9o83d002av1nptmx7ltfu","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t0091v1npwl3vzkne"},{"post_id":"ck3o9o83e002bv1npitglfpld","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t0092v1np57b94ivs"},{"post_id":"ck3o9o83e002cv1np0pl6k3ym","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t0093v1npdvn5nz4e"},{"post_id":"ck3o9o83f002dv1np1t2qf2jv","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t0094v1npa83fwunp"},{"post_id":"ck3o9o83f002ev1npjbezdwai","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t0095v1npz5b4v5ab"},{"post_id":"ck3o9o83f002fv1np0eta9y8m","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t0096v1npfs03c0k6"},{"post_id":"ck3o9o83g002gv1np2dmz65su","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t0097v1nppacjubhd"},{"post_id":"ck3o9o83h002hv1npthdghg5t","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t0098v1np946uqp4p"},{"post_id":"ck3o9o83h002iv1np6gqeefys","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t0099v1npv5hbqz01"},{"post_id":"ck3o9o83i002jv1npr5frk354","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t009av1npicf66n09"},{"post_id":"ck3o9o83i002kv1npvub2yvzm","tag_id":"ck3o9o8z4006wv1nppdi00vbe","_id":"ck3o9o91t009bv1nptmctyj3y"},{"post_id":"ck3o9o83j002lv1npbannn7hu","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91t009cv1npkx9vkigz"},{"post_id":"ck3o9o83k002mv1npl1hllwjp","tag_id":"ck3o9o8z4006wv1nppdi00vbe","_id":"ck3o9o91u009dv1npkaz9pg6e"},{"post_id":"ck3o9o83l002ov1nplw4xm9ta","tag_id":"ck3o9o8yc005pv1npmoj6cijs","_id":"ck3o9o91u009ev1npc6oba57p"},{"post_id":"ck3o9o83m002rv1npnw0qiuo9","tag_id":"ck3o9o8z4006wv1nppdi00vbe","_id":"ck3o9o91u009fv1np396dasz3"},{"post_id":"ck3o9o83n002sv1npphr8n3jh","tag_id":"ck3o9o8z4006wv1nppdi00vbe","_id":"ck3o9o91u009gv1np5qr3bmps"},{"post_id":"ck3o9o83t0034v1nplwjsml4n","tag_id":"ck3o9o8z60072v1npn9wbf37k","_id":"ck3o9o91u009hv1nphynbyg80"},{"post_id":"ck3o9o83w003bv1npp2wwypvq","tag_id":"ck3o9o8z60072v1npn9wbf37k","_id":"ck3o9o91u009iv1npox4rc4se"},{"post_id":"ck3o9o83x003dv1npi231cu2n","tag_id":"ck3o9o8z60072v1npn9wbf37k","_id":"ck3o9o91u009jv1npbujjwl1o"},{"post_id":"ck3o9o840003kv1npbomyd7o2","tag_id":"ck3o9o8z60072v1npn9wbf37k","_id":"ck3o9o91u009kv1npdeazsla8"},{"post_id":"ck3o9o842003ov1nprl2gj5qw","tag_id":"ck3o9o8z60072v1npn9wbf37k","_id":"ck3o9o91u009lv1np6730771e"},{"post_id":"ck3o9o843003rv1np7gqqe1sy","tag_id":"ck3o9o8z60072v1npn9wbf37k","_id":"ck3o9o91u009mv1npsrz8m90v"},{"post_id":"ck3o9o844003vv1npjfsapseo","tag_id":"ck3o9o8z80078v1npd3psbssv","_id":"ck3o9o91u009nv1npd09r5jzm"},{"post_id":"ck3o9o845003yv1npkzve6n6o","tag_id":"ck3o9o8z80078v1npd3psbssv","_id":"ck3o9o91u009ov1npzqmgw5i2"},{"post_id":"ck3o9o8460040v1np6k8huhnv","tag_id":"ck3o9o8z80078v1npd3psbssv","_id":"ck3o9o91u009pv1npash8d969"},{"post_id":"ck3o9o8480044v1npcfpu6apj","tag_id":"ck3o9o8z80078v1npd3psbssv","_id":"ck3o9o91u009qv1npvjpr0pvk"},{"post_id":"ck3o9o8480045v1npu09gwdzn","tag_id":"ck3o9o8z80078v1npd3psbssv","_id":"ck3o9o91u009rv1npezxpjl2i"},{"post_id":"ck3o9o84a0049v1npv9hbbkow","tag_id":"ck3o9o8z80078v1npd3psbssv","_id":"ck3o9o91u009sv1npnphottmv"},{"post_id":"ck3o9o84b004av1npyris4r01","tag_id":"ck3o9o8z80078v1npd3psbssv","_id":"ck3o9o91u009tv1npv3xawl0k"},{"post_id":"ck3o9o84k004qv1npk3rhile2","tag_id":"ck3o9o8zc007fv1npru66584q","_id":"ck3o9o91v009uv1np0du0h51x"},{"post_id":"ck3o9o84l004rv1npynmp0h8q","tag_id":"ck3o9o8zc007fv1npru66584q","_id":"ck3o9o91v009vv1np13grluo0"},{"post_id":"ck3o9o84m004sv1npyiob7eb5","tag_id":"ck3o9o8zc007fv1npru66584q","_id":"ck3o9o91v009wv1npd4c0hjlw"},{"post_id":"ck3o9o84m004tv1nprhwta91x","tag_id":"ck3o9o8zc007fv1npru66584q","_id":"ck3o9o91v009xv1np9mteomz3"},{"post_id":"ck3o9o84n004vv1np9v6nnjeo","tag_id":"ck3o9o8zc007fv1npru66584q","_id":"ck3o9o91v009yv1npag1axoju"},{"post_id":"ck3o9o84o004wv1npexa5sndv","tag_id":"ck3o9o8zc007fv1npru66584q","_id":"ck3o9o91v009zv1npt6u549gr"},{"post_id":"ck3o9o84p004yv1npsjkspm45","tag_id":"ck3o9o8zc007fv1npru66584q","_id":"ck3o9o91v00a0v1npc61rja8t"},{"post_id":"ck3o9o84p004zv1npxquqri17","tag_id":"ck3o9o8zc007fv1npru66584q","_id":"ck3o9o91v00a1v1npqu64sh0z"},{"post_id":"ck3o9o84r0053v1npdrmdwehf","tag_id":"ck3o9o8zc007fv1npru66584q","_id":"ck3o9o91v00a2v1npiwtqj71i"},{"post_id":"ck3o9o84s0054v1npx8sfv2fj","tag_id":"ck3o9o8zc007fv1npru66584q","_id":"ck3o9o91v00a3v1npt61ls0x0"},{"post_id":"ck3o9o84t0055v1npe83nckd3","tag_id":"ck3o9o8zc007fv1npru66584q","_id":"ck3o9o91w00a4v1np0kpwuao7"},{"post_id":"ck3o9o84v005av1np982j10fr","tag_id":"ck3o9o8zg007qv1npqnpqpz67","_id":"ck3o9o91w00a5v1npnmp3wlvm"},{"post_id":"ck3o9o84w005bv1npzzf0hwp3","tag_id":"ck3o9o8zg007rv1nputabhf9i","_id":"ck3o9o91w00a6v1npbnhk5nu8"},{"post_id":"ck3o9o84w005cv1npr74jwyda","tag_id":"ck3o9o8zg007rv1nputabhf9i","_id":"ck3o9o91w00a7v1npf9ntt7f2"},{"post_id":"ck3o9o84x005dv1npehvx1jq9","tag_id":"ck3o9o8zh007tv1npztu3o9lj","_id":"ck3o9o91w00a8v1np9j4ktrnx"},{"post_id":"ck3o9o84x005ev1npg6akec64","tag_id":"ck3o9o8zh007uv1npm9l1l12v","_id":"ck3o9o91w00a9v1nptj1mhf5k"}],"Tag":[{"name":"Cobar","_id":"ck3o9o8xn005fv1npizm9equg"},{"name":"Curator","_id":"ck3o9o8y7005hv1npvlkbvfhc"},{"name":"Raft","_id":"ck3o9o8y9005jv1nppvpphlml"},{"name":"分布式事务","_id":"ck3o9o8ya005kv1np9ik3vmui"},{"name":"分布式设计","_id":"ck3o9o8ya005lv1npaxjx6ig7"},{"name":"面试","_id":"ck3o9o8yb005nv1npysy6dvvw"},{"name":"Guava","_id":"ck3o9o8yc005ov1npj91o62rh"},{"name":"JVM","_id":"ck3o9o8yc005pv1npmoj6cijs"},{"name":"Kafka","_id":"ck3o9o8z4006wv1nppdi00vbe"},{"name":"Linux","_id":"ck3o9o8z60072v1npn9wbf37k"},{"name":"Netty","_id":"ck3o9o8z80078v1npd3psbssv"},{"name":"RocketMQ","_id":"ck3o9o8zc007fv1npru66584q"},{"name":"序列化","_id":"ck3o9o8zg007qv1npqnpqpz67"},{"name":"源码分析","_id":"ck3o9o8zg007rv1nputabhf9i"},{"name":"TCP","_id":"ck3o9o8zh007tv1npztu3o9lj"},{"name":"THread","_id":"ck3o9o8zh007uv1npm9l1l12v"}]}}